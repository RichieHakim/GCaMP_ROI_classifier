{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# import copy\n",
    "# import pathlib\n",
    "# import time\n",
    "# import gc\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import scipy\n",
    "\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# %matplotlib inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/josh/Documents/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Function\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "from basic_neural_processing_modules import h5_handling, pickle_helpers\n",
    "\n",
    "def load_h5(path, h5_keys):\n",
    "    base_data = h5_handling.simple_load(path=path)\n",
    "    h5_subsets = [base_data[key] for key in h5_keys]\n",
    "    return torch.as_tensor(np.concatenate(h5_subsets, axis=0), dtype=torch.float32, device='cpu')\n",
    "\n",
    "def drop_nan_imgs(rois):\n",
    "    ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(rois), dim=1), dim=1))[0]\n",
    "    return rois[ROIs_without_NaNs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "path_to_h5 = f'{base_dir}/label_data/masks_20211202_balanced.h5'\n",
    "h5_keys = ['RHmasks']\n",
    "\n",
    "data = load_h5(path_to_h5, h5_keys)\n",
    "data = drop_nan_imgs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217802 examples loaded.\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[0], 'examples loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[:2048]\n",
    "data = data[:data.shape[0]//100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "model_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=norm'\n",
    "model_file = importlib.import_module(model_name)\n",
    "\n",
    "### Have a .py file for each class definitions\n",
    "### Includes all architectures\n",
    "    # Within model.py — model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "    # Every .pth file will be associated with a single .py file that will instantiate the model / ModelTackOn\n",
    "\n",
    "model = model_file.get_model(model_name)\n",
    "# ?? model.eval();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Sets / Data Loaders\n",
    "\n",
    "# Include necessary transformations to push any data through -- no augmentations\n",
    "\n",
    "dataset, dataloader = model_file.get_dataset_dataloader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_latents(dataloader, model, DEVICE='cpu'):\n",
    "    def subset_to_latents(data):\n",
    "        return model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu()\n",
    "    return torch.cat([subset_to_latents(data) for data in tqdm(dataloader)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda49b79547849d2a56be2cb1d1c3a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Model Latents\n",
    "latents = dataloader_to_latents(dataloader, model).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_model(classifier_name):\n",
    "    with open(classifier_name, 'rb') as classifier_model_file:\n",
    "        classifier = pickle.load(classifier_model_file)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Logistic Model\n",
    "\n",
    "### Separate directory thing\n",
    "classifier_model = load_classifier_model('./logreg_model_0.01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCaMP_ROI_classifier.new_stuff import util\n",
    "def get_returns(latents, classifier_model):\n",
    "    ret = {}\n",
    "    ret['latents'] = latents\n",
    "    ret['proba'] = classifier_model.predict_proba(latents)\n",
    "    ret['preds'] = np.argmax(ret['proba'], axis=-1)\n",
    "    ret['uncertainty'] = util.loss_uncertainty(torch.as_tensor(ret['proba']), temperature=1, class_value=None).detach().cpu().numpy()\n",
    "    \n",
    "#     h5_prm = {}\n",
    "    params = classifier_model.get_params()\n",
    "#     for k in params:\n",
    "#         h5_prm[k] = np.array(params[k]).astype(np.float64)\n",
    "#     ret['params'] = h5_prm\n",
    "    ret['params'] = params\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ROIs — Save to File\n",
    "\n",
    "### Save the activations \n",
    "### \n",
    "\n",
    "### Outputs -- Latents for every ROI\n",
    "### Activations of the classifier for each example\n",
    "### Probabilities of activations for each example\n",
    "### Predictions for each example\n",
    "### L2 confidence value for each example\n",
    "\n",
    "### Details about the run\n",
    "### Throw all of the output arrays into an H5\n",
    "### If you can save strings -- save the names of the nets &\n",
    "### parameters of logistic regression (C/maxiter/etc.)\n",
    "### everything that generated the results. Save logistic\n",
    "### regression object as pickled file. -- get parameters\n",
    "### function of the logistic regression class\n",
    "### If it's possible to peel the parameters of the object --\n",
    "### get_params() -- take those and throw them into a nested part of H5.\n",
    "\n",
    "### Anything else I can think of.\n",
    "\n",
    "preds = classifier_model.predict_proba(latents)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = get_returns(latents, classifier_model)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_dict_to_h5( , ret , write_mode='w-', show_item_tree_pref=True)\n",
    "# h5_handling.simple_save(ret, path='./tmp_dict_h5.h5', write_mode='w', verbose=False)\n",
    "\n",
    "pickle_helpers.simple_save(ret, './tmp_dict_pkl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
