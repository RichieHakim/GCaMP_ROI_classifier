{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import copy\n",
    "# import pathlib\n",
    "# import time\n",
    "# import gc\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import scipy\n",
    "\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# %matplotlib inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Function\n",
    "def load_h5(path, h5_keys):\n",
    "    base_data = h5_handling.simple_load(path=path)\n",
    "    h5_subsets = [data_unlabeled[key] for key in h5_keys]\n",
    "    return torch.as_tensor(np.concatenate(h5_subsets, axis=0), dtype=torch.float32, device='cpu')\n",
    "\n",
    "def drop_nan_imgs(rois):\n",
    "    ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(rois), dim=1), dim=1))[0]\n",
    "    return masks_cat_raw[ROIs_without_NaNs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "path_to_h5 = f'{base_dir}/label_data/masks_20211202_balanced.h5'\n",
    "h5_keys = ['RHmasks']\n",
    "\n",
    "data = load_h5(path_to_h5, h5_keys)\n",
    "data = drop_nan_imgs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "def get_model():\n",
    "    base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "    model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))\n",
    "    model = ModelTackOn(model_chopped,\n",
    "                        base_model_frozen,\n",
    "                        pre_head_fc_sizes=[1024, 512],\n",
    "                        post_head_fc_sizes=[64],\n",
    "                        classifier_fc_sizes=[4])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "\n",
    "### Have a .py file for multiple class definitions\n",
    "### Includes all architectures\n",
    "    # Within model.py — model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "    # Every .pth file will be associated with a single .py file that will instantiate the model / ModelTackOn\n",
    "\n",
    "model = get_model('_____')\n",
    "# ?? model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Sets / Data Loaders\n",
    "\n",
    "# Include necessary transformations to push any data through -- no augmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Logistic Model\n",
    "\n",
    "### Separate directory thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ROIs — Save to File\n",
    "\n",
    "### Save the activations \n",
    "### \n",
    "\n",
    "### Outputs -- Latents for every ROI\n",
    "### Activations of the classifier for each example\n",
    "### Probabilities of activations for each example\n",
    "### Predictions for each example\n",
    "### L2 confidence value for each example\n",
    "\n",
    "### Details about the run\n",
    "### Throw all of the output arrays into an H5\n",
    "### If you can save strings -- save the names of the nets &\n",
    "### parameters of logistic regression (C/maxiter/etc.)\n",
    "### everything that generated the results. Save logistic\n",
    "### regression object as pickled file. -- get parameters\n",
    "### function of the logistic regression class\n",
    "### If it's possible to peel the parameters of the object --\n",
    "### get_params() -- take those and throw them into a nested part of H5.\n",
    "\n",
    "### Anything else I can think of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
