{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(_[0], _[1].requires_grad) for _ in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_SYT = data_labeled['SYTmasks']\n",
    "# labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "# non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "# labels_SYT = labels_SYT[non_nan]\n",
    "# masks_SYT = masks_SYT[non_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUEklEQVR4nO3df6xf9X3f8ecrhhArgYaIC3JsJ0aZ080g1RTLo0LasiQrLqlm0g7JbAWkMpkxkMjWboL80+QPb6nWJB3aYCMDYbYsrqUkw0pCWpcmy9AI5po5GGNYrOBgxx52ShFGmlht3vvjflC/u/na9/r++N5wP8+HdPQ9530+n3M+R5Zf9+jzPd/vN1WFJKkP71joAUiSRsfQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKGvRS/JwSQfn2bbSvLXZnieGfeVRsXQlxZQkmVJdiQ50v5orFroMWlxM/SlhfUm8G3gNxd6IOqDoa+uJFmf5IkkryY5muTfJnnnpGbXJvlRkp8m+ddJ3jHQ/7eT7E/yF0n+OMkHT3Oea5M8l+REkp8k+d1h7arq5aq6F3hq7q5SOj1DX705BfxT4CLgV4CPAf9kUptPAuuAXwY2Ar8NkOQ64NPAbwBjwH8HvnKa8zwA3FpV5wOXA382lxchzZShr65U1e6q+n5Vnayqg8B/AP72pGa/X1WvVNVLwB8CN7T6rcC/qqr9VXUS+JfA2tPc7f8lsCbJBVX1F1X19LxckHSWDH11JcmHk3wjyf9O8hoTwX3RpGaHBtZ/DLy/rX8Q+DdtauhV4BUgwPIhp/pN4Frgx0n+W5JfmcvrkGbK0Fdv7gOeB1ZX1QVMTNdkUpuVA+sfAI609UNMTNm8d2BZWlX/Y/JJquqpqtoIXAz8V2D7HF+HNCOGvnpzPvAa8HqSvw7cNqTNP09yYZKVwJ3AH7X6vwfuTnIZQJJfSHL95M5J3pnkHyb5har6y3a+U6cbUJJ3Aee1zfPatjQvDH315neBfwCcAL7EXwX6oEeA3cAe4JtMvClLVX0d+H1gW5saehb4tdOc50bgYGv3j4HfOsOY/g/welt/vm1L8yL+iIok9cM7fUnqiKEvSR0x9CWpI4a+JHXknIUewFQuuuiiWrVq1UIPQ5LeVnbv3v3TqhqbXP+5D/1Vq1YxPj6+0MOQpLeVJD8eVnd6R5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOvJz/4lcSXq7WnXXN2fc9+DnPjGHI/kr3ulLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSNThn6SdyXZleQHSfYl+WyrfybJT5Lsacu1A33uTnIgyQtJrhmoX5lkb9t3T5LMz2VJkoaZzrdsvgF8tKpeT3Iu8HiSR9u+L1bVHww2TrIG2ARcBrwf+NMkH66qU8B9wGbg+8C3gA3Ao0iSRmLKO/2a8HrbPLctdYYuG4FtVfVGVb0IHADWJ1kGXFBVT1RVAQ8D181q9JKkszKtOf0kS5LsAY4BO6vqybbrjiTPJHkwyYWtthw4NND9cKstb+uT68POtznJeJLx48ePT/9qJElnNK3Qr6pTVbUWWMHEXfvlTEzVfAhYCxwFPt+aD5unrzPUh53v/qpaV1XrxsbGpjNESdI0nNXTO1X1KvBdYENVvdz+GLwJfAlY35odBlYOdFsBHGn1FUPqkqQRmc7TO2NJ3tvWlwIfB55vc/Rv+STwbFvfAWxKcl6SS4HVwK6qOgqcSHJVe2rnJuCRubsUSdJUpvP0zjJga5IlTPyR2F5V30jyn5KsZWKK5iBwK0BV7UuyHXgOOAnc3p7cAbgNeAhYysRTOz65I0kjNGXoV9UzwBVD6jeeoc8WYMuQ+jhw+VmOUZI0R/xEriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjkznh9HflWRXkh8k2Zfks63+viQ7k/ywvV440OfuJAeSvJDkmoH6lUn2tn33tB9IlySNyHTu9N8APlpVvwSsBTYkuQq4C3isqlYDj7VtkqwBNgGXARuAe9uPqgPcB2wGVrdlw9xdiiRpKlOGfk14vW2e25YCNgJbW30rcF1b3whsq6o3qupF4ACwPsky4IKqeqKqCnh4oI8kaQSmNaefZEmSPcAxYGdVPQlcUlVHAdrrxa35cuDQQPfDrba8rU+uS5JGZFqhX1WnqmotsIKJu/bLz9B82Dx9naH+swdINicZTzJ+/Pjx6QxRkjQNZ/X0TlW9CnyXibn4l9uUDe31WGt2GFg50G0FcKTVVwypDzvP/VW1rqrWjY2Nnc0QJUlnMJ2nd8aSvLetLwU+DjwP7ABubs1uBh5p6zuATUnOS3IpE2/Y7mpTQCeSXNWe2rlpoI8kaQTOmUabZcDW9gTOO4DtVfWNJE8A25PcArwEXA9QVfuSbAeeA04Ct1fVqXas24CHgKXAo22RJI3IlKFfVc8AVwyp/znwsdP02QJsGVIfB870foAkaR75iVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI1OGfpKVSb6TZH+SfUnubPXPJPlJkj1tuXagz91JDiR5Ick1A/Urk+xt++5Jkvm5LEnSMFP+MDpwEvidqno6yfnA7iQ7274vVtUfDDZOsgbYBFwGvB/40yQfrqpTwH3AZuD7wLeADcCjc3MpkqSpTHmnX1VHq+rptn4C2A8sP0OXjcC2qnqjql4EDgDrkywDLqiqJ6qqgIeB62Z7AZKk6TurOf0kq4ArgCdb6Y4kzyR5MMmFrbYcODTQ7XCrLW/rk+vDzrM5yXiS8ePHj5/NECVJZzDt0E/yHuCrwKeq6jUmpmo+BKwFjgKff6vpkO51hvrPFqvur6p1VbVubGxsukOUJE1hWqGf5FwmAv/LVfU1gKp6uapOVdWbwJeA9a35YWDlQPcVwJFWXzGkLkkakek8vRPgAWB/VX1hoL5soNkngWfb+g5gU5LzklwKrAZ2VdVR4ESSq9oxbwIemaPrkCRNw3Se3rkauBHYm2RPq30auCHJWiamaA4CtwJU1b4k24HnmHjy5/b25A7AbcBDwFImntrxyR1JGqEpQ7+qHmf4fPy3ztBnC7BlSH0cuPxsBihJmjt+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkem88PoK5N8J8n+JPuS3Nnq70uyM8kP2+uFA33uTnIgyQtJrhmoX5lkb9t3T/uBdEnSiEznTv8k8DtV9TeAq4Dbk6wB7gIeq6rVwGNtm7ZvE3AZsAG4N8mSdqz7gM3A6rZsmMNrkSRNYcrQr6qjVfV0Wz8B7AeWAxuBra3ZVuC6tr4R2FZVb1TVi8ABYH2SZcAFVfVEVRXw8EAfSdIInNWcfpJVwBXAk8AlVXUUJv4wABe3ZsuBQwPdDrfa8rY+uT7sPJuTjCcZP378+NkMUZJ0BtMO/STvAb4KfKqqXjtT0yG1OkP9Z4tV91fVuqpaNzY2Nt0hSpKmMK3QT3IuE4H/5ar6Wiu/3KZsaK/HWv0wsHKg+wrgSKuvGFKXJI3IdJ7eCfAAsL+qvjCwawdwc1u/GXhkoL4pyXlJLmXiDdtdbQroRJKr2jFvGugjSRqBc6bR5mrgRmBvkj2t9mngc8D2JLcALwHXA1TVviTbgeeYePLn9qo61frdBjwELAUebYskaUSmDP2qepzh8/EAHztNny3AliH1ceDysxmgJGnu+IlcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdmc4Poz+Y5FiSZwdqn0nykyR72nLtwL67kxxI8kKSawbqVybZ2/bd034cXZI0QtO5038I2DCk/sWqWtuWbwEkWQNsAi5rfe5NsqS1vw/YDKxuy7BjSpLm0ZShX1XfA16Z5vE2Atuq6o2qehE4AKxPsgy4oKqeqKoCHgaum+GYJUkzNJs5/TuSPNOmfy5steXAoYE2h1tteVufXB8qyeYk40nGjx8/PoshSpIGzTT07wM+BKwFjgKfb/Vh8/R1hvpQVXV/Va2rqnVjY2MzHKIkabIZhX5VvVxVp6rqTeBLwPq26zCwcqDpCuBIq68YUpckjdCMQr/N0b/lk8BbT/bsADYlOS/JpUy8Yburqo4CJ5Jc1Z7auQl4ZBbjliTNwDlTNUjyFeAjwEVJDgO/B3wkyVompmgOArcCVNW+JNuB54CTwO1Vdaod6jYmngRaCjzaFknSCE0Z+lV1w5DyA2dovwXYMqQ+Dlx+VqOTJM0pP5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjU4Z+kgeTHEvy7EDtfUl2Jvlhe71wYN/dSQ4keSHJNQP1K5PsbfvuaT+QLkkaoenc6T8EbJhUuwt4rKpWA4+1bZKsATYBl7U+9yZZ0vrcB2wGVrdl8jElSfNsytCvqu8Br0wqbwS2tvWtwHUD9W1V9UZVvQgcANYnWQZcUFVPVFUBDw/0kSSNyEzn9C+pqqMA7fXiVl8OHBpod7jVlrf1yfWhkmxOMp5k/Pjx4zMcoiRpsrl+I3fYPH2doT5UVd1fVeuqat3Y2NicDU6SejfT0H+5TdnQXo+1+mFg5UC7FcCRVl8xpC5JGqGZhv4O4Oa2fjPwyEB9U5LzklzKxBu2u9oU0IkkV7Wndm4a6CNJGpFzpmqQ5CvAR4CLkhwGfg/4HLA9yS3AS8D1AFW1L8l24DngJHB7VZ1qh7qNiSeBlgKPtkWSNEJThn5V3XCaXR87TfstwJYh9XHg8rManSRpTvmJXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZlV6Cc5mGRvkj1JxlvtfUl2Jvlhe71woP3dSQ4keSHJNbMdvCTp7MzFnf7fqaq1VbWubd8FPFZVq4HH2jZJ1gCbgMuADcC9SZbMwfklSdM0H9M7G4GtbX0rcN1AfVtVvVFVLwIHgPXzcH5J0mnMNvQL+JMku5NsbrVLquooQHu9uNWXA4cG+h5uNUnSiJwzy/5XV9WRJBcDO5M8f4a2GVKroQ0n/oBsBvjABz4wyyFKkt4yqzv9qjrSXo8BX2diuublJMsA2uux1vwwsHKg+wrgyGmOe39VrauqdWNjY7MZoiRpwIxDP8m7k5z/1jrwq8CzwA7g5tbsZuCRtr4D2JTkvCSXAquBXTM9vyTp7M1meucS4OtJ3jrOf6mqbyd5Ctie5BbgJeB6gKral2Q78BxwEri9qk7NavSSpLMy49Cvqh8BvzSk/ufAx07TZwuwZabnlNSnVXd9c1b9D37uE3M0krc/P5ErSR0x9CWpI4a+JHXE0Jekjsz2w1n6OTObN7x8s0ta/LzTl6SOLOo7fe96Jen/552+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoy8tBPsiHJC0kOJLlr1OeXpJ6NNPSTLAH+HfBrwBrghiRrRjkGSerZqO/01wMHqupHVfV/gW3AxhGPQZK6laoa3cmSvw9sqKp/1LZvBP5mVd0xqd1mYHPb/EXghRme8iLgpzPs+3blNfeht2vu7Xph9tf8waoam1wc9Y+oZEjtZ/7qVNX9wP2zPlkyXlXrZnuctxOvuQ+9XXNv1wvzd82jnt45DKwc2F4BHBnxGCSpW6MO/aeA1UkuTfJOYBOwY8RjkKRujXR6p6pOJrkD+GNgCfBgVe2bx1POeorobchr7kNv19zb9cI8XfNI38iVJC0sP5ErSR0x9CWpI4sy9Hv8qockDyY5luTZhR7LKCRZmeQ7SfYn2ZfkzoUe03xL8q4ku5L8oF3zZxd6TKOSZEmS/5nkGws9llFIcjDJ3iR7kozP6bEX25x++6qH/wX8XSYeEX0KuKGqnlvQgc2zJH8LeB14uKouX+jxzLcky4BlVfV0kvOB3cB1i/nfOUmAd1fV60nOBR4H7qyq7y/w0OZdkn8GrAMuqKpfX+jxzLckB4F1VTXnH0hbjHf6XX7VQ1V9D3hloccxKlV1tKqebusngP3A8oUd1fyqCa+3zXPbsrju2oZIsgL4BPAfF3osi8FiDP3lwKGB7cMs8jDoXZJVwBXAkws8lHnXpjn2AMeAnVW16K8Z+EPgXwBvLvA4RqmAP0myu30tzZxZjKE/ra960OKQ5D3AV4FPVdVrCz2e+VZVp6pqLROfZl+fZFFP5SX5deBYVe1e6LGM2NVV9ctMfCPx7W36dk4sxtD3qx460ea1vwp8uaq+ttDjGaWqehX4LrBhYUcy764G/l6b494GfDTJf17YIc2/qjrSXo8BX2di2npOLMbQ96seOtDe1HwA2F9VX1jo8YxCkrEk723rS4GPA88v6KDmWVXdXVUrqmoVE/+X/6yqfmuBhzWvkry7PZxAkncDvwrM2VN5iy70q+ok8NZXPewHts/zVz38XEjyFeAJ4BeTHE5yy0KPaZ5dDdzIxJ3fnrZcu9CDmmfLgO8keYaJm5udVdXFI4yduQR4PMkPgF3AN6vq23N18EX3yKYk6fQW3Z2+JOn0DH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkf8HaHzVE381SwwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch_helpers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1cc7fba76dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_GPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# DEVICE = torch_helpers.set_device(use_GPU=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch_helpers' is not defined"
     ]
    }
   ],
   "source": [
    "DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/josh/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14f974292b54f758a559d5df028475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.15, 0.15), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    ")\n",
    "    \n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=default'\n",
    "model.forward = model.forward_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.5411, loss_val: nan, pos_over_neg: 1.0592623949050903 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.1111, loss_val: nan, pos_over_neg: 3.236527442932129 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 6.7996, loss_val: nan, pos_over_neg: 4.7997331619262695 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.6477, loss_val: nan, pos_over_neg: 27.631826400756836 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.5866, loss_val: nan, pos_over_neg: 21.695289611816406 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.5191, loss_val: nan, pos_over_neg: 27.44672203063965 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.4748, loss_val: nan, pos_over_neg: 24.605899810791016 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.4226, loss_val: nan, pos_over_neg: 25.321962356567383 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.3898, loss_val: nan, pos_over_neg: 38.1678352355957 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.367, loss_val: nan, pos_over_neg: 79.34306335449219 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.3407, loss_val: nan, pos_over_neg: 123.05043029785156 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.3282, loss_val: nan, pos_over_neg: 115.31581115722656 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.3047, loss_val: nan, pos_over_neg: 143.41839599609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.275, loss_val: nan, pos_over_neg: 149.4844207763672 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.2552, loss_val: nan, pos_over_neg: 151.4322509765625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.2373, loss_val: nan, pos_over_neg: 192.05929565429688 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.2175, loss_val: nan, pos_over_neg: 232.6253204345703 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.2126, loss_val: nan, pos_over_neg: 248.4789276123047 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.1946, loss_val: nan, pos_over_neg: 277.1551818847656 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.1811, loss_val: nan, pos_over_neg: 311.49444580078125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.1752, loss_val: nan, pos_over_neg: 426.5718994140625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.1536, loss_val: nan, pos_over_neg: 333.12835693359375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.1633, loss_val: nan, pos_over_neg: 218.2388916015625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 6.1337, loss_val: nan, pos_over_neg: 428.0062561035156 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 6.1324, loss_val: nan, pos_over_neg: 547.6406860351562 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 6.1194, loss_val: nan, pos_over_neg: 229.388916015625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 6.1222, loss_val: nan, pos_over_neg: 350.32806396484375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 6.1184, loss_val: nan, pos_over_neg: 544.017822265625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 6.1055, loss_val: nan, pos_over_neg: 474.1595458984375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 6.1104, loss_val: nan, pos_over_neg: 301.6853942871094 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 6.0887, loss_val: nan, pos_over_neg: 617.2664794921875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 6.0841, loss_val: nan, pos_over_neg: 328.838623046875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 6.0869, loss_val: nan, pos_over_neg: 407.0340576171875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 6.0728, loss_val: nan, pos_over_neg: 391.86224365234375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 6.0741, loss_val: nan, pos_over_neg: 377.46392822265625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 6.0556, loss_val: nan, pos_over_neg: 1403.2742919921875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 6.07, loss_val: nan, pos_over_neg: 496.73272705078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 6.0613, loss_val: nan, pos_over_neg: 252.94784545898438 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 6.0545, loss_val: nan, pos_over_neg: 394.7818603515625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 6.0477, loss_val: nan, pos_over_neg: 463.29058837890625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 6.054, loss_val: nan, pos_over_neg: 596.0033569335938 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 6.0405, loss_val: nan, pos_over_neg: 849.3046264648438 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 6.0392, loss_val: nan, pos_over_neg: 447.1424255371094 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 6.0335, loss_val: nan, pos_over_neg: 959.4078979492188 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 6.0415, loss_val: nan, pos_over_neg: 454.496826171875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 6.0281, loss_val: nan, pos_over_neg: 654.4046630859375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 6.0266, loss_val: nan, pos_over_neg: 648.5693969726562 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 6.0269, loss_val: nan, pos_over_neg: 657.3994140625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 6.0228, loss_val: nan, pos_over_neg: 580.0164794921875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 6.0119, loss_val: nan, pos_over_neg: 1128.383544921875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 6.016, loss_val: nan, pos_over_neg: 373.59765625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 6.0241, loss_val: nan, pos_over_neg: 559.369384765625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 6.0131, loss_val: nan, pos_over_neg: 682.6962890625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 6.0186, loss_val: nan, pos_over_neg: 915.0721435546875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 6.0056, loss_val: nan, pos_over_neg: 270.90631103515625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.9994, loss_val: nan, pos_over_neg: 381.2758483886719 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 6.0081, loss_val: nan, pos_over_neg: 264.4792175292969 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 6.0012, loss_val: nan, pos_over_neg: 496.9595642089844 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 6.0, loss_val: nan, pos_over_neg: 188.16627502441406 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.9987, loss_val: nan, pos_over_neg: 274.4844055175781 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.9978, loss_val: nan, pos_over_neg: 132.4634246826172 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.9818, loss_val: nan, pos_over_neg: 377.1601257324219 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.9843, loss_val: nan, pos_over_neg: 285.33544921875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.9943, loss_val: nan, pos_over_neg: 117.46995544433594 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 6.0019, loss_val: nan, pos_over_neg: 197.0648651123047 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.9961, loss_val: nan, pos_over_neg: 187.56951904296875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.977, loss_val: nan, pos_over_neg: 441.5752868652344 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.98, loss_val: nan, pos_over_neg: 232.3636474609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9742, loss_val: nan, pos_over_neg: 285.3995361328125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.9804, loss_val: nan, pos_over_neg: 282.4725036621094 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.9806, loss_val: nan, pos_over_neg: 214.15911865234375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.9726, loss_val: nan, pos_over_neg: 273.689697265625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.9764, loss_val: nan, pos_over_neg: 455.23773193359375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.973, loss_val: nan, pos_over_neg: 164.8780975341797 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.9749, loss_val: nan, pos_over_neg: 327.25384521484375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.9595, loss_val: nan, pos_over_neg: 291.9214782714844 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.9716, loss_val: nan, pos_over_neg: 186.5828094482422 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.9667, loss_val: nan, pos_over_neg: 300.794189453125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.9614, loss_val: nan, pos_over_neg: 358.3593444824219 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.9598, loss_val: nan, pos_over_neg: 243.73641967773438 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.9477, loss_val: nan, pos_over_neg: 490.9085693359375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.9611, loss_val: nan, pos_over_neg: 274.26806640625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.9568, loss_val: nan, pos_over_neg: 282.9115295410156 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9606, loss_val: nan, pos_over_neg: 236.66439819335938 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.946, loss_val: nan, pos_over_neg: 1601.255859375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 264.9794006347656 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.9497, loss_val: nan, pos_over_neg: 297.61474609375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.9527, loss_val: nan, pos_over_neg: 307.84088134765625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.9489, loss_val: nan, pos_over_neg: 317.65216064453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.9382, loss_val: nan, pos_over_neg: 588.5206909179688 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.9394, loss_val: nan, pos_over_neg: 297.5496520996094 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9402, loss_val: nan, pos_over_neg: 406.12091064453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.9532, loss_val: nan, pos_over_neg: 193.471435546875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.9401, loss_val: nan, pos_over_neg: 280.0110168457031 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.9352, loss_val: nan, pos_over_neg: 220.61473083496094 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.9396, loss_val: nan, pos_over_neg: 260.3316345214844 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.9494, loss_val: nan, pos_over_neg: 306.73065185546875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.9473, loss_val: nan, pos_over_neg: 232.29537963867188 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9396, loss_val: nan, pos_over_neg: 455.9507751464844 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.9366, loss_val: nan, pos_over_neg: 388.6786804199219 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9297, loss_val: nan, pos_over_neg: 385.90814208984375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.9433, loss_val: nan, pos_over_neg: 602.34423828125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.934, loss_val: nan, pos_over_neg: 384.77655029296875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.942, loss_val: nan, pos_over_neg: 503.0411682128906 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.9305, loss_val: nan, pos_over_neg: 551.2427368164062 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.9366, loss_val: nan, pos_over_neg: 398.56683349609375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.9284, loss_val: nan, pos_over_neg: 753.1249389648438 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.9334, loss_val: nan, pos_over_neg: 1121.3704833984375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.928, loss_val: nan, pos_over_neg: 810.7379760742188 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9218, loss_val: nan, pos_over_neg: 923.5484619140625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.9257, loss_val: nan, pos_over_neg: 386.66351318359375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.9203, loss_val: nan, pos_over_neg: 826.7962036132812 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 348.5617980957031 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.9246, loss_val: nan, pos_over_neg: 457.6337585449219 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.9153, loss_val: nan, pos_over_neg: 696.3280639648438 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.9358, loss_val: nan, pos_over_neg: 143.2862091064453 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 537.2359619140625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.9212, loss_val: nan, pos_over_neg: 379.6175231933594 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.9204, loss_val: nan, pos_over_neg: 392.92108154296875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.9331, loss_val: nan, pos_over_neg: 216.22085571289062 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.9208, loss_val: nan, pos_over_neg: 312.5001220703125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.9292, loss_val: nan, pos_over_neg: 202.8278045654297 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.9187, loss_val: nan, pos_over_neg: 388.5715026855469 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.9179, loss_val: nan, pos_over_neg: 297.5546569824219 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.9154, loss_val: nan, pos_over_neg: 206.49893188476562 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.9202, loss_val: nan, pos_over_neg: 158.20448303222656 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.9176, loss_val: nan, pos_over_neg: 326.2987060546875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.9196, loss_val: nan, pos_over_neg: 179.46607971191406 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.9131, loss_val: nan, pos_over_neg: 712.624267578125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.9205, loss_val: nan, pos_over_neg: 210.852783203125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 516.0079956054688 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.9131, loss_val: nan, pos_over_neg: 436.426513671875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.9199, loss_val: nan, pos_over_neg: 977.9222412109375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 384.3013610839844 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.9102, loss_val: nan, pos_over_neg: 368.4949645996094 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.9289, loss_val: nan, pos_over_neg: 305.60894775390625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 237.3574981689453 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.9151, loss_val: nan, pos_over_neg: 370.9686279296875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.9178, loss_val: nan, pos_over_neg: 207.4466094970703 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.9159, loss_val: nan, pos_over_neg: 256.1927490234375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.9152, loss_val: nan, pos_over_neg: 306.4562683105469 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 226.64071655273438 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.9128, loss_val: nan, pos_over_neg: 216.37283325195312 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.915, loss_val: nan, pos_over_neg: 539.3475952148438 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 251.2081298828125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 343.9605407714844 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 201.6256561279297 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 244.97772216796875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.9065, loss_val: nan, pos_over_neg: 258.48040771484375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.9121, loss_val: nan, pos_over_neg: 501.0278625488281 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.9145, loss_val: nan, pos_over_neg: 286.36981201171875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 355.0216369628906 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.9039, loss_val: nan, pos_over_neg: 198.9960174560547 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.907, loss_val: nan, pos_over_neg: 236.0748748779297 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.9079, loss_val: nan, pos_over_neg: 191.46946716308594 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.909, loss_val: nan, pos_over_neg: 225.55987548828125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 458.0835876464844 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.9085, loss_val: nan, pos_over_neg: 151.4971466064453 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.9018, loss_val: nan, pos_over_neg: 220.41973876953125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 318.3958435058594 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.9107, loss_val: nan, pos_over_neg: 149.64987182617188 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 392.7933654785156 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.9139, loss_val: nan, pos_over_neg: 293.2562255859375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.9071, loss_val: nan, pos_over_neg: 225.13719177246094 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.9009, loss_val: nan, pos_over_neg: 305.9122619628906 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 230.43447875976562 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 283.45477294921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 309.3838195800781 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 202.70986938476562 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 480.5371398925781 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 277.9996337890625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8999, loss_val: nan, pos_over_neg: 218.21177673339844 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 359.65863037109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8999, loss_val: nan, pos_over_neg: 254.7541961669922 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 332.85662841796875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 156.02476501464844 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.9051, loss_val: nan, pos_over_neg: 319.7023010253906 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 363.14794921875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.9045, loss_val: nan, pos_over_neg: 312.6104431152344 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 443.8044738769531 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.9012, loss_val: nan, pos_over_neg: 325.35662841796875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8853, loss_val: nan, pos_over_neg: 379.8262939453125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 421.6338195800781 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8872, loss_val: nan, pos_over_neg: 469.672607421875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 518.434326171875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 557.9445190429688 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 434.3085632324219 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8917, loss_val: nan, pos_over_neg: 458.1703186035156 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 508.2038879394531 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8912, loss_val: nan, pos_over_neg: 458.6784973144531 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8896, loss_val: nan, pos_over_neg: 292.3089599609375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8835, loss_val: nan, pos_over_neg: 635.7197875976562 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8878, loss_val: nan, pos_over_neg: 414.8761901855469 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8908, loss_val: nan, pos_over_neg: 319.72088623046875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8922, loss_val: nan, pos_over_neg: 470.2619934082031 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8901, loss_val: nan, pos_over_neg: 343.1057434082031 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 411.7867126464844 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8825, loss_val: nan, pos_over_neg: 330.2955322265625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 428.52435302734375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8891, loss_val: nan, pos_over_neg: 347.2069396972656 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 472.94403076171875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8958, loss_val: nan, pos_over_neg: 905.311279296875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8892, loss_val: nan, pos_over_neg: 494.8865051269531 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 498.85418701171875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 390.2584533691406 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.895, loss_val: nan, pos_over_neg: 239.40716552734375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8839, loss_val: nan, pos_over_neg: 705.3309326171875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 363.6382751464844 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 436.1103820800781 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 287.1240539550781 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8924, loss_val: nan, pos_over_neg: 419.9329833984375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 306.43426513671875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 349.94891357421875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 401.9412841796875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 225.37738037109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 561.5005493164062 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8843, loss_val: nan, pos_over_neg: 573.62939453125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8783, loss_val: nan, pos_over_neg: 289.2052001953125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.883, loss_val: nan, pos_over_neg: 275.31817626953125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 415.0041809082031 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 443.7305603027344 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 382.38909912109375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8841, loss_val: nan, pos_over_neg: 593.7662353515625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 331.3123779296875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8813, loss_val: nan, pos_over_neg: 385.1626281738281 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8848, loss_val: nan, pos_over_neg: 421.878662109375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 266.75537109375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 315.4652099609375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 281.0825500488281 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 365.30206298828125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8738, loss_val: nan, pos_over_neg: 486.8310241699219 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 241.57492065429688 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 466.8612060546875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 395.83544921875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 449.4658508300781 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 571.2069702148438 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 422.54339599609375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 514.652587890625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 494.34979248046875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 814.4564819335938 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 506.8334655761719 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 668.687255859375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 502.43804931640625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 342.2362365722656 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 473.1329650878906 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 358.3614196777344 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 373.12640380859375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 460.9366760253906 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 532.1607055664062 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8754, loss_val: nan, pos_over_neg: 222.36178588867188 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 989.005615234375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8717, loss_val: nan, pos_over_neg: 232.90170288085938 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8673, loss_val: nan, pos_over_neg: 485.6452331542969 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 632.5682373046875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 356.87982177734375 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 766.8944091796875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 1001.2249145507812 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 333.91131591796875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 518.7106323242188 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 291.0449523925781 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 321.33868408203125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 537.3133544921875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8683, loss_val: nan, pos_over_neg: 622.097412109375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 468.6255187988281 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 492.1857604980469 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 583.0111083984375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 410.21734619140625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 514.7424926757812 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 767.5147705078125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 452.93170166015625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 764.035400390625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 929.900146484375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 356.7826843261719 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 621.1871948242188 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 455.56683349609375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 477.9310607910156 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 297.9556884765625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 410.4861145019531 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 567.8734741210938 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 538.5025634765625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 294.5372619628906 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 288.2881774902344 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 587.89111328125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 631.7052612304688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 264.55657958984375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 562.7904052734375 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 469.24395751953125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 391.81085205078125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 1379.3255615234375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 304.302978515625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 600.3980102539062 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 2369.85400390625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8651, loss_val: nan, pos_over_neg: 394.75787353515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 315.8934631347656 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 647.4309692382812 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 502.6444396972656 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 840.049560546875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 1033.3291015625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 340.087646484375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 415.79754638671875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 443.61846923828125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 371.7149658203125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 434.893310546875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 652.0569458007812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 569.2185668945312 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 320.2918395996094 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 301.64312744140625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 433.0592956542969 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 326.4866638183594 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8593, loss_val: nan, pos_over_neg: 379.67926025390625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 467.2384033203125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 512.5743408203125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 383.418212890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 381.0321350097656 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 593.867431640625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 697.5585327148438 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 588.2948608398438 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 405.96527099609375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 534.5236206054688 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 161.1255340576172 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 337.5500183105469 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 312.1282043457031 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 391.6070556640625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 402.0593566894531 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 348.2807312011719 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 824.428955078125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 373.6597595214844 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 218.78521728515625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 511.8371276855469 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 327.03216552734375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 335.37646484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 553.4093627929688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 453.43231201171875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 434.94488525390625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 513.2366333007812 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 637.9635620117188 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 599.1920776367188 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 506.46435546875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1008.5286254882812 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 385.7738952636719 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 317.024169921875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 753.14990234375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 624.4983520507812 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 524.7177734375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 562.3231811523438 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 989.3966674804688 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 384.5263977050781 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 722.433837890625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 579.1134643554688 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 929.143310546875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 805.1903076171875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 576.2215576171875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 675.2417602539062 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 485.8847351074219 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 545.9652709960938 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 797.72314453125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1132.9017333984375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 488.50628662109375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 538.30712890625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 938.3367919921875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 733.3816528320312 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 852.255859375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 719.9910888671875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 557.5885620117188 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 916.4676513671875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 486.8207702636719 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 1093.91845703125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 526.3231201171875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 1104.137451171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 625.903076171875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 713.1082153320312 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1022.2177734375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 765.5811767578125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 1051.768798828125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 1487.0621337890625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 307.50970458984375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 676.9764404296875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8519, loss_val: nan, pos_over_neg: 830.6240844726562 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 645.2799682617188 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 2537.415283203125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 576.5502319335938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 334.3704833984375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 642.4667358398438 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 737.310302734375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 239.9048309326172 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 360.8359375 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 502.2469787597656 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 344.71197509765625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 413.959716796875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 420.13330078125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 330.8096618652344 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 356.646728515625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 382.5062255859375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 374.5344543457031 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 462.89752197265625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 677.7240600585938 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 396.5465393066406 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 464.0140380859375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1239.0283203125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 462.6827697753906 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 457.5995178222656 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 474.6021728515625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 441.3175048828125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 340.4575500488281 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 914.5401000976562 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 799.7611694335938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 319.72210693359375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 388.0775146484375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 896.423583984375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 466.6935119628906 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 488.80023193359375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 534.0309448242188 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 967.771728515625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1592.5372314453125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 588.8681030273438 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 634.07373046875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 471.0279846191406 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 628.9730834960938 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 287.7059020996094 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 733.87939453125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 520.7992553710938 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 408.29638671875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 928.2449951171875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 581.7451171875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 408.7223815917969 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 1324.7889404296875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 648.5648193359375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 454.48516845703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 408.1045837402344 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 532.1016235351562 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 600.2213745117188 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 449.72222900390625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 568.0477294921875 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 303.34844970703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 552.1015625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 856.4384155273438 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 781.7352294921875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1642.169189453125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 519.1943969726562 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 414.6566162109375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 562.1210327148438 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1248.7664794921875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 428.65142822265625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 396.2169189453125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 614.4996337890625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 374.6924743652344 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 301.31005859375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 604.4854736328125 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 694.83544921875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 490.6768493652344 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 446.1412048339844 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1467.4649658203125 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 558.8969116210938 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 649.419189453125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 456.5855407714844 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 400.8526306152344 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 604.0333862304688 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 877.4136352539062 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 275.3774108886719 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 308.7056884765625 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 657.24853515625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 495.155517578125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 579.3722534179688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 621.1004638671875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1076.231689453125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1531.187744140625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 505.3993835449219 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8252, loss_val: nan, pos_over_neg: 1016.1669921875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 1906.1016845703125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 480.2744445800781 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 351.4363708496094 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 625.3176879882812 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 341.2700500488281 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 550.7190551757812 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 343.8113708496094 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 860.2276611328125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 266.06280517578125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 742.4344482421875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 367.4197692871094 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 406.0503234863281 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 905.5067749023438 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 502.0009460449219 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 386.6715087890625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 209.82801818847656 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 681.6788330078125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 366.9575500488281 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 477.9522705078125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 991.9985961914062 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 634.1044921875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 502.2566223144531 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 778.9251098632812 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8306, loss_val: nan, pos_over_neg: 606.4273681640625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 406.390869140625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 324.155029296875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 452.3140869140625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 578.397705078125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 335.6120910644531 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 415.4976501464844 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 533.9605712890625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 220.33486938476562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 522.7935180664062 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 430.2674255371094 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 266.4413757324219 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1003.791259765625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 614.7468872070312 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 248.79005432128906 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 335.9574279785156 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 589.9540405273438 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 555.3246459960938 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 225.8197479248047 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 459.1532287597656 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 473.6697082519531 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 453.5172424316406 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 304.99664306640625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 649.6158447265625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 580.8357543945312 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 619.82080078125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 513.2044677734375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 494.3911437988281 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8248, loss_val: nan, pos_over_neg: 796.4515380859375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8307, loss_val: nan, pos_over_neg: 344.7320861816406 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 693.7025146484375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 908.9283447265625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 529.6823120117188 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 343.26275634765625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 271.9039306640625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 432.78900146484375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 623.993896484375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 356.4383239746094 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 481.62432861328125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 377.511474609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 413.170166015625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 555.2539672851562 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 640.47119140625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 480.7867431640625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 398.307861328125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 638.1804809570312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 436.0295715332031 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 486.3904724121094 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 403.04718017578125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 569.5184936523438 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 541.5629272460938 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 590.60546875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 483.9391174316406 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 352.1444091796875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 833.4563598632812 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 675.1600341796875 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 389.90130615234375 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 365.2412109375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 1064.157470703125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 470.7794189453125 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 392.1070251464844 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 334.0672302246094 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 288.62518310546875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 338.1103820800781 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 464.911376953125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1308.352783203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 611.2966918945312 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 418.8901672363281 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 748.3226928710938 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 548.1212768554688 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 380.4026184082031 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 771.3038940429688 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 856.170654296875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 445.44561767578125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 449.34759521484375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 595.2987670898438 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 786.5506591796875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8233, loss_val: nan, pos_over_neg: 409.54815673828125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 604.8433227539062 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 684.7357788085938 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 494.9058532714844 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 466.783935546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 857.8911743164062 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 643.4329223632812 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 406.2275085449219 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 632.1973266601562 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 904.4273681640625 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 1060.1351318359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 503.7689514160156 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 558.1215209960938 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 545.02392578125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 571.070068359375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 403.8465881347656 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 313.7022705078125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 1197.669189453125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 880.1221923828125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 1784.7100830078125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 375.5597839355469 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 455.51995849609375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 399.49359130859375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 399.482421875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 426.6829528808594 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 940.7045288085938 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 781.1063842773438 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 413.47967529296875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 258.06097412109375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 675.0615844726562 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8223, loss_val: nan, pos_over_neg: 939.785888671875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 304.0751647949219 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 329.0513916015625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 352.1204833984375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 1131.4246826171875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 406.0364074707031 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 402.13165283203125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 456.70458984375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 559.2935180664062 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 667.9758911132812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 398.1170959472656 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8204, loss_val: nan, pos_over_neg: 606.24267578125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 484.7119445800781 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8265, loss_val: nan, pos_over_neg: 536.5654296875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 649.2756958007812 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 570.1985473632812 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 616.9313354492188 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 592.9872436523438 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 710.9930419921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 665.0933227539062 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8228, loss_val: nan, pos_over_neg: 786.7293090820312 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8217, loss_val: nan, pos_over_neg: 550.3607788085938 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 370.47723388671875 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 727.4169921875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 686.7257690429688 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 716.2828369140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 769.8720703125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 300.39483642578125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 655.7926025390625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.827, loss_val: nan, pos_over_neg: 733.3910522460938 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 565.4588623046875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 426.8345642089844 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 445.9276428222656 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 531.850830078125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 306.11016845703125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 372.9922790527344 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 487.0645751953125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 401.42645263671875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 940.7601318359375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 330.9799499511719 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 374.5946960449219 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 530.8577880859375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 293.49688720703125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 411.21356201171875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 355.646728515625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 309.9566650390625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 490.20428466796875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 491.3627014160156 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8122, loss_val: nan, pos_over_neg: 577.621826171875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 473.2652587890625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8264, loss_val: nan, pos_over_neg: 484.10284423828125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 727.4931640625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 669.9480590820312 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 825.7979125976562 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.827, loss_val: nan, pos_over_neg: 514.7442626953125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 543.551025390625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 894.072265625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8224, loss_val: nan, pos_over_neg: 1085.5855712890625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 457.0010681152344 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 449.70068359375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8206, loss_val: nan, pos_over_neg: 1038.057373046875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 1127.398193359375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8165, loss_val: nan, pos_over_neg: 830.6585083007812 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8184, loss_val: nan, pos_over_neg: 618.5556030273438 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 939.9082641601562 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 368.7000732421875 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: 397.2945251464844 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 738.4837646484375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8204, loss_val: nan, pos_over_neg: 554.9605102539062 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 346.14276123046875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 626.1834716796875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8211, loss_val: nan, pos_over_neg: 569.7244262695312 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 426.8154602050781 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 544.4388427734375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 395.9910583496094 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.819, loss_val: nan, pos_over_neg: 831.58740234375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 530.4847412109375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8263, loss_val: nan, pos_over_neg: 492.579345703125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 507.4964294433594 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 392.9183349609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8224, loss_val: nan, pos_over_neg: 322.3828125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8191, loss_val: nan, pos_over_neg: 513.7591552734375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 592.9238891601562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8222, loss_val: nan, pos_over_neg: 395.6203918457031 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 382.91888427734375 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 1378.7587890625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 566.3374633789062 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8221, loss_val: nan, pos_over_neg: 286.6322937011719 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8231, loss_val: nan, pos_over_neg: 707.004638671875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 640.4971313476562 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 420.3765869140625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 523.762451171875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 1191.95263671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 420.2113952636719 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 647.4256591796875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 1233.4156494140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 440.71002197265625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [20:31<102665:57:50, 1232.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 763.1651611328125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 698.0069580078125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 476.7935791015625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8212, loss_val: nan, pos_over_neg: 964.7258911132812 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8211, loss_val: nan, pos_over_neg: 676.50390625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8139, loss_val: nan, pos_over_neg: 1042.5511474609375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 761.4599609375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 434.4414978027344 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 1378.072509765625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 325.4195556640625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8166, loss_val: nan, pos_over_neg: 712.9781494140625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 670.8097534179688 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 1409.117919921875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 651.9111328125 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 659.716796875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8265, loss_val: nan, pos_over_neg: 742.426513671875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 696.2476806640625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 410.61456298828125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8234, loss_val: nan, pos_over_neg: 499.8667297363281 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 513.530517578125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8124, loss_val: nan, pos_over_neg: 931.8460693359375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 1120.0777587890625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 2476.891357421875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 523.9747924804688 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8125, loss_val: nan, pos_over_neg: 1081.8157958984375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 682.0394287109375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8191, loss_val: nan, pos_over_neg: 462.35614013671875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 1009.284912109375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 563.0723266601562 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 775.4041137695312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8139, loss_val: nan, pos_over_neg: 957.9944458007812 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 937.8580932617188 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 1211.7552490234375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 1329.2210693359375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 952.8217163085938 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 738.874755859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 1174.6923828125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 1463.1436767578125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 1018.5989379882812 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 594.3646850585938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 2539.3359375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 2180.929931640625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 926.7683715820312 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8173, loss_val: nan, pos_over_neg: 387.8627624511719 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 1226.68603515625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 641.4188232421875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 6033.982421875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 2482.529052734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 357.2684326171875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 1159.159423828125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 1493.3924560546875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 1677.6651611328125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 603.8197631835938 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 674.0306396484375 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 561.9432373046875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 334.361083984375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 399.0252685546875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8152, loss_val: nan, pos_over_neg: 358.8720703125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 427.7254333496094 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 412.93359375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 438.9312438964844 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8162, loss_val: nan, pos_over_neg: 699.4108276367188 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8166, loss_val: nan, pos_over_neg: 856.6190185546875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 385.64605712890625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 403.0106201171875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 937.644775390625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.824, loss_val: nan, pos_over_neg: 609.4912109375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 736.4808349609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 389.73663330078125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 497.38299560546875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 736.948974609375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 366.1299743652344 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 468.6256408691406 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 433.89373779296875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 1806.80419921875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 664.3115234375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 658.9043579101562 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 774.197998046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 1701.887939453125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 479.3162841796875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 282.85308837890625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 722.1370849609375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 710.86328125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 1108.25 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 919.1700439453125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 731.271240234375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.815, loss_val: nan, pos_over_neg: 602.2167358398438 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 1000.0205078125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 808.900390625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 604.2078857421875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 1126.7119140625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1520.5899658203125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 723.3223876953125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 843.7172241210938 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 612.8182983398438 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 686.744384765625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 575.6328735351562 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 462.97247314453125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 594.08203125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 402.9997253417969 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 528.3252563476562 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 662.3430786132812 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 443.90985107421875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 563.4451293945312 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8179, loss_val: nan, pos_over_neg: 320.2216796875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 677.2987060546875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 467.7087097167969 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 385.75439453125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 684.8018798828125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 455.82525634765625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8197, loss_val: nan, pos_over_neg: 696.2030639648438 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 751.947021484375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 642.511474609375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 1029.7919921875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 1105.10009765625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 650.5270385742188 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 301.7258605957031 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 627.120849609375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 589.7308959960938 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 596.56494140625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8203, loss_val: nan, pos_over_neg: 643.4275512695312 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 482.24090576171875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 2087.58837890625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 484.9422607421875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 1424.002685546875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 729.2522583007812 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8137, loss_val: nan, pos_over_neg: 504.4057922363281 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 2213.58740234375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 1262.3349609375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 816.3905029296875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8169, loss_val: nan, pos_over_neg: 2260.930908203125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 2338.155029296875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 1236.899169921875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 759.2911987304688 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 491.49237060546875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 855.6123657226562 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 514.6741943359375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 610.9224853515625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 697.313232421875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 809.2507934570312 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 447.2563171386719 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 585.6387329101562 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 1242.07275390625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 454.97857666015625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 850.9401245117188 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8167, loss_val: nan, pos_over_neg: 534.25634765625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 717.6690673828125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 833.8004760742188 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 2781.5751953125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 879.0545043945312 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 873.2664794921875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 915.5911254882812 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 1217.951904296875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 923.6704711914062 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 683.2911987304688 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 651.9796752929688 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8153, loss_val: nan, pos_over_neg: 639.4520263671875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 779.3659057617188 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 895.8731079101562 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 432.7518615722656 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 605.4259033203125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 678.6248779296875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 366.51580810546875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 444.35614013671875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 943.7920532226562 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 422.5785827636719 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 590.3883666992188 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 829.6067504882812 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 374.1181335449219 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 1438.912841796875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 418.08135986328125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 456.906005859375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 551.402587890625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 545.2080688476562 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 928.3632202148438 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 530.2096557617188 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.816, loss_val: nan, pos_over_neg: 460.41168212890625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 422.9637756347656 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 470.3834228515625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 336.2019958496094 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8168, loss_val: nan, pos_over_neg: 471.9013671875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8153, loss_val: nan, pos_over_neg: 472.78936767578125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 431.24517822265625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 576.881591796875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 540.2484130859375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8112, loss_val: nan, pos_over_neg: 871.9070434570312 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 601.9852905273438 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 713.4906005859375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 580.7798461914062 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 663.7246704101562 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 1201.7154541015625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 582.386962890625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 380.87353515625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8075, loss_val: nan, pos_over_neg: 791.3986206054688 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 1702.52978515625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 1787.1839599609375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 972.836181640625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 1030.8956298828125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 1407.6976318359375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 1908.7767333984375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 954.3912963867188 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 394.3869934082031 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1271.2261962890625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8064, loss_val: nan, pos_over_neg: 579.7183837890625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 495.24981689453125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 868.209716796875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 1064.20263671875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 435.7030944824219 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 530.0988159179688 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 772.604736328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 2380.43505859375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 806.7615966796875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 348.7166442871094 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 668.3764038085938 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 1122.38037109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 579.92138671875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 379.0142822265625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 499.54071044921875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 1168.796875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 740.933349609375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8104, loss_val: nan, pos_over_neg: 670.5765991210938 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 472.83056640625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 935.11865234375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 714.30810546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 390.1725769042969 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 510.5552978515625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 382.47247314453125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 851.0830688476562 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 824.8532104492188 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 519.0655517578125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 906.2153930664062 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 766.5719604492188 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 858.6887817382812 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 485.3473815917969 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8122, loss_val: nan, pos_over_neg: 614.8735961914062 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 533.947265625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 643.5886840820312 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 1061.277587890625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 596.6171264648438 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 795.1245727539062 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 520.03662109375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 757.1956787109375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 946.01318359375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 688.8826904296875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 664.7505493164062 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 872.6712646484375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 697.1812133789062 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 1305.7476806640625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8038, loss_val: nan, pos_over_neg: 813.4403686523438 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 537.7213745117188 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 1458.40283203125 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 743.6881103515625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 1084.9459228515625 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 1138.8489990234375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 534.4567260742188 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 485.159423828125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 390.5928955078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 529.0042114257812 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 2334.989990234375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 675.7506713867188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 473.7375183105469 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 695.1329956054688 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 1723.3941650390625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 659.7634887695312 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 893.8411254882812 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 972.8357543945312 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 1048.65576171875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 587.7943725585938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 344.04107666015625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 984.5750732421875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 754.2061767578125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 577.0736083984375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 543.8947143554688 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 878.4201049804688 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 898.182861328125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 702.3134155273438 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 531.81005859375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 649.7445678710938 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 836.7142333984375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 392.69891357421875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 395.9484558105469 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8126, loss_val: nan, pos_over_neg: 483.6117858886719 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 770.448974609375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 474.16217041015625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 378.6313171386719 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 705.0174560546875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 475.9314270019531 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8088, loss_val: nan, pos_over_neg: 551.8212890625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 585.5553588867188 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 509.6341552734375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 826.9478149414062 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 509.6580505371094 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 311.755859375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 710.3956298828125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 3554.033935546875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 1218.551025390625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 780.0655517578125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8158, loss_val: nan, pos_over_neg: 358.5574035644531 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1155.6334228515625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 485.8587951660156 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 329.737548828125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 514.7277221679688 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 825.9283447265625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.807, loss_val: nan, pos_over_neg: 882.2424926757812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 657.8804931640625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 588.118896484375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 668.9876098632812 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 1577.0992431640625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 840.33740234375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 575.572998046875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 623.2982788085938 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 521.9666137695312 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 956.6228637695312 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 1333.360107421875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 662.2750244140625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 477.8021240234375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 491.6752624511719 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 2012.102783203125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 459.1629333496094 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 733.5505981445312 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 1050.111328125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1593.78369140625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 799.0186157226562 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 476.18896484375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 536.7991333007812 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 563.196533203125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8049, loss_val: nan, pos_over_neg: 917.0784912109375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 842.99658203125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 499.5499572753906 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 1735.73828125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 7925.0439453125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 434.5365905761719 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 414.416015625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 1081.508544921875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 690.9625854492188 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 681.1044311523438 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 1442.1900634765625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 536.681396484375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 628.2658081054688 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 970.8355102539062 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 1339.8277587890625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 434.9658203125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 379.25299072265625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 774.6320190429688 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 1224.65625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 624.5450439453125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 523.8099975585938 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 652.3477172851562 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 362.9884948730469 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 343.8351745605469 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 957.7969360351562 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 411.5618896484375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 456.4035949707031 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 1652.3089599609375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 422.83001708984375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 831.4210205078125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 678.5230712890625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 539.6493530273438 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 415.9213562011719 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 596.9321899414062 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 1128.2242431640625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 534.04052734375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 421.006103515625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8028, loss_val: nan, pos_over_neg: 964.0458984375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 1808.47998046875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 508.46441650390625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 469.20147705078125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 811.8060302734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 640.4015502929688 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 544.9495239257812 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 1012.517822265625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 609.8886108398438 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 7128.17626953125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 856.867919921875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 415.0548400878906 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 488.21649169921875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 382.7571105957031 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 494.62261962890625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 477.3162536621094 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 433.7618103027344 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 643.8600463867188 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 1290.12841796875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 768.8301391601562 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 459.1131591796875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 797.3894653320312 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 1015.5499877929688 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 661.0585327148438 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 736.913818359375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1802.028076171875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 990.3292236328125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 546.9397583007812 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1269.60693359375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 1106.9832763671875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 567.3433227539062 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 1633.460205078125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 1607.07568359375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1152.3057861328125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 2759.1015625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 1218.7510986328125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 976.234130859375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 858.1039428710938 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 873.7568359375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 1252.5313720703125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 530.8359985351562 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 1754.0323486328125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 730.772705078125 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 654.2706298828125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 661.907470703125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 941.86279296875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 522.1565551757812 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 876.4891967773438 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 426.4448547363281 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8028, loss_val: nan, pos_over_neg: 521.7489624023438 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 586.3397216796875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 730.556640625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 587.36474609375 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 361.3953857421875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 506.34478759765625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 643.8887329101562 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 607.2106323242188 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 980.0944213867188 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 537.9724731445312 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 3781.333984375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 867.7156982421875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 495.3766784667969 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 1159.2322998046875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 491.358642578125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 1307.0699462890625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 555.8013916015625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 425.6192626953125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 609.585693359375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 473.06573486328125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 572.9671020507812 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 1583.2498779296875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 616.0672607421875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8064, loss_val: nan, pos_over_neg: 356.7377014160156 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 536.14794921875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 516.6758422851562 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 806.3627319335938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 652.0236206054688 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.803, loss_val: nan, pos_over_neg: 605.2034912109375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 485.40008544921875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 1021.1365356445312 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 910.822021484375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 520.847900390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 589.6528930664062 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 1185.1348876953125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 949.3745727539062 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 620.530029296875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 891.7156372070312 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 746.4663696289062 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 730.1854248046875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 631.7598876953125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 668.3384399414062 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1695.3116455078125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 1083.4205322265625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 729.3195190429688 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 1547.2139892578125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 1117.614990234375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 690.2161254882812 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 606.9176635742188 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 1124.1728515625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 864.0062866210938 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 1159.15087890625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 1207.186279296875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 675.849365234375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 1955.80517578125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 546.3269653320312 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 1896.380615234375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 784.8008422851562 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 526.3732299804688 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 857.0545043945312 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 706.813720703125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1225.5635986328125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 724.7910766601562 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 858.4526977539062 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 855.8195190429688 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 447.54498291015625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 633.2122802734375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 1023.9971313476562 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 604.3153686523438 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 638.7923583984375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 2158.329833984375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 721.8656005859375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 706.6146850585938 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 423.3343811035156 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 1022.8851318359375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1551.627197265625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 865.9823608398438 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 746.4150390625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 500.8408203125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 594.3768920898438 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1557.5843505859375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 671.8844604492188 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 560.09912109375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 466.7461853027344 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 941.2637329101562 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 1413.630126953125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 968.998046875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 935.9346313476562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 921.562255859375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 466.110107421875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 1958.26025390625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 638.2957153320312 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 724.8153076171875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 588.1596069335938 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 485.6064453125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 1157.274169921875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 909.4971313476562 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 479.06103515625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 682.496337890625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 675.5211181640625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 667.9928588867188 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 874.9114379882812 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 533.849365234375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 493.0564880371094 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 741.49951171875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 1072.4754638671875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1018.7433471679688 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 503.07379150390625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 569.23681640625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 842.5955200195312 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 2173.865478515625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 649.0989990234375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1437.5538330078125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 688.3198852539062 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 1018.0075073242188 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 545.3466186523438 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 972.3363037109375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 712.7850341796875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 546.4573974609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 719.1783447265625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 1704.4434814453125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 649.9447631835938 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1415.0623779296875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 661.9866333007812 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 454.5727844238281 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 401.0436706542969 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 1234.8714599609375 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 818.74951171875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 442.328369140625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 488.0174255371094 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 733.9201049804688 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 939.396484375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 961.26123046875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 839.3538208007812 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 907.5137329101562 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 356.4577941894531 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 1280.0614013671875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 1403.512451171875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 914.5428466796875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 506.4419860839844 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 537.1762084960938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 756.291748046875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 924.1920776367188 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 516.955322265625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 502.67913818359375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 623.6324462890625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 1141.4669189453125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 719.0401611328125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 649.2711791992188 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 883.7443237304688 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 1148.01025390625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 576.3505249023438 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7932, loss_val: nan, pos_over_neg: 1094.653076171875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 1195.3658447265625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 578.1932373046875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 582.7999267578125 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 720.0486450195312 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 1490.5655517578125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 792.9171142578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1050.5106201171875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 904.8412475585938 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 1017.9303588867188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1450.689208984375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 856.600341796875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 481.3893127441406 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 831.8634643554688 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 725.3458251953125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 37623.7578125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 1469.778076171875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 862.1202392578125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 1209.5262451171875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1232.1822509765625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 1226.727783203125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1680.1563720703125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1019.2022094726562 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 817.1326293945312 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 415.6828308105469 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 676.62841796875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 1105.5633544921875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 870.1123046875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 860.3096313476562 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 521.5769653320312 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 662.4168701171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 2456.1962890625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 801.4794921875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 723.2429809570312 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 565.2657470703125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 1366.7054443359375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 809.7364501953125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 521.2547607421875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 483.02105712890625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 715.6849365234375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 1145.3878173828125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1093.975830078125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 720.6135864257812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 471.4652404785156 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1806.81298828125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 758.32470703125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 849.4337158203125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 697.8895263671875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 547.8289794921875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 1383.0438232421875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 845.6901245117188 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 651.4674072265625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 505.9544982910156 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 1696.514404296875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 741.22705078125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 636.5236206054688 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 1028.59033203125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 1464.92626953125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 673.893310546875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1029.4140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 663.7100219726562 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1597.818115234375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 471.7082214355469 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 303.7674865722656 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 622.6654052734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1121.0238037109375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1070.09765625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 911.9268188476562 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 923.1475219726562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1544.01513671875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1572.396484375 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 1613.3787841796875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1194.4842529296875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 619.9692993164062 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1153.6573486328125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 849.454833984375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1013.458984375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 502.37432861328125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1498.1171875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 3626.615478515625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 1683.4508056640625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 4054.21337890625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1283.6279296875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 700.9979248046875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 884.3660278320312 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 1098.8795166015625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 877.2803955078125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1194.3807373046875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 1256.425537109375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 830.0621948242188 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 2033.3248291015625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 901.6048583984375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 623.8736572265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 577.7469482421875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 854.5260620117188 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 621.9373168945312 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 550.0579223632812 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 469.7515869140625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 716.8029174804688 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1144.545166015625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 601.7817993164062 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 501.914794921875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 652.34326171875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 1190.7755126953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 470.0259704589844 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 623.2373046875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 460.44708251953125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 483.3597412109375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 403.4478454589844 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 763.895751953125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 815.9918823242188 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 704.4000244140625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 550.1887817382812 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 649.589599609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 1364.98828125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 914.28759765625 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 2012.453125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 533.1202392578125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 792.8777465820312 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 1265.0552978515625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 865.1387329101562 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 1721.052734375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 857.5718383789062 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1863.5194091796875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 1183.36767578125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 1867.2506103515625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1390.6331787109375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1603.9561767578125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 1494.6002197265625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 482.46844482421875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 642.0213623046875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [41:05<102736:51:58, 1232.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 724.3930053710938 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 1201.9158935546875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 2244.66259765625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 430.5342102050781 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 626.291748046875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1172.35791015625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 835.0794067382812 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 764.2077026367188 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 840.1447143554688 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 620.227294921875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1177.754150390625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1151.77001953125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 348.13604736328125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 438.56414794921875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1496.75 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1443.302734375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 908.5895385742188 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 1334.438232421875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 592.3383178710938 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 1346.535888671875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 2892.77490234375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 887.9925537109375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 539.065673828125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 502.7187805175781 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 885.8357543945312 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 1176.6009521484375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 811.042724609375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 315.38623046875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 704.9727172851562 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 797.4718017578125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 575.2963256835938 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 582.0376586914062 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 597.0794067382812 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 4062.118408203125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1261.271240234375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 711.8606567382812 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 922.4844360351562 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 465.7955017089844 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 577.5223388671875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 1128.503662109375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1443.7210693359375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 812.3889770507812 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 1031.4666748046875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 561.1472778320312 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 773.157470703125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 886.3502807617188 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 819.7889404296875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 550.060302734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 826.788818359375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 763.9710693359375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 840.2200317382812 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 1102.854736328125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 463.2434387207031 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 655.5379638671875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 641.0249633789062 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 583.2935180664062 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 800.5714721679688 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 466.8383483886719 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 664.3200073242188 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 329.36590576171875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 768.0330810546875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 1138.5394287109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 546.9310302734375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 540.0394897460938 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 824.3797607421875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 870.6693115234375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 420.67974853515625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 622.3526000976562 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 569.7347412109375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 431.0658264160156 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1143.9029541015625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 444.6146240234375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1178.0699462890625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 550.1353149414062 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 563.5213012695312 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1829.6107177734375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 746.33251953125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 600.791748046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 762.3448486328125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 679.065185546875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1221.7880859375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 857.3890380859375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 482.0655517578125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 1012.8381958007812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 575.6546630859375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 797.8084716796875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 756.198486328125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 1492.470458984375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 3184.623046875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 583.5540161132812 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 939.5029296875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 407.4434814453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 381.99041748046875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1064.7142333984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 596.9783325195312 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 533.5936889648438 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 528.2655029296875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1208.355712890625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1944.2691650390625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 467.3396301269531 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 1023.1339111328125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 396.3404846191406 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 590.1669921875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7933, loss_val: nan, pos_over_neg: 780.7333374023438 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 588.9022827148438 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 661.7670288085938 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 813.1373291015625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 654.0759887695312 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 908.41845703125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 680.4024658203125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1087.9937744140625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 669.3040161132812 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 859.189208984375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 344.152099609375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 944.9771728515625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 755.6168823242188 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 2023.11572265625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 513.9039306640625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 657.6314086914062 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 474.8557434082031 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 660.021728515625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 730.3541870117188 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 431.8539123535156 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 701.4269409179688 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 2343.71142578125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 744.4559326171875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 607.9195556640625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 931.28271484375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 390.47479248046875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 633.3516845703125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 755.1139526367188 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 577.0468139648438 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 800.005859375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 640.9368286132812 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 657.35498046875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 578.797119140625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 608.5211181640625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 656.7185668945312 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 712.8452758789062 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 398.8460693359375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 658.2979125976562 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 890.0187377929688 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 635.3085327148438 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 940.4547119140625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 776.4760131835938 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1474.76953125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 1034.277099609375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1052.251708984375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 1532.7098388671875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 704.2489013671875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 1047.4930419921875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 851.4295043945312 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 1112.4444580078125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 461.0573425292969 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 602.1358642578125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 610.3892211914062 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 828.9769287109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 622.5206909179688 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 702.8347778320312 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 793.015625 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 528.898193359375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 578.887939453125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1182.186279296875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 955.3357543945312 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 585.0310668945312 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 594.1452026367188 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 661.67333984375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 882.90478515625 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 788.6522216796875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 490.0376892089844 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 978.8841552734375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1148.52490234375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 670.4725952148438 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 538.5413208007812 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 627.8648681640625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 646.4127197265625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1118.62890625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 323.2146911621094 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 487.38665771484375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 908.1773681640625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 3004.61083984375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 639.1220703125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 416.7198486328125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 684.8115234375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 989.383056640625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 488.7938537597656 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 433.3251037597656 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 621.2537231445312 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 898.3868408203125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 656.8615112304688 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1318.3905029296875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 476.4703063964844 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 797.6028442382812 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 634.54736328125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 671.6155395507812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 810.1262817382812 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 907.4165649414062 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 639.571044921875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 845.664794921875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 643.1565551757812 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 548.7400512695312 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 656.38330078125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 711.31201171875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 806.6524047851562 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 735.3155517578125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 643.3574829101562 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 2137.719482421875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1368.49365234375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1088.63916015625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1853.2109375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1844.6136474609375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 499.4566955566406 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 808.5485229492188 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 767.8034057617188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 927.9896240234375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 1587.0849609375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 1125.726806640625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1410.8935546875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 665.5909423828125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 935.3954467773438 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1752.732421875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 559.49951171875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 836.0909423828125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 634.4410400390625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1414.1522216796875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 954.5809326171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1090.5281982421875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 750.9763793945312 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 978.9118041992188 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 1375.301025390625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 2135.1787109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 717.0054321289062 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 435.88800048828125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 429.135009765625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 1130.013427734375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 2799.949951171875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1752.2716064453125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 3099.580078125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 766.426025390625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 1402.5120849609375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 1095.3258056640625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 2711.401611328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 867.8486328125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 1506.0902099609375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 793.1217651367188 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 699.7759399414062 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 582.6475219726562 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1193.697998046875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 1537.9810791015625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 629.0814819335938 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 493.6322021484375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 840.8731079101562 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 569.0083618164062 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 718.4776000976562 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 897.943603515625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 801.84765625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 490.5522155761719 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 753.9550170898438 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 2049.645751953125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 766.8724975585938 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 846.3890991210938 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 2136.960693359375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 676.6845092773438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 590.8648071289062 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1358.4464111328125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1009.3780517578125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1368.351318359375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1351.55712890625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 397.3365173339844 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 598.6039428710938 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1307.621337890625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1216.8011474609375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 883.3825073242188 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 1001.50390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 707.7366333007812 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 823.691162109375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 752.890869140625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1553.6778564453125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1523.9036865234375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 613.3063354492188 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1032.86328125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1487.1876220703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 724.7564086914062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 594.6554565429688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1233.6744384765625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 621.9412841796875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 678.3218994140625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 441.2156066894531 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 523.593994140625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 571.0250244140625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1386.8851318359375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 606.922607421875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1052.0865478515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 1178.161376953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 808.121826171875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 656.1209106445312 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 736.6035766601562 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 3049.1005859375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1499.3306884765625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 571.5401000976562 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 996.0636596679688 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 819.061767578125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 789.9547119140625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1007.6793823242188 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1157.7742919921875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 698.3949584960938 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 1655.939453125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 786.7567138671875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 695.45947265625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 3411.245361328125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 551.6386108398438 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 527.0109252929688 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1247.8289794921875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 1062.978515625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 515.6482543945312 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 742.7123413085938 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 443.0167236328125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 779.1709594726562 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 924.0355224609375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 738.9909057617188 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1093.077392578125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 876.7951049804688 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 494.0279235839844 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 2015.8358154296875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 989.665771484375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 442.6564636230469 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 378.89031982421875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 911.3136596679688 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1370.292236328125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 971.0836181640625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1000.1177978515625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 914.0799560546875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 657.662109375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 592.4545288085938 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 988.9271240234375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 853.0933837890625 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 856.6325073242188 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 882.0394287109375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 2036.11328125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 1008.9032592773438 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 582.7003173828125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 1004.9915771484375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 921.1022338867188 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 741.1400756835938 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 490.09197998046875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 364.81268310546875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 921.9945678710938 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 645.2422485351562 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 710.5584716796875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1139.38720703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 1260.56884765625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 671.4712524414062 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 986.4515991210938 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 609.3965454101562 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 423.81207275390625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 977.6632690429688 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 579.9698486328125 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 519.405517578125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 606.2074584960938 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 716.2667846679688 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 901.2449951171875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 319.8618469238281 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 654.2353515625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 849.6389770507812 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 517.521484375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 587.4661254882812 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 480.4108581542969 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 1247.8487548828125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 576.6929321289062 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 611.859619140625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 678.0615844726562 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 556.7138671875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 992.8502197265625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 675.070068359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1264.8331298828125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 464.82635498046875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 860.2899169921875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 732.5602416992188 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1100.15283203125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1287.8175048828125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 591.2576904296875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 672.564697265625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 655.8758544921875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1031.0233154296875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1356.539306640625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 936.0636596679688 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 463.1073913574219 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 581.6195678710938 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 639.3225708007812 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1221.9287109375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1230.3704833984375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 550.8204956054688 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 503.43365478515625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 470.60369873046875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 802.2674560546875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 1258.917724609375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 714.8732299804688 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 396.9356994628906 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 402.76251220703125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1421.5517578125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1165.0992431640625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1027.3021240234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 607.0294189453125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 476.93170166015625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1054.447265625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1517.1678466796875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 1238.84228515625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 677.2702026367188 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 443.0380554199219 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1117.1103515625 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1121.1470947265625 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 589.3674926757812 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 1689.6185302734375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 657.51025390625 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 3136.249755859375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 1213.16796875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 944.4323120117188 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2727.631103515625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 2290.829345703125 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 650.7697143554688 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1807.444091796875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1801.64892578125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 676.8078002929688 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 2183.1396484375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1262.4014892578125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 2830.834716796875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 751.5320434570312 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1132.5499267578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 493.8045349121094 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 602.888427734375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 629.5725708007812 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1746.0076904296875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1563.180908203125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 1041.39208984375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1439.83837890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1333.4215087890625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 855.043701171875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1365.3671875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 788.9750366210938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 1211.936279296875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1165.3338623046875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 742.0060424804688 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 2920.602783203125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 4117.24951171875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 926.472900390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 2907.68115234375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1372.06103515625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 618.7511596679688 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 798.328857421875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 1023.0452270507812 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 632.01708984375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 993.60888671875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1088.8046875 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1235.2421875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 1015.8865356445312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 544.0628662109375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 2804.890380859375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 390.4808349609375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 660.9501342773438 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 972.7112426757812 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 553.4803466796875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1348.623779296875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 661.8927612304688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 734.13037109375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 590.5958862304688 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 843.4293212890625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 2599.08447265625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1465.4154052734375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 516.078857421875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 489.60333251953125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 583.2010498046875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 731.4058837890625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1525.4647216796875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 1708.2442626953125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 665.37744140625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 416.9092712402344 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1472.5166015625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 959.901611328125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 698.2230224609375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 580.9950561523438 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 853.3333129882812 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1774.515869140625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 2259.495849609375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1016.1201782226562 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 610.0234985351562 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 564.04833984375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 588.836669921875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 823.8233032226562 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 814.723876953125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 780.1739501953125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 991.6884765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1295.5743408203125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 878.90625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 1248.9730224609375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1471.2513427734375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 798.952880859375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 923.867431640625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 761.4691162109375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 689.0166015625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 1200.589111328125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1271.6622314453125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 856.9720458984375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 772.1983642578125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 3230.216064453125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1288.58154296875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 936.306396484375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 682.095947265625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 546.7369995117188 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1075.8385009765625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 700.4226684570312 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 635.1922607421875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 924.3461303710938 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 883.173095703125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 542.2943115234375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 827.0676879882812 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 608.5228881835938 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1346.0191650390625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1352.6866455078125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 946.0851440429688 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1052.2005615234375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 1333.3475341796875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1126.0045166015625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1062.6514892578125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 2787.380126953125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 372.33428955078125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1182.416259765625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1827.0406494140625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 416.3896789550781 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 559.6304321289062 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 453.7890625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1031.4903564453125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 522.5239868164062 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 696.2603149414062 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 662.3294677734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1319.7340087890625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 624.1215209960938 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 483.0776672363281 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 657.8204956054688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1362.4405517578125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1088.28466796875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 848.0132446289062 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 652.1152954101562 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 2515.96630859375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 1066.080078125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 567.8597412109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 455.86383056640625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1096.3681640625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 605.3374633789062 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1062.329833984375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 547.5086669921875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 995.5543823242188 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 521.3347778320312 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 611.5047607421875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 779.4934692382812 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 653.3134155273438 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 440.7424011230469 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 844.18408203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 613.546142578125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 382.34552001953125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 728.8699340820312 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 823.8004760742188 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 951.891357421875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 716.432373046875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 333.4165954589844 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 645.5667114257812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 787.3324584960938 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 431.2933654785156 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 645.8456420898438 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 834.7578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 659.0805053710938 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 913.962646484375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 808.0700073242188 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 793.8768310546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 826.6168823242188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1035.9146728515625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 659.4055786132812 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 664.2909545898438 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 792.9194946289062 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1136.01220703125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 804.8558349609375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 749.3307495117188 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1301.9207763671875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1241.1805419921875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1518.8834228515625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1261.43359375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1146.967041015625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1175.706298828125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1125.74267578125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 919.5171508789062 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 857.0787353515625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 706.6017456054688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1855.3668212890625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 756.4385986328125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 776.701171875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 786.5992431640625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 1373.77001953125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 1288.7666015625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1077.3486328125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 850.8241577148438 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 893.4186401367188 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1464.3431396484375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 813.3597412109375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 889.10888671875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 658.9889526367188 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 960.1105346679688 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1022.810546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1182.8310546875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 829.9506225585938 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 867.6143188476562 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 964.9081420898438 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 936.4375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1027.3184814453125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1180.8636474609375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 844.6327514648438 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1345.7437744140625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1868.69189453125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 987.6175537109375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 824.3359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1395.8682861328125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 813.408447265625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 914.1832885742188 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 825.5884399414062 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 991.6984252929688 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1004.0665283203125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 464.6661071777344 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1464.9600830078125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1160.749267578125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1524.5284423828125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 865.8901977539062 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 482.58258056640625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 1196.68701171875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 743.613037109375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1390.1051025390625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 830.4119873046875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 777.8389892578125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1444.5672607421875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1883.8948974609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 673.9883422851562 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 821.5248413085938 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 463.8523254394531 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 634.9339599609375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1162.205322265625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 599.1289672851562 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1465.610107421875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 739.9853515625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 827.1959228515625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 1172.3001708984375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1881.2457275390625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1003.5679321289062 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 886.2670288085938 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 560.6842651367188 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 641.6329345703125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 2230.97265625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 763.3800659179688 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 781.1688232421875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 826.4129638671875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1102.4700927734375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 668.1226806640625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 563.7305908203125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1408.1953125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1225.9786376953125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 891.934326171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 806.7689819335938 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 914.8496704101562 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 973.85400390625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 4376.2998046875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 586.3743896484375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 696.7428588867188 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1307.1448974609375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 815.0255126953125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 5416.5244140625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 891.6075439453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 657.21875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 433.0115661621094 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 691.7605590820312 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 765.9154052734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 707.3366088867188 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 633.7153930664062 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2309.933837890625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 879.4631958007812 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 966.3067016601562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 935.30859375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1108.0421142578125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 597.591796875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 619.3667602539062 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1063.52880859375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1010.3697509765625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 712.7491455078125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 640.7702026367188 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1038.6888427734375 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 1399.1893310546875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 922.855712890625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 623.5573120117188 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2305.294677734375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1286.82666015625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:01:36<102679:51:34, 1232.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1280.7095947265625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 859.1217651367188 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1021.0913696289062 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1258.7589111328125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1103.7548828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1813.1912841796875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1506.253173828125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1016.82470703125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1076.43798828125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 841.2095336914062 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 752.9331665039062 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 781.5733032226562 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 1254.24609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 884.2095947265625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1007.05810546875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1094.2650146484375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 1170.506591796875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1410.444091796875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 902.4143676757812 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2037.599609375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1213.54345703125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1091.3780517578125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 4096.08740234375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1304.4462890625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 822.5621948242188 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 632.7693481445312 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 867.4949340820312 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1258.366943359375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 2066.941650390625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1102.9578857421875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1550.197998046875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1369.0218505859375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 833.5358276367188 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1871.6302490234375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1308.72802734375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1411.0374755859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 2958.510498046875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1026.53466796875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1964.2840576171875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 2056.35302734375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1733.676025390625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 761.1174926757812 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 846.6138305664062 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 2066.2880859375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 700.4956665039062 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 804.121337890625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 802.294189453125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 775.5609741210938 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1397.24755859375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 712.2144775390625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 817.6162109375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 532.390869140625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 651.3143310546875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 772.370361328125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 882.5807495117188 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 2509.115478515625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 881.7333374023438 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 722.6307373046875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1243.2928466796875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1376.9095458984375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1142.26171875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1041.1988525390625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 829.473388671875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 599.372802734375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 583.7250366210938 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 855.2197875976562 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 596.9999389648438 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 858.1329345703125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1159.0791015625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 974.2547607421875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 793.9979858398438 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 991.1483764648438 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 698.4271850585938 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 866.4871215820312 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 563.8948974609375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 465.86090087890625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 654.92041015625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 632.42724609375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1584.2919921875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 761.0327758789062 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1285.3795166015625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1250.614013671875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1042.1265869140625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1119.280029296875 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 693.47607421875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 653.0020141601562 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1155.95703125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 760.7098999023438 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 564.642333984375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1017.8692016601562 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 690.484619140625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 861.564697265625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 425.2555847167969 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1593.5316162109375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 822.8994750976562 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 682.7667846679688 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 808.9656982421875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 762.2722778320312 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 734.7501220703125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1128.7945556640625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1523.690673828125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 501.25372314453125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 969.9266967773438 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 780.5678100585938 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1590.15087890625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1147.110107421875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 2797.169677734375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 810.7481079101562 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 774.5445556640625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1544.069580078125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 840.32958984375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 777.4915771484375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1201.593017578125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 758.6939697265625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 520.6668701171875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1647.8680419921875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1094.798095703125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 519.9625244140625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 928.1497802734375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 8065.2060546875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 941.3767700195312 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1144.685546875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 2298.4794921875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1497.33984375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1157.526123046875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 738.4834594726562 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 793.9220581054688 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1394.5426025390625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 8525.470703125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1378.6661376953125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1016.4152221679688 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1134.5206298828125 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1696.4512939453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1169.2603759765625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1340.822265625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 936.31689453125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 783.7926635742188 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 1687.6446533203125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1987.531005859375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1592.0594482421875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 2445.43798828125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1214.197265625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1159.3033447265625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 3946.6962890625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 836.5857543945312 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 556.5744018554688 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 545.6654052734375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 2031.81103515625 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 749.0364990234375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 883.973876953125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 635.7218017578125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 897.2379760742188 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3718.390380859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 2086.417724609375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 800.1785888671875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 924.9100341796875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1639.3485107421875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 2801.644287109375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1395.670166015625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 782.4204711914062 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 829.5516357421875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 751.508056640625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 694.5678100585938 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 2021.28759765625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1209.050048828125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 750.406494140625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 814.4484252929688 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 814.1019287109375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 2042.0538330078125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1329.7056884765625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 548.9470825195312 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 629.2607421875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 597.537109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 868.6279296875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1124.239501953125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1064.2303466796875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 907.8082275390625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 764.5259399414062 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1154.398193359375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1245.727783203125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 938.0167846679688 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 979.33984375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1770.701416015625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1028.00439453125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 789.7951049804688 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 959.0387573242188 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 880.3931274414062 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 623.2890014648438 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 485.2953186035156 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1186.3099365234375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1164.6351318359375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 837.224365234375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 788.4578247070312 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1199.20068359375 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1131.1409912109375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 1297.8232421875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 832.6542358398438 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1709.0908203125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1346.8035888671875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 849.2589721679688 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 852.7382202148438 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1341.379638671875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 786.2879638671875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1818.00390625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 520.4985961914062 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 666.7454833984375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 691.0364990234375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 570.6001586914062 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 657.2035522460938 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1054.951171875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 883.1854858398438 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 666.7731323242188 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 774.9232177734375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 717.0786743164062 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 649.3096923828125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 6887.2333984375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1029.5550537109375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 557.3704833984375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1121.866455078125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 12825.9150390625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 627.8457641601562 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 530.3848876953125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 814.0894775390625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1961.7127685546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 775.1314697265625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 707.9967041015625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 811.2948608398438 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 881.2974243164062 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 736.9241333007812 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 950.7888793945312 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 824.9921264648438 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 583.178466796875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1040.476806640625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 979.6951293945312 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 924.4324340820312 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 841.6129760742188 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1079.9112548828125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 741.3685302734375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 611.2942504882812 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 4633.1533203125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1050.7274169921875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 650.59912109375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1315.169677734375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 2159.45751953125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 738.8565673828125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 764.2434692382812 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 728.6211547851562 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1012.5321044921875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 11983.6484375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1893.52392578125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 2759.165771484375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1560.7236328125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 1934.88232421875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 1393.681640625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1924.3804931640625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 5208.466796875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 840.040771484375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 786.8656005859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 898.2841186523438 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1181.796630859375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1244.605224609375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 698.2120361328125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1369.151123046875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1479.56494140625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2035.6309814453125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 833.3828125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 660.3118896484375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1229.8917236328125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 552.359375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 4105.42529296875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1125.2568359375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 466.3746032714844 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 1066.258544921875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1476.8482666015625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1308.85302734375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1392.531005859375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1011.716064453125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1829.5625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 986.5070190429688 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 690.496826171875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 454.4317932128906 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 767.0706787109375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 777.7661743164062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 958.3232421875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2378.1767578125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 933.1422119140625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1325.6787109375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 947.8327026367188 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 541.6334838867188 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1791.513427734375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1564.701904296875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 492.5316162109375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 817.7928466796875 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2127.0888671875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 696.9768676757812 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 526.275634765625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1919.093505859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 982.088623046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1310.72607421875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 643.1694946289062 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1411.4947509765625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 2013.130859375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1331.0704345703125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 697.79541015625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1121.880126953125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1147.21240234375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 3941.111083984375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 940.47021484375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 497.22943115234375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 636.3535766601562 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1258.544921875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1722.2281494140625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1269.5042724609375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1428.9456787109375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 624.3121337890625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1741.8720703125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1509.453857421875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 695.9024047851562 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1004.5075073242188 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 759.6696166992188 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 5925.26220703125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1119.5374755859375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 961.3175659179688 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1080.424560546875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1140.736328125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1396.5703125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1030.9742431640625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 820.8782958984375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 713.9854736328125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 671.7759399414062 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 745.6565551757812 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 799.5889282226562 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1005.2032470703125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 449.70831298828125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 882.5437622070312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1344.168701171875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 833.9199829101562 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 734.8881225585938 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1144.156494140625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1363.227294921875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: -205439.046875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: -28849.07421875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1164.5269775390625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 737.7466430664062 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 719.6798095703125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 515.8712158203125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 1116.267822265625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 2079.27294921875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 571.27783203125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 715.5171508789062 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 789.1732788085938 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 938.773193359375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 883.2628784179688 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 591.7420654296875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 814.9149780273438 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 436.5791320800781 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1057.8629150390625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 2257.223876953125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1079.7801513671875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 565.5315551757812 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 819.4485473632812 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1134.1063232421875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 691.8439331054688 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 630.9650268554688 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 556.5285034179688 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1168.05126953125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 732.8079223632812 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 666.33203125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 755.0948486328125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1306.2574462890625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 729.6446533203125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 568.7118530273438 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 688.2799682617188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 640.0827026367188 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 779.5526733398438 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 749.1198120117188 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1131.338134765625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 945.826904296875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 704.8761596679688 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 797.2066650390625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1438.2945556640625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 929.9468994140625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 842.4412841796875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 703.9569091796875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1060.5810546875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 906.0789184570312 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 695.5486450195312 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 714.27587890625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 667.6702270507812 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 764.3971557617188 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 873.1778564453125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1055.3455810546875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1319.4168701171875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 682.2357177734375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 554.9981079101562 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 2673.2890625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 2391.297119140625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 616.3489990234375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 624.9263916015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1255.8712158203125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1571.599365234375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 441.40850830078125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 3111.265625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 2887.06005859375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 992.3614501953125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 610.1478881835938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1275.6383056640625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1966.2293701171875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1134.806884765625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 722.0926513671875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 895.3992309570312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 530.3782348632812 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1450.676513671875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1724.8826904296875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 812.1495361328125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1004.9214477539062 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 657.72216796875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1064.84228515625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 6030.99609375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 872.1748046875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 565.328125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1270.5504150390625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2138.617431640625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1070.880859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 987.4310913085938 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 494.8869323730469 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 869.1771850585938 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 621.8594360351562 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 663.220703125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 698.7744750976562 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 922.3487548828125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 640.789306640625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 867.5147705078125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1857.795654296875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 711.4390869140625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 570.1812133789062 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1401.3695068359375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 769.2960815429688 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 428.7864685058594 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 531.733642578125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 604.4739379882812 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 668.6077270507812 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 778.5337524414062 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1199.4102783203125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1255.686767578125 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1049.613037109375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 871.7492065429688 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 952.1896362304688 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 628.1857299804688 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 754.5784912109375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 681.4129638671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1032.605224609375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 2850.3115234375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1107.376708984375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1629.1204833984375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 3066.58984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 910.53662109375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 812.0999755859375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 665.7659912109375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1820.70361328125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 840.5935668945312 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 956.8451538085938 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 651.5776977539062 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 742.1880493164062 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1082.7193603515625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 824.6403198242188 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1303.12353515625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1046.549560546875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 580.8323974609375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 605.0438232421875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 655.269287109375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1020.6323852539062 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1417.58251953125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 434.4497375488281 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 658.6763305664062 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 643.302490234375 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1934.238037109375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1411.640380859375 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1109.5380859375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 795.7522583007812 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1064.78564453125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 901.7568969726562 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 449.9353332519531 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1838.990478515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1030.9764404296875 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 967.341796875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 904.8040161132812 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1211.8404541015625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1258.8865966796875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 986.00341796875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1643.108154296875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 639.79248046875 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 691.7601318359375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3580.47216796875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 6708.52734375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1360.9285888671875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 3165.318115234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: -8042.234375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 2036.619384765625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 7076.326171875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1809.25537109375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1365.929443359375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1004.7141723632812 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 785.5567626953125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1021.1776733398438 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1552.2459716796875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 2084.927490234375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 788.9459838867188 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 903.3848876953125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1518.34423828125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 2776.677734375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1275.3594970703125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1263.549072265625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1706.8380126953125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 910.1526489257812 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 971.1410522460938 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1052.90625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 993.5390014648438 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 959.3857421875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1244.332275390625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 2081.08154296875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2551.02978515625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 682.73291015625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1055.671875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1468.8114013671875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 921.1692504882812 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 790.4170532226562 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 912.9087524414062 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 899.417236328125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 3180.155517578125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 746.7435913085938 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 751.335693359375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 724.7034301757812 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 898.1107177734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 3101.848876953125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 975.6795654296875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 617.6768798828125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 544.5431518554688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 550.6539916992188 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 699.1010131835938 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1735.514892578125 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1818.6160888671875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1006.9115600585938 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 796.4638671875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 572.915771484375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 2408.704345703125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1262.6676025390625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 716.73681640625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 786.82861328125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 931.0972900390625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1150.4306640625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 906.0277099609375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1180.150390625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 787.240234375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1182.772216796875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 691.7395629882812 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1271.14794921875 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1332.0465087890625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1277.429443359375 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 888.9134521484375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 973.9036865234375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 861.8340454101562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 927.3185424804688 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 601.9541625976562 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 745.0863037109375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1401.2314453125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 936.3766479492188 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 538.0115356445312 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 801.617431640625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 508.7646789550781 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 636.9368286132812 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1453.224609375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1082.063720703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 948.968505859375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 2159.653076171875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 568.3479614257812 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1179.4638671875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 800.9559326171875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1560.2427978515625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1354.12451171875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 841.08154296875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 823.1797485351562 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1681.869873046875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 4205.1279296875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 2640.050537109375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 776.8471069335938 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 851.9050903320312 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 860.5357055664062 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 2155.4091796875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 798.7064208984375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 707.4542846679688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1576.0994873046875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 863.2930297851562 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 649.4166870117188 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 530.300048828125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 539.5927124023438 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 660.8511352539062 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 826.841064453125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1513.513427734375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1013.2348022460938 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 841.7986450195312 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 778.99560546875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 752.5531005859375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 703.8623046875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 807.4041748046875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1005.4273071289062 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1046.6884765625 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1373.611572265625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1063.104736328125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 2204.70654296875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1878.92822265625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1471.5787353515625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 2344.89453125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1004.6243286132812 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 3153.95947265625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1746.487060546875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 2271.455078125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 4128.5087890625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 3349.4345703125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1666.073486328125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 189611.28125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1368.6234130859375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 5851.51806640625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1204.3375244140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2047.3553466796875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3533.177734375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 983.6844482421875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 2585.90673828125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1354.372802734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1065.702880859375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 2627.160400390625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 2016.7705078125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 838.1229858398438 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1822.2574462890625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 855.04150390625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 576.5160522460938 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1372.71533203125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1463.239990234375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 835.468994140625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 767.57958984375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1935.797607421875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1024.275146484375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1339.8729248046875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 3706.439453125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1288.7054443359375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 630.0732421875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 495.4972839355469 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1156.6651611328125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1151.0814208984375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1095.019287109375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1367.2933349609375 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1440.717529296875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1676.62353515625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 670.6381225585938 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1349.195556640625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1914.6370849609375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1008.0099487304688 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 874.15771484375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 982.7728881835938 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 948.3711547851562 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1412.48876953125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 3225.1826171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1042.033935546875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1243.536376953125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 973.7167358398438 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1167.8392333984375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1081.6602783203125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1126.2001953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1436.68798828125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 833.737060546875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 861.4049682617188 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 1056.0081787109375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1116.366455078125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1229.590576171875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2949.443359375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 2488.75927734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1558.0423583984375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1156.3740234375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 4678.57666015625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 995.10888671875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 818.2212524414062 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1376.52099609375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 16838.375 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 923.460693359375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 736.8858642578125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1192.219970703125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1970.871337890625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 2039.9517822265625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 986.5167846679688 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1392.44384765625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1841.867431640625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1480.8260498046875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 738.5921020507812 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 469.60882568359375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1543.03564453125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:22:09<102682:38:22, 1232.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 748.7344970703125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 901.8676147460938 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 557.8255004882812 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1104.2650146484375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1375.758056640625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 803.4733276367188 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1367.10302734375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 6710.83349609375 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1138.9603271484375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 742.7294311523438 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 525.0872802734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1347.7177734375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 608.4573974609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 686.2486572265625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1307.7728271484375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 551.8882446289062 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1176.40625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 728.2660522460938 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 981.0083618164062 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1424.677978515625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 601.727783203125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 475.9935607910156 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1448.2958984375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1054.4375 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 886.3543090820312 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 4232.9111328125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 2136.085693359375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 3612.195556640625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2905.609130859375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1117.4832763671875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1142.8236083984375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1119.0802001953125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 7150.61279296875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1175.56982421875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 753.8128051757812 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 869.8958129882812 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 918.169677734375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 974.8301391601562 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1245.6226806640625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2052.520263671875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 13282.13671875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 679.6918334960938 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1949.4444580078125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 2532.193359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1115.51171875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1672.7855224609375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 887.918701171875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 4560.5751953125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1347.249267578125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 2655.384521484375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1293.4580078125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1072.6151123046875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 711.7078857421875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 760.0161743164062 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2221.84814453125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 872.4344482421875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1043.2294921875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 2022.5860595703125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1355.561279296875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 14178.673828125 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 2029.6324462890625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2392.162841796875 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 707.2373657226562 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1492.3240966796875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3604.042236328125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1403.8929443359375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 757.2715454101562 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 929.5112915039062 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1058.9090576171875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 2992.88134765625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 713.6763305664062 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 564.904296875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2036.0389404296875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 2123.144287109375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1748.515625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 518.6890869140625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1272.8160400390625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 972.0872192382812 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 837.3298950195312 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 984.5423583984375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 906.1917114257812 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 574.3055419921875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 955.9824829101562 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 942.1854858398438 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 608.5310668945312 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 918.659423828125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1266.6480712890625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1083.6468505859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 932.2440795898438 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 617.0213623046875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1007.819091796875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 793.2403564453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 613.6008911132812 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1445.9744873046875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 964.0697021484375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1678.6456298828125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1030.3233642578125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 608.82666015625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 530.4434814453125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 966.5938720703125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1224.594970703125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 820.7102661132812 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 673.159423828125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 845.3560791015625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 908.736328125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1774.52099609375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1447.55908203125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1105.476806640625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 722.50537109375 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1197.1302490234375 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 4824.0537109375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1583.0606689453125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1304.46435546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1300.6121826171875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1310.012939453125 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 3913.562744140625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1197.234375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 2587.233154296875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 669.3886108398438 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 929.2128295898438 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1085.953125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1141.2166748046875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 2633.35693359375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1233.3741455078125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1038.9837646484375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1216.6627197265625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 6667.78125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1494.1832275390625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1344.3978271484375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 6039.9501953125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1321.3450927734375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 906.2907104492188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 735.5493774414062 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 974.9950561523438 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 860.7045288085938 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 990.7117309570312 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1108.966552734375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1454.051025390625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 767.5450439453125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1265.7506103515625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1014.106201171875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1600.049560546875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 638.9783325195312 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 916.2531127929688 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1284.413330078125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1227.6424560546875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2383.044189453125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1066.5198974609375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 922.9237670898438 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2321.1533203125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1527.2156982421875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1305.192138671875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1062.6622314453125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 968.9273681640625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 828.314453125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 2518.37109375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2234.029296875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 657.9185180664062 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 779.4990234375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2467.35595703125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1470.81884765625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 12235.9951171875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 721.1306762695312 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1475.411376953125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 5590.14892578125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 703.1287231445312 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 3272.373046875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1057.9522705078125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 2628.750244140625 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 3084.05859375 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1215.0213623046875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1494.084716796875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1209.80224609375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1060.4962158203125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 992.9089965820312 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1195.9132080078125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1336.6634521484375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1713.6734619140625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 958.6781616210938 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1550.47412109375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 594.7557373046875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 697.7555541992188 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 629.1904907226562 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 705.4239501953125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1017.9554443359375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 721.3463745117188 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 814.632568359375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1017.498046875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2007.443359375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 923.50390625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1704.9600830078125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 699.2918090820312 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1163.2618408203125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 983.1373291015625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 792.6286010742188 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1357.036376953125 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 2149.909912109375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 3012.686767578125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1421.5142822265625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 2043.7091064453125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 958.631591796875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1808.250244140625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 979.2186889648438 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1562.4208984375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 911.14990234375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 993.04052734375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 998.4684448242188 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2626.325439453125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 3959.2880859375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1188.5557861328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 742.4786987304688 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1189.4931640625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1174.4290771484375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 3052.353515625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 2118.499755859375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 9192.884765625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 841.767578125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1507.226318359375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 4439.88671875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2089.89306640625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 755.1187133789062 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1561.2357177734375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1125.3369140625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1148.69970703125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 2159.873046875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1493.247802734375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1193.619384765625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1140.258056640625 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 720.290283203125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 2429.617431640625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1652.6077880859375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 950.5362548828125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1096.34326171875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 2506.06298828125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1045.258544921875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1164.5338134765625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1344.4771728515625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1420.6708984375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 578.7144775390625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1030.2171630859375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1300.15234375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 3047.82177734375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1696.1124267578125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1046.005615234375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1115.609375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 2263.604248046875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1022.7173461914062 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1095.3087158203125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1167.0101318359375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2157.601318359375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 586.25390625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 662.1341552734375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1426.845458984375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1029.1690673828125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 908.5095825195312 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 824.8759155273438 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 9047.505859375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 2042.749755859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 861.737548828125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 750.3375854492188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 734.8958129882812 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 798.13037109375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 858.8130493164062 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1535.924560546875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2111.138916015625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 457.83892822265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 779.3766479492188 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 972.4922485351562 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 445.4956359863281 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 817.9152221679688 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 667.665283203125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 768.5986938476562 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 789.6190185546875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 662.7835693359375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 447.8181457519531 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1574.4786376953125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 883.08544921875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1354.47119140625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 958.7202758789062 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 880.8907470703125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1176.76025390625 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 738.5750122070312 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 466.2973327636719 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 627.6717529296875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1403.52392578125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 995.8806762695312 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 846.4400634765625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 660.2354125976562 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 894.5030517578125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 950.8783569335938 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1620.5743408203125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1237.9718017578125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1496.6142578125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1236.145751953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 995.4682006835938 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 12963.794921875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1366.104736328125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1689.5203857421875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 908.5692138671875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2152.63671875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1100.85888671875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1674.4779052734375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1345.1253662109375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 933.2472534179688 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1744.2064208984375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 2795.4677734375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1696.6409912109375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1169.18798828125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 689.6832885742188 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 704.9782104492188 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1495.292236328125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1386.427978515625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 684.6250610351562 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1345.3056640625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1485.5479736328125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1188.8343505859375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 2387.27001953125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 892.7371826171875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2711.609375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1015.0193481445312 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1056.6485595703125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1286.6640625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1269.48974609375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1314.0931396484375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1374.3602294921875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1006.1714477539062 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 461.29730224609375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 2204.46240234375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 2055.519775390625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 942.7120971679688 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1597.4302978515625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 677.7492065429688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1467.87451171875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1708.414306640625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 982.9505615234375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 652.1642456054688 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 640.42333984375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1281.1800537109375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 797.4130859375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 915.09814453125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 989.4785766601562 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 780.3759155273438 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1393.142822265625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1279.2789306640625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 1181.0706787109375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1054.866455078125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 758.5352783203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1150.1602783203125 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 740.78955078125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1964.107666015625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 826.7611694335938 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1104.536865234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 587.5429077148438 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1331.8173828125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 745.9234619140625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1401.5726318359375 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 2384.724609375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1209.4779052734375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1193.53369140625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1363.1490478515625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 2264.703857421875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 3975.544677734375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 2745.379638671875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 697.4594116210938 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 964.5181274414062 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 636.4296264648438 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1069.3255615234375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 960.523681640625 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1501.895263671875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 852.72119140625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1503.513916015625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1006.8805541992188 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 673.5319213867188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 491.07568359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 620.6752319335938 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 890.47119140625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1191.8636474609375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1082.1693115234375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 865.1937255859375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1150.0640869140625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 3611.378662109375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 2614.465087890625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 727.2978515625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 834.3551635742188 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 942.4292602539062 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1267.172119140625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 715.01220703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1336.7576904296875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 885.1602172851562 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 887.4269409179688 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 661.2731323242188 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1319.73046875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 879.5235595703125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1008.0762939453125 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1120.08349609375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 756.9364013671875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1826.26953125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1628.60986328125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1470.623291015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 635.1318969726562 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1045.41650390625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1887.427490234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2542.1279296875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1851.7760009765625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1795.0404052734375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 976.6823120117188 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1468.82861328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1938.3597412109375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 3502.5361328125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 934.4776000976562 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 631.5750122070312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1853.4345703125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1035.222900390625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1194.10205078125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2844.963623046875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1460.108154296875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1756.5447998046875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1442.7322998046875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1746.42138671875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 539.2720336914062 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 891.5525512695312 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 2943.6669921875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1639.8717041015625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 780.1160888671875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 868.0875854492188 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 950.2289428710938 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1233.8321533203125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 929.949951171875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1083.24609375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1577.9312744140625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 659.216552734375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 758.5516357421875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1186.956298828125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1310.4210205078125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1262.1622314453125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1130.31201171875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1009.4203491210938 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 4501.166015625 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2785.3427734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1035.648681640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1240.92724609375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2257.418701171875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1547.155517578125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 729.0008544921875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1152.9468994140625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1800.446044921875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 932.8726196289062 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 2022.8480224609375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 2048.437255859375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 838.9887084960938 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1503.0379638671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1518.0650634765625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 929.6032104492188 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1085.1114501953125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1169.8414306640625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1270.3145751953125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1635.1422119140625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1808.4197998046875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 858.199462890625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 3012.759033203125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1433.7811279296875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 868.5186157226562 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 3061.485107421875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 976.3807373046875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1287.510498046875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 641.1043701171875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1826.9110107421875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 5642.8330078125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 777.8352661132812 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 4869.84326171875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 4477.23583984375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 984.1044921875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1188.17333984375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1975.469970703125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1095.2144775390625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1826.8807373046875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 2167.359130859375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 661.4974975585938 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1134.2657470703125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1129.3463134765625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1206.322021484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1028.6793212890625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 679.0088500976562 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 867.068603515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 2254.47412109375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1566.5771484375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1695.357177734375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1660.4617919921875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1700.3060302734375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1362.0162353515625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 2650.78759765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 661.961181640625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1364.015869140625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2661.300048828125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1136.03125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 623.272705078125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 492.38934326171875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1242.281005859375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1584.7626953125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1684.0623779296875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1094.9854736328125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1208.6981201171875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1076.790283203125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 769.0874633789062 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 765.6327514648438 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 3374.776611328125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1248.212646484375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1018.9032592773438 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 841.6666259765625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 617.8176879882812 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1665.0528564453125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1725.2569580078125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 795.7880859375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1342.7259521484375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1191.5009765625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1034.9278564453125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1854.7701416015625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 731.19580078125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1422.8663330078125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1133.669921875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1296.6712646484375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 937.7479248046875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1373.6690673828125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1623.1051025390625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1225.197998046875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1419.702880859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 849.2891235351562 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1407.3189697265625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 809.3185424804688 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1433.5057373046875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1471.2618408203125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 729.2350463867188 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1106.223388671875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1222.0611572265625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1493.216552734375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 572.2772216796875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1310.04150390625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1702.63037109375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 538.8256225585938 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 896.8056640625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 832.2056274414062 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1322.6103515625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 785.028564453125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 545.6634521484375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1456.997802734375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 762.082275390625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1075.81884765625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 847.9362182617188 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 920.1151123046875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1167.4310302734375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 664.0087280273438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 722.0618896484375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1050.28955078125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1509.78662109375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 3032.078857421875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 721.7933959960938 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1387.164306640625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1327.941650390625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 807.9834594726562 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 889.473388671875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 525.4693603515625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 851.1768188476562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1561.587158203125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1252.7886962890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 736.8606567382812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1113.1085205078125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 805.9288940429688 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 791.4060668945312 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1093.053955078125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1571.13525390625 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1425.1834716796875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 777.7444458007812 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1569.6680908203125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 670.9677124023438 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 736.3327026367188 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1002.1647338867188 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1270.4578857421875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1888.1710205078125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1388.4945068359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1127.2255859375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 820.5020751953125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 899.8850708007812 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 747.9330444335938 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1151.4703369140625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1872.404052734375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 809.50830078125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1101.932861328125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 771.3276977539062 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1892.883544921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1136.0501708984375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1550.89013671875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1431.4761962890625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1648.434814453125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1607.191650390625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1635.57080078125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 799.336181640625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 554.3214111328125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1655.5008544921875 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1104.6199951171875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1510.287109375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 2420.089111328125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 766.0174560546875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1307.0601806640625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1053.7425537109375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 923.0089721679688 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1621.282470703125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 703.5319213867188 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1098.2008056640625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 984.2603149414062 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1250.2852783203125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1058.3323974609375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 609.8001708984375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1333.6776123046875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1464.69921875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1104.4508056640625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1111.3948974609375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1134.0089111328125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1152.104248046875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 670.9778442382812 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1196.7694091796875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2003.7081298828125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1840.407470703125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1411.053955078125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 994.5663452148438 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 3092.0791015625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 2483.9873046875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 783.7772827148438 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1544.3787841796875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 534.0106811523438 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 642.9960327148438 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 736.450439453125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 938.7559204101562 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 521.6334838867188 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 767.4898681640625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 975.4611206054688 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 730.808349609375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 538.6937255859375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1053.801025390625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 936.7501220703125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 730.9293823242188 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 956.5938720703125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 563.1969604492188 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 828.0647583007812 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1270.812255859375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1407.6107177734375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 827.4957275390625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1124.7303466796875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 952.2467651367188 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 969.361572265625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1339.8157958984375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 932.1070556640625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 912.4450073242188 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 940.7667236328125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1046.0325927734375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 958.4205322265625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 899.777587890625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1088.65869140625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 962.2027587890625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1370.8121337890625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1620.3074951171875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 3879.912109375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 871.7940673828125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 960.3407592773438 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 941.3640747070312 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 733.1467895507812 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 589.2136840820312 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 855.3900756835938 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 654.2186279296875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 643.61083984375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1733.9232177734375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1239.1732177734375 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1190.4044189453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 833.2061767578125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1961.302978515625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 2113.915283203125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 728.5987548828125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 856.1949462890625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1357.5189208984375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1266.11572265625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1159.1033935546875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1300.5167236328125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1417.638427734375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1722.5645751953125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1165.52685546875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 829.7971801757812 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1626.15771484375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1156.9578857421875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 871.5979614257812 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1517.6612548828125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1421.1187744140625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1856.5819091796875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1576.7364501953125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 928.5654907226562 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 871.328369140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1030.68310546875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:42:47<102855:46:31, 1234.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 989.275390625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1082.8218994140625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 915.406494140625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 910.8564453125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1154.419677734375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1458.289794921875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 655.6886596679688 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 687.8790893554688 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 863.7052001953125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2132.72265625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 563.3482055664062 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 427.2876892089844 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 972.4315185546875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 905.4677734375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 824.4879760742188 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 967.3168334960938 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1914.546630859375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 5994.169921875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1355.175537109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 985.0735473632812 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 651.566162109375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1558.783447265625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2118.486083984375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 788.0914306640625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 2986.544921875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1089.4495849609375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 770.6963500976562 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 984.9702758789062 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 3425.778076171875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1381.0570068359375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1160.6890869140625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 2085.54443359375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1128.40625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1736.197509765625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 851.0160522460938 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 625.8845825195312 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2081.9970703125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 800.9121704101562 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 751.8397827148438 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 736.9684448242188 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1003.4527587890625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 679.5204467773438 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1093.25048828125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 750.2413330078125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1131.4755859375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1137.7962646484375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1167.540283203125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1539.9853515625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1312.92626953125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1372.10791015625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 3262.14208984375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1112.13232421875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1290.0972900390625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 976.4314575195312 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2382.65771484375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2122.48828125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2910.91552734375 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1481.6890869140625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1085.6605224609375 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2184.43896484375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1206.8402099609375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2150.73193359375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1909.3538818359375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 3202.410400390625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1919.286376953125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1283.2138671875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2781.359619140625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 639.281982421875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1048.094970703125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 999.8280029296875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1249.9471435546875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1871.8414306640625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 843.6961669921875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1045.151123046875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1051.417236328125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 833.9119262695312 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 760.8103637695312 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 880.4290161132812 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 956.1514282226562 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1303.9169921875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 674.3851928710938 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1853.4166259765625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 716.4655151367188 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 970.799072265625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 903.927734375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1159.0799560546875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1051.8193359375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2426.654296875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1567.64453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1866.3101806640625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1002.3685913085938 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 2208.65283203125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1755.626708984375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1257.4791259765625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1477.2725830078125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1156.0648193359375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1097.664794921875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 970.1340942382812 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1185.34130859375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1033.6378173828125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1521.8450927734375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1182.8282470703125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2526.8466796875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1215.4842529296875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1334.8533935546875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1268.174072265625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 774.0354614257812 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1265.591552734375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 896.2992553710938 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1329.8892822265625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1091.606689453125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 631.366943359375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 948.071044921875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 825.5357055664062 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 4713.35009765625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 802.8873291015625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1685.9404296875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 892.22265625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 710.7748413085938 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1065.622314453125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 729.20361328125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1723.1141357421875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 674.329833984375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 862.544189453125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1024.4608154296875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 994.0318603515625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 754.632080078125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 930.3837890625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2754.4208984375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 970.2490234375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 943.2605590820312 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 931.8719482421875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1086.84130859375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1084.223388671875 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2289.213623046875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 739.6563720703125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1053.5733642578125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1467.62744140625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 713.079345703125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 2624.29736328125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 532.7694702148438 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 699.66015625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 827.8613891601562 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1597.9052734375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 904.863525390625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1371.677978515625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 881.35009765625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1023.9158935546875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1102.523681640625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 807.16796875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 816.5526733398438 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 811.037109375 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 883.43505859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1148.8377685546875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 797.38427734375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1141.80712890625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 934.1026000976562 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1353.4234619140625 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1540.6768798828125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 775.97314453125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1197.81640625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 786.3717651367188 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 963.1790161132812 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1956.0015869140625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 966.2113647460938 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1807.5037841796875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 935.872802734375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 765.9736328125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1493.7987060546875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 844.1710205078125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1059.8897705078125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 879.9518432617188 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 2646.165283203125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1813.99169921875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1240.300537109375 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 827.2781982421875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 926.84765625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 3677.464111328125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1327.816162109375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 2247.28125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 970.7924194335938 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 83833.5078125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1972.2821044921875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 613.70849609375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 994.5032348632812 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 36066.03125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 936.070556640625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1239.6058349609375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1394.4200439453125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2658.83447265625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 734.1773681640625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 482.56011962890625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 977.1055297851562 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1537.7872314453125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1748.985107421875 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1639.36572265625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 862.947021484375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 4126.40087890625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1681.5865478515625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1284.3795166015625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1295.7845458984375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1459.943359375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1286.35302734375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1199.66015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1321.8321533203125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1469.2301025390625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 649.6557006835938 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1853.8453369140625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 2363.92822265625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 854.3743896484375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 2731.150146484375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 3931.60107421875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 3122.27685546875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1984.4925537109375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1332.550537109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1130.79248046875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1211.24951171875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 945.9312133789062 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 536.7728271484375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1018.818603515625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1525.75634765625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1657.6739501953125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1398.393798828125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 2157.018310546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 818.2175903320312 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1503.621826171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2150.7705078125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 723.551513671875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 970.76708984375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1920.7314453125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1712.206787109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 946.4864501953125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1520.859619140625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2576.09912109375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1629.073974609375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 970.7070922851562 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1807.7281494140625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 854.5162963867188 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 855.20654296875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 3004.082763671875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1287.95068359375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1154.1739501953125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1273.366455078125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1391.470703125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 12147.0126953125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1784.236083984375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1010.4039306640625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 559.5552368164062 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1706.1314697265625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1059.262451171875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1489.1336669921875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1468.648193359375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 664.6633911132812 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1300.0904541015625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1545.390625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 909.909423828125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 729.4066772460938 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 621.85595703125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 652.9544067382812 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1731.80615234375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2656.38330078125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 973.8614501953125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 649.2753295898438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 766.079833984375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1444.7593994140625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1054.5101318359375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 741.7423095703125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 757.8368530273438 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 661.6507568359375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 675.6154174804688 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 697.9866943359375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1433.57666015625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1015.8081665039062 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1241.199951171875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1142.7169189453125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1021.8717651367188 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1302.303466796875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1350.2813720703125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 722.58251953125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1070.0943603515625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 827.4874877929688 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1027.8516845703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 760.7246704101562 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1596.37451171875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1231.7908935546875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1244.345947265625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 2639.35693359375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 2545.016845703125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 3338.18994140625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1597.07763671875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1571.61865234375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1046.416748046875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1308.746337890625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1025.6376953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2790.880615234375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1322.0020751953125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1071.8134765625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 994.3985595703125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 3627.640869140625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2187.31396484375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2200.8017578125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 5150.49609375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 819.1068115234375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1006.7257080078125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 865.632080078125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1317.6246337890625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1838.0264892578125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 669.704345703125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1189.10205078125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1419.555908203125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1045.314453125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 5323.13037109375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 559.7650146484375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2381.796875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2387.84765625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1424.4580078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1214.92822265625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 3959.54052734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1078.947021484375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1914.281494140625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 600.3833618164062 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1829.2781982421875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 7192.5830078125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 760.1510009765625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2614.5185546875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 842.9005126953125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 991.72265625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2338.423583984375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1398.3099365234375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 767.22607421875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1449.978271484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1749.3582763671875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1464.4287109375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1469.9366455078125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2424.69873046875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1415.8800048828125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 899.9676513671875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1043.533447265625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1125.7294921875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1569.80078125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 3074.292724609375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2394.560546875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1487.2860107421875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 652.9930419921875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1056.031005859375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1774.4051513671875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1056.1912841796875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1408.447021484375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1090.3582763671875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1024.8720703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1596.325439453125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1268.8944091796875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 787.1757202148438 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 730.5264892578125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 53305.7734375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1128.177490234375 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1373.56787109375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1055.42724609375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1163.062744140625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2846.905029296875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1949.943603515625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1182.9744873046875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 422.2174377441406 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2030.34423828125 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 3546.630859375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1698.048583984375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 957.6619873046875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1608.0589599609375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 807.6824951171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1019.571533203125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 6496.14794921875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 759.3355102539062 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 598.3961791992188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 731.6114501953125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1399.8900146484375 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1240.7816162109375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 3715.230712890625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 2591.4072265625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 924.5283203125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 946.3133544921875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 776.4183959960938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3121.04541015625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 951.6231079101562 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 636.888916015625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1020.4911499023438 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1188.57470703125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1341.3956298828125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1013.3095092773438 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 702.113037109375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1068.768798828125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2218.3623046875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 966.9973754882812 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 477.0714111328125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 751.15625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2707.7451171875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 598.4708862304688 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 530.0184936523438 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 820.35546875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 733.3795166015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1149.282958984375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 957.4768676757812 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 684.2018432617188 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 756.4097290039062 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 905.913818359375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 957.9996337890625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 572.5060424804688 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 915.0185546875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1049.2877197265625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2222.142578125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1100.7655029296875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1027.5252685546875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1067.1373291015625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1024.74658203125 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 981.2808227539062 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 910.9939575195312 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2210.873046875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1042.604736328125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1335.8282470703125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 951.2456665039062 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 745.273681640625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 979.9985961914062 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 851.9605102539062 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1190.9136962890625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 576.3368530273438 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1623.3553466796875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1026.6898193359375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1561.7442626953125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 491.8150634765625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1538.1824951171875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1241.818359375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 774.9906005859375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1227.853759765625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 725.1881713867188 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1495.08447265625 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1472.4412841796875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1151.544677734375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2934.8623046875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 735.30224609375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1537.8450927734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2152.431640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 743.23046875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1159.3057861328125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1217.126953125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 630.4808349609375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 925.85400390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 797.9061889648438 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 983.778564453125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 2120.54150390625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 664.943115234375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 862.5804443359375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1104.53369140625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 703.5613403320312 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1852.301025390625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 633.7988891601562 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1039.2720947265625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 851.7130737304688 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1299.661865234375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 953.5660400390625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 584.0613403320312 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 848.171142578125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1112.2869873046875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1361.2003173828125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 778.4796752929688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 651.7364501953125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 826.8717651367188 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 697.911865234375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1409.3250732421875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1018.7833862304688 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 545.4328002929688 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 555.51953125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 891.6456909179688 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1340.1400146484375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1781.2100830078125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 942.294189453125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 482.3736267089844 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1372.6746826171875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1241.868408203125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 740.94091796875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1871.1884765625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1744.6982421875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1206.7867431640625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 787.601806640625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1085.0286865234375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1127.0472412109375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1661.600830078125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 598.5569458007812 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 701.1778564453125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 585.4924926757812 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 751.5436401367188 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1614.6849365234375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 4730.2666015625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 841.2378540039062 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 911.6634521484375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2706.484619140625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 931.7800903320312 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1177.9322509765625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1123.685546875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 913.186279296875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 995.8551025390625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 805.1267700195312 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 844.0360107421875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1130.5218505859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1652.8245849609375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1298.420166015625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1068.0347900390625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1095.228515625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1980.291015625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1054.8603515625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1516.833984375 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 890.25927734375 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 879.100830078125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 952.6039428710938 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1895.2197265625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 2390.411865234375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1689.868896484375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1490.6617431640625 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1129.2276611328125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 838.6276245117188 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1815.487548828125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1090.679931640625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 723.6030883789062 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 721.46826171875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 795.0353393554688 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1291.314208984375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 3568.11669921875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 5352.03759765625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 7215.1083984375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 3072.64697265625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1802.6070556640625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1805.732177734375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1270.1785888671875 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 851.5174560546875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1396.4310302734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 918.8397827148438 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 2666.93359375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 2128.271728515625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2421.939453125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 920.603271484375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 598.9175415039062 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2088.701416015625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1185.73291015625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1359.744140625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1472.8284912109375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1123.90380859375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 539.5425415039062 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1161.2979736328125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 930.9054565429688 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1473.6580810546875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 919.4141235351562 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1353.39501953125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1292.6717529296875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1700.2373046875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 664.3422241210938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1505.569580078125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 903.3683471679688 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 911.440185546875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1016.9850463867188 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 908.513671875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1200.7010498046875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 990.2457275390625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1942.8907470703125 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1782.9442138671875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1416.53173828125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 799.3329467773438 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 573.8206176757812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1130.6619873046875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2203.62158203125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1126.21630859375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 492.5735168457031 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 621.7310180664062 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2625.900634765625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 2499.98828125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1282.84326171875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 657.4811401367188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 817.9684448242188 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1830.0499267578125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1018.9073486328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1649.8670654296875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1306.0159912109375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 856.865234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1189.1553955078125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 918.94287109375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 920.5428466796875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1056.2061767578125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1345.7457275390625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 832.1021728515625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1910.96533203125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 899.4896240234375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1440.4703369140625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2225.625732421875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2002.9033203125 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1979.6314697265625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1498.3189697265625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 780.8570556640625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1010.4909057617188 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1239.975830078125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1699.24462890625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1088.991943359375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1312.3251953125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1322.6483154296875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 944.3505859375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1789.195556640625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 558.7836303710938 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 2149.2060546875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1438.9969482421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1725.830810546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 4486.9443359375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2144.77685546875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1855.4730224609375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1900.119873046875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1881.0545654296875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 5590.03662109375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 885.84619140625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 961.53173828125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 777.700439453125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2232.450927734375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1743.1669921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1151.2667236328125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 948.1024780273438 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1028.3505859375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 903.7826538085938 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 2180.90771484375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1858.8175048828125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 827.4512939453125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1000.4143676757812 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 3028.107666015625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1600.85302734375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1154.8531494140625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 867.5972290039062 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 762.65283203125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1370.7069091796875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1683.2557373046875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 15606.005859375 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2233.564208984375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1467.5506591796875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2731.741455078125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2184.067138671875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1457.7657470703125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1379.8438720703125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1984.9757080078125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2144.763916015625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2078.241455078125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 935.10009765625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1133.063720703125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1594.5906982421875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1786.2320556640625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2053.1728515625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 964.3231201171875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 768.2776489257812 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 834.1328125 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1264.177001953125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1527.5130615234375 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1935.3218994140625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1007.4240112304688 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1797.9947509765625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1362.0198974609375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1302.7890625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 992.6076049804688 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2228.16748046875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1161.985595703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 943.6344604492188 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1805.016845703125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 804.2469482421875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1028.849365234375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1817.1373291015625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1180.2164306640625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 2366.4970703125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1587.1717529296875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1880.560302734375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2643.3134765625 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1234.0845947265625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2386.993408203125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 721.7671508789062 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2046.71875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 763.3319091796875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1545.482421875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1072.6849365234375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1069.089599609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 952.779296875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 869.623779296875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 908.4981689453125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1686.755615234375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 801.8629150390625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1712.5098876953125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1219.7037353515625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1366.2503662109375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 896.3142700195312 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 559.8462524414062 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1269.6558837890625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1512.1488037109375 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1596.5145263671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1008.8704223632812 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1191.6324462890625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1186.525146484375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1750.94970703125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:03:27<103016:14:45, 1236.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 873.6111450195312 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1001.1782836914062 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1692.8115234375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2364.4619140625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1294.3135986328125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2074.734130859375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 994.3507690429688 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 849.922119140625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1571.00927734375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 4690.46142578125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 683.06201171875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1296.1494140625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1658.140625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1739.4447021484375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 885.9360961914062 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 919.2357177734375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 484.09039306640625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1547.0213623046875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1287.316162109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 821.6377563476562 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2454.17919921875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1010.5321044921875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1078.6817626953125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1797.5504150390625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1137.61962890625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2606.22900390625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2764.5927734375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 708.8939819335938 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1385.9215087890625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 2565.91015625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 828.4259033203125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 606.0690307617188 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 772.73974609375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1317.1201171875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1992.02734375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1539.600341796875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1208.476318359375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 746.7572021484375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 806.095703125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1387.2989501953125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1102.8060302734375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1964.92236328125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1200.3446044921875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1679.365478515625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1175.422607421875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1030.0850830078125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1011.0709838867188 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 760.3128051757812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1746.3797607421875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 8990.255859375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 825.57763671875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 758.1635131835938 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 4282.095703125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1410.9346923828125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 968.8624877929688 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2444.317626953125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 5605.6845703125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 6458.61328125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 746.2510375976562 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1466.57666015625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2258.960693359375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1128.066162109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1289.859375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1140.0203857421875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1262.972412109375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1241.1971435546875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1472.2386474609375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1635.245849609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1573.3524169921875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 775.0615234375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 974.6107788085938 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 842.7608642578125 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 975.0369873046875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 665.1043090820312 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 841.75634765625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 718.4864501953125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1096.070068359375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 748.2182006835938 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 397.2931823730469 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1598.576416015625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1481.82958984375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 938.421142578125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 761.5499877929688 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 521.1575317382812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1587.24560546875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 828.3221435546875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 861.7503662109375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 839.0028686523438 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 480.5797119140625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 666.745849609375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 666.3955078125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1613.713134765625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 994.7982177734375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 960.208984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 747.3460083007812 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 898.8214721679688 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2040.1441650390625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 978.3845825195312 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 681.4033203125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1100.0406494140625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 837.9951171875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1571.676513671875 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2466.8037109375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 5569.982421875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1593.517822265625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2690.4111328125 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 3017.048828125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1799.4505615234375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1551.1324462890625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3604.86376953125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2710.29833984375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1626.9248046875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1134.627685546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2195.98583984375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1158.8658447265625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1308.515869140625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 9379.109375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1208.8426513671875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1017.4815063476562 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1577.6759033203125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1220.164794921875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 909.6528930664062 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1852.3489990234375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1216.59619140625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 710.3915405273438 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 977.4263305664062 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 628.1080322265625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1356.392578125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1147.5914306640625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1287.9720458984375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1620.0191650390625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 863.8366088867188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1869.5806884765625 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1608.251708984375 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 770.2650146484375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1054.4423828125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 4032.7646484375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1168.364990234375 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1460.633056640625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 899.8944702148438 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 792.8060913085938 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1398.609130859375 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1196.906005859375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1869.2935791015625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2385.160888671875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1897.187744140625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1581.8282470703125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1202.2391357421875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 977.7937622070312 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1128.0335693359375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 4518.126953125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1842.5718994140625 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1311.918701171875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 2042.294189453125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 3117.846435546875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 876.098388671875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1539.925537109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1364.8526611328125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1158.753662109375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1358.8499755859375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1185.243896484375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1677.607666015625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1021.6151123046875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1680.8677978515625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2726.363525390625 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1539.8065185546875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1511.882568359375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2794.61083984375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 618.266845703125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 3067.37890625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 842.6199340820312 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1138.045166015625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1173.0966796875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1367.208984375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1670.73388671875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 814.493408203125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1464.9443359375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1965.67529296875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1107.4432373046875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1527.16943359375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1537.0565185546875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1864.1138916015625 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 951.468505859375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1909.654052734375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2283.778076171875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1258.6243896484375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2153.580322265625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2291.49169921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1774.552001953125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 920.326171875 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 6217.755859375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 4408.3408203125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1257.17724609375 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 849.9828491210938 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1770.859619140625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1047.7083740234375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2029.4683837890625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1259.8306884765625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1274.946533203125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2181.97314453125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1434.175048828125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1729.7926025390625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1431.5592041015625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1842.107666015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1431.9217529296875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 897.9053955078125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 822.4553833007812 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 875.9283447265625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1022.5569458007812 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1069.68798828125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 545.7879638671875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 821.14697265625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 961.2678833007812 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1080.707763671875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1295.1058349609375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 737.08056640625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3857.805908203125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1994.4951171875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1615.641845703125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1443.1517333984375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2047.0130615234375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1679.4041748046875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2693.915771484375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1372.995849609375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1586.1591796875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 905.7203979492188 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1065.66845703125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1088.5682373046875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1252.36181640625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1505.56396484375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1545.97900390625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2475.8466796875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 845.0641479492188 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 15948.353515625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 2004.3299560546875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 871.0101318359375 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 989.626220703125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1042.9571533203125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 910.431884765625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1048.7833251953125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1362.416259765625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1788.307861328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2060.447509765625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1793.0738525390625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 652.9054565429688 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1212.624755859375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1023.0336303710938 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1669.5191650390625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 948.5424194335938 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 988.4583740234375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2768.170166015625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2007.378173828125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1135.1146240234375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 876.018310546875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1524.1715087890625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1106.4151611328125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 964.975830078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 794.171142578125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1769.2327880859375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 744.90283203125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 592.5108642578125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 647.1326293945312 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 853.6797485351562 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 962.3970336914062 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 812.8355712890625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 608.3580322265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1092.144775390625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 719.3253784179688 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1442.9578857421875 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 646.6427001953125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 730.0453491210938 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1713.81884765625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1534.2550048828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 811.1966552734375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 856.8004760742188 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 899.6749267578125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1380.9954833984375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 715.8616943359375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1064.0108642578125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1711.6475830078125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1083.8125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1277.779052734375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1166.4705810546875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 910.3433227539062 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1065.2529296875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 8567.3916015625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 605.25927734375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 868.3786010742188 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 785.4967041015625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 993.206298828125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1564.762939453125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 906.6118774414062 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2126.928955078125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 864.1095581054688 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 858.0945434570312 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1330.32568359375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1313.83203125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 984.4632568359375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1051.2806396484375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1798.134033203125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1343.8355712890625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 399.6438293457031 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1179.68505859375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1517.43017578125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1437.991455078125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1605.116455078125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1027.236083984375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1243.922119140625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 3061.663818359375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1141.0740966796875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1623.1629638671875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1093.2803955078125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1754.0933837890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2903.9697265625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1056.9581298828125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1400.9288330078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 538.0557861328125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1610.1339111328125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1212.347900390625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 979.7626953125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1706.3309326171875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 643.11474609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 739.050048828125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1768.14794921875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1228.6982421875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1466.735107421875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1773.441650390625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 887.6703491210938 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 936.6661987304688 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2014.792236328125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1609.3004150390625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 10126.572265625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1583.022705078125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 852.7933349609375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 758.3748168945312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 14687.2763671875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2183.261474609375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1869.24658203125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1131.035400390625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 605.9243774414062 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1248.8756103515625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1429.199951171875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 625.2415771484375 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 798.9708862304688 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1769.3720703125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1708.5198974609375 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 866.7662963867188 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 4516.8046875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1165.6180419921875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1491.1337890625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1171.077392578125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1096.7708740234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 744.8701782226562 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3163.90234375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1820.7862548828125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1449.2374267578125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2186.59228515625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 831.6201171875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 3898.259521484375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1667.922119140625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1664.603515625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 769.2487182617188 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 853.7476806640625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 812.611572265625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1436.4915771484375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1096.1649169921875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 3132.18798828125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3575.47802734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1019.8006591796875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 692.0595092773438 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1190.8734130859375 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2223.649658203125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 940.659423828125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 802.121826171875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 663.9239501953125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 686.8428955078125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 21797.6328125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 3731.407470703125 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 929.2799072265625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 2216.244140625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1973.709716796875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 2405.4990234375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2836.7890625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 617.0778198242188 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1606.478515625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1198.520751953125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3653.814697265625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1825.1748046875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2535.172119140625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1062.4649658203125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1476.95849609375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 914.7738037109375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 4142.47705078125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3509.741943359375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 894.1863403320312 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1217.7850341796875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2229.087158203125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1472.2869873046875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1266.8858642578125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 529.5694580078125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2051.85693359375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 724.828857421875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1075.6571044921875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 910.4902954101562 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1635.0350341796875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2259.82958984375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 800.2291870117188 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1221.611572265625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 710.8360595703125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 957.1769409179688 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 950.766845703125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 775.5917358398438 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1770.734619140625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1506.0821533203125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1615.6663818359375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1048.4688720703125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 4174.17822265625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1173.4820556640625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 750.2515869140625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1360.302734375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1129.553466796875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 2612.05712890625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 897.5403442382812 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1595.370849609375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1749.977783203125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 759.5125732421875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2318.16064453125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1369.1436767578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1667.12158203125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1787.0582275390625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1055.1016845703125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 769.413818359375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 969.3609008789062 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2446.720703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 2143.2109375 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1925.3876953125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 790.2194213867188 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1457.535888671875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 873.3627319335938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 3186.31396484375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 4385.78564453125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 3975.406005859375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1181.8485107421875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1016.8645629882812 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 800.8934326171875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 923.0261840820312 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 990.203125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1867.3592529296875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1388.401611328125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1731.06689453125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1535.8426513671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1793.5155029296875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2395.6806640625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 906.287109375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 959.5691528320312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 5290.61083984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 735.5076904296875 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 885.4547729492188 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 694.1685791015625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 813.0731201171875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1216.4595947265625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 818.9180297851562 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1237.1275634765625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 616.3597412109375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 588.5098266601562 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1637.486083984375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 873.6725463867188 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 828.0097045898438 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 665.8207397460938 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 876.51318359375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1242.8182373046875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 906.035888671875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 698.0647583007812 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 625.5240478515625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1629.9512939453125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 954.0001220703125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 900.6688232421875 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1353.9638671875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 962.3065795898438 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2707.040771484375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 818.1135864257812 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 649.3010864257812 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1046.2017822265625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 885.6163940429688 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1041.4844970703125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 865.3157348632812 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 718.1895141601562 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 765.5223388671875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 682.24462890625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 695.3031005859375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1102.454833984375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1139.468994140625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1401.224365234375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 719.0543823242188 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 823.9302368164062 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 583.181396484375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 4586.490234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 896.1027221679688 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2822.368896484375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1211.6715087890625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2346.587646484375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 744.30322265625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1051.0953369140625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2265.5361328125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1480.449951171875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1147.1519775390625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3906.236328125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1092.9522705078125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1765.6656494140625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1295.28857421875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 771.7182006835938 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1176.165283203125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 2404.8125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 676.1254272460938 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 882.237060546875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1413.087646484375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 983.2943725585938 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1109.134033203125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 668.7233276367188 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1191.585205078125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1666.5391845703125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1243.8089599609375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1708.92138671875 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 799.6163330078125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1246.599365234375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3846.418212890625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1079.474365234375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 3862.571044921875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1119.9754638671875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 828.3701782226562 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1669.1402587890625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1117.466064453125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 3127.802978515625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1680.6107177734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 970.304931640625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 829.3383178710938 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 698.6041870117188 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 813.2401123046875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 746.6580810546875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1234.233154296875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1274.0726318359375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2149.138671875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 844.6229858398438 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1603.953125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 2414.2578125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1463.5135498046875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1425.46630859375 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1189.3770751953125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 2396.1708984375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 28398.59375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 7656.9208984375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1284.394287109375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 856.9650268554688 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 819.8449096679688 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 677.1129150390625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 954.3848876953125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 988.6032104492188 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1203.7044677734375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3683.0048828125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1681.8316650390625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 667.228515625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2327.066650390625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 984.6201171875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 838.2562866210938 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1049.729736328125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1058.5123291015625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 928.3781127929688 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 3021.816162109375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 779.4986572265625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 873.4625854492188 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2253.695068359375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1471.9669189453125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1018.174560546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1960.8311767578125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1198.4503173828125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 10640.9375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1911.4385986328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 820.2052612304688 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2085.857177734375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1422.358154296875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1215.6597900390625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1775.978759765625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 964.4110107421875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1107.748779296875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2175.699951171875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1584.3389892578125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 735.0927734375 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 823.83349609375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 847.1160278320312 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 992.7816162109375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1132.1751708984375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1930.2645263671875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1866.251220703125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1000.958740234375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2042.8153076171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1633.0916748046875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1008.7660522460938 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1411.0484619140625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1814.204833984375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1296.57421875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 11914.8359375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 913.5634155273438 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1220.13134765625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1038.311767578125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1823.3914794921875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 4236.05029296875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 892.1350708007812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1020.9651489257812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1233.89453125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1818.8692626953125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 3854.0380859375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1640.811279296875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1757.5533447265625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1036.924072265625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1072.7509765625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1614.7254638671875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1533.4473876953125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1891.968017578125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 886.9717407226562 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1940.1075439453125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 16567.078125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1006.9762573242188 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 847.7783203125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 675.4064331054688 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 841.6568603515625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1617.6522216796875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1266.801513671875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1283.623046875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 722.2842407226562 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 904.0634765625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1096.18798828125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1950.267333984375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 995.953369140625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1092.0692138671875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1452.0733642578125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 654.6988525390625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1893.0277099609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1285.480224609375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1377.7939453125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1072.7728271484375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1486.99609375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1870.21728515625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1296.6119384765625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1466.4501953125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1506.8997802734375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 969.41064453125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 851.6752319335938 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 933.4378662109375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 966.8927612304688 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1574.35009765625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1864.1466064453125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1605.4022216796875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 913.7054443359375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1326.595458984375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1173.5770263671875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 497.4517822265625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 887.4149780273438 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 895.7008666992188 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 625.6744384765625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 812.0703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 960.6787109375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 510.5201416015625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1989.03173828125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 763.5259399414062 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 502.74896240234375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 523.2550659179688 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1306.33056640625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1487.38330078125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1182.1204833984375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 991.0300903320312 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 714.7177124023438 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2810.636474609375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1168.82373046875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 763.1903686523438 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1045.8958740234375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1591.4844970703125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1145.7044677734375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 898.8038940429688 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1212.4794921875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1448.1563720703125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1149.09765625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1245.2841796875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 822.3527221679688 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1138.006591796875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1008.1268310546875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 780.8212280273438 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1171.83544921875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1343.59765625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1240.6011962890625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1048.3885498046875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 991.8350219726562 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 740.7175903320312 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 2464.396484375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2204.53271484375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1606.9864501953125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:24:06<103100:06:15, 1237.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 2822.497314453125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1018.8573608398438 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 791.387451171875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1578.17578125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1226.47802734375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1232.1617431640625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1520.988525390625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 863.732421875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 863.0729370117188 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1285.159423828125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1175.7591552734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1916.1668701171875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1054.366943359375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1920.406494140625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1257.7867431640625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 12816.306640625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2043.0635986328125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1668.475341796875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 4865.109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1164.279296875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1822.5164794921875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1486.491943359375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 557.4087524414062 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 719.6631469726562 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 948.5435791015625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 885.4020385742188 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1364.224853515625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1055.0201416015625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 519.1239013671875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 771.0208740234375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 962.415771484375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1337.2552490234375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 2169.371337890625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1075.1832275390625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 752.596435546875 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 791.1732788085938 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1299.6678466796875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1144.4427490234375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 852.0728759765625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 817.39208984375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 831.8389892578125 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1976.6534423828125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 2421.1640625 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1891.443359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 991.28466796875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1021.4020385742188 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 869.5847778320312 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 848.5510864257812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1063.5098876953125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1821.0166015625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1942.4180908203125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1258.7930908203125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 861.6943359375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1153.959716796875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1039.538818359375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1875.9466552734375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1079.6710205078125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1202.54296875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 833.2764892578125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3411.69921875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1121.0137939453125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1101.2052001953125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 2285.208984375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 878.3258666992188 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1190.135986328125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1477.6085205078125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1118.66748046875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 762.2597045898438 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1749.353271484375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3202.76025390625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 2446.0966796875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2101.64306640625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1644.5804443359375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1413.3028564453125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 2116.9873046875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1458.0830078125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1050.3695068359375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1524.1578369140625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 739.6716918945312 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2640.0283203125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1048.150390625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 708.2095336914062 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 683.55126953125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 2690.408447265625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2758.39111328125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1536.862548828125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 2764.110107421875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: -5116.130859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 981.7300415039062 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 961.7498168945312 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1672.817138671875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1180.4197998046875 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 2209.53173828125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 2951.74560546875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 2358.945068359375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1339.0478515625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 867.5938110351562 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 2337.869873046875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1766.5301513671875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2974.879638671875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1386.3929443359375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1245.4434814453125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 838.28125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 711.8582763671875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 779.6487426757812 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 704.9818115234375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1023.4987182617188 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1573.8226318359375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1114.5185546875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2841.529541015625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 999.9931640625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 791.25 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1953.1971435546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1968.531982421875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1213.53662109375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1417.4244384765625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1258.1436767578125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 987.7013549804688 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1499.1748046875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1666.030029296875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1641.939697265625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1052.48046875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1050.42919921875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1607.8558349609375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1851.718505859375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1678.68115234375 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2739.8759765625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1196.8079833984375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1443.271728515625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2269.851318359375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2035.1029052734375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 711.4559326171875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1461.37939453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1480.862548828125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1071.33837890625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2439.426513671875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1535.0389404296875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1408.734619140625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 3147.654541015625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 703.81689453125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 789.6726684570312 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1121.57861328125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2047.6209716796875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1261.642822265625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1229.990478515625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1486.5303955078125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1257.5782470703125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1009.752685546875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 905.6324462890625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 863.0866088867188 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 2338.469482421875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1288.09814453125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 2175.249755859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 935.2291259765625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 3762.4111328125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1217.0970458984375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1556.1441650390625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1394.9503173828125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 831.002197265625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2541.975341796875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2611.49658203125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1333.014404296875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1040.3922119140625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1234.980224609375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1433.82568359375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 706.9884643554688 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 745.917724609375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1250.0233154296875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2252.538818359375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2031.981201171875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1426.6483154296875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1159.9146728515625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2671.152099609375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1587.7496337890625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 854.385986328125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2685.582275390625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1322.22998046875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1400.51513671875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 850.2250366210938 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 3755.064208984375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1293.6689453125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 819.9945678710938 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1532.6973876953125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1763.895751953125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1808.591796875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1357.6285400390625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1109.7828369140625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1361.5477294921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1018.2122802734375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1246.50244140625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1038.7772216796875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1096.2877197265625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 983.0774536132812 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1635.2080078125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 857.0209350585938 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1882.7532958984375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3729.611328125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1473.3465576171875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 980.538330078125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 901.6539306640625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1505.2518310546875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 615.66748046875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1918.6087646484375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1385.8173828125 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1317.0428466796875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1961.3221435546875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 949.8934326171875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1128.029541015625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1041.02490234375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1394.7515869140625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1457.1336669921875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1275.8651123046875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 6067.3857421875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1325.4847412109375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 780.6007690429688 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 3024.754638671875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 21161.73828125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1314.978759765625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 664.8958129882812 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2111.601806640625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1333.972900390625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 3322.25 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1959.1976318359375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2314.984130859375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1504.78369140625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 3435.27099609375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2042.4114990234375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 10062.5576171875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1787.9332275390625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 21456.162109375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 4968.18994140625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2432.152587890625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1105.5703125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 825.21630859375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1292.935791015625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1571.5985107421875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1120.7598876953125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 2864.928466796875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2095.212646484375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 2783.614990234375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 4424.24169921875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1630.5079345703125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1685.5177001953125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2249.975830078125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1411.0792236328125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1000.7188720703125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1099.6170654296875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 779.3130493164062 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1210.676513671875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 12659.61328125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1386.7613525390625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 925.685546875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1183.818359375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 788.6682739257812 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1132.875732421875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 750.5881958007812 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 918.1486206054688 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 822.3283081054688 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1776.8172607421875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 753.017333984375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1495.7271728515625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 731.9619750976562 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 557.2421264648438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 562.57373046875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 513.3575439453125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1604.8892822265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1423.591552734375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1157.122314453125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 992.3707275390625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1112.8316650390625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 827.6278686523438 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 784.04931640625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 834.1065063476562 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1033.255859375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 788.1724853515625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1459.505859375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2586.599609375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 995.9962768554688 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 863.1993408203125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 928.1392211914062 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 685.516845703125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 758.39892578125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1440.13916015625 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2478.232666015625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 857.7329711914062 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1263.849365234375 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 898.9472045898438 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 4282.185546875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 949.4324340820312 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2019.8165283203125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1355.982666015625 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1776.0423583984375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1779.24072265625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1342.442626953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1103.44140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1128.5478515625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1396.7952880859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1762.0213623046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 587.1494140625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1152.5889892578125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2638.947021484375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 4938.08837890625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1443.09423828125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 2265.652099609375 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 3838.30859375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1864.0655517578125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 954.8611450195312 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1331.9774169921875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 805.9767456054688 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1191.2996826171875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1837.0452880859375 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 8670.728515625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2026.419189453125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1087.9388427734375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 5217.8974609375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1624.007080078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 3351.0791015625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1607.5325927734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1202.711669921875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 3163.23291015625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 2924.004150390625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1289.4771728515625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1899.3682861328125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1114.2244873046875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 5179.20068359375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 934.9794311523438 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 960.0226440429688 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2311.61669921875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 726.7384643554688 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 885.2197875976562 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2874.302001953125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 945.5060424804688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 3430.357666015625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1150.1561279296875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2417.8466796875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2180.3125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1076.905517578125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 948.0155639648438 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 804.0589599609375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 966.8508911132812 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 935.8580932617188 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2252.523193359375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 806.1492309570312 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 3196.85107421875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 875.515380859375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 869.8931274414062 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1828.2733154296875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2288.675537109375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 967.950927734375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 818.380126953125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1281.775146484375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 778.4246215820312 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 868.9420776367188 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 755.8746948242188 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 865.6455078125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 844.8742065429688 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 864.3820190429688 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 915.9976196289062 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1289.6959228515625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1533.7620849609375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1759.0194091796875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1034.846923828125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2050.031494140625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 866.7622680664062 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1106.8760986328125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 646.5068359375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1178.1671142578125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1174.693115234375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 975.7794189453125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 641.4266357421875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1026.946044921875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1319.09130859375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1170.596435546875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2599.44921875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 727.4198608398438 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 657.24853515625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 826.980224609375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1100.2093505859375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1068.89404296875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2922.82177734375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1238.316162109375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1003.9073486328125 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 650.9255981445312 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1764.71240234375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2009.49951171875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1168.728759765625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1249.6119384765625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1468.9893798828125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1217.62939453125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1636.6309814453125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1189.2586669921875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1071.64599609375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1794.8463134765625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2114.629638671875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1470.4185791015625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2032.6962890625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 790.8013916015625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 2259.919189453125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1814.6885986328125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 5054.90966796875 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1034.9237060546875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1065.9080810546875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1192.86865234375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1550.7425537109375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2048.821044921875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1038.951416015625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2599.323486328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1876.4617919921875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 26597.486328125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 5858.6298828125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1800.9073486328125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1522.453125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2196.83056640625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2534.2060546875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 5666.234375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1349.552978515625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 840.8849487304688 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1306.1070556640625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 8771.6171875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 4132.1083984375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1346.0986328125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 3236.405517578125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1872.2491455078125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2193.5859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1287.44677734375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 942.7487182617188 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1446.5628662109375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1454.6220703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1239.75732421875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1203.82421875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 875.0294799804688 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1065.1668701171875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1266.4993896484375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 3194.203857421875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2398.155517578125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 588.3468627929688 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 851.3088989257812 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1310.731689453125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1866.2025146484375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2435.482666015625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1187.60302734375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 885.1602783203125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1460.6165771484375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1362.8499755859375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 5170.19873046875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 3368.3876953125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 700.966796875 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1593.9127197265625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 3538.596435546875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1087.8759765625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1118.6458740234375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1549.2601318359375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 648.4404907226562 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 3227.592041015625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 2452.784912109375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1012.7608642578125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1157.14208984375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1450.0894775390625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1145.8875732421875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 819.6788940429688 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1772.901123046875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2248.462890625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1111.8680419921875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1298.7490234375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1061.386962890625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1153.4718017578125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 2640.47119140625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 778.9343872070312 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1484.5045166015625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1518.6744384765625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 868.1240234375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 701.4417724609375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1189.7216796875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1188.70556640625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1335.4849853515625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 719.908935546875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1056.7880859375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 630.7911376953125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 839.2180786132812 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 4383.1298828125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1037.884521484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1171.327880859375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 3319.644775390625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 833.6986083984375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 660.44677734375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2181.09765625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 3678.975341796875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2322.401611328125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 784.6488037109375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 773.7437744140625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1583.9610595703125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1498.6790771484375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1797.38623046875 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1465.478271484375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 909.1106567382812 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 532.1959838867188 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 4003.017333984375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1637.6053466796875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 770.59033203125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1257.197021484375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1655.1944580078125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1406.5264892578125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1082.07470703125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 610.2026977539062 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1605.1151123046875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1843.02001953125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1245.9178466796875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 909.841796875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1502.893310546875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2841.371826171875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1648.942626953125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1004.7644653320312 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1181.7763671875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1112.5155029296875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1351.0692138671875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 959.9163818359375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2720.377685546875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1002.2255859375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1495.6982421875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1343.33447265625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2561.40869140625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 4496.44970703125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 849.5579223632812 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1686.7117919921875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1533.0506591796875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1963.1630859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1253.1771240234375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1132.5128173828125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1476.31103515625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2270.529296875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1854.98046875 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1397.1727294921875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 3497.214111328125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1744.8197021484375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1831.5064697265625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 982.2254028320312 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2862.57861328125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 765.0878295898438 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 3070.502685546875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1400.5714111328125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 938.1031494140625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1169.5733642578125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 891.6062622070312 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1540.6187744140625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1499.9534912109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 894.4306030273438 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 945.8829956054688 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1797.678955078125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1461.3271484375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 975.5642700195312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1243.04443359375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 632.9653930664062 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 775.8213500976562 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2688.403564453125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1032.343994140625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 827.1808471679688 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1276.3583984375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1064.3704833984375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 968.9437866210938 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 974.7411499023438 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1576.13037109375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1155.58056640625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1520.442138671875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1835.2952880859375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 894.6346435546875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 696.8250732421875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1321.881591796875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1079.5084228515625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 982.4962158203125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1868.616943359375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1770.375732421875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 3050.93603515625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1883.5155029296875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: -13598.29296875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1410.8494873046875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 637.141357421875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1802.4033203125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 3363.003173828125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1753.4530029296875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1740.06640625 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 848.117431640625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1572.485595703125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1863.0438232421875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1489.9722900390625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2212.4697265625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1699.58935546875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1251.16357421875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1733.0574951171875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 13111.8837890625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1686.7630615234375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1094.3739013671875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1036.5501708984375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1615.5880126953125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 3637.68701171875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1170.0233154296875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 951.2595825195312 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1098.476806640625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 988.2737426757812 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1988.977783203125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 621.5180053710938 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 8883.6455078125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 5374.31201171875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1169.2947998046875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 913.0442504882812 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 2212.00732421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 13077.5615234375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2092.553955078125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 4346.6181640625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1361.7498779296875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1888.9866943359375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1630.830078125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1233.2242431640625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1195.464599609375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1196.86328125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 961.8142700195312 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1233.76904296875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 762.5804443359375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1601.8594970703125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1357.9466552734375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1213.669677734375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1042.2650146484375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1705.19677734375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1645.1815185546875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 719.6492919921875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1995.9420166015625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 916.6362915039062 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 956.2618408203125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 624.5798950195312 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1523.28759765625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1183.02783203125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1304.05810546875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1588.6029052734375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 880.47314453125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1213.6610107421875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1075.15478515625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1316.9932861328125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1406.472412109375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2416.54443359375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1439.35302734375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1241.4271240234375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 3856.87939453125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1792.1048583984375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 2487.831298828125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2800.168212890625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: -32039.4140625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 3148.0087890625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1898.515380859375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1835.24853515625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1883.5126953125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1214.5650634765625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 3338.306884765625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1319.960205078125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 704.3590698242188 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1543.472900390625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1417.403564453125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1182.1678466796875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1035.933837890625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1027.83935546875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1083.707763671875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1726.4290771484375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2226.53125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 611.30810546875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1682.3975830078125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 984.5790405273438 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 970.3162231445312 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1680.2015380859375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 929.3466186523438 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 725.2301635742188 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1164.19873046875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1481.24169921875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2203.151123046875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1538.0181884765625 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 2035.403564453125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1320.11376953125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 3584.7509765625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1978.629150390625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 749.1919555664062 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1745.0911865234375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1355.3021240234375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1726.0721435546875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1270.3939208984375 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 889.1303100585938 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 9902.845703125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1401.3167724609375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 2289.320556640625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 5306.439453125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1249.141845703125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1322.341064453125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 3077.9052734375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 3707.06884765625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2148.80859375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1239.0 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1437.939208984375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1609.8609619140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 827.080078125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/300000 [2:44:43<103107:07:34, 1237.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Iter: 0/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1102.3458251953125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1920.077880859375 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1267.6754150390625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1291.6595458984375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1378.7940673828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1004.037841796875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1548.5928955078125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1827.9136962890625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1620.94384765625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1264.5333251953125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 745.9796142578125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1740.30859375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 5883.60205078125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 811.2192993164062 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1148.5386962890625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2106.351318359375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1195.687255859375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2007.29150390625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1315.8951416015625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1223.83349609375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1916.549072265625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1145.0479736328125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 673.9437866210938 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 819.7024536132812 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 2365.67822265625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 2472.453125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 2691.23681640625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1521.820068359375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1288.503173828125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 859.1744384765625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2196.79345703125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1209.842041015625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1529.66357421875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 798.4937744140625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1052.6422119140625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1402.4193115234375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1457.2537841796875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1714.5260009765625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1026.0374755859375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1065.5318603515625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 4976.0771484375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1658.621826171875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2399.112060546875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1021.8055419921875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2085.267333984375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1512.3917236328125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1107.2064208984375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1080.8607177734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 3072.737060546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 4737.11279296875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2019.60986328125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 982.2710571289062 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1009.1521606445312 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1603.1231689453125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1549.69189453125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1339.3626708984375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 2068.6416015625 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss — Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix — Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josh/Documents//github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/ResNet18_simCLR_model_202112078_EOD_transfmod=default_losses_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-de25315fd340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_train_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_val_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josh/Documents//github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/ResNet18_simCLR_model_202112078_EOD_transfmod=default_losses_train.npy'"
     ]
    }
   ],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-Transfer—L2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-Transfer—L2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}—C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE — RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scripted_transforms_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-423cf9bf6d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0;31m# class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscripted_transforms_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                     \u001b[0;31m# DEVICE='cpu',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mDEVICE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scripted_transforms_validation' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.18it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.37it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 24.42it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "c_lst = [1e-1, 1e-2, 1e-3]\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train — C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val — C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-2)).fit(features_train, y_labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
