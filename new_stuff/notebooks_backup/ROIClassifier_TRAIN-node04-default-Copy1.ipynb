{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(_[0], _[1].requires_grad) for _ in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')\n",
    "data_labeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_unbalanced.h5')\n",
    "\n",
    "masks_SYT = data_labeled['SYTmasks']\n",
    "labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])\n",
    "\n",
    "nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "labels_SYT = labels_SYT[non_nan]\n",
    "masks_SYT = masks_SYT[non_nan]\n",
    "\n",
    "X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjEklEQVR4nO2de5xlVXXnv+veuvWuflTTDU13A4pIRGdE0kF8RUZGgxpHjUFARzFB0UQzIaNGwsSIGSeDjkKM+sGgoqigovh+jQQffBwRbQgiBBU0Df1+VnXXu+reu+aPszu5XZ61qupW1a2Ss76fT33q3r3vPnudfc4659z9u2ttUVWCIHjkU1pqA4IgaA3h7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFoTDOLiIfFJG3zvKz3xWRVxt1IiIfFZEBEfnRwlo5d0Tk5SLyraW2Y7kiIioij1mivi8WkT9dir7zeEQ6u4i8SkS+31imqq9T1f+5AJt/OvBsYKOqnjmfDXkXldmiqjeo6nNm2d+vjUuRSeOvIvLEaeVfTOVnp/dXiMgnG+pVREZEZFhEdojIVSJSnraNNwNvB94oIr923olIv4h8IW3nIRF5mWPnRSJyp4gcFpHtIvIuEWmb6/4+Ip19kTkR2KqqI0ttSDMHfLFZjjbNwC+AVx55IyJrgLOAfTO0e6Kq9gLnAC8DXtOwjYuAPwF+F3gG8Ici8vpp7T8ATALHAi8HrhGRxxt9dQOXAscAT059vmkW+3Y0qrqkf8BbgB3AEPBz4JxUfgXwOeAzqe6uNMBH2l0G/DLV/Qvw4lT+OGAcqAHDwGAq/xjwjvR6NfBVsgM6kF5vbNj2d4FX59h68bRtvz2VvwZ4EDgIfBk4vqHNU4EfA4fS/6em8v+VtjOetvX+VK7AfwN+BewH/g9QSnWvAv4fcHXq6x2p7PsN/SnwOuCBtG8fAMQZl+el8RtKx+FNzrF6DXB/w5ifkcq3puN4DzABtAH/BbgPGEzj+biG7WwF/iptYwD4KNCZ6s4GtgOXp/3fCry8oW0H8G7gYWAP8EGgq6H+zcAuYCfwx2k8HmPsz3eBv0n9lVPZG4BrUtnZDefiJ6eN8WMa3n+24fg9P+3Xpob6dcA/A+el9z1kjv7Yhs98Arhylj7z34GvzNnXltjRTwW2kZwDOAk4uWGAp4A/BCpkV7J/BSqp/jzgeLKnk/OBEWB9g1N8f1pfH+PfnX0N8BKyK2ZfOlhfnMnZ87YNPCudlGekE/F9wG2prj+dzK8gc4AL0/s1Vj/pRPpOansC2Z3n1Q19V4E/S9vryrFHyS5eq1L7fcC5zrjsAp7RcBE8w9jv88guBr9DdvF4DHBig/PeDWxKNj02HY9np2P3l2QXw/aGz9+bPt9PdgE7cmzOTvt4VRrPZ6ZtnZrq/57sgtqfjt1XgP+d6s4luwA8gcyhbmRmZ3818C3guansR8BTmKWzA6cBu4GL53DePwkYm1b2JmbpwMAXmeWFofFvqR/ja2QH9DQRqajqVlX9ZUP9nar6OVWdIjv4nWSPWKjqZ1V1p6rWVfUzZHeyWX2HVtUDqnqzqo6q6hDZXfaZTe7Dy4HrVPUuVZ0gu2M9RUROIrvKP6Cqn1DVqqp+CvgZ8IIZtvlOVT2oqg+TndwXNtTtVNX3pe2NGe2vVNXB1P47wOlOX1Nk479CVQdU9S7jc68G3qWqP9aMB1X1oYb6f1DVbcmm84Gvqeot6di9m+wi8NSGz78/ff4g2fg37iPAW1V1QlW/B3wNeKmICNnTxV+k8RkC/g64ILV5KfBRVb1Xs69ZVzj73cjHgVeKyKnAKlW9fRZt7hKRAbKLzYfJnk5mSy/Zk14jh8guXi4i8kfAZrIxnRNL6uyq+iDZd5ErgL0i8mkROb7hI9saPlsnu9oeDyAirxSRu0VkUEQGya7mx8ymXxHpFpF/TBMjh4HbgFXTJ1lmyfHAv530qjoMHAA2TK9LPJTqPLY1vH4obSevzmJ3w+tRspPL4iVkj/IPicj3ROQpxuc2kX1tsmi0a/qY1FP9BuPz0/dxQI+eEzlSv5bsaezOhuP+zVR+pN/p250Nnyd7Qvszssfp2XCGqq5W1ZNV9a/TPs6WYWDFtLIVZF+PTETkRcCVZE8h++fQH7AMJuhU9UZVfTrZxJcC72yo3nTkhYiUgI3AThE5EfgQ2ferNaq6iuyxUI5sdoZu30j2FeLJqrqCbCKFhvZzYWey/YidPWRfE3ZMr0uckOo8Ozc1vD4hbecI8wlT/LW26U79QrLvlV8EbjLabgNOnuW2p4+JkO3TjobPePu4Oo3j9Pr9wBjweFVdlf5WajZRBtlXkunbnRFVHQW+QTapNltnnw+/ANpE5JSGsieSzXHkIiLnkp3zL1DVnzbT6ZI6u4icKiLPEpEOssmjMbJH+yP8toj8QZrhvZRs8ueHZN/HlDRjmh5tntDQbg+wUUTaja77Ul+DItIPvG0eu3Ej8Ecicnraj78D7lDVrcDXgceKyMtEpE1Ezif7jvfVBjsfnbPNN4vIahHZBPw52STlQnDUuIhIe9LpV6bH7cMcPf6NfBh4k4j8dvqtwWPSRTePm4Dni8g5IlIhu7hOAD9o+MzrRWRjGv/L+fV9fHuy7xnA7wOfTXfPDwFXi8i6tA8bROT3Gvp9lYicJiLdzO24Xg48Mx23RSU9tXwe+FsR6RGRpwEvxLjQiMizgBuAl6hq07/tWOo7ewfZY8l+skfPdWSDfoQvkX3/OzLJ9QeqOqWq/wK8B7id7AT+D2STPEf4NtlVcreI5D3u/D3Zd8j9ZBePbza7A6p6K/BW4GayO8vJpO+QqnqA7ER9I9mj/V8Cv9/wCPZeMllmQET+Ydp+30k26fU14CPN2jeNvHF5BbA1fZ15HfBf8xqq6mfJvlvfSPa4+UWySbK8z/48bed9ZGP8ArI70mTDx24kmxj7Vfp7R0PdbrJjvpPsJH+dqv4s1b2FbLLvh8nmfyJ7SkNVv0F2bL+dPvPtGcaj0eadqtrK3yD8Kdk5uBf4FPAnqnofgIickDT8I08mbwVWAl9P5cMi8o25dihpdm/ZISJXkM145p58j1RERIFT0nzGIxIR2UqmMPxTTt3ZZDPfG1ts1iOepb6zB0HQIsLZg6AgLNvH+CAIFpa4swdBQWhp0EK7dGgnPTN/cJlSX51vuzqXTHF+alEaaC6WprrOHkNt4pcClT22HVPHOcfLeSi09rtt35LHDy07rOPZzLGcOnSQ6thIbst5OXsS+t8LlIEPq+qV3uc76eHJcs58ulxShp9zVm55tcM+KpVR29t7br6jKTv2nv9Us65emfv2jrv6B2bdzovsvsRS5IG2kfwrwdoPzuaXqMVizwX5Y6xNeOeDN1xl1jX9GJ9+WvoB4LlkPxS5UEROa3Z7QRAsLvP5zn4m8KCq/ir9WOLTZL8CCoJgGTIfZ9/A0UEH28kJ8BCRS0Rki4hsmWJiHt0FQTAf5uPseV9U8wItrlXVzaq6uULHPLoLgmA+zMfZt3N0hNFGjo5cCoJgGTGf2fgfA6eIyKPIQhcvIMvF9YilVDW0Jmc2vjy58D9aWvd+e/Z8x1vyZ3Y9CXD3X9gz7p6sWLNiCoHKcH75jsvsvjZcae/XQjN0fr6yAv4+j66zK8WTIh3lwgqsLo/bG1x7Tb6q8ZCTGrFpZ1fVqoi8Afi/ZNLbdUeidoIgWH7MS2dX1a+TxWwHQbDMiZ/LBkFBCGcPgoIQzh4EBSGcPQgKwm/aUj1LSmkqXwqRuqO5LEK6gOHznmzWlar55VNORvKylX0eP/Kq2mvv3Gg5v6ErQTXJ8EttGc06Np5MNrTRvgeWpux23Xvmkk363+n79A+bajdX4s4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBB+o2fjD19oz8LW25zgFGNWHWDgsfb1b/Uv8mdbR4+127RN2H3tvtQOCvFmdgdPnfs1utpp21FzIo/L4/Y4ekJDrSu/tjSZWzwj3ox73VmOc+y4/Epvny1FA6BntzPj7gxIfRl4WtzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFIRlIAjMzOGX5csutUoT6+MAtXannVN18LT8yvZDdptqZ3N9jffb1+F6m63xTPXNPfLGC05xl69ygkJqnfnl9W7bvqELbHltzBkPqy+w88m58tqu5gJa1JEAS84YW+f3ihsXNkAm7uxBUBDC2YOgIISzB0FBCGcPgoIQzh4EBSGcPQgKQkult+q6HnPh+c4BW+7QkqFRNae8uXnVPBlqcnW+bOQtgzSxyu6s3mHLUN07HCMdda1tLL9dtc8eX5lybHTkpLIzVvXu/P7Kw/b9ZeQ4245ql91X+2G7bqrXqrDbHD7RtrHvYe88tbfpRWGay4otMPNydhHZCgwBNaCqqpsXwqggCBaehbiz/ydV3b8A2wmCYBGJ7+xBUBDm6+wKfEtE7hSRS/I+ICKXiMgWEdlSHbOXkw2CYHGZ72P801R1p4isA24RkZ+p6m2NH1DVa4FrAbqP3dSamYggCH6Ned3ZVXVn+r8X+AJw5kIYFQTBwtP0nV1EeoCSqg6l188B/tZrU2+DsWPzb+6TK+zrTu/2/Db1itOZ9wzh1PXstCsnV+eXV1fZGlTloK1d1St2XyPOQ1D7gD1WVSMizpPXPMlIPJmy7m0z3w6vr+GTbFmrNOH05chaGJvUbruJJ+l6EpqXVNJLcNlmJPW0ouGguYi4+TzGHwt8QbKzoQ24UVW/OY/tBUGwiDTt7Kr6K+CJC2hLEASLSEhvQVAQwtmDoCCEswdBQQhnD4KC0PqEk4ai5CVKPHxyfnnHAS+SyDah5Kz1Zkk1AJ1786+NI45kVF1p13Vvs2W5sXXNJT2sGWu6edF8XqJETyrzJMzSeH7DWo+X3dKuqvfYnVXXOoZM5NvRvt/e6VK1yXBKBy070qEY9i/wT9Dizh4EBSGcPQgKQjh7EBSEcPYgKAjh7EFQEFo6G1+agu5d+bOSE/12u6qxZJAVVANQGbZnP9sP2XXjaxw7jBnhyqA9s1vtsWfVp5wZ5pITuDLZ78zUG5usrbTlCRl1gnXW2O3qziy4DOZHKZVX2snfamPODPmQfarWnX2zZvgn19qqQNc2py8n+MpbKqs8YY/V+Jp8I1c8vLDT8XFnD4KCEM4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBBaHggjmi8nWMsWgZ3rzJLkAKZ6nboVZpWbF86qUyPvG4A4QRWTa5ygEC8vXM0Jqqjk6z/i2KhdtmbU3jNpt3OUobW/NZBb3tc+YbZ5cNc6s67m3ZasQBKgfV++nNe92x7DtjFnrBw7Bk+167Rsb7Nrb74tvTfZeebGX5Cf21W/d7vZJu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkJLpTepQ8VYyLU06cgdhpWjleaWNPJkkMqY3bBtLL+81m73NbnalrVqnXZdpc+WvGpVZ6msvvHc8v5uw3hg92CfWdfTZUtl45N2CNiartHc8n2jPWab2oSTDM+RG8uH7NPYUuW8KMth20Rqvc4SVc654+W1q3pLUVl2tOdvT0tOXsaZNioi14nIXhG5t6GsX0RuEZEH0n9jFbQgCJYLs3mM/xhw7rSyy4BbVfUU4Nb0PgiCZcyMzp7WWz84rfiFwPXp9fXAixbWrCAIFppmJ+iOVdVdAOm/+TtHEblERLaIyJbquPGFPQiCRWfRZ+NV9VpV3ayqm9s6nZmPIAgWlWadfY+IrAdI//cunElBECwGzUpvXwYuAq5M/780X0NqXbZkUDes7Jg+k9DYxkkMOHKCF9XkLOXkSCtNYUTzAdTrdl89hrwGMDrakVve5uyXqm3H2IStK5ZK9jgeGMvXkzy5rtzpJLd05MaaE8WoJUPOcyLltN2uKw870uyII695yUVtldWmiRWqZiO9fQq4HThVRLaLyMVkTv5sEXkAeHZ6HwTBMmbGO7uqXmhUnbPAtgRBsIjEz2WDoCCEswdBQQhnD4KCEM4eBAWhpVFvWoLJvnzNwJPKrAg2N7LN2bP2Qbvh+Hp7LbKqIcnIpBNpNNHc9VQcaWh0pNOs6+7Jl+W62u39am+zE1/WHVmup93WjDrK+TLa8Hi+NAjQv9L+heWh4S6zbtKJiKsbkq44a+m1HbaPWXnC0bycKk+Ws9bnm3j+75hNSlNGIycLaNzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFITWrvWmtmQgdlAW4/1Gcj0nP2HJVppoy8+FCEDlgD0k9Y5822u9tnRVc9ZRkw67nThRak5OQR69Oj8UcLxm79eJvXb44L7xXrszh72j+UksH792t9nm4ISdefGwIzeW252knlZkYbcT3ViydWAV+/5Y73Si5Zy1DHu3GX05B7rrSz/KLS+pfXLHnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgILR0Nr7eAUMnGZXeZcf4cb/Yk9nUnSWZvAAaz46SFTxx2B7G2go7r1qpzVn+qWLv3PGrDpt13W35wSkn9+4z23SUbBs3dQ6YdQNT9uz5aSvyZ91/MWxmHWfPkL0MlZfvrqvbXqKq1pF/QKcmnWPmBdYYikxWaVeJPcSMbMjvb2ydbeOGr9jbs4g7exAUhHD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQ8kAYUy5zZAsLL3gGJ3davWLLJ9U1dgSNtOW303EnIscJWimX7R3w6rrabBtXtY/llpecnHbPX3m3WXdKJX97AAccieoTA2fllrc5B+3k/v1m3e4Re42nwVE7P13VWDaqr9fer8lOe3xH9tqLk7YfsM+DkjNWNUPO0za7zfa/empu+dR1P7RtMGsSInKdiOwVkXsbyq4QkR0icnf6e95M2wmCYGmZzWP8x4Bzc8qvVtXT09/XF9asIAgWmhmdXVVvA5z1UoMg+E1gPhN0bxCRe9Jj/mrrQyJyiYhsEZEttRE7L3gQBItLs85+DXAycDqwC3iP9UFVvVZVN6vq5nKPPbkRBMHi0pSzq+oeVa2pah34EHDmwpoVBMFC05T0JiLrVXVXevti4F7v80coTUHPjvy68bWONGEsu1TtseUkLTt1TgQVhlSTtTNkI0fW8vLMdXbYEs/KrvxlnAB62+wor4OT+ZFox/cNmm2OL9t5y9aV7Rx0HWLLVyd0HMgtf3is32wzXrNzv3nS4dSULXlNHc5fbmrgkL0MFU5OO2upppnq6oZsCyCGLFd3zuG6cVi8vIwzOruIfAo4GzhGRLYDbwPOFpHTyXZvK/DambYTBMHSMqOzq+qFOcUfWQRbgiBYROLnskFQEMLZg6AghLMHQUEIZw+CgtDahJNtMHZsvsxQ7XakMkO2MBNAAm0H7TovWq5uqz9MnJwvh7X32hJam5NUsla3r7VlZ/knbyknS77aP2VLaA9V7YiyVaVhs263k/BzXPPt8JJbevR32vLgvpK9bz3H5LebGLcPdHXIkQDHnOWfnCSnpfw8oIB9Poq1dJWHc27HnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgIISzB0FBaG3CScFMwNh/n92sVjGighyZzItEqzuJ/CbMNBwgA/naSm2PHUE12WNrIdpty1C9nXZkm6qdF6CjnL/Nat0Oh/rK4Olm3Q8qdsKRzpItOd4/sj63fKzJyLYHDxxj1lUq9jiWjW1W2+z7XK3LuQc6x6x20D4P2obtbZpSsBNFVzakPE9Wjjt7EBSEcPYgKAjh7EFQEMLZg6AghLMHQUFo6Wx8eRJ6H86fYqx7lhiXpHq7Pas+udLenJXTDkAdO0rj+f15eb/cwAQnSObwaKdd53R3xvHbc8t3j/eZbR7bu9es2zJ4glm3ttMOkjk0lW//o3ryc9MB7J+wA1rq/faxbneCa/aM5u/3oQFb0dBR+4CWh526McfGIbOKmjGJ7/qElwvPIO7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICsJsVoTZBHwcOI5MSLpWVd8rIv3AZ4CTyFaFeamqDnjbUrFlBi81WbXTCIRxrO9wFpkePc6uK03a8km9I1/vcKW8ilPnLFs0NulIPJ128rcHB+2AEYu+ih1088uD9vb2dtpy3sBIV275fdiDv6rHXk5qz0E7T54XQHP6pnwpsm7kQgTY/dAas65sr8rl1qmTTk6Mc985LIhxCjhDMas7exV4o6o+DjgLeL2InAZcBtyqqqcAt6b3QRAsU2Z0dlXdpap3pddDwP3ABuCFwPXpY9cDL1okG4MgWADm9J1dRE4CngTcARx7ZCXX9H/dglsXBMGCMWtnF5Fe4GbgUlX1frE5vd0lIrJFRLZUx+xECEEQLC6zcnYRqZA5+g2q+vlUvEdE1qf69UDuD6xV9VpV3ayqm9u67N8jB0GwuMzo7CIiZEs036+qVzVUfRm4KL2+CPjSwpsXBMFCMZuot6cBrwB+KiJ3p7LLgSuBm0TkYuBh4LyZNiR1aDPUlakeW5uwItHaDzUZvVZzdBBHulDj0qgVJ7TNQUZseU3LjiGO9GbhLTV1z778fHEA7W12X23OElVTk/kHoKvLXgdpzwE7VFGd4WjvtnPh7RvLj6Q7cMh+yhRnfCdXOUuOOXntvKWcLBnNO7+t89TaFszC2VX1+5hpIjlnpvZBECwP4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAWh5cs/WfKV1GyZoW3UaOMoXo7SRJvzQ76aneeR7h35osTIRltCq/XZWkjlsG3kVK89HrUxu7/BSn60WXenLXmNjucvawWwfrX9Y0lrqSmAqfH8U6s6YZ9ylS5bQvMYG7Xt37o//1fcbb12XzLgLFE15ci2DlMr7ONpJaocOsnenlTz29TsoYg7exAUhXD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQWulNsaPKHEWjZKhGlTEv6s1Zd+uw3W6iZLcbO85IOOnIa+UR+3pqyZAA7YecdezElt4m2/Nlo0lHnupZaSd6HJ4wMoQCg7V8mQ9ARvJPLS9CcHLc0T2ddjJuj4eVQLRqSFcArLQlxfJeW5bzzuHKYbuya0/+eeUlYS3V8sdju5OkMu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAWhpbPx5QMj9H/09ty6/a99itmu/7r8Nh6Dr7S35wXdjBxvz5pWV+TPgLYN2rPBXrBOZchZasqZ9MXuDoxcZyVnNnti3O5s0sglBzB5wJk9N3LolYedsXJmyEWdnfby0w3mb3Oqz8t56OQG9FQjJ46nbAse7pJNZptFWv4pCIJHAOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVhRulNRDYBHweOA+rAtar6XhG5AngNsC999HJV/Xqzhhzzj3OX15pl4Lccea3PlqjKQ/nXxmPusfWO8X77ejphr3aEttnblAlHNjIOaa1kb6/uSV6r7Nx1pUlnuSMniMNs48hG3rJGXt41S7Hr2WG3Ge+3x2P8OCfoacI51mvsnes4lF/uqY2WNOtJg7PR2avAG1X1LhHpA+4UkVtS3dWq+u5ZbCMIgiVmNmu97QJ2pddDInI/sGGxDQuCYGGZ03d2ETkJeBJwRyp6g4jcIyLXicjqhTYuCIKFY9bOLiK9wM3Apap6GLgGOBk4nezO/x6j3SUiskVEtkzhRNYHQbCozMrZRaRC5ug3qOrnAVR1j6rWVLUOfAg4M6+tql6rqptVdXMFO+tJEASLy4zOLiICfAS4X1Wvaihf3/CxFwP3Lrx5QRAsFLOZjX8a8ArgpyJydyq7HLhQRE4niznaCrx2EexzGT7vyXbdBi+Cyllqathud9Jf58uDB//YjrDzaB+y68acgLL2QWfZKCMyz0t4V293libaZhviLr9lnFm1LkdSdOS1tlFHLu2xDam3G+0cma97r105tcIeR08CLDty6dAJ+eW92207qp352/PyGs5mNv775KfSa1pTD4Kg9cQv6IKgIISzB0FBCGcPgoIQzh4EBSGcPQgKQmuXf3I4/LKzzDpPTrAoOz/W69ll102sdsKGDFz7HHlqaoVdVzaWLQI/osxK2lhrIppvJqyllTLyZSN1kjJ649h5wJahOg/M3Q5vaSVPUlz1M7tucoWTQNSR5WrGb81Gj7W317Mzf78i4WQQBOHsQVAUwtmDoCCEswdBQQhnD4KCEM4eBAWhpdJbvb+Hod+zJTYLSwrxpJqufU50lRP1dtzVc0986Uk1Hu2Ddt2kl4zS2W8zgs1JKllyos28Nec8mceKUvPWt5tc6RwzZ4ybWSvNw1uzzaNzwDbEk+UsmXjSkWatNQm94xV39iAoCOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVh2US9eQkATWnFaaOeBGEvX9YU5Ym5JwYEXwKU+tyj7wBKU/ntSmNzbwOgzhpxVSd55Ip/NSocCa3WYdsxdqzdru8hZx07Y700T770jotHvWTb33nQ3vHRtfnGtDnHbKo3v9xb6y3u7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFYcbZeBHpBG4DOtLnP6eqbxORfuAzwElkyz+9VFUHvG2VDo7Q9+kfztfmf2PofDuopjxpz6iWagsbObHyBnufBl5lLw01dowzC27MImeVdpUVVNG531EFnBnyiVXODPN+Z4ytYBLH9hVb7cqhE5xAnqm5B9DUy854OIFBXtDNyk/OPYgKwIp3GbrAPr+HTsi/T883B90E8CxVfSLZ8sznishZwGXArap6CnBreh8EwTJlRmfXjOH0tpL+FHghcH0qvx540WIYGATBwjDb9dnLaQXXvcAtqnoHcKyq7gJI/9ctmpVBEMybWTm7qtZU9XRgI3CmiDxhth2IyCUiskVEtkzhJHMPgmBRmdNsvKoOAt8FzgX2iMh6gPR/r9HmWlXdrKqbKxjZ8IMgWHRmdHYRWSsiq9LrLuA/Az8DvgxclD52EfClRbIxCIIFYDaBMOuB60WkTHZxuElVvyoitwM3icjFwMPAeYtoZy59n1k4GW+xaB+2da2R9ba+5i1f1bXX1lfKpgxlt6lVnPxo47YdHp58ZeFJoqsesOuaOQ88WWsh5eH54NnRZ5Rv0xGzzYzOrqr3AE/KKT8AnDNT+yAIlgfxC7ogKAjh7EFQEMLZg6AghLMHQUEIZw+CgiDaZL6tpjoT2Qc8lN4eA+xvWec2YcfRhB1H85tmx4mqujavoqXOflTHIltUdfOSdB52hB0FtCMe44OgIISzB0FBWEpnv3YJ+24k7DiasONoHjF2LNl39iAIWks8xgdBQQhnD4KCsCTOLiLnisjPReRBEVmyRJUislVEfioid4vIlhb2e52I7BWRexvK+kXkFhF5IP1fvUR2XCEiO9KY3C0iz2uBHZtE5Dsicr+I3Ccif57KWzomjh0tHRMR6RSRH4nIT5Idb0/l8xsPVW3pH1AGfgk8GmgHfgKc1mo7ki1bgWOWoN/fBc4A7m0oexdwWXp9GfDOJbLjCuBNLR6P9cAZ6XUf8AvgtFaPiWNHS8cEEKA3va4AdwBnzXc8luLOfibwoKr+SlUngU+TZaotDKp6G3BwWnHLs/UadrQcVd2lqnel10PA/cAGWjwmjh0tRTMWPKPzUjj7BmBbw/vtLMGAJhT4lojcKSKXLJENR1hO2XrfICL3pMf8Rf860YiInESWLGVJMxhPswNaPCaLkdF5KZw9LwfSUul/T1PVM4DnAq8Xkd9dIjuWE9cAJ5MtCLILeE+rOhaRXuBm4FJVPdyqfmdhR8vHROeR0dliKZx9O7Cp4f1GYOcS2IGq7kz/9wJfIPuKsVTMKlvvYqOqe9KJVgc+RIvGREQqZA52g6p+PhW3fEzy7FiqMUl9DzLHjM4WS+HsPwZOEZFHiUg7cAFZptqWIiI9ItJ35DXwHOBev9Wisiyy9R45mRIvpgVjIiICfAS4X1Wvaqhq6ZhYdrR6TBYto3OrZhinzTY+j2ym85fA/1giGx5NpgT8BLivlXYAnyJ7HJwie9K5GFhDtmbeA+l//xLZ8Qngp8A96eRa3wI7nk72Ve4e4O7097xWj4ljR0vHBPiPwD+n/u4F/iaVz2s84ueyQVAQ4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkI4exAUhP8PBaNlzNKPnB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUEklEQVR4nO3df6xf9X3f8ecrhhArgYaIC3JsJ0aZ080g1RTLo0LasiQrLqlm0g7JbAWkMpkxkMjWboL80+QPb6nWJB3aYCMDYbYsrqUkw0pCWpcmy9AI5po5GGNYrOBgxx52ShFGmlht3vvjflC/u/na9/r++N5wP8+HdPQ9530+n3M+R5Zf9+jzPd/vN1WFJKkP71joAUiSRsfQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKGvRS/JwSQfn2bbSvLXZnieGfeVRsXQlxZQkmVJdiQ50v5orFroMWlxM/SlhfUm8G3gNxd6IOqDoa+uJFmf5IkkryY5muTfJnnnpGbXJvlRkp8m+ddJ3jHQ/7eT7E/yF0n+OMkHT3Oea5M8l+REkp8k+d1h7arq5aq6F3hq7q5SOj1DX705BfxT4CLgV4CPAf9kUptPAuuAXwY2Ar8NkOQ64NPAbwBjwH8HvnKa8zwA3FpV5wOXA382lxchzZShr65U1e6q+n5Vnayqg8B/AP72pGa/X1WvVNVLwB8CN7T6rcC/qqr9VXUS+JfA2tPc7f8lsCbJBVX1F1X19LxckHSWDH11JcmHk3wjyf9O8hoTwX3RpGaHBtZ/DLy/rX8Q+DdtauhV4BUgwPIhp/pN4Frgx0n+W5JfmcvrkGbK0Fdv7gOeB1ZX1QVMTNdkUpuVA+sfAI609UNMTNm8d2BZWlX/Y/JJquqpqtoIXAz8V2D7HF+HNCOGvnpzPvAa8HqSvw7cNqTNP09yYZKVwJ3AH7X6vwfuTnIZQJJfSHL95M5J3pnkHyb5har6y3a+U6cbUJJ3Aee1zfPatjQvDH315neBfwCcAL7EXwX6oEeA3cAe4JtMvClLVX0d+H1gW5saehb4tdOc50bgYGv3j4HfOsOY/g/welt/vm1L8yL+iIok9cM7fUnqiKEvSR0x9CWpI4a+JHXknIUewFQuuuiiWrVq1UIPQ5LeVnbv3v3TqhqbXP+5D/1Vq1YxPj6+0MOQpLeVJD8eVnd6R5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOvJz/4lcSXq7WnXXN2fc9+DnPjGHI/kr3ulLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSNThn6SdyXZleQHSfYl+WyrfybJT5Lsacu1A33uTnIgyQtJrhmoX5lkb9t3T5LMz2VJkoaZzrdsvgF8tKpeT3Iu8HiSR9u+L1bVHww2TrIG2ARcBrwf+NMkH66qU8B9wGbg+8C3gA3Ao0iSRmLKO/2a8HrbPLctdYYuG4FtVfVGVb0IHADWJ1kGXFBVT1RVAQ8D181q9JKkszKtOf0kS5LsAY4BO6vqybbrjiTPJHkwyYWtthw4NND9cKstb+uT68POtznJeJLx48ePT/9qJElnNK3Qr6pTVbUWWMHEXfvlTEzVfAhYCxwFPt+aD5unrzPUh53v/qpaV1XrxsbGpjNESdI0nNXTO1X1KvBdYENVvdz+GLwJfAlY35odBlYOdFsBHGn1FUPqkqQRmc7TO2NJ3tvWlwIfB55vc/Rv+STwbFvfAWxKcl6SS4HVwK6qOgqcSHJVe2rnJuCRubsUSdJUpvP0zjJga5IlTPyR2F5V30jyn5KsZWKK5iBwK0BV7UuyHXgOOAnc3p7cAbgNeAhYysRTOz65I0kjNGXoV9UzwBVD6jeeoc8WYMuQ+jhw+VmOUZI0R/xEriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjkznh9HflWRXkh8k2Zfks63+viQ7k/ywvV440OfuJAeSvJDkmoH6lUn2tn33tB9IlySNyHTu9N8APlpVvwSsBTYkuQq4C3isqlYDj7VtkqwBNgGXARuAe9uPqgPcB2wGVrdlw9xdiiRpKlOGfk14vW2e25YCNgJbW30rcF1b3whsq6o3qupF4ACwPsky4IKqeqKqCnh4oI8kaQSmNaefZEmSPcAxYGdVPQlcUlVHAdrrxa35cuDQQPfDrba8rU+uS5JGZFqhX1WnqmotsIKJu/bLz9B82Dx9naH+swdINicZTzJ+/Pjx6QxRkjQNZ/X0TlW9CnyXibn4l9uUDe31WGt2GFg50G0FcKTVVwypDzvP/VW1rqrWjY2Nnc0QJUlnMJ2nd8aSvLetLwU+DjwP7ABubs1uBh5p6zuATUnOS3IpE2/Y7mpTQCeSXNWe2rlpoI8kaQTOmUabZcDW9gTOO4DtVfWNJE8A25PcArwEXA9QVfuSbAeeA04Ct1fVqXas24CHgKXAo22RJI3IlKFfVc8AVwyp/znwsdP02QJsGVIfB870foAkaR75iVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI1OGfpKVSb6TZH+SfUnubPXPJPlJkj1tuXagz91JDiR5Ick1A/Urk+xt++5Jkvm5LEnSMFP+MDpwEvidqno6yfnA7iQ7274vVtUfDDZOsgbYBFwGvB/40yQfrqpTwH3AZuD7wLeADcCjc3MpkqSpTHmnX1VHq+rptn4C2A8sP0OXjcC2qnqjql4EDgDrkywDLqiqJ6qqgIeB62Z7AZKk6TurOf0kq4ArgCdb6Y4kzyR5MMmFrbYcODTQ7XCrLW/rk+vDzrM5yXiS8ePHj5/NECVJZzDt0E/yHuCrwKeq6jUmpmo+BKwFjgKff6vpkO51hvrPFqvur6p1VbVubGxsukOUJE1hWqGf5FwmAv/LVfU1gKp6uapOVdWbwJeA9a35YWDlQPcVwJFWXzGkLkkakek8vRPgAWB/VX1hoL5soNkngWfb+g5gU5LzklwKrAZ2VdVR4ESSq9oxbwIemaPrkCRNw3Se3rkauBHYm2RPq30auCHJWiamaA4CtwJU1b4k24HnmHjy5/b25A7AbcBDwFImntrxyR1JGqEpQ7+qHmf4fPy3ztBnC7BlSH0cuPxsBihJmjt+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkem88PoK5N8J8n+JPuS3Nnq70uyM8kP2+uFA33uTnIgyQtJrhmoX5lkb9t3T/uBdEnSiEznTv8k8DtV9TeAq4Dbk6wB7gIeq6rVwGNtm7ZvE3AZsAG4N8mSdqz7gM3A6rZsmMNrkSRNYcrQr6qjVfV0Wz8B7AeWAxuBra3ZVuC6tr4R2FZVb1TVi8ABYH2SZcAFVfVEVRXw8EAfSdIInNWcfpJVwBXAk8AlVXUUJv4wABe3ZsuBQwPdDrfa8rY+uT7sPJuTjCcZP378+NkMUZJ0BtMO/STvAb4KfKqqXjtT0yG1OkP9Z4tV91fVuqpaNzY2Nt0hSpKmMK3QT3IuE4H/5ar6Wiu/3KZsaK/HWv0wsHKg+wrgSKuvGFKXJI3IdJ7eCfAAsL+qvjCwawdwc1u/GXhkoL4pyXlJLmXiDdtdbQroRJKr2jFvGugjSRqBc6bR5mrgRmBvkj2t9mngc8D2JLcALwHXA1TVviTbgeeYePLn9qo61frdBjwELAUebYskaUSmDP2qepzh8/EAHztNny3AliH1ceDysxmgJGnu+IlcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdmc4Poz+Y5FiSZwdqn0nykyR72nLtwL67kxxI8kKSawbqVybZ2/bd034cXZI0QtO5038I2DCk/sWqWtuWbwEkWQNsAi5rfe5NsqS1vw/YDKxuy7BjSpLm0ZShX1XfA16Z5vE2Atuq6o2qehE4AKxPsgy4oKqeqKoCHgaum+GYJUkzNJs5/TuSPNOmfy5steXAoYE2h1tteVufXB8qyeYk40nGjx8/PoshSpIGzTT07wM+BKwFjgKfb/Vh8/R1hvpQVXV/Va2rqnVjY2MzHKIkabIZhX5VvVxVp6rqTeBLwPq26zCwcqDpCuBIq68YUpckjdCMQr/N0b/lk8BbT/bsADYlOS/JpUy8Yburqo4CJ5Jc1Z7auQl4ZBbjliTNwDlTNUjyFeAjwEVJDgO/B3wkyVompmgOArcCVNW+JNuB54CTwO1Vdaod6jYmngRaCjzaFknSCE0Z+lV1w5DyA2dovwXYMqQ+Dlx+VqOTJM0pP5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjU4Z+kgeTHEvy7EDtfUl2Jvlhe71wYN/dSQ4keSHJNQP1K5PsbfvuaT+QLkkaoenc6T8EbJhUuwt4rKpWA4+1bZKsATYBl7U+9yZZ0vrcB2wGVrdl8jElSfNsytCvqu8Br0wqbwS2tvWtwHUD9W1V9UZVvQgcANYnWQZcUFVPVFUBDw/0kSSNyEzn9C+pqqMA7fXiVl8OHBpod7jVlrf1yfWhkmxOMp5k/Pjx4zMcoiRpsrl+I3fYPH2doT5UVd1fVeuqat3Y2NicDU6SejfT0H+5TdnQXo+1+mFg5UC7FcCRVl8xpC5JGqGZhv4O4Oa2fjPwyEB9U5LzklzKxBu2u9oU0IkkV7Wndm4a6CNJGpFzpmqQ5CvAR4CLkhwGfg/4HLA9yS3AS8D1AFW1L8l24DngJHB7VZ1qh7qNiSeBlgKPtkWSNEJThn5V3XCaXR87TfstwJYh9XHg8rManSRpTvmJXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZlV6Cc5mGRvkj1JxlvtfUl2Jvlhe71woP3dSQ4keSHJNbMdvCTp7MzFnf7fqaq1VbWubd8FPFZVq4HH2jZJ1gCbgMuADcC9SZbMwfklSdM0H9M7G4GtbX0rcN1AfVtVvVFVLwIHgPXzcH5J0mnMNvQL+JMku5NsbrVLquooQHu9uNWXA4cG+h5uNUnSiJwzy/5XV9WRJBcDO5M8f4a2GVKroQ0n/oBsBvjABz4wyyFKkt4yqzv9qjrSXo8BX2diuublJMsA2uux1vwwsHKg+wrgyGmOe39VrauqdWNjY7MZoiRpwIxDP8m7k5z/1jrwq8CzwA7g5tbsZuCRtr4D2JTkvCSXAquBXTM9vyTp7M1meucS4OtJ3jrOf6mqbyd5Ctie5BbgJeB6gKral2Q78BxwEri9qk7NavSSpLMy49Cvqh8BvzSk/ufAx07TZwuwZabnlNSnVXd9c1b9D37uE3M0krc/P5ErSR0x9CWpI4a+JHXE0Jekjsz2w1n6OTObN7x8s0ta/LzTl6SOLOo7fe96Jen/552+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoy8tBPsiHJC0kOJLlr1OeXpJ6NNPSTLAH+HfBrwBrghiRrRjkGSerZqO/01wMHqupHVfV/gW3AxhGPQZK6laoa3cmSvw9sqKp/1LZvBP5mVd0xqd1mYHPb/EXghRme8iLgpzPs+3blNfeht2vu7Xph9tf8waoam1wc9Y+oZEjtZ/7qVNX9wP2zPlkyXlXrZnuctxOvuQ+9XXNv1wvzd82jnt45DKwc2F4BHBnxGCSpW6MO/aeA1UkuTfJOYBOwY8RjkKRujXR6p6pOJrkD+GNgCfBgVe2bx1POeorobchr7kNv19zb9cI8XfNI38iVJC0sP5ErSR0x9CWpI4sy9Hv8qockDyY5luTZhR7LKCRZmeQ7SfYn2ZfkzoUe03xL8q4ku5L8oF3zZxd6TKOSZEmS/5nkGws9llFIcjDJ3iR7kozP6bEX25x++6qH/wX8XSYeEX0KuKGqnlvQgc2zJH8LeB14uKouX+jxzLcky4BlVfV0kvOB3cB1i/nfOUmAd1fV60nOBR4H7qyq7y/w0OZdkn8GrAMuqKpfX+jxzLckB4F1VTXnH0hbjHf6XX7VQ1V9D3hloccxKlV1tKqebusngP3A8oUd1fyqCa+3zXPbsrju2oZIsgL4BPAfF3osi8FiDP3lwKGB7cMs8jDoXZJVwBXAkws8lHnXpjn2AMeAnVW16K8Z+EPgXwBvLvA4RqmAP0myu30tzZxZjKE/ra960OKQ5D3AV4FPVdVrCz2e+VZVp6pqLROfZl+fZFFP5SX5deBYVe1e6LGM2NVV9ctMfCPx7W36dk4sxtD3qx460ea1vwp8uaq+ttDjGaWqehX4LrBhYUcy764G/l6b494GfDTJf17YIc2/qjrSXo8BX2di2npOLMbQ96seOtDe1HwA2F9VX1jo8YxCkrEk723rS4GPA88v6KDmWVXdXVUrqmoVE/+X/6yqfmuBhzWvkry7PZxAkncDvwrM2VN5iy70q+ok8NZXPewHts/zVz38XEjyFeAJ4BeTHE5yy0KPaZ5dDdzIxJ3fnrZcu9CDmmfLgO8keYaJm5udVdXFI4yduQR4PMkPgF3AN6vq23N18EX3yKYk6fQW3Z2+JOn0DH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkf8HaHzVE381SwwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.15, 0.15), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    ")\n",
    "    \n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAD8CAYAAABHPleGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABI/UlEQVR4nO29W6gt23nf+fvGqKo557rsfXQkWVJLIpLBDa3kJe5gBxJCIB3iGIPykmA3hDQY/OKQBPIQOX7Ik8HJg6Gh6QdD3HFD2o7pBNoPBrdj0phAJ223kRPLalmS7diydTlH5+zLWmteqsb4+mGMUTWqZs05a67L2XNL64O519w16zJq1H989+8rUVUe6ZGmkHnVA3ik14cewfJIk+kRLI80mR7B8kiT6REsjzSZHsHySJPpwcAiIt8nIl8QkS+JyGce6jqP9N6RPISfRUQs8LvAXwW+Avw68EOq+jv3frFHes/ooTjL9wBfUtXfU9UN8PPApx/oWo/0HlHxQOf9KPBH2f+/Anzvrp0rmevCXIAqic+JCBiZfkVt/xlsuwXJ4IvsONfW8NKGbOfhcb1zazfuY8cq8Z8kGYYSQg7MnbT/9K7/wn/zbVX94NghDwWWsZH27kZEfgT4EYC5nPPnz34ggMW58HtVIVUZbnpMVOaT4TyoB68dwHw4ZihmJR7Xbve++9GY3j4YAdnBfHMgp/3Tvuq7MXvdPi7trxp+dy6Mx/vxex2SCGItGEGdB+e276O9h+3x9+4vjjHNx//54n/5L7su+1Bg+Qrw8ez/HwP+JN9BVX8a+GmAp8UHVcoCdb5FmcjgYaiOr5b8oaSHawREQT3itw/pnd/aNJ7+DmkidXCC9vzS35aO8dqBYOxYr/TWTQ6U/H6H97d124r4cB9qbXsfvXsboxwgbsfk7KCHAsuvA98lIp8E/hj4QeC/37m3ANZ23N77bRG0a/UOH4oRMBbEgwrgxld3Old8wOJc4GrDlZiOHXKSnOMMxxq5xdY183HmnC8BJQdGGkfiNt6PcokwHOkvlHzc+TV7XHKEGx2gBwGLqjYi8neBXwYs8DOq+rndR8QH7BURRdPA00PJb1iziR2CIB1jBLwBdXECR1ZQj0PsAFN+/lzEDWnkt5xTyRjQYTdHMQaxYV+FALx8ToZjHeN26dl7s71/fl+7OPYIPRRnQVV/CfilSTsLkSMIuDi5YrKVb/qcZIxasRFXdc51cjEB/YerYZ8tMSQGcO122RINA26gfWBviQIxYE23Ly4wv2xFj+lKYkd05JyT5DR88EOu6AeceKijHaAHA8uxJCJoyxXCw+xW10APyB92AlWiXCfIOZI13cM0+b70AChDEdMbZLZ9KALFgMnFyGAFGwmiVqJS6hXMQKcaihIAbxDLNg33y2lsUSUOmonHNL9b97aDTgYs7cpOYkOk26ZJ4+/kvHj6kzUmOvZRDrytwfjxyUvbc32gXb2+z/LTfUwdzy5KnHW4DTrFv3eNXMSM3McQxBNAkug0wJKLDiMENYfugcaVOMnb3LJ6BUe7glEJOkwGkm0LKOccI+IknStN8FAf6nGZ+JDz370GLuldD2iq2l1H/TY4YFsnSfc4vPaQ6w73HRvzRMCcCFgIgICBH8K3QNLcujikuYsB0iTE49LxCSS5YhnP2T6wofjIjhHsNmAy8IlIi/UtruDd1vkTYHvccgg66cSTGBP9UT7cYw6YNE43GEcCUMt9+4r2VMCcCFgiZ2lXY9wunf6Cmp752E5uBIM2cYLKou8S3CXXdymWsG0FZcd0D3XcR6EazPChwruLW+zUWSJApLBQFFBYtLBBIXYOWddQ12jTAJ0o2rqX4X0k0HjtAb1dVHvoNMAC4aatDcpcmthcBRDpWQ6QmZ7OhZVmTcBJycCE7usOPdEyZNmZUrxL7HVAZeSh+PhAgxug3We4eltlO1sQyWKSaDoXBTqvoCrRqkBLiy8MZtVgzCrcq2qfK+f30g7Yb29P+7p4n0O/0AidBljSQxdBCeZi3ytqWsthy00fWbI2NWjwZEpZHHab56bnwPrYpZjmoYKentEe63t/FYJ4a4E1eGjt9X0HFGuRxEnKAj2b4eclflbgK4MvhKIwiPdI3SCNQaPLAeh5csNYdvii2u9RZA/F8gidBlgkmJWd11I7eZtTZNtjrnlJLu+c+/R8ChOsJZHAzRI4kXHQ2MHKbVm8GZ30jgOm4zP3fBqfNUhZRi4S/vp5gVuUuLnFVwa1ghowjUZOUyCNg7ruj2VoJfrBnORiProolDJsW+6enpMBi5TFwLPo6SFm6MntHS5BrifPZzIphz4Z6JuOuWhovawZYIhD2BUfGov/7FK+VdG6Cd8rkKFTTaLYqcrATRYlblHQLCxubvCW9r5MZbClwZQFbOptsTN2z/lvPYsp+X9eFwUX+ibdiLNsi9IqTlwpbRMzLoJ68npXdDECMgEmjSHXZ/Y4wyT3DeXkI5vPQxXQuQmMRc7m6Nkcf1bhLirq84JmYXAzwVUS9GUPxoGtBS0NWphgHeXjGVsAu0Ry7vGdkA5yOmCB7ibTah4Lgo2JomT2JkXSm774GfGKtr/l1LuebE9yGsPQl5GBvJeH42PKRTpP9OC2Vl4hyHyOziv8+Rx3MaO+LNlcGupzQ7MAtYK3IAriwG7A1IayCBxUTfawcwdh4srDsMeQy+hhxTbRaYEF+lp61PJbHWGHKJKoGIbjXKfZjwFFBGy+ErX7u6Ww6jhg02/teG3nsOvtl/wqvu/HSTGZokAXM/zFgubpjPqyYP3EsHkibJ4IbkbrBpAGbA2+EOwaXNRhRMJni3d47e4zieMkyiBYUM7ttPjG6HTAMjQtfeY4E+mLjsRddqQTbFkqPV8J+9nzockbgnXo4o/jC/tG/xCZUmtNtHYK9HyBe98Zm6cVm6cF6wiS+hLqJx4/T0AGqQW7EoobwdRCeW3w8xKzrLctoH1j121P8GsWSNRuZeZcMeolPa9kxnYl975lHtq+JzY67VL0OAUUe2x7MIFjiiv0Xerdhcc5GHSKY8yxkcIGa2c+w5/NcE8q1u8rWT21kZtA/URpnjrsZc1ivoljFzabgvqqxM0s0hjKa0N1XmBuSmy+aMwI1xTTifaeJzzO4Wvl7k804gYP26PfIvkshitJfSeyBqtkmK7Y+nFyvcabwLLFBBke2fNoHvBITElywy3XdUSgsAGgZQllcLK5J3Pqi5L1+wrWbxjWbwibp0r9xMPTmvPLNR+8vOJptcKIx6vh+WbOW/MLrss59bqifik0zw3FvMDaAUcbCx5CGytT1f6ieb04S6TswSRH1paogRFR0DnqNOoGW867KRMyFoU+EDXeYuEZUHK/ic4qdF7QXASRs7k0rJ8a1m9A/VRpnjaUT9e8+eSGD5+/5GNnz3h/dYVTQ62Wt9cXFMbzNVGulpbNi4LNhaF8UVCURVhAQ464I2FrKyQwUW85EbDINivfl0M7xoEyZ9jWtrEkn6ELfELG2FYi1L74i5gAlGQOn1U05x1INk8DN9k81cBNnqz40JOXfOLiHT62eJdPzt7iDXvDypdc+xmX9g2MKAblyzcz6ueWzYUwO7PMqhKMJaRKmv697Uspzce8w4eV04mAhW2WmALGh8TABDc1jHhdh5SSpgaxoa1qAOiHCoZkgoNQiiLoJhdz6suK+ollcx4snSR2mjcc9smG9z254SOXL/jE+Tf5rsU3+Hj1TT5evMOlqXnpS176OXNTY1C8Cl87v+TleUVzbnFzQUuLsQZV3zeFx5yJYzTRKjodsCTaVUKxy4PbM0kHLn1rRy2jPofo+xl6XClGmXvDkAEHbMdh2+BfUGIrmqcL6qcV66eBC9QXwdLZvM/j3mhYPF3xgctrPnbxjI+fBW7yieptPmhf8kG7YS5CyYZSPBu1vCzmfLM852y24UWp+ALUhAxDjQHFPGN/K5F7mNnXjl3AvS5gEfrWCez2b+SH5eUcPV9Kx1p7FlOey6Ia0jj30VhGfQrxG0ubbyPSWTqzCj2b4c5KNm9UrN+wrN4w1JfQnCv1E0Xft+HJ0yUfefKCP3XxDt+5eJuPVe/w0eJdPmSveMN4Lk1BKZaSmlIbanvNO/aGJ8WKedFAoahpLXPaioJUQ2RDOoO0Il46br0r9naATgMsyrjsPCLlr0fDfI2D11e2yiL2AamXre+D32RWobMKfzGjuZxRXyRLx3Qm8YWHJzWXT5Z89OlzPnHxDp9cvMV3Vm/x4eIZH7RL3jBwJgUzCYG9UgxzlFI8c1NTSkrmEowDcYrsECF784nzjLyJqZ+nAZaUSNzjDiOsPktVgExkNM240jnMeGv9CgPz2nW+mNYd355j4H2F4P00Gn0nESiLqJ88qVi/UQQl9lKoL6C+VJonDnNZc3654jsur/jA/Io3y2ue2iWXZslcGmww7KnVAzUOpVbPjSortVz7GVduxtV6hr02lC+UYqnQxLwYawPwU1hh6HPJFXCvqDb9+zxApwEWzRKKRrLFujgPQAyUJHab+U8QiUpxfzVt1e2UmW6jHtSE5KvcRZ4XeUW2Hh5GdGw5YBa2aVXizyqai5L1GwWrNw3r9wn1OTRnirsIQHlyueQDF9d8aPGSD81e8oHyJW/Ya87Nmrm4ICVUQaBWh1NlpbBSw0s/56Wbc+VmXK8qiivD7LmnvG4Q54K7oCj6dcNmcJ9ZJYRq083hhAIzOBWwQOcjaVMWs3yP4aowEtzWYzGwrRDA4LzW9i0uH0WJCLodYenONwwcWosk0/hiQfNkxvqNsovtXCpuofiFQuUpSkdZOErjMJE11mq58TOe+TNqLZhLEDM2jmODYaUlN37GF9cf5rMvP87vvPshVl8758nbMH+noXi5QdZ14LLDzDvoK7VZSKWNJ00ECpwSWKD/YHG94KA6HzmEbbmPRGsHRnwfu6oB8roiCEpwrBcWYCs3dxj+txZMhRQWPV/gL+c9oNSXQnMGfga+UtQqYsP16sZyU1dc2Rkz4zCi1L7gpVswMzWVNBg8NiroToWXfsGVm/NbLz7GZ7/6UdZfueDiDw2XX3HMvrHEXC1huYLEGRNl4Y+WBjkuUhTjyes76LTAAgEwELLoLTHM70NysrUhIJcKplLC82iKpOvMwS2uxbby2ysD0U70DM3OZPnMZ+hZUGZDEDA62i6j6Jl7tFIoPWI9qtB4w6opuK5nFHEcS1vy3C6wscLRiGLFY1BqtVy5Gc/rBf/fN7+D9R9e8OTLhss/bjj7yg32rWfoehNEaB5ph63FspV37E2U6L6rLz9ApwOWYUpi7vpPK79NRRyLFsdjk2jKUx13UZYD24tiJzmeRF5Ka5ACmVXoPJjHzdMEFEt9GXQUd6b4KpqmkauIVUysVnTesHYFK1dSiMer4KP96zONoxDH2hc8rxc8Wy94ebWgfBn1lBcOc7NB1xtomqhvxTHn/pJcOd/jSBxLhh+j0wELdIDJi8BttGL2heF3BSDZEX5vk6ySqz8459rQQn6tqPRKUUBZoovAUdx5xeayZP3EsrmMHOVCcTPFl0H8YBSxHiPaqkk+cph1U1BIEEUmip21tzTexm2ejS94tl7wbLWgWRZUKyhWil07aFw/QWxfLdQwlDLippiSpnAaYBG64F8LlDxPJDqUEo0UgcEgwixdw5tRyifQxW4LDFh5+t3aAJR5hS4q3HlFfVFQXxjqc6gvguhpForOcqCEjy08NoIGgsbUqGHjCwrv28jyxlua6PswoqxcydVmxvW6grXBrsGuFakzSzDP+8kXyjCDfw9QpqRUwqmAJVJPSdUst6VXU5yx07yUYsSxpKqdB3dX7fIuV2ZemjGfBc9sBEqzsLiFoZkJbib4ErQELRUtPBSKFB5TesrSUZYNpXVYo1TWsShrFkVNZYKfY+O7x1CYIJoSNd7QNBZxYZsvBE1J6W0qqdmvcwxTTceCixMSqE4ELNJfzdCy2F4bLGO6QrR9LSzyifO6HQ7YWXEYuVRyh1uLVFWbce/OSpqzArewNHODm4Ev46dQtAxmsik8xipl1VAWjlnZUFlHaR0z23BWbLgo1wCsXMnGBdFTmKDYepGoywjOG5wT8AICakELA0X0+zhP3tNmmDTeq6Acy8VJvqx93t5IJwIWtq2ZFMOITrG2hZhIB5JdlKckjKURpJWW5+JmxWxtKaiJgCwLfGXxs1C/4yoJQTwbPybEaZBO7JRVw6xsWFQ186JhZhsq46hsw9zWLGxN4y0bURq1FJGNGtHATaIivG4szabA1JA8/Sk1VFLCtvbLYEerDMZqvIdK7YHQyGmAReh3P4A2FVCIukhbPjEwcSXjBoyYiNAXaW2mGDEflTbG0znpMm9fxu7VpP3T9YnlGYJ4DQ9NAljmVc15VXNRrbko11TGsbA1pQnndlHUGLRVdCHoMitXcl1XPFvOubmZoTcFdinYtWIaRRrt7r3lCN2Yd6Ub5FbPTpG/h04DLEiX6ZU6A+RJz9Yiu9zS0XPZc84NzcS8xUaKOEOrAIeVmBTlWNTeDk1iJWCo3Wkj1REo4sKQxXfHWOtZlA1PZiuelCveqJYszIaZaTCiLF3JlZu1pnLSU9Jn2ZS8XM+4Xs5wNwX22lDcRLBsFHGZjtYCXUbFzNZM5yBJc+RcP060g04ELHtITJDJUQHbZQr3itCTspbyYVPxd9461PuWI/Xc/G0pbeheoIVFrUVtKOrSdGrt/qbv0ZuIMZ7SOioTxE8h3bKt1bL2JRtfsIz6SqO2BUrtLc9Xc66WMzarEllZzFp6YkhNFMVFgaiiamJMzI/mpex0J2ShgdGy4AEdBIuI/AzwA8A3VPXPxG1vAv8K+ATwB8DfUtV3428/BvwwYfh/T1V/+dA1gM4DmceBIAsiZpwir4FpWXCqSsxZM9D2acmAMrxmXsoppvWr6Czlz1p8aaIlIi3jkR1zKwTdw6uh9palq1iL58rNaLwNIPGWlSupnWXtChpvcCpsGsvNasZmVQTxsw6lH+LDiX0ZqxGrIpT8xuspTezH10/uGuuvG0Ib8SZsBzRhZCFmNCWK9C+A7xts+wzwq6r6XcCvxv8jIp8itDH90/GY/zn28T9AUQbnQEkOp0wXGW3qlxKRbFRG80y2XSUa6aqp1UT7CcAMDrjwSW0ufCnhQUXlsj2HZFKrVW+0p4OsveW6CW77dzcLXtRzXm7mXNcVV3XF9abi5WrGy+Wcq5s562WJvykwK4PZRK7iw3V8IbjSoGXoskDq35JZfFtzlQCTPlnLNaB1ERwynw+CRVV/DXhnsPnTwM/G7z8L/I1s+8+r6lpVfx/4EqGP/2GaUHObWl205LO2X91OYXuakGwCWxEz1m0hp7wiwEo7NlFt68bCQxN8BX6muIVH5o5qVjOv6mD92CbmzQaH26opWbmSZRMU2OtNxXJTsqoL1puC9aqkXhXo0iJrE8TPRhBHy1nUCloYfGlCS44iFq4ZExeN7RZK1Me6uTX0ErvSAnGdSN5Ht9VZPqSqXw3PRr8qIt8Rt38U+A/Zfl+J2w6Q9EVFMmPH+sWmh9xmeqU+FtJxJhcj1haCSRUnDrsNxmG5hHrUS1Aik8WRcJXUHQuuDJFlNwM3V3ThmJ1tuFiseVKtOSs2VNHySfpIE8XSqilY1QW1szgXnG6usbiNgbVFNoJZG0wDpgbTkJXGRMdcadCZRXwRk7Fc0FnS3LU0aASdOmelnBzY7+nO6L4V3LErjsK117vfXPR/HFvpw1KN3HLJ2WfsPyfQCwW0eSjDKPJwktpC8uiazy0ggnLpi8BRElDcwmPPGp6cr3hzccOTasVlEZxunqC0hiELjTfUzrJpigASJ3hvOqCsO9FjNhIA04A4DdI6mu5qpM8lkt8lgTvzeCdnZS6aNM5V+13Ntpgf0G3B8nUR+UjkKh8BvhG3H+zZ3w42791fflB7IqVXdE4vwLjzhnITMmUxZ+Wr4Vy2Y7ejbU0zs7nlKtFstuHjywSSULjuZgoLx9nZmg+chSy4c7thYTd4Fda+ZC1F4C62xnnDynRxIlRQL9CYUM8cLR9Tp79gNh2HafNua49sGqjDR+t6Z8ysTeXo5j7j0J11uF8ITVNwx+gXgb8Tv/8d4P/Itv+giMxi3/7vAv6fg2dTDTfcNGjdoHkdS5K7w5KP9IEuRtJLG8yUV585sKBNpko6kEZupGnfLDinRtAiKLcufWZCMydmwnnKecMbixUfPXvOR+fP+PDsOd9RveB95Q1PiiULu+G82DC3DbOiYWYdhXWYmNOiXkIC9kYCMDaCZECxaw2tNhoNQHGK2Thk0yDrDbrZhKY+PmvvkWjgwu/luORKbd59YgdNMZ1/DvjLwAdE5CvAPwF+EvgFEflh4A+BvxkH8jkR+QXgd4AG+FHVaQ1ARl+hMlRQoQNFXv+S9yChMxnbgvrWWyv9a+2jxOKjSz1wlywWVIKrFGae+WLDG/MlH6xe8qHyBaU0lOJYmZJyyztbYI3Hmi5tAS+IE6SRlqOIC2CxmwCUYqWYWrFrT3HjMOsGWUWQbOrYR1i6tNEhaAalNsl5KX6HnjBCB8Giqj+046e/smP/nwB+YuL1I0nb3ms0CAZbSmg4bETcxH1bJ1PqDoXrgyxcIJ4ncq5kQppgLal0PpVUo9PGgwpFK8XOHGdVzUWx5sxumJmac7OmlIa5hpzaUlwUSUVrVicAeRXURYvHgTQdUHLOUtwEkBQ3NeZmgyw3gRv3XhSxQ1DkSV55n7ye2Hpdkp+E1nqRTJ9Q5/qK2ZCjJMpjGxIfeEqr1NR9qfPy5s1v1DmkKGKng6rrSVfYNtCYlEpvMw5TBMCUVcN5FcTMzNTMZcNcAmAcwlxCbu3KlzxrzjpdpR26QBO4SjKRk1JrasVulCJyk/LFGvP8BoncRBtH2627ncs4V3lGf5vLkqV0xH1a/eW1SqscsM68jHQ0fxa6SeqtEM9og+IhxebD3fVN5/1N7n0TXPwYtoKI0pOWwtpbrtycM7NptzukLWy/8VWbTrluCtZ1wWZj8RuLbIIFZDcSdJNNAIqpQ7cns4k6yiqKnrqOL4sYONeGOUBb99wXRdCJ99crrXI0rzZucy5wAhvriVN2265eKcOocZ5emMh1XKbNt4VOVzEGiuDi90UUR0oMGsa/jVDXlqv1jLeLC2bGsfIlT+2SM7vGq2HlQ9Dwrc0l724WvNzMuFpXLNclzapElha7NBQrwa7ArjqgFOugp4jTwHGhA/QYDcUx0Cur2WVttvO2n04HLNC/mawBcS+inOWytM39Mg/l2MsbepHoXAlOoBhSfCDJXE5N/kSDmBQnmEaQjeBWBddVRWEXbUT5ZTnn3K6p1bYBw3fXZ7ysQzXhzapisyzRpQ2pB0vBLolg0cBNogiyax8A40fKVAemcuA2nfNy1M2QUjSGov0VOOVuT7muMuiv0iZr502V0/8H/pe9kdOh2IrH99qKxaw8EcHcFJRGEAXTGERNq7OEj1BLwdItqDcFq03Js9miTZv0Km2g8KYug2t/WdHcFMiNpbwx2BuhWEJxA8WNUi77ILFrh2w8ZtUEq6dxQalNukpyF6T6p11zG+8/Kf090f5a1TqnsfpBK1CgTaXMxUjiDil4CK0eI4NeI9st0weiKxdB6tEmJUL7kJBWO8xmRnNRgRYk11TIZQm+kWYtNGvDs7Xlej7DFp6iiK5+Hzy09abArW1IvL6ylNdR7CyDWVwsoVh6yhuPXXnM2sUsfo/UDtnUyGqDJn/KlgMueqizfNxeSqWYfopq6iKhE/S7SKcBFuhQP4wDpQhq7jyCTqzkjjmN/vBcH0mUVwDA+O+GrvoxOgelbjDOU6QUxhBHQLxgGsWuJH4s9UpoFgW1VSjyPGBB6hAYtGuhuBLKayiW2mbsFyuNprHDrhpkWSN1qAcS56Ontg6Vhz29Iyr0RkivDBzt4mn6Yr1NJhvG3PbQ6YAF+r6WvOhdFRlzz48pe3ki1HBf6HI2xlhv5r0NvU0iJU7jPKY2mEJDOVMNpSjuWqhXgl2lJG7FF7aLlGkyhUMP2+IGiusIkLVSLD126YMPZVmHUo+6CX352yStuJhS/kl6f2N6+0hPp+/8Ve3iSElRqUy3nRfTb0a4h04HLFmHA4m6Q/tCqkHcouu+ZPtBwUTDGpmx8lbZFR+iz91SeoILua+m9iFtRiU40LyiRiiWIfXRzQgJ3SXR5I6XrYPDza6jyFkpxSqInOLGYZc15nqN3Kx6gcz0hrf2oae2Go5OnKRxJ2uRICZ16L43ples13atjPkwDxVIfFiKGeut/E1xntx6yfI12hduJtpVT5RzIkM/xWHsbV5JLIZC5aC/RBPaNILZeMwmjMuuLMUqlIj4UkO/fUOIEEvnaLObBBLFrlzQTZY1chOAoqtVu8q7TLeBqZv0tzYJPQI71WYD2ya06YtzCNw6xock5brsodMDy6D5cXpz194+IolD5B7LMa6SkyTHSbhWL80hs460aZB1mEhjQFwEiBGkiZFfEfBV8L5uFF/FrLpsoQagRAtnGfWSdSZy1nWIHKdGQSrocNytVRN1stRFIg9XDB1vY2Km5SBd4LVdkHvotMCyp/lxj4a6Sn6jyQk1SKDq0dT2Yc5BE64lJijQss4ssMYhjQtiqPGYusTOijZft72cB1N7TO2QtcOsNtETG7ofqPdBZKS2GW2OzsBdn7+vOubnCLJlEfZuNU9AH5vHdgp1XCRndDpgGTjjUkyodZ7llGT6IDO/V646PHfqCWugbf+Zvzlk2H6jdQpG7gJB4TQZWFQDYGLtkvEeWTWY0kKR7aOhPrnHRTab7uGnexpWSkYx1v5/eE/7KOX1bC2skdjaUOfbQacDFjLNPSmYQ2ccdJZK4iTSsd1ew73hBKT926q+OIH5G8VyH0zeckM1tLeArv55mDykGl5DZ4PI0kHVpDSx84H3XT+VXtQbwPZFae4sHNLQeWmSFZhqVQxSmHb8vdcUx9+3CvteG86SaJiikCcb5yEA4qIbc1dvpWVue4XRgYwfK9BKNcAuPGDdbJDUHqwYTF3T9I+DVkkFgngdtjyL+4RjpFO6h+kYI+JlK//HuVDikZTWtHDSNQexNEnW4FSRzImBpSdyxmIbwxZeubNp9IRZHkeLEdMdD+1q6yVEJaUxvXIlv2Y6ZvjG05ySmBsmFo2mDSjtXvmLJ7Zyg/v32aZSkC2qXcr8SNC1yxVyk+JCcEpgaRU2u73C891yt/9QzifdY8jGVVq/Sq+MKXae7K3S5OGMllh6d2B4OFX/WAhiLa9fSr/tYu352FR7Sn27S3priaEDLfS5UqpekD2lYerbMg91gyx/aLeNvmllhE4HLInGkosjjUWPezQs6wB6Re+tPJfWsTWaYulDVwRJ7zVMwbr0zh6vWUNEuurIOP7UAbPTZ0aUSjGdHpGLk7a+aWRucs6U+Uy2gqhpv6EX9450OmAZPPxdb/Zo980fHnQrLommYUuN3O/SPhgTe71kky3SKa/pBZ0Dj3AbuY37SBJXwjYnGbtHb8A37XgkIiNPUt8qw83v08Tr5aUc8X56FPUgKYrxxbXH5B6j0wHLGOUWD5mcNdkqTuUd+RvL8iTttMLH9IF0fEq3hL6vxw5EhhGoIyfI2bpXYrLL4XuKY231DGvbJs6Scw7ohygit+rpGsOHbLRvJqe5KzLxmOtaeXbihDSFEwHLiEs7p7FMN+i77mPLjNFIcq7b5FHadI58zl2myCZ2n/bLzOQ2cpt0m4Ey3B9nX2z2ckqA9qURbQgi7bjbEuqlmbb3a9gq7unpeCYAKm0XE7nhpAKMEwGLDs1kCVHS3I2dTNVc/ubf23LVjNpkpq43SyhhzQAzlPNJGYTgtR3OflyRvTarYxUESX/KuUSWpderSR4TEakpYirBzai3IIZicmgiJ1GTtyFp5y8Tba+bU26MRKR92RPs8Ffk8j13jUeOlSdUjXp5h0BJ4i9FeAesXaztJ2m1nAba1AHvoy+HrFER3Xhht67QRsPdVqxn252QWWG+6Sc4AUqJyDiHSmNv5+AAnQxYhn6CtqneRB9Av4YoUtYRqqXk0Evezriy20lOlOsj+TynfjB5g+WMRovloNM77GBbd+D4ffmBLmQGXGVr/x0cYoxzpAX3Wjnl8tB5OxnRGxkrDltfxJgXNG2H/gTkkevc4eYc2vonbMu+Nb5dI6VytucdOsly8z421BlGesNtDZxku4CvA64zTJ3QAUCGuoz6/t9WzGWOzTEwTsy9TXQiYGE74DVU9pISNpYtlygBYRC57qUaZqBICmaqd25d5imJKCnGQ6U4v3brzOryYkfffRR+6Lvg91GvbGVg+QyDgEMlHro2GrvSHBJN5CpwKmCBbZMvUduHZbANaCPJYWMm68dOHxOJ2uRv02WVpZU4LA0ZxmhyoyE9iIEu0rOec6C1Y2yy37Lr5hbTmFXUXlO2OWsuSsbalQ7HeUs6HbDkNJSlu9C/Axxjr5Npt5ugMPdXvQ2Wz1aKgHTKaUrzzJOJ9lT9tdbIltKbORvLsu1k0O+YmTzOcRytRZU4haddHCP33msKkKy0YWpputfXr25owJ79CJcYu5nRMP2IP4bMNM8TgdL1jIDEqRgqutnxnZU0EANpfLtSGuP4dPBOIDEOKEmtvARCKmYeLkgPdt/DHCyYvPGgQv8lGblD8rXUWXbRDoDAIN4xeAH4aGwpz4PJlb7Wn5FMb20dfO311Ldg7FHqJpW+D6hf6xSTpfutsElxph4NOUb7YBPXSee1nagbzE84zvTnJGEmpl2M1orvodMBS0pAHiboJMqTk8bMw+xBbmW159wn98S2TQqz2E6rv8RxDF+QPQaYkXsZvjRLLG29dntoiijXm85HtM96iSZ+rzVI28ayL5by4GLfidf3cB8TZDwdsHjtx3CGlFZx3hQ4T1aW7XqjnZQlhfecdPm1x8A5poSPcr/Mn5K52kPqwdDvk8RYsriG50qOvx3Kex5VH7aSpxNJLTCzpkbH0mmARXWk0m5E90gTbk2/CDxSW+ubREYGpF2ZdL2EpmSCjqVY5vsn7+rQhd4qkPT9Ptl1x6Lpe5PTByBplev0WzcwoNNxhhyjFUUSxVlUardee7yHTgYsmqUlbrHNPHQfl2ycmm7/TGFrg3zJTLa2U0qdpxf1zRXTZPUkbjL2UoTc0tGoCGRhhm7splOKc/0AtktbhmMYmMhtrKosOoAmHSZ39xvtM5bBG0BUNehsAwfjVgB2B50GWMZolzMpi6v0+vUnN/yYm334f5X+S6vGFL0Jtb+91ITotNMBJ9k+ZkTM7mzvJZ0ut2s8WykJA1E0BHwa19QwSkYHZ0REPi4i/05EPi8inxORvx+3vykivyIiX4x/35cd82Mi8iUR+YKI/LWDo5BwM+mTXbzzyqaM+LyV+JioGqOUx5GsjtS+PI8QDyK1bbQ21vRs1dWk2uNU75OPr60B6oO3BVJy/uX3m+5l6MkWg5RFt1+6/xSJb10OfZ9U3uGzVYjzSHe0wjTPbzkwlxOWDw3wD1X1vwH+PPCjEnr032P/fuluZIxyp9jQWhKze2WazGXvst5r1vYcc60Ty/fPu7/QzXRAqptM3Gjnq8mBPeRa6W2yu3J0EuUPOpnZ0SvbJmeFm9jivp0IjmJ46P4fcrkDGXMHwaKqX1XV34zfXwKfJ7RY/zT31b9f6CblAMLbFb7Taur65oY73OGr2fUQ8xU+moglLeeR9A6A/Lh0zSGIzWBcvZvyGagj4MYUTpNxIs04m2aLoY1nZePx2fnS2EzIyektiANxoqN0FhH5BPBngf/IvfbvjysgOciG7uecNQ9fEp5PiAn5rKNv60qUQv7ZSjzIQdI+2UQnEdkVu2Uueejyf1vrJ5j+W5mXLVg7f05XwL5Htxgqz7sca6NVCNFQSKb8vuPzqTi4RyQRuQD+NfAPVPXFvl3Hhjxyvh8Rkd8Qkd/Y6LIL549FSqFbkXHV7VQkTab7bLH4zCIa404j1x4FUh54TBwkB3QuHseSlUaoFYNJP8p8Qb3x5wHMDChJlI6awLn4SuNPn6Eo3kOTOIuIlASg/EtV/Tdx853692uvd/93qA5XSOveZjBh2WSnrtLDfXbR0OrZJWqyMeRNcdq8V0fHmdqXamUAyiv9xtzqW/6jkbybNN5h8G8s2793rqxfnLV9hXcP5Q2AdtEUa0iAfw58XlV/KvvpF7m3/v0aLIdegpPvu9vzkpDsNShax37/YytjBEDBAsismx4XGEkLyF7qpDlA0rsG0qflVunjW0U3WR298eXXi6AVGdEjchqCewQo5HOVrtNaWX3u3HLYtOsBQE3hLH8B+NvAfxaRz8Zt/5j77N+vHOwNAuxQDjWs5ujk2kr8zuk2OR1ZR8xwub753KPE6cSQvKRbQG/Pmzhi5ufZZw2aIzjoFMrF8H0FElX13zOuh8B99u/fqoHpK5GjtzMCnh5Q0qrKxEWnPMZ9dLAK8++pLdyYlTBw5vVzSLqH25XBDsaVaHju4W9JNA8Tr9LfHQ+69dbmlCdiTUkBGdBpenCjC1ts1wRZBvGOYc1zPzIcH0gbR3FtqWoPLMNYVH58uEjmhnfdCs9c+uE8od1GClmotVsv5d5KPorjbv/m4E7kTedfasdm+hHtYSu0gdWYjglzCHnf/mNpsjX0WlLSHXITuXVi+TbusuW7GY3uDvSFMYtNBoDreWVzZ1jfktvyDqd9xjharjttWXOdPjc8pndcpC0974BT7jQ5C4B36CCTP9fYh0lO6fdwrMLwZd75gx7WCKl2r6/tlbkCZNHjxAFUw/aB6brV+n2ojA5zh9VvJYq3IY48N8Vud5bop012957GsfctH0fmsSQ6HbDkZmKL/m2HUT4pu2643V5HPSXPdM8fbmqQDP2WEznY9hVnqQ+ufuiA0l5rqAPkIsdngIkdGUzSgUY4kJH2PUHD5C81eRwrF8VdbCtP/tr59o8JxfGnJYaGyUeHyhSSWXvotKOOKt//PXuD/CTK9+2lUEQamuNDBTI3zXecf+/qHwsJGDlo/t6F5Dbs6N4HIfIWcA28/arHcgR9gG/N8f4pVf3g2A8nARYAEfkNVf1zr3ocU+nbcbynJYYe6aTpESyPNJlOCSw//aoHcCR92433ZHSWRzp9OiXO8kgnTo9geaTJ9MrBIiLfF6sAviQin3nV4wEQkZ8RkW+IyG9n2+6vmuH+x/vwFRjQuc1fxYeQBfpl4DuBCvgt4FOvckxxXH8J+G7gt7Nt/wz4TPz+GeCfxu+fiuOeAZ+M92Pf4/F+BPju+P0S+N04rnsd86vmLN8DfElVf09VN8DPE6oDXimp6q8B7ww2f5r7qma4Z9L3ogKDVy+GPgr8Ufb/CZUAr4x61QxAXs1wMvewrwKDO475VYNlUiXAidPJ3MN9V2AM6VWDZVIlwInQ12MVA7epZnho2leBEX+/85hfNVh+HfguEfmkiFSEstdffMVj2kX3WM1wv/TeVGDwaq2hqJl/P0F7/zLw4696PHFMPwd8FagJq/CHgfcTarq/GP++me3/43H8XwD++isY718kiJH/BHw2fr7/vsf86O5/pMn0YGLoFJ1tj3Q3ehDOElts/C7wVwls/NeBH1LV37n3iz3Se0YPxVlO0tn2SHejh8ruH3P6fG++g4j8CPAjABb7357x5IGG8kjH0EvefVt35OA+FFgOOn0066LwRN7U7zX/Xfph5GxHZKxPEatjvWb39Z8dG0fab2xsw3Psu96+444Z265zTjkuo3+r//t/2fXbQ4mhV+OoOvSg02e4766mwre5zth1d50jfe56rtuMa8r5BvRQYLm9s22r++KEyT520m+j1B8zsUNg3mVMY/Oxt2/uxLloGw9NH+eDiCFVbUTk7wK/TEhD+BlV/dzkExyajFMi1aNX6Og57pvSuKaeu+W4u3d5sPJVVf0l4JfueJL9D2L4220nfaqeMrbt0EoeE3HH6B679J8p57pnEL7q2NA2DcVKfsOHFMRd29pi8z1K6UPRVIV9qugagvNYMbXr+hPodMAyRdYee5PHcKX7uN5DnOMhgH0bPY9T6qJwjHzdRcPjp4BvF5u/K93GND50rimc8dg5PELnOh2wTKVcpOyT7buOnbLtrnSfQLnteceO2bXvRMCcjhiCaU6lu3Cf+1T4bsHG7+26r4hOCyxw2K9yaL9DdEt5vXWOY+kuHGyf0j/l2Hva7/UTQ7tol84z1Vy9T7qL1XXMw516/qn7Hrj2tw5YYBswh3wcx8Ri7gN0+85x2/MeE5u64z2cnhi6KwcYTsyu3w+NYcyyOkZJnWq2H3veKfQt72e5T3qgydp7rmODkcee/wToWxMsD+Hgm3KOY4OHh+iQ7rNPWT/WrTCBvrV0FhjXSfaJpGP8NXexwA6Jxangvq2v5B5CHacNltt4de/DE/wQtO8hH0N3vb87HHs6YNmF/F2Tc2i1DjnMPqvhNi7ysWvuottYIXcVIw+wYE4HLLehYwCTH3PXa04Zy9jYpnKFuwY5H4iznp6Cu2vVTgkFHDrvQwHlmP3zVIT78OpOueY90Wlyln0iabhP+n5CJmaPDo1tjNsMjzlGhD6gznZ6nCWnu8RA7it+M5UD7NMx3muFe5dJf8cFddpggeO8mzlrvq9Eqani6z7CAGPXva2oOeTJvgWdPljg+EhxDpj7dpSNUW7tTDWRHyLFYZ/Y3rdtIr0eYDlluusKfmiudY90OgruFL/CMb6HY5Xe+8xROdavcl+AeWBF/3TAcojukhuSi6L7TAU4tM8u5+ChkMJ9eWgPpS8cOSfffmJoilzft/2uNEUBf0hd6w7nfn04yzFWzl1TFI7RQ3YlGk09/1Qfy0PqLRO52elwlqkWz0NbEVNX3EN6UO/r/u55nk4HLInug/0ea2qn60497779T82TPHUeJsz7aYmhuzrSjo1OH0PHRpqH+9wlrjTFX/IemNenw1mmKp63oWPDBvclSg498Hz7MMA4VESnAvMB3QWnxVmGNNWMvO2q3Wfq7hM3U7nV1BSFFhAGSS8rb6/l0fS2+Sk5M2PXuaeFd9pggf1s/JDzbujjGDv+0ESOgSZxjakPb9J2077Zvn3zPKBNA77ZP7ax8069ryPE9OmDJdFU2X/sKpoyWVPPKSNSPX/rffxdjPT3zwCSAIO13RvpvaJucK5XQK8PWB6SDnlUJ2wTa8PDN9lvXkEF9dqKF7EmAMHE7xCOi9tbrmIM+AAObRpwd7nB+6HXDyzHuMNv4zq/jXwXE4BQFuF4E0HgHOocggtAKIoAqrKAokCMCfuaCDJjQAS1cZtz0DTI2qL1iCgaRrv3cd+p+tMeOh2wTJWdt3n4x1pDo9wkUz6T2ID2AUtVQVV2ABAJYGkceAfGIoWFooDCovGTLBiN55OBniUi423ejtXBbvtbRgfBIiI/A/wA8A1V/TNx25vAvwI+AfwB8LdU9d34248R3qLhgL+nqr98cBRHDvpoug1gcjJBl5CyiHpFEiVRITUGZhValWhZoIVBjUGcQ2oHzkNh8YVBrYXCoFZQk4AC4jV8Go/UDmk8eE9qly9Got5yZLR9LJA55Z5HaApn+RfA/wT8r9m2zwC/qqo/GV/i8BngH4nIpwhtTP808F8B/1ZE/mtVvR+J+9COpx0TKUaQskCqEsqqzyFsAIDOS/yswFcWLQ3eCsYpUnvEKVoYfGnQIoBEhdbLpSKYRrFrh1k7jGoAjItm813v6Z7m7SBYVPXX4nv3cvo08Jfj958F/i/gH5G9qBH4fRFJL2r8v+880ocOpEEnapKimYkYOVsE7lEWUYSY8LEGLS1ubnEzgy8FhMA1tBMrvpDwsYTf4zWNU8RBsfJIIxgIXKVuYFND06DOTQfNA3p2b6uz9F7UKCL5ixr/Q7bfzhc15r3755wdd/VDeRpTjtmKFptW1EhRBCXURJGzmKNnc9x5hZY2cIZC8KUJAKiEZmZwlaAGxAeQeCuoBV8EsKgFbcECpgGzAbsG8UKxlCCGGo9sanRTRz+LdmbzXRyVU/xCe0593wru2Gh26Gf93v3h6Any9D4CeGJ6I5Wkh5QlUpVIWUJZQlmgZYE/m+EuKuqLIogRC94KvhR8Aa4S3AzcLHKLBvCCL8HPwFVEoChqiBwHTC3YVTif3XS6S8tV1muoa9QNpPghT/AxdMQxtwXL10XkI5Gr3N/LJccUsPt0W+deUms7cZMAkhTUskCrIuggs4LmzIbPQnBln1v4kvCpwM1AjSIKqOArxc0VP/NBP5Hgd5GNYGrBrCGwGSivg7IrtUPqBq0DV1E3wRF3TFrF2Pw+sAc3vajxJ9l+UeP/JiI/RVBwj3+55JT821uSGOlxEIqiA8m8QqsCLS2+svjK0CwszZmhmQnNXHAzaYHhi8gtCvCl4maKnylaaOBaosjMUy5qZrO6HUPTWFbXFe6mQFsOJ7gqjjHTV3Sz6eJCw7m57XwcWpB7aIrp/HMEZfYDIvIV4J8QQPILIvLDwB8CfzNcUz8nIr8A/A7QAD862RK6R619/PzRQ1pVMJshs+AX0Vn4+HmBmxf4yuAqg5sJzSIDSRXEiS8iWEptgeJnHmYeu2goCocxirWeedlwXm2YFzVGFCPKdV3xtj3nWuZ4LRBno/iJQFlvMq6STd1tnYv3mO87xRr6oR0//ZUd+/8E8BOTR5DTsbkfE1daEjlmNgtWzdmi5SSBiwRrxs8M9ZmhmRvcvNNFfBm4iC/BF4rGv36u6NxhzxoWiw1PFivOyhornsJ04sOIMrc1c1vzpFy126+aM+TKUqygvFGK6wa5XqLL1W6gDOfozqJ5OmBOx4Ob05QQ+1ju6ti+A47CYo6/mOPnZQeUmcHPgkVTnwv1ueDmUdQUSeQETqImfPelogtHdbHhyfmK959d85GzF1wWK0pxgYu4Gc82C1au4LzY8GZ5DYBHUBWWywp8SXEN1UuPfblGr2/w63Xn3r+NE+7YdIWJgDlNsMDt4zp5ZDcG7mQ+C860s2AC+7MKNy8CSCrTippmLjRnQnM2YsEEPTQAZaZo5TEzR1k6ZkXDRbnmabnkA+UVZ2bDzNTc+Irn5RlLV1IYTymOpSvxKjTe4DeW+bUwe+apntWY6yUuAeVQhPkYi+jbIp9lH8vdMVmtUy0F7aoSmc2CfrKYtUBpFhY/E1xlqBcBIM0iEztFAImmwLAPumhTgVYee95QlA0iSuMNjbd4FQzKhV3xfntFKQ127qm14Gv1U75av8E79TlvLS9493qBPCuZvQNnX68p37lBb5YheDim0CbKOcc+EHxbJj/ldDDhyHRASYG9qgr6yaxCFyXurIj6SXSkzQJQ6kuhWXScRA1gAjcRCOq6hm0ycyzO1ogoqkLtDI0aGrVY8ZybNR8sXvB+s+SpcVjgN6Xh6/VTnm/mPF/OWb6cUz03LL7pmX3tGvnmM/zVddBVjhU97xG9XmA5kA0m0X8iZRGAMp8FkFQlOrMhNhPjMsGpBs0c3DyYrm6mASBC62VFNHgVi7DNLxzVvGFeNjgvbJoC7w2NNzgVXGRFPv6tJLjw51JTSlBab1YV8m7gKtVzh7kKXEWbHRlxUxT/e4gqH6LXAyxT9JfIVbAhyBc4ygydl8FFXySgSHCaAa4U3Fxo5uArjX6TTkdJpEbRUqH0FGcN54s1i7JmWZfhPDlIEGq1bNSyUsu1d1gBp4Yzu8aIslmVzN4NXKV6tkGvl/j1Ooig28zDMEXyNukLE+h0wHLbnFZoA4AiwemWYjs6K/CLMgT7YjwnRH1BI2dJOkr4RKeaBRVFNGi1WijMHEUUP4uqprSOVVOgCt6bqLRaarW8dAueBfcsDsGiPPNnXLk5V/UMvSqYfxMWbzuK50v05maaUjtlLh7QV3U6YNlFUxW1xFmKkIXWuuxLG4J+Ngb+KsFVQr0IAcCWm6S/pYJVMEEfwQNWw4IleGA3TYEAzkvMXVKcN1y7irc2l1w1M75eP+HSrjgzGwA+f/MRvvD8O/iDr76fxR8XnH/NMXt7iby8wTcZULYCnPtF797fxtwL35KmM0y+WTHSpiW2XKUMQAkAyaPDyUyOHlmbmciFQqFI5ZAWLMnyUHxjaMSysmHavI9muihehVVT8rae4/UCr0JhPHNb03jLF9/9IG+/dUn1xxUXX1HO/3iJ/foz9OXLbfFzrH6xL7h6TAoqvKdR57vRMSw0S3NMmWsyq0LOyWKGLkq06gMleGSD1ePm0UyuUiBQIfpObOmwVvFeUC94FdR1350zbMS286oqbJzlZT3Db+Ys65J1XdB4E37bWJq3F8y/YTn/E+XijzcUX3+OPn8RHHA+0zmOna/3UCSdFlhgv+afJynluSfWgjXI+Rl6cYa7nHVOt7JLOvI2cJOk1LqFBrf+mUcXDrtoqKqGxWxDaT21M9TO0jSWprY4ZzBRO1YCZ3EucJdrKjaNpXaW1bKiWRbIjaW4NhQvhfN3YfGOZ/52zewb1531kwcKE91XwHDX/O3bZw+dHlgmUJvmGJ1tYkzQU87muMsZ9UWJT0CxEvNdU0pBzD1ZKM0C/KIDymKx4Xy24XK2pjSOtStYNQXLTcmKwEGSKaUqeC84F2xs54SNFNTrAr0qKF5Y5u8Ii28oi7cbqmcbihcrzIubEPu5WUafSl5XNCI2doUxdj3oqVH7W3Cd0wLLBA9tF+sJfhRmVciStzZ4ZxcFzbkNIqfqEpR8GQKDzRmBm8zAzz0669z2VdFQWUdpHJVxeA1gc0X0oziDRLAEoJhgCTUGdQKNwVxbZs8M1TNYvOU5/1pN9fXr4Eu5XuJXq7ZEhGPSJe9TpNzyXKcDlikxjSR+rG2DgrqYtfmwblHSzANQmoWhWQQXfrMInMRXikoKBAa3vVQOaz3WeoyAV6H2sXQ0Kqnp01gfuEv8TX3UZTYGWVnsjaF8LizeVs7e8szeqSnfvsG8+wJdr9H1Bt1sWtGjYyLoNkrp1N/2iabX3hoaULJ6kjs/xXp8LK1IbvwAFthcCs0F1Bced+Fh5qAx4KI4qTym9NjCY2JKgQK1i3GeyEWMKDbmqHgfIsYtV6ktbAz2ylC9EOZvKxdfdSz+5Br77nWIIl9dx6pCNw6Qe52kIxxvQ04Or4k1NNElHbLuBazBx3wUNRKdbAZXBtHTLITmHDZPPP7SUV6uKUvXKqsoiA0JSd4LdR3d9s5QFo7SBnPWq+C8iT4Vxfuo7DYG3RioTeAoV0L1HObPlOrdDfadK/TqBl2tQuL1UD+5qxJ7G/P6jtc8HbDAfmWutwpi1V+sxWlLK6ISGyweaM61BcrTixWLsmbVFKzrIgDAGZwTvDM4B3VtaaJ+UpvAXXwUO0YUIeoqG4uubJtLW9wI5RVUL5TqeUPxYhWAcnPTZbxNcbrtS3LadcyuORqjfSLutRVDEwaeuInaVLAVldmy86U0Fx1Q3lzcsChqVq5gXRUs65KbTYn3Ib/E1yboIGWwchqrOCeoD0qtLYJe45oAFHttQtL1hsBVXijzdx3Vu2vMixv89TV+td6fbjDlnneB6cj5utW1B3SaYJlAbamn1+B4Kw31wrC5EDZPoH7isU9r3rhccjlbMysaCuMo1KDq2Bi7XbeiBMtGBSeKumjlALWJLv+VxV4ZihvBLoXiBqqXyuKbjtk319hnwerpxXr2AeG2NUC3oTue53TAMnXiUocCVXChPhiJrvyFUF9C/VTxTxved3nDhy9eUpku9F+IxxvBxgTqHinQGDQ9ZxXExfiQhv8Xq1AMVtxA+VIDR3kWgFJ84wX64mU/h/au9T3HRpDvct4DdDpggcOAkdidIBaUp9JQtTHdYEZ0uHmKecNZVXNWhEBeSmUEKIwPim00f30jrZ8kgALEBaBIE797EAd2JRRLKG6U2XNl9sxFhfYaff4CvQ56CurvDpR9NAVE37Lu/kMlC9AVhxWx3rgMnQmCrhKUW2IuivfCzabk3dUZpQ0J1Cbahelv4wzNukDXBmkMNN1EiwezEUwNpgncxTRgV1BeKdWVUr3wlC9q7Ms1slzjY7npTkfbsRHf2/hFjoqvTfexwCmBZRdlE9y20opg8aXpzOVUS2wit3HCalPyvJgzLxpmtqG0jkI8RnzgNI0NQFkbzEaQJoBNrYIPQLErwTQxB7eB8lqpXiqzF47yRUPxco25XqLLZSgK2yd+JtxjS1P8IrflHPvSHl4LP8shSuZyTEVQExOaDCDSpkICUccYpFxG/aRRQxNjPs4Z8AEk0gRQQLC0xINdR85SBxFkXChiL9aKXXnsqkGWG1itQ23ylPzZ+6QHFDlj9HqAJdUopwY61oTE6ahfhIkK2UniBfGhW5K1nkVZsyhCgZdXw3VTcVOX3Kyr1tKBcK6gpwRgiA/gCDpL7HjQaPwtKtaN7+qSD6VEwjRRm/9/avLSrv3vmU4TLOnG48S0bn4bc1cyi0h8KEQXDQ+Y+FENjrTKuEyhhWVd8mI5Z70qg6s+O9Y0dJyk6cAYftMglmoNv3lFnOs6HowFBY/RCe7Dwpl6vVtWM54OWHatLGP7nKUoUGsQp5hlQynBMefKThkVJ7Ax3NzM+IYoZeGorKPxhpfLGaubCr8skNogawmKbFJmN2A3II3GPisZZ6mVYuWxq9ChSerQIFBV0eEDui/94jZ0CDT570cA5nTAso+iqYyxUMS2n43D1A3iHGVKmVzY8FAd+LWh0Ypna4spPcaEkg63LJCVxaxj24smWj2bDihmE7iIcQRQusRZlGLpKZYOs2qQdR1aYnjf9ayF462e29AU7jAFCEcA5nTBMpzYpNymG3MOWddI47CzErsosBttXfAWAytQa/Cl0hQhW9+spVVckx/FNAkkgXvY+DfpKeG8iqkjV7mpg2JbN6ETZVuKMaHkdOze8t/2Hbdrbu5K3zKms8ZVW9ewjj3emk6ZVGtawyc4zZTiOjbKMcGySe0xgMBRNpFrREebqcGutdVXTKPxk8DjsUuHWTeYdYOsamS9CWOqm8BZpqQdjHGDh4r3PACdHlhGJqmN2q5AnQ/5LLMqtPIypgWMcdFpZoJXN3WEDOmVgNAzhZMCazeKXYe/SeyIi9ykUezSYW82mJsNso4AqevWCtrSVybeF3DYx3Ks0rtPPH3LxIZgtwsbT9sSyHkoXZsEBSCqmPhwi1UAgZoMLLGlF9LpI5IxAhtFj9341tIJOorHbDxmVWOu1sjNKoCkacD5NqEJr8e1IN2lJ9zVhZ//lh93T1zqtMBygEIPfB9anKdW5XWDWdbYIokj24IFAmBCW9FgYgcuEiyd5NDrwBE/G4/ZOMyywaxrZLmG1Rpdrbv8WdV+Hm3eTfLeb3ziw34AbpLT6YDl0IqJE6FeEdFghbjgFJNVjU2+FwBs8OYmX53RwFk09JstlkEPSvkw4cSBo9h1BMlNjblZhcBg7Jmim7oFRVfrs0NXOdZvctuHehv/zC0ts9MByxRST/valchZqGNsJ+4S/CJKzL4Oh1lpJ8iug5s+bI8dr5PzTxV70wTd5CaWa9yEmE/OUXbSWE7rwXu6w8o/dI33OuosIh8ntGL/MME/+tOq+j/ee//+Y9Cusa/9JqQfCFFv0eBVNetifCK9b5sSA22PfUx3fXOzQa5CYDB1jJxcsjHVHT/VTD5GKR4by9Tf7jGQ2AD/UFV/U0Qugf9XRH4F+B94Ff37iSLADfJFVJHGhc7U2ds2gACS5DxLJOEFDWpNt68qslyjV9chiuz8dqL1rQas/fHk23OaEh+acq1j6D49uLHtemq9/lJEPk9osf5p3uv+/dCJIvXguoUgzoU3bgxf8gRRhPjgQOuVwBryHv2ohmz89brLS9mVkT95vEf4UcY400OFCh46uz++8OHPAv+RO/bvH+3dv8vU21qRHk0dDAgiQk3Te/CavynMd5YL0N8nO7eqBmDVA6Ac87D2mcXHiI/7tqru4XyTwSIiF8C/Bv6Bqr6Q3Rcf+2Frtkd793cXSzvtHlCyShykd8Lle4u1oYN1VHS364r77ys8aN3cJx0bhb6Nv+QBLLFJYBGRkgCUf6mq/yZufpj+/VPpgFWiziGWIKoSl+gdk0xgMy2mcxuv6kNZOocU6WPoiDEefAm4BBbyz4HPq+pPZT+l/v2w3b//B0VkJiKf5Db9+7uLh7+q258JpEOH2fC80Bc1+86dFNT7AMoha+iu1s4D0RTO8heAvw38ZxH5bNz2j3mI/v1jdKyCN6LfnEywbp9omQKQ4VzcNWHqyPufYg39e8b1EHiI/v1jdBeLYGe86cAxY9ec+oBvazU9RKjgHs//+nhw9zmr7pLvsQuIU7YdE+SbMr5D9zWkY0XiHQFzUGc5OTp2QvP9HjLIN3VcQ0X5tmN6SC60g14fzrJvNY45svYdM+W8Q9p3ztsA+FCO7r4I8iFLaeoYxq51R3f/q6e7KqJ3WYW3nfT0//tQoqfoWLelI+7v9RND7yW9Alb/IHRP9yGTUgIfmETkLeAaePtVj+UI+gDfmuP9U6r6wbEfTgIsACLyG6r65171OKbSt+N4H8XQI02mR7A80mQ6JbD89KsewJH0bTfek9FZHun06ZQ4yyOdOL1ysIjI94nIF0TkSzGX95WTiPyMiHxDRH472/amiPyKiHwx/n1f9tuPxfF/QUT+2isY78dF5N+JyOdF5HMi8vcfZMypXcSr+AAW+DLwnUAF/BbwqVc5pjiuvwR8N/Db2bZ/Bnwmfv8M8E/j90/Fcc+AT8b7se/xeD8CfHf8fgn8bhzXvY75VXOW7wG+pKq/p6ob4OcJCd+vlFT114B3Bps/TUhMJ/79G9n2n1fVtar+PpAS1N8zUtWvqupvxu8vgTyp/t7G/KrB8lHgj7L/jyZ3nwj1EtSBPEH9ZO5hX1I9dxzzqwbLpOTuE6eTuYdhUv2+XUe2HRzzqwbLe5PcfT/09ZiYzitJUD9A+5Lq4+93HvOrBsuvA98lIp8UkYpQyfiLr3hMu+jhE9RvSe9ZUv0JWB7fT9Devwz8+KseTxzTzxGqMGvCKvxh4P3ArwJfjH/fzPb/8Tj+LwB//RWM9y8SxMh/Aj4bP99/32N+9OA+0mR61WLokV4jegTLI02mR7A80mR6BMsjTaZHsDzSZHoEyyNNpkewPNJkegTLI02m/x+qT4JfZPiLxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAD8CAYAAABHPleGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgHUlEQVR4nO2dS4gs2Xnnf9+JRz7qcZ8tqyULqc20Z9SeGbCmkQQ2xmCM2mJA3niwBowXgt7IjA1e+MpaeCWQvfBq8KLBjTVgJIuxYXohEJbwIARjTzdGtrrV0w89LLX7dt++fR9Vt6oy4/XNIiLrRmVFRJ7IjKyMuvf8IKmsiMgTJyL+8Z3vfOeLE6KqOBw2mE1XwHF+cGJxWOPE4rDGicVhjROLwxonFoc1axOLiDwlIq+IyOsicm1d+3GcHbKOOIuIeMCrwK8CbwDPA59W1e91vjPHmbEuy/JR4HVV/YGqRsBXgE+taV+OM8JfU7nvB35S+v8N4GN1G4cy0CFba6qKow373L6pqo9UrVuXWKRi2Yn2TkSeBp4GGDLmY/Ira6qKow3f0P/5L3Xr1tUMvQF8oPT/TwNvljdQ1WdU9UlVfTJgsKZqOLpkXWJ5HnhcRB4TkRD4TeC5Ne3LcUaspRlS1UREfgf4OuABz6rqS+vYl+PsWJfPgqp+Dfjausp3nD0uguuwxonFYY0Ti8MaJxaHNU4sDmucWBzWOLE4rHFicVjjxOKwxonFYY0Ti8MaJxaHNU4sDmucWBzWOLE4rHFicVjjxOKwxonFYY0Ti8MaJxaHNU4sDmucWBzWOLE4rFnbc0OOGmTuMfBzNLWsE8tZMROJmOKPoJkC2bkRjGuGzhIxiBHE846/z8RzHnCWZd1ILgjxPCTwTzZDaQpphur5sC5OLOtECivieYjvI2EInrkvjDiBKEJTw3lojpxY1kUhFPF9CAJkECJBAL6fiyJNURFQRdIMTaHvgnFi6ZpZs2MEGQyQ4SC3KIMQDQPwPUhSJElzq1MIB8gFk6umlzixrAHxPMQzuVBGI3Q0QAchOvRRI0icIXGaC2omliwDzdBs07Wvx4mlS0QQP8hFMgiRrTG6PSYbh6QDj2zgAWCiDDNNMICkGUQhpFn+6TFOLF1hvNyiDAeY7S10e0y6PSLdDYm3fLJQyHwBBf8ow/cFUdA4QXwPPIOaqnkb+4MTSxfMnNnAR4ZDdGeL7MKY6EJIvOsTj3OhZB6YFNTLRSFxhgx8JAwgjhER+uveOrGszkwowwEyHMKFbdLLW0wvDYgueEQ7QjyW48leTQwomMTgTT00yLvWxx/jQU/jLgvDhyLyrIjcEJEXS8sui8jfishrxd9LpXWfK+brf0VEPrGuiveCmVDCELM1LoSyzfTKgKOrPkdXDJMrwvQyRLuQjCEdQhZCGgpZYNDAQ30PMUXgrojunhpD6gE2sea/AJ6aW3YN+KaqPg58s/gfEXmCfBrTnyt+82fFPP4PJmLygFsYwGiYNz2XBhxd9plcESZXYHpZiS6nxLsZyZaSDiAdCGkgZIGgnsm7075fWBbJhwF6yEKxqOq3gFtziz8FfKn4/iXg10vLv6KqU1X9IfA6+Tz+DxYiuUMb+JjBANnaItsdE18YMr3kM7ksTK4o0ysZyZUYczkivZgQ7+SCSUaQhpAFhXUxJo/segaR/o4XLeuz/JSqXgdQ1esi8p5i+fuBvy9t90ax7IFDjBTBtgE6HpLsDIgu+kwuFc3O1RRvN2a8NWEcxuwNhkz8AbEGeBPJm6Kg6CH5BozJRWJMb7vQXTu4C+fsP95wbu7+c8Pszi+aHxkPybaGxDsB0x1DdEGILmaElydc3j3gyuiQ7WDKW/4u74hyGBvSoZCGgnqKepJ/jEC5+RHTu2jusmJ5W0QeLazKo8CNYvnCOftnqOozwDMAu3K5f65/HWLyLnIY5t3k8ZBkOyTe8Yh2hWhX4ULM1Qv3eP/2Xd43usu2N8WgxJlhOglJQx/1QGcpLmkxPpRpHskF+hjKXbZxfA747eL7bwP/q7T8N0VkICKPAY8D/3e1KvaI0uCghAEMQrJxSLIdEG0L8Q4kuxlbF4744M5tfnb7Bv9udJ0Pj97kQ+N3+anxPsNRRBYq6gECouQCyTLIUlS1l0IBC8siIl8Gfhm4KiJvAH8EfBH4qoh8Bvgx8BsAqvqSiHwV+B6QAJ9V7ZktXRUzC8AF6CAgGwYkI0MyEpKxouOUC6MJjw7v8tPhLT4U3mTHHHFnMObt6S6hn3DoKShIBpIokhSh/jSFTIsMuv6xUCyq+umaVZUvCFLVLwBfWKVSvWQ2mixyHEDTwCMLTREzgcwHE6QM/IRtf8pF75BHvH12TMyOOcI3xX2TCiYGL1JMlEIUo3GMpllvrQq4CG57jMkdUT8XSzoTSwgaKMZTRn7M2ERc9A65aCIuGGHXmxBIhqogaR7J9aaKN02RaYxGcZ7jkun5jeA6KhAByQNq6guZD5mXWxbPTwlNQiC5FYnUsJ8p7ybb3Jhuc3A4wD8UggPFP0yRoxiNIjRJ0DR1luWBQItM/BmSd3XVCGpADeApxii+yQgkZaIBb6fbpAj/7+hRfrx3ifjOgO27wmA/xd+PMIcTdDqFOD5OguqjVQEnlpVQyYVC8VGTi8WIkiLspUMOsgF30jGv7b+Hm7d3CG57DO4o4Z0Eb38CRxN0Mi1Zln4KBZxY2qHlOEgeGzGJIglICpIKcexxezLmR5OrXDcXmWY+N6fbvPrOI/DWgNENYXgrJdibIoeFUNIsF0rPcWJZBtVjsUiieLFiEkFiIZ76vHOwhWfeQ6bCYRxy+3DE5PoWW28Ztt7KGN2MMHcO0IPD3F/pefMzw4mlJaqKpGmedB2neFGGicFEYCIhOfLY80fEqUcce0STAPYDRm96bF3PGL8VEdw8hP0D9PAIjZPe9n7mcWJpS6b5BY5iZJpgogx/muEfCcGBgPFJp4Z7YYiZGIIDIdgXxm8p4xsJwa1D5N4hejRB4/77KWWcWFqiaQqJIHGExEmeeD0N8I8guJf7Lep5qAH/CMK7yuBuxvBmzODGAebWPnpwSDadokm86cNphRNLWzQPy2sUI1GMRAn+JCU4NKShwUyL/NpMCe/lQglvR/h3Jpg7++jefu6nxMm5sSgznFiWQLPiWZ8kQaYJ3lFCcM9DBTJfMCmYRPEPUoK9GP/uEbJ/eN+hTZJeB9/qcGJpi2qeZ5IKGufWxRzFBJ5BMh8V8KYZJkrxDiLkYJL7KJMJWeGnnBeHdh4nliXRTIsH22PkcIqniokCAGSaO78ymaKHE7LDwzzoFieQ9T+eUocTy7JoljcnkwmSZUicoEH+0LsUItI4RqdRPkio/R5RtsGJZQU0ToDJ8dQZs2d+8tB9BnF8LsL4tjixLIvq/chrViQuGXP8XWfTajwgQgEnltXQYl4VLTLdZgnXPc9LWRYnllUoekaacT/rHx44kcxwYukSvT8i/SDixNIVD6hAyri0Soc1TiwOa5xYHNY4sTiscWJxWOPE4rDGicVhjROLwxonFoc1TiwOa5xYHNY4sTiscWJxWOPE4rDGicVhjc3c/R8Qkb8TkZdF5CUR+d1iuZu//yHDxrIkwO+r6oeBjwOfLebod/P3P2TYzN1/XVX/sfi+D7xMPsX6wz1//0NIK59FRD4E/DzwD8zN3w+U5+//SelnD+z8/Q8b1mIRkW3gr4HfU9W9pk0rlp1KUBWRp0XkBRF5IWZqWw3HBrESi4gE5EL5S1X9m2Lx28W8/Swzf7+qPqOqT6rqkwGDZevvOENsekMC/Dnwsqr+aWnVwzl//0OMzaMgvwD8FvBdEflOsewPeZjn739IsZm7/9tU+yHwsM3f/5DjIrgOa5xYHNY4sTiscWJxWOPE4rBGtAdP/4vIO8ABcHPTdWnBVR7M+n5QVR+pWtELsQCIyAuq+uSm62HLw1hf1ww5rHFicVjTJ7E8s+kKtOShq29vfBZH/+mTZXH0HCcWhzUbF4uIPFU8BfC6iFzbdH0ARORZEbkhIi+WlvX2aYYzewJDVTf2ATzg+8DPACHwT8ATm6xTUa9fAj4CvFha9ifAteL7NeCPi+9PFPUeAI8Vx+OdcX0fBT5SfN8BXi3q1WmdN21ZPgq8rqo/UNUI+Ar50wEbRVW/BdyaW9zbpxn0jJ7A2LRYztOTAOfiaYZ1PoGxabFYPQnQc3pzDF0/gTHPpsVi9SRAT1jpaYZ1s44nMObZtFieBx4XkcdEJCR/7PW5Ddepjt4+zXBmT2D0oOfxSXLv/fvA5zddn6JOXwauAzH5XfgZ4Ar5M92vFX8vl7b/fFH/V4Bf20B9f5G8Gfln4DvF55Nd19mF+x3WrK0Z6mOwzbEaa7EsxRQbrwK/Sm7Gnwc+rarf63xnjjNjXZall8E2x2qs601mVUGfj5U3EJGngacBPLz/NJbdfMV5caFmkYrzUN8Wdd3n9k2tycFdl1gWBn1U9RmKhJxdc1k/7n8if2Mp5O8alJLRa3p5tixpHFd5IbcYxMj9+s6XOV+n+X1V1bnLbeaWS/FW2OM3wlZR/OYb6V/9S/UG62uGVgtUzZ+EZQXRZh8tqRXKMvvq+k3yc+VppqfrW8byXKzLshwH24B/JQ+2/dfarbXi5MPJO7XugKpOtK0QxCy+UFVWYpmLO9tXl8JvW94q54o1iUVVExH5HeDr5GkIz6rqS+0KsbggS1y0Eyb59Er7MlXzdzm323lFOR1alXJZZSF1tI+1vapXVb8GfK2bwiruoKYT0NBun6Jtk3dsISzLm9XHZrsm6o530Xko76tq2zo/q4Lz815n2+bi+EXc9wUzL5TG9rtqv22atarf15Vb9ZtFzn3VulmszNbSVVlFC+uz6YHEM6GVOOZZRShtfn+WtG0+C86PZZlRZ1IXdCsXCeZUV9jWorTdpqreVVaxjnmnv6lJnN93m6a8gh7KvoFKM9+ySaksVk78bbxoFidYjBx/KlZWl7msE9pk0coiLJV/XK+mXmYF/bEsS5+smruqRWCvVTNV7jHVnOiF5dnc4bZByfk6lX9j27uzFMz5sixtsTXr813ORZSbgEXb12xT2zublV+1v7bUNNXL+nD9sSxVLNMNXeTL1MUfqnye2YW2icAushYVvbPKIYMe0x+xNJnS+e0WYRswq3OWZ8ttYy4tWSiQOoE2RYHbRLiXpD9igZoYwpIh8ibBzJdp4YfUYtscLSpjVq9yHau2md+2jaAbtj1uFhumtz4fPotlD6TLMluVt0wXu624longtip+cXPYH8ti4yiWaYqjlC3KkuMjnfoSbZqNJup6OE2Ww2a8qFi26Jj7I5a22JjhuqamXMYyzmvTvrq405usUFdjQYuWVXA+mqGzoG33tEp4q8ZLqrZrK741Di+cX8sC7a3CvHVZNinJJn5TLr/q4q8jIWrVcawFnF+x2MZg5i+ObXd3mbu73AOrE+lcL60xv6aOBmu1sLzSb9vu+/yKZZ4O4wmdDD0UVk2MFBfIg1IPS0TyJwOb8mJPld8Qeznerdaum6etE//giGUZ6qK2HTETingGPA/xSoLJNLcycYymICZDs5r91zQbxxHgRU5+R8fUH7Esk6a4LHUnsM2gW4XQTozmQi6SIEB8H3wf8T0wBrIMzTIkTfNjjiLyd71VRMQahDL72zqZa0n6I5Y2QtlkQlHNnS+Bj3heLoygEEcQQOCjgQ+eQWfHmGaQpkicoN40tzhRBBFocgbxoCW7+T0SS8Xdvowo6py/RY7uMifw2ILkIpEwRIYDGIToICQb+OggIAu9vGgByRQTZ0icwjRGjLl/o6QpmprT9a44D9YiaTqelt36/ogFVh+jqVu26OQvCt5VbHvCHwkCZDxCRkN0PCQbh6RbAcnQIwsNaVg0GQomVkyU4U9SvEMPI4Ko5tbG84D4dL0XBQbrzlmXTj99EotN/KNpG9v4ybww2jDzSwpnVXwfwgAZjdDtEen2kHg3JNr1ibeEZCikoZAFIFn+8SLFPzSEB4bANwSASfImial32gdZJR5jY61bCKo/YqngxIlrc5csCsYt2l+ThROTCyUMkOEQhgN0a0RycUR0MWB6wWNy0RDvQjqENFTUK8SSgDcRwn0hCwQVwSQZchQg0yi3LGJoHPqdP87FB7VSiL9Mr8XSKJQqQZTXLZsL07CtGMkd2cEAGYQwHpFtD0l2h0yvhEwueUwvCdOLEF3M0GEKYYbxM7LIg9jg3cuHFSQVvKmQDD28oY9OCqfYKwb10gWCsTkntr+zpJ9iWdZvaSrHoqw6p/G4SzxzZGdC2RmR7AyILoYcXfaYXBWml5X4UkpwccLWKGJrEBF4KXePhtw7HBCbAUkk+IezJsqQhR4mDJAwQIMAIQbNWOrV6cvm/1jQT7HMsE1bKMU4TjUjXSEGEcm7xYMQHQ1It0LinYDpRZNblCtKfDVm+8ohH7h4h6vDe1wODxmYhJ8cXuLH4SVuqJAeeqSD3JfJQiELPTTwcqvl+2iW5Q4vafWNY3NepGamhxXot1hacOqZn5Mrq092mzvQSB5QMx54+cVNhz7JliHaFuIdiHdThhemfPDSbf7jhX/lPeEeF71DDBmBpGQIR7HPrb0wtygBZL6gRlBj8vK94u/pA2xtMbrO7+23WGy6i7a0GTw81eX2iuUCpri4npAODPHIkGwJyZYiWwlXdg74tztv89HtH/CIt5eLRPPyMhXuTEfcHm2TDXwyX8g8RQ1gQI/HkTo45lWi0TX0WyxNdJGgXJc51lCGSG4F1DOoL6QDSIaQjjIG45j3bu3x+Oht/kP4FheM4CFMNONAb3M33eLi4Cp+kKIeuUgkj7+c2of9UbTn3KcodDU21NZfsdhWM0VEiwhrxuwpyNnFRkB9JQwSxn7E0MQEAoEYAjwgwUOZqE+UeqSpwU/AxHncxUQZMi3C/1l6vyfUZZCtA6e3P2KZp8XBncrLsM11qdtnxbazCyiai0U0j53kCwGjhH7KyIsJJCVV8BA8EQxCijDNAg7iAVnkYSLBixRvqniTBIliiGKIE6jrNtvcCA05tqvST7EsIZTZ9+N502zKsLVmxYnXFEgzJM0gy0CBjPyvCplClPncSce8kw3ImBJIwkSFH0WP8MPDq7y1v4Pc8wgOIDhUvKMUOYqRKEbjGE2SPM9lnZlyFcdmQ3/EUpVhZkGtx18XtDtxx7WfowTNIEmRJMMkiknBJCBTw8HRgDcPLvCK/14CSdkyUzwy9rIR377zb/jujfex99YOoxsew3eVwZ2U4F6cR2+nESRJbsGajqmONQsF+iQWWG5MqGnbud5NbnlKomnITalcDmiaIVk+amziQjCx4E2E6DDkxmAbz2Qk6uEXPaFb0ZiX3nkve9d3GL3pM35bGd1MCW9HeHsT5GiKRhFaaoKsJzhcpsk9FVo4b2mVXUVra4uX+QUnv9veZVmGRjEyifCOEoJDn2BfSQfC1A+4k2xz72DIG+MLAKSpYToN0BtDxm8bRjeU8c2U4Y0jvLtHyOEEnUzQqGiCls3FtWWd4X4ReRb4z8ANVf33xbLLwF8BHwJ+BPwXVb1drPsc+Vs0UuC/qerXl67dqcpYdpcrLn4n02AAmiTIdAqewdsbEg59Ms8HDJIa0v2QLAg48kdIlvd4wqkwuAPD2xnDWymDdyd47+6jB4e5SKIotyiLph/tOip9XLZYWRcby/IXwH8H/kdp2TXgm6r6xeIlDteAPxCRJ8inMf054H3AN0TkZ1VbjHKsOi5km8W/zH40z3DLplMMYO4NCAIPGGISH39iSAPy3pGCV3SNvWlGsJ8Q3IvzZmfvgOzuHjqZnih7bVZl1uSumHO8UCyq+q3ivXtlPgX8cvH9S8D/Bv6A0osagR+KyOxFjf/HukZNB1DVy1n1bmsZRtdMEdLcwkymmIOAwICJQ/wjH/WAolttogxvmmKmCeYohmmU+ycHB+hkunhkucN6L+5yz2a9qt9kWZ/lxIsaRaT8osa/L21X+6LG8tz9Q8ZzKy0V30Iojc/IVIX560SpRRZ+nKCTCeJ5mCzDHMV49wIwIKlCliHT+/ETTZK8txMnebPTRZPSNMhoE8rfcG/I+kWNJ+bul8v29ndRr2CVi2CbdVakD2gUAwcQxYjv4XnFGFKa5iPHUUw2zXs6p3fVkKtTZzFsE5mWcd4trNSyYnlbRB4trMp6Xi7Zpj1tm6uyKNWwuoDTi+Ik/5Jm+WhxSbBaZPBrXMROFu2jyxyUNeW0LFvic5zFyyVnSUvlT9U2i6gbJFyUFDXLuKu5mzVN8/jIZEp2NEGPjtCjo/x7FOWfmV/SlNm2ijPfdG7K2y3C4sa06Tp/mdyZvSoibwB/BHwR+KqIfAb4MfAbAKr6koh8FfgekACfbdUTWifruNuOs9lyy3GqLV3CX6hKWKpMYlpTNlwTNr2hT9es+pWa7b8AfGHpGq0yAHbsU1RM7GPTpW7K621bB9t1c/uscsCthGI7wGi7fQX9ieDaOG7zVOaiWPjKTSd7jTmsndBU96bUy6rk9ZY3Zn/EYkubXFTrFx+sKTJqw6KodBfCbepdze+vgfMjFtuT1jaBqqlpaNskthWdTXPSxtItK/pzl1bZdWR2vtxVI56LhNOFUJrqsqi302ZUekl63DiXWOWAy11fGx/Ipitb1Z1epQtcLreuXotYNqzQgv5YlmUzw8pte5fZZauW1+a3bZKamizc/PmwxfJYz4dlaaLqjm7zWplFZa/yWxtLtYqobC1RTXCx7UTT/RHLMhHa8kk4ccfNTZrc0uu32n9bIdXFb9ac9NW0/tRsDQvq0p9mqA1tA1CzZU2xlCbzvUrPyEYYq/a05uu2plBA/8Uyf2E3GRNpok0OThfldrV9C/rTDK0bW8tQ5ResYOqt1tv+rqmp6CIWs6Ce/bcsYBdnKG/bpndRt79V6tMFtrk1s//Xta8S58OyNN1N67hobcs9q+huV2Uvaen6a1mWMbdNWWc2gbkuo6pd/aaOeetyBr5cvyzLXA+i9nW3trTpoi7qti+Km6xj/KZLq7lqchR9sixVaYtdzxzdFF1ddNeX19sOH7RlXdZhUS7PuRtIXMQyYew6AbQJyZe37Sr83xTnqXpYfxkLY9uMtzim/ollmYM5q9jL/CtiVhn4q7zD9f7fuokCNhhn6pfPYuM3zFPn1K6rp7SIlcaT5OTfeWyF0nVPrqA/lmUZB6yp99Pl/o+3WZDP24U421iUKutme66WqGu/LEtfWMY/6bJLbCuU+f0uK5Rz1xuqYt3tc5/GnFZpOrpodiwGIPsjli4Tl2z31VWC0CJfqsu4TAeR3drJlBeU/fA1Q6skG1U1ETZOdwf+wkq/64j+ieVE07AgKLfIt5hPjrLNNFs3dfWuq+ey5dWIa2ZVTkXHF+y3f2KZZ14wVd3iZQNm8+WeNVVjO9owu0Kb8tbw2/6JZT49ss1zQHXNRlPMpeuubxs6GK9pnX9TWude1dtEbYh9yRHkunKbhhMWDmg23BxVWYN1+1okmCV6VP2zLB2ycNR6mV5KG99nlS5u3W/m/Zr5np3qYl+v/LsWnG/LUu7Olk5q45RgdZTvtjWFy0/sa/73tiPCVdvNN91rop9iWeFi1VqSs06FtB3HsilrvkyLAFptPZaJMRX0rxlaxwW1zT+x6VW1rd95HdSsoJ+WxZaKO7k2MrmOmEpbn6SuCVk13cGWujRMy330z7LY0rbLuLC8xY7hcRO3iqVom2ZRxTKR5VPn6+Tx2qSw9losK+XfroHGOXQX/7idoFfNXSk3vZVilLnNF3cGFopFRD4gIn8nIi+LyEsi8rvF8ssi8rci8lrx91LpN58TkddF5BUR+cTCWsDJeEFxcJVvxlglvbExCFY6efMnuik0X96+ilUsXtshiqrIdhPHs2rXnO85bCxLAvy+qn4Y+Djw2WKO/tn8/Y8D3yz+Z27+/qeAPxMRz2I/zdg4nqu271WCsd3/OseZ2t4kp5qgUpNT53BblL/w7KrqdVX9x+L7PvAy+RTrnyKft5/i768X34/n71fVHwKz+fvb0Wakts4PWLZ3Uye8eadww6PAtZw6d900562Otnjhw88D/8Dc/P1Aef7+n5R+Vjl/v4g8LSIviMgLMdP51TmLBGN7wWyt0nx5DWVb+1NW6Zo1DuoygqztVa0uGOuaiMg28NfA76nqXtOmFctOzyes+oyqPqmqTwYM6kvbVBpBAyeE0kYM8wKoE0MHCU6ty7HAqjQRCciF8peq+jfF4reLeftZ2/z9qzB/YVZxjOdofC/jImwiqItGz5usXxcj2TXY9IYE+HPgZVX909Kq5ziL+fubWNRLmVGV+zL/aaLCApyaNalp/031rWMVh362zjJVwRabCO4vAL8FfFdEvlMs+0POcv7+pnGd8p26VMJQy5eP244x1aUB9LBZtcVm7v5vU+2HQNfz99edTFvzuczgXTnWYPt7G8HU5Z2sq5loqlOdX9Smx0kfx4bKPkYdNtagSXRdNhOLHNRy4G5RwGxZsazq5D7QY0M2D46v4w5eMpjVaR3alGVj/VrU43yIpc4RbRuHsBlprYtvLHNx2wYEV/Fnlq1fi32eD7HMYyuStj6MbWBs0b6bxpPOMedPLG3voL6G5BfRQ8GJdjV1+SqVEHkHOABubrouLbjKg1nfD6rqI1UreiEWABF5QVWf3HQ9bHkY63tObbRjEzixOKzpk1ie2XQFWvLQ1bc3Pouj//TJsjh6zsbFIiJPFYndr4vItU3XB0BEnhWRGyLyYmlZtwnq3db3bJLqVXVjH8ADvg/8DBAC/wQ8sck6FfX6JeAjwIulZX8CXCu+XwP+uPj+RFHvAfBYcTzeGdf3UeAjxfcd4NWiXp3WedOW5aPA66r6A1WNgK+QJ3xvFFX9FnBrbvF6E9RXQM8oqX7TYrFK7u4JKyWonxVdJtXPs2mxWCV395zeHEPXSfXzbFos/UjutqPXCepnkVS/abE8DzwuIo+JSEj+JONzG65THZtPUK/hzJLqe9Dz+CS59/594PObrk9Rpy8D14GY/C78DHCF/DHd14q/l0vbf76o/yvAr22gvr9I3oz8M/Cd4vPJruvsIrgOazbdDDnOEU4sDmucWBzWOLE4rHFicVjjxOKwxonFYY0Ti8Oa/w+ss4K1ZjH+jwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=default'\n",
    "model.forward = model.forward_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.5411, loss_val: nan, pos_over_neg: 1.0592623949050903 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.1111, loss_val: nan, pos_over_neg: 3.236527442932129 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 6.7996, loss_val: nan, pos_over_neg: 4.7997331619262695 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.6477, loss_val: nan, pos_over_neg: 27.631826400756836 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.5866, loss_val: nan, pos_over_neg: 21.695289611816406 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.5191, loss_val: nan, pos_over_neg: 27.44672203063965 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.4748, loss_val: nan, pos_over_neg: 24.605899810791016 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.4226, loss_val: nan, pos_over_neg: 25.321962356567383 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.3898, loss_val: nan, pos_over_neg: 38.1678352355957 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.367, loss_val: nan, pos_over_neg: 79.34306335449219 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.3407, loss_val: nan, pos_over_neg: 123.05043029785156 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.3282, loss_val: nan, pos_over_neg: 115.31581115722656 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.3047, loss_val: nan, pos_over_neg: 143.41839599609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.275, loss_val: nan, pos_over_neg: 149.4844207763672 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.2552, loss_val: nan, pos_over_neg: 151.4322509765625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.2373, loss_val: nan, pos_over_neg: 192.05929565429688 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.2175, loss_val: nan, pos_over_neg: 232.6253204345703 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.2126, loss_val: nan, pos_over_neg: 248.4789276123047 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.1946, loss_val: nan, pos_over_neg: 277.1551818847656 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.1811, loss_val: nan, pos_over_neg: 311.49444580078125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.1752, loss_val: nan, pos_over_neg: 426.5718994140625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.1536, loss_val: nan, pos_over_neg: 333.12835693359375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.1633, loss_val: nan, pos_over_neg: 218.2388916015625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 6.1337, loss_val: nan, pos_over_neg: 428.0062561035156 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 6.1324, loss_val: nan, pos_over_neg: 547.6406860351562 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 6.1194, loss_val: nan, pos_over_neg: 229.388916015625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 6.1222, loss_val: nan, pos_over_neg: 350.32806396484375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 6.1184, loss_val: nan, pos_over_neg: 544.017822265625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 6.1055, loss_val: nan, pos_over_neg: 474.1595458984375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 6.1104, loss_val: nan, pos_over_neg: 301.6853942871094 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 6.0887, loss_val: nan, pos_over_neg: 617.2664794921875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 6.0841, loss_val: nan, pos_over_neg: 328.838623046875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 6.0869, loss_val: nan, pos_over_neg: 407.0340576171875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 6.0728, loss_val: nan, pos_over_neg: 391.86224365234375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 6.0741, loss_val: nan, pos_over_neg: 377.46392822265625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 6.0556, loss_val: nan, pos_over_neg: 1403.2742919921875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 6.07, loss_val: nan, pos_over_neg: 496.73272705078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 6.0613, loss_val: nan, pos_over_neg: 252.94784545898438 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 6.0545, loss_val: nan, pos_over_neg: 394.7818603515625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 6.0477, loss_val: nan, pos_over_neg: 463.29058837890625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 6.054, loss_val: nan, pos_over_neg: 596.0033569335938 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 6.0405, loss_val: nan, pos_over_neg: 849.3046264648438 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 6.0392, loss_val: nan, pos_over_neg: 447.1424255371094 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 6.0335, loss_val: nan, pos_over_neg: 959.4078979492188 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 6.0415, loss_val: nan, pos_over_neg: 454.496826171875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 6.0281, loss_val: nan, pos_over_neg: 654.4046630859375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 6.0266, loss_val: nan, pos_over_neg: 648.5693969726562 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 6.0269, loss_val: nan, pos_over_neg: 657.3994140625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 6.0228, loss_val: nan, pos_over_neg: 580.0164794921875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 6.0119, loss_val: nan, pos_over_neg: 1128.383544921875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 6.016, loss_val: nan, pos_over_neg: 373.59765625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 6.0241, loss_val: nan, pos_over_neg: 559.369384765625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 6.0131, loss_val: nan, pos_over_neg: 682.6962890625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 6.0186, loss_val: nan, pos_over_neg: 915.0721435546875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 6.0056, loss_val: nan, pos_over_neg: 270.90631103515625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.9994, loss_val: nan, pos_over_neg: 381.2758483886719 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 6.0081, loss_val: nan, pos_over_neg: 264.4792175292969 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 6.0012, loss_val: nan, pos_over_neg: 496.9595642089844 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 6.0, loss_val: nan, pos_over_neg: 188.16627502441406 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.9987, loss_val: nan, pos_over_neg: 274.4844055175781 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.9978, loss_val: nan, pos_over_neg: 132.4634246826172 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.9818, loss_val: nan, pos_over_neg: 377.1601257324219 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.9843, loss_val: nan, pos_over_neg: 285.33544921875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.9943, loss_val: nan, pos_over_neg: 117.46995544433594 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 6.0019, loss_val: nan, pos_over_neg: 197.0648651123047 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.9961, loss_val: nan, pos_over_neg: 187.56951904296875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.977, loss_val: nan, pos_over_neg: 441.5752868652344 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.98, loss_val: nan, pos_over_neg: 232.3636474609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9742, loss_val: nan, pos_over_neg: 285.3995361328125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.9804, loss_val: nan, pos_over_neg: 282.4725036621094 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.9806, loss_val: nan, pos_over_neg: 214.15911865234375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.9726, loss_val: nan, pos_over_neg: 273.689697265625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.9764, loss_val: nan, pos_over_neg: 455.23773193359375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.973, loss_val: nan, pos_over_neg: 164.8780975341797 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.9749, loss_val: nan, pos_over_neg: 327.25384521484375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.9595, loss_val: nan, pos_over_neg: 291.9214782714844 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.9716, loss_val: nan, pos_over_neg: 186.5828094482422 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.9667, loss_val: nan, pos_over_neg: 300.794189453125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.9614, loss_val: nan, pos_over_neg: 358.3593444824219 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.9598, loss_val: nan, pos_over_neg: 243.73641967773438 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.9477, loss_val: nan, pos_over_neg: 490.9085693359375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.9611, loss_val: nan, pos_over_neg: 274.26806640625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.9568, loss_val: nan, pos_over_neg: 282.9115295410156 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9606, loss_val: nan, pos_over_neg: 236.66439819335938 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.946, loss_val: nan, pos_over_neg: 1601.255859375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 264.9794006347656 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.9497, loss_val: nan, pos_over_neg: 297.61474609375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.9527, loss_val: nan, pos_over_neg: 307.84088134765625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.9489, loss_val: nan, pos_over_neg: 317.65216064453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.9382, loss_val: nan, pos_over_neg: 588.5206909179688 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.9394, loss_val: nan, pos_over_neg: 297.5496520996094 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9402, loss_val: nan, pos_over_neg: 406.12091064453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.9532, loss_val: nan, pos_over_neg: 193.471435546875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.9401, loss_val: nan, pos_over_neg: 280.0110168457031 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.9352, loss_val: nan, pos_over_neg: 220.61473083496094 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.9396, loss_val: nan, pos_over_neg: 260.3316345214844 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.9494, loss_val: nan, pos_over_neg: 306.73065185546875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.9473, loss_val: nan, pos_over_neg: 232.29537963867188 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9396, loss_val: nan, pos_over_neg: 455.9507751464844 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.9366, loss_val: nan, pos_over_neg: 388.6786804199219 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9297, loss_val: nan, pos_over_neg: 385.90814208984375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.9433, loss_val: nan, pos_over_neg: 602.34423828125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.934, loss_val: nan, pos_over_neg: 384.77655029296875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.942, loss_val: nan, pos_over_neg: 503.0411682128906 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.9305, loss_val: nan, pos_over_neg: 551.2427368164062 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.9366, loss_val: nan, pos_over_neg: 398.56683349609375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.9284, loss_val: nan, pos_over_neg: 753.1249389648438 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.9334, loss_val: nan, pos_over_neg: 1121.3704833984375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.928, loss_val: nan, pos_over_neg: 810.7379760742188 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9218, loss_val: nan, pos_over_neg: 923.5484619140625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.9257, loss_val: nan, pos_over_neg: 386.66351318359375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.9203, loss_val: nan, pos_over_neg: 826.7962036132812 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 348.5617980957031 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.9246, loss_val: nan, pos_over_neg: 457.6337585449219 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.9153, loss_val: nan, pos_over_neg: 696.3280639648438 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.9358, loss_val: nan, pos_over_neg: 143.2862091064453 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 537.2359619140625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.9212, loss_val: nan, pos_over_neg: 379.6175231933594 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.9204, loss_val: nan, pos_over_neg: 392.92108154296875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.9331, loss_val: nan, pos_over_neg: 216.22085571289062 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.9208, loss_val: nan, pos_over_neg: 312.5001220703125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.9292, loss_val: nan, pos_over_neg: 202.8278045654297 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.9187, loss_val: nan, pos_over_neg: 388.5715026855469 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.9179, loss_val: nan, pos_over_neg: 297.5546569824219 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.9154, loss_val: nan, pos_over_neg: 206.49893188476562 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.9202, loss_val: nan, pos_over_neg: 158.20448303222656 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.9176, loss_val: nan, pos_over_neg: 326.2987060546875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.9196, loss_val: nan, pos_over_neg: 179.46607971191406 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.9131, loss_val: nan, pos_over_neg: 712.624267578125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.9205, loss_val: nan, pos_over_neg: 210.852783203125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 516.0079956054688 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.9131, loss_val: nan, pos_over_neg: 436.426513671875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.9199, loss_val: nan, pos_over_neg: 977.9222412109375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 384.3013610839844 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.9102, loss_val: nan, pos_over_neg: 368.4949645996094 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.9289, loss_val: nan, pos_over_neg: 305.60894775390625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 237.3574981689453 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.9151, loss_val: nan, pos_over_neg: 370.9686279296875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.9178, loss_val: nan, pos_over_neg: 207.4466094970703 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.9159, loss_val: nan, pos_over_neg: 256.1927490234375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.9152, loss_val: nan, pos_over_neg: 306.4562683105469 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 226.64071655273438 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.9128, loss_val: nan, pos_over_neg: 216.37283325195312 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.915, loss_val: nan, pos_over_neg: 539.3475952148438 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 251.2081298828125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 343.9605407714844 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 201.6256561279297 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 244.97772216796875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.9065, loss_val: nan, pos_over_neg: 258.48040771484375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.9121, loss_val: nan, pos_over_neg: 501.0278625488281 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.9145, loss_val: nan, pos_over_neg: 286.36981201171875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 355.0216369628906 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.9039, loss_val: nan, pos_over_neg: 198.9960174560547 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.907, loss_val: nan, pos_over_neg: 236.0748748779297 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.9079, loss_val: nan, pos_over_neg: 191.46946716308594 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.909, loss_val: nan, pos_over_neg: 225.55987548828125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 458.0835876464844 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.9085, loss_val: nan, pos_over_neg: 151.4971466064453 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.9018, loss_val: nan, pos_over_neg: 220.41973876953125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 318.3958435058594 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.9107, loss_val: nan, pos_over_neg: 149.64987182617188 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 392.7933654785156 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.9139, loss_val: nan, pos_over_neg: 293.2562255859375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.9071, loss_val: nan, pos_over_neg: 225.13719177246094 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.9009, loss_val: nan, pos_over_neg: 305.9122619628906 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 230.43447875976562 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 283.45477294921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 309.3838195800781 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 202.70986938476562 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 480.5371398925781 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 277.9996337890625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8999, loss_val: nan, pos_over_neg: 218.21177673339844 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 359.65863037109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8999, loss_val: nan, pos_over_neg: 254.7541961669922 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 332.85662841796875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 156.02476501464844 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.9051, loss_val: nan, pos_over_neg: 319.7023010253906 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 363.14794921875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.9045, loss_val: nan, pos_over_neg: 312.6104431152344 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 443.8044738769531 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.9012, loss_val: nan, pos_over_neg: 325.35662841796875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8853, loss_val: nan, pos_over_neg: 379.8262939453125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 421.6338195800781 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8872, loss_val: nan, pos_over_neg: 469.672607421875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 518.434326171875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 557.9445190429688 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 434.3085632324219 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8917, loss_val: nan, pos_over_neg: 458.1703186035156 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 508.2038879394531 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8912, loss_val: nan, pos_over_neg: 458.6784973144531 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8896, loss_val: nan, pos_over_neg: 292.3089599609375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8835, loss_val: nan, pos_over_neg: 635.7197875976562 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8878, loss_val: nan, pos_over_neg: 414.8761901855469 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8908, loss_val: nan, pos_over_neg: 319.72088623046875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8922, loss_val: nan, pos_over_neg: 470.2619934082031 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8901, loss_val: nan, pos_over_neg: 343.1057434082031 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 411.7867126464844 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8825, loss_val: nan, pos_over_neg: 330.2955322265625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 428.52435302734375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8891, loss_val: nan, pos_over_neg: 347.2069396972656 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 472.94403076171875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8958, loss_val: nan, pos_over_neg: 905.311279296875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8892, loss_val: nan, pos_over_neg: 494.8865051269531 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 498.85418701171875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 390.2584533691406 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.895, loss_val: nan, pos_over_neg: 239.40716552734375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8839, loss_val: nan, pos_over_neg: 705.3309326171875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 363.6382751464844 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 436.1103820800781 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 287.1240539550781 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8924, loss_val: nan, pos_over_neg: 419.9329833984375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 306.43426513671875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 349.94891357421875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 401.9412841796875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 225.37738037109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 561.5005493164062 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8843, loss_val: nan, pos_over_neg: 573.62939453125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8783, loss_val: nan, pos_over_neg: 289.2052001953125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.883, loss_val: nan, pos_over_neg: 275.31817626953125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 415.0041809082031 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 443.7305603027344 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 382.38909912109375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8841, loss_val: nan, pos_over_neg: 593.7662353515625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 331.3123779296875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8813, loss_val: nan, pos_over_neg: 385.1626281738281 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8848, loss_val: nan, pos_over_neg: 421.878662109375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 266.75537109375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 315.4652099609375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 281.0825500488281 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 365.30206298828125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8738, loss_val: nan, pos_over_neg: 486.8310241699219 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 241.57492065429688 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 466.8612060546875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 395.83544921875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 449.4658508300781 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 571.2069702148438 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 422.54339599609375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 514.652587890625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 494.34979248046875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 814.4564819335938 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 506.8334655761719 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 668.687255859375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 502.43804931640625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 342.2362365722656 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 473.1329650878906 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 358.3614196777344 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 373.12640380859375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 460.9366760253906 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 532.1607055664062 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8754, loss_val: nan, pos_over_neg: 222.36178588867188 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 989.005615234375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8717, loss_val: nan, pos_over_neg: 232.90170288085938 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8673, loss_val: nan, pos_over_neg: 485.6452331542969 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 632.5682373046875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 356.87982177734375 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 766.8944091796875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 1001.2249145507812 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 333.91131591796875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 518.7106323242188 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 291.0449523925781 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 321.33868408203125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 537.3133544921875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8683, loss_val: nan, pos_over_neg: 622.097412109375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 468.6255187988281 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 492.1857604980469 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 583.0111083984375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 410.21734619140625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 514.7424926757812 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 767.5147705078125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 452.93170166015625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 764.035400390625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 929.900146484375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 356.7826843261719 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 621.1871948242188 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 455.56683349609375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 477.9310607910156 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 297.9556884765625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 410.4861145019531 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 567.8734741210938 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 538.5025634765625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 294.5372619628906 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 288.2881774902344 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 587.89111328125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 631.7052612304688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 264.55657958984375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 562.7904052734375 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 469.24395751953125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 391.81085205078125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 1379.3255615234375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 304.302978515625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 600.3980102539062 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 2369.85400390625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8651, loss_val: nan, pos_over_neg: 394.75787353515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 315.8934631347656 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 647.4309692382812 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 502.6444396972656 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 840.049560546875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 1033.3291015625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 340.087646484375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 415.79754638671875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 443.61846923828125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 371.7149658203125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 434.893310546875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 652.0569458007812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 569.2185668945312 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 320.2918395996094 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 301.64312744140625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 433.0592956542969 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 326.4866638183594 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8593, loss_val: nan, pos_over_neg: 379.67926025390625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 467.2384033203125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 512.5743408203125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 383.418212890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 381.0321350097656 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 593.867431640625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 697.5585327148438 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 588.2948608398438 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 405.96527099609375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 534.5236206054688 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 161.1255340576172 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 337.5500183105469 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 312.1282043457031 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 391.6070556640625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 402.0593566894531 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 348.2807312011719 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 824.428955078125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 373.6597595214844 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 218.78521728515625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 511.8371276855469 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 327.03216552734375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 335.37646484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 553.4093627929688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 453.43231201171875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 434.94488525390625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 513.2366333007812 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 637.9635620117188 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 599.1920776367188 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 506.46435546875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1008.5286254882812 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 385.7738952636719 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 317.024169921875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 753.14990234375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 624.4983520507812 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 524.7177734375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 562.3231811523438 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 989.3966674804688 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 384.5263977050781 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 722.433837890625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 579.1134643554688 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 929.143310546875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 805.1903076171875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 576.2215576171875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 675.2417602539062 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 485.8847351074219 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 545.9652709960938 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 797.72314453125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1132.9017333984375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 488.50628662109375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 538.30712890625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 938.3367919921875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 733.3816528320312 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 852.255859375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 719.9910888671875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 557.5885620117188 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 916.4676513671875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 486.8207702636719 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 1093.91845703125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 526.3231201171875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 1104.137451171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 625.903076171875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 713.1082153320312 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1022.2177734375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 765.5811767578125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 1051.768798828125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 1487.0621337890625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 307.50970458984375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 676.9764404296875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8519, loss_val: nan, pos_over_neg: 830.6240844726562 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 645.2799682617188 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 2537.415283203125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 576.5502319335938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 334.3704833984375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 642.4667358398438 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 737.310302734375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 239.9048309326172 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 360.8359375 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 502.2469787597656 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 344.71197509765625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 413.959716796875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 420.13330078125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 330.8096618652344 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 356.646728515625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 382.5062255859375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 374.5344543457031 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 462.89752197265625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 677.7240600585938 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 396.5465393066406 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 464.0140380859375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1239.0283203125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 462.6827697753906 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 457.5995178222656 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 474.6021728515625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 441.3175048828125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 340.4575500488281 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 914.5401000976562 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 799.7611694335938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 319.72210693359375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 388.0775146484375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 896.423583984375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 466.6935119628906 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 488.80023193359375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 534.0309448242188 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 967.771728515625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1592.5372314453125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 588.8681030273438 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 634.07373046875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 471.0279846191406 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 628.9730834960938 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 287.7059020996094 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 733.87939453125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 520.7992553710938 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 408.29638671875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 928.2449951171875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 581.7451171875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 408.7223815917969 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 1324.7889404296875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 648.5648193359375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 454.48516845703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 408.1045837402344 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 532.1016235351562 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 600.2213745117188 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 449.72222900390625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 568.0477294921875 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 303.34844970703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 552.1015625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 856.4384155273438 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 781.7352294921875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1642.169189453125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 519.1943969726562 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 414.6566162109375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 562.1210327148438 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1248.7664794921875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 428.65142822265625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 396.2169189453125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 614.4996337890625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 374.6924743652344 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 301.31005859375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 604.4854736328125 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 694.83544921875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 490.6768493652344 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 446.1412048339844 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1467.4649658203125 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 558.8969116210938 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 649.419189453125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 456.5855407714844 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 400.8526306152344 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 604.0333862304688 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 877.4136352539062 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 275.3774108886719 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 308.7056884765625 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 657.24853515625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 495.155517578125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 579.3722534179688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 621.1004638671875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1076.231689453125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1531.187744140625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 505.3993835449219 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8252, loss_val: nan, pos_over_neg: 1016.1669921875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 1906.1016845703125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 480.2744445800781 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 351.4363708496094 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 625.3176879882812 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 341.2700500488281 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 550.7190551757812 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 343.8113708496094 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 860.2276611328125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 266.06280517578125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 742.4344482421875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 367.4197692871094 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 406.0503234863281 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 905.5067749023438 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 502.0009460449219 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 386.6715087890625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 209.82801818847656 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 681.6788330078125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 366.9575500488281 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 477.9522705078125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 991.9985961914062 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 634.1044921875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 502.2566223144531 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 778.9251098632812 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8306, loss_val: nan, pos_over_neg: 606.4273681640625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 406.390869140625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 324.155029296875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 452.3140869140625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 578.397705078125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 335.6120910644531 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 415.4976501464844 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 533.9605712890625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 220.33486938476562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 522.7935180664062 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 430.2674255371094 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 266.4413757324219 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1003.791259765625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 614.7468872070312 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 248.79005432128906 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 335.9574279785156 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 589.9540405273438 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 555.3246459960938 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 225.8197479248047 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 459.1532287597656 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 473.6697082519531 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 453.5172424316406 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 304.99664306640625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 649.6158447265625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 580.8357543945312 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 619.82080078125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 513.2044677734375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 494.3911437988281 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8248, loss_val: nan, pos_over_neg: 796.4515380859375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8307, loss_val: nan, pos_over_neg: 344.7320861816406 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 693.7025146484375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 908.9283447265625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 529.6823120117188 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 343.26275634765625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 271.9039306640625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 432.78900146484375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 623.993896484375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 356.4383239746094 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 481.62432861328125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 377.511474609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 413.170166015625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 555.2539672851562 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 640.47119140625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 480.7867431640625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 398.307861328125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 638.1804809570312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 436.0295715332031 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 486.3904724121094 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 403.04718017578125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 569.5184936523438 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 541.5629272460938 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 590.60546875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 483.9391174316406 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 352.1444091796875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 833.4563598632812 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 675.1600341796875 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 389.90130615234375 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 365.2412109375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 1064.157470703125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 470.7794189453125 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 392.1070251464844 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 334.0672302246094 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 288.62518310546875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 338.1103820800781 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 464.911376953125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1308.352783203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 611.2966918945312 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 418.8901672363281 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 748.3226928710938 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 548.1212768554688 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 380.4026184082031 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 771.3038940429688 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 856.170654296875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 445.44561767578125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 449.34759521484375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 595.2987670898438 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 786.5506591796875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8233, loss_val: nan, pos_over_neg: 409.54815673828125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 604.8433227539062 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 684.7357788085938 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 494.9058532714844 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 466.783935546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 857.8911743164062 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 643.4329223632812 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 406.2275085449219 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 632.1973266601562 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 904.4273681640625 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 1060.1351318359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 503.7689514160156 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 558.1215209960938 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 545.02392578125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 571.070068359375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 403.8465881347656 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 313.7022705078125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 1197.669189453125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 880.1221923828125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 1784.7100830078125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 375.5597839355469 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 455.51995849609375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 399.49359130859375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 399.482421875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 426.6829528808594 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 940.7045288085938 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 781.1063842773438 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 413.47967529296875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 258.06097412109375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 675.0615844726562 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8223, loss_val: nan, pos_over_neg: 939.785888671875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 304.0751647949219 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 329.0513916015625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 352.1204833984375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 1131.4246826171875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 406.0364074707031 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 402.13165283203125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 456.70458984375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 559.2935180664062 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 667.9758911132812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 398.1170959472656 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8204, loss_val: nan, pos_over_neg: 606.24267578125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 484.7119445800781 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8265, loss_val: nan, pos_over_neg: 536.5654296875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 649.2756958007812 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 570.1985473632812 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 616.9313354492188 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 592.9872436523438 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 710.9930419921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 665.0933227539062 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8228, loss_val: nan, pos_over_neg: 786.7293090820312 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8217, loss_val: nan, pos_over_neg: 550.3607788085938 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 370.47723388671875 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 727.4169921875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 686.7257690429688 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 716.2828369140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 769.8720703125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 300.39483642578125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 655.7926025390625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.827, loss_val: nan, pos_over_neg: 733.3910522460938 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 565.4588623046875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 426.8345642089844 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 445.9276428222656 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 531.850830078125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 306.11016845703125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 372.9922790527344 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 487.0645751953125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 401.42645263671875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 940.7601318359375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 330.9799499511719 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 374.5946960449219 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 530.8577880859375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 293.49688720703125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 411.21356201171875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 355.646728515625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 309.9566650390625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 490.20428466796875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 491.3627014160156 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8122, loss_val: nan, pos_over_neg: 577.621826171875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 473.2652587890625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8264, loss_val: nan, pos_over_neg: 484.10284423828125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 727.4931640625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 669.9480590820312 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 825.7979125976562 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.827, loss_val: nan, pos_over_neg: 514.7442626953125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 543.551025390625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 894.072265625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8224, loss_val: nan, pos_over_neg: 1085.5855712890625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 457.0010681152344 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 449.70068359375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8206, loss_val: nan, pos_over_neg: 1038.057373046875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 1127.398193359375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8165, loss_val: nan, pos_over_neg: 830.6585083007812 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8184, loss_val: nan, pos_over_neg: 618.5556030273438 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 939.9082641601562 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 368.7000732421875 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: 397.2945251464844 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 738.4837646484375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8204, loss_val: nan, pos_over_neg: 554.9605102539062 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 346.14276123046875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 626.1834716796875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8211, loss_val: nan, pos_over_neg: 569.7244262695312 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 426.8154602050781 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 544.4388427734375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 395.9910583496094 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.819, loss_val: nan, pos_over_neg: 831.58740234375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 530.4847412109375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8263, loss_val: nan, pos_over_neg: 492.579345703125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 507.4964294433594 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 392.9183349609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8224, loss_val: nan, pos_over_neg: 322.3828125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8191, loss_val: nan, pos_over_neg: 513.7591552734375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 592.9238891601562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8222, loss_val: nan, pos_over_neg: 395.6203918457031 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 382.91888427734375 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 1378.7587890625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 566.3374633789062 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8221, loss_val: nan, pos_over_neg: 286.6322937011719 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8231, loss_val: nan, pos_over_neg: 707.004638671875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 640.4971313476562 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 420.3765869140625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 523.762451171875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 1191.95263671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 420.2113952636719 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 647.4256591796875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 1233.4156494140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 440.71002197265625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [20:31<102665:57:50, 1232.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 763.1651611328125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 698.0069580078125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 476.7935791015625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8212, loss_val: nan, pos_over_neg: 964.7258911132812 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8211, loss_val: nan, pos_over_neg: 676.50390625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8139, loss_val: nan, pos_over_neg: 1042.5511474609375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 761.4599609375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 434.4414978027344 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 1378.072509765625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 325.4195556640625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8166, loss_val: nan, pos_over_neg: 712.9781494140625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 670.8097534179688 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 1409.117919921875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 651.9111328125 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 659.716796875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8265, loss_val: nan, pos_over_neg: 742.426513671875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 696.2476806640625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 410.61456298828125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8234, loss_val: nan, pos_over_neg: 499.8667297363281 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 513.530517578125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8124, loss_val: nan, pos_over_neg: 931.8460693359375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 1120.0777587890625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 2476.891357421875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 523.9747924804688 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8125, loss_val: nan, pos_over_neg: 1081.8157958984375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 682.0394287109375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8191, loss_val: nan, pos_over_neg: 462.35614013671875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 1009.284912109375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 563.0723266601562 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 775.4041137695312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8139, loss_val: nan, pos_over_neg: 957.9944458007812 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 937.8580932617188 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 1211.7552490234375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 1329.2210693359375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 952.8217163085938 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 738.874755859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 1174.6923828125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 1463.1436767578125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 1018.5989379882812 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 594.3646850585938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 2539.3359375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 2180.929931640625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 926.7683715820312 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8173, loss_val: nan, pos_over_neg: 387.8627624511719 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 1226.68603515625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 641.4188232421875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 6033.982421875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 2482.529052734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 357.2684326171875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 1159.159423828125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 1493.3924560546875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 1677.6651611328125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 603.8197631835938 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 674.0306396484375 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 561.9432373046875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 334.361083984375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 399.0252685546875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8152, loss_val: nan, pos_over_neg: 358.8720703125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 427.7254333496094 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 412.93359375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 438.9312438964844 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8162, loss_val: nan, pos_over_neg: 699.4108276367188 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8166, loss_val: nan, pos_over_neg: 856.6190185546875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 385.64605712890625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 403.0106201171875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 937.644775390625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.824, loss_val: nan, pos_over_neg: 609.4912109375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 736.4808349609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 389.73663330078125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 497.38299560546875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 736.948974609375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 366.1299743652344 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 468.6256408691406 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 433.89373779296875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 1806.80419921875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 664.3115234375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 658.9043579101562 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 774.197998046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 1701.887939453125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 479.3162841796875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 282.85308837890625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 722.1370849609375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 710.86328125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 1108.25 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 919.1700439453125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 731.271240234375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.815, loss_val: nan, pos_over_neg: 602.2167358398438 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 1000.0205078125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 808.900390625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 604.2078857421875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 1126.7119140625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1520.5899658203125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 723.3223876953125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 843.7172241210938 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 612.8182983398438 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 686.744384765625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 575.6328735351562 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 462.97247314453125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 594.08203125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 402.9997253417969 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 528.3252563476562 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 662.3430786132812 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 443.90985107421875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 563.4451293945312 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8179, loss_val: nan, pos_over_neg: 320.2216796875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 677.2987060546875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 467.7087097167969 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 385.75439453125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 684.8018798828125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 455.82525634765625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8197, loss_val: nan, pos_over_neg: 696.2030639648438 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 751.947021484375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 642.511474609375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 1029.7919921875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 1105.10009765625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 650.5270385742188 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 301.7258605957031 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 627.120849609375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 589.7308959960938 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 596.56494140625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8203, loss_val: nan, pos_over_neg: 643.4275512695312 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 482.24090576171875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 2087.58837890625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 484.9422607421875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 1424.002685546875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 729.2522583007812 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8137, loss_val: nan, pos_over_neg: 504.4057922363281 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 2213.58740234375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 1262.3349609375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 816.3905029296875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8169, loss_val: nan, pos_over_neg: 2260.930908203125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 2338.155029296875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 1236.899169921875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 759.2911987304688 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 491.49237060546875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 855.6123657226562 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 514.6741943359375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 610.9224853515625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 697.313232421875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 809.2507934570312 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 447.2563171386719 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 585.6387329101562 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 1242.07275390625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 454.97857666015625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 850.9401245117188 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8167, loss_val: nan, pos_over_neg: 534.25634765625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 717.6690673828125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 833.8004760742188 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 2781.5751953125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8177, loss_val: nan, pos_over_neg: 879.0545043945312 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 873.2664794921875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 915.5911254882812 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 1217.951904296875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 923.6704711914062 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 683.2911987304688 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 651.9796752929688 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8153, loss_val: nan, pos_over_neg: 639.4520263671875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 779.3659057617188 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 895.8731079101562 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 432.7518615722656 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 605.4259033203125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 678.6248779296875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 366.51580810546875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 444.35614013671875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 943.7920532226562 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 422.5785827636719 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 590.3883666992188 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 829.6067504882812 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 374.1181335449219 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 1438.912841796875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 418.08135986328125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 456.906005859375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 551.402587890625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 545.2080688476562 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 928.3632202148438 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 530.2096557617188 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.816, loss_val: nan, pos_over_neg: 460.41168212890625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 422.9637756347656 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8175, loss_val: nan, pos_over_neg: 470.3834228515625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 336.2019958496094 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8168, loss_val: nan, pos_over_neg: 471.9013671875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8153, loss_val: nan, pos_over_neg: 472.78936767578125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 431.24517822265625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 576.881591796875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 540.2484130859375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8112, loss_val: nan, pos_over_neg: 871.9070434570312 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 601.9852905273438 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 713.4906005859375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 580.7798461914062 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 663.7246704101562 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 1201.7154541015625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 582.386962890625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 380.87353515625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8075, loss_val: nan, pos_over_neg: 791.3986206054688 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 1702.52978515625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 1787.1839599609375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 972.836181640625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 1030.8956298828125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 1407.6976318359375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 1908.7767333984375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 954.3912963867188 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 394.3869934082031 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1271.2261962890625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8064, loss_val: nan, pos_over_neg: 579.7183837890625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 495.24981689453125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 868.209716796875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 1064.20263671875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 435.7030944824219 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 530.0988159179688 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 772.604736328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 2380.43505859375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 806.7615966796875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 348.7166442871094 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 668.3764038085938 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 1122.38037109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 579.92138671875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 379.0142822265625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 499.54071044921875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 1168.796875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 740.933349609375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8104, loss_val: nan, pos_over_neg: 670.5765991210938 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 472.83056640625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 935.11865234375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 714.30810546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 390.1725769042969 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 510.5552978515625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 382.47247314453125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 851.0830688476562 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 824.8532104492188 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 519.0655517578125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 906.2153930664062 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 766.5719604492188 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 858.6887817382812 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 485.3473815917969 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8122, loss_val: nan, pos_over_neg: 614.8735961914062 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 533.947265625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 643.5886840820312 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 1061.277587890625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 596.6171264648438 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 795.1245727539062 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 520.03662109375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 757.1956787109375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 946.01318359375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 688.8826904296875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 664.7505493164062 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 872.6712646484375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 697.1812133789062 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 1305.7476806640625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8038, loss_val: nan, pos_over_neg: 813.4403686523438 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 537.7213745117188 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 1458.40283203125 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 743.6881103515625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 1084.9459228515625 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 1138.8489990234375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 534.4567260742188 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 485.159423828125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 390.5928955078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 529.0042114257812 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 2334.989990234375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 675.7506713867188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 473.7375183105469 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 695.1329956054688 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 1723.3941650390625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 659.7634887695312 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 893.8411254882812 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 972.8357543945312 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 1048.65576171875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 587.7943725585938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 344.04107666015625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 984.5750732421875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 754.2061767578125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 577.0736083984375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 543.8947143554688 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 878.4201049804688 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 898.182861328125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 702.3134155273438 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 531.81005859375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 649.7445678710938 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 836.7142333984375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 392.69891357421875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 395.9484558105469 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8126, loss_val: nan, pos_over_neg: 483.6117858886719 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 770.448974609375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 474.16217041015625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 378.6313171386719 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 705.0174560546875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 475.9314270019531 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8088, loss_val: nan, pos_over_neg: 551.8212890625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 585.5553588867188 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 509.6341552734375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 826.9478149414062 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 509.6580505371094 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 311.755859375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 710.3956298828125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 3554.033935546875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 1218.551025390625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 780.0655517578125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8158, loss_val: nan, pos_over_neg: 358.5574035644531 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1155.6334228515625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 485.8587951660156 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 329.737548828125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 514.7277221679688 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 825.9283447265625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.807, loss_val: nan, pos_over_neg: 882.2424926757812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 657.8804931640625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 588.118896484375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 668.9876098632812 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 1577.0992431640625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 840.33740234375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 575.572998046875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 623.2982788085938 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 521.9666137695312 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 956.6228637695312 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 1333.360107421875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 662.2750244140625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 477.8021240234375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 491.6752624511719 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 2012.102783203125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 459.1629333496094 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 733.5505981445312 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 1050.111328125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1593.78369140625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 799.0186157226562 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 476.18896484375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 536.7991333007812 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 563.196533203125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8049, loss_val: nan, pos_over_neg: 917.0784912109375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 842.99658203125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 499.5499572753906 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 1735.73828125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 7925.0439453125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 434.5365905761719 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 414.416015625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 1081.508544921875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 690.9625854492188 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 681.1044311523438 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 1442.1900634765625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 536.681396484375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 628.2658081054688 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 970.8355102539062 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 1339.8277587890625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8094, loss_val: nan, pos_over_neg: 434.9658203125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 379.25299072265625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 774.6320190429688 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 1224.65625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 624.5450439453125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 523.8099975585938 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 652.3477172851562 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 362.9884948730469 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 343.8351745605469 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 957.7969360351562 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 411.5618896484375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 456.4035949707031 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 1652.3089599609375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 422.83001708984375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 831.4210205078125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 678.5230712890625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 539.6493530273438 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 415.9213562011719 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 596.9321899414062 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 1128.2242431640625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 534.04052734375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 421.006103515625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8028, loss_val: nan, pos_over_neg: 964.0458984375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 1808.47998046875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 508.46441650390625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 469.20147705078125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 811.8060302734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 640.4015502929688 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 544.9495239257812 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 1012.517822265625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 609.8886108398438 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 7128.17626953125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 856.867919921875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 415.0548400878906 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 488.21649169921875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 382.7571105957031 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 494.62261962890625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 477.3162536621094 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 433.7618103027344 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 643.8600463867188 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 1290.12841796875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 768.8301391601562 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 459.1131591796875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 797.3894653320312 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 1015.5499877929688 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 661.0585327148438 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 736.913818359375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1802.028076171875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 990.3292236328125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 546.9397583007812 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 1269.60693359375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 1106.9832763671875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 567.3433227539062 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 1633.460205078125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 1607.07568359375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1152.3057861328125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 2759.1015625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 1218.7510986328125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 976.234130859375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 858.1039428710938 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 873.7568359375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 1252.5313720703125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 530.8359985351562 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 1754.0323486328125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 730.772705078125 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 654.2706298828125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 661.907470703125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 941.86279296875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 522.1565551757812 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 876.4891967773438 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 426.4448547363281 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8028, loss_val: nan, pos_over_neg: 521.7489624023438 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 586.3397216796875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 730.556640625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 587.36474609375 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 361.3953857421875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 506.34478759765625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 643.8887329101562 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 607.2106323242188 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 980.0944213867188 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 537.9724731445312 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 3781.333984375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 867.7156982421875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 495.3766784667969 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 1159.2322998046875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 491.358642578125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 1307.0699462890625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 555.8013916015625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 425.6192626953125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8032, loss_val: nan, pos_over_neg: 609.585693359375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 473.06573486328125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 572.9671020507812 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 1583.2498779296875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 616.0672607421875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8064, loss_val: nan, pos_over_neg: 356.7377014160156 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 536.14794921875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 516.6758422851562 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 806.3627319335938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 652.0236206054688 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.803, loss_val: nan, pos_over_neg: 605.2034912109375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 485.40008544921875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 1021.1365356445312 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 910.822021484375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 520.847900390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 589.6528930664062 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 1185.1348876953125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 949.3745727539062 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 620.530029296875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 891.7156372070312 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 746.4663696289062 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 730.1854248046875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 631.7598876953125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 668.3384399414062 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1695.3116455078125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 1083.4205322265625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 729.3195190429688 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 1547.2139892578125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 1117.614990234375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 690.2161254882812 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 606.9176635742188 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 1124.1728515625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 864.0062866210938 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 1159.15087890625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 1207.186279296875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 675.849365234375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 1955.80517578125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 546.3269653320312 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 1896.380615234375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 784.8008422851562 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 526.3732299804688 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 857.0545043945312 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 706.813720703125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1225.5635986328125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 724.7910766601562 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 858.4526977539062 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 855.8195190429688 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 447.54498291015625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 633.2122802734375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 1023.9971313476562 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 604.3153686523438 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 638.7923583984375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 2158.329833984375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 721.8656005859375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 706.6146850585938 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 423.3343811035156 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 1022.8851318359375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1551.627197265625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 865.9823608398438 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 746.4150390625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 500.8408203125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 594.3768920898438 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1557.5843505859375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 671.8844604492188 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 560.09912109375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 466.7461853027344 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 941.2637329101562 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 1413.630126953125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 968.998046875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 935.9346313476562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 921.562255859375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 466.110107421875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 1958.26025390625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 638.2957153320312 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 724.8153076171875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 588.1596069335938 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 485.6064453125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 1157.274169921875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 909.4971313476562 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 479.06103515625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 682.496337890625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 675.5211181640625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 667.9928588867188 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 874.9114379882812 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 533.849365234375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 493.0564880371094 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 741.49951171875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 1072.4754638671875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1018.7433471679688 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 503.07379150390625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 569.23681640625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 842.5955200195312 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 2173.865478515625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 649.0989990234375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1437.5538330078125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 688.3198852539062 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 1018.0075073242188 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 545.3466186523438 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 972.3363037109375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 712.7850341796875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 546.4573974609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 719.1783447265625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 1704.4434814453125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 649.9447631835938 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1415.0623779296875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 661.9866333007812 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 454.5727844238281 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 401.0436706542969 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 1234.8714599609375 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 818.74951171875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 442.328369140625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 488.0174255371094 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 733.9201049804688 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 939.396484375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 961.26123046875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 839.3538208007812 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 907.5137329101562 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 356.4577941894531 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 1280.0614013671875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 1403.512451171875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 914.5428466796875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 506.4419860839844 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 537.1762084960938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 756.291748046875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 924.1920776367188 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 516.955322265625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 502.67913818359375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 623.6324462890625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 1141.4669189453125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 719.0401611328125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 649.2711791992188 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 883.7443237304688 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 1148.01025390625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 576.3505249023438 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7932, loss_val: nan, pos_over_neg: 1094.653076171875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 1195.3658447265625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 578.1932373046875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 582.7999267578125 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 720.0486450195312 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 1490.5655517578125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 792.9171142578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1050.5106201171875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 904.8412475585938 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 1017.9303588867188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1450.689208984375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 856.600341796875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 481.3893127441406 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 831.8634643554688 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 725.3458251953125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 37623.7578125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 1469.778076171875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 862.1202392578125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 1209.5262451171875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1232.1822509765625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 1226.727783203125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1680.1563720703125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1019.2022094726562 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 817.1326293945312 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 415.6828308105469 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 676.62841796875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 1105.5633544921875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 870.1123046875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 860.3096313476562 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 521.5769653320312 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 662.4168701171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 2456.1962890625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 801.4794921875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 723.2429809570312 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 565.2657470703125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 1366.7054443359375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 809.7364501953125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 521.2547607421875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 483.02105712890625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 715.6849365234375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 1145.3878173828125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1093.975830078125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 720.6135864257812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 471.4652404785156 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1806.81298828125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 758.32470703125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 849.4337158203125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 697.8895263671875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 547.8289794921875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 1383.0438232421875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 845.6901245117188 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 651.4674072265625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 505.9544982910156 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 1696.514404296875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 741.22705078125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 636.5236206054688 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 1028.59033203125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 1464.92626953125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 673.893310546875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1029.4140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 663.7100219726562 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1597.818115234375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 471.7082214355469 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 303.7674865722656 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 622.6654052734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1121.0238037109375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1070.09765625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 911.9268188476562 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 923.1475219726562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1544.01513671875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 1572.396484375 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 1613.3787841796875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1194.4842529296875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 619.9692993164062 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1153.6573486328125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 849.454833984375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1013.458984375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 502.37432861328125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1498.1171875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 3626.615478515625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 1683.4508056640625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 4054.21337890625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1283.6279296875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 700.9979248046875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 884.3660278320312 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 1098.8795166015625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 877.2803955078125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1194.3807373046875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 1256.425537109375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 830.0621948242188 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 2033.3248291015625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 901.6048583984375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 623.8736572265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 577.7469482421875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 854.5260620117188 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 621.9373168945312 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 550.0579223632812 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 469.7515869140625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 716.8029174804688 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1144.545166015625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 601.7817993164062 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 501.914794921875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 652.34326171875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 1190.7755126953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 470.0259704589844 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 623.2373046875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 460.44708251953125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 483.3597412109375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 403.4478454589844 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 763.895751953125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 815.9918823242188 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 704.4000244140625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 550.1887817382812 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 649.589599609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 1364.98828125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 914.28759765625 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 2012.453125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 533.1202392578125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 792.8777465820312 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 1265.0552978515625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 865.1387329101562 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 1721.052734375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 857.5718383789062 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1863.5194091796875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 1183.36767578125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 1867.2506103515625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1390.6331787109375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1603.9561767578125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 1494.6002197265625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 482.46844482421875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 642.0213623046875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [41:05<102736:51:58, 1232.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 724.3930053710938 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 1201.9158935546875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 2244.66259765625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 430.5342102050781 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 626.291748046875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1172.35791015625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 835.0794067382812 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 764.2077026367188 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 840.1447143554688 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 620.227294921875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1177.754150390625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1151.77001953125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 348.13604736328125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 438.56414794921875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1496.75 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1443.302734375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 908.5895385742188 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 1334.438232421875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 592.3383178710938 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 1346.535888671875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 2892.77490234375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 887.9925537109375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 539.065673828125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 502.7187805175781 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 885.8357543945312 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 1176.6009521484375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 811.042724609375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 315.38623046875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 704.9727172851562 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 797.4718017578125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 575.2963256835938 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 582.0376586914062 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 597.0794067382812 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 4062.118408203125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1261.271240234375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 711.8606567382812 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 922.4844360351562 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 465.7955017089844 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 577.5223388671875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 1128.503662109375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1443.7210693359375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 812.3889770507812 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 1031.4666748046875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 561.1472778320312 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 773.157470703125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 886.3502807617188 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 819.7889404296875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 550.060302734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 826.788818359375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 763.9710693359375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 840.2200317382812 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 1102.854736328125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 463.2434387207031 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 655.5379638671875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 641.0249633789062 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 583.2935180664062 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 800.5714721679688 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 466.8383483886719 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 664.3200073242188 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 329.36590576171875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 768.0330810546875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 1138.5394287109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 546.9310302734375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 540.0394897460938 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 824.3797607421875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 870.6693115234375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 420.67974853515625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 622.3526000976562 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 569.7347412109375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 431.0658264160156 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1143.9029541015625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 444.6146240234375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1178.0699462890625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 550.1353149414062 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 563.5213012695312 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1829.6107177734375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 746.33251953125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 600.791748046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 762.3448486328125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 679.065185546875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1221.7880859375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 857.3890380859375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 482.0655517578125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 1012.8381958007812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 575.6546630859375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 797.8084716796875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 756.198486328125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 1492.470458984375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 3184.623046875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 583.5540161132812 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 939.5029296875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 407.4434814453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 381.99041748046875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1064.7142333984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 596.9783325195312 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 533.5936889648438 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 528.2655029296875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1208.355712890625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1944.2691650390625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 467.3396301269531 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 1023.1339111328125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 396.3404846191406 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 590.1669921875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7933, loss_val: nan, pos_over_neg: 780.7333374023438 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 588.9022827148438 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 661.7670288085938 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 813.1373291015625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 654.0759887695312 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 908.41845703125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 680.4024658203125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1087.9937744140625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 669.3040161132812 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 859.189208984375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 344.152099609375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 944.9771728515625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 755.6168823242188 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 2023.11572265625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 513.9039306640625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 657.6314086914062 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 474.8557434082031 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 660.021728515625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 730.3541870117188 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 431.8539123535156 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 701.4269409179688 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 2343.71142578125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 744.4559326171875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 607.9195556640625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 931.28271484375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 390.47479248046875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 633.3516845703125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 755.1139526367188 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 577.0468139648438 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 800.005859375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 640.9368286132812 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 657.35498046875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 578.797119140625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 608.5211181640625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 656.7185668945312 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 712.8452758789062 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 398.8460693359375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 658.2979125976562 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 890.0187377929688 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 635.3085327148438 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 940.4547119140625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 776.4760131835938 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1474.76953125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 1034.277099609375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1052.251708984375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 1532.7098388671875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 704.2489013671875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 1047.4930419921875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 851.4295043945312 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 1112.4444580078125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 461.0573425292969 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 602.1358642578125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 610.3892211914062 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 828.9769287109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 622.5206909179688 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 702.8347778320312 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 793.015625 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 528.898193359375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 578.887939453125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1182.186279296875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 955.3357543945312 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 585.0310668945312 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 594.1452026367188 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 661.67333984375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 882.90478515625 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 788.6522216796875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 490.0376892089844 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 978.8841552734375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1148.52490234375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 670.4725952148438 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 538.5413208007812 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 627.8648681640625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 646.4127197265625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1118.62890625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 323.2146911621094 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 487.38665771484375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 908.1773681640625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 3004.61083984375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 639.1220703125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 416.7198486328125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 684.8115234375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 989.383056640625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 488.7938537597656 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 433.3251037597656 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 621.2537231445312 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 898.3868408203125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 656.8615112304688 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1318.3905029296875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 476.4703063964844 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 797.6028442382812 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 634.54736328125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 671.6155395507812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 810.1262817382812 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 907.4165649414062 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 639.571044921875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 845.664794921875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 643.1565551757812 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 548.7400512695312 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 656.38330078125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 711.31201171875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 806.6524047851562 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 735.3155517578125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 643.3574829101562 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 2137.719482421875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1368.49365234375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1088.63916015625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1853.2109375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1844.6136474609375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 499.4566955566406 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 808.5485229492188 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 767.8034057617188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 927.9896240234375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 1587.0849609375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 1125.726806640625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1410.8935546875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 665.5909423828125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 935.3954467773438 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1752.732421875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 559.49951171875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 836.0909423828125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 634.4410400390625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1414.1522216796875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 954.5809326171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1090.5281982421875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 750.9763793945312 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 978.9118041992188 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 1375.301025390625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 2135.1787109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 717.0054321289062 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 435.88800048828125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 429.135009765625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 1130.013427734375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 2799.949951171875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1752.2716064453125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 3099.580078125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 766.426025390625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 1402.5120849609375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 1095.3258056640625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 2711.401611328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 867.8486328125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 1506.0902099609375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 793.1217651367188 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 699.7759399414062 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 582.6475219726562 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1193.697998046875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 1537.9810791015625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 629.0814819335938 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 493.6322021484375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 840.8731079101562 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 569.0083618164062 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 718.4776000976562 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 897.943603515625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 801.84765625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 490.5522155761719 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 753.9550170898438 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 2049.645751953125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 766.8724975585938 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 846.3890991210938 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 2136.960693359375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 676.6845092773438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 590.8648071289062 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1358.4464111328125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1009.3780517578125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1368.351318359375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1351.55712890625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 397.3365173339844 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 598.6039428710938 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1307.621337890625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1216.8011474609375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 883.3825073242188 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 1001.50390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 707.7366333007812 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 823.691162109375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 752.890869140625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 1553.6778564453125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1523.9036865234375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 613.3063354492188 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1032.86328125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1487.1876220703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 724.7564086914062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 594.6554565429688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1233.6744384765625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 621.9412841796875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 678.3218994140625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 441.2156066894531 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 523.593994140625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 571.0250244140625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1386.8851318359375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 606.922607421875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1052.0865478515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 1178.161376953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 808.121826171875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 656.1209106445312 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 736.6035766601562 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 3049.1005859375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1499.3306884765625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 571.5401000976562 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 996.0636596679688 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 819.061767578125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 789.9547119140625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1007.6793823242188 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1157.7742919921875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 698.3949584960938 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 1655.939453125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 786.7567138671875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 695.45947265625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 3411.245361328125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 551.6386108398438 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 527.0109252929688 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1247.8289794921875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 1062.978515625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 515.6482543945312 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 742.7123413085938 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 443.0167236328125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 779.1709594726562 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 924.0355224609375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 738.9909057617188 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1093.077392578125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 876.7951049804688 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 494.0279235839844 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 2015.8358154296875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 989.665771484375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 442.6564636230469 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 378.89031982421875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 911.3136596679688 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1370.292236328125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 971.0836181640625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1000.1177978515625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 914.0799560546875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 657.662109375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 592.4545288085938 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 988.9271240234375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 853.0933837890625 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 856.6325073242188 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 882.0394287109375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 2036.11328125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 1008.9032592773438 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 582.7003173828125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 1004.9915771484375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 921.1022338867188 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 741.1400756835938 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 490.09197998046875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 364.81268310546875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 921.9945678710938 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 645.2422485351562 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 710.5584716796875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1139.38720703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 1260.56884765625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 671.4712524414062 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 986.4515991210938 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 609.3965454101562 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 423.81207275390625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 977.6632690429688 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 579.9698486328125 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 519.405517578125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 606.2074584960938 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 716.2667846679688 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 901.2449951171875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 319.8618469238281 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 654.2353515625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 849.6389770507812 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 517.521484375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 587.4661254882812 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 480.4108581542969 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 1247.8487548828125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 576.6929321289062 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 611.859619140625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 678.0615844726562 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 556.7138671875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 992.8502197265625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 675.070068359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1264.8331298828125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 464.82635498046875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 860.2899169921875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 732.5602416992188 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1100.15283203125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1287.8175048828125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 591.2576904296875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 672.564697265625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 655.8758544921875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1031.0233154296875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1356.539306640625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 936.0636596679688 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 463.1073913574219 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 581.6195678710938 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 639.3225708007812 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1221.9287109375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1230.3704833984375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 550.8204956054688 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 503.43365478515625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 470.60369873046875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 802.2674560546875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 1258.917724609375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 714.8732299804688 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 396.9356994628906 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 402.76251220703125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1421.5517578125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1165.0992431640625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1027.3021240234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 607.0294189453125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 476.93170166015625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1054.447265625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1517.1678466796875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 1238.84228515625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 677.2702026367188 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 443.0380554199219 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1117.1103515625 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1121.1470947265625 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 589.3674926757812 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 1689.6185302734375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 657.51025390625 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 3136.249755859375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 1213.16796875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 944.4323120117188 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2727.631103515625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 2290.829345703125 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 650.7697143554688 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1807.444091796875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1801.64892578125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 676.8078002929688 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 2183.1396484375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1262.4014892578125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 2830.834716796875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 751.5320434570312 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1132.5499267578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 493.8045349121094 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 602.888427734375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 629.5725708007812 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1746.0076904296875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1563.180908203125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 1041.39208984375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1439.83837890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1333.4215087890625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 855.043701171875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1365.3671875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 788.9750366210938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 1211.936279296875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1165.3338623046875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 742.0060424804688 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 2920.602783203125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 4117.24951171875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 926.472900390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 2907.68115234375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1372.06103515625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 618.7511596679688 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 798.328857421875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 1023.0452270507812 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 632.01708984375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 993.60888671875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1088.8046875 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1235.2421875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 1015.8865356445312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 544.0628662109375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 2804.890380859375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 390.4808349609375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 660.9501342773438 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 972.7112426757812 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 553.4803466796875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1348.623779296875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 661.8927612304688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 734.13037109375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 590.5958862304688 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 843.4293212890625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 2599.08447265625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1465.4154052734375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 516.078857421875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 489.60333251953125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 583.2010498046875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 731.4058837890625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1525.4647216796875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 1708.2442626953125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 665.37744140625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 416.9092712402344 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1472.5166015625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 959.901611328125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 698.2230224609375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 580.9950561523438 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 853.3333129882812 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1774.515869140625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 2259.495849609375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1016.1201782226562 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 610.0234985351562 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 564.04833984375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 588.836669921875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 823.8233032226562 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 814.723876953125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 780.1739501953125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 991.6884765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1295.5743408203125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 878.90625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 1248.9730224609375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1471.2513427734375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 798.952880859375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 923.867431640625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 761.4691162109375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 689.0166015625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 1200.589111328125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1271.6622314453125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 856.9720458984375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 772.1983642578125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 3230.216064453125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1288.58154296875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 936.306396484375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 682.095947265625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 546.7369995117188 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1075.8385009765625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 700.4226684570312 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 635.1922607421875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 924.3461303710938 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 883.173095703125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 542.2943115234375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 827.0676879882812 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 608.5228881835938 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1346.0191650390625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1352.6866455078125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 946.0851440429688 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1052.2005615234375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 1333.3475341796875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1126.0045166015625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1062.6514892578125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 2787.380126953125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 372.33428955078125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1182.416259765625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1827.0406494140625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 416.3896789550781 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 559.6304321289062 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 453.7890625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1031.4903564453125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 522.5239868164062 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 696.2603149414062 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 662.3294677734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1319.7340087890625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 624.1215209960938 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 483.0776672363281 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 657.8204956054688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1362.4405517578125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1088.28466796875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 848.0132446289062 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 652.1152954101562 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 2515.96630859375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 1066.080078125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 567.8597412109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 455.86383056640625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1096.3681640625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 605.3374633789062 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 1062.329833984375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 547.5086669921875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 995.5543823242188 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 521.3347778320312 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 611.5047607421875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 779.4934692382812 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 653.3134155273438 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 440.7424011230469 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 844.18408203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 613.546142578125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 382.34552001953125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 728.8699340820312 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 823.8004760742188 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 951.891357421875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 716.432373046875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 333.4165954589844 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 645.5667114257812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 787.3324584960938 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 431.2933654785156 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 645.8456420898438 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 834.7578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 659.0805053710938 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 913.962646484375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 808.0700073242188 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 793.8768310546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 826.6168823242188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1035.9146728515625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 659.4055786132812 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 664.2909545898438 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 792.9194946289062 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1136.01220703125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 804.8558349609375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 749.3307495117188 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1301.9207763671875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1241.1805419921875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1518.8834228515625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1261.43359375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1146.967041015625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1175.706298828125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1125.74267578125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 919.5171508789062 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 857.0787353515625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 706.6017456054688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1855.3668212890625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 756.4385986328125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 776.701171875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 786.5992431640625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 1373.77001953125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 1288.7666015625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1077.3486328125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 850.8241577148438 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 893.4186401367188 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1464.3431396484375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 813.3597412109375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 889.10888671875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 658.9889526367188 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 960.1105346679688 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1022.810546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1182.8310546875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 829.9506225585938 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 867.6143188476562 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 964.9081420898438 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 936.4375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1027.3184814453125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1180.8636474609375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 844.6327514648438 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1345.7437744140625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1868.69189453125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 987.6175537109375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 824.3359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 1395.8682861328125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 813.408447265625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 914.1832885742188 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 825.5884399414062 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 991.6984252929688 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1004.0665283203125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 464.6661071777344 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1464.9600830078125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1160.749267578125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1524.5284423828125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 865.8901977539062 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 482.58258056640625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 1196.68701171875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 743.613037109375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1390.1051025390625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 830.4119873046875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 777.8389892578125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1444.5672607421875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1883.8948974609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 673.9883422851562 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 821.5248413085938 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 463.8523254394531 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 634.9339599609375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1162.205322265625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 599.1289672851562 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1465.610107421875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 739.9853515625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 827.1959228515625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 1172.3001708984375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1881.2457275390625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1003.5679321289062 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 886.2670288085938 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 560.6842651367188 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 641.6329345703125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 2230.97265625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 763.3800659179688 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 781.1688232421875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 826.4129638671875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1102.4700927734375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 668.1226806640625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 563.7305908203125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1408.1953125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1225.9786376953125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 891.934326171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 806.7689819335938 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 914.8496704101562 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 973.85400390625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 4376.2998046875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 586.3743896484375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 696.7428588867188 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1307.1448974609375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 815.0255126953125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 5416.5244140625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 891.6075439453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 657.21875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 433.0115661621094 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 691.7605590820312 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 765.9154052734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 707.3366088867188 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 633.7153930664062 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2309.933837890625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 879.4631958007812 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 966.3067016601562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 935.30859375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1108.0421142578125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 597.591796875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 619.3667602539062 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1063.52880859375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1010.3697509765625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 712.7491455078125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 640.7702026367188 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1038.6888427734375 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 1399.1893310546875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 922.855712890625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 623.5573120117188 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2305.294677734375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1286.82666015625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:01:36<102679:51:34, 1232.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1280.7095947265625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 859.1217651367188 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1021.0913696289062 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1258.7589111328125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1103.7548828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1813.1912841796875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1506.253173828125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1016.82470703125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1076.43798828125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 841.2095336914062 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 752.9331665039062 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 781.5733032226562 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 1254.24609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 884.2095947265625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1007.05810546875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1094.2650146484375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 1170.506591796875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1410.444091796875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 902.4143676757812 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2037.599609375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1213.54345703125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1091.3780517578125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 4096.08740234375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1304.4462890625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 822.5621948242188 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 632.7693481445312 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 867.4949340820312 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1258.366943359375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 2066.941650390625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1102.9578857421875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1550.197998046875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1369.0218505859375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 833.5358276367188 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1871.6302490234375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1308.72802734375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1411.0374755859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 2958.510498046875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1026.53466796875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1964.2840576171875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 2056.35302734375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1733.676025390625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 761.1174926757812 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 846.6138305664062 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 2066.2880859375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 700.4956665039062 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 804.121337890625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 802.294189453125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 775.5609741210938 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1397.24755859375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 712.2144775390625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 817.6162109375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 532.390869140625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 651.3143310546875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 772.370361328125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 882.5807495117188 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 2509.115478515625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 881.7333374023438 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 722.6307373046875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1243.2928466796875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1376.9095458984375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1142.26171875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1041.1988525390625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 829.473388671875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 599.372802734375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 583.7250366210938 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 855.2197875976562 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 596.9999389648438 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 858.1329345703125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1159.0791015625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 974.2547607421875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 793.9979858398438 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 991.1483764648438 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 698.4271850585938 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 866.4871215820312 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 563.8948974609375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 465.86090087890625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 654.92041015625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 632.42724609375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1584.2919921875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 761.0327758789062 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1285.3795166015625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1250.614013671875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1042.1265869140625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1119.280029296875 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 693.47607421875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 653.0020141601562 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1155.95703125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 760.7098999023438 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 564.642333984375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1017.8692016601562 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 690.484619140625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 861.564697265625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 425.2555847167969 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1593.5316162109375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 822.8994750976562 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 682.7667846679688 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 808.9656982421875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 762.2722778320312 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 734.7501220703125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1128.7945556640625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1523.690673828125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 501.25372314453125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 969.9266967773438 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 780.5678100585938 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1590.15087890625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1147.110107421875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 2797.169677734375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 810.7481079101562 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 774.5445556640625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1544.069580078125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 840.32958984375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 777.4915771484375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1201.593017578125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 758.6939697265625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 520.6668701171875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1647.8680419921875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1094.798095703125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 519.9625244140625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 928.1497802734375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 8065.2060546875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 941.3767700195312 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1144.685546875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 2298.4794921875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1497.33984375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1157.526123046875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 738.4834594726562 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 793.9220581054688 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1394.5426025390625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 8525.470703125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1378.6661376953125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1016.4152221679688 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1134.5206298828125 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1696.4512939453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1169.2603759765625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1340.822265625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 936.31689453125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 783.7926635742188 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 1687.6446533203125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1987.531005859375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1592.0594482421875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 2445.43798828125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1214.197265625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1159.3033447265625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 3946.6962890625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 836.5857543945312 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 556.5744018554688 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 545.6654052734375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 2031.81103515625 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 749.0364990234375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 883.973876953125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 635.7218017578125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 897.2379760742188 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3718.390380859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 2086.417724609375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 800.1785888671875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 924.9100341796875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1639.3485107421875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 2801.644287109375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1395.670166015625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 782.4204711914062 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 829.5516357421875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 751.508056640625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 694.5678100585938 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 2021.28759765625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1209.050048828125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 750.406494140625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 814.4484252929688 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 814.1019287109375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 2042.0538330078125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1329.7056884765625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 548.9470825195312 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 629.2607421875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 597.537109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 868.6279296875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1124.239501953125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1064.2303466796875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 907.8082275390625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 764.5259399414062 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1154.398193359375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1245.727783203125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 938.0167846679688 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 979.33984375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1770.701416015625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1028.00439453125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 789.7951049804688 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 959.0387573242188 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 880.3931274414062 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 623.2890014648438 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 485.2953186035156 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1186.3099365234375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1164.6351318359375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 837.224365234375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 788.4578247070312 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1199.20068359375 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1131.1409912109375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 1297.8232421875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 832.6542358398438 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1709.0908203125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1346.8035888671875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 849.2589721679688 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 852.7382202148438 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1341.379638671875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 786.2879638671875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1818.00390625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 520.4985961914062 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 666.7454833984375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 691.0364990234375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 570.6001586914062 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 657.2035522460938 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1054.951171875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 883.1854858398438 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 666.7731323242188 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 774.9232177734375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 717.0786743164062 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 649.3096923828125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 6887.2333984375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1029.5550537109375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 557.3704833984375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1121.866455078125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 12825.9150390625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 627.8457641601562 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 530.3848876953125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 814.0894775390625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1961.7127685546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 775.1314697265625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 707.9967041015625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 811.2948608398438 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 881.2974243164062 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 736.9241333007812 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 950.7888793945312 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 824.9921264648438 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 583.178466796875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1040.476806640625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 979.6951293945312 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 924.4324340820312 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 841.6129760742188 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1079.9112548828125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 741.3685302734375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 611.2942504882812 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 4633.1533203125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1050.7274169921875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 650.59912109375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1315.169677734375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 2159.45751953125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 738.8565673828125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 764.2434692382812 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 728.6211547851562 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1012.5321044921875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 11983.6484375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1893.52392578125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 2759.165771484375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1560.7236328125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 1934.88232421875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 1393.681640625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1924.3804931640625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 5208.466796875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 840.040771484375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 786.8656005859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 898.2841186523438 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1181.796630859375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1244.605224609375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 698.2120361328125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1369.151123046875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1479.56494140625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2035.6309814453125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 833.3828125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 660.3118896484375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1229.8917236328125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 552.359375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 4105.42529296875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1125.2568359375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 466.3746032714844 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 1066.258544921875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1476.8482666015625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1308.85302734375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1392.531005859375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1011.716064453125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1829.5625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 986.5070190429688 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 690.496826171875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 454.4317932128906 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 767.0706787109375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 777.7661743164062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 958.3232421875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2378.1767578125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 933.1422119140625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1325.6787109375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 947.8327026367188 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 541.6334838867188 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1791.513427734375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1564.701904296875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 492.5316162109375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 817.7928466796875 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2127.0888671875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 696.9768676757812 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 526.275634765625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1919.093505859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 982.088623046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1310.72607421875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 643.1694946289062 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1411.4947509765625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 2013.130859375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1331.0704345703125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 697.79541015625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1121.880126953125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1147.21240234375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 3941.111083984375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 940.47021484375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 497.22943115234375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 636.3535766601562 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1258.544921875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1722.2281494140625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1269.5042724609375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1428.9456787109375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 624.3121337890625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1741.8720703125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1509.453857421875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 695.9024047851562 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1004.5075073242188 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 759.6696166992188 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 5925.26220703125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1119.5374755859375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 961.3175659179688 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1080.424560546875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1140.736328125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 1396.5703125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1030.9742431640625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 820.8782958984375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 713.9854736328125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 671.7759399414062 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 745.6565551757812 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 799.5889282226562 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1005.2032470703125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 449.70831298828125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 882.5437622070312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1344.168701171875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 833.9199829101562 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 734.8881225585938 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1144.156494140625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1363.227294921875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: -205439.046875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: -28849.07421875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1164.5269775390625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 737.7466430664062 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 719.6798095703125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 515.8712158203125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 1116.267822265625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 2079.27294921875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 571.27783203125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 715.5171508789062 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 789.1732788085938 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 938.773193359375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 883.2628784179688 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 591.7420654296875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 814.9149780273438 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 436.5791320800781 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1057.8629150390625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 2257.223876953125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1079.7801513671875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 565.5315551757812 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 819.4485473632812 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1134.1063232421875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 691.8439331054688 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 630.9650268554688 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 556.5285034179688 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1168.05126953125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 732.8079223632812 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 666.33203125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 755.0948486328125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1306.2574462890625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 729.6446533203125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 568.7118530273438 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 688.2799682617188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 640.0827026367188 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 779.5526733398438 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 749.1198120117188 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1131.338134765625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 945.826904296875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 704.8761596679688 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 797.2066650390625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1438.2945556640625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 929.9468994140625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 842.4412841796875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 703.9569091796875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1060.5810546875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 906.0789184570312 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 695.5486450195312 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 714.27587890625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 667.6702270507812 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 764.3971557617188 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 873.1778564453125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1055.3455810546875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1319.4168701171875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 682.2357177734375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 554.9981079101562 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 2673.2890625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 2391.297119140625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 616.3489990234375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 624.9263916015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1255.8712158203125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1571.599365234375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 441.40850830078125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 3111.265625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 2887.06005859375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 992.3614501953125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 610.1478881835938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1275.6383056640625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1966.2293701171875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1134.806884765625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 722.0926513671875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 895.3992309570312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 530.3782348632812 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1450.676513671875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1724.8826904296875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 812.1495361328125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1004.9214477539062 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 657.72216796875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1064.84228515625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 6030.99609375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 872.1748046875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 565.328125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1270.5504150390625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2138.617431640625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1070.880859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 987.4310913085938 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 494.8869323730469 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 869.1771850585938 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 621.8594360351562 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 663.220703125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 698.7744750976562 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 922.3487548828125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 640.789306640625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 867.5147705078125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1857.795654296875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 711.4390869140625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 570.1812133789062 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1401.3695068359375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 769.2960815429688 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 428.7864685058594 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 531.733642578125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 604.4739379882812 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 668.6077270507812 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 778.5337524414062 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1199.4102783203125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1255.686767578125 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1049.613037109375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 871.7492065429688 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 952.1896362304688 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 628.1857299804688 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 754.5784912109375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 681.4129638671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1032.605224609375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 2850.3115234375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1107.376708984375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1629.1204833984375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 3066.58984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 910.53662109375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 812.0999755859375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 665.7659912109375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1820.70361328125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 840.5935668945312 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 956.8451538085938 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 651.5776977539062 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 742.1880493164062 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1082.7193603515625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 824.6403198242188 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1303.12353515625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1046.549560546875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 580.8323974609375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 605.0438232421875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 655.269287109375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1020.6323852539062 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1417.58251953125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 434.4497375488281 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 658.6763305664062 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 643.302490234375 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1934.238037109375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1411.640380859375 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1109.5380859375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 795.7522583007812 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1064.78564453125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 901.7568969726562 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 449.9353332519531 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1838.990478515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1030.9764404296875 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 967.341796875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 904.8040161132812 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1211.8404541015625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1258.8865966796875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 986.00341796875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1643.108154296875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 639.79248046875 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 691.7601318359375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3580.47216796875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 6708.52734375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1360.9285888671875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 3165.318115234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: -8042.234375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 2036.619384765625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 7076.326171875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1809.25537109375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1365.929443359375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1004.7141723632812 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 785.5567626953125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1021.1776733398438 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1552.2459716796875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 2084.927490234375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 788.9459838867188 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 903.3848876953125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1518.34423828125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 2776.677734375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1275.3594970703125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1263.549072265625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1706.8380126953125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 910.1526489257812 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 971.1410522460938 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1052.90625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 993.5390014648438 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 959.3857421875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1244.332275390625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 2081.08154296875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2551.02978515625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 682.73291015625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1055.671875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1468.8114013671875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 921.1692504882812 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 790.4170532226562 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 912.9087524414062 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 899.417236328125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 3180.155517578125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 746.7435913085938 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 751.335693359375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 724.7034301757812 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 898.1107177734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 3101.848876953125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 975.6795654296875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 617.6768798828125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 544.5431518554688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 550.6539916992188 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 699.1010131835938 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1735.514892578125 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1818.6160888671875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1006.9115600585938 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 796.4638671875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 572.915771484375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 2408.704345703125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1262.6676025390625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 716.73681640625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 786.82861328125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 931.0972900390625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1150.4306640625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 906.0277099609375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1180.150390625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 787.240234375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1182.772216796875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 691.7395629882812 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1271.14794921875 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1332.0465087890625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1277.429443359375 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 888.9134521484375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 973.9036865234375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 861.8340454101562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 927.3185424804688 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 601.9541625976562 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 745.0863037109375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1401.2314453125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 936.3766479492188 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 538.0115356445312 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 801.617431640625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 508.7646789550781 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 636.9368286132812 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1453.224609375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1082.063720703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 948.968505859375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 2159.653076171875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 568.3479614257812 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1179.4638671875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 800.9559326171875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1560.2427978515625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1354.12451171875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 841.08154296875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 823.1797485351562 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1681.869873046875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 4205.1279296875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 2640.050537109375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 776.8471069335938 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 851.9050903320312 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 860.5357055664062 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 2155.4091796875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 798.7064208984375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 707.4542846679688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1576.0994873046875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 863.2930297851562 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 649.4166870117188 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 530.300048828125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 539.5927124023438 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 660.8511352539062 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 826.841064453125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1513.513427734375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1013.2348022460938 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 841.7986450195312 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 778.99560546875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 752.5531005859375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 703.8623046875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 807.4041748046875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1005.4273071289062 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1046.6884765625 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1373.611572265625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1063.104736328125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 2204.70654296875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1878.92822265625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1471.5787353515625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 2344.89453125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1004.6243286132812 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 3153.95947265625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1746.487060546875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 2271.455078125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 4128.5087890625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 3349.4345703125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1666.073486328125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 189611.28125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1368.6234130859375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 5851.51806640625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1204.3375244140625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2047.3553466796875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 3533.177734375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 983.6844482421875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 2585.90673828125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1354.372802734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1065.702880859375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 2627.160400390625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 2016.7705078125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 838.1229858398438 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1822.2574462890625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 855.04150390625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 576.5160522460938 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1372.71533203125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1463.239990234375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 835.468994140625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 767.57958984375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1935.797607421875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1024.275146484375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1339.8729248046875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 3706.439453125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1288.7054443359375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 630.0732421875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 495.4972839355469 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1156.6651611328125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1151.0814208984375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1095.019287109375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1367.2933349609375 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1440.717529296875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1676.62353515625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 670.6381225585938 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1349.195556640625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1914.6370849609375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1008.0099487304688 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 874.15771484375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 982.7728881835938 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 948.3711547851562 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1412.48876953125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 3225.1826171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1042.033935546875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1243.536376953125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 973.7167358398438 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1167.8392333984375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1081.6602783203125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1126.2001953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1436.68798828125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 833.737060546875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 861.4049682617188 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 1056.0081787109375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1116.366455078125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1229.590576171875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2949.443359375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 2488.75927734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1558.0423583984375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1156.3740234375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 4678.57666015625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 995.10888671875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 818.2212524414062 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1376.52099609375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 16838.375 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 923.460693359375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 736.8858642578125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1192.219970703125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1970.871337890625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 2039.9517822265625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 986.5167846679688 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1392.44384765625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1841.867431640625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1480.8260498046875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 738.5921020507812 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 469.60882568359375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1543.03564453125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:22:09<102682:38:22, 1232.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 748.7344970703125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 901.8676147460938 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 557.8255004882812 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1104.2650146484375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1375.758056640625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 803.4733276367188 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1367.10302734375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 6710.83349609375 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1138.9603271484375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 742.7294311523438 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 525.0872802734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1347.7177734375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 608.4573974609375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 686.2486572265625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1307.7728271484375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 551.8882446289062 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1176.40625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 728.2660522460938 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 981.0083618164062 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1424.677978515625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 601.727783203125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 475.9935607910156 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1448.2958984375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1054.4375 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 886.3543090820312 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 4232.9111328125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 2136.085693359375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 3612.195556640625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2905.609130859375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1117.4832763671875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1142.8236083984375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1119.0802001953125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 7150.61279296875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1175.56982421875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 753.8128051757812 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 869.8958129882812 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 918.169677734375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 974.8301391601562 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1245.6226806640625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2052.520263671875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 13282.13671875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 679.6918334960938 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1949.4444580078125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 2532.193359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1115.51171875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1672.7855224609375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 887.918701171875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 4560.5751953125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1347.249267578125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 2655.384521484375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1293.4580078125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1072.6151123046875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 711.7078857421875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 760.0161743164062 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2221.84814453125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 872.4344482421875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1043.2294921875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 2022.5860595703125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1355.561279296875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 14178.673828125 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 2029.6324462890625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2392.162841796875 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 707.2373657226562 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1492.3240966796875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3604.042236328125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1403.8929443359375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 757.2715454101562 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 929.5112915039062 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1058.9090576171875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 2992.88134765625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 713.6763305664062 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 564.904296875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2036.0389404296875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 2123.144287109375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1748.515625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 518.6890869140625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1272.8160400390625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 972.0872192382812 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 837.3298950195312 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 984.5423583984375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 906.1917114257812 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 574.3055419921875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 955.9824829101562 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 942.1854858398438 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 608.5310668945312 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 918.659423828125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1266.6480712890625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1083.6468505859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 932.2440795898438 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 617.0213623046875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1007.819091796875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 793.2403564453125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 613.6008911132812 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1445.9744873046875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 964.0697021484375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1678.6456298828125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1030.3233642578125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 608.82666015625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 530.4434814453125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 966.5938720703125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1224.594970703125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 820.7102661132812 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 673.159423828125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 845.3560791015625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 908.736328125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1774.52099609375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1447.55908203125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1105.476806640625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 722.50537109375 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1197.1302490234375 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 4824.0537109375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1583.0606689453125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1304.46435546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1300.6121826171875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1310.012939453125 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 3913.562744140625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1197.234375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 2587.233154296875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 669.3886108398438 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 929.2128295898438 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1085.953125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1141.2166748046875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 2633.35693359375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1233.3741455078125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1038.9837646484375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1216.6627197265625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 6667.78125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1494.1832275390625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1344.3978271484375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 6039.9501953125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1321.3450927734375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 906.2907104492188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 735.5493774414062 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 974.9950561523438 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 860.7045288085938 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 990.7117309570312 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1108.966552734375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1454.051025390625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 767.5450439453125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1265.7506103515625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1014.106201171875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1600.049560546875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 638.9783325195312 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 916.2531127929688 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1284.413330078125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1227.6424560546875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2383.044189453125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1066.5198974609375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 922.9237670898438 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2321.1533203125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1527.2156982421875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1305.192138671875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1062.6622314453125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 968.9273681640625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 828.314453125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 2518.37109375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2234.029296875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 657.9185180664062 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 779.4990234375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2467.35595703125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1470.81884765625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 12235.9951171875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 721.1306762695312 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1475.411376953125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 5590.14892578125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 703.1287231445312 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 3272.373046875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1057.9522705078125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 2628.750244140625 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 3084.05859375 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1215.0213623046875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1494.084716796875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1209.80224609375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1060.4962158203125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 992.9089965820312 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1195.9132080078125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1336.6634521484375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1713.6734619140625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 958.6781616210938 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1550.47412109375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 594.7557373046875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 697.7555541992188 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 629.1904907226562 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 705.4239501953125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1017.9554443359375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 721.3463745117188 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 814.632568359375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1017.498046875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2007.443359375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 923.50390625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1704.9600830078125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 699.2918090820312 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1163.2618408203125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 983.1373291015625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 792.6286010742188 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1357.036376953125 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 2149.909912109375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 3012.686767578125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1421.5142822265625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 2043.7091064453125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 958.631591796875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1808.250244140625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 979.2186889648438 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1562.4208984375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 911.14990234375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 993.04052734375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 998.4684448242188 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2626.325439453125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 3959.2880859375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1188.5557861328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 742.4786987304688 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1189.4931640625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1174.4290771484375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 3052.353515625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 2118.499755859375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 9192.884765625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 841.767578125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1507.226318359375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 4439.88671875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2089.89306640625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 755.1187133789062 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1561.2357177734375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1125.3369140625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1148.69970703125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 2159.873046875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1493.247802734375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1193.619384765625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1140.258056640625 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 720.290283203125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 2429.617431640625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1652.6077880859375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 950.5362548828125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1096.34326171875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 2506.06298828125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1045.258544921875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1164.5338134765625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1344.4771728515625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1420.6708984375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 578.7144775390625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1030.2171630859375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1300.15234375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 3047.82177734375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1696.1124267578125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1046.005615234375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1115.609375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 2263.604248046875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1022.7173461914062 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1095.3087158203125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1167.0101318359375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2157.601318359375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 586.25390625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 662.1341552734375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1426.845458984375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1029.1690673828125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 908.5095825195312 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 824.8759155273438 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 9047.505859375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 2042.749755859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 861.737548828125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 750.3375854492188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 734.8958129882812 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 798.13037109375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 858.8130493164062 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1535.924560546875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2111.138916015625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 457.83892822265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 779.3766479492188 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 972.4922485351562 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 445.4956359863281 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 817.9152221679688 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 667.665283203125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 768.5986938476562 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 789.6190185546875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 662.7835693359375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 447.8181457519531 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1574.4786376953125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 883.08544921875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1354.47119140625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 958.7202758789062 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 880.8907470703125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1176.76025390625 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 738.5750122070312 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 466.2973327636719 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 627.6717529296875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1403.52392578125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 995.8806762695312 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 846.4400634765625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 660.2354125976562 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 894.5030517578125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 950.8783569335938 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1620.5743408203125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1237.9718017578125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1496.6142578125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1236.145751953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 995.4682006835938 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 12963.794921875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1366.104736328125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1689.5203857421875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 908.5692138671875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2152.63671875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1100.85888671875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1674.4779052734375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1345.1253662109375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 933.2472534179688 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1744.2064208984375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 2795.4677734375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1696.6409912109375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1169.18798828125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 689.6832885742188 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 704.9782104492188 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1495.292236328125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1386.427978515625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 684.6250610351562 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1345.3056640625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1485.5479736328125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1188.8343505859375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 2387.27001953125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 892.7371826171875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2711.609375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1015.0193481445312 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1056.6485595703125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1286.6640625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1269.48974609375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1314.0931396484375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1374.3602294921875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1006.1714477539062 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 461.29730224609375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 2204.46240234375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 2055.519775390625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 942.7120971679688 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1597.4302978515625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 677.7492065429688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1467.87451171875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1708.414306640625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 982.9505615234375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 652.1642456054688 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 640.42333984375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1281.1800537109375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 797.4130859375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 915.09814453125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 989.4785766601562 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 780.3759155273438 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1393.142822265625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1279.2789306640625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 1181.0706787109375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1054.866455078125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 758.5352783203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1150.1602783203125 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 740.78955078125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1964.107666015625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 826.7611694335938 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1104.536865234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 587.5429077148438 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1331.8173828125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 745.9234619140625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1401.5726318359375 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 2384.724609375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1209.4779052734375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1193.53369140625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1363.1490478515625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 2264.703857421875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 3975.544677734375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 2745.379638671875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 697.4594116210938 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 964.5181274414062 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 636.4296264648438 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1069.3255615234375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 960.523681640625 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1501.895263671875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 852.72119140625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1503.513916015625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1006.8805541992188 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 673.5319213867188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 491.07568359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 620.6752319335938 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 890.47119140625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1191.8636474609375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1082.1693115234375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 865.1937255859375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1150.0640869140625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 3611.378662109375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 2614.465087890625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 727.2978515625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 834.3551635742188 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 942.4292602539062 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1267.172119140625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 715.01220703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1336.7576904296875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 885.1602172851562 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 887.4269409179688 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 661.2731323242188 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1319.73046875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 879.5235595703125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1008.0762939453125 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1120.08349609375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 756.9364013671875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1826.26953125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1628.60986328125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1470.623291015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 635.1318969726562 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1045.41650390625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1887.427490234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2542.1279296875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1851.7760009765625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1795.0404052734375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 976.6823120117188 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1468.82861328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1938.3597412109375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 3502.5361328125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 934.4776000976562 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 631.5750122070312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1853.4345703125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1035.222900390625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1194.10205078125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2844.963623046875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1460.108154296875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1756.5447998046875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1442.7322998046875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1746.42138671875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 539.2720336914062 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 891.5525512695312 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 2943.6669921875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1639.8717041015625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 780.1160888671875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 868.0875854492188 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 950.2289428710938 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1233.8321533203125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 929.949951171875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1083.24609375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1577.9312744140625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 659.216552734375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 758.5516357421875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1186.956298828125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1310.4210205078125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1262.1622314453125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1130.31201171875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1009.4203491210938 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 4501.166015625 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2785.3427734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1035.648681640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1240.92724609375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2257.418701171875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1547.155517578125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 729.0008544921875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1152.9468994140625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1800.446044921875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 932.8726196289062 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 2022.8480224609375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 2048.437255859375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 838.9887084960938 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1503.0379638671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1518.0650634765625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 929.6032104492188 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1085.1114501953125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1169.8414306640625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1270.3145751953125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1635.1422119140625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1808.4197998046875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 858.199462890625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 3012.759033203125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1433.7811279296875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 868.5186157226562 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 3061.485107421875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 976.3807373046875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1287.510498046875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 641.1043701171875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1826.9110107421875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 5642.8330078125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 777.8352661132812 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 4869.84326171875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 4477.23583984375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 984.1044921875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1188.17333984375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1975.469970703125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1095.2144775390625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1826.8807373046875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 2167.359130859375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 661.4974975585938 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1134.2657470703125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1129.3463134765625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1206.322021484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1028.6793212890625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 679.0088500976562 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 867.068603515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 2254.47412109375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1566.5771484375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1695.357177734375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1660.4617919921875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1700.3060302734375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1362.0162353515625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 2650.78759765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 661.961181640625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1364.015869140625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 2661.300048828125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1136.03125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 623.272705078125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 492.38934326171875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1242.281005859375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1584.7626953125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1684.0623779296875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1094.9854736328125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1208.6981201171875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1076.790283203125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 769.0874633789062 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 765.6327514648438 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 3374.776611328125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1248.212646484375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1018.9032592773438 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 841.6666259765625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 617.8176879882812 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1665.0528564453125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1725.2569580078125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 795.7880859375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1342.7259521484375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1191.5009765625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1034.9278564453125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1854.7701416015625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 731.19580078125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1422.8663330078125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1133.669921875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1296.6712646484375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 937.7479248046875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1373.6690673828125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1623.1051025390625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1225.197998046875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1419.702880859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 849.2891235351562 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1407.3189697265625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 809.3185424804688 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1433.5057373046875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1471.2618408203125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 729.2350463867188 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1106.223388671875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1222.0611572265625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1493.216552734375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 572.2772216796875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1310.04150390625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1702.63037109375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 538.8256225585938 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 896.8056640625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 832.2056274414062 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1322.6103515625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 785.028564453125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 545.6634521484375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1456.997802734375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 762.082275390625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1075.81884765625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 847.9362182617188 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 920.1151123046875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1167.4310302734375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 664.0087280273438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 722.0618896484375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1050.28955078125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1509.78662109375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 3032.078857421875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 721.7933959960938 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1387.164306640625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1327.941650390625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 807.9834594726562 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 889.473388671875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 525.4693603515625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 851.1768188476562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1561.587158203125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1252.7886962890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 736.8606567382812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1113.1085205078125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 805.9288940429688 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 791.4060668945312 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1093.053955078125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1571.13525390625 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1425.1834716796875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 777.7444458007812 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1569.6680908203125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 670.9677124023438 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 736.3327026367188 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1002.1647338867188 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1270.4578857421875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1888.1710205078125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1388.4945068359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1127.2255859375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 820.5020751953125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 899.8850708007812 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 747.9330444335938 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1151.4703369140625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1872.404052734375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 809.50830078125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1101.932861328125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 771.3276977539062 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1892.883544921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1136.0501708984375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1550.89013671875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1431.4761962890625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1648.434814453125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1607.191650390625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1635.57080078125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 799.336181640625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 554.3214111328125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1655.5008544921875 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1104.6199951171875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1510.287109375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 2420.089111328125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 766.0174560546875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1307.0601806640625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1053.7425537109375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 923.0089721679688 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1621.282470703125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 703.5319213867188 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1098.2008056640625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 984.2603149414062 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1250.2852783203125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1058.3323974609375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 609.8001708984375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1333.6776123046875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1464.69921875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1104.4508056640625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1111.3948974609375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1134.0089111328125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1152.104248046875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 670.9778442382812 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1196.7694091796875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2003.7081298828125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1840.407470703125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1411.053955078125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 994.5663452148438 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 3092.0791015625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 2483.9873046875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 783.7772827148438 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1544.3787841796875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 534.0106811523438 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 642.9960327148438 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 736.450439453125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 938.7559204101562 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 521.6334838867188 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 767.4898681640625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 975.4611206054688 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 730.808349609375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 538.6937255859375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1053.801025390625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 936.7501220703125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 730.9293823242188 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 956.5938720703125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 563.1969604492188 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 828.0647583007812 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1270.812255859375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1407.6107177734375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 827.4957275390625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1124.7303466796875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 952.2467651367188 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 969.361572265625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1339.8157958984375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 932.1070556640625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 912.4450073242188 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 940.7667236328125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1046.0325927734375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 958.4205322265625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 899.777587890625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1088.65869140625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 962.2027587890625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1370.8121337890625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1620.3074951171875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 3879.912109375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 871.7940673828125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 960.3407592773438 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 941.3640747070312 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 733.1467895507812 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 589.2136840820312 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 855.3900756835938 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 654.2186279296875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 643.61083984375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1733.9232177734375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1239.1732177734375 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1190.4044189453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 833.2061767578125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1961.302978515625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 2113.915283203125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 728.5987548828125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 856.1949462890625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1357.5189208984375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1266.11572265625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1159.1033935546875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1300.5167236328125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1417.638427734375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1722.5645751953125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1165.52685546875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 829.7971801757812 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1626.15771484375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1156.9578857421875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 871.5979614257812 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1517.6612548828125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1421.1187744140625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1856.5819091796875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1576.7364501953125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 928.5654907226562 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 871.328369140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1030.68310546875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:42:47<102855:46:31, 1234.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 989.275390625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1082.8218994140625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 915.406494140625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 910.8564453125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1154.419677734375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1458.289794921875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 655.6886596679688 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 687.8790893554688 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 863.7052001953125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2132.72265625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 563.3482055664062 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 427.2876892089844 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 972.4315185546875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 905.4677734375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 824.4879760742188 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 967.3168334960938 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1914.546630859375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 5994.169921875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1355.175537109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 985.0735473632812 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 651.566162109375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1558.783447265625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2118.486083984375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 788.0914306640625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 2986.544921875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1089.4495849609375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 770.6963500976562 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 984.9702758789062 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 3425.778076171875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1381.0570068359375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1160.6890869140625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 2085.54443359375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1128.40625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1736.197509765625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 851.0160522460938 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 625.8845825195312 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2081.9970703125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 800.9121704101562 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 751.8397827148438 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 736.9684448242188 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1003.4527587890625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 679.5204467773438 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1093.25048828125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 750.2413330078125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1131.4755859375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1137.7962646484375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1167.540283203125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1539.9853515625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1312.92626953125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1372.10791015625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 3262.14208984375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1112.13232421875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1290.0972900390625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 976.4314575195312 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2382.65771484375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2122.48828125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2910.91552734375 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1481.6890869140625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1085.6605224609375 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2184.43896484375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1206.8402099609375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2150.73193359375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1909.3538818359375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 3202.410400390625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1919.286376953125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1283.2138671875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2781.359619140625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 639.281982421875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1048.094970703125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 999.8280029296875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1249.9471435546875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1871.8414306640625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 843.6961669921875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1045.151123046875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1051.417236328125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 833.9119262695312 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 760.8103637695312 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 880.4290161132812 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 956.1514282226562 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1303.9169921875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 674.3851928710938 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1853.4166259765625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 716.4655151367188 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 970.799072265625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 903.927734375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1159.0799560546875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1051.8193359375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2426.654296875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1567.64453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1866.3101806640625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1002.3685913085938 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 2208.65283203125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1755.626708984375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1257.4791259765625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1477.2725830078125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1156.0648193359375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1097.664794921875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 970.1340942382812 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1185.34130859375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1033.6378173828125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1521.8450927734375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1182.8282470703125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2526.8466796875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1215.4842529296875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1334.8533935546875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1268.174072265625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 774.0354614257812 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1265.591552734375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 896.2992553710938 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1329.8892822265625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1091.606689453125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 631.366943359375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 948.071044921875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 825.5357055664062 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 4713.35009765625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 802.8873291015625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1685.9404296875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 892.22265625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 710.7748413085938 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1065.622314453125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 729.20361328125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1723.1141357421875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 674.329833984375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 862.544189453125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1024.4608154296875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 994.0318603515625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 754.632080078125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 930.3837890625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2754.4208984375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 970.2490234375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 943.2605590820312 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 931.8719482421875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1086.84130859375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1084.223388671875 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2289.213623046875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 739.6563720703125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1053.5733642578125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1467.62744140625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 713.079345703125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 2624.29736328125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 532.7694702148438 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 699.66015625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 827.8613891601562 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1597.9052734375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 904.863525390625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1371.677978515625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 881.35009765625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1023.9158935546875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1102.523681640625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 807.16796875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 816.5526733398438 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 811.037109375 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 883.43505859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1148.8377685546875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 797.38427734375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1141.80712890625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 934.1026000976562 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1353.4234619140625 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1540.6768798828125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 775.97314453125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1197.81640625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 786.3717651367188 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 963.1790161132812 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1956.0015869140625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 966.2113647460938 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1807.5037841796875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 935.872802734375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 765.9736328125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1493.7987060546875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 844.1710205078125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1059.8897705078125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 879.9518432617188 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 2646.165283203125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1813.99169921875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1240.300537109375 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 827.2781982421875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 926.84765625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 3677.464111328125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1327.816162109375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 2247.28125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 970.7924194335938 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 83833.5078125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1972.2821044921875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 613.70849609375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 994.5032348632812 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 36066.03125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 936.070556640625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1239.6058349609375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1394.4200439453125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2658.83447265625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 734.1773681640625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 482.56011962890625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 977.1055297851562 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1537.7872314453125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1748.985107421875 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1639.36572265625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 862.947021484375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 4126.40087890625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1681.5865478515625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1284.3795166015625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1295.7845458984375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1459.943359375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1286.35302734375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1199.66015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1321.8321533203125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1469.2301025390625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 649.6557006835938 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1853.8453369140625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 2363.92822265625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 854.3743896484375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 2731.150146484375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 3931.60107421875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 3122.27685546875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1984.4925537109375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1332.550537109375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1130.79248046875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1211.24951171875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 945.9312133789062 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 536.7728271484375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1018.818603515625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1525.75634765625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1657.6739501953125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1398.393798828125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 2157.018310546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 818.2175903320312 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1503.621826171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2150.7705078125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 723.551513671875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 970.76708984375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1920.7314453125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1712.206787109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 946.4864501953125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1520.859619140625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2576.09912109375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1629.073974609375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 970.7070922851562 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1807.7281494140625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 854.5162963867188 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 855.20654296875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 3004.082763671875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1287.95068359375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1154.1739501953125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1273.366455078125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1391.470703125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 12147.0126953125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1784.236083984375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1010.4039306640625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 559.5552368164062 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1706.1314697265625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1059.262451171875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1489.1336669921875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1468.648193359375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 664.6633911132812 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1300.0904541015625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1545.390625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 909.909423828125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 729.4066772460938 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 621.85595703125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 652.9544067382812 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1731.80615234375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2656.38330078125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 973.8614501953125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 649.2753295898438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 766.079833984375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1444.7593994140625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1054.5101318359375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 741.7423095703125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 757.8368530273438 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 661.6507568359375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 675.6154174804688 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 697.9866943359375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1433.57666015625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1015.8081665039062 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1241.199951171875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1142.7169189453125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1021.8717651367188 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1302.303466796875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1350.2813720703125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 722.58251953125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1070.0943603515625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 827.4874877929688 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1027.8516845703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 760.7246704101562 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1596.37451171875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1231.7908935546875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1244.345947265625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 2639.35693359375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 2545.016845703125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 3338.18994140625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1597.07763671875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1571.61865234375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1046.416748046875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1308.746337890625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1025.6376953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2790.880615234375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1322.0020751953125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1071.8134765625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 994.3985595703125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 3627.640869140625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2187.31396484375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2200.8017578125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 5150.49609375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 819.1068115234375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1006.7257080078125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 865.632080078125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1317.6246337890625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1838.0264892578125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 669.704345703125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1189.10205078125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1419.555908203125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1045.314453125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 5323.13037109375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 559.7650146484375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2381.796875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2387.84765625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1424.4580078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1214.92822265625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 3959.54052734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1078.947021484375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1914.281494140625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 600.3833618164062 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1829.2781982421875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 7192.5830078125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 760.1510009765625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2614.5185546875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 842.9005126953125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 991.72265625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2338.423583984375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1398.3099365234375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 767.22607421875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1449.978271484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1749.3582763671875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1464.4287109375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1469.9366455078125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2424.69873046875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1415.8800048828125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 899.9676513671875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1043.533447265625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1125.7294921875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1569.80078125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 3074.292724609375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 2394.560546875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1487.2860107421875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 652.9930419921875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1056.031005859375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1774.4051513671875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1056.1912841796875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1408.447021484375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1090.3582763671875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1024.8720703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1596.325439453125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1268.8944091796875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 787.1757202148438 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 730.5264892578125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 53305.7734375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1128.177490234375 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1373.56787109375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1055.42724609375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1163.062744140625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2846.905029296875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1949.943603515625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1182.9744873046875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 422.2174377441406 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2030.34423828125 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 3546.630859375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1698.048583984375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 957.6619873046875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1608.0589599609375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 807.6824951171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1019.571533203125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 6496.14794921875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 759.3355102539062 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 598.3961791992188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 731.6114501953125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1399.8900146484375 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1240.7816162109375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 3715.230712890625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 2591.4072265625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 924.5283203125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 946.3133544921875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 776.4183959960938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3121.04541015625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 951.6231079101562 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 636.888916015625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1020.4911499023438 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1188.57470703125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1341.3956298828125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1013.3095092773438 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 702.113037109375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1068.768798828125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2218.3623046875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 966.9973754882812 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 477.0714111328125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 751.15625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2707.7451171875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 598.4708862304688 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 530.0184936523438 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 820.35546875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 733.3795166015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1149.282958984375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 957.4768676757812 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 684.2018432617188 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 756.4097290039062 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 905.913818359375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 957.9996337890625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 572.5060424804688 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 915.0185546875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1049.2877197265625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2222.142578125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1100.7655029296875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1027.5252685546875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1067.1373291015625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1024.74658203125 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 981.2808227539062 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 910.9939575195312 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2210.873046875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1042.604736328125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1335.8282470703125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 951.2456665039062 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 745.273681640625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 979.9985961914062 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 851.9605102539062 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1190.9136962890625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 576.3368530273438 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1623.3553466796875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1026.6898193359375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1561.7442626953125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 491.8150634765625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1538.1824951171875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1241.818359375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 774.9906005859375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1227.853759765625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 725.1881713867188 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1495.08447265625 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1472.4412841796875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1151.544677734375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2934.8623046875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 735.30224609375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1537.8450927734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2152.431640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 743.23046875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1159.3057861328125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1217.126953125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 630.4808349609375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 925.85400390625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 797.9061889648438 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 983.778564453125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 2120.54150390625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 664.943115234375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 862.5804443359375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1104.53369140625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 703.5613403320312 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1852.301025390625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 633.7988891601562 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1039.2720947265625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 851.7130737304688 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1299.661865234375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 953.5660400390625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 584.0613403320312 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 848.171142578125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1112.2869873046875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1361.2003173828125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 778.4796752929688 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 651.7364501953125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 826.8717651367188 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 697.911865234375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1409.3250732421875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1018.7833862304688 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 545.4328002929688 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 555.51953125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 891.6456909179688 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1340.1400146484375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1781.2100830078125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 942.294189453125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 482.3736267089844 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1372.6746826171875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1241.868408203125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 740.94091796875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1871.1884765625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1744.6982421875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1206.7867431640625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 787.601806640625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1085.0286865234375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1127.0472412109375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1661.600830078125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 598.5569458007812 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 701.1778564453125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 585.4924926757812 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 751.5436401367188 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1614.6849365234375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 4730.2666015625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 841.2378540039062 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 911.6634521484375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2706.484619140625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 931.7800903320312 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1177.9322509765625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1123.685546875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 913.186279296875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 995.8551025390625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 805.1267700195312 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 844.0360107421875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1130.5218505859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1652.8245849609375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1298.420166015625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1068.0347900390625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1095.228515625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1980.291015625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1054.8603515625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1516.833984375 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 890.25927734375 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 879.100830078125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 952.6039428710938 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1895.2197265625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 2390.411865234375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1689.868896484375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1490.6617431640625 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1129.2276611328125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 838.6276245117188 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1815.487548828125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1090.679931640625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 723.6030883789062 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 721.46826171875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 795.0353393554688 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1291.314208984375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 3568.11669921875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 5352.03759765625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 7215.1083984375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 3072.64697265625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1802.6070556640625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1805.732177734375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1270.1785888671875 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 851.5174560546875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1396.4310302734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 918.8397827148438 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 2666.93359375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 2128.271728515625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2421.939453125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 920.603271484375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 598.9175415039062 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2088.701416015625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1185.73291015625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1359.744140625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1472.8284912109375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1123.90380859375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 539.5425415039062 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1161.2979736328125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 930.9054565429688 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1473.6580810546875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 919.4141235351562 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1353.39501953125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1292.6717529296875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1700.2373046875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 664.3422241210938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1505.569580078125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 903.3683471679688 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 911.440185546875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1016.9850463867188 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 908.513671875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1200.7010498046875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 990.2457275390625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1942.8907470703125 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1782.9442138671875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1416.53173828125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 799.3329467773438 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 573.8206176757812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1130.6619873046875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2203.62158203125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1126.21630859375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 492.5735168457031 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 621.7310180664062 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2625.900634765625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 2499.98828125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1282.84326171875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 657.4811401367188 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 817.9684448242188 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1830.0499267578125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1018.9073486328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1649.8670654296875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1306.0159912109375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 856.865234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1189.1553955078125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 918.94287109375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 920.5428466796875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1056.2061767578125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1345.7457275390625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 832.1021728515625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1910.96533203125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 899.4896240234375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1440.4703369140625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2225.625732421875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2002.9033203125 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1979.6314697265625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1498.3189697265625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 780.8570556640625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1010.4909057617188 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1239.975830078125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1699.24462890625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1088.991943359375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1312.3251953125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1322.6483154296875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 944.3505859375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1789.195556640625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 558.7836303710938 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 2149.2060546875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1438.9969482421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1725.830810546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 4486.9443359375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2144.77685546875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1855.4730224609375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1900.119873046875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1881.0545654296875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 5590.03662109375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 885.84619140625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 961.53173828125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 777.700439453125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2232.450927734375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1743.1669921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1151.2667236328125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 948.1024780273438 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1028.3505859375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 903.7826538085938 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 2180.90771484375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1858.8175048828125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 827.4512939453125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1000.4143676757812 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 3028.107666015625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1600.85302734375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1154.8531494140625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 867.5972290039062 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 762.65283203125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1370.7069091796875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1683.2557373046875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 15606.005859375 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2233.564208984375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1467.5506591796875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2731.741455078125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2184.067138671875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1457.7657470703125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1379.8438720703125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1984.9757080078125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2144.763916015625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2078.241455078125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 935.10009765625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1133.063720703125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1594.5906982421875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1786.2320556640625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2053.1728515625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 964.3231201171875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 768.2776489257812 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 834.1328125 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1264.177001953125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1527.5130615234375 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1935.3218994140625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1007.4240112304688 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1797.9947509765625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1362.0198974609375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1302.7890625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 992.6076049804688 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2228.16748046875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1161.985595703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 943.6344604492188 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1805.016845703125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 804.2469482421875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1028.849365234375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1817.1373291015625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1180.2164306640625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 2366.4970703125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1587.1717529296875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1880.560302734375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2643.3134765625 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1234.0845947265625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2386.993408203125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 721.7671508789062 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2046.71875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 763.3319091796875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1545.482421875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1072.6849365234375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1069.089599609375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 952.779296875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 869.623779296875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 908.4981689453125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1686.755615234375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 801.8629150390625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1712.5098876953125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1219.7037353515625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1366.2503662109375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 896.3142700195312 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 559.8462524414062 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1269.6558837890625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1512.1488037109375 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1596.5145263671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1008.8704223632812 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1191.6324462890625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1186.525146484375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1750.94970703125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:03:27<103016:14:45, 1236.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 873.6111450195312 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1001.1782836914062 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1692.8115234375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2364.4619140625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1294.3135986328125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2074.734130859375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 994.3507690429688 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 849.922119140625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1571.00927734375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 4690.46142578125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 683.06201171875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1296.1494140625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1658.140625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1739.4447021484375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 885.9360961914062 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 919.2357177734375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 484.09039306640625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1547.0213623046875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1287.316162109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 821.6377563476562 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2454.17919921875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1010.5321044921875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1078.6817626953125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1797.5504150390625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1137.61962890625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2606.22900390625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2764.5927734375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 708.8939819335938 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1385.9215087890625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 2565.91015625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 828.4259033203125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 606.0690307617188 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 772.73974609375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1317.1201171875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1992.02734375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1539.600341796875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1208.476318359375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 746.7572021484375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 806.095703125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1387.2989501953125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1102.8060302734375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1964.92236328125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1200.3446044921875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1679.365478515625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1175.422607421875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1030.0850830078125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1011.0709838867188 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 760.3128051757812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1746.3797607421875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 8990.255859375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 825.57763671875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 758.1635131835938 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 4282.095703125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1410.9346923828125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 968.8624877929688 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2444.317626953125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 5605.6845703125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 6458.61328125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 746.2510375976562 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1466.57666015625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2258.960693359375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1128.066162109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1289.859375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1140.0203857421875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1262.972412109375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1241.1971435546875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1472.2386474609375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1635.245849609375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1573.3524169921875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 775.0615234375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 974.6107788085938 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 842.7608642578125 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 975.0369873046875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 665.1043090820312 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 841.75634765625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 718.4864501953125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1096.070068359375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 748.2182006835938 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 397.2931823730469 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1598.576416015625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1481.82958984375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 938.421142578125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 761.5499877929688 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 521.1575317382812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1587.24560546875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 828.3221435546875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 861.7503662109375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 839.0028686523438 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 480.5797119140625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 666.745849609375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 666.3955078125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1613.713134765625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 994.7982177734375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 960.208984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 747.3460083007812 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 898.8214721679688 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2040.1441650390625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 978.3845825195312 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 681.4033203125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1100.0406494140625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 837.9951171875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1571.676513671875 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2466.8037109375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 5569.982421875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1593.517822265625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2690.4111328125 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 3017.048828125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1799.4505615234375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1551.1324462890625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3604.86376953125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2710.29833984375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1626.9248046875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1134.627685546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2195.98583984375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1158.8658447265625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1308.515869140625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 9379.109375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1208.8426513671875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1017.4815063476562 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1577.6759033203125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1220.164794921875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 909.6528930664062 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1852.3489990234375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1216.59619140625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 710.3915405273438 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 977.4263305664062 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 628.1080322265625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1356.392578125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1147.5914306640625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1287.9720458984375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1620.0191650390625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 863.8366088867188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1869.5806884765625 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1608.251708984375 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 770.2650146484375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1054.4423828125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 4032.7646484375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1168.364990234375 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1460.633056640625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 899.8944702148438 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 792.8060913085938 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1398.609130859375 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1196.906005859375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1869.2935791015625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2385.160888671875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1897.187744140625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1581.8282470703125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1202.2391357421875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 977.7937622070312 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1128.0335693359375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 4518.126953125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1842.5718994140625 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1311.918701171875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 2042.294189453125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 3117.846435546875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 876.098388671875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1539.925537109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1364.8526611328125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1158.753662109375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1358.8499755859375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1185.243896484375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1677.607666015625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1021.6151123046875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1680.8677978515625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2726.363525390625 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1539.8065185546875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1511.882568359375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2794.61083984375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 618.266845703125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 3067.37890625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 842.6199340820312 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1138.045166015625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1173.0966796875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1367.208984375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1670.73388671875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 814.493408203125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1464.9443359375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1965.67529296875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1107.4432373046875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1527.16943359375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1537.0565185546875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1864.1138916015625 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 951.468505859375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1909.654052734375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2283.778076171875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1258.6243896484375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2153.580322265625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2291.49169921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1774.552001953125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 920.326171875 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 6217.755859375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 4408.3408203125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1257.17724609375 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 849.9828491210938 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1770.859619140625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1047.7083740234375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2029.4683837890625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1259.8306884765625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1274.946533203125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2181.97314453125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1434.175048828125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1729.7926025390625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1431.5592041015625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1842.107666015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1431.9217529296875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 897.9053955078125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 822.4553833007812 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 875.9283447265625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1022.5569458007812 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1069.68798828125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 545.7879638671875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 821.14697265625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 961.2678833007812 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1080.707763671875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1295.1058349609375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 737.08056640625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3857.805908203125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1994.4951171875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1615.641845703125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1443.1517333984375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2047.0130615234375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1679.4041748046875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2693.915771484375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1372.995849609375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1586.1591796875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 905.7203979492188 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1065.66845703125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1088.5682373046875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1252.36181640625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1505.56396484375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1545.97900390625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2475.8466796875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 845.0641479492188 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 15948.353515625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 2004.3299560546875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 871.0101318359375 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 989.626220703125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1042.9571533203125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 910.431884765625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1048.7833251953125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1362.416259765625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1788.307861328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2060.447509765625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1793.0738525390625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 652.9054565429688 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1212.624755859375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1023.0336303710938 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1669.5191650390625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 948.5424194335938 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 988.4583740234375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2768.170166015625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2007.378173828125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1135.1146240234375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 876.018310546875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1524.1715087890625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1106.4151611328125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 964.975830078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 794.171142578125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1769.2327880859375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 744.90283203125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 592.5108642578125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 647.1326293945312 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 853.6797485351562 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 962.3970336914062 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 812.8355712890625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 608.3580322265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1092.144775390625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 719.3253784179688 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1442.9578857421875 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 646.6427001953125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 730.0453491210938 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1713.81884765625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1534.2550048828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 811.1966552734375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 856.8004760742188 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 899.6749267578125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1380.9954833984375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 715.8616943359375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1064.0108642578125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1711.6475830078125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1083.8125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1277.779052734375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1166.4705810546875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 910.3433227539062 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1065.2529296875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 8567.3916015625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 605.25927734375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 868.3786010742188 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 785.4967041015625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 993.206298828125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1564.762939453125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 906.6118774414062 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2126.928955078125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 864.1095581054688 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 858.0945434570312 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1330.32568359375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1313.83203125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 984.4632568359375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1051.2806396484375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1798.134033203125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1343.8355712890625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 399.6438293457031 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1179.68505859375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1517.43017578125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1437.991455078125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1605.116455078125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1027.236083984375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1243.922119140625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 3061.663818359375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1141.0740966796875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1623.1629638671875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1093.2803955078125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1754.0933837890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 2903.9697265625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1056.9581298828125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1400.9288330078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 538.0557861328125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1610.1339111328125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1212.347900390625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 979.7626953125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1706.3309326171875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 643.11474609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 739.050048828125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1768.14794921875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1228.6982421875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1466.735107421875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1773.441650390625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 887.6703491210938 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 936.6661987304688 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2014.792236328125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1609.3004150390625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 10126.572265625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1583.022705078125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 852.7933349609375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 758.3748168945312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 14687.2763671875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2183.261474609375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1869.24658203125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1131.035400390625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 605.9243774414062 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1248.8756103515625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1429.199951171875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 625.2415771484375 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 798.9708862304688 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1769.3720703125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1708.5198974609375 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 866.7662963867188 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 4516.8046875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1165.6180419921875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1491.1337890625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1171.077392578125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1096.7708740234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 744.8701782226562 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3163.90234375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1820.7862548828125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1449.2374267578125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2186.59228515625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 831.6201171875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 3898.259521484375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1667.922119140625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1664.603515625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 769.2487182617188 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 853.7476806640625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 812.611572265625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1436.4915771484375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1096.1649169921875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 3132.18798828125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3575.47802734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1019.8006591796875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 692.0595092773438 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1190.8734130859375 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2223.649658203125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 940.659423828125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 802.121826171875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 663.9239501953125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 686.8428955078125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 21797.6328125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 3731.407470703125 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 929.2799072265625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 2216.244140625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1973.709716796875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 2405.4990234375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2836.7890625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 617.0778198242188 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1606.478515625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1198.520751953125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 3653.814697265625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1825.1748046875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2535.172119140625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1062.4649658203125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1476.95849609375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 914.7738037109375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 4142.47705078125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3509.741943359375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 894.1863403320312 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1217.7850341796875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2229.087158203125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1472.2869873046875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1266.8858642578125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 529.5694580078125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2051.85693359375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 724.828857421875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1075.6571044921875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 910.4902954101562 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1635.0350341796875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2259.82958984375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 800.2291870117188 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1221.611572265625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 710.8360595703125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 957.1769409179688 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 950.766845703125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 775.5917358398438 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1770.734619140625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1506.0821533203125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1615.6663818359375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1048.4688720703125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 4174.17822265625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1173.4820556640625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 750.2515869140625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1360.302734375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1129.553466796875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 2612.05712890625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 897.5403442382812 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1595.370849609375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1749.977783203125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 759.5125732421875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2318.16064453125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1369.1436767578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1667.12158203125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1787.0582275390625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1055.1016845703125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 769.413818359375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 969.3609008789062 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2446.720703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 2143.2109375 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1925.3876953125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 790.2194213867188 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1457.535888671875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 873.3627319335938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 3186.31396484375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 4385.78564453125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 3975.406005859375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1181.8485107421875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1016.8645629882812 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 800.8934326171875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 923.0261840820312 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 990.203125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1867.3592529296875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1388.401611328125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1731.06689453125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1535.8426513671875 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1793.5155029296875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2395.6806640625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 906.287109375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 959.5691528320312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 5290.61083984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 735.5076904296875 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 885.4547729492188 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 694.1685791015625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 813.0731201171875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1216.4595947265625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 818.9180297851562 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1237.1275634765625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 616.3597412109375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 588.5098266601562 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1637.486083984375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 873.6725463867188 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 828.0097045898438 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 665.8207397460938 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 876.51318359375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1242.8182373046875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 906.035888671875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 698.0647583007812 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 625.5240478515625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1629.9512939453125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 954.0001220703125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 900.6688232421875 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1353.9638671875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 962.3065795898438 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2707.040771484375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 818.1135864257812 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 649.3010864257812 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1046.2017822265625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 885.6163940429688 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1041.4844970703125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 865.3157348632812 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 718.1895141601562 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 765.5223388671875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 682.24462890625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 695.3031005859375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1102.454833984375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1139.468994140625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1401.224365234375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 719.0543823242188 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 823.9302368164062 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 583.181396484375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 4586.490234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 896.1027221679688 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2822.368896484375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1211.6715087890625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2346.587646484375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 744.30322265625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1051.0953369140625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2265.5361328125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1480.449951171875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1147.1519775390625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3906.236328125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1092.9522705078125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1765.6656494140625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1295.28857421875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 771.7182006835938 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1176.165283203125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 2404.8125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 676.1254272460938 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 882.237060546875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1413.087646484375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 983.2943725585938 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1109.134033203125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 668.7233276367188 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1191.585205078125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1666.5391845703125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1243.8089599609375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1708.92138671875 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 799.6163330078125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1246.599365234375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3846.418212890625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1079.474365234375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 3862.571044921875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1119.9754638671875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 828.3701782226562 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1669.1402587890625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1117.466064453125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 3127.802978515625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1680.6107177734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 970.304931640625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 829.3383178710938 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 698.6041870117188 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 813.2401123046875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 746.6580810546875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1234.233154296875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1274.0726318359375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2149.138671875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 844.6229858398438 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1603.953125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 2414.2578125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1463.5135498046875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1425.46630859375 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1189.3770751953125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 2396.1708984375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 28398.59375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 7656.9208984375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1284.394287109375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 856.9650268554688 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 819.8449096679688 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 677.1129150390625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 954.3848876953125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 988.6032104492188 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1203.7044677734375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3683.0048828125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1681.8316650390625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 667.228515625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2327.066650390625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 984.6201171875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 838.2562866210938 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1049.729736328125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1058.5123291015625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 928.3781127929688 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 3021.816162109375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 779.4986572265625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 873.4625854492188 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2253.695068359375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1471.9669189453125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1018.174560546875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1960.8311767578125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1198.4503173828125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 10640.9375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1911.4385986328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 820.2052612304688 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2085.857177734375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1422.358154296875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1215.6597900390625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1775.978759765625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 964.4110107421875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1107.748779296875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2175.699951171875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1584.3389892578125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 735.0927734375 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 823.83349609375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 847.1160278320312 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 992.7816162109375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1132.1751708984375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1930.2645263671875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1866.251220703125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1000.958740234375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2042.8153076171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1633.0916748046875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1008.7660522460938 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1411.0484619140625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1814.204833984375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1296.57421875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 11914.8359375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 913.5634155273438 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1220.13134765625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1038.311767578125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1823.3914794921875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 4236.05029296875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 892.1350708007812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1020.9651489257812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1233.89453125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1818.8692626953125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 3854.0380859375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1640.811279296875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1757.5533447265625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1036.924072265625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1072.7509765625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1614.7254638671875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1533.4473876953125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1891.968017578125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 886.9717407226562 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1940.1075439453125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 16567.078125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1006.9762573242188 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 847.7783203125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 675.4064331054688 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 841.6568603515625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1617.6522216796875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1266.801513671875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1283.623046875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 722.2842407226562 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 904.0634765625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1096.18798828125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1950.267333984375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 995.953369140625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1092.0692138671875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1452.0733642578125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 654.6988525390625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1893.0277099609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1285.480224609375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1377.7939453125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1072.7728271484375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1486.99609375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1870.21728515625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1296.6119384765625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1466.4501953125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1506.8997802734375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 969.41064453125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 851.6752319335938 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 933.4378662109375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 966.8927612304688 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1574.35009765625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1864.1466064453125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1605.4022216796875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 913.7054443359375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1326.595458984375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1173.5770263671875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 497.4517822265625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 887.4149780273438 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 895.7008666992188 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 625.6744384765625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 812.0703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 960.6787109375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 510.5201416015625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1989.03173828125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 763.5259399414062 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 502.74896240234375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 523.2550659179688 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1306.33056640625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1487.38330078125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1182.1204833984375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 991.0300903320312 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 714.7177124023438 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2810.636474609375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1168.82373046875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 763.1903686523438 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1045.8958740234375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1591.4844970703125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1145.7044677734375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 898.8038940429688 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1212.4794921875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1448.1563720703125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1149.09765625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1245.2841796875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 822.3527221679688 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1138.006591796875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1008.1268310546875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 780.8212280273438 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1171.83544921875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1343.59765625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1240.6011962890625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1048.3885498046875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 991.8350219726562 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 740.7175903320312 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 2464.396484375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2204.53271484375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1606.9864501953125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:24:06<103100:06:15, 1237.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 2822.497314453125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1018.8573608398438 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 791.387451171875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1578.17578125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1226.47802734375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1232.1617431640625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1520.988525390625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 863.732421875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 863.0729370117188 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1285.159423828125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1175.7591552734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1916.1668701171875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1054.366943359375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1920.406494140625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1257.7867431640625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 12816.306640625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2043.0635986328125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1668.475341796875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 4865.109375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1164.279296875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1822.5164794921875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1486.491943359375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 557.4087524414062 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 719.6631469726562 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 948.5435791015625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 885.4020385742188 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1364.224853515625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1055.0201416015625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 519.1239013671875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 771.0208740234375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 962.415771484375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1337.2552490234375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 2169.371337890625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1075.1832275390625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 752.596435546875 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 791.1732788085938 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1299.6678466796875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1144.4427490234375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 852.0728759765625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 817.39208984375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 831.8389892578125 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1976.6534423828125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 2421.1640625 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1891.443359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 991.28466796875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1021.4020385742188 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 869.5847778320312 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 848.5510864257812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1063.5098876953125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1821.0166015625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1942.4180908203125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1258.7930908203125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 861.6943359375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1153.959716796875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1039.538818359375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1875.9466552734375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1079.6710205078125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1202.54296875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 833.2764892578125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3411.69921875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1121.0137939453125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1101.2052001953125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 2285.208984375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 878.3258666992188 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1190.135986328125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1477.6085205078125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1118.66748046875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 762.2597045898438 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1749.353271484375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3202.76025390625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 2446.0966796875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2101.64306640625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1644.5804443359375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1413.3028564453125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 2116.9873046875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1458.0830078125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1050.3695068359375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1524.1578369140625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 739.6716918945312 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2640.0283203125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1048.150390625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 708.2095336914062 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 683.55126953125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 2690.408447265625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2758.39111328125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1536.862548828125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 2764.110107421875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: -5116.130859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 981.7300415039062 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 961.7498168945312 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1672.817138671875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1180.4197998046875 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 2209.53173828125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 2951.74560546875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 2358.945068359375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1339.0478515625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 867.5938110351562 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 2337.869873046875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1766.5301513671875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2974.879638671875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1386.3929443359375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1245.4434814453125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 838.28125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 711.8582763671875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 779.6487426757812 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 704.9818115234375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1023.4987182617188 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1573.8226318359375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1114.5185546875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2841.529541015625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 999.9931640625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 791.25 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1953.1971435546875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1968.531982421875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1213.53662109375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1417.4244384765625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1258.1436767578125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 987.7013549804688 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1499.1748046875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1666.030029296875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1641.939697265625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1052.48046875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1050.42919921875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1607.8558349609375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1851.718505859375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1678.68115234375 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2739.8759765625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1196.8079833984375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1443.271728515625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2269.851318359375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2035.1029052734375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 711.4559326171875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1461.37939453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1480.862548828125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1071.33837890625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2439.426513671875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1535.0389404296875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1408.734619140625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 3147.654541015625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 703.81689453125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 789.6726684570312 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1121.57861328125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2047.6209716796875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1261.642822265625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1229.990478515625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1486.5303955078125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1257.5782470703125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1009.752685546875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 905.6324462890625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 863.0866088867188 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 2338.469482421875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1288.09814453125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 2175.249755859375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 935.2291259765625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 3762.4111328125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1217.0970458984375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1556.1441650390625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1394.9503173828125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 831.002197265625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2541.975341796875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2611.49658203125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1333.014404296875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1040.3922119140625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1234.980224609375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1433.82568359375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 706.9884643554688 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 745.917724609375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1250.0233154296875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2252.538818359375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2031.981201171875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1426.6483154296875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1159.9146728515625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2671.152099609375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1587.7496337890625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 854.385986328125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2685.582275390625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1322.22998046875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1400.51513671875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 850.2250366210938 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 3755.064208984375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1293.6689453125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 819.9945678710938 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1532.6973876953125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1763.895751953125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1808.591796875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1357.6285400390625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1109.7828369140625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1361.5477294921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1018.2122802734375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1246.50244140625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1038.7772216796875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1096.2877197265625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 983.0774536132812 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1635.2080078125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 857.0209350585938 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1882.7532958984375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3729.611328125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1473.3465576171875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 980.538330078125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 901.6539306640625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1505.2518310546875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 615.66748046875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1918.6087646484375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1385.8173828125 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1317.0428466796875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1961.3221435546875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 949.8934326171875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1128.029541015625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1041.02490234375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1394.7515869140625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1457.1336669921875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1275.8651123046875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 6067.3857421875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1325.4847412109375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 780.6007690429688 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 3024.754638671875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 21161.73828125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1314.978759765625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 664.8958129882812 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2111.601806640625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1333.972900390625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 3322.25 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1959.1976318359375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2314.984130859375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1504.78369140625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 3435.27099609375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2042.4114990234375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 10062.5576171875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1787.9332275390625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 21456.162109375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 4968.18994140625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2432.152587890625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1105.5703125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 825.21630859375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1292.935791015625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1571.5985107421875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1120.7598876953125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 2864.928466796875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2095.212646484375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 2783.614990234375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 4424.24169921875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1630.5079345703125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1685.5177001953125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2249.975830078125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1411.0792236328125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1000.7188720703125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1099.6170654296875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 779.3130493164062 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1210.676513671875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 12659.61328125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1386.7613525390625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 925.685546875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1183.818359375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 788.6682739257812 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1132.875732421875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 750.5881958007812 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 918.1486206054688 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 822.3283081054688 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1776.8172607421875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 753.017333984375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1495.7271728515625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 731.9619750976562 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 557.2421264648438 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 562.57373046875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 513.3575439453125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1604.8892822265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1423.591552734375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1157.122314453125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 992.3707275390625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1112.8316650390625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 827.6278686523438 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 784.04931640625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 834.1065063476562 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1033.255859375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 788.1724853515625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1459.505859375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2586.599609375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 995.9962768554688 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 863.1993408203125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 928.1392211914062 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 685.516845703125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 758.39892578125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1440.13916015625 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2478.232666015625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 857.7329711914062 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1263.849365234375 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 898.9472045898438 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 4282.185546875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 949.4324340820312 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2019.8165283203125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1355.982666015625 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1776.0423583984375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1779.24072265625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1342.442626953125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1103.44140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1128.5478515625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1396.7952880859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1762.0213623046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 587.1494140625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1152.5889892578125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2638.947021484375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 4938.08837890625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1443.09423828125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 2265.652099609375 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 3838.30859375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1864.0655517578125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 954.8611450195312 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1331.9774169921875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 805.9767456054688 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1191.2996826171875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1837.0452880859375 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 8670.728515625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2026.419189453125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1087.9388427734375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 5217.8974609375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1624.007080078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 3351.0791015625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1607.5325927734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1202.711669921875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 3163.23291015625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 2924.004150390625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1289.4771728515625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1899.3682861328125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1114.2244873046875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 5179.20068359375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 934.9794311523438 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 960.0226440429688 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2311.61669921875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 726.7384643554688 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 885.2197875976562 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2874.302001953125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 945.5060424804688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 3430.357666015625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1150.1561279296875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2417.8466796875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2180.3125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1076.905517578125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 948.0155639648438 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 804.0589599609375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 966.8508911132812 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 935.8580932617188 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2252.523193359375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 806.1492309570312 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 3196.85107421875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 875.515380859375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 869.8931274414062 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1828.2733154296875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2288.675537109375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 967.950927734375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 818.380126953125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1281.775146484375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 778.4246215820312 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 868.9420776367188 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 755.8746948242188 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 865.6455078125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 844.8742065429688 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 864.3820190429688 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 915.9976196289062 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1289.6959228515625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1533.7620849609375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1759.0194091796875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1034.846923828125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2050.031494140625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 866.7622680664062 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1106.8760986328125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 646.5068359375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1178.1671142578125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1174.693115234375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 975.7794189453125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 641.4266357421875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1026.946044921875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1319.09130859375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1170.596435546875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2599.44921875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 727.4198608398438 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 657.24853515625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 826.980224609375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1100.2093505859375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1068.89404296875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2922.82177734375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1238.316162109375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1003.9073486328125 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 650.9255981445312 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1764.71240234375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2009.49951171875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1168.728759765625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1249.6119384765625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1468.9893798828125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1217.62939453125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1636.6309814453125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1189.2586669921875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1071.64599609375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1794.8463134765625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2114.629638671875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1470.4185791015625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2032.6962890625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 790.8013916015625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 2259.919189453125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1814.6885986328125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 5054.90966796875 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1034.9237060546875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1065.9080810546875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1192.86865234375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1550.7425537109375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2048.821044921875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1038.951416015625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2599.323486328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1876.4617919921875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 26597.486328125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 5858.6298828125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1800.9073486328125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1522.453125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2196.83056640625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2534.2060546875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 5666.234375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1349.552978515625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 840.8849487304688 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1306.1070556640625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 8771.6171875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 4132.1083984375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1346.0986328125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 3236.405517578125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1872.2491455078125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2193.5859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1287.44677734375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 942.7487182617188 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1446.5628662109375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1454.6220703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1239.75732421875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1203.82421875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 875.0294799804688 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1065.1668701171875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1266.4993896484375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 3194.203857421875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2398.155517578125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 588.3468627929688 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 851.3088989257812 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1310.731689453125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1866.2025146484375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2435.482666015625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1187.60302734375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 885.1602783203125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1460.6165771484375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1362.8499755859375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 5170.19873046875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 3368.3876953125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 700.966796875 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1593.9127197265625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 3538.596435546875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1087.8759765625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1118.6458740234375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1549.2601318359375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 648.4404907226562 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 3227.592041015625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 2452.784912109375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1012.7608642578125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1157.14208984375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1450.0894775390625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1145.8875732421875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 819.6788940429688 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1772.901123046875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2248.462890625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1111.8680419921875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1298.7490234375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1061.386962890625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1153.4718017578125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 2640.47119140625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 778.9343872070312 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1484.5045166015625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1518.6744384765625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 868.1240234375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 701.4417724609375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1189.7216796875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1188.70556640625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1335.4849853515625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 719.908935546875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1056.7880859375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 630.7911376953125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 839.2180786132812 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 4383.1298828125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1037.884521484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1171.327880859375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 3319.644775390625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 833.6986083984375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 660.44677734375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2181.09765625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 3678.975341796875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2322.401611328125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 784.6488037109375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 773.7437744140625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1583.9610595703125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1498.6790771484375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1797.38623046875 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1465.478271484375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 909.1106567382812 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 532.1959838867188 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 4003.017333984375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1637.6053466796875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 770.59033203125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1257.197021484375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1655.1944580078125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1406.5264892578125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1082.07470703125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 610.2026977539062 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1605.1151123046875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1843.02001953125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1245.9178466796875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 909.841796875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1502.893310546875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2841.371826171875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1648.942626953125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1004.7644653320312 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1181.7763671875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1112.5155029296875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1351.0692138671875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 959.9163818359375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2720.377685546875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1002.2255859375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1495.6982421875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1343.33447265625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2561.40869140625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 4496.44970703125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 849.5579223632812 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1686.7117919921875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1533.0506591796875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1963.1630859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1253.1771240234375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1132.5128173828125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1476.31103515625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2270.529296875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1854.98046875 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1397.1727294921875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 3497.214111328125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1744.8197021484375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1831.5064697265625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 982.2254028320312 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2862.57861328125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 765.0878295898438 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 3070.502685546875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1400.5714111328125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 938.1031494140625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1169.5733642578125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 891.6062622070312 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1540.6187744140625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1499.9534912109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 894.4306030273438 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 945.8829956054688 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1797.678955078125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1461.3271484375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 975.5642700195312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1243.04443359375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 632.9653930664062 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 775.8213500976562 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2688.403564453125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1032.343994140625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 827.1808471679688 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1276.3583984375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1064.3704833984375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 968.9437866210938 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 974.7411499023438 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1576.13037109375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1155.58056640625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1520.442138671875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1835.2952880859375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 894.6346435546875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 696.8250732421875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1321.881591796875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1079.5084228515625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 982.4962158203125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1868.616943359375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1770.375732421875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 3050.93603515625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1883.5155029296875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: -13598.29296875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1410.8494873046875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 637.141357421875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1802.4033203125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 3363.003173828125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1753.4530029296875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1740.06640625 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 848.117431640625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1572.485595703125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1863.0438232421875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1489.9722900390625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2212.4697265625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1699.58935546875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1251.16357421875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1733.0574951171875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 13111.8837890625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1686.7630615234375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1094.3739013671875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1036.5501708984375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1615.5880126953125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 3637.68701171875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1170.0233154296875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 951.2595825195312 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1098.476806640625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 988.2737426757812 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1988.977783203125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 621.5180053710938 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 8883.6455078125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 5374.31201171875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1169.2947998046875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 913.0442504882812 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 2212.00732421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 13077.5615234375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2092.553955078125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 4346.6181640625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1361.7498779296875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1888.9866943359375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1630.830078125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1233.2242431640625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1195.464599609375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1196.86328125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 961.8142700195312 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1233.76904296875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 762.5804443359375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1601.8594970703125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1357.9466552734375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1213.669677734375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1042.2650146484375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1705.19677734375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1645.1815185546875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 719.6492919921875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1995.9420166015625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 916.6362915039062 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 956.2618408203125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 624.5798950195312 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1523.28759765625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1183.02783203125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1304.05810546875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1588.6029052734375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 880.47314453125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1213.6610107421875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1075.15478515625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1316.9932861328125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1406.472412109375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2416.54443359375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1439.35302734375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1241.4271240234375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 3856.87939453125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1792.1048583984375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 2487.831298828125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2800.168212890625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: -32039.4140625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 3148.0087890625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1898.515380859375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1835.24853515625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1883.5126953125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1214.5650634765625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 3338.306884765625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1319.960205078125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 704.3590698242188 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1543.472900390625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1417.403564453125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1182.1678466796875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1035.933837890625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1027.83935546875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1083.707763671875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1726.4290771484375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2226.53125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 611.30810546875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1682.3975830078125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 984.5790405273438 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 970.3162231445312 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1680.2015380859375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 929.3466186523438 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 725.2301635742188 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1164.19873046875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1481.24169921875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2203.151123046875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1538.0181884765625 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 2035.403564453125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1320.11376953125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 3584.7509765625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1978.629150390625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 749.1919555664062 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1745.0911865234375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1355.3021240234375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1726.0721435546875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1270.3939208984375 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 889.1303100585938 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 9902.845703125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1401.3167724609375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 2289.320556640625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 5306.439453125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1249.141845703125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1322.341064453125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 3077.9052734375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 3707.06884765625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2148.80859375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1239.0 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1437.939208984375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1609.8609619140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 827.080078125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/300000 [2:44:43<103107:07:34, 1237.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Iter: 0/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1102.3458251953125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1920.077880859375 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1267.6754150390625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1291.6595458984375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1378.7940673828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1004.037841796875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1548.5928955078125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1827.9136962890625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1620.94384765625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1264.5333251953125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 745.9796142578125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1740.30859375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 5883.60205078125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 811.2192993164062 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1148.5386962890625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2106.351318359375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1195.687255859375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2007.29150390625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1315.8951416015625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1223.83349609375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1916.549072265625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1145.0479736328125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 673.9437866210938 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 819.7024536132812 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 2365.67822265625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 2472.453125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 2691.23681640625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1521.820068359375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1288.503173828125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 859.1744384765625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2196.79345703125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1209.842041015625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1529.66357421875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 798.4937744140625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1052.6422119140625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1402.4193115234375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1457.2537841796875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1714.5260009765625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1026.0374755859375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1065.5318603515625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 4976.0771484375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1658.621826171875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2399.112060546875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1021.8055419921875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2085.267333984375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1512.3917236328125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1107.2064208984375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1080.8607177734375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 3072.737060546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 4737.11279296875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 2019.60986328125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 982.2710571289062 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1009.1521606445312 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1603.1231689453125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1549.69189453125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1339.3626708984375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 2068.6416015625 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss  Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix  Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josh/Documents//github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/ResNet18_simCLR_model_202112078_EOD_transfmod=default_losses_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-de25315fd340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_train_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_val_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josh/Documents//github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/ResNet18_simCLR_model_202112078_EOD_transfmod=default_losses_train.npy'"
     ]
    }
   ],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE  RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scripted_transforms_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-423cf9bf6d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0;31m# class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscripted_transforms_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                     \u001b[0;31m# DEVICE='cpu',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mDEVICE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scripted_transforms_validation' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "#                                     torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "#                                     torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "#                                     torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "#                                     torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [33:47<00:00, 40.55s/it]  \n",
      "100%|| 50/50 [19:09<00:00, 22.99s/it]\n",
      "100%|| 50/50 [12:27<00:00, 14.94s/it]\n",
      "100%|| 50/50 [07:02<00:00,  8.45s/it]\n",
      "100%|| 50/50 [04:21<00:00,  5.24s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "# train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train_SYT[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "# test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train_SYT[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "c_lst = [1e1, 1e0, 1e-1, 1e-2, 1e-3]\n",
    "\n",
    "fig, ax = plt.subplots(len(c_lst), 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train  C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val  C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-2)).fit(features_train, y_labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEICAYAAAD8yyfzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzrElEQVR4nO3deVxV1f7/8ddHHHFgUFMRREkkwSE1zS75TQ3N4aamWZrDrVtqmRqlppZNVy0rjfqlZZpW1+tw81rJ7VqWU6mFQ844AU7ghAaOIKSu3x/gCeQwKId9jsfP8/E4jzzr7LX32pvTm3XWXusgxhiUUkpZo5SzG6CUUrcSDV2llLKQhq5SSllIQ1cppSykoauUUhbS0FVKKQtp6CqXISJtRSTJ2e1QqiRp6CqllIU0dJVSykIausrhRGSsiPznmrIPROT/icgTIrJbRM6JyH4RGeKsdirlDBq6qiQsALqISBUAEfEAHgHmA8nAX4EqwBNAlIg0d1ZDlbKahq5yOGPMIWAz0CO7qD2QZoyJMcb8zxiTYLL8BPwAtHFSU5WynIauKinzgb7Z/34s+zki0llEYkQkRUROA12Aas5polLW09BVJWUR0FZE/IGHgPkiUg5YDEwBahhjvIGlgDitlUpZTENXlQhjzElgNfAZcMAYsxsoC5QDTgKXRKQz0NFpjVTKCTR0VUmaD0Rk/xdjzDlgBPAlkErWsEO001qnlBOIfom5UkpZR3u6SillIQ1dpZTKh4jMEZFkEdmZz+uSvegnXkS2F2XOuYauUkrl73OgUwGvdwaCsx+DgY8L26GGrlJK5cMY8zOQUsAm3YF/Zi/2iQG8RaRWQfss7cgG2hMXF6d36rJ17tzZ2U1wGQkJCc5ugnJBxhhHzNkucuZkf/fH4BxFM40xM6/jWLWBxBzPk7LLjuVXocRDVymlXFV2wF5PyF7L3i+JAkNfQ1cp5VauZxqsSLE71klAQI7n/sDRgiromK5Syq1cuXKlyA8HiAYGZs9iaA2cMcbkO7QA2tNVSrkZRy74EpEFQFugWvafknoNKJN9nBlkfXdIFyAeSCPr60oLpKGrlHIrjgxdY0zfQl43wLPXs08NXaWUW3H1rzbQ0FVKuRUNXaWUspCGrlJKWchBsxJKjIauUsqtaE9XKaUspKGrlFIW0tBVSikLaegqpZSF9EaaUkpZSHu6SillIQ1dpZSykIauUkpZSENXKaUspKGrlFIW0tkLDnLy5ElmzZrF1q1bMcZw5513MmjQIG677bZC6yYnJ/Ovf/2LHTt2cPbsWapWrUqbNm3o3bs35cuXt23397//neTk5Dz1X375Ze655x6Hnk9x1KpVi5dffpnw8HBEhHXr1jFx4kSOHSvwC+sBGDlyJI0bNyYsLAwfHx9efPFFvvrqqwLr/PWvf+X999/n+PHj3HvvvY46Dafx9/cnKiqKDh06ICIsX76cyMhIEhMTC6/sRtz1OmhP1wEuXrzISy+9RJkyZXj++ecREebOnctLL73EtGnTcgWnvbrjx4/n8uXL9O/fn+rVq7Nv3z7mz5/P0aNHGTNmTK7tmzdvzmOPPZarzN/fv0TO60aUL1+euXPnkpmZyejRowF4/vnnmTdvHl27diU9Pb3A+gMGDGD37t2sWrWKnj17Fnq8ypUr8/LLL9v9ZXQzqlChAitXriQjI4O//e1vGGOYOHEiq1atokmTJqSlpTm7iZZw5+ugoesAy5Yt48SJE8yYMQM/Pz8A6taty+DBg/nuu+946KGH8q27a9cujh49yj/+8Q+aN28OQJMmTTh//jxfffUVFy9ezBXaVapU4Y477ijZEyqGRx99lICAADp27MihQ4cA2LNnD8uXL6dv377MmTOnwPrNmjXDGENgYGCRQnfMmDHs2bOH5ORkwsPDHXIOzjRo0CCCgoIICQmx/Rn47du3ExcXx5AhQ4iKinJyC63hztfB1UP3pvjDlOvXryckJMQWuAA1a9YkNDSU9evXF1j30qVLAHh6euYqr1ixosv/cOy5//772bp1qy1wAZKSkti8eTMRERGF1r+ec27evDndu3fn9ddfv5GmuqRu3boRExNjCxqAgwcPsm7dOrp37+7EllnLna+DMabID2e4KUL38OHDBAYG5imvU6cOhw8fLrDunXfeiZ+fH59//jmHDx8mPT2dbdu2ER0dTefOnfMMTWzYsIFevXrRo0cPRo4cya+//urQcymu4OBg9u3bl6c8Li6O+vXrO+w4pUuXZtKkSXz66ae5Av5mFxYWxs6dO/OUx8bGEhoa6oQWOYc7XweL/xrwdSt0eEFE7gC6A7UBQ9bfdI82xuwu4bbZnD9/nkqVKuUpr1y5MufPny+wbtmyZXnnnXd48803GTp0qK28Y8eOPP3007m2bdWqFcHBwdSoUYPTp0/z7bffMmnSJEaOHEm7du0cczLF5OXlxdmzZ/OUnz59mipVqjjsOIMHD6Zs2bJ8/PHHDtunK/D19SU1NTVPeUpKCj4+Pk5okXO483Vw9U+wBYauiIwB+gILgQ3Zxf7AAhFZaIyZXMLtK1BRLm5mZiZvv/02Z86cYeTIkbYbaQsWLMDDw4Nnn/3zD3leG8L33HMPo0aN4osvvnCZ0AX75y0iDtt/YGAgQ4cOZejQoWRmZjpsv66ipK/fzcJdr8NNHbrAk0CYMeaPnIUi8h4QC9gNXREZDAwG+Mc//kGfPn2K1chKlSrZ7dHm1wPO6YcffmDHjh3MmjWLWrVqAdCoUSM8PT2ZNm0anTt3JigoyG5dDw8PwsPD+fzzz0lJScHX17dY5+EIZ8+excvLK095fj3gG/HKK6/w66+/smXLFipXrgxAmTJlgKxPF5mZmWRkZDjkWFZLTU21+3P08fGx2/NzV+58HW720L0C+AHXDurVyn7NLmPMTGAmQFxcXLGvQH5jt4cPH6ZOnToF1j148CCVKlWyBe5VDRo0ACAxMTHf0M3JVXoAcXFxBAcH5ymvX78+8fHxDjlG/fr18ff3Z8uWLXle27JlC5999hmTJk1yyLGsFhsbS1hYWJ7y0NBQdu3a5YQWOYc7XwdXD93CbqRFAitE5DsRmZn9+B5YATxX4q3Ldvfdd7Nnzx6OHz9uKztx4gS7d++mVatWBdb18fHh/PnzHD16NFf51ZtRVatWzbfu5cuXWbt2LdWrV3eZca4VK1Zw5513EhAQYCurXbs2zZs3Z8WKFQ45RmRkJP369cv1+Pnnn0lJSaFfv37861//cshxnCE6OprWrVtTr149W1lgYCDh4eFER0c7sWXWcufr4OqzF6SwA4tIKaAVWTfSBEgCNhpjLhflAI7o6V68eJHhw4dTtmxZBgwYYFsckZ6ezrRp06hQoQKQtfLsqaeeom/fvvTt2xfICudhw4bh4+PDo48+SvXq1YmLi2PhwoXUrl2b9957j1KlSvHTTz8RExPDXXfdRfXq1UlNTeV///sfu3btYvTo0dx3333FPQ06d+5c7H1UqFCBb7/9losXLxIVFYUxhsjISCpWrMhf//pX26R2Pz8/Vq5cybRp05g2bZqtfqtWrfD19aV69eq89tprzJ071zbt7vvvv8/3uG+//Tbh4eEOW5GWc6qSlTw9Pdm2bRvp6emMHz8eYwwTJkygcuXKNGnShAsXLjilXVZz1etgjCn2R8r4+PgiZ079+vUt/whb6OwFY8wVIMaCtuSrfPnytulLU6dOBaBp06YMGjTIFriQ9Rvu2qkgNWrUYOrUqcyfP5+5c+dy9uxZqlWrRqdOnXj00UcpVaqUbbszZ87w2Wefce7cOcqVK0dwcDBvvPEGLVq0sPaEC5Cenk7//v15+eWXmTJlCgC//vorEydOzLWKSEQoXbq07fyueu6557j77rttzwcMGMCAAQMAHDrlzFWlpaXRvn17oqKimDt3LiLCihUriIyMvGUCF9z7Orj68EKhPd3ickRP1104oqfrLpzV01WuzRE93X379hU5cxo0aOB6PV2llLqZuHpPV0NXKeVWNHSVUspCGrpKKWUh/RJzpZSykPZ0lVLKQhq6SillIVcP3Zvi+3SVUqqoHLkMWEQ6icheEYkXkbF2XvcSkf+KyDYRiRWRJwrbp/Z0lVJuxVE30kTEA5gOdCD76w9EJNoYk/MbgZ4FdhljHhSR6sBeEZlnjMn3O1G1p6uUcisO7Om2AuKNMfuzQ3QhWX/QIdfhgMqS9TWElYAU4FJBO9XQVUq5lesJXREZLCKbcjwG59hVbSDn36NPyi7LaRrQkKy/qLMDeC77+2rypcMLSim3cj030nJ+97cd9r6X4dqdPwBsBdoDtwM/isgaY0y+f1FAe7pKKbfiwOGFJCAgx3N/snq0OT0BfGWyxAMHgDsK2qmGrlLKrTgwdDcCwSJST0TKAn2Aa7/h/TBwP4CI1ABCgP0F7VSHF5RSbsVRsxeMMZdEZBiwDPAA5hhjYkXk6ezXZwATgM9FZAdZwxFjjDGnCtqvhq5Syq04cnGEMWYpsPSashk5/n0U6Hg9+9TQVUq5FVdfkaahq5RyKxq6SillIQ1dpZSy0C0ful27di3pQ9w0PvjgA2c3wWUMHz7c2U1wGQcOHHB2E9yKfom5UkpZ6Jbv6SqllJU0dJVSykIaukopZSENXaWUspDeSFNKKQtpT1cppSykoauUUhbS0FVKKQtp6CqllIU0dJVSykI6e0EppSykPV2llLKQhq5SSllIQ1cppSykoauUUhbS0FVKKQvp7AWllLKQ9nSVUspCGrpKKWUhDV0HqVmzJi+99BLh4eGICL/88guTJk3i2LFjhdZ94YUXaNSoEWFhYfj4+DBmzBi+/vrrPNutXLkSf3//POVDhw5l+fLlDjmPkpKamsqSJUvYt28fxhgaNGhAjx498PHxKbDe999/zw8//GD3tdKlS/POO++URHMdplatWowfP557770XgF9++YUJEyZw9OjRQuuOGjWKxo0b06hRI3x8fBg9ejSLFy/OtU3FihWZPHkyYWFh3HbbbVy6dIn9+/fzxRdfsGTJkhI5J6v4+/sTFRVFhw4dEBGWL19OZGQkiYmJzm5asWjoOkD58uX55z//SWZmJmPGjMEYQ2RkJHPnzuXBBx8kPT29wPr9+/dnz549rF69moceeqjAbX/++Wc+/PDDXGWu/tdaMzMz+fjjjyldujR9+/ZFRFi6dCkfffQRo0aNoly5cvnWbd26NXfccUee/c2cOZOwsLCSbnqxlC9fnnnz5pGRkcGoUaMwxjBy5EjmzZtHly5dCn1fDBw4kN27d7Ny5Up69epld5syZcpw+fJlZsyYQVJSEmXLlqVr165ERUVRtWpV5syZUxKnVuIqVKjAypUrycjI4G9/+xvGGCZOnMiqVato0qQJaWlpzm7iDdMbaQ7wyCOPEBAQwAMPPMDhw4cB2Lt3Lz/88AN9+vThs88+K7B+ixYtMMZQp06dQkM3NTWVbdu2OaztVoiJieH3339n7NixVK9eHcjqAb711lv8+uuvtG3bNt+63t7eeHt75yrbtGkTV65coWXLliXY6uLr06cPAQEBREREcOjQIQD27NnDypUreeyxx5g9e3aB9Zs2bYoxhsDAwHxD9/Tp00RGRuYqW716NfXq1aN37943begOGjSIoKAgQkJCSEhIAGD79u3ExcUxZMgQoqKinNzCG+fqPd1Szm5AUdx///1s3brVFrgASUlJbN68mfvvv7/Q+q7+Qyiu2NhYAgMDbYELULVqVerWrcvOnTuve38bN26kcuXKhISEOLKZDhcREcGWLVtsgQtZ74vffvuNiIiIQusX531x+vRp/vjjjxuu72zdunUjJibGFrgABw8eZN26dXTv3t2JLSs+Y0yRH85wU4Ru/fr1iYuLy1MeFxdH/fr1HXqs9u3bs23bNnbu3MmXX35ZpP95ne348ePUrFkzT3nNmjU5ceLEde3r9OnTxMfH07x5czw8PBzVxBIRHBzMvn378pSXxPsCwMPDA29vb/r06UObNm0K/YTlysLCwuz+Qo6NjSU0NNQJLXIcVw/dm2J4wcvLi7Nnz+YpP3PmDFWqVHHYcVatWsWOHTtISkqiatWq9O/f3zYuGh0d7bDjOFpaWhqenp55yj09PQsd17zWpk2bMMa4/NAC5P++OH36NF5eXg491oABA3jjjTeArDHvCRMm2L0Ze7Pw9fUlNTU1T3lKSkqhN19dnat/sr3h0BWRJ4wxlv2qt3chRcShx5gwYUKu5z/++COLFi1i5MiRLh26jrRp0yZq166Nn5+fs5tSJFa8LwD+97//sXXrVnx8fIiIiOC1117j8uXLLFiwwOHHsopV185qrh66xRleeCO/F0RksIhsEpFNZ86cKcYhspw9e9Zuz6VKlSp2ezqOcuXKFb777jtq1aqVa7zU1VSoUMHu3ea0tDQqVKhQ5P0cOnSI5OTkm6KXC/m/L7y8vHDE+y6nlJQUduzYwc8//8yrr77K119/zbhx4yhd+qb4sJhHamoqvr6+ecp9fHzs9oBvJleuXCnywxkKDF0R2Z7PYwdQI796xpiZxpi7jDF3OeJjXlxcHMHBwXnK69evT3x8fLH3X5Crv/ld+bdnfmO3J06coEaNfH9MeWzatIlSpUrRvHlzRzavxOzbt48GDRrkKbfifbFjxw4qVapEtWrVSvQ4JSU2NtbulMDQ0FB27drlhBY5jquP6RbW060BDAQetPP4vWSb9qeVK1fStGlTAgICbGW1a9emefPmrFy5ssSO6+HhQadOnThy5AinTp0qseMUV1hYGIcOHeL33//8kaSkpHDgwAEaNWpUpH1cunSJLVu20LBhQypVqlRSTXWoFStWcOedd+Z5X7Ro0aLEF7PcfffdnD9/Ptc1v5lER0fTunVr6tWrZysLDAwkPDz8ph9Kc2ToikgnEdkrIvEiMjafbdqKyFYRiRWRnwrbZ2Gfjb4FKhljtto50OpCW+wgX375pe2m1vvvv29bHHH8+HEWLlxo287Pz4/ly5czffp0pk+fbitv2bIlvr6+tiGCxo0b2z6OL1u2DICuXbsSERHBTz/9xLFjx6hWrRr9+vWjcePGPP/881ad6g1p3bo1a9euZfbs2XTp0gWA7777Dm9vb+655x7bdikpKbz55pt06NCBBx54INc+du3aRVpa2k0ztACwcOFCBgwYwMyZM5k6dSrGGF544QWOHTuWa6zVz8+P1atX8+GHH+Za+NKqVSuqVq1q663mfF989913APTt25dmzZqxbt06jh07ho+PD126dKFLly68/fbbN+20sVmzZjFs2DCWLFnC+PHjMcYwYcIEEhMT+eSTT5zdvGJxVA9WRDyA6UAHIAnYKCLRxphdObbxBj4COhljDovIbYXtt8DQNcY8WcBrjxWx7cWWnp7OwIEDeemll3j33XeBrAUBkyZNyjWWKSKULl2aUqVyd+BHjBjB3XffbXvev39/+vfvD2D7eJqUlISvry8vvvgiXl5eXLx4kR07dvD3v/+dtWvXlvQpFku5cuUYOnQo33zzDfPmzQOyplP16NEjz2q0K1eu2H1Tbty4EU9Pz5tqulB6ejr9+/dn/PjxTJ061bY8fMKECUV6X0RGRtK6dWvb84EDBzJw4EAAgoKCgKxFOB06dGDcuHF4eXmRmppKQkICTz75JKtWrbLgLEtGWloa7du3Jyoqirlz5yIirFixgsjISC5cuODs5hWLA4cNWgHxxpj9ACKyEOgO5Bx/eQz4yhhzOPvYyYXtVEp6XKNBgwauOxhqsZt5lY+jDR8+3NlNcBmuvszcSsaYYk+fmDlzZpEzZ8iQIUOAwTmrG2NmAojIw2T1YJ/Kfj4AuNsYM+zqxiLyPlAGCAMqAx8YY/5Z0DFvzluvSimVj+vpSGYH7Mx8Xrb3C+DanZcGWgD3AxWAX0UkxhiTd9VOjgpKKeU2HPjpPQkIyPHcH7j26+uSgFPGmAvABRH5GWgK5Bu6N8UyYKWUKioHzl7YCASLSD0RKQv0Aa6d2rEEaCMipUXEE7gb2F3QTrWnq5RyK47q6RpjLonIMGAZ4AHMMcbEisjT2a/PMMbsFpHvge3AFeBTY0yB3zKloauUciuOnBxgjFkKLL2mbMY1z98F3i3qPjV0lVJuRb/EXCmlLOTKS/ZBQ1cp5WY0dJVSykIaukopZSENXaWUspCGrlJKWUhnLyillIW0p6uUUhbS0FVKKQtp6CqllIU0dJVSykJ6I00ppSykPV2llLKQhq5SSllIQ1cppSx0y4duXFxcSR/ipjFq1ChnN8FlLFiwwNlNcBmDBw8ufCNVZLd86CqllJV09oJSSllIe7pKKWUhDV2llLKQhq5SSllIQ1cppSykoauUUhbS2QtKKWUh7ekqpZSFNHSVUspCGrpKKWUhDV2llLKQ3khTSikLaU9XKaUspKGrlFIW0tBVSikLaegqpZSFNHSVUspCrj57oZSzG6CUUo5kjCnyozAi0klE9opIvIiMLWC7liJyWUQeLmyf2tNVSrkVRw0viIgHMB3oACQBG0Uk2hizy852bwPLirJftw5df39/oqKi6NChAyLC8uXLiYyMJDEx0dlNK5aaNWsyduxY/vKXvyAi/Prrr7z11lscO3as0LqRkZE0atSIsLAwvL29GTduHN98843dbW+77TZGjBjB//3f/+Hl5UVycjJLly4lKirKwWd0437//Xfmz5/Pzp07McYQFhZGv379qFatWoH1vvrqq3zPu0yZMsyePdv2/Ny5cyxcuJCtW7dy8eJFAgIC6NmzJ02aNHHkqRRbjRo1GD16NK1bt0ZEWL9+Pe+88w7Hjx8vtO7w4cMJCwujYcOGeHt788orrxAdHZ1nOy8vL4YMGcJ9991HtWrV+P3331mzZg0zZswgNTW1JE7rujlwTLcVEG+M2Q8gIguB7sCua7YbDiwGWhZlp24buhUqVGDlypVkZGTwt7/9DWMMEydOZNWqVTRp0oS0tDRnN/GGlC9fns8//5zMzEzGjRuHMYbnnnuOzz//nB49epCenl5g/f79+7N7925Wr15Njx498t3Oz8+P+fPnk5SUxJtvvsnvv/+On58fgYGBDj6jG5eRkcHkyZMpXbq07S/qLl68mMmTJzNp0iTKlSuXb922bdvmCc2MjAymTJlCs2bNbGV//PEHkydP5ty5czz66KN4eXnx888/ExUVxYsvvkjDhg1L5uSuU/ny5Zk1axZ//PEHr7zyCsYYhg0bxqeffkrv3r0LfV/07duXvXv38vPPP9OtW7d8t/vggw8IDAzko48+4sCBAwQFBfHss8/SsGFDBg4c6OjTuiHXE7oiMhjI+eeYZxpjZmb/uzaQs4eWBNx9Tf3awENAe2710B00aBBBQUGEhISQkJAAwPbt24mLi2PIkCEu1Vu7Hr1798bf358uXbpw+PBhAPbu3cv333/PI488whdffFFg/ZYtW2KMoU6dOgWG7uuvv86JEyd4/PHHuXTpkiNPwWFWr15NcnIy77zzDjVq1ACgTp06jB49mpUrV9K5c+d86/r6+uLr65urbN26dVy+fJl7773XVrZhwwYSExMZN26cLWCbNGnC+PHj+fe//83rr7/u+BO7AT179sTf35/u3bvbPsnFxcURHR3Nww8/zNy5cwusHx4ejjGGgICAfEM3MDCQZs2a8Y9//IPFixcDsGnTJowxjB8/nsDAQA4dOuTYE7sB1xO62QE7M5+XxV6Va56/D4wxxlwWsbd5Xm57I61bt27ExMTYAhfg4MGDrFu3ju7duzuxZcXTrl07tm3bZgtcgCNHjrBlyxbuv//+QusX5Q0ZEBBAmzZtmDdvnssGLsCWLVuoX7++LXABqlevTnBwMJs3b77u/a1ZswYvLy8aN25sK0tISKBs2bLccccdtjIRoVGjRuzfv5+UlJTinYSDtG3blu3bt+caOjty5Ahbt26lbdu2hdYvyvuiTJkyAFy4cCFX+blz5wAoVco14uTKlStFfhQiCQjI8dwfOHrNNncBC0XkIPAw8JGI9Chop4VeJRG5Q0TuF5FK15R3KqyuM4WFhbFz58485bGxsYSGhjqhRY5Rv3594uLi8pTHx8dz++23O+QYzZs3B+DixYvMnj2bbdu2ERMTw+TJk/H29nbIMRzhyJEj+Pv75ymvXbs2R49e+/9GwVJSUti9ezf33HMPHh4etvJSpUrh4eHBtb2Y0qWzPiQmJSXdQMsd7/bbb8/VwbgqISGBoKAghxwjPj6eTZs2MXjwYEJDQ6lQoQKNGjVi8ODBrFmzhgMHDjjkOMXlwNkLG4FgEaknImWBPkCugW5jTD1jTF1jTF3gP8BQY8w3Be20wNAVkRHAErIGineKSM4u4puFtdiZfH197Q7sp6Sk4OPj44QWOYaXlxdnz57NU37mzBmqVKnikGNUr14dgEmTJnHw4EEGDx7M1KlTue+++5g1a1aeAHKW8+fP4+npmae8UqVKeXpjhVm3bh3GmFxDC5B10zI9PZ0jR47kKo+Pjwfy9vqcxYr3BcCwYcM4ePAgCxYsICYmhnnz5nHkyBFGjhzpsGMUl6NC1xhzCRhG1qyE3cCXxphYEXlaRJ6+0fYVNqY7CGhhjDkvInWB/4hIXWPMB9gf7wDsDk47hb2L6iqBURwlveLm6sfEDRs2MGHCBADWr1/P+fPnee+997j33ntZs2ZNibahqOz9PG/k+qxdu5bAwEDq1KmTq/yee+7h66+/ZtasWTz55JN4e3uzatUq9u7dm+/xncWK9/urr75K48aNmTBhAvv37ycoKIhnnnmGKVOmMGLECJdYDebINhhjlgJLrymbkc+2jxdln4WFrocx5nz2Dg+KSFuygjeQAkI35+C0iDjlp5CamprnRgmAj4+Py0xtuRFnz57Fy8srT3l+PZ0bcfr0aQB++eWXXOXr1q0DoGHDhi4RuhUrVrTb07xw4QIVK1Ys8n4SEhI4duwY/fr1s3uMESNGMHPmTF5++WUgayrdQw89xOLFi11muCW/90WVKlUc9r5o06YNXbp0YdCgQWzYsAGAzZs3k5SUxCeffMJ9993H6tWrHXKs4nCF4C9IYaF7XETuNMZsBcju8f4VmAM0LrCmk8XGxhIWFpanPDQ0lF27rp1md/OIj4+nfv36ecrzG9O70WNA/m9eV1lmWbt2bbtjqkePHsXPz6/I+1m7di0eHh7cc889dl8PCQlhypQpnDhxgitXrlCzZk2WLl1K2bJlqVu37o0236ESEhLsjukHBQWxf/9+hxwjODgYyPp/K6er906CgoJcInRd5f2Zn8JupA0Ecs2sNsZcMsYMBP6vxFrlANHR0bRu3Zp69erZygIDAwkPD7c76ftmsWrVKpo2bZrrBpKfnx/NmjVj5cqVDjnGtm3bOHnyJG3atMlVfnW8094NSmdo1qwZCQkJJCcn28pOnjxJXFyc7WZgYS5dukRMTAxNmjQpcOxTRKhZsyZ+fn5kZmayevVqwsPDKV++fLHPwxFWr15N48aNqV27tq3Mz8+PO++8k59++skhxzh16hQAjRo1ylV+dbZHzp+DMzlyGXBJKDB0jTFJxhi7y1mMMetKpkmOMWvWLA4ePMiSJUvo1q0bDz74IEuWLCExMZFPPvnE2c27YYsWLeLIkSNMnz6d9u3b065dO6ZPn87x48f58ssvbdv5+fmxY8cOhg4dmqt+y5Yt6dixoy1AGzVqRMeOHenYsaNtm8uXLzN16lTatm3La6+9xl/+8hf69u3Lq6++yvr164mJibHmZAvRrl07qlWrxvvvv89vv/3G5s2bef/99/H19aVdu3a27U6dOsXjjz9udwXali1buHDhQp4baDl9+eWXbNiwwbao5NVXX8XDw4PevXuXxGndkK+++oqjR4/ywQcf0LZtW+677z7ef/99Tpw4waJFi2zb1apVi99++40hQ4bkqt+iRQsiIiIIDw8Hsmb/REREEBERYdtmxYoVJCcnM3HiRHr37k3Lli3p3bs3EydO5NixY6xYscKaky2Eq4eu2y6OSEtLo3379kRFRTF37lxEhBUrVhAZGekyd5xvRHp6Ok888QRjx47l7bffzrUM+NpVdqVLl85zI2XYsGG0atXK9rxfv362scycq6uWLFmCMYannnqKnj17cubMGf773/+61KKScuXKMXbsWObPn2/7RRoaGkq/fv1y9UCNMfnOy1y7di0VK1bMtQrtWmfOnGHevHmcPXuWKlWq0KJFC3r27EmlSpXyrWO19PR0Bg0axOjRo5k0aZJtGfC7776bazWaiNh9XzzzzDO0bPnngqo+ffrQp08fAJo2bQpkjZX379+fZ555hieeeIJq1apx6tQpfvrpJ2bMmFHoqjeruPqYrpR0A511I80V5Zxgf6v7/PPPnd0El3F1CbOCbdu2FXu6xWOPPVbkzJk/f77l00/ctqerlLo1uXpPV0NXKeVWXH32goauUsqtaE9XKaUspKGrlFIW0tBVSikLaegqpZSF9EaaUkpZSHu6SillIQ1dpZSykIauUkpZSENXKaUspKGrlFIW0tkLSillIe3pKqWUhTR0lVLKQhq6SillIQ1dpZSykIauUkpZSGcvKKWUhbSnq2z27Nnj7Ca4jAcffNDZTXAZy5cvd3YT3IqGrlJKWUhDVymlLKShq5RSFtIbaUopZSHt6SqllIU0dJVSykIaukopZSFXD91Szm6AUko5kjGmyI/CiEgnEdkrIvEiMtbO6/1EZHv24xcRaVrYPrWnq5RyK46avSAiHsB0oAOQBGwUkWhjzK4cmx0A7jPGpIpIZ2AmcHdB+9XQVUq5FQcOL7QC4o0x+wFEZCHQHbCFrjHmlxzbxwD+he1UhxeUUm7leoYXRGSwiGzK8RicY1e1gcQcz5Oyy/LzJPBdYe3Tnq5Syq1cT0/XGDOTrCEBe8ReFbsbirQjK3TvLeyYGrpKKbfiwOGFJCAgx3N/4Oi1G4lIE+BToLMx5vfCdqrDC0opt+LA2QsbgWARqSciZYE+QHTODUSkDvAVMMAYs68o7dOerlLKrThq9oIx5pKIDAOWAR7AHGNMrIg8nf36DOBVoCrwkYgAXDLG3FXQfjV0lVJuxZGLI4wxS4Gl15TNyPHvp4CnrmefGrpKKbfi6ivSNHSVUm5FQ1cppSykoauUUhZy9S8xd+spY/7+/ixatIjTp09z5swZFi9eTEBAQOEV3ZA7XAs/Pz9mz55NfHw8CQkJfPbZZ9SuXdACoT+VK1eO1157jR07dnDo0CGWLl1K69at82zn4+PDxIkT2bhxI4cOHWLjxo289dZbVK1aNd99t2zZkuPHj5OcnIyHh8cNn19xnTp1iilTpjBw4EAGDhzIu+++y8mTJ4tU9+TJk0ybNo2nn36afv36MWLECBYsWMDFixdt2xw9epQ5c+YwcuRI+vfvz6BBg5g8eTIHDx4soTO6MY78wpuSICV9YBFxyplVqFCBbdu2kZGRwfjx4zHGMHHiRDw9PWnSpAlpaWnOaJZTuOK1qF69+nVtX6FCBVatWkVGRgaTJ0/GGMPYsWPx9PSkbdu2hZ7Dxx9/TEREBG+88QaHDh3i73//O+3bt6dr167s3LnTtt23335LUFAQ77zzDvv27SMkJIQxY8awf/9+unTpkme/pUuXZvny5VStWpUaNWpQq1YtLl++fF3n5oi/BpyRkcGoUaMoU6YMffr0QURYsGABmZmZTJkyhfLly+db9+LFi7z44otcunSJRx55hGrVqpGQkMC///1v7rrrLl544QUAvvvuO5YvX07btm2pV68eFy5cYMmSJRw8eJAJEyZw++23F/s8mjRpYm8V2HUJCQkpcubs3bu32Me7Xm47vDBo0CCCgoIICQkhISEBgO3btxMXF8eQIUOIiopycgut4w7Xon///gQGBvKXv/yFAwcOALBr1y5iYmIYOHAgM2bMyLduWFgYvXr1YsSIESxcuBCAX375hTVr1vDiiy8ycOBAAIKCgmjVqhUjR45k7ty5tu2uXLnCu+++y+233267flc9++yziAjz58/n+eefL4lTL5Lly5dz4sQJPvjgA2rVqgVAnTp1GDFiBD/++GOBf/J+7969HDt2jPHjx9O0adY3EzZq1Ihz587x3//+l4yMDMqVK0d4eDidOnUiez6qbbtnn32WpUuXMnz48JI9ySJy9TFdtx1e6NatGzExMbn+Jzl48CDr1q2je/fuTmyZ9dzhWjzwwAP89ttvtsAFOHz4MBs2bKBTp06F1s3MzGTJkiW2ssuXL/PNN9/Qrl07ypYtC2D777lz53LVP3PmDAClSuX+36Vu3bpERkYyZswYLl26dOMn5wCbNm2iQYMGtsAFqFGjBiEhIWzcuLHAulfbXqFChVzlFStWzPUxvEqVKrkC9+o2tWrVIiUlxRGn4RCuPrzgtqEbFhaW62PjVbGxsYSGhjqhRc7jDtfijjvuYM+ePXnK9+7dS4MGDQqsGxISwuHDh0lPT89VvmfPHsqVK0e9evVsz3/55RdeeOEFmjZtSsWKFWnWrBkjR45k+fLlxMXF5ar/zjvv8O233xITE1PMsyu+xMREu2P0AQEBJCUlFVi3cePG1KpVi3/9618kJiaSnp7Ojh07WLp0KR06dChwaOLcuXMkJiYWeWzdCq4euoUOL4hIK8AYYzaKSCjQCdiTvVLDZfn6+pKampqnPCUlBR8fHye0yHnc4Vp4e3tz+vTpPOWpqal4e3sXWNfHx8du3atlOes/9thjTJ8+nR9//NFW9sMPP/DUU7kXHT388MM0bdqU8PDwop5CiTp//jwVK1bMU16pUiUuXLhQYN2yZcsyYcIEpkyZYhu/Bbj//vt58sknC6w7Z84cjDF07dr1xhpeAlx99kKBoSsirwGdgdIi8iNZ34i+GhgrIs2MMZNKvok3zt5vsms/Ht0q3OFa3Og55LeNvfKpU6fSokULRo0axb59+2jQoAEvvvgis2fPpn///hhj8Pb25o033uDNN9/k1KlT138iJcTe+RSlN5eZmUlUVBRnzpxh+PDhVKtWjfj4eP7zn/9QqlQpBg8ebLfe119/zdq1a3nmmWdyDWs4m6uP6RbW030YuBMoBxwH/I0xZ0XkXWA9YDd0s78I2P5PyiKpqan4+vrmKffx8bHb63Nn7nAtzpw5Y7dXnl8POKfU1FS7H3+9vLyAP3u8ERER9OrVi169erFmzRoAYmJiOHToEIsWLeKBBx7g+++/Z9y4cZw8eZIlS5ZQpUoVIGtKGmSNe2ZkZFg+I6RSpUqcP38+T/mFCxfs9oBzWrlyJbGxsXz44YfUrFkTgNDQUDw9Pfnkk0/o2LEjdevWzVXnhx9+YP78+fTp04f27ds77DwcwdVDt7Ax3UvGmMvGmDQgwRhzFsAYkw7k24c3xsw0xtxV2LftlKTY2FjCwsLylIeGhrJr1y47NdyXO1yLPXv2EBISkqe8QYMG7NtX8Dfq7d27lzp16uS5URQSEkJGRobt5lzDhg0B2LJlS67tNm/eDEBwcLDtmKGhoezbt4/4+Hji4+MZMWKE7Vgff/zxDZxh8fj7+5OYmJinPCkpCX//gv+CzOHDh6lYsaItcK+qX78+AEeOHMlV/tNPP/Hpp5/y4IMP0qtXr2K23PFcfUy3sNDNFBHP7H+3uFooIl4UELquIDo6mtatW9tukgAEBgYSHh5OdHR0ATXdjztci2XLltGiRQsCAwNtZQEBAbRq1Yply5YVWrds2bJ069bNVubh4UH37t1ZvXo1mZmZACQnJwPQvHnzXPVbtMh66x8/fhyAV155hR49euR6XJ2K1qtXL956661inu31a9myJXFxcZw4ccJWlpyczN69e2nZsmWBdb29vblw4QLHjh3LVX71xmHOT0nr16/no48+on379rapdq7G1UO3wMURIlLOGJNhp7waUMsYs6PQAzhpcYSnpyfbtm0jPT3dtiBgwoQJVK5cmSZNmhR6c8GduOK1uN7FEZ6enqxatYr09PRciyMqVapE27Ztbefg7+/Phg0bmDp1KlOnTrXV/+STT2jXrh1vvPEGhw8f5vHHH6dDhw507dqVHTuy3saVKlVi3bp1iAjvvfcecXFxBAcHM2rUKDIzM2nTpk2+12r06NGMHj3aaYsjLl68yKhRoyhbtix9+/YF4N///jfp6elMmTLF1ss/efIkw4YN4+GHH6Z3795AVjiPGjUKb29vevbsaVscsXjxYmrVqsVbb71FqVKl2LVrFxMnTsTf358nn3wy1xhymTJlcv1Sv1GOWBwREBBQ5MxJTEx0rcUR9gI3u/wU4Dp3EOxIS0ujffv2REVFMXfuXESEFStWEBkZeUsFLrjHtUhLS6Nnz55MmDCB6dOnIyKsWbOG8ePH5zoHEaF06dJ55tQ+99xzvPTSS4wbN44qVaoQGxtLnz59bIELWTMAOnfuzOjRo3n22WepUaMGJ06cYNmyZbz77rsufa3Kly/Pa6+9xhdffMGHH36IMYbGjRvz+OOP5xpWMcZw5cqVXL282267jUmTJrFo0SIWLlzI2bNnqVatGhEREfTs2dN2LXfu3Mkff/zBgQMHGD9+fK7jV69enY8++siaky2Eq89ecNtlwMq1XW9P1505oqfrLhzR0/Xz8yty5hw9etS1erpKKXWzcfXZCxq6Sim3oqGrlFIW0tBVSikLufqNNA1dpZRb0Z6uUkpZSENXKaUspKGrlFIW0tBVSikLaegqpZSFdPaCUkpZSHu6SillIQ1dpZSykIauUkpZSENXKaUspKGrlFIW0tkLSillIe3pKqWUhVw9dAv7a8BKKXVTceRfAxaRTiKyV0TiRWSsnddFRP5f9uvbRaS5vf3kpKGrlHIrjgpdEfEApgOdgVCgr4iEXrNZZyA4+zEY+Liw9mnoKqXcypUrV4r8KEQrIN4Ys98YkwksBLpfs0134J8mSwzgLSK1CtppiY/pGmMs/2ub9ojIYGPMTGe3wxXotfiTXos/ucu1uJ7MEZHBZPVQr5qZ4xrUBhJzvJYE3H3NLuxtUxs4lt8xb6We7uDCN7ll6LX4k16LP91y18IYM9MYc1eOR85fOvbC+9oxiaJsk8utFLpKKXU9koCAHM/9gaM3sE0uGrpKKWXfRiBYROqJSFmgDxB9zTbRwMDsWQytgTPGmHyHFuDWmqd7049VOZBeiz/ptfiTXoscjDGXRGQYsAzwAOYYY2JF5Ons12cAS4EuQDyQBjxR2H7F1ScSK6WUO9HhBaWUspCGrlJKWcjtQ7ewZXy3EhGZIyLJIrLT2W1xJhEJEJFVIrJbRGJF5Dlnt8lZRKS8iGwQkW3Z1+INZ7fJ3bn1mG72Mr59QAeypnZsBPoaY3Y5tWFOIiL/B5wnawVNI2e3x1myVwzVMsZsFpHKwG9Aj1vxfSEiAlQ0xpwXkTLAWuC57NVVqgS4e0+3KMv4bhnGmJ+BFGe3w9mMMceMMZuz/30O2E3WKqJbTvby1fPZT8tkP9y3J+YC3D1081uipxQAIlIXaAasd3JTnEZEPERkK5AM/GiMuWWvhRXcPXSve4meunWISCVgMRBpjDnr7PY4izHmsjHmTrJWU7USkVt26MkK7h66171ET90asscvFwPzjDFfObs9rsAYcxpYDXRybkvcm7uHblGW8albTPbNo9nAbmPMe85ujzOJSHUR8c7+dwUgAtjj1Ea5ObcOXWPMJeDqMr7dwJfGmFjntsp5RGQB8CsQIiJJIvKks9vkJOHAAKC9iGzNfnRxdqOcpBawSkS2k9VJ+dEY862T2+TW3HrKmFJKuRq37ukqpZSr0dBVSikLaegqpZSFNHSVUspCGrpKKWUhDV2llLKQhq5SSlno/wP/cFlq+92STAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
