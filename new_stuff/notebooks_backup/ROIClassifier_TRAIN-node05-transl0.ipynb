{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_SYT = data_labeled['SYTmasks']\n",
    "# labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "# non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "# labels_SYT = labels_SYT[non_nan]\n",
    "# masks_SYT = masks_SYT[non_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.0, 0.0), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAD8CAYAAABHPleGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABM7ElEQVR4nO29W4wuy3Ue9q2q7v+fy76dfXinCJM2mER0AtgKIwmwYRgwnMhCEPrFgWTAyAMBvsiIDfhBx9aDnwTIfuBT4AcCJuwAlhQBNhA+CBEcwYbgwHYoGJRMihFFiZJI6YiH57b3npn/0l218lC1qldVV/ffM3vvs/8tzQIGM/P/famuWrUu37o0MTNu6ZaWkHnRA7ill4dumeWWFtMts9zSYrpllltaTLfMckuL6ZZZbmkxPTdmIaIfIaLfJKJvEtFrz+s+t/TeET0PnIWILIBvAPirAL4D4MsAfpyZf+OZ3+yW3jN6XpLlBwF8k5l/h5n3AH4ewGee071u6T2i5jld96MAvq3+/w6AH5o6eEVrPsF5+IfkU1JHMHATAUhT/9zgYlOn0OhGEydOHcPLh1S9lzo/fV/M1+TwxnPyhN95k5nfXzv6eTFLbXjZdBDR5wB8DgBOcIYfsv99+NzEUykKPfbxV2U243fZ8foehurf6/OuQWkMcj6ZcI/KvZeMTx+TXbs8Nn5WvZc6P33PPlxPn1ejypj+9f5nf69+8PNTQ98B8DH1//cB+EN9ADN/gZk/zcyfbmkNMpQ/FPt5RgHCw8pPhWbPW0jsOV0njTHec3IR1Nizz2rHTYwtmw99L33OzDVnmXju/Bl6XpLlywA+SUSfAPAHAH4MwN+cPpyqO18vNhkaLX5tsSYZZHRLc2MJc0hiTY5z4n5zz1VlyOI61WcmA7LT98yuRQaYYnxFz4VZmLknor8N4JcAWABfZOavzZ4kg/V8eCG1qC6O1ZMrUmFSAlyX5sZ1TcZbwvjpnje8Rzr/hpuipOclWcDMvwjgFxefUNkdBxd5gmGq59dsgYU0KxkO3bdCs4wyt7gHFj7bGNdhEPaAPzw3z41Zrkc8XswpA1fr5GvfZn6ih1vPqwFtw4yoxpAztldVpWmmODAvU2ObvMfksa56jKbjgvuXGIXaoNUT+l6QMj4nScbyrFSfXHPmGUfOQf0gdTmuMtUhOhLJMrh8h4y30iYpd0Tmei8xBMuRzNkOhoK4ntnVZCgX6wc8ukM2VSbFbrApFnlFC+m4JEsk4fxFRqAwWA3TKHbTtaiG2xAdlBiZulwoDeYYSf8t/y+dn2dm2Ec6LmZZIuZruIrGPSZ20dKJm2MqZq4a4uV5ejGvJfILtboEGijve/gWrP+5lrQ6EjWkKKqPQ7tOH58xiXbBR4eOr5nwG4XKVon9yAZ8pm65vo+iGr40PuWAUTvHEOUGnbFzj0uyCKkFu9Zi6GMXnDcJri2g0qicMzLn1MOS57suQz5zBo50fJJlKeJYI9lhhoa/K4ZubfFYwMDaOPTnhqLtEj/zHinNw3NATTXJ8VMqTEnROdISpjx+yu1fcNFrnXNczHIoFlQcVxW1ZMaLsgDFHHtZhScRv6emAVkLWAuwBzsP8j4wAxX3MAaIjEXeA85hlD80411NjlGPyTPI+MUqsVRr12Gu42IWTDNKaW/UFjd87kcLPGWUqpPyf638NoEpjBn+bhpQ0wCNBXoH9D3gXGCWdIF4X2uDVCECR2Yhp4xYz2DnBiaasp1qzHQDVTPLJAvU8NExS42mvAL5XHZLkgQ31dlaxVgLWrWgtgXaFmgbcGPBqxa+tYAlUOdA+x7oejVYOd+AjQGLF+84MJf3gWG8D/93HbDvEtOxKyzMIlbGUZLAj59zTrpMeVEvp2SZEMVzINu1qHZ+bTdZC2oboF2BTtbgkxV4vQKfNPDrBn5l4FYGbAl262G3Pcx+WGA2BG4tfGvAaiGM86CeQc6D+vjTOdBmBzR7YLcLTOMFATbBHjJIklG8NvZmYBjJXVlKhS3GnoNafVFR5+vT8ofNpMghmpvEKIHE/iBrgoppW2DVgtcr+LM13FkLd9LAnRr0Jwa+JfgmMIXpGHbfwPQMcgAxgw3BN+EYEIGF1z2DfDBrTM8gzzA7D7s9hd10MJsOtNmBtrugsjwDfQ9yDtz3YOdAcODIl0nCXHPeqpuG65KqpCNhloGmbBH9gHOiNu24+sWz2A01TZAi63WQIqsW/nQFXgcG6c8b9GcG3SmhPyW4dWQUC4TsRQoM4ADTMUzURmzCMUyELGcwZjyCA/OYDmi2jHazRnPl0Vx0sJcdzL4H9h1o34G3O9BmO8wHTYNwhzZQ1esbLnYw8nxczFIYdUulSIliVndcEQIgUTfrNejsFP78FP7OCu60QX9qA5OcGXRnQH9GcCeAO+HAKECQGCasPTFgdwSzC38zAaDhNygykMGw2EwwXTiv2QDNpcH6iUF70aK57IN6u9yBSEBDjl7XAbVzIH2zBkxmMa0ZOi5mqdAzBZhE7RCBTtag01Pw6Rru3im6+yfo7trIIBQY5BToTwOTuDWDVxwW3wMpQTr+z9bANIDpKUmPgVFYSRsZDMO3gG8Jbg24NcGtDdpTg/bcoL1s0KwtmtbCSExqQ2DnMRk8BZ7OrjtAx8UsMxlw9cOvZ9ETBdWDVRsY5ewE/u4J9g9PsH2lwe4+oT8ndGeAO+PAJKceaBm0cjANB2ndG6A3g6nlCY4Dd7AJ6ohc3MFRwrApJA1F5mk4MktgmP4M6C8N+hPCuiXAEhoEqJ2dC4aw4pXrOACHI/jzdBzMsqgMIp+Mm+RjwBigDUYsn6zg756gu7fG7kGD7UPC7hVCd4/Rn3vwmYNZO6xXPZrGwxqPxjrs+wa7XQPXW7AjsDNAD6BheA8YpsDzU+uW1FOQNt4CMAzvgqqzO8CvgpEcbJw2eFGdA+27YL8kr0ih1JU5mpuryRDETGzoOJhFj3tKukxA9mVU93ASEAFRugQj1mJ3l7B7QNg99HD3HVb3drhztsWqcWhNYBShyz3DOQPvbOBxD8ATIAwS1Q9T+J8YICZ4BBXGLHZutHYtgxsGtwysAL8yg/HsCKYzwePar2G6PjCM3YH3+4DNCEmIo8Bkynm9TllIScfBLCVdUx2lc4CIQRxgmIiFuBOL7tygu0Po7jPcKz3uPLzCR+49xvtPL2DIw7OBZ0LPBnvXgJmw7Rrs9w3YG8ARqI8/joL9KlYvKDGQAcEbxTBiIBMAG5gGxOCVR89N8LB6QrcDmp2B3TWg7gSmdwG/YQacHz0XgDyEMFNucl06TmY5RIqBloTwAUTXME6cZzAR/CrYBv0Z0J97rO/u8IG7F/gz997EB1eP4UHovMWVX+GyX+MJrWG79SAIxSBxA1MASKhtcpMnhsfR+EXjQZZhLId4Y2/g9hb9DmhOgH5tYE8szK4B7VagrgeaDmz29QsbmlYnU4zy8oByVH+IBbuixiiz7nbfA10Hcg4gBI9kDfCJx/npDq+sr/CgucLD5hIOBM8Gj9wp9r5B7w2cN4OJVWGGZMSawAhkojstUgTDd9wEiUIm/CS/mxhsGdwIwMdgS2BrUigB1gTPzldslLlmB1NR+5fGwK3REmh+5vsawzBziOPQHtR7MBFcS3Brhjnpce9kh1dWG7zSXuK+vQQAeBh0bGHA6L1F5w28Vyuv51h7OsQgT2BTMBOEUTAwS2QYfR22CEwiDNNSCCVYAsXYFSIMEMTRTPlISTd0r4+XWVC4xhM7Yiqj7mBUlTlC8BykgwFWxuHU7nHXbHHPbuE4MEpLBa5BUQpo8M2Ea4YDBo8HFIzf4eToMlsO58gwo0RJGI0HyFOwXRzDdENcCRIOENI5NcAiKXETOj5mmctpmZI2Cu0NH1cYJQJy1DbBG6JgZ9g9YDpC7wgeBEOMM7PDXbPBpV+ji5CtIQ9DHpYYRAxDDG842ByWo6ChAYwDBqlTuMtsg5oZ0Fw5TQxUgtkT7BawO0azZdith9n0IfC4i56QzpG5CYMcqEEq6biYZaKgbNbDUeUZk0VfknpAFIKGjYU3JsVnTA+wI3gmtORwYjqc0x4dNbga3Y5hRbIIozCDHIGJgxuNwU4hBKOVoxRhy6Gg1yAltTJTOE7+7iUUANgt0Gw87KaH2e6B7Q7cdWBJaSjzYJbSDTyi42KWkioPNJIeS7LqvIkLF8mGfJRkjAIAE5w32PkGW9/iklfYs8WebTJ0xY0GAGOC9+IbBiPYP/ADkMIV6RIYDIHJklErwwwncWdgtwbNhtBsGO2G0Vw52Ks9aLsH7/fgfTdilJqN9qxzcY+LWSqZ/SNIOpM2Y0S3nh4ZM/OtpMBRSEyyBG/jrmeg9wYbt8Ijd457doutb4OB6xt0bNCzgWNSDOPBKRXBhHtE3IQaH2wbhM8oMgsB6XNmCj8e8M4AnQHtTJQmQHsJtJcO9rIDbaJU2XdA14UYUU1lX1di/HEoBQl/TuwMDhagqKdZnCUmCwEIUdvR/ZCMysAsLZ64Ezx2J+kQG20VQ4zWeKwaB+cNvGEY6+GdgW8YvieQYdjGwzYexngYE2wcQlBhAOAjwzln0HcWTsC9zsBuDJorQnPFaDYezZWDuQq5LkGq7EMaJ8bqOui3gso5rKV9LGSw42KWA/UtITHZIHcvDohbXZXofMhGMzuY7R7NZo1mY2F3BOwNdl2Dq77FlV9hyyucmx3umWC1iKH7dnOGx+0JrlYrdN6gcxbOE7wPUocANNahtR6N8Witw8o4eFDCaTpv0DuLLRr0nQ3xpc7AbAh2E1MWNkCzYZitA+32If1Sp29OPOOIbpLOMEFHwixcFamjbHZNZZyjYtlnUoc92AHUdWAA5moLuzlFe9Wg2RiYnTDLChcueEEn1OGhvcBds0FLDmdmjzebO3h3dYbH3Qm2rklgnY8qRVRMYzxObIezZo+1cdh5i70P19/0LTZdi30fGJAdgfYGdktorhCkypZhtw5mG+JB3HUh6jwVB5tb+LkWHtegI2GWQEsCgoEBlj9kmR3GzoMQMtDMxR7tWYvm0qK5JGwvV3hyZ42Na+HZoKUe57SHJYZtGCfU4b69wiN3hkerU1y5FXa+wc7n0+gj3r82Pe41G7TG4cqt8Lg/ieCewY4aMAAXpYrdEJorQnsBtFeM9tKh2TiYXUzo7npgCpldsOg3ri1SdFTMsrQ8YUnrrOHjiuHLDNp3MFdbtI8bnL7ToLtn4U5XeOf8DJv7LVrqg60CRkseD8wGJ9ThVXuBS17h0q9x5dcJi/Fs4EDofBNiShHMW5sOAODYoI15C84bbPsGu10Lv2lgL6OdcgmsnjBWTzzaix72YhdslShV2Lnk+YzmQRfWjScsOQOT3bAWGLpHxSwAcgbRE7Cwec3BYjEgBBL3e9DVBsYQ1ndWOD0j9CcGVw/XuOpX2TVb8jghh/vo4LEJTMEGW7a45BW2vkUHi44b7Nli61tsebhGxxZXtA5RbBB2rsG2a9DtGtBWpMrAKKvHPZpHO5gnG2Abs/6jCpo15qcYxhAAmxWkzc3pFB0fs9RoAkcAxlHngzm7MkHOgbdbEBHad09xcm7RnRF2b7X4nVdfxa+ffAxXfg23NvhQ8wh3qcNd47Eiiliax5YddrzHpWki8zS49Gs8wSm8N7j0a+x88K6+t7+LN3Z38L3NHbx5cY6rJ2vgcYv2kcHqMWH1mLG64NxVVrZKGRycteeeEx1kFiL6IoD/EcAbzPxfx88eAvg/AHwcwO8C+J+Z+Z343d8H8FkE1OF/ZeZfutaIdAyoUhg1xTDlcVPfpe/FMwJAFxus3l3h9NRg/12Ld87u4//xn8Abr97B1f0Vtiev40PNI1i6hAVjbSxaBDWzYg/je2wjC22pxZZbvOvO8E5/jkf9Kd7en+GNzV28vTnDo4tT7B+tYR81WD2ONsoTxuoJo33i0Fx0MNsupCH0/ShnpcokhwDKQpJUcaxnlPz0zwD8bwD+d/XZawB+mZl/Jr7E4TUAP0lEn0JoY/pnAXwEwP9NRP8FMx9uWKZJ+/9T2ewLoqm1ROZUqOUQfzvYiys0qxanDaE/WcM3DZ64e/i6M2iirvdrgxPqYM0OJ8xojU1xIEcOHh47ZnRRurzZ3cV3d/fw1u4Mb2/P8dblGa4u1/CPW7TvWqzfJbRPOAJvHu2FC3bK5X6QKrXSWP3s10GxRx9x+v3MCuOZ+VeI6OPFx58B8Jfj3/8cwL8F8JPx859n5h2AbxHRNxH6+P/7RaOZoCrwNpPCIMcfSuhmHwAz3m5BT1o0xuD0xMLbFsQWV3wHv+Y/ircenuNb5+/Dnzn7AD6yegcfah7hob0AQPC8wh4WT/wJnrhTfLt7iG9t3o/fv3wFb23O8OjyFNurFfgyGLInFwbtY2D1KKqdK4/m0qG56mCu9qCrHWjXgWOwMLjLeRVhokra5OT8LJnTA3RTm+WDzPw6ADDz60T0gfj5RwH8B3Xcd+JnT00HuX+qCY6Ue0aofwD2hvN43wFPnsB4j5PGADgD+RbkLDa7O/jmkzVef3APv3vvIT54+gQfPX0XH1g9RksOFoyObUB9+xP8wfYBvv3kAd58dAf7ixXo0qK5NGgupT5IbJNon1z1obBsG2I/EihMkkWnH5SSpMCmUlOA0ed1PEpvqiXVjc/awK2taJV9y9794wOW5eCOJkSDcwutfd7vwTEZ2hDhxHuY7hymb2F3BrvLFTaPG3zrwQn+6O5d/N75K3j19Aor0yd09qJb47Jb4e3LMzx5dAq8u8LqgtBcBLukuYpBwU2E8S/7rGwV+yhNujCWUCQ/kWMbn28ujWOx6i7mcY5uyizfJaIPR6nyYQBvxM8P9uxPg2P+AoAvAMA987A09efvviR+VF7nUO+XaL/w5RUMEYLjew7j2lA1eGWwv1hhe9biD8/O8fppn2W4+b0F7w1oY9EKk1wGSdJGRLbZeNitg72KRuwmRpK3u6GLgkgTV2H2Aoy8iSpZNBcTdFNm+RKA/wXAz8Tf/6f6/GeJ6PMIBu4nAfy/B6/GM4bWlG2yAN7Wk1kri8hP4VB4vtmA+x6m67B2DLM/RXO1wv6Jwf4uoT81cCcGbtWkXFopRTW95J9ECbJlNFeRQbYOdudAu5xJuAspB6nVRhZZL/fQWFIuRmOvmehUoyWu888hGLPvI6LvAPiHCEzyC0T0WQC/D+BvAAAzf42IfgHAbyCUXv3EdTyhZ9LQb66B35KKvT64rN57GCK0XQ+7PUV7ucLqcRPKTGMRGEt6A0IVoukZds+wO4bZe9hdaMlBO5cVu2O3B+9ibkrfB7XzNDQTF6ui4s8rB5eZf3ziq78ycfxPA/jpG40mXaTu6j01I81Io5ER6FzoYGAMjPdo9z3sZRsy7AmxD4tJfVjIM8iFH7N3MJ0PUmQXbCFp3MORGcUuWZoOWbXJhJb0tinnoXIOzZWQ4CVBcA+pkOy72jkHrl3r1cbMwG4H7nvQdgtzuYJZtWFxfUyaXsdGP+0wjRQ7OlHvgK7PM9sEM4musHg51aRzhTVl46tUHpbPPAu0qUK06/SiA46MWZa01phOiFomWq9Tvin93uDCwmNrw6Lv92BmmPUaWK8DE0kfOebBk+n7IEm6bjqpeiql4pCRf8hIvUYYYOnGOipmSTTVnegaRtpUicgi0ucYGoAxad0VXVru+5BoJzXHsusllhPPO8QoZX+82XHXDPZII8R6rpjsBnbL8THLXFE8D6mUyy+38NipFENZHHAqRM8Cl86FygH5fy7bvsLsI9hd5SEf9BCnxixzV34/obZq39Xo+JhFkzy0+j2ZgnCAlrSdiAeOJ39K5EvlQIk7VgCzuWSu2r0OfRcPqF5zRBUmIVN2BI/5uzM8c9zMoklPTKVXy6RRN+U1xE6N4c+JXTznhh8c7jUAsxu4s7O21wLEe3TOAnrvkiGegjJ9vuTBlqieCVWwZCzXbst1IBFd/y77zWTHlGMkM95E2W3za80yiqGXr1vlFI1TCAfXb0TlhBYSZfbaQhXjsybRwscHSipG2X+FPVZEzLNzihjXLKMuiDSPSO7/HGNDz5ZooSG6dKEPnD9Z5rrk3hP4xpIsvsWdvwVPAQCXS4TJZK6J76rq+ZpMJvRSqKERHSgqm6OkyuYAq3Qpnvz+OknjB0mkRzmuBbv9oJqp0ZRaO0DHwSw8Mei5HTC3MDL5SoRP2RpLJiuVzRaAWc0zmx2X5/waU8Y4+5ghdwOjV65b1lVNzN11JPNxqKGS5soaZrCCqVzcKU8pwzgspoGziSK38GtgutpYlgBloz40M89VqrxJr0tsI7mv/l271gLH4TgkyxQteACRGFP6uuoOH9qxN1An5QLmlyvAryXR78pxi702uf8BRrhuhcBxShZNC7yZWaqI3yWA2XV0eQK5rC2/mLyezk25kcE9ReW1dOBxYmxL6TiZpYYzTD3cnM4torOLUNzrTGKJ1OprTUSG06nOje2KiTFOfaZV0GIMSqg2tpcCZ1nqOgPjeMekvp5mjCVh+eFYtaBLwLVirDeJClcN5wpVXealErGUuAuwluNgFk214FhtkWa9jkpgTZ0z6/YWi0gWs5Kper2ZSZ9j0hE6C0wDj+ML1+dkJg/5ukj0kTALjR92SnwvguQnAm5L9fZo8SfGNhGhfp40ShMtXPCRF1V4YDfCZSIdCbPkIf2nSaFcHEleSsXkc8VYTHU3lV18nYj4UtU4cpcPbKyDxrSmlymtsnQPlzLNnKF449zdcgcjx1XSdxDbZkKiiQ3F4zTG2dKU8hkm8m+r/WqyzVekZt6QjhtnwWE3dwpjiScPk34dtaaR1pvmkAhVGGNW/Kvo8/DRDZK9ZoDEFGFeEGnWdCSSJc8QO3j0UiNxjqbUnk62Kr8bBjAYnnPByZgcVVuQ6iaoRZ+vQePUzAmJckPb6kiYJVINgFu6s5dEUmdCBSOGQS4JRjYJzaid8t5ask2lJJTXmRp/LYUSdYlCGiNUqrB6vwV0XMwy9SCl97EEV5gTwzMqaXGi91LwbsK4vo7kqMWOrnWtij137QQuHA2z8Gg3T00MgMU4xmSgbMpYLa4zZ3zWzkvSp/SKtLEqqO0Bxs2ur4zo4oaTYzukdmrq9dAGOSoDVwfQroUBTEx4xig1g06J8LnEodnYURnwk78XorBV4qLvG08Y2xNjmzp2al6rqZwVOhpmORgTWWqrTJFcqxZ3mjFSq2mOE+dn4y28mcWMV963vNfUuRgWfcTIlQj2XJR8io5EDV2DFrjApQpJ6qFclKWplNcaXmEMK5trLmiZ1ELBMGVH8ZFNxbHlWTHemv01kqALVKGm45AserNPpTzOnT7S7Tz+Xnkj1Ujx1D0rWETJmJNu8xxTVsY6K0krEeqpa+rrLb3+LF4V6Tgky5Ko8wz3T8Hw+vvqNQQHmbv+Alg9GwPqbnh+22umSkx4U7VnfubenKLjYBZNcxb+7Gljg3KRLp6LSc3gMrVz9EJNjWFkn0xIjEP3SteemK8pb24UU5oDFQs6LmYpYymKqm7w0nSGp6RrezPPgWoockZ6zgpQb2l+zCE6LmapJeHMIbhzGXSYn5jEfIrxbpJeObcQo52vd/yBHT2702vSZGKctVjasPEq7yeaoeNiFqCqq5cE3q59/RINLnJWrrsDZxmlkJSTjPA0+cVz16gwbPXYA1L5OLyhKTqkUir4wexxU+imFt+QP68X0JzNvrtOcFODegvxjyq2MjWmYcCjVqmH6CCzENHHiOjfENHXiehrRPR34ucPiehfE9Fvxd+vqHP+PhF9k4h+k4j+h4OjODQG7dbpgJzQDOBUU2Oj6014HiUzlD/p+IpKSQCZFItdx5ZiPzCxINq16xxAoA/SVBrGBC2RLD2Av8fM3w/ghwH8ROzRL/37Pwngl+P/KPr3/wiAf0JE11OOh0hhFFXYfQaTSOqhVHHlItQWosSAyr/JjJkwLnQN+1nymR5jVTUWQNzomIkodY2eOjbEzK8z83+Kfz8B8HWEFuufQejbj/j7r8e/P4PYv5+ZvwVA+vc/NxpN0hRG8ZTR37nrXOf4qUWpSbylSVCT4FsJ+ZeS+RoS71oGbnzhw58H8B/xHPv3z3F4qRoy2Nvn6uAQWHftRS/PnZvouThOZkirKPQCXGfpmMXjye5ZqthrwgyLZ4uI7gD4lwD+LjM/nju08tnoqYnoc0T0q0T0qx3vhgMPpAXMfjcRlR3ZGUvpGgszfYmJe9fedzgVlERFqigDeOr+o8j1U2JQi2aDiFoERvkXzPyv4sffjX37cZP+/cz8BWb+NDN/usU6qZLJyZ1bOB20m/pe/2QDqUdl5btJu+gGlNs+FXh/4vqHmHzRRiDKjftiPp5JigKFVoz/FMDXmfnz6qsvIfTtB8b9+3+MiNZE9Aks7t9/PUi/8uX857ITC09pKZ4yaRMdGNekhJgJmFbtlBK1rgQFJ5lGG99y32u45kJLbJa/AOBvAfjPRPSV+Nk/wLPu3888UmCz2WoFXVvFzMWEnjOVz3XwGZeowwM21LN4viW9+/8d6nYI8Cz795v4QuxasAzzHkT5fXViFsLhieakRyVXZck1r4sKV1Wxvt/CiLjcOzNqD0XbK3QccD/FdhXKRnhmO/26YFg5tBqT5Ac83T0rdG11WwlTVJOkVA6vrkxYysTHwSzPgG7k6TyHCPXo2tfMRpsMGxxIK52SrDX4oBZcTHT85atjt25KHU1SbVHm8maXjKq2AGpxZqVONdNt4m3vM/fO7jsR+JtUwZFp80gzxvOycD6OKpB441yLCuw++qz293VJL07pVgvN4CHh9ofd3EXG7yFJVcAJI09IvtPzcWBcR8UsLz3VGGXquyX0PNTk1DiWRNnL19a/CCKi7wG4BPDmix7LNeh9+OM53j/FzO+vfXEUzAIARPSrzPzpFz2OpfQncby3auiWFtMts9zSYjomZvnCix7ANelP3HiPxma5peOnY5Ist3TkdMsst7SYXjizENGPxCqAbxLRay96PABARF8kojeI6Kvqs/esmuEG431vKjCY+YX9IJTE/TaAPw1gBeDXAHzqRY4pjusvAfgBAF9Vn/1jAK/Fv18D8I/i35+K414D+ER8Hvsej/fDAH4g/n0XwDfiuJ7pmF+0ZPlBAN9k5t9h5j2An0eoDnihxMy/AuDt4uOjqWYoid+jCowXzSwfBfBt9f+1KwHeQ8qqGQDoaoajeYa5Cgw85ZhfNLMsqgQ4cjqaZ3jWFRglvWhmWVQJcCT0VNUMz5ueRwVGSS+aWb4M4JNE9AkiWiGUvX7pBY9pip5tNcMzpPeuAuPFex4/imC9/zaAn3rR44lj+jkArwPoEHbhZwG8ilDT/Vvx90N1/E/F8f8mgL/2Asb7FxHUyK8D+Er8+dFnPeZbuP+WFtNzU0PHCLbd0tPRc5EsscXGNwD8VQQx/mUAP87Mv/HMb3ZL7xk9L8lylGDbLT0dPa9SkBro80P6ACL6HIDPAYBF89+em/uxeJsCCsCsPH/OfsULRLSAwhfXEpCV49P11L3T9dU55X2nsu/lGPnNPHRO0NeVz/Wz62eVz5kB78Heh6I8+Tx7rLKRj7pPNh51X8TqAyIAhMf7777JEzm4z4tZDoI+zPwFxISc+/Z9/MN3/idQ0wBNA7IG7DzQ91khuFaZZA3QNENBl1uYCR9bcHGcfDAD1oZ7S6NA54L1T5Q+k3tn9/UOvO/CdYSMCecBgLWAjeUWfZ9fVyowuz4fgzXh//jeZ6xaUNOA+x58tQFvNqEG6WQdjpdnAsKcyViMCWMFhvIPY8PcMofxdH2473oFtC1gDf6vb33+96am7nkxy82AKvZhAeT/plGM4IbFK5vnkQGaODHeDbu9LG+IfdoSo6TPPbjvx8NhBhxnx6VdDj+WKqZSg8OM1FzfEKjYR2TtwEByPBCYScbsXPhJjEAZI6fj1DjS9YpOldyrLgyxpim6xQc33PNilgS2AfgDBLDtb86dQCQPHie2aUDGAGzA6IeKPNmpQNpRZE2YXO/BPQDf6wuPxbNzo+95vwc8D9cyZlgcURMIDESy69mDiMCKSUirBvb5O6ataq0nJaUWoFq1YeynAkSJIQtJRm0aClZnreTUDOcnxpVr1CoRncuZvULPhVmYuSeivw3glxDSEL7IzF+bPKFUWtKpsTZ2MoModYgPfsBOVwyTeX9EYYKEediDOez9xASaYfT49OtvNYOMOjyphZm0b9T4ZcfXriGqxdpxlaXxII+McUdvfFMqODCcB2Aj43K+iSr03GqdmfkXAfzisqMp3wlAFJkY1JDnvCG0H8RmkDyRwaJtECbKDjaNTBaQpAS1TZh4Z4Au7lRrQ0cHQyAPIKqJZN94n0uIsn54iqK9Au/T9SeL872J/O+HElMLEKJNk+ZIqVsfGAYuMoJ0l5J50bYaooT0AODifBx2jI+jMJ6QLwAQGcEPC62IOT68ZgLn851Ts7F1Abm14Z5NE70LJWFkIeOQiKMX4n0uqksxX9od6r6sVB1ajgZ1xe4B4ucGsKSuH8ern9e5KGUoHOsAIsVAZMIcom6rBV/IBjWs7aYJOg5mAYaJlt1mkC+ekHcAU5I2gxE6oRaE4oSTc7moFtvBMGAmpqP2km1tNzkMzC4LpOyc2qZNDD3V1iscVPcrs7HxwFRCyZ6JEifOTfLC4v0T44jhfwB/OBJmKT0cO+wa7dmkrtPKu/D5gyeJIZT0vUWUu8GgFC9DbITZXaVEtyyCoaBaul6eIEip9EhKrRJATRyjtgs8R2O6uL+WTMKM+nOlVha9q0EkU/ob0UgXSRhhigPF8UfCLBjcwUhshWH0A0QMxLlB7xsKkkWseflM9DVzYBQ9YQ5JBTD3A3ZSqkJt52jS3SbFFjEGZHMJJ8+Vns/aYe+K7RPxj6oxCtQZ5MA8pmESgQ2CJDZINln8MlPdgJtt5AMcDbNEJgDGVr4mw+HB2SgDDTlmUr18tPqnSBnLIwyHh4Uj8Z50r5O2DbsUGIC0dL6SClGCEWzukSmSzcIG+VtKSqbVRnX0jogITAGnSkPXuIkwd2obpq65sB3IcTALI4hBITUJ+XEUcYZhslnD6MC0aNbiP+lyl65B8iIFa5EuoHdytHMSzG4oYkEUvCnPcXH8oKpkPHLP+Dsx+cQiJYngDeD63HbToKR4b8lId2BPSgo5jNSrgJb62axdxDBHwiyc7QKiAWtIu42VIcpUR2Jnrp+RWkCxedgFMUzhptHQLtBRY7JxsQGCT0vAvkuLytaObClwxEgiJpKP74Dk06QZhUwALvW4ALBINM8AeHC3JYyQob2FJzdDx8EsREMcowZKxcAZw49MgoS0CuqqYfbiGiXmkCganpntQfEccG5IQy6vjdA45ogii2QZgWRiG9SwGefABc4Uno+Cl6a7fAsOQwB7D+r7YR7kGeVcPRfl59n9DthCOBpmgTK8cpXCZrAViOvOHVll6Zd2Tsl87JMUS+rCSRzIjSVV/L5KnqFjUck11Son+r7s4juDELGNEUrLQeWU95ZrCuAo6LE3wbtziH3n1CA1+KiZJ02Ykk7y/QH0FjgWZoFyHWWt58SiXhwg1+PFMYlGqsiDjRnsB2BgtKlQg76WllA1Q7GQEkEyFveaamOaxmhyb1AYVxjGxc/mGpjXGCX7P3pKNSypoCNhFvVAGpyLk8neB6ni/PjhRfxr9LT0SmqqJ4pt+UTC/UlKiVdRRqqJgvQjPzCgDinImCQ4qBiJxC7R0ifhMX5YNO3OaspUp3yv0iAUki3pCmQt0DbBPWc/liTiTKyalwjB1YhnRUowu2EiNDQtmIeIaqdEtRif4CHXI4bvkxcV7Z0UJ4r3G7mr0R5g54IHxEqqCUNFrIc8BoYRkvBBJn2URPQm2klRtXAfFrucJ8mvEZVmCKAmU5fsPNB14fcKoFULamzwlGKOEMdwQcohatuDRu5xMAtjgK1r6oTzXVx9iV46LtgGBFt1MIgIaBuQnwG3hQFS7McH8ONQGL8WN6qNMx0PAB5ZH33BP2q2U021Jqa2g1QVY12OcR5s/fCdK66vbKw5Og5mAeJEUR4LKRklweImnyiH4FLLREhgTK4j6LCI5CZ4FyOMxPkhBUCg+wjrE/qYVSlGrMJiIkqa4Se1xCu9iIBKN8DwnPIMauxpLCQgX6GehEm6PiRxiUfWBsnKfR9iYpJEBajMPDuopQMe0ZEwS2WQJaMAAwhFFHdHn0HVmUcjk9DYYACm3WMDNtEYcB+Zr++BfR9tmJDGGDCRwa4IiDEP9lGyh6K9ofGTFBMSvCZEfrlYEIbCdTSjiAucUibC9Vg2RUSx08JHPIV1rGrVpiw8OAcvUsXLC8DMkPYJDFH1GToOZpHdqiHpMq82ZXtFPIJ9tAuUDk8SqIJXaPUmeSVE4Vo61iOnaWS4BLKENEMnVFh9J2omgolp8STomQUbKalYBoaFcw5csSWIKMTPDKUFD0FUQXvNgPWkk8L7A4ZclyjNdVhiho6DWUBJNYwsdo2dJNXTK6wgwvayCMYkEG+YDGRJQxkjRJUhQT5Su7yKeEpmXplHI7s0c6uV66tspSoDpzGapPLggyFKvsvnQTLj4ryJJ6efK0OLrY0SLGYCauY7BBMoOg5moSAWM5havB5BwiVKmkWdgxfAPecitERNM4ZTu0iDUyaKdi19xAaIY4QxYYEkYVsH4+R6hEE9GmWHyXcGhcFeARKtHQxwce85GvbJY1OMI5+JqixyepMUIgqJ2TJHGuBbQMfBLCVFNzALyGXfK/AMajLid+m8LEG6Imfl0iSR25zJRGUw84C/1IhMsIUayTozORMJ6bQDxcQpp1jjQYZAOhlLJ6uLUZ2OV5BA04RnLSSiGObViPfc+4wUHQmzKLUgAJW1gE4RVGojeR0Kos4gf2CwgWJ9T5boJN8DQ0DQFGqQfe6ZlPm/Sb1E20BHyZ2afJ1gBIzd3cjU5NyAJanxaexJjG6Nl4ApgZZhHgw41RFF3EcxGaHiguvxzdCRMEuFBIYu/5fE5DJyWtsZpaRwLohzjcJCF4VR8Di4btDmZR48HCNpC2LvaNdZq6w4jiQ9qLiH2Eia0XX0vQaaiUsuTFtTa3o+xDHwajxT81fQ8TGL7GyiAcuQzyUxmeNilzkqQjpCq/+P6isUVQVGSWiwLLQmHQ3X6Zql3RMumttNYmMBSLEbFRZIY/CDqqtSXMwBcVbMJmPpB2nE8hxkctWZodEqfGEMiGzmAEzRcTGLz9VRwheYcyOMgOABKaRVx4am0hSAtKAMxDRIRSnJGYPByzwAWMkeQPBSiIY8KUmgKkkBcaSOTXEmrxKWaukZaV6Ul1h8J9B/AhVJMTiQM1fCh3y+2eZsskjHxSzAsOgqPyTZEErUBk+BByCszJaTawgV+SVJpXgOpa/aWzCRSeLiDDm6JkDnXRdySDRp/EcoenSIydHZMmsj/VB6QJleqV3oEjYon7uW6CT3l2eN9HIEEjnuNgG2BGGUB+mj4SflGsnbMQOOUqoeqQAsGSZ1FSjdVQNuBVYvADpjgMaCLYE6B9p1oai87wPyKZhMv8+vGVXMqAxWe2xADj5OpS7E8ScJm86V78wQiijzWFQNVDg2Vi9GNDwFJw9oouNgFmBwFwVmF3SSKXkmIUvdAka5y5KANEpBmHAHNVIsC9M04PUKvGrBrQ2GbjRSOU4mGwJbgtk7mE0Ps+uAfQfa7oPE2HfTkW0gSZiU9C3PNwfSTXkoxQZIz5PFrNz0db2p11jXvCRFx8MspkAWkzFXegw+6HigMtHKeJQCLmMBOGTZ8mRAqxZ8ugbWK+xfOcX+wQr7ewZuRfAt4BsERiGAbTRfDNBsGO0FsH7isHq3R/vOBubxVWCALaoqJUupkFiP2BbRIxs/p/K0innKqDRki+/GRr7GrgRueJkStglB7QDKxVQBNSDHMJwfHk48GfGS4JDaZCRklgAUunu9gn9wjv3DE1x+sMXVhwnbVxnu1IPXHmiDa0uGQZZhDIOI0T1ZoXm7wcnbDc7+yOK8IawR8A1iBnddHH8weDMWkDrq+BOeOVYIej9IyXh+GCuUJKx4bJKjKzQFBkoQVK6T5t6MN+oEHQezIIrmSseC5FJqke0ZUhaSJjPV9erLmiFYyNEgNRbUtvB3T7F9/ykuP9Tg8vsIm491eOVDj3H/dIv7qy3Omj0MMQx5tORxajsY8vjmk/fjd996iIs3zuBtA9O3MO4UjTGwnkE7G0IEfR/HOKRHJEYxdlBHCOMnAFwyivw9Z0toXEWHEYprJFedmkWYSo2OhFki1iC7S3k+1RxSkbol8OWGDLDklgLBEHU+pB6cn8I/uIPNR8/x6OMtLj/G6D+yxcc++A6+/5U/wr1mizMbDNWtb7FxLQwx1qaHhcf7Ti5wcXeN7zqD7e4MpjfwzRqnZxarkwbNow3ocgO+jJls1oZcX90xCkh5N6nUxfkBaS5TQrN+MmqhVbggXAPzgGIqbyk2VX+oyjnQkTALBhtFYOys2ItznasxFSFhkqi+UvojkDLEsGrB56fYv3qKi480ePJxxtkn38V/9b438OfufQf/5cnrAICOLS79Gt/t7qP3Bh1b9LH84tR2+MDZEwDAHzqDK5zANwZu1eCsIZwQ0DgPXG0TYxOQ2p8FuN6H5+w5GNLAgMQygxozGKq+LwznCuIqUop54INaBWM538V9X458Fs53VpblBozxhZLKfNki6jyglRb+bIXdgwbbVwn+g1v8uQ/+Af67e7+H/+bk2/hY8xhPfIu3/Blc/wAAsPErXPQrWGIYMHa+gWdCax1OT/e4eGCxcy3IG5jewnQrmE0Pe9GmGE219EKnMQD5gpV2h+oNwxL5BgabrJbqqVXTaL4Vo2gs6AAdCbNw1qBPwvIEJIkSPAplq5QkOR4SEJTdF91xRgtatXAnDbozg/6MsT7t8P7VBd7fPMZDe4W7hnDJjEu/xvf6u/jD3QP8/uUruOxWcQyEnbPY7lvsugb7fZg+f8Lozxm7+wS7s2ifrGDfbUEpyTsGJaXuJxuzSEkKhnk8nih2NWCPEXCmItDaMA1B0aFbRGAKOy2Vo/2XRe1n6GiYhfcloBVtmPg9EF1ZzmudM5EsDyzPLTtZ0g9WLdypRX8KuBPg7nqPV9orPLQXeGB63KEVAI8rv8ab3V380fYu3ri8g6vdCt4TvCf0XQO3N0BnIkgIcOvRnxqYe8B+Q+juNGhP14FZ+gjY7X14Ro6NfNomN069siUE6JOQkvZUxPVVUeikPmIsiyUMItcTXqt5PClQ+bIwCzCgm/p/1aZTf5fhFp7HJRaaUvgg/tsz7B4we2CzW+GN/V28vb6DS/8I940DlAL0THCe0PcGrrfwjuD3FtgbUEchod5GO8Ew3ArozwjdHYP+wSkaItDVduxCp7Hlxmrw3CpqRds1Eq2OWW/aSK7O6aiaoHJ/LXFm6KAPRe/VyyUFBhcXE8ptJkqfE9F4p8n5QBD3qkg9NeuLO7C56rB+5LF+m7B96xRfe/fD+Orm+/Dt/j4eeQfPhBPT4X5zhfurLU7bHm3rQCYujieQ/OwI5srAXhmYLtzfr4D9XYPdq2v0D04D8EcEWJNhLFlEXUie0ZohNqYYJb3Rw8Xwh6juPmT0sfNDEpX0uRXjXv8IA4mHJln+B1TREof7nwH4keKz1wD8MjN/EuHVJK+F9aJPIbQx/bPxnH9CS+QbMEyS7oQkxmnKRLcFAilPoaSOLrAC8hhM72Au9li/0+HkLcbqLYtvv/kA/9+TD+K39h/C99wKl9yipR53zRbndo87qx1WTQ+rI9RRwpuO0GwIdkOgHgABbgV0dwibhxb7+y38uh3G3jZDY+Ri3MlYbZv8WUe1234o6XAuelV9YB6puxZHITFRsAVZoAWNZNvQiUF+5uigGmLmX6Hw3j1NnwHwl+Pf/xzAvwXwk1AvagTwLSKSFzX++9mbyCQVuRphhxVBN4Htk0RREVh2yVjLWnUAQ2bcbo/2HcLZmUV3p8VFc46v+O/DVb/CGw/v4b7dYG06dGxxavd4uL5C5y28N+g7i74zAXFmDKBwMKUAA/gVoz8lUE/oLw14HXNFOgzPp0s6pkjsLZX/EuZEp4oWsTAplpc5Tfm6wfVO3bJUfGzU32aGbmqzZC9qJCL9osb/oI6bfFGj7t1/Yu8EUdj3QKfyM3TArXoRk+tbQUplR6pcV9k1tNmB9h1OjAHbc5jO4nJ7hq9ffQTfu7yDj959hI/feQuvNFdoyeEDJwFT6ZzFrmvgOhNbY1CKG4Fj7MgGH871gOmAfk3wrVWBxdh+vcwTHmXb56o1S49URWFZwZoHUoI4MBj1PNRzS9A063rZL2MU4NkbuLVVrY4m692/+iCTMWAdqSUFlQvVIrTaoxB0V+/YlOsaUc7dHuh7WOdxxgy7OYXdrXC5W+GtzSt4/IETbN7X4uN338Kp7bA2Pc6bPU6bDm3jsG8YLgYVYTnYMQiMwjY8Lq0Atya4FYEbAlszTEy0OQbPzsS4VoG96M/S7EawjqIqcZWpTbABpXgZiWSSxHRjQmhhIb4idFNm+S4RfThKlWfwckkObnK07FNqIDDkzQJ1sWsASCGXKgEFMMSOSnIOvNvDPLrEOubRGNfAbi02l+f4xlWL11+5i3snOzw42cAzYdO3sMbDNg7+xASn1AMkEXCBLzylKDUIQ4FYFrwTd5UGtRROjs/o8kUUqZLZOArNlWcV8lFHSrhE8ngkb8W7YNd0fS6dnlPy05cQXtD4Mxi/qPFniejzAD6C5S9qHDpj648l/4N5wFwijQrfK7XCCcQzNsHlSTJ1e/ATD7Pd4WTfo7k8x/rRCu2FxeZyjctXWzy53+Htu2c4WXUgYljDWK16sCf0xIExmILr7IOnBIshtYGAoYMUBq+sNCRVGkHWzRtQKQ2qbNZHjAc2V8N6o3hG6t+SxZrcoMYkaSuO6dCLyg4yCxH9HIIx+z4i+g6Af4jAJL9ARJ8F8PsA/kYYK3+NiH4BwG8A6AH8BPNcpxmZLIx2kiQKhUIzn2MtB6z2dFmORWo+SKeQ9xomLnhNW/BuD/Ie7XYPe3kO052j2TZoLg32D1bY3m+xOe9h1g7NysE7A+9oyKmR3S1evg/pm+QA4xCLvuqLoDtupoXSbd+BoXh9KuckizrnUessr0eHGjSjXIOWeEM/PvHVX5k4/qcB/PS1RkFIaiRLZpayyzJvVnaLTk5WEWpRWYJLkI8QusrUp3DBcL99BxDBEGFtCWZ/gtVFg+19g/09g/5sBXfKcCcAmxC3sgT4BkDD4TNPgAPMjtBcEdpLoNkyqPOBYTQpyZGBcKOCeJsa8ZDKvk8xYt15QvJ2pN5KaoSGhRnOkTnVjaZfmuQnICx8rxKebD5BGVMAw47SiTtWJ0XHJCgJzLFPxmgwEimqPk42DPoedt/BPF5j9dYaJ3fX6O626O4YdOcG3TnBrwi+CYziThluTeCGAQ5SxW4JzRXQXjDaSw+zd7laiVIzNeORpHQgO2bAnGze0aGWr5LNkceo7ZcYvSpGJC+xCPP2UjGLSAqbLPeswq9MBgKgG+GkJoXpcjRMnJxTehZFgpX0weXNBtjtYTY7tJsTNBdrrM5X6O406M8sfBuYxbUUYkynwesBwoa2G2D1mLF+7NE+6WG2Xciz0SJfe3kRnda2SgoWatUj6G0ZYQcGDwpAqqmGy5hjuLdsujKyfVglHQezEGJkGICNGV0Z/pCDdYmZSBl6+g0asWfKqOmfLiEVQ1gqADWI1fdgDi26qHegfQ+zbdGumwH7MAR3auHWIW83eD8E0zHaS4fmooO93IOudirGRcNzAoMEIRPePAJkx2ZD1zC/kCqITx6hjmKXqIW2XaCwFunf+7QG7ntDg33CaHIsZcJTYEEkBecAhomSkEDNtJZJ12UaROlVMimJSkCv3R6028NeWlhRGX10bderUBXQNqEqoAmq1OxC1n+A44vUBJJuCGZYXGMB74bGPkXdDxskaH8obitLPhhohpSF6rKLxCJAGgyFKVmGtxwJsyjStTH6My70bBk3kVfL1NpoAMhyWVVx1vB+wDhZRZknyKc2W1mWm2egd6CuD80LjQHH/izUu8RQWaqojDu9yIjG95TnEgwGYaiIoFoWadOvsSsL8cuc5PJezucM8tLks2BwFQHkIXkhMkBbGLcAsoY6QCwxHfR3Blzp66viNI5v8yL9vXhbEgGXe2jbR0S4qhUKnxdYCReLpvOLdS/98vnTtbTtodSHDg3MBVjL1A+tgqPN9BIxC8Y+f2lwJQjbZsZsgBYGewbOR8i/YtwJkdq96v6pSVCSTrpYzA8vo5DvmYOKSZJqsBvSeRnDDwubmhd5DDu8GmXm4bppk7gQQxOcZsqTKSsyC0ZJz6vnd4aOh1m0/tWGKJB7QKLD9e6WHRdd5OCCq0gtUY72RilB1oJO1RflpLN6ta3EVspj5PV8MhZJNLdSAkKDy17zxsT7yzAkdQ+xvXS0WttvrQLt4nXDd26o4hQGTKmdCl/RSWQvzZvMjIkPUpQyZDaE7GDKJRFR7ErpQxmpmhAAwGo1LIKLNgjR0Hla7lNKtyL3I+WhFHGoLL4i48EA7QeQ0EdJUsAAsXNTloit76FJGEaMc6H0WuPIKJIUlfrRREO27+NLx/0goc3ASIfoSJhFka6TUUBSNWFb2yna+1H9TjSeUStEG9p60LB4GhZPeSSAFI2FDwwGeN3PhyAydRexIcTdX3t+wZDKzzUZxbjhAQa7StIvZS4yhNiDPYfnMXnC9yE6EmaJut+pYu4s+y16LhT73wugpO0UIWtBJ+uYOaauldxUBYhJbqw2OmXn6tIMadaHiMkIphGvnd7yoUIQkmpBEb7PvCjNCJ7Twge3uLIhsmh7BAChjumlu2VuUJc10CxhDi565FmLl6eZTw1wAnIXVwKLIq696l8vxxuKi9WArMo3LQuyrB0MPXF9mwZDUZuKUQHIOkYCquO1MAgyzylJR4oSxNA4/1U/pjXpeVhCHeLFlbZXmcdTpBpkto8mz0N1pHouYRRpjzpHx8EswNiYBQYXV+BxEZtSI6StVjHmZOePru8HvKK4bwgyinHN1QXNxH7MXU2eWPx8AMTidZKaGp5rlD9ihudJkXGhrEBOq17lscnhZTMf7Z4r2yfrWllWIL4c3pDYAgWuoiPPthD1GHQ1XGxDLikBeldJoVbv82sbCkFEpZIAJHczAwD1tawK8snCO1eMyY9UQrp1uSDyPEwpDTLRgnjNMDZTMJ8AkxjcbI0OO2ULJjzopfCGgBTncfEB5DPC4FZXIs1DcI0Hw1ZLIRHlOsqbAFQVOxKbRKgU47IAKfN+YAyZ8PxVeH682Bo4E6ZOiC2QNVQuvRP9Mq3UaXNIiEp4i+50CWRGeFLhYuhPue8TdCTMMuACw6tPPLK3hxZ1Nqx3dbYbK4E2DftnaYhu3oupUem2agjeFzu0SAvIbCddNalJFtJapDQLnRhVy+4Xu2mK4vMPCLOoTgUS0ssCyjEPRprXD+JyfEPvSu3i+kGajPVwODct6FRxvVDF88hLTF1o9SK9eKWvncRySptHM2w2rgMuazLEfZKYyQiVpCcxWPTbVdPvCkN7Hkm7kNtrh/mboSNhFgw98gGkDDYX8QBUkFMNXQMDo2iGyeIlxY6c6teGQWpldkuKfitgEBhUiGaUWtxmjjlqY1E4jn7RVEqVFDxGqxytWkQdy/1js+nslcg6tFGWpFToOJhlgrJu0TrbSwNPmRcQf+v4kV40da7o6FGpidw3i6noc3jwurKEq6g+Ii8N16tEw7VNkiVTa5tnSGtImIh+JuF97XWV1wCPN5mG+iVlc6EqPmpmGUVSCxFaJuuMFrlktPi3SDGW1E3lopL2usp7xXofQsxz1UhrzPRL+AqrkIPD8BYT7b0BWU5OGp+OWqvg6diALha5JqH8AEaiK9Sjev1MfMjx+YqOi1mS2DSFZAAy1DTuYgHpwqk0XmQd19E4h5ZGgnFoV7JWKyeJUqU7rcV9eV81+Sl1k8yQHhDLL0b3092viyh79T5pnmoba1CZWalqUqtKjR+g42EWcXfVm+MT/F2mTQLJqBv1cgXURIgnMhxDROC2DX9L4ZYPwbYhhsLjkIJWdZn0Uh6GQzRII0OmFEYM/2PIf0lgo2ZAYiTEKdllLh0PYHChp/J+ym5OZZ4NEDtN+AF5rnV1KOh4mAUDugii9N5CBmI5CGHojqU7FWlJwpOQeiIz0WVbQDqIyhlfI1NRGnIHoJOYyuTsNLwSOzGV68RCIorHD+3cFRioqYblOGSqLn2uqeuB/R5MoScwtYe7WB4VsySqQe4xxTFIVZOLeh1RVnUzi0mkS2PGKQdlbolmFABZSkUViFMJVHNpAKNMuYhcS7CTPYJXWCK1BTI9dV1pcy+Zf9JIOgMJ5+fsqJiFmUFxN2gkNpHOL9GkI8FWPXw1RwXj8lZdsGYojSG5lPp6S4J4Qjp7Xxa9fM1MzLEZkSR06bCC2C+6h03ZtkNnAep85sgoFNM5CG0OGC6go2KWtIuAwYaRhxb3VZdd6uQimQRp0+HUq1m0FBJ7IqY8gKNEkeAgANh4TqbLHbLaHEOhNalEkyt5rHkWvgdKZhLcpLSx5BwbJUFChJVnk5hCX09Lp9hpipRalDGWEWbJqjtAx8EshOwdxFWK6oWgPBpd2C2vmiPOpUkJlgGDtEot3wsVILtazgcwJGXZwUyKrb9Yv5GDff56XABDpNoOhqvgHRmo5gbm0RIjMllms5T4iowxjjn13BUvLFU9FmEUZee9XHVDzsU3fRT5FhQhaYOwQMypbxxLhrohSEftxFDCTFlnheHtZEktJMNUPK4i1VLO9z5GwA2Siljlmzu9P6B8H0v0vMjQYHiK1GxirVRktHFQU6VmiIelmb9If0iMuwpzhY4G49oz4PN3JY06N0zQcTALYXCFnQsubFkakiLNJuafOHBqvRUnT7o4SoKzjh3J9UQU+4DGpunRRq28DbXPGQVxbCTXNZSBWrOSURngpHex2B8+2kwQD2hY+KSKxaiNr4dJ0H3ZAjZ2v6KmCcfYQdpmXbXk3FpuS4WOg1kkbC591hyPQaKY1Z95AqobQiLmfKuLZ1ECVtrFNYT08gWoRdeBN6M8ka4HTLBTOFMjGO/OUkoouyR/ZY6PDJBHwqupAzrPx/Og2uJ32XPwIFFTM0cgez1eisu9FO3YSXazCnJlQbDoNqsieLYmYANlVFeMSfkbCB4SxUeVVAgdgNTBNGGSONG1191yF/ruw/rcjiDKJFmQQhGWL9zqdD05p8jLGTEM1HxIoZngUcKL4j2mBCeXnkPmNDFfhPold4gPJZ3jWJgFGHsKmgrXbuiPq3CGLM9W4TDpOHGpkS+aJA+Vu7wM54t73fvEbOR9aPOe7p8b0ZMwvcZr1P2qsa6SIkCXmMbFRRamLsMkZUpC8tDMYCeayGQvhWRB5GzOdyWAYUdFOyPtljLNoIT9BQcBgo6XQ3XapL6/8xE19RmekyK+Ec6XxsRB4lBIfhYYXxEp3CY+wBApTtFvM3hWpdsr5S36OVW8COkF4gbEQ2eGoUqxEmjU+ExMImfnRww1RcfBLIy0k1OwKxmkQwyFDYL4n4Ox5TOZAJ3SIN9JZpn2JsQw1u9b1MlPUu0ouEqhVnSAMusBJ+dn43IJks/KPlL6gFG1UMOxKTIOxGsrCRGfY+T+ls+uer6kN7GUkMIEHQezKErdKoVqXF8yg0ZagVz61M4R0rZGDSrXgUj5P6UMBJtJ4kX6NcDDuNI/9esXaig7V7L45Tiu3EOfq3Nx9Hf6Ppqk9Ebf+4AaOhiXJqKPEdG/IaKvE9HXiOjvxM+fff9+cZEV8BQ8Ez+IS9G5ZZGUiT/MoUecrmqU40VXy+fR0JOWZCnFMDKAqBvu+kF9tQ1otQKdrEGrFli1QLsKrdblGqIupXe+tEyX8lwgAXUARhKV9Tkqp2Vo5x6fw8e5iS3X01xIUFD/aCQ5MoqUs7IG7eaWZ8ES9gD+HjN/P4AfBvATsUf/M+/fnyZFDC5gQFhFXCaATnkHRKDGJumR1fTKdYkSMDbcT/Wsl2Oy2I9PlZJZ0+FVC1qvgPU6vEqvscMLE8QdFUbTr+LT7vhEBls8ORXADdItboamrM9W1waS2s6uX/akc8NzDR7TgMVM0UFmYebXmfk/xb+fAPg6Qov1zyD07Uf8/dfj359B7N/PzN8CIP37526S7yL1ijgAw8RlO5SHHUZmeFAVgxkWqYJOeg6Ibx9/5P1G4r4W4BppRorSJ2XEa4TVGiVlJvaILLAwv7UxRSBuEg3Eyfxo26KkMuA6RSrAmOZXb5Q5jxTXtFkovPDhzwP4j3jK/v1Z7346D50NmiZ0QzAEMA9Ipx/niFDRaiJ724W4gZEBKHkPxSBEVZTR5dSBQAFy6d4Ti0LqxVAAUusv3cVa7tHF1E5rQxAzwv3kVY8YO0jKPF+X80UlM4wvzlt6DmFGnc2nGHjSKJ6gxcxCRHcA/EsAf5eZH88UJNW+GI2Gde9+8yoPVX3RyDUWsPHdyOKqZlZ9xb1UsREG0iRzGpTa6azUA9FQyajth3itTD3J/TVJFFuf05hYMhJrf9Q5WcnLqh1KYSXCrHOPFayfsgYNMoZJdhIw7wYrPIlFlVEMXC5wnxcxCxG1CIzyL5j5X8WPn13/frFVPIc26b3avWKTiOss5H09D0TTItGsUM8I8pEHENHNQd0Ung4A1ntAvWaXV22uRtI5MeONYqZf7M7AooLZD96MMLp+9bC1Y0ZV4xmRrk4Ud3kUgaeAxyywKpd4QwTgnwL4OjN/Xn31JYS+/cC4f/+PEdGaiD6BJf37VUCOux6822WiV8Ty6E1mU/YIkOtiXVQuP15qf3Wx/eB1ICYKDe3QC4YRo9u7wODbXfjZ74d2YkJegLy48OJV2Yjf7LsBOxLp5mJYoVSJYVHiGEqcp2ACcfOtyefMF9ezZviZoSWS5S8A+FsA/jMRfSV+9g/wrPv3W6PwEZ9iFvLgBDvoVkk6ltwPjYRqqgQjSxqXj4hup4kFUhFeDfilRCYevgdym0LGDGUjdcrtVSWmqXLBK2kzHjwqGn762OSea8BRfh+Wwkt69/871O0Q4Fn27xeRrxdOl3K0NKQmaokgJJMhqkSG7NW7BcuukuW9HAqIvhhfUUyexmYRUgLQJtee1aLo2qRRXoohpFYbsQ+MFICRHKM9M8nKa5oIYEZ7Rs9VGl9kYmNzu6ZkFADVLlQFHQeCy4iusAFsKNNIL4QEQkvTWI9L6KddPCKM+tZHGyQLw5dqpVZxWGb+A3VPQ743K9VyrJBIkuVX5rqUzyHftw2obYOX5GIvXQHqPEfmNJFhQjfwUYPo6BikjDnJ8dH3LisTDtBxMIuiZK2XkD9VbJMyeltSSo90aicXdodiinHC9YQxmbwHp+6BtPgExTC6rJUrEo2KmiUgjytZm0DDIK36AQsqXfJagFWOndIN8ixFVUONjoRZxPWN7wEySkTLw0sznjJtQCOu6sHTIkYXkbQaSOkKccGBsQGrr5uG6QHwkDkHILUOA6KrTPk1fFSN7IYxytjDIKJNRjH0oEDGpHIi80jWG5A8KDH4WXJxuJASUxtJ1KpGc1+WFAWdFlmG1rP0QZ3pBVQXlJ0L9cgNpSAcrM31evx71ChZkxR2IUoKEeWiFuR1MFAbVxfBA0qFRWM0K9OIG0IwFvG+ZJdzbBSonjlVLEQvkGNbU7IWrCL3yWucM1z1ewoOFedhWWzoxVGGbfj8NzDexUuuo2gkdmu20BwErsdUJkvVaHaMqqHO1DjKz1OcaWIZa4asPrf8/0BhHi2Fep8nEdH3AFwCePNFj+Ua9D788Rzvn2Lm99e+OApmAQAi+lVm/vSLHsdS+pM43uNWQ7d0VHTLLLe0mI6JWb7wogdwTfoTN96jsVlu6fjpmCTLLR05vXBmIaIfiYnd3ySi1170eACAiL5IRG8Q0VfVZ88+Qf3Zjfe9SaqXiOyL+EEIqvw2gD8NYAXg1wB86kWOKY7rLwH4AQBfVZ/9YwCvxb9fA/CP4t+fiuNeA/hEfB77Ho/3wwB+IP59F8A34rie6ZhftGT5QQDfZObfYeY9gJ9HSPh+ocTMvwLg7eLjz+BZJag/Y+L3IqkeL14NfRTAt9X/1eTuI6EsQR2ATlA/mmeYS6rHU475RTNLLVjysrlnR/MMZVL93KGVzw6O+UUzy/WTu18cfTcmpuOpE9SfA80l1cfvn3rML5pZvgzgk0T0CSJaIVQyfukFj2mKnl2C+jOm9ySpHnix3lC0zH8UwXr/bQA/9aLHE8f0cwBeB9Ah7MLPAngVoUz3t+Lvh+r4n4rj/00Af+0FjPcvIqiRXwfwlfjzo896zLcI7i0tphethm7pJaJbZrmlxXTLLLe0mG6Z5ZYW0y2z3NJiumWWW1pMt8xyS4vpllluaTH9/5G5zSXyur+qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAD8CAYAAABHPleGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABTiklEQVR4nO29Xagt3XrX+XvGqJpzrrX3fs8578mJJseQHCFCx74xHVRQRBAxhobjjWIE6YZAbhQVvMiJufAqEL0INDReBAwqaGJAoXMRSMegBEHtpCVqPkhykqg59iEfnq/97rXWrKoxnr4YHzVq1Kg553rfvd89t9kPzL3mrlkfo0b9x/P9PCWqylt6S5eQed0DeEtvDr0Fy1u6mN6C5S1dTG/B8pYuprdgeUsX01uwvKWL6ZWBRUS+VUR+SUQ+KyKfeVXXeUsfHsmr8LOIiAV+GfjTwOeAnwa+XVV/4aVf7C19aPSqOMsfBj6rqr+mqgPww8CnX9G13tKHRN0rOu8ngd8o/v854I9s7byTgx7kSfyfAoIAiKx3VmXmhelbvd/W9jVtXqdFkQu3ePHqPM1xzmOSxS+6Gmv5v/p67d+2r5HHlce03jfRc/3C76jqJ2jQqwJLa/YX9ywi3wl8J8BBnvBH938WvIJ6EINYA9YWRyt4H7/qvC+AGDDxkvV2mH9L5DVvlzSRpmCy8TqLbcX2LLr9fEtiTdhfJI81jxNWY03XVVVwbjXWxe8NWvzuG/u07s171Pn1eAr6ieGf/JfmBXl1YPkc8HXF/38f8P+VO6jqDwA/APAR83EVEdQA3qTfkXKi6smHxQSLyHJipSFhG5OqqmFSE0CYH5B4vwRAnHRJYzFSjafiDvmetD2exn3UY9haFHkujCwXSotKkKcx1+NR3zhwSa8KLD8NfKOIfAr4b8BfBP7S5t4iYEx4CGlyAXVuuV+cOPWKGFlylMX5ao7QXnmJFiAruM5qjGHneaynjANjwPsZMNU4Fse27iHv6PM8iCUvpvQbfuZUWj//rfGV1yvm9By9ErCo6iQifxX4ccACP6iqP3/xCVqTd8HN5GO9rv/fYrunzukVbAuIknWXR1MaS+IIW9c9xymgyQlENhZAY5/3YwW/Ks6Cqv4Y8GOPOqhYsVKx9JKdi10furr5U6s1/ZYe3ql9kyiCNlDKY7PoqHQbWD/4LSCsOFpxvwvdbAl6NUuwLMRywS1XY8o6YtxWMfOSXhlYHk3Fg5AolkplETi9GhOVMvzRQ9g6fwRMBYZT1FQ8t/SCLX0m30djdZQcNIojNSDJKEhj9BU4Cq6lzgVxvrjWNl0PWEpQNCitlCYbrTjEWXbcWNWbQMnHLMfWPm+DoywucoFbqwZ+Y3z5/FvKakm1WC6uIRVAzs3BVYBFVVfKrJTsn3mCygexAM6GGTwrzSaswFNmdWFi1tc9RfUk53EVyvrqWi1qPdTGMQsRUwOqteBKHWihwC851rl7vQqwQPQ1QH6IaiJgampYK4uHlcRX8X/xHq1dW1FW5+NrnwoXcKUSoA1amM5n9j33oGo97iwnpMGNKi5TiqxLFsV1RZ0rv8ljqHmzDW60Iq9Rv7hAzJwiY+ZPfY7SN1L8Vn5WzrviuPc1jooums8zFueVcBY5LRY44QhjViYVDa7jljd2dcmNdXJOeW3pAKespYqaFlJL8S0djaU4aojK1TgupdojfoauBCysxUopTh5hFqvqQnyd9eo2jtvUi6rrr8YZHXGlQ241joaFpA2Fc8UJtvw+rEXURRTN7cU9vRmcpUHFpENbLKRJEhGws9K32vdCh14LJC3Kv1kbdKIMFgGbVn4h3koA29rXYRBzJpZVjK+lx+XrN37bBGnalkS+MUHfHbbu+krBkm+wdvdHWsWB4uqWZFUVzqYF1Z7R+v9lEHODSm4i1kaA2HKHWXH2DpwLwbvSj1THalp+lESl9zn6UvI4KqpF1gwibYu6DM4qaLtBVwEWYYPdn7N84v5ZT0mxGJYPf0WtlVtPZiX/8xE1SLoujKkUSRIdg86j44hM0/zAEsehsPZWnPCE3hTBcFL01CZ3GU+DTXH8RvhZ8kTXk9Rwsp2l5Gn1jQlp+DzqaPci1SCeT9LDtzZstzZs6zroLNoFcUQXftd4rDgH44SMEzgfuIz3SLnSy3SLBKTSc21keS9bAdCNORMR1FpE1guv3A/nmnk6JV0HWGAGTBIjLSWyzBM5eaqlDrOlsywmND2PUsTAkoN0XTRNw5i0swEsvUV3Hb63lFlNZvLI6GCMoJlcAJDXcC+FTqPOg3cBSM4FcVpH4k/k5bTuq56PBZVW1YV+lusByxl3P7DKFwmbtpW7rNtcoOnn84ggfReVV4t0ASi679G+y5OsIgEkvUF7i+8NvgscSJwiXtHJIJ3BdAbpbeAqLoLEhYck5d9pQr2HKWQKrlI0tuhcMPQMvVGm88Ldf8GgVx7b+UTNfWdFcn3d+lySuEjfw36H9h2636E3PX5nUYHE0X1v8LsAEjWCdgSOMipmUkQ0SFcjsJ/HKF4DaCaPOIdMPnIei4xTEAeJ+yRO1KJTVtOFsa7HOB+vAizZ3V/nmpxbLS2gFCy1FDPzbmuHXslVsDaIm12P3uzxhx3+tme6sbiDDdl7Sd3oBLeTwFEEVMA4UKMgPohCJ9BHpTRdxiniwYwemTxmmJDOwHEKrgACVxEnqDGBC8XIcrLUHvOQz+57oWvhSsAibJq5JZ296fOpAyuze3FNE/wkfY/ud/jDDvekx912uL3B7SWMNVn2uwAWtQEb4kGt4jvB7S1o5EKq8W8cQ1I1BqW7d2AEU8Z9nIum7FgM3KzzUR5Dp7IFLxDTcCVgkaQnNBStbBq3aAMcpRneSlo+SdZC36GHPnCUJx3uxuD6mYNACHS6nTAdBEwUPQOBm9gYcc7KrmAmMBOg8292ULRwbxgADzJOUekuzPBLMwXr0EB5v6V7oLU43xgPbpmH2/I7VH6Pep+W/yX9vcgbG01k6Tq0C9aN21vcwTDtDb4j6iYE5mLAHQS3D9+NFawoCPhe8N0SMGYI4BAPPgLKHgEMEtU1FbCq6NgF3clacFUe72JeLhTVhaI8hxY8K2fgmXNdD1hqs7hMbt5KV2ieZmN1JMAZs67xSb6UPvhNgu8keEs1PljfC74Hb+dtbgd+R/wdplvJIkYLDoQQwLaTIKqSNEvRaBNEXHdv0M7QAca5cM/Jyefceo7qxOvVtmrOZB1aeIwP6zrAcgIo6f/ZK9tIX2gG3crTl/mptQ8Fsj5AF0zmABQJoDCBE/ge3F4ihwGNf30P2oWgXLKUzAhmDAptEEmKeMFHvYaov2gEnu8Ft1N8H64pTpHRIc4jxoQStElyzc8q4LlR4rKgUymacFHE+irAEnTAE7Z+IzP/pKJa758SmiEApe/A2Bl4yfFnTDCVrUWtCQ/SBoC4XjInmcGi8YGD3ynaKziwDwa1OoPFaqHsRmXYgU4RfLvIrULcApk6ZNojUxBBIXkLhOiHKWkrE2/DW72YpsyhLkttuAqwAOvcjlYmu4lcIXpzBRasNt/8VoGZBPe59D30fRA3tnDti6CHPjjaOsniRuMDdfsIlp3iLVl3UauBu1gFC058dNCB9nF7HiSIE2QSZAxcyB4lAkiYHJjRYIcOcXsswTqSlCTlksf3hP+lQSd1urKY7gRdD1hgGfAyhbiQojykTIEs0hiaRVur5KIYXe179LALvpQ+XiPGZPzOhk9vgp5i59XvDuD3GjhKmjmdwULvsy6ivYBVpPeYzi9Sc3QyeCcwGPQhsDzxgrjAccwkmMkivkecx8RQAc4j1s3cpbWwyvvemuZSfD3C83s9YIk3LrWCtpEi+Ch/QxmKN0GBZdfjb3e4Q0eZXKomAiSaymqDFRQAo7i94vceOgUTrB+xiu09tnPB6TrZ6Or39LuJ3W7KVrRXYZosbjJMvcUnkSfJzBKMA3EGM1nM0GMepuDh9R71wUIKU6bVfL1PH0y++TfCdC4GWYiQXDRe710E4GraymyT6JmVKHa0M7jbjuFZP3OJYji+E1xfKbMdASg3jv4w0fWOvnPs+4neOnrjOTrL8/sDx4eefjfx9ObIk92AEcWr4LzhYeo4jh1jbxm74PCbug7EgkoUU2AHgz1YzK7DDF2IH41jwWEroJzIWTnvxX19tc7vj7bYaV31VwLlEq9t8lmkACGgnWE6WManweGWlr44DS57CU433yerJyqwe8/uduSdJw+8c3jgI7t7nvZHrCgG5cvjgc+L8mXgZjfy7s0d7+7vwlARBme5m3Ycdx0PU8ewtwxTx53dMwHiLeIEMwp2ELq9odtbOHYwTjHAOc0ct9LPWimam+KmSCS/xIS+LrCUtFVJByeBsvTaFi70tBrT8b6wTlTxRrKJrSY63fbBXHZ78HvwB09/O/KxZ3d87dMv84nDe/ze/VfYy8Sd3/GeC9FC81T52OGe227gI/0DT7pjvA3BF961e9fz5fHAl4cbflOU9yaDGwz2KOF6vURz2qDJP5TmxVpkt8vzoDGHZ5WiWc1Diy71tVwJWIrY0Am5u5WD2goRwNK3kinlxDqHGT12CIqtJsvGRFO4C0CZbsDdKO7gkYPjye2R3/fsS/yBp7/FJ/df5JP9FzF4/svwCUb9GPQP/J79V9ibiV6WItQj9OL4WPeCj9oX3Pk9nxve5TcePoZXYRw7Hh4s7iD4u+gFttHtn569jx0Vui74hTT0XBEfk6v0zIOvuPWb55R7BD06kz3X8wg54Ug1Rns99iGmXkY/iLczZ9Gkr/SgO6XfT3z09p6vv/0Cf/D2v/HJ7ot8wr7AITxoz5fdDR+xytfuvsjXdl9kxPIl94QXfo+PD/GZfeDr+v/OJ+17vNCOZ+aBXhzPxwPPj3uO9z3uzmTlOnmRF4AXE9IorAnz4VzOxMueXjibhvDYioDrActWFliDLgGM1NxEgntVYz4Jk8M8jPRGsEN8OJ1kc3m6CX4Wl/JQrNLvJj6ye+Crd8/5ZPdFPmruMVE5/2r7HA6wE8cn7Fd41zxwFzVnp0EnsqI8MUcOMtIL9Op5Zu75iL3jq/bv8d8PT3h+c+DY9+EeUszIxFSFbM1JEEF9F1ImNNyPjiMyjJHD6OyP2goRLOb/DfHgCg0r5kwU9LGrRVWRmOcaOIvD3A2I07xyg3/E4vYWM9kQVX4iwVgzSmc97+zu+Zr+i3xt9xyAUQ0O4V17x7v2jicy8cwIt2L5bTfw3A+8MCHVYCeOWzliUcY4/J04Pmrv+Hj/go8fXvCFm1se+pvovIPcbq4LaZw5c+9mj+76+b6dQx6GcB/jiKSc2kpsP7q+qKCrAEtJm81m3m/qYFl/JBLMy2kK1/IxQy0pv9GDK2OHmh32qcEMwVmGC9e2ohzMyK0oHnBxnM+M41aEg3T0YjEYepnoZWInDoNnJ46duCi2LA9qcQhGPL04buzITT+C1biCghgKDkKD7HrksA9R8UOP7rqsb4mzmHhPAqhIOzzwAejqwLKgmrts1ftsZLwv8nONCdlnQ/LfeGSKaZQxM187CzF/1jjFDkp3r3R3wnQ0HIeOF9OOO79nVOgFnkTr4yCCRRjV86COUZUve8uoHQaPlbCfQ7jzex6k58H3fMnf8oXpKe+5PUffBd3GaAhc7mKC1V4why6IT0MASB8DnjYEPcX5mJ4Z/TGqYVHUKQpbIvyN87NAlp0ne7Zd2JpiYRWVyl7MnE9plOx6hB1Yk2Mw4hNYwD6AvTeMx46vDAeeuxse1NCL5yBCH500RoSjep575YV2PPc7BrUZKACjdjwgjL7jhd/zJXfLl6db3nN7Bm+D6DCK7zWY7QO4QTA3Buix1mQFNuT9hoCneMGMHTJ0MDlkmqJX+Ix7oTFfW3QVYElR5/ctT0+Ip3X6QhFPMmahx0A0Va3BxxULMa3Ag58Md+OOzw8f4df27/IJ+5xnMnIQHyotFB5UuPM9L7Tnhd/zoD2jdrgIKK+GQS0ewwu/5z134M7v8Gowouysw+4d060yPYkgmMIC8p3gdwYzeszkwZ3xyqpfcoyqXdhj+8udBYuI/CDwvwK/par/c9z2LvBPgW8A/jPwF1T1i/G37wa+g9Cd7K+p6o9fNBLWfpRFf5MWnSokz/sUqYVFt4OyqjD03I0pCtbi9x3uYGKObTCfk5/jxdDzn+8+zlP79fye/st8ovsK75gHjHhsXMUJHA/aB5GjPYN2HH2fQRP2szz4Hq9Bb3liBz62v+MLt7d85Z2OYeyz+1+NwfeB43T3wD3YyWXAiIuebRc+oQ5pXgQLivOpvPxA4j8A/k/gHxXbPgP8pKp+n4SXOHwG+C4R+SZCG9M/CHwt8C9E5A+o6vkCmHQD+XnOTqMmYGqn0inTr/wt567MyU6k4jFr0N6E5OxDyF5zOwnZcUZBhYeh5/N372BE+eLhluf7A+/a97Ci9DJhiX/F86A9D9rz3N1w53fc+R2jtxhRenF4BBdvuBfHk+6IR/jIzQP3T3vGyQTFdQrabkrtRMEcAxiC6SyhvGTyITrtQ8FaSGOoxFCdh7tRqNais2BR1Z8SkW+oNn8a+JPx+z8E/hXwXXH7D6vqEfh1EfksoY//vzk7kkQFaJoVg+nm3q91ZGI5Raow7Ht0H2qE/E2Pu+1xB8u0F6YDuJuQmpASq30MBL437vlKd+CpvcWimbMczMhBRg5mZNSglySg3Lkdo1osnqN0GTS9cTgMo7M4FXrrOBxGxn2f65JI+bwKxoW6JDNMQSUxBKDcDzBOaPS1UCn7ZZlumIsPxyn3e1T18wCq+nkR+eq4/ZPAvy32+1zcdhktoqbL9L9FWkIqeE8ZcEmBrbPZ66Y+Kdc21QZFoOhhj3+6w910TLeW6Uaiqz+6+/cxiAh4L0zO8uA67l3Pnd/RO0dvgjk+agcWjHoefM/R9xko927HqCYHHfdm5NCN7GVixDKpZfABRPvOcbd3aNfnlE082FExg2KOLqQuTC77jRhG9DjAOMxt1+s5rDj3Y+hlK7itETQVDil793O73qFsXlNaSKfKt1cphw1zMJVX2JjXYi26t/i9ZbqxTFFX8X1w8+d0ybiq1QuTM4w+PNh71wcu4iK4LfS+x+AZ1S6AcvQdU3xayfO79xN7G4HmLUM8T2cdXecY+pBolTmrBv0kpCukpCgXPLjDGEpgnW/fO5XYXgRWX53p/Jsi8jWRq3wN8Ftx+9me/Ym06N3/jvl4iqvPXIPC9K1jHFXTm7PNe7JVE4Nu4tFpCt7QVH+cEqkh5SBhHJijYDpiPq1hGi3HseNu7Lnrd0w7i1ODA6x4jr4PAUQPz/2BO7fjhdtz73ruXZ9jREaUUQ2jGt5ze+7djufTngfXMzrL5FIqhWe6Cc5B44Ip7Xehvpq+Cx0bYi5xcDd4RM3svS0yCVfc5BFpHvD+wfKjwP8GfF/8+38V2/+JiHw/QcH9RuD/OX+6dvJTrfQCp+XsVo82F86rJrjFQ2mFCf4ImwrWPcaFysHcMmOKtT0SdAbtgl9j7Doe+p7jrmP0NgPAqwUDd27PaCzvuUMEQs+LaceD65m8oTMegzJIyG0xokzeMPiOo+s4OsswWbwX6BX3xDM5g5kE+xCrDHYGv+sQK4izqA12VvYTpVlNcaJSZDd67r2ULgoi8kMEZfarRORzwN8mgORHROQ7gP8K/Pl4wZ8XkR8BfgGYgL9ykSUEM0cpvbNFx6OLlTGdUw7zPVSpmqGO2GbuIqPDDA4zWOxRsH2IE4UC9si9OsFbg+sVNxoehp4XY+AG+6ivABjxGFEsnnu/4yvjgffG4HA7ug7nDalXiin+Tt7gvGH0JmTRTRaf3pDSafDm7mG6EcajwT7pkCmII/GhdMTEmic5jjCmTxS7pSMyz9Vl/pVEl1hD377x05/a2P97ge991ChaVDexuaQ/STpG/RIgrWx/5wJ3GUbEWowxdBJqdszR424s041hvAGQOVXhaPDWMnbK84c9v909ZXAWrwZfqGxehckH3SZZOSmtcnKGyYdkpl3nsMaH/eP2ceyYRosfDYyCjLE4rYPplghgi+8ldGuI1pE9Osz9DnOckLsjcn+EfpoL6yHqJ7roAfOqxdArpVWbjJa5vMg5tbM3siXS6sZAiVU7j4pDhhEBjPfI0WKtxR86zDt94EDG5Kw1b0NKpuss97bni+aGh6nLQHBeUA0f30hEct4wjpZptIhRht7R9xPeG6bJ4J3BOYNOBh0NMhjM0YSy107hZl4Yvg+lr8ZpKCkZLPaho7+bsJ3BiIQGQikNNZWRTBNMMb+naBp0jq4DLBrExuptH1sFVOfoVNfHsmIgBtiUIOvFOSSyavPQI+6AuB3QxXySGAomKLSj7ngvOuoCQIJpTQmUuD3fqhd0NDCGMbjec+x61AtMJkS3PTHWI0GxHQM3SWmgoSif7IxLhff2KHSxqrE3grUGMwTHnEx+biA0hU5UGBsy71KTRID77Wm9DrBA4BIa2Cuw5Bxb/WurikPgshAAzLEh50Jqoo+Kb+xWKeOE9UknOAAdogZ8cL+PapicMHph2s2V7RkYKuHBu7B/KlnFx1IPH/fJnS0TSMpPrCWKKlGqoxYXvqcyFaKbSa3mRCntOuzeBtE0+Lkc1ik6+dCpYdcH0EzJX3Oau1wPWBqUM9XtRnJUIq8rnWah9bdYbKqvhmAtDWM6MICo65Bpwg5jMK25ATrEm/BgNTzIyVl0X4YTCsV6NDNn8AV3AOYyVpm/F7XQZT+XrTd4qiWKxbCPiqASAOM7g9mHcpLu3mOPJvarizrOYJGxQ45TEMPjdFbhvR6w1FX9RhCdv2+mLpyqAqgo+xqSKFqcx5c7huczGsQY5O5It7NoFx62eBOqMUbBHgW31+ybCYOMwx4ktNoYmblGAYJQfaihb0tiovH3BVgW80QuyPe9BEd2lI7aRTFIyP4zNo0lug08MYYU5skU1lFOzzxB1wEWYX7nIWSFS2ONT6trwkVN8zYqGvNv8VpNz69IiN5OYeWZu5CvKy4ovXYw2GMwZf1OZpd8+kAAylEzZ4GCc/ikmAawiOrs31HN+6RSFYj5Kxamg2G8iRlysetUrkroIeUbQ8z/hcAtI1jMOIPbauA2uNgp8wRdB1hSKUjJFVKdzGPoAiV4lUm3VXuULIVJ4DhgjIlKsGKmDnvssEfD9BBbhQnLbk+AGaE7hodTih8zpSaEYAaPGRNwgyjJfetiEpb4ACS1wSlonljAhusZmYv0o8oXzha7Mkg41lhiWWwAXQCj4p3FTj6EPcwbAZbGILde1tCiUzUwdX5M4kjngJWcd0bQyQWZbkMg0nofHGLTnNg9X2QWR3ZUzFGxg88cQrxGkRTGkZxqKxHgI0eJ4Qi1qZWqRU2wdsAwRkXZ71gANkXJnQhqFD8JdojpveoXBXZ5Ds9Yz1cCFsivnbXzal9U+29ZRmVzn1rknGlrXr+Ecj0mjbGkKegvEHwzYxeti10QJ0PqfRuPS7GlSaNn2MXc3pDdttAPymBeyp0trp/75BqDHnaoU2zkPuIs4gMqnCeWszDXPZkgpnwXTGvxGvQnjecurxVDGqfoesCyRXXBd9mPvxJbJ+kRnkpgztqLrnIdR1INjrjIaTz0ToNzLCYfAeSM+zGarMNI2SA5Z7CJ5Ay9HPl18zmS00y9D9ZZupUkqpTY9cHk/X2yGktml7iIJzZKDNxOYmvVfN03QsFNtOXOv+hFlBcAocp0b9FK5CVv7ziFBzdNuamygfggzYqFCwRfxhjaZWRvaeRWeQFYu3YLULgKYpt2hRAln1y43iShqnLS3PVSU76KQlI/ZNIgfgalv1P69xz2bsIMbgHmN9J0BnLZxvz/4q1esNI5LurlX2bdNXSkk+dwRQMda5HexWCkW3h9tfTzxPgLwxi4UrjIMi4T73XRPiP1u02cJZ0HYOoQ62CyYELSthk8NnWpMtExV/hs7ADdg9Lde7o7R/dixNyPM0dJOTHjHAzdoisBS81RthN3tlqrn6XE9k9RFV5IomhhpqccGyLAvJ+z76pkotCHf1q0VE+lKAksEp2AFHpXfguJn19wJYCa0JtF4jUMLPQXM4U0hsRdxAdrzN57unuHvRuxL4YQPE25ulPl7j9BVwKWSKXbvqLmyj/VNXq1r1/tk728WY9Yp0ks3l0EgJ0V32jRqJGQDlByg1LPKoHiN7LY0v2lstMaeICMQ0huihyNydGNDv8QXPvuvqPbhzqiRPbosQ+hrtvcjyESPYwxmDid91UVdF1ggfbgmz1eq4dY6TWl2GoBbZUEBLHtlqfM/80coIx2R7NHyzyR3OdNlw6/OuzQBP0SPM3xpiSmIpaT8m6tDdWUZtfT7VOnTQNCeD/A/Ygch6BoHwd0HEMKZhKP9Tg36HrAUpeqNjjE4oUNqTzkhPK79YKH+rUzOX3z3Kvfiv75iw6PCQRVL9/gaS+AlKLcj0w6yhzXuahzgYhB1cMUxJ9YiwwjOvRzDZTI8gVZESgkZd3NAJfEFU/Q9YAF2hHjDd/JqkV5K+eleKlV0j02AVS9FzEDKJ2rsloyYLYA1mhtdilIVsp8cV/Ju6zTFKLg0xQCrkag3wVQxHSKDID0LqNpmvUl7xcLdKt/X0lXARZhwzlWVBAutpWAqaPQKQKdGuCcM5fTRFdvS1sO0Cz1mw1q61WBA61iWZcq6SXHTWNNHDFyNI0cJ4GC1gtBk2LdMpEv1FuuAizBodjIPq/LTi9JLm41KyyvtRmx9otM+Ex1zKo8rixVSSLinE5SveTzEm6TOjyla6du4fV9zcnoS3E3+2zcnMCdqATjm5TPsikmas5Qr9BTJZhbD6OpSFcWzAokBZDUoyqLt7KGPxdyjFOWXJlsHvUPIT5sXSrg6ZpZmU9zlXQSU3DY0g1Q39sZoMCVgaWkBds+1Ri4kc9SK7CJmqkNVXvPrXZazThV+GHbyqnvJSdNL7lLWWHZpBKAp16zW3JHFwOhKqH1Rq0DwTYn3KCrA8uKRVKtVlu4xjcmt2n5VHm35fmb1z5FqRiuNKPra9Yr+dTKtfY0pymtNTmRowML7ictTrulK6V7OkFXAZY8/GrFr5TKYpIWr7AtqeJGtWir3f2tMEJTFNbXSVWTteezVJaNCYXqBUCXSV5FCCLdS+0YhJljiIQXVCROVulkK7A33jnZNiTkrBsCrgQsCyoLy+p3EZ+j9xMG4AJ2XAPl1Ar0MX/R2rUYXETJN3ScumN24hKlmZ4svJZldk50N6oRV/tv0PWBBXJZyCI2A3NtS8rHFWkDasvETeeqdYatcZzSQ/wJVh8Ozl/zPo3UipbYDWNtPPSWWb9xngV3pLCKpBJtlyrkXCFYctlp1PprkxHWoFlQraOkfVcBwdmqWGyvk6IauoRuKqImn2+VWN4ywVdDL3SdSlTOF0/jbLgR6nGlRbPyjjcW0wV9cC9IFPkQSJJ+Et3WpVyHpVOqpFZQ7jGu9BTVbW3PbbYaAcjyr5j5E/cpmxCR9kmdDorPSaqBVTsoS+7aGP/m+VrWW8v52aDr4Swpo9/A5nv8tujUKmk52hKlVM7G9oWYqcWWmLl6snqomTuUYQZTbG+Nt+H3SErv4nzF/Zzzwpb9+RaAqhTi/NsF4uh6wBInZdWL5QRtRpO3xFSZeVf6PNK2+P9SzKxeANUCxxla7XNhiucKKMsfT5+nFNsb8bCVN/iNiTqfc+GfMP3qbatiMhrmKWw7uC60qjYfQiMW1Wpl1kzmatUw1RbMpbGdMvjYCk42PNSn6HrAAqdjP+ccaI340QowSczF5j6LdM1NH8c8sVtcZPUQajEWGwmlMZR0ymxf3MNqPiqgt7zCQOpts+UvqufoFF2HgluYhFui5SKl8JGU2HwI5RcP+BHXWid4x/OoX34vUwG2xnLqvGdvZivFcL72yYDhVgZfQVfBWZTG6qydVi3lMD0As1yxW9Hr2nROgcDFg4nbz455y2SNb2XXqDgvLLtKLJTnyduimGrqOeX9n3OotRT3YoxpPM3WYRt0FWDJtCV7y1yTDaWumeJwqotCvuYyfUCLNl6PHm/hNm++fu5SOtWitbindM9NrtTqMvEB6TrEUE0l68zbHnmzrQmuKWfPz1ZSNpXLT3Wei/JpSt9Ldc10jmbA89R9PJYeC5IzovfsSETk60TkX4rIL4rIz4vIX4/b3xWRnxCRX4l/P1Yc890i8lkR+SUR+TNnr5FHsx6sFvpMNa4YtDuhz4iEeEr8m4+pKYqKS60gYCkuTXXecltTRCwf4maWYCultNItEujKz2J8l9IFOtolsJ2Av6mq/xPwR4G/IqFHf+rf/43AT8b/I8v+/d8K/D2RVQOwxliLwV7wcs10TGuim5aSMTNgWt7h0htL8K+kz7nQ/cXe2JpjbSVgtcznrQVzimrOuDm+y7jX2b1U9fOq+u/j9+fALxJarH+a0Lef+PfPxe+fJvbvV9VfB1L//pdDW/pHvRKLjPv8qWM1q3NI8bPkzwzeRjrCB6SsXBYiTutxnzu+Jt+4z0VAsgHGC+hRCq6EFz78IeDf8TL792/K622n0UreF1aTtCyG+rylGelNzu7PL0OoCvDXynPbk9tMyiqjzMkjnPw5hfJeHrvyvp5Y/RLvtZnP0kifzPVRC7/MebF1sfYkIk+Bfwb8DVX9yqldG9tWIxGR7xSRnxGRnxn04dR11ye7QC63ZPlCpjd1F1PEShor8sS1VuO9QAQ0gVCJqIv9LWnsjZTRi/xGF3Cxi8AiIj0BKP9YVf953PybEvr2I++jf7+q/oCqfouqfsuO/fxDrvlZ+iHaXsySterJfI/iXrYBmFZnw4Nb+kPwOtcvtx6qSYr1WvcqlejNe2taUb79eQyVinzpa6kX0tbh584vYWb/PvCLqvr9xU8/SujbD+v+/X9RRPYi8iku6N+/cMqlm9rad+uGisnbSjsoaZE+EH/PaQn1GBqZcqWXtgZMBmRpDdUvhSrHXYJ8I0Eqf5yfPxcsjpP3XN7fBWb2JTrLHwP+MvCfRORn47a/xavo379BTYdb9ftZWpi2DcfeuZ67FFylRXWaQUq5SGPb8Lkk7/NF99DINy6915cuuM2F8EETtlX1X9PWQ+Al9e8XNmIjW9FRWCqoF+gXWzkd8w5rZXaREF6CIeWzlAnXtdu+dse38njTC7bqTg2pLKS0zqQo1y3NeW+W7zq8QMda6EqWWfyeChFwbe5+WK76req9OFlzZHe53yVBwJNcojjPFmDqeErJHUpOuAAenFzJ5+5HYhJ4ipyH/UOTxBRdrmNOrXsC4otE57TVOfFsm67P3Z/N3mq1sXbcLfwgDRm/oJZHtDr/ovxkES5omMmPdMMv9Jg4/vw3flZ+nZrKVILUZPoUJ2nlD7dAVAF7i66Os5S5Jdkn4XWZxV/XudTZ7KXlAmuxsLqoXz+gInMvW0jl5F/oUV2MIfX2lcSFbHWMaT7Mhc5WRtfLDg4l0KvIfIosLzhfahoUNlykM10VWBZJSBvUyi5brPSSMxXm96NyYc44CVeZZ61xpLEkgKWuDrB0HMYwRM6eq8zpGvj1WBbXrqm1CMq0jjMtNmq6GjFUT8ZmuUVF+QEtFNhHBtE+yHGPjezW4qt2zL3kBK9L6FLHnzw6I+sVkIj8NvAC+J3XPZZH0FfxP+Z4v15VP9H64SrAAiAiP6Oq3/K6x3Ep/W4c79WIobd0/fQWLG/pYromsPzA6x7AI+l33XivRmd5S9dP18RZ3tKV01uwvKWL6bWDRUS+NVYBfFZEPvO6xwMgIj8oIr8lIj9XbHtp1QyvYLyvvAIDOJ1++Ko/hAD5rwK/H9gB/wH4ptc5pjiuPwF8M/Bzxba/C3wmfv8M8Hfi92+K494Dn4r3Yz/k8X4N8M3x+zPgl+O4XuqYXzdn+cPAZ1X111R1AH6YUB3wWklVfwr4QrX507yOaoYLSD+kCozXDZZPAr9R/P98JcDro0U1A1BWM1zNPZyqwOADjvl1g+WiSoArp6u5h5ddgVHT6wbLRZUAV0IfqJrhVdOrqMCo6XWD5aeBbxSRT4nIjlD2+qOveUxb9NKqGV42fRgVGMDrtYaiZv5tBO39V4Hved3jiWP6IeDzwEhYhd8BfJxQ0/0r8e+7xf7fE8f/S8CffQ3j/eMEMfIfgZ+Nn2972WN+6+5/SxfTKxND1+hse0sfjF4JZ5HQYuOXgT9NYOM/DXy7qv7CS7/YW/rQ6FVxlqt0tr2lD0avKru/5fT5I+UOIvKdwHcCWLr/5Ym8A8zGfiiZOFNasfwhnbi9LW0+x0jL017CdC+5hpAKutdjbF6/OFfRMn5rTpbbtD1u1Xm/NJ4GfcX/99/RjRzcVwWWs04fVf0BYkLOR8zH9Y8evm19RJ21r5pLLcXa3MkpvfsvH5MolVvE6juMxOL3urHPXMKxqj/aagRYF7Rbm9te6OIFWKY9xlTzU44l1RZZk19YpdME4xjuObU9q+YoF6/V7yLIlZ1xnOUY63uLx/3fL/7Rf2GDXhVYHuf0SZNQ608bvdbSClvU7NbHnurS1HpoXFb2Wo5js9lwWdbaGmP52t/yuPQARQidnefz5fdIlxyibIjodAmO3CdGV2NaACX9fkE3hlcFluxsA/4bwdn2lzb3Fua621ODLou0ylJQFyenAsySfedi44UoW5wHGl2bigq/+MDm+mWz3Xo9H1+NMf2etzOfP4IhvDizKJprlctucLnMgep96orGCiSXGDqvBCyqOonIXwV+nJCG8IOq+vPnjguF6BuNbBKV3Zmg6p+2BMxq0h7RA24xeU3uIYgHvZAbbd5b++Jr8Vc/5ESX9AQ+M8Z8ry+hP8v7IlX9MeDHLtt5vsFmvXBjkjPrTVTvY+32qi9Ej6qGd2KWhfX1cTVAIU9s2Ykgj6u8VqMzVLqmqq51p3mnxbYF5228IiePc3XHFZVlvqrLUtozrxm8nlrnrIAVXQRizXOe2EhNcVWKpviKGI3nXYmF8v2F3qPGZMDkB7h6KMW44ou00/WEhnLJadYeRE0F9lpBjnOSr+PbCydMUqPOuqbFG1LMAjCX0OsOJC5oMbm5Wc26+HxRgF483ACiamWbAnjxITQL2NO1Vv3dahP9kX3cWmNv/ziDPYvNcoxrMGYqWoSsRW8EYcVNy+uG85/vUXc9nCVp9s4DMzdYsfXURK/gHGgwMUUE7XtEC6XNx/10OZmL1UWDCySzPbNtpbRQ5hYYhZgpuFETFKkRUOIQrZUt4d0BWuhfs07hV+KpKSKLeyjFrjg3c7SyPYf361cON+g6wCJFK4308Fr7pQ6QsdORiIZJH8dlf7XW5EWuotYGP8aqP9uGAsmyt8nmtrJvSmntbLQ6a4qCstWX1n1WfCX+Kh9UqxVZ2m5NFs1MaxEbRK8/27niOsCiGyu7ua8nNzUu960tANbcY/7BgPFLBXk+qG1RVefN51+ITp11oFrVbImR3KGyAJYpO2ZWOobqrLSnB550vUbHzHyvMPdqSeKouC8RQVOfvBMtW64DLBAmofakFqtlad65eVvkJNLFWzFmpXxmcbU4b+RM5RhqYDUAO+sEhUgpxcRCbM208OCmcyePbQSdqsLo1k69wkyXUjlP525wvXKMC/DbJUdKCvMlDoDrAEtL3pv1Q5l3r7yOpaNs5QWuQFGet1xFpUJ4YQuwdB7xhdiM4NV6TAkMsSOVVKIgH1taerU1lkRTaf5WpvNi/3zeUqE1wfNVv2iiDiM06DrAUlJlyi4oASeZqg1w1WZ2Pk6LFe8noL0iNekPheJbAyX5eGowFDvMinV1/uzLuNBc3fQnlaAp3Pu14p1XxJZOs7zYyZ+vAyy1KexcUERL5lh2pRQB54N2n62DNPltoZtZfenfaIQPMtgqBXAhFpMFVpngWV9ocY06CFg84KZJnI53bgZGoZwvdLEarK1zunnceTzlGC9w91+Pn6W2970/vxJKOvdihUJ+a2lCnqMt38OloqoOVcTI7zkXfHls1s2yuKl8TaeOLz/leVr3/kb4WYRNXSH8vnROoW5hXSxYdZrgLMqWJq1K+Xpen725ISh4ZvWVFk2LcxQR8VYA8iS1HmAMVC7SJlr+kEbgUjxQhSIW87sKX7wpfhYEsSbI+DouU7Zaj2/jaJqgjW0ZMOn4FiVxUOd+wAnzfW1aa6VolvcTYkGz4nvy3AnA8wWW101WY+McrWh30u/yGFsc5RIOy9WAhQiKQqlM25N/IL6yZeGBzPs03PRnVnLTsVWGDSC/9GlhjoeDl55XIwsltBl0rIN0LUBuiZZT22rdqpyG1gKp/EiPoesBi56ITSRuUsrdRmynmXKZldKGCFm48/0sSh5pOqffE3fJD60+TwnqNJbESU8FAhvR6KYfKgE9ncttNIuur3WJ/sM1geXEq1kyNylXfbUyVykALB/wIlJdhP1zOmISI+XE1RNd+lTK38RQW2EL30oxpsWqLgFRRJfVbehNq/GZWSdzmpX3fG+Vv6ecrxVdoHBfCVg2PJAsHXArXSXJ9hY3KN3dxq+Dd6cmZ+u3kju1IuR5v0qpNqX7vRADlfm7EiM1LfSiRmhDNvKBTomdCxTbRNcBljI21PBbNGVsNkNlyX3g/ASUekjL0X2hwyycS7eV50gL/ehUSCFZZfX4S7FbcorqjSaoWXKkrXM8AiAlXY+fpRQRl8jQJLPrt5huKokXvFRydYnl+3sWelM55pYILcG/ihCb9vZk7VziA2lcM6cjlNZS6Z85ZeWl8Zyg6+AssEL9orwh5WO0JqyM0iZaeIQvXEU1CEzjdS51ykD0Y2zlyCyoFWyElShajb++LgXHbUXN0zkb11qI90ZM6dxiug6wlI6ykqwFie/GqRW9tNLLEohTtHiFbcPRVvtXzj3w9P/kzynDBfncDastnbsMNDaut1gsNYdojSkclDPimpHo8rU75Tghv9f6FF0HWFqpTotEIGGRDFQWaOVTbHtd5110GwirIZ1Rgk9R9Lw2uUPtdKPiSGmMp5yIJVX6T0uZXWb6mxW3vVQ8XwdYlFWsRp2f632KZKBFpHfLF9FypEGTe2kJslaYvvRblFT6ZRb6k2+XiNTiJimz9T75/IX/5BTVYYX5ZlduhWBpucW29L0Z5a/oSsCiDTd/VFbrvNeUg+vctn4AK73jnK9BKqDUVXsLsVA8iFWRGgRxRBGXqf0j6Z5P6AzNCoYzwNE4j3W5S3ZalvfemrczgdvrsYZKOqWVX/Ba3sWExE+yZloZ9nNWfePBV97hmhYVBefYe1oAeSEsr3H2vsp7ah1b0VnxUvmwznGx6+AsiQpfRDPpGeZYUTM5eV6hubS0UioTrR9kZT3VwUm/rCYoz6tAXT3QTDY6YeEs96tqhAoxs/Jgl7dQ+XM2I+Ql1WGHE3QdnKW6ySZrp1jFdbL24lTLFdsuSKvOX6VwrjLfEkCKsEPenrZFYK6qGSvQrep6tij6hbbyVppVkMbkTgklpfM065YK7ntO8b8eztKyYqrVuU4ZrKg0Y2svaakcu2JiogIbdJY5S76ZBpC2lR0fWopsOcZKr1qw+ko5bXKo6tx1TOwSy25Ve3Vmny26HrC03Pxu6fC6iCorQ6J+kPwI6nzBBXzgUvHhL65QP4zGar3kIazOVYrKMpyRrhNNbi3acixM6yIelq+dI91LRbquxSotxK0OEKfoOsAi82S3TNuW/rLK8C9XeumvgCji0uT6DJRgrvuc3aaFb6R0mK2AUCYWteiU2VsDprzXmAWXx1NcO1k4tTtgZaK3Uji2trdiVSfoOsCCnH8A2QpKK7CK08A6JlICqizOgmzeolIot/MqTA9qVYPTokt8Ii29yRdOQhODgNGjnF7QXYN1DdwIvI1rZ0BumeVJT9weeaYrAUukMtd2ZcJqtY9fl3NC1k1qaygrnpHjiPcxe60KoJXmpDFtN3htOVE8gAs8vyUAy9SJlM6Qzpff6J6i69V8ZMsoufiTsl0D55wVVoi8U3RdYAFyqUeKJicqlVrvloCoLalEi4BiYwJrNtwUG7p+UKU1diriXI6jEJOnUiOS/hFOo0jyD7GcC90SN4+hU47FBl0XWIyACatIkhlYioGUQeZMSPSBuUNAzWbPUcWNFmw5kV+mKbb0qqYS2vDOFoObPbqtsZoqkau04EoqzPnm3ZaKfm0ZLqbhMqDAtYEFAlC6LtxUZ9FUmxsVV5lCdrsQ3NeSLBpor/L08E/IdOK5VjpPUUkg1jZbgi0izkFTR6dpPq7cubRKykBjCdSkmG95eNO9+HXm4CoJvaX8s1xYj6HrAIsAXRdA0nUBJH0Hux7tTFghBmTyMHkYJ2SckGEMrT+Toy6ZxYlawb/yskW8p5nBVhSzK+S81prOBuKqh5srFre4zxY1HHzr2u6GdZSO3apnvrCY7+wo5cN4uaQY5HCA/S4AZL9Db/e4Z3umZ3vcOzumd/ZM7xyY3jngnx3Q2wN6s0d2O2TXB6Cl/rHL8YePDWmYuSIwpQHUuhEXrDxTVBZGSt7ls76XRgig9rAuPtbkT+YaiYPEcUhyKpb3Fga1uE4J2lIvKj8nb/v0rADwD4BvrbZ9BvhJVf1GwqtJPhMn55sIbUz/YDzm70no43+ajKCHXQDJYYfe7HBPdky3PdPTnvFpx/BOx/hOx/SsDwB6skMPe/QQAEYfAWMq13Zy7afeJKUbvQGU8274uZuSlOy+Ci2cAspaT5HtTxq3FIAJF5g/iePV5n4xtkxpjKUYS/uccdKdFUOq+lMS3rtX0qeBPxm//0PgXwHfRfGiRuDXRSS9qPHfnLyIMeiTQxA3ncHvLO5gmW4sfif4LmbIezCjYntBrWB7izl2yDAhD2PmHmpG8MmvUlkz3gBuuS215ajyP3Ksherhl7GksVH01ojnzN5aT+h5UdCK22y4DSgUaWiawS3ukFMXClC9H3q/OsviRY0iUr6o8d8W+22+qFGK3v2H/UdwT/doJ6gR3M7gd4bpIPg+gMXbCJYefG9xO4M9GMzR0t13GGsx1iBp5TuHlqtlwZKT0usjeAicApYFbRRKY/jPkiONG5HvwtpZXLc0uYvzrhTVtJuRVdoD1oZ+eq2a5y3OkHQ6kcCBizZpi+zBM+L3ZSu4ras1BaEWvfufvfP7dHrSoUZQC74Xpr3B7QTfE7aFdFz8JPgOzA7c3mL3BrVCH89rkkk9CjJNMa1AgUI5LFMLU8pDBlDBLWBZm3SpmVmb4i2rpaYy2JiDoYW/5dS1q7yUlVVUXzsVp3mdleQL3P7vFyy/KSJfE7nKB3+5pIC3gnaBk7hecDvB7UC7EIhVE9zWYhS1oNPs7RRnMFMMBnoPk529n2VKg0ihpdn5N/WxLXqRvJ33L0CyesmCsGoUCOv/JwU0PbzihQuJFll/fp1yORegVdyjDFHUoY/kdANUSwfl2irMgDlB79f996O87JdLGvDdEih+RxZDaslcx+0Ftwe3I+4rQb/ZW3QXraK0or1bchRjwycrpxqCiuMUzPAUIoiUUxSTWW+W5nNexS3nW/nwrIU+KuK1e73Vb6WRX6LOBR9O9QYUVY1pF0vrJ+lwWfkXae8Ls8V1gs5yFhH5IYIy+1Ui8jngbwPfB/yIiHwH8F+BPx8H/fMi8iPALwAT8FdU9fI4uISPGsCEiGpK7M8CLj3j5JZTEBdiLGaymGNU5DobJijJ9qKAPQDJoOLDg0pe0NLvUZqj1kTTPDb/UxMmPAKy5GILCyOZq6UzrJVBV/+/TrxqbY/ny/1mWAIl7GDAMucrLy5RiTY5zzcusYa+feOnP7Wx//cC33v2yhWJC5aOSmAMiKBG8SIBQAlICTRJNFkNCnAfudDOYvYW8X0QW4nDlBZOAk4OH7gAKu8KZTD5YWThLMzjVc1OwKxIp9ZlaacSfCkwuXj2utyvBZJW8lUZ4Iwlq01t5tICu5YLoUHX4cHV4J0VMcGoTKpAJ0FHMUvAkPax0aDpwHnB7AS7M/hdBz4ou2pMCBEUrFs7O4cPYo+4vI82HGtdB303H1f4V2RyyDgFcDPN+g8zGEqPrdaipowj1dOSgJzGUbxkKz3gyF+XtPCznHe2rY7ZoKsAi6hiHxzGKW4XZJCaWYFFFfVRb0kiKYLFE0WBRv1lb5ApOOfoDDKYECKYou7S2Rw+gMhE/BwqEB+V5CQ+REJ8qu/QvgLL5KFzQeSNNlx3msCOME4z1yqp4SBrlqvU/6/1omT2l2mgdeJYEsFlmKCMfz2SrgMsTrEvRnRvkcmGViMmWggqmAm8DVZQVna7YE4nViSqOCeMt1Hp6wTTG0xvAtfyugSAMLNerwEkk0e9DzGoct/OhE8/BxNFFXGKehtjVj1ELiNuB8MYADpFxblO1IJtb2/rQTa5hW+ftzh3K+i4yAJMrPoC7nMVYMF7zIsH1PXIrgucRILfJSQHzWLJ9YrfgbMBNEj0J3lBvOJi5pvvBNsJ1koECnM2mWfWeSQALSjKijg/gysp2DaCpSv2h7CPC6AxMcgprkPGoGTLOKGDzM6+BBoKBRPOg6NO9SwTrVrpB5Xuo2VkXkzwhue50OhzeQkK7odCqsgwhr+TDw/AK2YKYklt9OT2ZA1XDbNYipt9vBtvg+PO7SzmJiiV4hVJHbk0VhVGURaAkrhFBMHCDBW8lWyhJZ3KTHH/yWOcIqMPFtnDFP0cAVgKMEX9ooxk6/xi0ExV1cEqoaumljOtAlr2s2xRAswZuhqwME7BOhknzDBihh3m2GF3HX5v8TuD20ebGgETJtN3BA1PmGNIneJ3Eh98+hsBo/P+WWFW8nbx6ftyXyBymRB6QKIFNylmMphRMaPHHsOkG+Lq9bpQQsODC/ebra1k2bSaIUMV2yqy8ytrK1yg4kgxNWGVo1twqdJbfIquBCygwxi+pyy5ccIcO8x+h7/pcYekpBCfcvRh7OKKNzO3WUxY4hoRMBDBwHyqDBSdj0FlBktxjLeEEISRAJRRsGP6GwKcCVwmgcX7GTC+UnqNoUxGr1thZKq6HzQBU1IRHddKLNV0kbXEtYAFnaPEGt36kwsTLBIMF42iySlmtJgJpikqvz24XtA+iCLtmJ15JK4SuMzqJd8VGEouk6lc2NGTDASADOBHkAnsKNhdEJmdFTojQf/2Poi4KQRKk58kmcaZ65Q6TOn6D18WM5ZSERapnIm2LJ1TYYk3RsFVYjNgw/z0Zq+nElapjA5ztJhdhxk6zGiZJmE6hOM0WkohpqRBRJmZs6DB0Ue8TAZQOQ6dOVD2Jguo0VlsRTZhBsEP4a9EVcQ+gLfB9Iegz9gxOv2shWkKQPF2frNY7HygZUJVmYZQhiBSgDD5W8ruT3UYoqRTQcJWI+oGXQlYQrxCROMEgDLN/jcX/SQp2613wWrxPeJt4ARi8J0iuyiLk7jodOYWaBZXMOsxSeykbXmpmwiSDJh5yKJgIlcxoyBTAGTXS95fvMWOHWZwwaweCtd6CgWkZtClhQJzcK8wfSU6EusXl2v4EsfcyKOpS1TOlYZs0HWABWbvptMAGgJgcDF+M8ZYTd8FU5vwwILZ28UHbLI6MxnBd4q3GgLMouSDkgWV/klg8SAqGSxqdOYksvyuKvhDPGY0mEEwY1CAIcaqRoO96ZDB040uxjECJU4iEBBaJVqHsSUFtygCKwOOJ7yzi1BCJaJW0W5YK8ANuh6wpFWWXPSxtBQIkwLQd4jrI0Cip9UnUzvcippoanfAAbCgvYfeI1YRo+GZSGqsrHgV1AnqBbRk5QEg89/lcckc9U5w9x3+GDiGeEGmAB47GOzR4h86bFJmjQYF2gNdt37gpf+kBNEFKZ9NSufKuTnFPfoZMK8qn+XVUhV0m2MsqbTTIxIUQwNRhod8GLcT7B4mH/0aotApdu+wNoi6sDg9xigmgsU5g/dJTyJzt0TpuPB3GbibnOFoFdd1TAriDOKC8m1HwQ4WM/SY4z4AfBiXwcf4VrGTekMDCFv7r7L+ayW49ZLPC8TRdYGljKqm8Hl8LS9i5nKRyM5lCl0sZeqQ6CAzyUx2ZB+JWI+1nt1uipdRrCid9XTWoSqMzqAqWKNY47HG47zBR+5hInhENH/3KvlYERhEGRUmFzhLAoyZbBiPv8EagxyH4IQcRlRctARdWOXprR91olXlqW2KGe9zKWvp0s96Tml9WTsr8mcCmomuBywtVptD5yFhSbqi1CGJIufRyc9uemcwk8yKqoAYpe8du27Kp+6tZ2cd+24KnCW6u3vr2NuJTjyTGkaXJn9eqQkszpu8TwIZwDgJkwscxoxBHIk3oD0I2LuYLyOCMKAT5BeFXmL2PqJsdeFrSa1GkrKctquumxA16DrAIoSs/Dr6mjLhTXzdW0xq0gSaFLPZ9/jOROUyWjkOzAQyRl0EsFHsiCh767jtB267ASBzkM54dsZhxOM1gAHAEI41RULK5C2Dtwy+437qubd99AIYXNJbJsG4oHUH34/QW4MVmRPMhzGY2lNIxFq1Yy0pWTUlYEqFdSOCnfcrleVH0nWAJbbcKF+kBITvotDJEih9h9/36N7ie4tayR8gxpUkmLSj4KegjxhROuPpreOmG3ln98Cz7rgAgBWNwAhg8Uj+fy8uAkaxeI6+497vuHc9L+yOvd1lsNx7CVFwb6J/R2b/S/D5gwk5NzmtMma+5aSqLR1mywyGOVDZ+q34fysd4s1pQFi5s1e1wkn8dBbtLf7Q4W67mP8Sj8kZcCDJFT8IfjRBgdUAmJ1x3HYDz7ojH+3vMggS+SroZkQ5mJFeXNzXY1EetOPO7XnP7dmZQxBdPogl7w0Pk8FNEgOYMqc3eIO4OPUiIUlLBMnJTCmJqqGknqItD20VtV41dkwc543RWUqLoCWTVbOrXLugy9SZcwDGKYzQPQj+jpjgbRhvOu53PdZ4bggA6E14+HszYcVjUEa1jNgMLCuevUzc2iMHCYCxkRPttcsA8ipM3nKwE72Nllfn0U7RXkL+TU9Ir9gL7sYgOk+/gdnLm/QxWIqkKhaUuUHtSznhoKuDhgvdxVq4335EVwIWnZsCNjT7sEt01NmQuZa4SLKf86qdwDql6zTn5bqDMNx0HPddUHJ30EVwJMD0ZoqXFcYY/LFR9BzMyDPzwDN7jyUAyKlhVMtBBnpxHLXj6Hs64+ijNWWs4joNzsEeZJJYExWU3yArunx/ZnKIc6FHi4mlKvULu0sukdz9J5oahVPPC7BuM5Ytzgue0nWAJQfxCvNtkeNR+FliCkEKKmKicyyKEeM0cCgLvjO4XrAPghwNbrRMzsbKADARMDaKFSMeDDg1eBH2MtGbiVtz5En89DHB1othUEuvHR7DU/vAnd1xsFMAiuQYQ6b83xgdD5WWgulMVthnD20ssfXKos17nZUPF4mQMOgNwITJWCjKLboOsCQqV0aLVENytJUY/reYwccsf5kz3SK4fCdMB41WCbjJLPQRH7lDr4G7BK4x0Xcug6cXxxNzDDoLjl3KoMJhYiS4F8dBJm7twN4Eszt5hcUFRdsMghnADBpMaReAndI5V/koiZs0MvSDGTx3C9eUQJU4c4onnamJziIpZ8q9KQpuPVktLd/7ABYIPpUx1sNYyeakHF1+5Yw7WMwYTehJwAneSwaMJ3wvOU0vjp1MGDy7qMweZGQnASi9TNhiUj2Gg4zcmiNPbceNHUMoAFBnkAgUO4A9ho8ZQxagTOG7xNTMhd6R/CJbJRoxfiQ21kfBnLpZHt+KPq/mNvp4ztD1gGVL24/lpeollGsQLU/vkSnWz+TVqDnjzgwTduixg8kpBDjJVhFAJ45bO3BrhshZPBYfldYpg+MgY/xM9FFkAfTqMOpxCAftudWBGzuws27WAXyyzsAele6o2PR5cNijwzxMSEpjSKI4hTYWKScbwUEIoNK4aGrQNfJ50/ke0wXqesCSqGXrx0lUP1sI4k0K4oTDTErMDpMjk8cMnu4Y2L4ZI2dxs1f2qT3y1f1X2ElYjU5NVF4FGxNhehwHGXlmBp7JRC9zw4zn6sEH/WU0HaNabu3AzkzsOhcChlGdMhOYEboHxd57unuHfZgCUIZpTit1SyCsfB9+/buUZSGtZKhEZwORb4LOcg7czgUuaQN7l86GySmTfdIKSg1vdM6JtUMMATjBe8MUXfu3duDj9j2seAa1jNqF6gCCRmLwWPEcZOKJTDwzQi+GPsLF6giMOASHMKjl1gwc7ERnHcbGhCkN3MWOin3w9HcT9sWIuR9z+Uipb+Rs/CanLbgLFAumStXcAMwiPWERbDzPYa4DLOU9lTkdMb8l19dA8K9M0MpGl5xFVt24ErISvcxzTTCRH7TnQMj/tfh8aOnVDftZjHccxHEQpReDAZ6lLCjgQXtuzcCT7shtP2KsYzKax5ASvGX0MzdJlZBlKa1fuvzPcYncYr0OBiaRVABss+b5AroOsMDK24j3MI7ztjgZuQh9qlZFWmEmVhCaGIvJRWGz6ZqCgg++57k74IxE/WRencnxNmrHC0J57AtxkcM4Dig9wsEEa8rpyJ0M3Joj73QPPOuP9L1jSpUAGkx9mTQGPJNuEq0e59ApAqUM6rWiwY0cl5VzblGUVsxtrfQ+ojLxesASPYjZkUSZx1KkEibNfdFhOiQVqZ3zTDSBJ28APKEMVoXJG15Me75gn+I6wxNzBMiufAiWzoMaHrTnBXuseO5kYNR7npmRZwb2GA4CO5no42dvJg7dSGf9nLsbSXKJSSNAqCnftnDAlTVGK99I40G3kqbS8fWCXABK3xCdBZoOoUUHozIdsNWywsa/kZ2neuXgvIsK5iBMR8uL444v7m7pjMeI5z23X1hFvUw5KaokI8oTc+SF3fFRveOFDnw0iqDnvueF3/OgO46+Y3AhZJBrsrvQZ8btDLK3MPUhb1wEkbn4XVOMLCZFpTuV0uQtRHUYWAGaFhDSXNb7Fv6YS0TR9YClZKfF/1ftuVrvH0q919TPOS55BUddYQQ7gBsMD/c7vtQdcvDwhd2ztxM7E7jCrRmyS99X2vdT+8ALv+e5ueGj9o47c4cRz3N/4Lm/4T134IXbczftQuadaIgPdSHV0/cGv7fBcotRZ2XWx8TaIJJiUpSkdzKWr44pk5WKZKeVE66eyw9I1wOWFr2fm8wTSeQsQak0Q3D7m3thOnS86PYZf3fdjoMd2ZkQVAzJTy56eMMYfPz7pDvyZXvLM/vAl+wdH7UBLA++57m/4XfGp3xpuOG9Yc80hbeO5DcNxzLckGjVzTVEnQl97CYXFd5YcjoBdumsy9n8KYlJ14vn5ItGT87dm+LBTVRV/wdFNc52pDL3InMXScnQc7a6+Gg+D4buQfH3gnth0K7jKOSE63FnGTrLbTfwIB0mKs9eo4c3AQbhYA8c7MiNHXlqjzztjvTiuHM77vyO3zk+5Tfvn/GVhz3jQ4cMIdQgnlkk7QQ1FhO5jJlCBYB5mDDDBMOY+8bMHNWvxU2qJyq5SknJGmoVz6ff47mbx1d0XWCp20REJ5VYM3siy/zTknKT4dmbm9zodtAAlhiFViuMxjJIz3tGCXXwksEzqVn8P4FGgT4mT/XGcbAjt92IEc8Q9ZQvHm/50t0N93d79MFijyG1MhUUehurEnuNnR8MZtLgD7Iyx70mh0ymaAOWbqshhrdc+wUt6o4KPTDP+xuTVglroLQAcWqVQDZBEYlFXROmM9idoUv9dPv4wKxhsh1Hq/G0hqG3MR93Bkq4rGTAGEkJ3UpnHXvrEFGcN4zecHfccXe3Z7rrkAebg4aiURTlGZ9rqSU2KoIumPjp/QTWhuK6S+bOFAuqnK90tXMK7MtQcEXk64B/BPxewvr4AVX9P0TkXeCfAt8A/GfgL6jqF+Mx3w18B8Gt+NdU9cfPjqTpTyi6OJarqLi5uuWnTkFZlCEAyULsfCB0MW0hRakTYAYvuMny0LvWJcLQYkxJCH4aMRpKSYwvfF/CMHS4Fz1yb7D3IVMvuW9Sj5lwclh0b1ATqxIs4jrs0IWGQHW5xqmE7oalE+bxzDEv0RqagL+pqv9eRJ4B/6+I/ATwvxP693+fiHyG0L//u6r+/V8L/AsR+QMnu1Y2uMnC1EuAKYrF8/+TWIrhfqyi8b2HSfmzqXOTDQ0LU+uM0HfX4D1Mo2HqLJLiOdmDF30zTsAXDzqXhlS3Mhjk3tLdR4X6yFJnMfFvOlUEi/PE9iAGczSYbu4WrmmOkhi5kBa+mXqxFXRpM+hLulV+Hkit15+LyC8SWqx/mpfVv38r67zluSxl7nqsuZJRJU62mZCjw/ZTBAh4a/B9qEv2VvCjxe8U7U0uWdVUrgqUtdDzmDX/FL5I4BCDCSAZQMY5gJjqmub+L+k0Chra0IXmQBH00ZrTms2Vekb5yuByn5pLt3w0dQjAnXf7P0pniS98+EPAv+MD9u9f9O6XJ6v39OU6lqoQfDFZ6W8VJwk3PoVIdCy1MA8Ga0P7sK4rGjGL4EZwh6D8kjp41/NW1j2HOwjXk6CoEgvKUtlqSrgqE55CwZnmxKey3UdoBqTYwWNGH0FfcYEyVfLC4vYMttipIc9lGTcq3ql0ii4Gi4g8Bf4Z8DdU9SsnUNj6YTWOsnf/R7pPaO5+lDyYsb9rPRFNX0IJmLJjgDNzwtTRYKxg+9AbLlglYbjhIYau3bn1WHoWyiy2rK7uTmIRfAJHyF1J54zOwCiKbEx6SsAoc1VCaw6PDDHIOKXevG3HWqu4vTVXIWYUz2EL7lTO3fxM6se0oIvAIiI9ASj/WFX/edz8cvv3JypNuHIlbFFtAaTj0m/OgbcxFcBhBofZGbrj7FsIRWmpK6YsdAuIuLVzP9752szH+2AeS/lJaQmjhky5wQcuM/iYKefnlmQxvVJGF16HM06hTapfvqVEYfYlpSBpvYCKeQupGxEQxTsDtBTpadpOz/RF1pAAfx/4RVX9/uKnHyX07f8+1v37/4mIfD9Bwb28f7/XRV/6/AraVt6FW66CNseJfV8mF1uPRbAMFmOFTjQmf4eWX26QBWfJ3aMMsbNlY36S/lHj1ad0zhBm6O5jbs3RhUaFg4tKuS/+Fqmjx2F+l0CYhHhPM+dsv6B8CaQ8fxEYiYM/pntCoks4yx8D/jLwn0TkZ+O2v8Ur6N+/eCMHZGAsstovpJxBliK5k5m5y9HRhbBNtEAEPwqmT1yEuUedEcqedTVnEc/c4i4CbI5JaSzUD6kJ9ugw9xNmCOPI+Sw5RDHrEFqKoYbIgAt8JyXVwIptY6HSf07QJdbQv2abQ73U/v1AFiGhnDMFE31R8d+Wq015G6PQKh6RCZls4C6jm/0ck2BGg+9D39ys+CZuYjT3kcvgSYpuYaioB8w8UUkMLbiOJ4ib0cFxQI5j9p6Wi0GdDyKoLGFNoqXiHKv+/2k+WnNklu8OmKf8MtBdjwcXlpHT1bsLJQNl9V6dmhbOKR/kvpfA3juLDCHLTSaP6Qw6mmhOz+88CgpwYPc+pxiQe9ItXjwRPHXzg1AWfXfnFqo6e2cfBvQ4LJKdNHWNSMlQVdQ45e3k+4I5k7CRq7uIn0XxnHSeVSnrBXRVYDlJdbObVl3vVuG317BSRZAxKnlOQyG9CW3WpTORw5jAbXKxvSJWstJav3Qi6zHJ71I422YLiKjURgV2nNBxXHEPEV2+JKK4p8X91O+xrhfPllVTOPZK5R54OU6510ZFLUuzid4GrVZMTiYiv1JGAHV2XnFTh+kt2pvgQR0E7U14V2NvMARF2LhZL2laRdnMDvuFHBqli9n85m6A4xAaJmdFXrJOtiVSWnOS5yXc9LxP4Xw72Scuzqdmh+gbCJbkG1jVyJwLs5eUXrFSUIpgQzAn05u9sNEX4zvUW3Q0YAXvZueVR7L7X9MrbZi9r2XXSzWS3xhrYja/fXCYY3xD7MMQuEpKo0zjrcXJhoc6z8nqntuNBZsiqjzPG5mDCwu9pKaTTWpqkkLvSX34S3M6hQUSKzY+tkANyUTqwrbQrWnOuNOsl8xjTD3/k/IK5K5TKadGnC7BUL8boKRGBHnRO2UDKKspKI9piaaUPJX8MhfEh+TSVtyvkkTkt4EXwO+87rE8gr6K/zHH+/Wq+onWD1cBFgAR+RlV/ZbXPY5L6XfjeF9OJu9b+l1Bb8Hyli6mawLLD7zuATySfteN92p0lrd0/XRNnOUtXTm9drCIyLeKyC+JyGdjLu9rJxH5QRH5LRH5uWLbuyLyEyLyK/Hvx4rfvjuO/5dE5M+8hvF+nYj8SxH5RRH5eRH5669kzMlb+jo+hOT7XwV+P7AD/gPwTa9zTHFcfwL4ZuDnim1/F/hM/P4Z4O/E798Ux70HPhXvx37I4/0a4Jvj92fAL8dxvdQxv27O8oeBz6rqr6nqAPwwIeH7tZKq/hTwhWrzpwmJ6cS/f67Y/sOqelTVXwdSgvqHRqr6eVX99/H7c6BMqn9pY37dYPkk8BvF/5vJ3VdCiwR1oExQv5p7OJVUzwcc8+sGy0XJ3VdOV3MPdVL9qV0b286O+XWD5YMld3+49JsxMZ2XmqD+kuhUUn38/QOP+XWD5aeBbxSRT4nIjlDJ+KOveUxblBLUYZ2g/hdFZC8in+IxCeoviS5IqoeXMeYrsDy+jaC9/yrwPa97PHFMP0SowhwJq/A7gI8DPwn8Svz7brH/98Tx/xLwZ1/DeP84QYz8R+Bn4+fbXvaY33pw39LF9LrF0Ft6g+gtWN7SxfQWLG/pYnoLlrd0Mb0Fy1u6mN6C5S1dTG/B8pYuprdgeUsX0/8PV0dx4bJtFeoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=transl0'\n",
    "model.forward = model.forward_latent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.5785, loss_val: nan, pos_over_neg: 1.0340266227722168 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.3392, loss_val: nan, pos_over_neg: 2.6888039112091064 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 7.1201, loss_val: nan, pos_over_neg: 2.0475881099700928 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.866, loss_val: nan, pos_over_neg: 8.815142631530762 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.7192, loss_val: nan, pos_over_neg: 20.682579040527344 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.6898, loss_val: nan, pos_over_neg: 19.167526245117188 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.5998, loss_val: nan, pos_over_neg: 20.74757957458496 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.58, loss_val: nan, pos_over_neg: 23.270824432373047 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.5692, loss_val: nan, pos_over_neg: 26.619600296020508 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.4965, loss_val: nan, pos_over_neg: 47.59990310668945 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.4824, loss_val: nan, pos_over_neg: 54.01868438720703 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.4521, loss_val: nan, pos_over_neg: 78.09954071044922 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.4253, loss_val: nan, pos_over_neg: 84.71736907958984 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.4179, loss_val: nan, pos_over_neg: 89.1485824584961 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.4132, loss_val: nan, pos_over_neg: 89.18240356445312 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.3793, loss_val: nan, pos_over_neg: 116.91329956054688 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.3639, loss_val: nan, pos_over_neg: 141.4477996826172 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.3552, loss_val: nan, pos_over_neg: 109.11334991455078 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.3419, loss_val: nan, pos_over_neg: 122.47229766845703 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.3373, loss_val: nan, pos_over_neg: 105.9799575805664 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.3366, loss_val: nan, pos_over_neg: 259.17236328125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.3157, loss_val: nan, pos_over_neg: 270.9415588378906 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.3176, loss_val: nan, pos_over_neg: 256.2096252441406 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 6.3001, loss_val: nan, pos_over_neg: 215.9441680908203 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 6.2881, loss_val: nan, pos_over_neg: 122.32212829589844 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 6.276, loss_val: nan, pos_over_neg: 166.85108947753906 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 6.2794, loss_val: nan, pos_over_neg: 357.52471923828125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 6.2538, loss_val: nan, pos_over_neg: 252.68263244628906 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 6.2519, loss_val: nan, pos_over_neg: 235.07151794433594 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 6.2547, loss_val: nan, pos_over_neg: 265.0335693359375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 6.2513, loss_val: nan, pos_over_neg: 337.862060546875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 6.2531, loss_val: nan, pos_over_neg: 305.7766418457031 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 6.2375, loss_val: nan, pos_over_neg: 633.1246337890625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 6.2357, loss_val: nan, pos_over_neg: 298.6596984863281 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 6.2334, loss_val: nan, pos_over_neg: 301.9438781738281 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 6.2287, loss_val: nan, pos_over_neg: 371.3529052734375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 6.2129, loss_val: nan, pos_over_neg: 652.4263916015625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 6.1937, loss_val: nan, pos_over_neg: 926.3410034179688 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 6.1801, loss_val: nan, pos_over_neg: 711.48876953125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 6.2006, loss_val: nan, pos_over_neg: 13514.1748046875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 6.1985, loss_val: nan, pos_over_neg: 1290.5953369140625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 6.1853, loss_val: nan, pos_over_neg: 232.37286376953125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 6.1912, loss_val: nan, pos_over_neg: 415.76605224609375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 6.1775, loss_val: nan, pos_over_neg: 372.376220703125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 6.1815, loss_val: nan, pos_over_neg: 612.8436889648438 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 6.1672, loss_val: nan, pos_over_neg: 971.1683349609375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 6.1769, loss_val: nan, pos_over_neg: 758.5227661132812 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 6.1822, loss_val: nan, pos_over_neg: 309.4440612792969 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 6.1707, loss_val: nan, pos_over_neg: 280.4767150878906 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 6.1498, loss_val: nan, pos_over_neg: 320.40069580078125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 6.1543, loss_val: nan, pos_over_neg: 784.5090942382812 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 6.1805, loss_val: nan, pos_over_neg: 398.21197509765625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 6.1493, loss_val: nan, pos_over_neg: 472.9237365722656 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 6.16, loss_val: nan, pos_over_neg: 446.651123046875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 6.1349, loss_val: nan, pos_over_neg: 335.1882019042969 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 6.1319, loss_val: nan, pos_over_neg: 363.9139709472656 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 6.1206, loss_val: nan, pos_over_neg: 316.61181640625 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 6.1458, loss_val: nan, pos_over_neg: 440.0192565917969 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 6.1292, loss_val: nan, pos_over_neg: 735.2374267578125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 6.1488, loss_val: nan, pos_over_neg: 289.18798828125 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 6.1403, loss_val: nan, pos_over_neg: 434.7727355957031 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 6.1443, loss_val: nan, pos_over_neg: 366.7488708496094 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 6.1246, loss_val: nan, pos_over_neg: 511.93731689453125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 6.1189, loss_val: nan, pos_over_neg: 575.5982666015625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 6.139, loss_val: nan, pos_over_neg: 227.02415466308594 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 6.123, loss_val: nan, pos_over_neg: 458.36065673828125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 6.1209, loss_val: nan, pos_over_neg: 232.28961181640625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 6.1267, loss_val: nan, pos_over_neg: 264.15203857421875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 6.124, loss_val: nan, pos_over_neg: 156.27207946777344 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 6.1397, loss_val: nan, pos_over_neg: 286.04754638671875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 6.1171, loss_val: nan, pos_over_neg: 395.7546081542969 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 6.115, loss_val: nan, pos_over_neg: 248.1392364501953 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 6.1051, loss_val: nan, pos_over_neg: 814.9216918945312 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 6.1101, loss_val: nan, pos_over_neg: 271.96697998046875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 6.1088, loss_val: nan, pos_over_neg: 158.92701721191406 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 6.0985, loss_val: nan, pos_over_neg: 247.7693634033203 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 6.1033, loss_val: nan, pos_over_neg: 822.7260131835938 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 6.1031, loss_val: nan, pos_over_neg: 196.8165740966797 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 6.1139, loss_val: nan, pos_over_neg: 250.2802276611328 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 6.1028, loss_val: nan, pos_over_neg: 388.1837463378906 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 6.1156, loss_val: nan, pos_over_neg: 222.47564697265625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 6.1004, loss_val: nan, pos_over_neg: 533.335205078125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 6.1135, loss_val: nan, pos_over_neg: 376.5443420410156 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 6.1041, loss_val: nan, pos_over_neg: 211.04335021972656 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 6.1048, loss_val: nan, pos_over_neg: 245.67474365234375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 6.0755, loss_val: nan, pos_over_neg: 334.8378601074219 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 6.0889, loss_val: nan, pos_over_neg: 273.4922180175781 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 6.0921, loss_val: nan, pos_over_neg: 334.611572265625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 6.0859, loss_val: nan, pos_over_neg: 188.90457153320312 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 6.0991, loss_val: nan, pos_over_neg: 418.66552734375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 6.0855, loss_val: nan, pos_over_neg: 465.7043151855469 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 6.0722, loss_val: nan, pos_over_neg: 386.2148742675781 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 6.089, loss_val: nan, pos_over_neg: 489.72015380859375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 6.0745, loss_val: nan, pos_over_neg: 603.6248779296875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 6.0979, loss_val: nan, pos_over_neg: 252.9903564453125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 6.0765, loss_val: nan, pos_over_neg: 499.3916931152344 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 6.0833, loss_val: nan, pos_over_neg: 368.01971435546875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 6.0774, loss_val: nan, pos_over_neg: 289.0410461425781 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 6.0783, loss_val: nan, pos_over_neg: 650.2849731445312 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 6.0774, loss_val: nan, pos_over_neg: 215.2547607421875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 6.0934, loss_val: nan, pos_over_neg: 257.0872497558594 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 6.0707, loss_val: nan, pos_over_neg: 777.4995727539062 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 6.0753, loss_val: nan, pos_over_neg: 444.6756591796875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 6.0793, loss_val: nan, pos_over_neg: 301.9212951660156 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 6.079, loss_val: nan, pos_over_neg: 324.0606689453125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 6.073, loss_val: nan, pos_over_neg: 412.1573791503906 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 6.0884, loss_val: nan, pos_over_neg: 225.4259033203125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 6.0751, loss_val: nan, pos_over_neg: 297.19268798828125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 6.0816, loss_val: nan, pos_over_neg: 470.4563903808594 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 6.0873, loss_val: nan, pos_over_neg: 306.38885498046875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 6.0795, loss_val: nan, pos_over_neg: 352.9260559082031 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 6.0661, loss_val: nan, pos_over_neg: 711.5982666015625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 6.0699, loss_val: nan, pos_over_neg: 354.6532897949219 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 6.0655, loss_val: nan, pos_over_neg: 413.16119384765625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 6.0652, loss_val: nan, pos_over_neg: 327.6457824707031 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 6.0676, loss_val: nan, pos_over_neg: 594.8363037109375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 6.0587, loss_val: nan, pos_over_neg: 705.8067016601562 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 6.0521, loss_val: nan, pos_over_neg: 519.8228759765625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 6.0684, loss_val: nan, pos_over_neg: 184.04714965820312 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 6.0523, loss_val: nan, pos_over_neg: 301.35125732421875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 6.0491, loss_val: nan, pos_over_neg: 471.7295227050781 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 6.0428, loss_val: nan, pos_over_neg: 259.9798278808594 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 6.0524, loss_val: nan, pos_over_neg: 400.1877136230469 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 6.0377, loss_val: nan, pos_over_neg: 207.1383056640625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 6.034, loss_val: nan, pos_over_neg: 471.8005676269531 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 6.043, loss_val: nan, pos_over_neg: 351.039794921875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 6.0346, loss_val: nan, pos_over_neg: 231.77362060546875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 6.0487, loss_val: nan, pos_over_neg: 454.43988037109375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 6.0399, loss_val: nan, pos_over_neg: 327.4486083984375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 6.0505, loss_val: nan, pos_over_neg: 1095.07666015625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 6.0447, loss_val: nan, pos_over_neg: 233.69789123535156 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 6.0453, loss_val: nan, pos_over_neg: 452.3835754394531 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 6.037, loss_val: nan, pos_over_neg: 759.9591674804688 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 6.0422, loss_val: nan, pos_over_neg: 281.02911376953125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 6.0373, loss_val: nan, pos_over_neg: 796.0535888671875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 6.0648, loss_val: nan, pos_over_neg: 165.12342834472656 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 6.0314, loss_val: nan, pos_over_neg: 559.9335327148438 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 6.0456, loss_val: nan, pos_over_neg: 730.5363159179688 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 6.0525, loss_val: nan, pos_over_neg: 409.2726745605469 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 6.0353, loss_val: nan, pos_over_neg: 491.0304870605469 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 6.051, loss_val: nan, pos_over_neg: 702.9345703125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 6.0294, loss_val: nan, pos_over_neg: 340.8833923339844 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 6.048, loss_val: nan, pos_over_neg: 280.5970458984375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 6.0387, loss_val: nan, pos_over_neg: 989.1207275390625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 6.041, loss_val: nan, pos_over_neg: 395.1683044433594 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 6.0364, loss_val: nan, pos_over_neg: 619.4559326171875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 6.0288, loss_val: nan, pos_over_neg: 378.05950927734375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 6.0307, loss_val: nan, pos_over_neg: 296.3126220703125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 6.047, loss_val: nan, pos_over_neg: 347.1698303222656 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 6.0356, loss_val: nan, pos_over_neg: 486.1070861816406 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 6.0216, loss_val: nan, pos_over_neg: 330.8927307128906 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 6.0468, loss_val: nan, pos_over_neg: 514.5458984375 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 6.0135, loss_val: nan, pos_over_neg: 429.8362731933594 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 6.0214, loss_val: nan, pos_over_neg: 458.36627197265625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 6.0224, loss_val: nan, pos_over_neg: 380.0051574707031 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 6.0206, loss_val: nan, pos_over_neg: 321.4898376464844 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 6.0266, loss_val: nan, pos_over_neg: 297.2198791503906 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 6.038, loss_val: nan, pos_over_neg: 280.510498046875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 6.0369, loss_val: nan, pos_over_neg: 484.8387451171875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 6.0252, loss_val: nan, pos_over_neg: 276.3338623046875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 6.014, loss_val: nan, pos_over_neg: 272.136962890625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 6.0305, loss_val: nan, pos_over_neg: 253.16497802734375 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 6.0241, loss_val: nan, pos_over_neg: 312.755859375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 6.0196, loss_val: nan, pos_over_neg: 541.646728515625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 6.0091, loss_val: nan, pos_over_neg: 701.50146484375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 6.0271, loss_val: nan, pos_over_neg: 298.00994873046875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 6.0223, loss_val: nan, pos_over_neg: 206.1167449951172 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 6.0313, loss_val: nan, pos_over_neg: 326.91339111328125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 6.0265, loss_val: nan, pos_over_neg: 852.8408203125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 6.0361, loss_val: nan, pos_over_neg: 265.9700012207031 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 6.0272, loss_val: nan, pos_over_neg: 270.81365966796875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 6.0234, loss_val: nan, pos_over_neg: 316.8646240234375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 6.0223, loss_val: nan, pos_over_neg: 291.8293762207031 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 6.041, loss_val: nan, pos_over_neg: 197.4921112060547 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 6.0172, loss_val: nan, pos_over_neg: 430.2823486328125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 6.0169, loss_val: nan, pos_over_neg: 417.15985107421875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 6.0243, loss_val: nan, pos_over_neg: 289.348876953125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 6.0318, loss_val: nan, pos_over_neg: 275.8428649902344 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 6.0272, loss_val: nan, pos_over_neg: 332.1764221191406 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 6.0283, loss_val: nan, pos_over_neg: 212.54364013671875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 6.0253, loss_val: nan, pos_over_neg: 312.5640563964844 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 6.0206, loss_val: nan, pos_over_neg: 488.9582824707031 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 6.0269, loss_val: nan, pos_over_neg: 295.5270080566406 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 6.0248, loss_val: nan, pos_over_neg: 623.2100830078125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 6.0054, loss_val: nan, pos_over_neg: 441.2593688964844 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 6.0178, loss_val: nan, pos_over_neg: 553.9671630859375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 6.0424, loss_val: nan, pos_over_neg: 285.1591491699219 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 6.0124, loss_val: nan, pos_over_neg: 295.082763671875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 6.017, loss_val: nan, pos_over_neg: 586.639892578125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 6.015, loss_val: nan, pos_over_neg: 741.6808471679688 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 6.0066, loss_val: nan, pos_over_neg: 603.4310913085938 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 6.0156, loss_val: nan, pos_over_neg: 488.43682861328125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 6.0233, loss_val: nan, pos_over_neg: 364.1496887207031 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 6.0127, loss_val: nan, pos_over_neg: 326.8819274902344 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 6.0146, loss_val: nan, pos_over_neg: 522.1526489257812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 6.0158, loss_val: nan, pos_over_neg: 344.7747497558594 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 6.0057, loss_val: nan, pos_over_neg: 1621.1778564453125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 6.0065, loss_val: nan, pos_over_neg: 816.6354370117188 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 6.0254, loss_val: nan, pos_over_neg: 312.6867980957031 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 6.0099, loss_val: nan, pos_over_neg: 357.34814453125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 6.0162, loss_val: nan, pos_over_neg: 284.3551940917969 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 6.0168, loss_val: nan, pos_over_neg: 791.3878784179688 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 6.029, loss_val: nan, pos_over_neg: 370.4875183105469 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 6.0185, loss_val: nan, pos_over_neg: 1076.20654296875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 6.0077, loss_val: nan, pos_over_neg: 521.6690063476562 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.9995, loss_val: nan, pos_over_neg: 472.94195556640625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.9981, loss_val: nan, pos_over_neg: 425.32037353515625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 6.0039, loss_val: nan, pos_over_neg: 313.99005126953125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 6.0029, loss_val: nan, pos_over_neg: 699.0155029296875 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.996, loss_val: nan, pos_over_neg: 797.3381958007812 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 6.0267, loss_val: nan, pos_over_neg: 612.6932983398438 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.9983, loss_val: nan, pos_over_neg: 345.137939453125 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 6.0135, loss_val: nan, pos_over_neg: 425.4640197753906 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 6.0116, loss_val: nan, pos_over_neg: 727.261474609375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 6.007, loss_val: nan, pos_over_neg: 332.5481872558594 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 6.0006, loss_val: nan, pos_over_neg: 678.33935546875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 6.0005, loss_val: nan, pos_over_neg: 362.1055908203125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 6.0014, loss_val: nan, pos_over_neg: 397.28106689453125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 6.0086, loss_val: nan, pos_over_neg: 188.94125366210938 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 6.0073, loss_val: nan, pos_over_neg: 236.67625427246094 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.998, loss_val: nan, pos_over_neg: 686.1589965820312 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.994, loss_val: nan, pos_over_neg: 2101.10791015625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.9967, loss_val: nan, pos_over_neg: 224.02447509765625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 6.0071, loss_val: nan, pos_over_neg: 458.53680419921875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 6.0098, loss_val: nan, pos_over_neg: 413.7962646484375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 6.0074, loss_val: nan, pos_over_neg: 251.07623291015625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 6.0094, loss_val: nan, pos_over_neg: 372.53753662109375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 6.0061, loss_val: nan, pos_over_neg: 201.43946838378906 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 6.0053, loss_val: nan, pos_over_neg: 199.40274047851562 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 6.0069, loss_val: nan, pos_over_neg: 595.7850341796875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.9944, loss_val: nan, pos_over_neg: 261.79534912109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 6.0142, loss_val: nan, pos_over_neg: 276.9334716796875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.9967, loss_val: nan, pos_over_neg: 554.4759521484375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 6.0126, loss_val: nan, pos_over_neg: 230.75479125976562 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.9943, loss_val: nan, pos_over_neg: 364.5345764160156 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 6.0035, loss_val: nan, pos_over_neg: 284.0459899902344 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 6.0013, loss_val: nan, pos_over_neg: 321.671142578125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.983, loss_val: nan, pos_over_neg: 268.1811828613281 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 6.0108, loss_val: nan, pos_over_neg: 368.6581115722656 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.9975, loss_val: nan, pos_over_neg: 260.7892150878906 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 6.0078, loss_val: nan, pos_over_neg: 294.9071350097656 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.9943, loss_val: nan, pos_over_neg: 424.187255859375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.9972, loss_val: nan, pos_over_neg: 328.6465759277344 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.9988, loss_val: nan, pos_over_neg: 198.1237030029297 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.9912, loss_val: nan, pos_over_neg: 421.8459777832031 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.9966, loss_val: nan, pos_over_neg: 433.11639404296875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.9974, loss_val: nan, pos_over_neg: 245.3419647216797 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.9813, loss_val: nan, pos_over_neg: 663.4561157226562 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.9923, loss_val: nan, pos_over_neg: 363.6677551269531 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.9945, loss_val: nan, pos_over_neg: 182.54562377929688 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 6.0218, loss_val: nan, pos_over_neg: 209.04847717285156 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.969, loss_val: nan, pos_over_neg: 439.7975769042969 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.9907, loss_val: nan, pos_over_neg: 304.47723388671875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.9935, loss_val: nan, pos_over_neg: 286.7227783203125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.9972, loss_val: nan, pos_over_neg: 798.4583129882812 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.9877, loss_val: nan, pos_over_neg: 241.68109130859375 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 6.001, loss_val: nan, pos_over_neg: 304.5649719238281 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 6.0041, loss_val: nan, pos_over_neg: 352.1695251464844 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.9962, loss_val: nan, pos_over_neg: 143.14974975585938 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.9953, loss_val: nan, pos_over_neg: 541.3110961914062 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 6.0006, loss_val: nan, pos_over_neg: 332.83642578125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 6.0049, loss_val: nan, pos_over_neg: 260.8045349121094 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.9977, loss_val: nan, pos_over_neg: 534.9609375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 6.0031, loss_val: nan, pos_over_neg: 381.34893798828125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.999, loss_val: nan, pos_over_neg: 526.0549926757812 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.9742, loss_val: nan, pos_over_neg: 390.7695617675781 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.9819, loss_val: nan, pos_over_neg: 651.6304321289062 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.973, loss_val: nan, pos_over_neg: 638.6755981445312 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.9919, loss_val: nan, pos_over_neg: 1403.7445068359375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.9947, loss_val: nan, pos_over_neg: 1703.1883544921875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.9872, loss_val: nan, pos_over_neg: 365.23040771484375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.9827, loss_val: nan, pos_over_neg: 323.74676513671875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.9865, loss_val: nan, pos_over_neg: 486.02728271484375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.9856, loss_val: nan, pos_over_neg: 358.71612548828125 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.9956, loss_val: nan, pos_over_neg: 316.3340148925781 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.9978, loss_val: nan, pos_over_neg: 535.419921875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.9902, loss_val: nan, pos_over_neg: 397.31536865234375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 6.0024, loss_val: nan, pos_over_neg: 817.0289916992188 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.9991, loss_val: nan, pos_over_neg: 356.09613037109375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.9809, loss_val: nan, pos_over_neg: 689.1744384765625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.996, loss_val: nan, pos_over_neg: 1665.1263427734375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.9905, loss_val: nan, pos_over_neg: 435.66302490234375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.9885, loss_val: nan, pos_over_neg: 697.3364868164062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.9868, loss_val: nan, pos_over_neg: 321.4059753417969 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.9848, loss_val: nan, pos_over_neg: 387.9443664550781 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.9859, loss_val: nan, pos_over_neg: 964.3389282226562 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.9811, loss_val: nan, pos_over_neg: 348.5596923828125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.9754, loss_val: nan, pos_over_neg: 468.30377197265625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.9658, loss_val: nan, pos_over_neg: 1055.5089111328125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.9761, loss_val: nan, pos_over_neg: 593.3245849609375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.9866, loss_val: nan, pos_over_neg: 444.6846923828125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.97, loss_val: nan, pos_over_neg: 432.7095642089844 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 6.0011, loss_val: nan, pos_over_neg: 224.6630859375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.9829, loss_val: nan, pos_over_neg: 375.142578125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.9708, loss_val: nan, pos_over_neg: 1106.371337890625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.9828, loss_val: nan, pos_over_neg: 429.140625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.9852, loss_val: nan, pos_over_neg: 1109.1390380859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.9801, loss_val: nan, pos_over_neg: 744.0438232421875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.9883, loss_val: nan, pos_over_neg: 415.6485290527344 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.9822, loss_val: nan, pos_over_neg: 295.5062255859375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.9816, loss_val: nan, pos_over_neg: 357.0909118652344 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.9779, loss_val: nan, pos_over_neg: 598.0786743164062 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.9848, loss_val: nan, pos_over_neg: 500.034423828125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.9749, loss_val: nan, pos_over_neg: 1556.2220458984375 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.9796, loss_val: nan, pos_over_neg: 1271.0286865234375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.9632, loss_val: nan, pos_over_neg: 875.3516845703125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.9748, loss_val: nan, pos_over_neg: 350.00946044921875 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.9866, loss_val: nan, pos_over_neg: 255.02227783203125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.9833, loss_val: nan, pos_over_neg: 466.1702575683594 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.9776, loss_val: nan, pos_over_neg: 315.8426818847656 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.9853, loss_val: nan, pos_over_neg: 446.5472412109375 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.9926, loss_val: nan, pos_over_neg: 341.73193359375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.975, loss_val: nan, pos_over_neg: 553.2890014648438 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.9974, loss_val: nan, pos_over_neg: 200.58514404296875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.9763, loss_val: nan, pos_over_neg: 340.252685546875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.9888, loss_val: nan, pos_over_neg: 273.4892272949219 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.9936, loss_val: nan, pos_over_neg: 634.2509155273438 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.9794, loss_val: nan, pos_over_neg: 364.9896240234375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.9831, loss_val: nan, pos_over_neg: 4079.553466796875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.9904, loss_val: nan, pos_over_neg: 310.3891906738281 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.9816, loss_val: nan, pos_over_neg: 424.126953125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.9856, loss_val: nan, pos_over_neg: 326.917724609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.9786, loss_val: nan, pos_over_neg: 534.4579467773438 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.9894, loss_val: nan, pos_over_neg: 384.82830810546875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.9923, loss_val: nan, pos_over_neg: 262.1011047363281 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.9903, loss_val: nan, pos_over_neg: 360.9793701171875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.9847, loss_val: nan, pos_over_neg: 380.3506164550781 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.982, loss_val: nan, pos_over_neg: 345.999267578125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.9727, loss_val: nan, pos_over_neg: 326.1825256347656 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.9909, loss_val: nan, pos_over_neg: 260.21685791015625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.98, loss_val: nan, pos_over_neg: 280.16668701171875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.9754, loss_val: nan, pos_over_neg: 363.1784973144531 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.9702, loss_val: nan, pos_over_neg: 1449.3966064453125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.9749, loss_val: nan, pos_over_neg: 289.8865966796875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.9806, loss_val: nan, pos_over_neg: 289.4479064941406 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.979, loss_val: nan, pos_over_neg: 914.9896240234375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.9736, loss_val: nan, pos_over_neg: 515.9573364257812 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.9753, loss_val: nan, pos_over_neg: 352.6732177734375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.9887, loss_val: nan, pos_over_neg: 281.5078125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.9643, loss_val: nan, pos_over_neg: 405.97137451171875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.9869, loss_val: nan, pos_over_neg: 252.3746795654297 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.974, loss_val: nan, pos_over_neg: 479.5358581542969 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.9686, loss_val: nan, pos_over_neg: 467.404296875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.9716, loss_val: nan, pos_over_neg: 280.5625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.966, loss_val: nan, pos_over_neg: 388.8982238769531 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.968, loss_val: nan, pos_over_neg: 328.3877258300781 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.9661, loss_val: nan, pos_over_neg: 348.0988464355469 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.9719, loss_val: nan, pos_over_neg: 475.9297790527344 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.9719, loss_val: nan, pos_over_neg: 533.7483520507812 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.9575, loss_val: nan, pos_over_neg: 347.9527282714844 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.9756, loss_val: nan, pos_over_neg: 401.15167236328125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.9649, loss_val: nan, pos_over_neg: 505.47259521484375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.9825, loss_val: nan, pos_over_neg: 285.10888671875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.9658, loss_val: nan, pos_over_neg: 338.5120849609375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.9717, loss_val: nan, pos_over_neg: 831.5810546875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.9617, loss_val: nan, pos_over_neg: 444.3211975097656 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.9575, loss_val: nan, pos_over_neg: 579.236083984375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.966, loss_val: nan, pos_over_neg: 513.3201904296875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.9711, loss_val: nan, pos_over_neg: 631.256103515625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.9727, loss_val: nan, pos_over_neg: 1426.1546630859375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.9802, loss_val: nan, pos_over_neg: 527.7888793945312 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.9717, loss_val: nan, pos_over_neg: 980.5802001953125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.985, loss_val: nan, pos_over_neg: 214.9716033935547 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.9688, loss_val: nan, pos_over_neg: 399.97320556640625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.9714, loss_val: nan, pos_over_neg: 802.7356567382812 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.9724, loss_val: nan, pos_over_neg: 763.7575073242188 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.9604, loss_val: nan, pos_over_neg: 444.42230224609375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.9548, loss_val: nan, pos_over_neg: 636.3869018554688 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.9835, loss_val: nan, pos_over_neg: 181.58750915527344 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.9652, loss_val: nan, pos_over_neg: 287.7917785644531 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.9576, loss_val: nan, pos_over_neg: 524.563232421875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.9778, loss_val: nan, pos_over_neg: 1019.3594970703125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.9697, loss_val: nan, pos_over_neg: 1689.9288330078125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.9839, loss_val: nan, pos_over_neg: 354.71600341796875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.9671, loss_val: nan, pos_over_neg: 590.0376586914062 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.9512, loss_val: nan, pos_over_neg: 460.851318359375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 397.1617736816406 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.9701, loss_val: nan, pos_over_neg: 522.3746948242188 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.9533, loss_val: nan, pos_over_neg: 363.359619140625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.9703, loss_val: nan, pos_over_neg: 397.63629150390625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.9572, loss_val: nan, pos_over_neg: 1056.385009765625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.9631, loss_val: nan, pos_over_neg: 337.3144836425781 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.986, loss_val: nan, pos_over_neg: 471.2216491699219 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 814.7364501953125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.9725, loss_val: nan, pos_over_neg: 325.99212646484375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.9658, loss_val: nan, pos_over_neg: 330.8762512207031 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.9561, loss_val: nan, pos_over_neg: 561.5689086914062 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.9692, loss_val: nan, pos_over_neg: 403.0609436035156 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.9625, loss_val: nan, pos_over_neg: 294.8686828613281 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.9872, loss_val: nan, pos_over_neg: 227.85549926757812 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.964, loss_val: nan, pos_over_neg: 518.2548828125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.9566, loss_val: nan, pos_over_neg: 405.6081848144531 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.9562, loss_val: nan, pos_over_neg: 363.4761962890625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.9658, loss_val: nan, pos_over_neg: 1350.0311279296875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.9688, loss_val: nan, pos_over_neg: 562.5449829101562 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.958, loss_val: nan, pos_over_neg: 527.8424682617188 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.9708, loss_val: nan, pos_over_neg: 170.3203582763672 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.9701, loss_val: nan, pos_over_neg: 375.41253662109375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.9874, loss_val: nan, pos_over_neg: 491.2532958984375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.9755, loss_val: nan, pos_over_neg: 581.0638427734375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.9556, loss_val: nan, pos_over_neg: 420.9991455078125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.9529, loss_val: nan, pos_over_neg: 647.7720947265625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.9637, loss_val: nan, pos_over_neg: 387.8565979003906 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.9637, loss_val: nan, pos_over_neg: 602.4642333984375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.9673, loss_val: nan, pos_over_neg: 273.7647705078125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.958, loss_val: nan, pos_over_neg: 279.2402648925781 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.9689, loss_val: nan, pos_over_neg: 372.6683349609375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.9648, loss_val: nan, pos_over_neg: 492.689208984375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.9625, loss_val: nan, pos_over_neg: 266.03216552734375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.9748, loss_val: nan, pos_over_neg: 380.1661376953125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.9458, loss_val: nan, pos_over_neg: 1245.0985107421875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.9718, loss_val: nan, pos_over_neg: 300.683837890625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.9716, loss_val: nan, pos_over_neg: 400.70025634765625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.9596, loss_val: nan, pos_over_neg: 752.4973754882812 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.9684, loss_val: nan, pos_over_neg: 711.4688110351562 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.9567, loss_val: nan, pos_over_neg: 426.71441650390625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.9568, loss_val: nan, pos_over_neg: 477.8011779785156 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.966, loss_val: nan, pos_over_neg: 788.5437622070312 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.9587, loss_val: nan, pos_over_neg: 684.5816040039062 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.9573, loss_val: nan, pos_over_neg: 577.9237060546875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.9668, loss_val: nan, pos_over_neg: 647.7173461914062 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.953, loss_val: nan, pos_over_neg: 304.7799377441406 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.9541, loss_val: nan, pos_over_neg: 628.6376342773438 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.9603, loss_val: nan, pos_over_neg: 390.98529052734375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.969, loss_val: nan, pos_over_neg: 528.0709838867188 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.9509, loss_val: nan, pos_over_neg: 753.7571411132812 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.955, loss_val: nan, pos_over_neg: 307.4422912597656 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.9487, loss_val: nan, pos_over_neg: 582.3737182617188 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.9486, loss_val: nan, pos_over_neg: 459.1286315917969 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.9598, loss_val: nan, pos_over_neg: 638.9457397460938 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.9551, loss_val: nan, pos_over_neg: 505.7932434082031 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.9547, loss_val: nan, pos_over_neg: 295.4744873046875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.9597, loss_val: nan, pos_over_neg: 559.9427490234375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.9413, loss_val: nan, pos_over_neg: 513.8881225585938 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.9585, loss_val: nan, pos_over_neg: 245.14308166503906 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.9532, loss_val: nan, pos_over_neg: 267.65301513671875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.9457, loss_val: nan, pos_over_neg: 1109.0467529296875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.9476, loss_val: nan, pos_over_neg: 570.7171020507812 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.9495, loss_val: nan, pos_over_neg: 387.25482177734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.9578, loss_val: nan, pos_over_neg: 457.1441650390625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.9574, loss_val: nan, pos_over_neg: 758.5652465820312 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.941, loss_val: nan, pos_over_neg: 506.2863464355469 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.9563, loss_val: nan, pos_over_neg: 212.12261962890625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.9641, loss_val: nan, pos_over_neg: 355.7885437011719 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.9577, loss_val: nan, pos_over_neg: 280.2891540527344 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.9578, loss_val: nan, pos_over_neg: 310.9286804199219 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.957, loss_val: nan, pos_over_neg: 497.00518798828125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.9617, loss_val: nan, pos_over_neg: 345.716064453125 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.9618, loss_val: nan, pos_over_neg: 345.5352478027344 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.9601, loss_val: nan, pos_over_neg: 249.27456665039062 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.9477, loss_val: nan, pos_over_neg: 336.2367858886719 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 302.8459167480469 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.9583, loss_val: nan, pos_over_neg: 310.4255065917969 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.9551, loss_val: nan, pos_over_neg: 482.7864685058594 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.9458, loss_val: nan, pos_over_neg: 526.7140502929688 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.9567, loss_val: nan, pos_over_neg: 787.7354736328125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.9559, loss_val: nan, pos_over_neg: 310.3905944824219 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.9575, loss_val: nan, pos_over_neg: 1130.9930419921875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.9571, loss_val: nan, pos_over_neg: 361.7742004394531 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.96, loss_val: nan, pos_over_neg: 283.0462341308594 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.9517, loss_val: nan, pos_over_neg: 456.88134765625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.9522, loss_val: nan, pos_over_neg: 1395.8590087890625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.953, loss_val: nan, pos_over_neg: 351.56744384765625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.9429, loss_val: nan, pos_over_neg: 404.8465881347656 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.9548, loss_val: nan, pos_over_neg: 834.1912231445312 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.9625, loss_val: nan, pos_over_neg: 600.7078857421875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.9602, loss_val: nan, pos_over_neg: 457.79132080078125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.9602, loss_val: nan, pos_over_neg: 506.59039306640625 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.9595, loss_val: nan, pos_over_neg: 360.3618469238281 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.9494, loss_val: nan, pos_over_neg: 331.8295593261719 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.9409, loss_val: nan, pos_over_neg: 1207.607421875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.9415, loss_val: nan, pos_over_neg: 668.166015625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.957, loss_val: nan, pos_over_neg: 562.8670654296875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.9375, loss_val: nan, pos_over_neg: 455.17596435546875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.9551, loss_val: nan, pos_over_neg: 467.09222412109375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.9456, loss_val: nan, pos_over_neg: 334.7424011230469 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.9492, loss_val: nan, pos_over_neg: 379.9796142578125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.9503, loss_val: nan, pos_over_neg: 385.5716247558594 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.9517, loss_val: nan, pos_over_neg: 669.1920166015625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.9453, loss_val: nan, pos_over_neg: 1418.068359375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.9407, loss_val: nan, pos_over_neg: 793.9945068359375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.9361, loss_val: nan, pos_over_neg: 1021.8470458984375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.9426, loss_val: nan, pos_over_neg: 1859.16357421875 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.9344, loss_val: nan, pos_over_neg: 1273.3258056640625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.9456, loss_val: nan, pos_over_neg: 448.94073486328125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.9551, loss_val: nan, pos_over_neg: 323.3120422363281 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.9425, loss_val: nan, pos_over_neg: 1719.061279296875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.9493, loss_val: nan, pos_over_neg: 1019.7810668945312 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.9537, loss_val: nan, pos_over_neg: 1878.483154296875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.9592, loss_val: nan, pos_over_neg: 5497.77783203125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.9517, loss_val: nan, pos_over_neg: 761.1292114257812 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.951, loss_val: nan, pos_over_neg: 546.5892944335938 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.9468, loss_val: nan, pos_over_neg: 616.3781127929688 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.9368, loss_val: nan, pos_over_neg: 565.6038818359375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.944, loss_val: nan, pos_over_neg: 594.2412109375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.9408, loss_val: nan, pos_over_neg: 696.5479736328125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.9503, loss_val: nan, pos_over_neg: 442.2668151855469 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.9479, loss_val: nan, pos_over_neg: 441.2154235839844 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.9515, loss_val: nan, pos_over_neg: 274.1280212402344 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.9412, loss_val: nan, pos_over_neg: 741.535400390625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.9473, loss_val: nan, pos_over_neg: 570.3773193359375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.957, loss_val: nan, pos_over_neg: 330.7912902832031 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.9449, loss_val: nan, pos_over_neg: 449.1583557128906 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.944, loss_val: nan, pos_over_neg: 272.4512939453125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.9407, loss_val: nan, pos_over_neg: 641.9605712890625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.9323, loss_val: nan, pos_over_neg: 419.16583251953125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.9456, loss_val: nan, pos_over_neg: 472.5428771972656 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.9381, loss_val: nan, pos_over_neg: 751.854248046875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.9537, loss_val: nan, pos_over_neg: 483.9403381347656 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.9454, loss_val: nan, pos_over_neg: 478.2812805175781 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 951.941162109375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.9544, loss_val: nan, pos_over_neg: 819.1432495117188 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.9388, loss_val: nan, pos_over_neg: 530.7918701171875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.9545, loss_val: nan, pos_over_neg: 862.9605712890625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.9516, loss_val: nan, pos_over_neg: 778.3824462890625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.9437, loss_val: nan, pos_over_neg: 455.1096496582031 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.9405, loss_val: nan, pos_over_neg: 1021.1266479492188 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.9427, loss_val: nan, pos_over_neg: 392.7335205078125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.9435, loss_val: nan, pos_over_neg: 367.7323913574219 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.9598, loss_val: nan, pos_over_neg: 347.4850769042969 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.9405, loss_val: nan, pos_over_neg: 417.3964538574219 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.9518, loss_val: nan, pos_over_neg: 433.94805908203125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.9432, loss_val: nan, pos_over_neg: 508.242431640625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.9399, loss_val: nan, pos_over_neg: 914.7380981445312 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.9338, loss_val: nan, pos_over_neg: 567.7254028320312 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.9493, loss_val: nan, pos_over_neg: 283.14971923828125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.9387, loss_val: nan, pos_over_neg: 692.2200317382812 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.9437, loss_val: nan, pos_over_neg: 1078.763427734375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.9494, loss_val: nan, pos_over_neg: 775.925048828125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.939, loss_val: nan, pos_over_neg: 459.43359375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.9339, loss_val: nan, pos_over_neg: 1662.10986328125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.9459, loss_val: nan, pos_over_neg: 567.6834716796875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.9285, loss_val: nan, pos_over_neg: 884.904052734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.9424, loss_val: nan, pos_over_neg: 896.2153930664062 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.9467, loss_val: nan, pos_over_neg: 673.8367919921875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.9423, loss_val: nan, pos_over_neg: 537.9749755859375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.9295, loss_val: nan, pos_over_neg: 876.4833374023438 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.9443, loss_val: nan, pos_over_neg: 500.5957336425781 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 1368.1717529296875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.954, loss_val: nan, pos_over_neg: 363.4567565917969 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 402.57684326171875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.9381, loss_val: nan, pos_over_neg: 835.8206787109375 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.9403, loss_val: nan, pos_over_neg: 471.7430725097656 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.9372, loss_val: nan, pos_over_neg: 413.8622131347656 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.9574, loss_val: nan, pos_over_neg: 340.1268615722656 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.943, loss_val: nan, pos_over_neg: 2398.147216796875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.9427, loss_val: nan, pos_over_neg: 418.0240173339844 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.9425, loss_val: nan, pos_over_neg: 457.5960998535156 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.9399, loss_val: nan, pos_over_neg: 543.4943237304688 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.9458, loss_val: nan, pos_over_neg: 2201.671142578125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.9571, loss_val: nan, pos_over_neg: 357.6556396484375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.9531, loss_val: nan, pos_over_neg: 230.73641967773438 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.9327, loss_val: nan, pos_over_neg: 393.56536865234375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.9374, loss_val: nan, pos_over_neg: 603.5847778320312 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.9289, loss_val: nan, pos_over_neg: 294.6625671386719 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.9372, loss_val: nan, pos_over_neg: 320.4703369140625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.9575, loss_val: nan, pos_over_neg: 340.27728271484375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.9493, loss_val: nan, pos_over_neg: 535.7688598632812 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.9358, loss_val: nan, pos_over_neg: 429.1997375488281 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.9404, loss_val: nan, pos_over_neg: 567.7555541992188 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.9452, loss_val: nan, pos_over_neg: 608.7025756835938 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.9473, loss_val: nan, pos_over_neg: 1347.41162109375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.94, loss_val: nan, pos_over_neg: 730.1399536132812 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.9493, loss_val: nan, pos_over_neg: 894.108154296875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.9368, loss_val: nan, pos_over_neg: 510.74896240234375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.9582, loss_val: nan, pos_over_neg: 270.753173828125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.9456, loss_val: nan, pos_over_neg: 432.15423583984375 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.942, loss_val: nan, pos_over_neg: 374.9728698730469 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.9294, loss_val: nan, pos_over_neg: 938.7119140625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.9289, loss_val: nan, pos_over_neg: 7992.9169921875 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.9295, loss_val: nan, pos_over_neg: 1127.022705078125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.925, loss_val: nan, pos_over_neg: -8376.982421875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.9612, loss_val: nan, pos_over_neg: 781.6016845703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.9401, loss_val: nan, pos_over_neg: 900.3347778320312 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.9426, loss_val: nan, pos_over_neg: 396.3359680175781 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.9398, loss_val: nan, pos_over_neg: 520.4799194335938 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.9526, loss_val: nan, pos_over_neg: 440.4091491699219 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.9263, loss_val: nan, pos_over_neg: 329.45843505859375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.9444, loss_val: nan, pos_over_neg: 639.0092163085938 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.9359, loss_val: nan, pos_over_neg: 1161.7586669921875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.9462, loss_val: nan, pos_over_neg: 569.4191284179688 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.9457, loss_val: nan, pos_over_neg: 234.5037078857422 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.9245, loss_val: nan, pos_over_neg: 678.8472290039062 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.9408, loss_val: nan, pos_over_neg: 363.5134582519531 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 476.5901184082031 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.9396, loss_val: nan, pos_over_neg: 478.2394104003906 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.9505, loss_val: nan, pos_over_neg: 365.8416442871094 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.9366, loss_val: nan, pos_over_neg: 1512.91845703125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.938, loss_val: nan, pos_over_neg: 620.2049560546875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.9382, loss_val: nan, pos_over_neg: 465.924072265625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.9451, loss_val: nan, pos_over_neg: 395.8296813964844 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.942, loss_val: nan, pos_over_neg: 611.0557250976562 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.9384, loss_val: nan, pos_over_neg: 434.66326904296875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.9374, loss_val: nan, pos_over_neg: 424.8110046386719 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.9374, loss_val: nan, pos_over_neg: 532.995849609375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.9337, loss_val: nan, pos_over_neg: 1089.7967529296875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.9368, loss_val: nan, pos_over_neg: 2213.56201171875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.9429, loss_val: nan, pos_over_neg: 777.2316284179688 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.9351, loss_val: nan, pos_over_neg: 708.2366333007812 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.9516, loss_val: nan, pos_over_neg: 505.4147644042969 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.9393, loss_val: nan, pos_over_neg: 854.9719848632812 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.9342, loss_val: nan, pos_over_neg: 310.342529296875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.9378, loss_val: nan, pos_over_neg: 397.71917724609375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.944, loss_val: nan, pos_over_neg: 2046.41357421875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.9427, loss_val: nan, pos_over_neg: 951.3368530273438 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.9278, loss_val: nan, pos_over_neg: 1166.5247802734375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.9329, loss_val: nan, pos_over_neg: 2506.238525390625 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.9389, loss_val: nan, pos_over_neg: 1812.9569091796875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.9371, loss_val: nan, pos_over_neg: 950.2203369140625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.9512, loss_val: nan, pos_over_neg: 550.1015014648438 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.9434, loss_val: nan, pos_over_neg: 325.3045349121094 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.9258, loss_val: nan, pos_over_neg: 1031.2808837890625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.9357, loss_val: nan, pos_over_neg: 786.6578369140625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.9411, loss_val: nan, pos_over_neg: 1049.0975341796875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.9508, loss_val: nan, pos_over_neg: 429.4016418457031 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.9387, loss_val: nan, pos_over_neg: 1069.5794677734375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.9326, loss_val: nan, pos_over_neg: 559.1255493164062 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.9476, loss_val: nan, pos_over_neg: 344.9280090332031 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.9257, loss_val: nan, pos_over_neg: 587.106689453125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.9337, loss_val: nan, pos_over_neg: 372.6478271484375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.9413, loss_val: nan, pos_over_neg: 326.02288818359375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.938, loss_val: nan, pos_over_neg: 635.513671875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.9355, loss_val: nan, pos_over_neg: 414.38055419921875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.9316, loss_val: nan, pos_over_neg: 675.6995849609375 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.9265, loss_val: nan, pos_over_neg: 897.6427001953125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.9364, loss_val: nan, pos_over_neg: 306.1666564941406 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.9251, loss_val: nan, pos_over_neg: 820.5632934570312 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.9392, loss_val: nan, pos_over_neg: 908.427734375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.9447, loss_val: nan, pos_over_neg: 725.060302734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.9354, loss_val: nan, pos_over_neg: 356.1870422363281 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.9318, loss_val: nan, pos_over_neg: 2898.659423828125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.9371, loss_val: nan, pos_over_neg: 489.6125793457031 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.9426, loss_val: nan, pos_over_neg: 350.5506591796875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.9355, loss_val: nan, pos_over_neg: 819.1332397460938 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.9532, loss_val: nan, pos_over_neg: 419.6957702636719 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.9329, loss_val: nan, pos_over_neg: 863.8773193359375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.9372, loss_val: nan, pos_over_neg: 580.7063598632812 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.9266, loss_val: nan, pos_over_neg: 1461.8211669921875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 1524.8953857421875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.9362, loss_val: nan, pos_over_neg: 495.2906188964844 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.9411, loss_val: nan, pos_over_neg: 389.2862854003906 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.935, loss_val: nan, pos_over_neg: 361.9350280761719 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.9282, loss_val: nan, pos_over_neg: 562.1588745117188 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 623.1642456054688 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.9415, loss_val: nan, pos_over_neg: 948.1382446289062 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.9351, loss_val: nan, pos_over_neg: 319.84039306640625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.933, loss_val: nan, pos_over_neg: 780.8867797851562 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.9326, loss_val: nan, pos_over_neg: 743.9932250976562 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.9225, loss_val: nan, pos_over_neg: 490.29931640625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.9444, loss_val: nan, pos_over_neg: 346.3164978027344 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.9339, loss_val: nan, pos_over_neg: 384.31744384765625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.9272, loss_val: nan, pos_over_neg: 897.1698608398438 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.9294, loss_val: nan, pos_over_neg: 655.0762329101562 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.938, loss_val: nan, pos_over_neg: 801.9020385742188 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.9198, loss_val: nan, pos_over_neg: 820.3717041015625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.936, loss_val: nan, pos_over_neg: 675.1707763671875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.9423, loss_val: nan, pos_over_neg: 555.9066772460938 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.9386, loss_val: nan, pos_over_neg: 478.86590576171875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.9364, loss_val: nan, pos_over_neg: 383.6432800292969 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.9372, loss_val: nan, pos_over_neg: 368.208251953125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.9392, loss_val: nan, pos_over_neg: 512.9080810546875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.9246, loss_val: nan, pos_over_neg: 457.1972351074219 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.9393, loss_val: nan, pos_over_neg: 729.4878540039062 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.9479, loss_val: nan, pos_over_neg: 477.44427490234375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.9313, loss_val: nan, pos_over_neg: 1114.987060546875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.9431, loss_val: nan, pos_over_neg: 485.91339111328125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.9291, loss_val: nan, pos_over_neg: 395.8935852050781 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.9268, loss_val: nan, pos_over_neg: 513.986572265625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 479.8262634277344 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.937, loss_val: nan, pos_over_neg: 338.7804870605469 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.9404, loss_val: nan, pos_over_neg: 523.9180297851562 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 1458.919189453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.9186, loss_val: nan, pos_over_neg: 855.93310546875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.9239, loss_val: nan, pos_over_neg: 495.0271301269531 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.9342, loss_val: nan, pos_over_neg: 383.6399230957031 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.9283, loss_val: nan, pos_over_neg: 699.5416870117188 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.9199, loss_val: nan, pos_over_neg: 421.5114440917969 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.9385, loss_val: nan, pos_over_neg: 276.98333740234375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.925, loss_val: nan, pos_over_neg: 431.0152587890625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.9327, loss_val: nan, pos_over_neg: 607.8488159179688 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.9308, loss_val: nan, pos_over_neg: 341.8612365722656 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.9394, loss_val: nan, pos_over_neg: 342.01171875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.9496, loss_val: nan, pos_over_neg: 286.4357604980469 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.9397, loss_val: nan, pos_over_neg: 453.6709289550781 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.9365, loss_val: nan, pos_over_neg: 436.68316650390625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.9283, loss_val: nan, pos_over_neg: 512.641845703125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.909, loss_val: nan, pos_over_neg: 750.504150390625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.9236, loss_val: nan, pos_over_neg: 272.3826599121094 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.923, loss_val: nan, pos_over_neg: 654.3102416992188 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.9307, loss_val: nan, pos_over_neg: 655.2653198242188 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.9301, loss_val: nan, pos_over_neg: 350.788330078125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.9275, loss_val: nan, pos_over_neg: 402.70025634765625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.9347, loss_val: nan, pos_over_neg: 493.63702392578125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.9402, loss_val: nan, pos_over_neg: 352.0485534667969 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.9223, loss_val: nan, pos_over_neg: 899.8087158203125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [20:13<101118:24:24, 1213.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.9285, loss_val: nan, pos_over_neg: 424.8764343261719 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.9314, loss_val: nan, pos_over_neg: 352.0105895996094 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.9261, loss_val: nan, pos_over_neg: 776.2827758789062 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.9262, loss_val: nan, pos_over_neg: 415.7971496582031 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.9469, loss_val: nan, pos_over_neg: 326.228515625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.9199, loss_val: nan, pos_over_neg: 752.5911865234375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.9346, loss_val: nan, pos_over_neg: 308.29833984375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 526.2825927734375 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.9393, loss_val: nan, pos_over_neg: 655.4852905273438 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.9304, loss_val: nan, pos_over_neg: 568.2061157226562 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.9272, loss_val: nan, pos_over_neg: 432.5284729003906 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.931, loss_val: nan, pos_over_neg: 622.9012451171875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.9151, loss_val: nan, pos_over_neg: 867.1334228515625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.9266, loss_val: nan, pos_over_neg: 596.6976928710938 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.9415, loss_val: nan, pos_over_neg: 227.84722900390625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.9356, loss_val: nan, pos_over_neg: 543.7960205078125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.9375, loss_val: nan, pos_over_neg: 414.6020812988281 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.9302, loss_val: nan, pos_over_neg: 403.8240051269531 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.923, loss_val: nan, pos_over_neg: 1930.5277099609375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.9217, loss_val: nan, pos_over_neg: 959.24853515625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.9239, loss_val: nan, pos_over_neg: 1408.3936767578125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.9335, loss_val: nan, pos_over_neg: 6919.19677734375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.9248, loss_val: nan, pos_over_neg: 1237.2860107421875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.9198, loss_val: nan, pos_over_neg: 462.5740966796875 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.9233, loss_val: nan, pos_over_neg: 455.96783447265625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.9315, loss_val: nan, pos_over_neg: 629.80126953125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.9315, loss_val: nan, pos_over_neg: 500.6127014160156 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.9188, loss_val: nan, pos_over_neg: 1074.6651611328125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 717.3128051757812 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.9216, loss_val: nan, pos_over_neg: 791.0789184570312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.9383, loss_val: nan, pos_over_neg: 299.93841552734375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.9201, loss_val: nan, pos_over_neg: 7008.8291015625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.9208, loss_val: nan, pos_over_neg: 755.0277099609375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.9243, loss_val: nan, pos_over_neg: 570.562255859375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.9271, loss_val: nan, pos_over_neg: 731.1220092773438 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.9224, loss_val: nan, pos_over_neg: 954.0985717773438 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.931, loss_val: nan, pos_over_neg: 725.6748657226562 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.9244, loss_val: nan, pos_over_neg: 907.4951171875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.9191, loss_val: nan, pos_over_neg: 2314.73828125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.9333, loss_val: nan, pos_over_neg: 889.0150756835938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.9245, loss_val: nan, pos_over_neg: 609.8812866210938 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.9343, loss_val: nan, pos_over_neg: 566.1915893554688 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.9227, loss_val: nan, pos_over_neg: 1075.980712890625 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.9334, loss_val: nan, pos_over_neg: 493.85296630859375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.9192, loss_val: nan, pos_over_neg: 575.8409423828125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.9236, loss_val: nan, pos_over_neg: 624.1416625976562 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.9161, loss_val: nan, pos_over_neg: 762.7825317382812 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.9196, loss_val: nan, pos_over_neg: 682.1261596679688 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.9195, loss_val: nan, pos_over_neg: 937.0512084960938 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.9157, loss_val: nan, pos_over_neg: 971.3603515625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.9364, loss_val: nan, pos_over_neg: 777.907470703125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.9226, loss_val: nan, pos_over_neg: 1106.5830078125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 840.9954223632812 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.9133, loss_val: nan, pos_over_neg: 655.6151733398438 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.912, loss_val: nan, pos_over_neg: 666.9992065429688 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.9244, loss_val: nan, pos_over_neg: 431.6743469238281 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.9084, loss_val: nan, pos_over_neg: 989.1925048828125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.9387, loss_val: nan, pos_over_neg: 2081.658447265625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.9372, loss_val: nan, pos_over_neg: 463.22802734375 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.9341, loss_val: nan, pos_over_neg: 375.25946044921875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.9217, loss_val: nan, pos_over_neg: 352.8844909667969 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 1249.7337646484375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.9187, loss_val: nan, pos_over_neg: 500.2584228515625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.9121, loss_val: nan, pos_over_neg: 1094.9949951171875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.9095, loss_val: nan, pos_over_neg: 537.9716186523438 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.9183, loss_val: nan, pos_over_neg: 733.4186401367188 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.9226, loss_val: nan, pos_over_neg: 417.273681640625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.9277, loss_val: nan, pos_over_neg: 277.8742370605469 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9224, loss_val: nan, pos_over_neg: 574.578369140625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.9358, loss_val: nan, pos_over_neg: 786.2880249023438 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.9179, loss_val: nan, pos_over_neg: 1512.6676025390625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.921, loss_val: nan, pos_over_neg: 439.541748046875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.9092, loss_val: nan, pos_over_neg: 562.6143188476562 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.9163, loss_val: nan, pos_over_neg: 1337.8682861328125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.9259, loss_val: nan, pos_over_neg: 396.372314453125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.9145, loss_val: nan, pos_over_neg: 412.5483093261719 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.9237, loss_val: nan, pos_over_neg: 513.9580688476562 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.9229, loss_val: nan, pos_over_neg: 471.8913879394531 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.9098, loss_val: nan, pos_over_neg: 445.9011535644531 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.927, loss_val: nan, pos_over_neg: 928.929443359375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 709.7760009765625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.9216, loss_val: nan, pos_over_neg: 415.59063720703125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.9232, loss_val: nan, pos_over_neg: 1518.376220703125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9201, loss_val: nan, pos_over_neg: 758.2110595703125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 490.2065124511719 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.9191, loss_val: nan, pos_over_neg: 394.841796875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.9294, loss_val: nan, pos_over_neg: 452.0814208984375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.9215, loss_val: nan, pos_over_neg: 492.1363525390625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.9296, loss_val: nan, pos_over_neg: 553.1380004882812 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.9168, loss_val: nan, pos_over_neg: 1311.2117919921875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.9228, loss_val: nan, pos_over_neg: 540.048095703125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9138, loss_val: nan, pos_over_neg: 723.7667236328125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.9106, loss_val: nan, pos_over_neg: 4358.7197265625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.932, loss_val: nan, pos_over_neg: 900.8324584960938 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 664.9981689453125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 361.31146240234375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.9226, loss_val: nan, pos_over_neg: 849.870361328125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 624.645751953125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9287, loss_val: nan, pos_over_neg: 890.4398803710938 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.9245, loss_val: nan, pos_over_neg: 800.6766357421875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9281, loss_val: nan, pos_over_neg: 672.4352416992188 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.9194, loss_val: nan, pos_over_neg: 1598.2286376953125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.9213, loss_val: nan, pos_over_neg: 949.953125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.9339, loss_val: nan, pos_over_neg: 768.8717041015625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.9139, loss_val: nan, pos_over_neg: 954.9060668945312 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.9357, loss_val: nan, pos_over_neg: 351.1263122558594 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.9053, loss_val: nan, pos_over_neg: 935.4710083007812 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.9367, loss_val: nan, pos_over_neg: 402.9378662109375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.9165, loss_val: nan, pos_over_neg: 1608.2105712890625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9335, loss_val: nan, pos_over_neg: 723.9801635742188 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.9219, loss_val: nan, pos_over_neg: 1345.3309326171875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.9277, loss_val: nan, pos_over_neg: 660.1790771484375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.9135, loss_val: nan, pos_over_neg: 706.4228515625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.9348, loss_val: nan, pos_over_neg: 378.8246765136719 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.9203, loss_val: nan, pos_over_neg: 795.2124633789062 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 1050.305908203125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.9367, loss_val: nan, pos_over_neg: 781.268798828125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.9213, loss_val: nan, pos_over_neg: 463.8302307128906 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.9127, loss_val: nan, pos_over_neg: 2355.088134765625 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.9202, loss_val: nan, pos_over_neg: 388.83172607421875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.9327, loss_val: nan, pos_over_neg: 329.9823913574219 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.9383, loss_val: nan, pos_over_neg: 599.0728759765625 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.9156, loss_val: nan, pos_over_neg: 755.8533325195312 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 476.5677185058594 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.9188, loss_val: nan, pos_over_neg: 430.1590576171875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 640.1522216796875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.9356, loss_val: nan, pos_over_neg: 421.2621765136719 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.9237, loss_val: nan, pos_over_neg: 276.10382080078125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.9269, loss_val: nan, pos_over_neg: 1163.8341064453125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.9266, loss_val: nan, pos_over_neg: 557.727294921875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.9135, loss_val: nan, pos_over_neg: 581.701416015625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.9228, loss_val: nan, pos_over_neg: 727.439697265625 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 1395.19189453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.9235, loss_val: nan, pos_over_neg: 768.8729248046875 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.9212, loss_val: nan, pos_over_neg: 984.1025390625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.9157, loss_val: nan, pos_over_neg: 623.7294921875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.9209, loss_val: nan, pos_over_neg: 1207.782958984375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.911, loss_val: nan, pos_over_neg: 773.6776733398438 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.9144, loss_val: nan, pos_over_neg: 512.533935546875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.9115, loss_val: nan, pos_over_neg: 652.1782836914062 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.9182, loss_val: nan, pos_over_neg: 891.208984375 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.9244, loss_val: nan, pos_over_neg: 688.7025756835938 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.9126, loss_val: nan, pos_over_neg: 1811.37841796875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.9263, loss_val: nan, pos_over_neg: 804.9833984375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.9293, loss_val: nan, pos_over_neg: 352.3024597167969 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.9157, loss_val: nan, pos_over_neg: 1735.5928955078125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.9392, loss_val: nan, pos_over_neg: 732.0902709960938 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.9144, loss_val: nan, pos_over_neg: 753.0628662109375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.9215, loss_val: nan, pos_over_neg: 2250.4677734375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.9133, loss_val: nan, pos_over_neg: 599.2727661132812 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.9209, loss_val: nan, pos_over_neg: 865.71484375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.9215, loss_val: nan, pos_over_neg: 507.975830078125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.9194, loss_val: nan, pos_over_neg: 743.6475219726562 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 517.0411987304688 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.9108, loss_val: nan, pos_over_neg: 1057.1966552734375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.9235, loss_val: nan, pos_over_neg: 836.147705078125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.919, loss_val: nan, pos_over_neg: 1228.302978515625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 1654.596923828125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.9212, loss_val: nan, pos_over_neg: 675.748291015625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.92, loss_val: nan, pos_over_neg: 569.6160888671875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.9197, loss_val: nan, pos_over_neg: 384.6114501953125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.9049, loss_val: nan, pos_over_neg: 754.8443603515625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 542.3576049804688 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.9274, loss_val: nan, pos_over_neg: 390.20263671875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.9289, loss_val: nan, pos_over_neg: 443.0591125488281 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.9233, loss_val: nan, pos_over_neg: 484.8516845703125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.911, loss_val: nan, pos_over_neg: 481.1258544921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.9059, loss_val: nan, pos_over_neg: 1271.296875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.917, loss_val: nan, pos_over_neg: 778.560546875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.9304, loss_val: nan, pos_over_neg: 413.9942321777344 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.92, loss_val: nan, pos_over_neg: 1629.0887451171875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.9173, loss_val: nan, pos_over_neg: 1765.54296875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.9107, loss_val: nan, pos_over_neg: 794.1809692382812 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.9068, loss_val: nan, pos_over_neg: 564.4993286132812 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.9151, loss_val: nan, pos_over_neg: 396.4543762207031 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.9174, loss_val: nan, pos_over_neg: 425.84893798828125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.9104, loss_val: nan, pos_over_neg: 659.2305297851562 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.9194, loss_val: nan, pos_over_neg: 787.2550048828125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.9136, loss_val: nan, pos_over_neg: 1357.591796875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.9073, loss_val: nan, pos_over_neg: 616.2926635742188 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 498.30126953125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.9039, loss_val: nan, pos_over_neg: -21379.80078125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.9153, loss_val: nan, pos_over_neg: 1367.106689453125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.9227, loss_val: nan, pos_over_neg: 479.3230285644531 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.9144, loss_val: nan, pos_over_neg: 842.1658325195312 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.9322, loss_val: nan, pos_over_neg: 743.0635375976562 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.9228, loss_val: nan, pos_over_neg: 379.64312744140625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.906, loss_val: nan, pos_over_neg: 749.6964111328125 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 324.2972717285156 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.924, loss_val: nan, pos_over_neg: 414.10400390625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.916, loss_val: nan, pos_over_neg: 560.4808349609375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.9179, loss_val: nan, pos_over_neg: 912.3444213867188 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.9142, loss_val: nan, pos_over_neg: 599.1796264648438 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.9079, loss_val: nan, pos_over_neg: 511.2461242675781 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.9168, loss_val: nan, pos_over_neg: 1298.6932373046875 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.9104, loss_val: nan, pos_over_neg: 460.8024597167969 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.9126, loss_val: nan, pos_over_neg: 386.5728454589844 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.9221, loss_val: nan, pos_over_neg: 292.20220947265625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.9223, loss_val: nan, pos_over_neg: 296.7071838378906 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.9104, loss_val: nan, pos_over_neg: 331.0606994628906 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.9114, loss_val: nan, pos_over_neg: 477.9125061035156 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 542.1668090820312 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.9023, loss_val: nan, pos_over_neg: 860.1044311523438 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.9184, loss_val: nan, pos_over_neg: 479.740234375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 723.0365600585938 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.9217, loss_val: nan, pos_over_neg: 660.6371459960938 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.9145, loss_val: nan, pos_over_neg: 661.9706420898438 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.913, loss_val: nan, pos_over_neg: 701.9006958007812 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 9617.4365234375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.9146, loss_val: nan, pos_over_neg: 465.4388732910156 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.9157, loss_val: nan, pos_over_neg: 444.3747863769531 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.9177, loss_val: nan, pos_over_neg: 990.1255493164062 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.9136, loss_val: nan, pos_over_neg: 364.60888671875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.9098, loss_val: nan, pos_over_neg: 867.602294921875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.9122, loss_val: nan, pos_over_neg: 538.0331420898438 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.9102, loss_val: nan, pos_over_neg: 684.4474487304688 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.93, loss_val: nan, pos_over_neg: 1170.2740478515625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 352.5603332519531 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.9169, loss_val: nan, pos_over_neg: 400.8402099609375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.9108, loss_val: nan, pos_over_neg: 862.7478637695312 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.9196, loss_val: nan, pos_over_neg: 7784.5849609375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.9055, loss_val: nan, pos_over_neg: 674.8997192382812 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.9111, loss_val: nan, pos_over_neg: 624.3306884765625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.9206, loss_val: nan, pos_over_neg: 717.5868530273438 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 566.877197265625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 762.1558227539062 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.9225, loss_val: nan, pos_over_neg: 622.4279174804688 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.9058, loss_val: nan, pos_over_neg: 1262.171142578125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.9295, loss_val: nan, pos_over_neg: 1333.4627685546875 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.9055, loss_val: nan, pos_over_neg: 1455.895263671875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.9082, loss_val: nan, pos_over_neg: 1134.2640380859375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.9163, loss_val: nan, pos_over_neg: 380.3961486816406 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.9134, loss_val: nan, pos_over_neg: 2644.598876953125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.9065, loss_val: nan, pos_over_neg: 3574.937744140625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.9249, loss_val: nan, pos_over_neg: 615.5647583007812 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.9059, loss_val: nan, pos_over_neg: 3137.802001953125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.912, loss_val: nan, pos_over_neg: 1774.3443603515625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.9017, loss_val: nan, pos_over_neg: 682.0838012695312 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.9103, loss_val: nan, pos_over_neg: 643.5286865234375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 459.42010498046875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.9076, loss_val: nan, pos_over_neg: 845.272216796875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.9185, loss_val: nan, pos_over_neg: 787.2783813476562 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.9062, loss_val: nan, pos_over_neg: 1822.3203125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.9099, loss_val: nan, pos_over_neg: 699.0394897460938 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.9022, loss_val: nan, pos_over_neg: 2933.888916015625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.9134, loss_val: nan, pos_over_neg: 1440.3134765625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.9095, loss_val: nan, pos_over_neg: 721.4447021484375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.913, loss_val: nan, pos_over_neg: 551.4442749023438 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.9102, loss_val: nan, pos_over_neg: 497.7862548828125 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.9295, loss_val: nan, pos_over_neg: 451.1436767578125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8989, loss_val: nan, pos_over_neg: 695.098876953125 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.9011, loss_val: nan, pos_over_neg: 1554.1876220703125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 496.0312194824219 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.9063, loss_val: nan, pos_over_neg: 465.69927978515625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.911, loss_val: nan, pos_over_neg: 816.39013671875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8924, loss_val: nan, pos_over_neg: 542.8995971679688 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 833.1382446289062 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.907, loss_val: nan, pos_over_neg: 798.5576171875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.9128, loss_val: nan, pos_over_neg: 492.2353515625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.9053, loss_val: nan, pos_over_neg: 727.4207153320312 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.9227, loss_val: nan, pos_over_neg: 1038.9842529296875 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.9105, loss_val: nan, pos_over_neg: 739.5665283203125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.9233, loss_val: nan, pos_over_neg: 764.753662109375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.9248, loss_val: nan, pos_over_neg: 328.1366882324219 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.9119, loss_val: nan, pos_over_neg: 1452.0855712890625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.9207, loss_val: nan, pos_over_neg: 668.6106567382812 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.9137, loss_val: nan, pos_over_neg: 591.0809936523438 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.9022, loss_val: nan, pos_over_neg: 839.2102661132812 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.9196, loss_val: nan, pos_over_neg: 887.6694946289062 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.901, loss_val: nan, pos_over_neg: 608.1176147460938 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.9106, loss_val: nan, pos_over_neg: 392.32537841796875 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.9024, loss_val: nan, pos_over_neg: 1127.42431640625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.9317, loss_val: nan, pos_over_neg: 629.4315185546875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.9239, loss_val: nan, pos_over_neg: 490.0606994628906 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 329.33306884765625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.9038, loss_val: nan, pos_over_neg: 522.8284301757812 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.9139, loss_val: nan, pos_over_neg: 1526.4073486328125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.9183, loss_val: nan, pos_over_neg: 650.666259765625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.913, loss_val: nan, pos_over_neg: 268.42706298828125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.9201, loss_val: nan, pos_over_neg: 223.41079711914062 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.9125, loss_val: nan, pos_over_neg: 401.19134521484375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.9143, loss_val: nan, pos_over_neg: 658.3914794921875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 662.3145751953125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.9042, loss_val: nan, pos_over_neg: 1966.68115234375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.9144, loss_val: nan, pos_over_neg: 703.2575073242188 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.9035, loss_val: nan, pos_over_neg: 1141.5318603515625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8964, loss_val: nan, pos_over_neg: 1220.74169921875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.9189, loss_val: nan, pos_over_neg: 556.2164306640625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.9279, loss_val: nan, pos_over_neg: 298.7792663574219 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.9161, loss_val: nan, pos_over_neg: 478.2953186035156 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.9077, loss_val: nan, pos_over_neg: 630.6995239257812 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.91, loss_val: nan, pos_over_neg: 413.04205322265625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.9113, loss_val: nan, pos_over_neg: 776.33935546875 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.9093, loss_val: nan, pos_over_neg: 1166.9432373046875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.9025, loss_val: nan, pos_over_neg: 1254.9000244140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.9031, loss_val: nan, pos_over_neg: 637.3419799804688 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.9183, loss_val: nan, pos_over_neg: 1366.5257568359375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.9129, loss_val: nan, pos_over_neg: 858.4903564453125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.9145, loss_val: nan, pos_over_neg: 869.4415283203125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.9032, loss_val: nan, pos_over_neg: 646.8131713867188 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.9065, loss_val: nan, pos_over_neg: 241.65255737304688 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.9071, loss_val: nan, pos_over_neg: 402.9285888671875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.9104, loss_val: nan, pos_over_neg: 393.9948425292969 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.9113, loss_val: nan, pos_over_neg: 727.0217895507812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.912, loss_val: nan, pos_over_neg: 737.4534912109375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.9042, loss_val: nan, pos_over_neg: 1032.1085205078125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.9226, loss_val: nan, pos_over_neg: 800.71044921875 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8995, loss_val: nan, pos_over_neg: 2010.1656494140625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.9192, loss_val: nan, pos_over_neg: 810.3557739257812 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.9039, loss_val: nan, pos_over_neg: 975.8497924804688 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.9076, loss_val: nan, pos_over_neg: 415.44879150390625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.9068, loss_val: nan, pos_over_neg: 587.4814453125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.9093, loss_val: nan, pos_over_neg: 1393.5565185546875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.9041, loss_val: nan, pos_over_neg: 777.955322265625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.9114, loss_val: nan, pos_over_neg: 477.1449279785156 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.9018, loss_val: nan, pos_over_neg: 1823.0047607421875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.905, loss_val: nan, pos_over_neg: 403.2022705078125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.9003, loss_val: nan, pos_over_neg: 429.3100891113281 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.9012, loss_val: nan, pos_over_neg: 848.8464965820312 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.9051, loss_val: nan, pos_over_neg: 2048.958984375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.9081, loss_val: nan, pos_over_neg: 594.8534545898438 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 958.056396484375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.907, loss_val: nan, pos_over_neg: 787.8374633789062 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.902, loss_val: nan, pos_over_neg: 761.110107421875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.9159, loss_val: nan, pos_over_neg: 906.7982788085938 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 605.7329711914062 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.9146, loss_val: nan, pos_over_neg: 368.67877197265625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.9099, loss_val: nan, pos_over_neg: 698.219482421875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 3978.905517578125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.9124, loss_val: nan, pos_over_neg: 493.6557312011719 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.9166, loss_val: nan, pos_over_neg: 397.5929870605469 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.9033, loss_val: nan, pos_over_neg: 563.4589233398438 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 1265.3052978515625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.9151, loss_val: nan, pos_over_neg: 464.8829040527344 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 345.4703674316406 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.9083, loss_val: nan, pos_over_neg: 435.4240417480469 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.9122, loss_val: nan, pos_over_neg: 366.90850830078125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.9008, loss_val: nan, pos_over_neg: 574.5353393554688 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8993, loss_val: nan, pos_over_neg: 995.12109375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.9059, loss_val: nan, pos_over_neg: 746.8809814453125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.9056, loss_val: nan, pos_over_neg: 1151.8966064453125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.9056, loss_val: nan, pos_over_neg: 686.0681762695312 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.897, loss_val: nan, pos_over_neg: 529.8804321289062 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.9089, loss_val: nan, pos_over_neg: 700.13134765625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.9065, loss_val: nan, pos_over_neg: 1335.20556640625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.896, loss_val: nan, pos_over_neg: 571.6119995117188 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 981.7589721679688 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.9044, loss_val: nan, pos_over_neg: 3262.0791015625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.9116, loss_val: nan, pos_over_neg: 493.29132080078125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 560.9379272460938 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.9115, loss_val: nan, pos_over_neg: 345.8763122558594 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8997, loss_val: nan, pos_over_neg: 665.7710571289062 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.9089, loss_val: nan, pos_over_neg: 859.0939331054688 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.9072, loss_val: nan, pos_over_neg: 374.172119140625 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.9115, loss_val: nan, pos_over_neg: 935.3250732421875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 1020.2460327148438 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.9027, loss_val: nan, pos_over_neg: 802.4857788085938 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8998, loss_val: nan, pos_over_neg: 682.4148559570312 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.9086, loss_val: nan, pos_over_neg: 609.0037841796875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.9107, loss_val: nan, pos_over_neg: 417.14764404296875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 471.5537109375 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.9048, loss_val: nan, pos_over_neg: 457.95379638671875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.918, loss_val: nan, pos_over_neg: 809.516845703125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.9107, loss_val: nan, pos_over_neg: 512.275390625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.9125, loss_val: nan, pos_over_neg: 786.7392578125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.9062, loss_val: nan, pos_over_neg: 2769.8994140625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 1536.570556640625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.9165, loss_val: nan, pos_over_neg: 482.8072814941406 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.9176, loss_val: nan, pos_over_neg: 647.1224365234375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8978, loss_val: nan, pos_over_neg: 752.712890625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.9089, loss_val: nan, pos_over_neg: 833.7823486328125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.9193, loss_val: nan, pos_over_neg: 969.054931640625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.9165, loss_val: nan, pos_over_neg: 575.2570190429688 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.914, loss_val: nan, pos_over_neg: 621.2944946289062 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.9195, loss_val: nan, pos_over_neg: 568.9425659179688 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8989, loss_val: nan, pos_over_neg: 574.9514770507812 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.911, loss_val: nan, pos_over_neg: 432.90301513671875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.9067, loss_val: nan, pos_over_neg: 629.7383422851562 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.903, loss_val: nan, pos_over_neg: 610.7008666992188 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.9282, loss_val: nan, pos_over_neg: 282.1377258300781 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 466.5179138183594 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.9143, loss_val: nan, pos_over_neg: 681.2111206054688 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.9125, loss_val: nan, pos_over_neg: 659.8326416015625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 514.3877563476562 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.9096, loss_val: nan, pos_over_neg: 1000.3394165039062 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.9171, loss_val: nan, pos_over_neg: 772.6347045898438 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.9109, loss_val: nan, pos_over_neg: 726.9435424804688 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8974, loss_val: nan, pos_over_neg: 5004.4296875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.9024, loss_val: nan, pos_over_neg: 1154.6474609375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.9003, loss_val: nan, pos_over_neg: 695.6729125976562 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 470.05242919921875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.9082, loss_val: nan, pos_over_neg: 430.40777587890625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.9115, loss_val: nan, pos_over_neg: 829.8978881835938 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.9007, loss_val: nan, pos_over_neg: 434.4809265136719 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.9152, loss_val: nan, pos_over_neg: 741.4396362304688 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.9074, loss_val: nan, pos_over_neg: 650.0127563476562 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.9036, loss_val: nan, pos_over_neg: 691.923828125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.9213, loss_val: nan, pos_over_neg: 395.1574401855469 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 662.97265625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.9184, loss_val: nan, pos_over_neg: 428.87506103515625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 562.1824951171875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.909, loss_val: nan, pos_over_neg: 367.92706298828125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.9193, loss_val: nan, pos_over_neg: 434.976318359375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.9164, loss_val: nan, pos_over_neg: 473.7510681152344 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.9034, loss_val: nan, pos_over_neg: 814.7197875976562 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.9079, loss_val: nan, pos_over_neg: 392.97052001953125 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.912, loss_val: nan, pos_over_neg: 465.2379150390625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8987, loss_val: nan, pos_over_neg: 762.6751708984375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.9031, loss_val: nan, pos_over_neg: 604.1585083007812 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8954, loss_val: nan, pos_over_neg: 858.7197875976562 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.913, loss_val: nan, pos_over_neg: 568.0438232421875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8984, loss_val: nan, pos_over_neg: 504.9197692871094 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.908, loss_val: nan, pos_over_neg: 397.5751037597656 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.9058, loss_val: nan, pos_over_neg: 570.1532592773438 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.9031, loss_val: nan, pos_over_neg: 4078.823486328125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8881, loss_val: nan, pos_over_neg: 481.94403076171875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.9027, loss_val: nan, pos_over_neg: 1105.565673828125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.9166, loss_val: nan, pos_over_neg: 633.3406372070312 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.9055, loss_val: nan, pos_over_neg: 1147.211181640625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8984, loss_val: nan, pos_over_neg: 661.660888671875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.909, loss_val: nan, pos_over_neg: 684.2202758789062 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.896, loss_val: nan, pos_over_neg: 688.556640625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8986, loss_val: nan, pos_over_neg: 537.49560546875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 1045.36181640625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.9011, loss_val: nan, pos_over_neg: 771.0715942382812 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.902, loss_val: nan, pos_over_neg: 1361.0682373046875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.9081, loss_val: nan, pos_over_neg: 392.0140380859375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.9025, loss_val: nan, pos_over_neg: 553.1638793945312 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.9003, loss_val: nan, pos_over_neg: 763.1806640625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 2151.592529296875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8991, loss_val: nan, pos_over_neg: 2213.877685546875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 692.33251953125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 1471.2442626953125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.9058, loss_val: nan, pos_over_neg: 710.635986328125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8976, loss_val: nan, pos_over_neg: 706.8296508789062 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.9052, loss_val: nan, pos_over_neg: 393.6554870605469 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.9015, loss_val: nan, pos_over_neg: 780.9771728515625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8939, loss_val: nan, pos_over_neg: 403.5781555175781 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.901, loss_val: nan, pos_over_neg: 1046.410400390625 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8888, loss_val: nan, pos_over_neg: 21493.009765625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8916, loss_val: nan, pos_over_neg: 3659.58837890625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 560.8214111328125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8957, loss_val: nan, pos_over_neg: 771.736572265625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8933, loss_val: nan, pos_over_neg: 411.20599365234375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 622.221435546875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.888, loss_val: nan, pos_over_neg: 550.52001953125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.9027, loss_val: nan, pos_over_neg: 490.9984436035156 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 754.7598266601562 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8993, loss_val: nan, pos_over_neg: 719.0755004882812 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 827.99560546875 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.908, loss_val: nan, pos_over_neg: 621.0225830078125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.908, loss_val: nan, pos_over_neg: 592.27197265625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.908, loss_val: nan, pos_over_neg: 625.6460571289062 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8983, loss_val: nan, pos_over_neg: 822.883056640625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.91, loss_val: nan, pos_over_neg: 494.0376892089844 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 547.7926635742188 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.9089, loss_val: nan, pos_over_neg: 530.2161865234375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.9067, loss_val: nan, pos_over_neg: 492.6903076171875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.9054, loss_val: nan, pos_over_neg: 627.9617309570312 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 440.0302429199219 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.904, loss_val: nan, pos_over_neg: 545.0814819335938 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.902, loss_val: nan, pos_over_neg: 800.7645263671875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.9113, loss_val: nan, pos_over_neg: 1273.47705078125 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.9028, loss_val: nan, pos_over_neg: 1090.5050048828125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.9076, loss_val: nan, pos_over_neg: 388.7165832519531 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8986, loss_val: nan, pos_over_neg: 636.7608642578125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8928, loss_val: nan, pos_over_neg: 754.9019775390625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8893, loss_val: nan, pos_over_neg: 761.05419921875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.9038, loss_val: nan, pos_over_neg: 657.5098876953125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.9, loss_val: nan, pos_over_neg: 1944.917724609375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8989, loss_val: nan, pos_over_neg: 1154.460693359375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.9167, loss_val: nan, pos_over_neg: 681.1680908203125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.9031, loss_val: nan, pos_over_neg: 636.1129150390625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.895, loss_val: nan, pos_over_neg: 1161.7374267578125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 1227.8046875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.9052, loss_val: nan, pos_over_neg: 688.2974243164062 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.9034, loss_val: nan, pos_over_neg: 660.9989013671875 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8983, loss_val: nan, pos_over_neg: 475.2289123535156 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.9044, loss_val: nan, pos_over_neg: 789.9968872070312 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 1384.629638671875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.9071, loss_val: nan, pos_over_neg: 650.5303955078125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8884, loss_val: nan, pos_over_neg: 664.5061645507812 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 818.7518310546875 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.9027, loss_val: nan, pos_over_neg: 595.9400634765625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.9028, loss_val: nan, pos_over_neg: 618.3487548828125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.9153, loss_val: nan, pos_over_neg: 707.2310180664062 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8944, loss_val: nan, pos_over_neg: 1508.120361328125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.9073, loss_val: nan, pos_over_neg: 840.0509033203125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.9027, loss_val: nan, pos_over_neg: 577.3344116210938 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.8952, loss_val: nan, pos_over_neg: 550.4493408203125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 1079.1204833984375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.9005, loss_val: nan, pos_over_neg: 1255.5460205078125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.9075, loss_val: nan, pos_over_neg: 531.0729370117188 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 1350.103759765625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 579.6641845703125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.9261, loss_val: nan, pos_over_neg: 361.50469970703125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 675.3211669921875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8969, loss_val: nan, pos_over_neg: 1848.1441650390625 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.9016, loss_val: nan, pos_over_neg: 878.8621826171875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.9025, loss_val: nan, pos_over_neg: 1706.0205078125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.9112, loss_val: nan, pos_over_neg: 497.0738220214844 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8984, loss_val: nan, pos_over_neg: 444.4118347167969 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 560.8355712890625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 1329.5399169921875 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.9007, loss_val: nan, pos_over_neg: 1275.892333984375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.892, loss_val: nan, pos_over_neg: 620.2474975585938 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 959.1121826171875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.9069, loss_val: nan, pos_over_neg: 740.6856689453125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.9039, loss_val: nan, pos_over_neg: 1831.0897216796875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.9036, loss_val: nan, pos_over_neg: 574.9491577148438 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.9082, loss_val: nan, pos_over_neg: 411.7864990234375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8933, loss_val: nan, pos_over_neg: 807.741943359375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.9015, loss_val: nan, pos_over_neg: 475.49798583984375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 551.6948852539062 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 802.6005859375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8988, loss_val: nan, pos_over_neg: 1399.3428955078125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 710.7921142578125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.9018, loss_val: nan, pos_over_neg: 567.6671752929688 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8944, loss_val: nan, pos_over_neg: 580.4749755859375 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 1062.8450927734375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.9095, loss_val: nan, pos_over_neg: 830.7635498046875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8931, loss_val: nan, pos_over_neg: 952.5997924804688 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.9016, loss_val: nan, pos_over_neg: 794.0310668945312 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.9008, loss_val: nan, pos_over_neg: 987.2880249023438 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.892, loss_val: nan, pos_over_neg: 956.2935180664062 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8995, loss_val: nan, pos_over_neg: 549.2769775390625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8923, loss_val: nan, pos_over_neg: 594.0468139648438 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 935.8734130859375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.9006, loss_val: nan, pos_over_neg: 564.3926391601562 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 923.874267578125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.9023, loss_val: nan, pos_over_neg: 621.8273315429688 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 604.8584594726562 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.9016, loss_val: nan, pos_over_neg: 728.1052856445312 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8983, loss_val: nan, pos_over_neg: 3730.660888671875 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8993, loss_val: nan, pos_over_neg: 740.9982299804688 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.906, loss_val: nan, pos_over_neg: 976.6036987304688 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 756.50830078125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 2585.237548828125 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.9051, loss_val: nan, pos_over_neg: 773.9024047851562 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.9054, loss_val: nan, pos_over_neg: 562.5455322265625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 943.4089965820312 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.9011, loss_val: nan, pos_over_neg: 707.5138549804688 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.9015, loss_val: nan, pos_over_neg: 2837.57177734375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 1342.550048828125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8939, loss_val: nan, pos_over_neg: 517.4547729492188 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.9077, loss_val: nan, pos_over_neg: 1143.37158203125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.9044, loss_val: nan, pos_over_neg: 635.1952514648438 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8894, loss_val: nan, pos_over_neg: 797.32080078125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 629.2852172851562 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.9032, loss_val: nan, pos_over_neg: 737.16845703125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8975, loss_val: nan, pos_over_neg: 822.811279296875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.9062, loss_val: nan, pos_over_neg: 480.4354248046875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8913, loss_val: nan, pos_over_neg: 561.7122802734375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.9045, loss_val: nan, pos_over_neg: 605.962890625 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 537.5969848632812 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8974, loss_val: nan, pos_over_neg: 1395.8603515625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 414.1134033203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.9017, loss_val: nan, pos_over_neg: 322.6884765625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.905, loss_val: nan, pos_over_neg: 663.9384765625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.9143, loss_val: nan, pos_over_neg: 502.47259521484375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.9096, loss_val: nan, pos_over_neg: 349.3450927734375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8923, loss_val: nan, pos_over_neg: 301.4650573730469 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8914, loss_val: nan, pos_over_neg: 569.7728881835938 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8914, loss_val: nan, pos_over_neg: 437.3009948730469 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.897, loss_val: nan, pos_over_neg: 436.54840087890625 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.9091, loss_val: nan, pos_over_neg: 421.0770263671875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8947, loss_val: nan, pos_over_neg: 775.7752685546875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8969, loss_val: nan, pos_over_neg: 554.0643920898438 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8958, loss_val: nan, pos_over_neg: 578.9200439453125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.893, loss_val: nan, pos_over_neg: 534.5310668945312 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 595.7489013671875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.9045, loss_val: nan, pos_over_neg: 1428.1361083984375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.899, loss_val: nan, pos_over_neg: 682.9290161132812 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.9062, loss_val: nan, pos_over_neg: 866.0834350585938 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.889, loss_val: nan, pos_over_neg: 550.3146362304688 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.904, loss_val: nan, pos_over_neg: 452.232177734375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8927, loss_val: nan, pos_over_neg: 1530.0240478515625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8969, loss_val: nan, pos_over_neg: 731.9275512695312 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8968, loss_val: nan, pos_over_neg: 929.6849365234375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8928, loss_val: nan, pos_over_neg: 702.6358642578125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8868, loss_val: nan, pos_over_neg: 1001.209716796875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8893, loss_val: nan, pos_over_neg: 832.9862670898438 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8869, loss_val: nan, pos_over_neg: 1001.83447265625 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 329.9217834472656 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.9024, loss_val: nan, pos_over_neg: 461.45184326171875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 612.1488037109375 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.888, loss_val: nan, pos_over_neg: 502.6328125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8864, loss_val: nan, pos_over_neg: 391.0682067871094 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 2373.722900390625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.9057, loss_val: nan, pos_over_neg: 1025.6309814453125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 715.3253173828125 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.9009, loss_val: nan, pos_over_neg: 1197.2554931640625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8784, loss_val: nan, pos_over_neg: 646.4188232421875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8974, loss_val: nan, pos_over_neg: 985.7322998046875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 974.3424072265625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 508.6701965332031 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8965, loss_val: nan, pos_over_neg: 520.28271484375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8893, loss_val: nan, pos_over_neg: 703.9381103515625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.9019, loss_val: nan, pos_over_neg: 549.0318603515625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 286.37652587890625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 485.8106689453125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.9017, loss_val: nan, pos_over_neg: 1104.1549072265625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8916, loss_val: nan, pos_over_neg: 870.9422607421875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.906, loss_val: nan, pos_over_neg: 382.1654052734375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8965, loss_val: nan, pos_over_neg: 616.4981689453125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 952.88525390625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.9006, loss_val: nan, pos_over_neg: 776.9671630859375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8997, loss_val: nan, pos_over_neg: 1392.853759765625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.9011, loss_val: nan, pos_over_neg: 2611.2265625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.9073, loss_val: nan, pos_over_neg: 476.062255859375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.9068, loss_val: nan, pos_over_neg: 413.7775573730469 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8945, loss_val: nan, pos_over_neg: 1291.8350830078125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8923, loss_val: nan, pos_over_neg: 2266.0126953125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8879, loss_val: nan, pos_over_neg: 592.1697998046875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.9033, loss_val: nan, pos_over_neg: 633.9154663085938 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8883, loss_val: nan, pos_over_neg: 719.118408203125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 1544.2607421875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 627.025146484375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 487.36871337890625 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8795, loss_val: nan, pos_over_neg: 1300.2442626953125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 963.3120727539062 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8921, loss_val: nan, pos_over_neg: 600.5736083984375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8897, loss_val: nan, pos_over_neg: 2265.820556640625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.9047, loss_val: nan, pos_over_neg: 834.1187133789062 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8912, loss_val: nan, pos_over_neg: 891.36328125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 1413.1722412109375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8935, loss_val: nan, pos_over_neg: 1332.1551513671875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.905, loss_val: nan, pos_over_neg: 509.89581298828125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8906, loss_val: nan, pos_over_neg: 748.930419921875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.9127, loss_val: nan, pos_over_neg: 612.962890625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 815.6377563476562 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8931, loss_val: nan, pos_over_neg: 462.8199768066406 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 780.31787109375 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.9019, loss_val: nan, pos_over_neg: 1031.4161376953125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8926, loss_val: nan, pos_over_neg: 802.5473022460938 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 620.5275268554688 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 565.3599853515625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8972, loss_val: nan, pos_over_neg: 991.09619140625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8877, loss_val: nan, pos_over_neg: 455.34185791015625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8936, loss_val: nan, pos_over_neg: 912.9921264648438 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.886, loss_val: nan, pos_over_neg: 1123.0775146484375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 870.2911987304688 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.896, loss_val: nan, pos_over_neg: 656.4837646484375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8953, loss_val: nan, pos_over_neg: 515.6616821289062 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 1053.904541015625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8948, loss_val: nan, pos_over_neg: 441.13873291015625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8874, loss_val: nan, pos_over_neg: 659.2194213867188 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8851, loss_val: nan, pos_over_neg: 1470.7137451171875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 11085.4326171875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8991, loss_val: nan, pos_over_neg: 630.7026977539062 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8895, loss_val: nan, pos_over_neg: 664.1300659179688 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 2087.811767578125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8947, loss_val: nan, pos_over_neg: 1291.99267578125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8957, loss_val: nan, pos_over_neg: 659.3645629882812 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8872, loss_val: nan, pos_over_neg: 755.8370971679688 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8966, loss_val: nan, pos_over_neg: 792.8466796875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 1076.447265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8988, loss_val: nan, pos_over_neg: 1704.0614013671875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8951, loss_val: nan, pos_over_neg: 466.72064208984375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8971, loss_val: nan, pos_over_neg: 1666.85498046875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8855, loss_val: nan, pos_over_neg: 993.874755859375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.893, loss_val: nan, pos_over_neg: 2736.318359375 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8763, loss_val: nan, pos_over_neg: 765.555419921875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.9054, loss_val: nan, pos_over_neg: 784.4601440429688 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 1929.1116943359375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.897, loss_val: nan, pos_over_neg: 741.7984008789062 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 582.343505859375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8921, loss_val: nan, pos_over_neg: 835.2476196289062 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8886, loss_val: nan, pos_over_neg: 838.6217041015625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.9092, loss_val: nan, pos_over_neg: 419.74273681640625 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8984, loss_val: nan, pos_over_neg: 576.19482421875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8946, loss_val: nan, pos_over_neg: 727.5205078125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 1119.1220703125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8903, loss_val: nan, pos_over_neg: 477.547607421875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8946, loss_val: nan, pos_over_neg: 541.6185302734375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8917, loss_val: nan, pos_over_neg: 1935.1448974609375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 796.6058959960938 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.9018, loss_val: nan, pos_over_neg: 699.5413818359375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8892, loss_val: nan, pos_over_neg: 748.1715087890625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8968, loss_val: nan, pos_over_neg: 976.8486328125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8893, loss_val: nan, pos_over_neg: 944.2325439453125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8949, loss_val: nan, pos_over_neg: 604.9060668945312 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.894, loss_val: nan, pos_over_neg: 793.8272705078125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.9012, loss_val: nan, pos_over_neg: 813.1654663085938 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8878, loss_val: nan, pos_over_neg: 1210.222412109375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.9091, loss_val: nan, pos_over_neg: 550.3704223632812 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8966, loss_val: nan, pos_over_neg: 2092.582763671875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 1040.8548583984375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.9052, loss_val: nan, pos_over_neg: 741.156005859375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8897, loss_val: nan, pos_over_neg: 479.3567810058594 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8905, loss_val: nan, pos_over_neg: 474.69879150390625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.9007, loss_val: nan, pos_over_neg: 958.5037841796875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.892, loss_val: nan, pos_over_neg: 1362.715087890625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 583.0355834960938 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8956, loss_val: nan, pos_over_neg: 847.3215942382812 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [40:27<101163:55:03, 1213.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 591.1575927734375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8843, loss_val: nan, pos_over_neg: 1207.9703369140625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 475.2821044921875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 1310.626708984375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8881, loss_val: nan, pos_over_neg: 770.9442749023438 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8885, loss_val: nan, pos_over_neg: 704.9644775390625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8916, loss_val: nan, pos_over_neg: 1115.5980224609375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8861, loss_val: nan, pos_over_neg: 3196.9541015625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8924, loss_val: nan, pos_over_neg: 336.06768798828125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8951, loss_val: nan, pos_over_neg: 353.0799865722656 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 55759.3125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8842, loss_val: nan, pos_over_neg: 851.9600219726562 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8975, loss_val: nan, pos_over_neg: 475.2629699707031 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8989, loss_val: nan, pos_over_neg: 598.2581176757812 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 1618.2608642578125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8985, loss_val: nan, pos_over_neg: 1241.736083984375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8832, loss_val: nan, pos_over_neg: 1295.0152587890625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8846, loss_val: nan, pos_over_neg: 1520.8482666015625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 451.3163757324219 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 472.5147399902344 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8894, loss_val: nan, pos_over_neg: 558.68505859375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8956, loss_val: nan, pos_over_neg: 830.3179931640625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 585.4564208984375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 474.7607727050781 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 1608.704833984375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 636.7130737304688 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.9006, loss_val: nan, pos_over_neg: 323.8226013183594 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 337.9325866699219 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 620.9357299804688 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.9012, loss_val: nan, pos_over_neg: 844.6873168945312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 704.6504516601562 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 465.11480712890625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 1559.2720947265625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8803, loss_val: nan, pos_over_neg: 2396.36962890625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.883, loss_val: nan, pos_over_neg: 1471.15869140625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8903, loss_val: nan, pos_over_neg: 928.5452880859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 945.475830078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 1429.3367919921875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8823, loss_val: nan, pos_over_neg: 2916.924072265625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8803, loss_val: nan, pos_over_neg: 4402.42724609375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8947, loss_val: nan, pos_over_neg: 1465.154296875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8853, loss_val: nan, pos_over_neg: 675.8198852539062 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8992, loss_val: nan, pos_over_neg: 815.7112426757812 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.893, loss_val: nan, pos_over_neg: 952.0581665039062 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8853, loss_val: nan, pos_over_neg: 624.8928833007812 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8908, loss_val: nan, pos_over_neg: 461.6307067871094 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8879, loss_val: nan, pos_over_neg: 674.3177490234375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8971, loss_val: nan, pos_over_neg: 798.6942138671875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 420.1968994140625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 715.2984008789062 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8944, loss_val: nan, pos_over_neg: 520.607421875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8966, loss_val: nan, pos_over_neg: 655.3172607421875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8948, loss_val: nan, pos_over_neg: 528.5048828125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8869, loss_val: nan, pos_over_neg: 978.0487060546875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8912, loss_val: nan, pos_over_neg: 1665.13623046875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.888, loss_val: nan, pos_over_neg: 2728.495361328125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8978, loss_val: nan, pos_over_neg: 531.068603515625 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 807.1033325195312 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8856, loss_val: nan, pos_over_neg: 587.8316040039062 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 720.32568359375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 496.4787902832031 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8805, loss_val: nan, pos_over_neg: 563.3102416992188 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8897, loss_val: nan, pos_over_neg: 732.419677734375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8875, loss_val: nan, pos_over_neg: 1215.0662841796875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 2739.145751953125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8823, loss_val: nan, pos_over_neg: 5976.52099609375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8848, loss_val: nan, pos_over_neg: 858.8370971679688 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 1476.4544677734375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9006, loss_val: nan, pos_over_neg: 594.7188110351562 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.895, loss_val: nan, pos_over_neg: 7124.28515625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8927, loss_val: nan, pos_over_neg: 825.0925903320312 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 1670.9769287109375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 711.3392944335938 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 803.8824462890625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 4172.52392578125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8852, loss_val: nan, pos_over_neg: 2443.054931640625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8855, loss_val: nan, pos_over_neg: 437.02423095703125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 762.449462890625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8874, loss_val: nan, pos_over_neg: 1200.1031494140625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8943, loss_val: nan, pos_over_neg: 522.9215087890625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8948, loss_val: nan, pos_over_neg: 1256.3338623046875 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8922, loss_val: nan, pos_over_neg: 378.3174743652344 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8946, loss_val: nan, pos_over_neg: 558.784423828125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9024, loss_val: nan, pos_over_neg: 555.43603515625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.889, loss_val: nan, pos_over_neg: 339.09759521484375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 442.0085144042969 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.89, loss_val: nan, pos_over_neg: 875.3407592773438 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 443.3166198730469 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 535.6602172851562 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8817, loss_val: nan, pos_over_neg: 681.1456298828125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8928, loss_val: nan, pos_over_neg: 547.0733642578125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 542.0989990234375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8921, loss_val: nan, pos_over_neg: 542.3333740234375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.9002, loss_val: nan, pos_over_neg: 578.4869384765625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8956, loss_val: nan, pos_over_neg: 329.2033386230469 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8966, loss_val: nan, pos_over_neg: 349.6807556152344 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.905, loss_val: nan, pos_over_neg: 555.0768432617188 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8955, loss_val: nan, pos_over_neg: 421.1217041015625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 563.5699462890625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8968, loss_val: nan, pos_over_neg: 789.45361328125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9089, loss_val: nan, pos_over_neg: 339.1805419921875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 1104.4564208984375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 584.7283325195312 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 815.6471557617188 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 2073.382080078125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8854, loss_val: nan, pos_over_neg: 1819.400146484375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 1028.5213623046875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 709.6487426757812 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8869, loss_val: nan, pos_over_neg: 877.2196044921875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9046, loss_val: nan, pos_over_neg: 1566.4302978515625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 1842.2933349609375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8727, loss_val: nan, pos_over_neg: 921.902587890625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8877, loss_val: nan, pos_over_neg: 362.0251770019531 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8914, loss_val: nan, pos_over_neg: 511.5682678222656 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8886, loss_val: nan, pos_over_neg: 1028.40576171875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.899, loss_val: nan, pos_over_neg: 515.072021484375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8891, loss_val: nan, pos_over_neg: 355.3853454589844 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8881, loss_val: nan, pos_over_neg: 906.0855712890625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8986, loss_val: nan, pos_over_neg: 1481.0994873046875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 653.751708984375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 1109.119873046875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 1175.028564453125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8953, loss_val: nan, pos_over_neg: 459.1233215332031 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8836, loss_val: nan, pos_over_neg: 1304.0166015625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 1404.2506103515625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.89, loss_val: nan, pos_over_neg: 632.8764038085938 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 413.6739807128906 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.9104, loss_val: nan, pos_over_neg: 641.0140380859375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8892, loss_val: nan, pos_over_neg: 633.5215454101562 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.894, loss_val: nan, pos_over_neg: 719.3646240234375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8878, loss_val: nan, pos_over_neg: 368.4507141113281 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8969, loss_val: nan, pos_over_neg: 742.2710571289062 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8892, loss_val: nan, pos_over_neg: 1428.385498046875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.9019, loss_val: nan, pos_over_neg: 544.0570678710938 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.889, loss_val: nan, pos_over_neg: 624.3466186523438 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8991, loss_val: nan, pos_over_neg: 437.43487548828125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8876, loss_val: nan, pos_over_neg: 1764.5079345703125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 694.8700561523438 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.9021, loss_val: nan, pos_over_neg: 533.0789794921875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 477.0314636230469 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8879, loss_val: nan, pos_over_neg: 620.751953125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 513.7247314453125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 1693.5361328125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8903, loss_val: nan, pos_over_neg: 545.6734008789062 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 915.9683837890625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8886, loss_val: nan, pos_over_neg: 492.153564453125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 787.2374267578125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.889, loss_val: nan, pos_over_neg: 667.1587524414062 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 545.3497314453125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8856, loss_val: nan, pos_over_neg: 335.5335998535156 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8791, loss_val: nan, pos_over_neg: 720.1300659179688 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 684.4397583007812 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8926, loss_val: nan, pos_over_neg: 984.2188110351562 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8766, loss_val: nan, pos_over_neg: 766.6302490234375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 350.1231689453125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8946, loss_val: nan, pos_over_neg: 444.7570495605469 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8999, loss_val: nan, pos_over_neg: 672.5341796875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8855, loss_val: nan, pos_over_neg: 923.5261840820312 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 829.9495239257812 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 1262.412109375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8883, loss_val: nan, pos_over_neg: 791.7837524414062 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8809, loss_val: nan, pos_over_neg: 420.6230773925781 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 656.8327026367188 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8919, loss_val: nan, pos_over_neg: 516.2469482421875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 503.17608642578125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 754.8318481445312 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 634.169921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.898, loss_val: nan, pos_over_neg: 749.1634521484375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 1149.7928466796875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.877, loss_val: nan, pos_over_neg: 1152.0438232421875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8841, loss_val: nan, pos_over_neg: 810.3162841796875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 694.2652587890625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 779.9262084960938 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8995, loss_val: nan, pos_over_neg: 645.9859008789062 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8843, loss_val: nan, pos_over_neg: 521.6163940429688 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 681.1552734375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 1350.8646240234375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8894, loss_val: nan, pos_over_neg: 517.0556640625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8875, loss_val: nan, pos_over_neg: 961.8121948242188 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8973, loss_val: nan, pos_over_neg: 459.23931884765625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 626.6348266601562 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8939, loss_val: nan, pos_over_neg: 837.824462890625 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8902, loss_val: nan, pos_over_neg: 1297.8077392578125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 1071.0736083984375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8954, loss_val: nan, pos_over_neg: 1163.797607421875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8905, loss_val: nan, pos_over_neg: 1780.9500732421875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8969, loss_val: nan, pos_over_neg: 3609.92822265625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 1008.8475341796875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 749.3157958984375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 514.9794311523438 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 1088.9718017578125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 910.9214477539062 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 405.7536315917969 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 501.1511535644531 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 5774.91015625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 622.646728515625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 492.2016906738281 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 602.0344848632812 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8931, loss_val: nan, pos_over_neg: 522.0438232421875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 496.2888488769531 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8839, loss_val: nan, pos_over_neg: 366.5667419433594 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8809, loss_val: nan, pos_over_neg: 491.51300048828125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8961, loss_val: nan, pos_over_neg: 339.4698181152344 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 1580.38916015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 1998.9886474609375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 525.1329956054688 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8917, loss_val: nan, pos_over_neg: 488.3367614746094 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 878.0519409179688 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 1001.4705810546875 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 441.8990173339844 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8992, loss_val: nan, pos_over_neg: 354.8352966308594 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.888, loss_val: nan, pos_over_neg: 875.6484985351562 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 1180.1900634765625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8836, loss_val: nan, pos_over_neg: 751.259765625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 643.8109130859375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8972, loss_val: nan, pos_over_neg: 357.737060546875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8936, loss_val: nan, pos_over_neg: 1218.3758544921875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 569.0009765625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8967, loss_val: nan, pos_over_neg: 372.8734436035156 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8897, loss_val: nan, pos_over_neg: 521.3591918945312 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8851, loss_val: nan, pos_over_neg: 558.4815063476562 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 794.5069580078125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8828, loss_val: nan, pos_over_neg: 639.5894775390625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8908, loss_val: nan, pos_over_neg: 582.8029174804688 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8961, loss_val: nan, pos_over_neg: 2286.4736328125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8955, loss_val: nan, pos_over_neg: 586.8466186523438 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8825, loss_val: nan, pos_over_neg: 1087.00537109375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8868, loss_val: nan, pos_over_neg: 1540.8170166015625 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8968, loss_val: nan, pos_over_neg: 594.843994140625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8916, loss_val: nan, pos_over_neg: 653.19482421875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 713.8545532226562 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 635.72998046875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.883, loss_val: nan, pos_over_neg: 510.7270812988281 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8988, loss_val: nan, pos_over_neg: 891.7315673828125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8835, loss_val: nan, pos_over_neg: 1719.623046875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 728.5487670898438 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 545.1341552734375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 1113.5787353515625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8856, loss_val: nan, pos_over_neg: 745.2177124023438 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8688, loss_val: nan, pos_over_neg: 714.4779663085938 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8911, loss_val: nan, pos_over_neg: 693.4879760742188 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 673.6158447265625 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 1036.839111328125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8769, loss_val: nan, pos_over_neg: 1135.7403564453125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8683, loss_val: nan, pos_over_neg: 2352.0869140625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 1032.62890625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8808, loss_val: nan, pos_over_neg: 484.94818115234375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 1135.082275390625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8797, loss_val: nan, pos_over_neg: 949.5924682617188 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 1541.751708984375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 1198.431640625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 1601.9605712890625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8931, loss_val: nan, pos_over_neg: 646.9938354492188 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8888, loss_val: nan, pos_over_neg: 790.5704345703125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8839, loss_val: nan, pos_over_neg: 645.93212890625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 479.9963684082031 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 17298.791015625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.887, loss_val: nan, pos_over_neg: 410.6851806640625 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 742.5859985351562 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8736, loss_val: nan, pos_over_neg: 590.2097778320312 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 1089.50830078125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8765, loss_val: nan, pos_over_neg: 6115.21875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8832, loss_val: nan, pos_over_neg: 648.4454956054688 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8795, loss_val: nan, pos_over_neg: 1081.1614990234375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.9017, loss_val: nan, pos_over_neg: 562.6530151367188 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 776.7432250976562 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8966, loss_val: nan, pos_over_neg: 514.668212890625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 1041.5316162109375 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8798, loss_val: nan, pos_over_neg: 909.39404296875 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 1083.5291748046875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 494.2930908203125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8933, loss_val: nan, pos_over_neg: 425.5756530761719 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8866, loss_val: nan, pos_over_neg: 551.219970703125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8882, loss_val: nan, pos_over_neg: 803.3975830078125 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8846, loss_val: nan, pos_over_neg: 628.38037109375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8784, loss_val: nan, pos_over_neg: 640.0546875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 477.156982421875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8875, loss_val: nan, pos_over_neg: 951.4282836914062 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8862, loss_val: nan, pos_over_neg: 745.6373291015625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8895, loss_val: nan, pos_over_neg: 714.5206909179688 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8742, loss_val: nan, pos_over_neg: 984.5045776367188 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8778, loss_val: nan, pos_over_neg: 1030.52978515625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 1633.663330078125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8894, loss_val: nan, pos_over_neg: 1132.039306640625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.9004, loss_val: nan, pos_over_neg: 295.4734802246094 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 562.589599609375 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8891, loss_val: nan, pos_over_neg: 558.935791015625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.887, loss_val: nan, pos_over_neg: 2246.1630859375 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8899, loss_val: nan, pos_over_neg: 1045.5765380859375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 636.7228393554688 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 956.124755859375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8866, loss_val: nan, pos_over_neg: 1446.0882568359375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 1094.006103515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8921, loss_val: nan, pos_over_neg: 527.0897216796875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 550.8555908203125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.88, loss_val: nan, pos_over_neg: 887.6765747070312 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 1014.8486938476562 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8794, loss_val: nan, pos_over_neg: 575.4788818359375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 566.4591064453125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8868, loss_val: nan, pos_over_neg: 598.9849243164062 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 1440.974853515625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8883, loss_val: nan, pos_over_neg: 890.9129028320312 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 566.0692749023438 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8832, loss_val: nan, pos_over_neg: 695.3754272460938 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.886, loss_val: nan, pos_over_neg: 2561.826416015625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8735, loss_val: nan, pos_over_neg: -44707.93359375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 1037.996337890625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 508.95599365234375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8765, loss_val: nan, pos_over_neg: 1090.87353515625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8808, loss_val: nan, pos_over_neg: 3005.602294921875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 935.3017578125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8883, loss_val: nan, pos_over_neg: 821.2269897460938 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 1329.4700927734375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 3019.240234375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 4462.970703125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8763, loss_val: nan, pos_over_neg: 981.36474609375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 2651.271240234375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8798, loss_val: nan, pos_over_neg: 770.3598022460938 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 1560.1304931640625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8878, loss_val: nan, pos_over_neg: -4174.17333984375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 701.211181640625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 516.4819946289062 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 1113.281494140625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 1097.9158935546875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.891, loss_val: nan, pos_over_neg: 1605.957763671875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8783, loss_val: nan, pos_over_neg: 1134.7347412109375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 1121.3045654296875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8799, loss_val: nan, pos_over_neg: 1073.140625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8872, loss_val: nan, pos_over_neg: 790.7368774414062 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8836, loss_val: nan, pos_over_neg: 457.2571105957031 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 493.46319580078125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 890.9318237304688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 666.211181640625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 733.9615478515625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 970.5624389648438 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 1292.6767578125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8858, loss_val: nan, pos_over_neg: 735.3096923828125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.88, loss_val: nan, pos_over_neg: 1153.019775390625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 823.3137817382812 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 901.8307495117188 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 942.12646484375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 1339.8626708984375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 766.2770385742188 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8765, loss_val: nan, pos_over_neg: 3622.47705078125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 829.547607421875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8735, loss_val: nan, pos_over_neg: 764.3671264648438 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8866, loss_val: nan, pos_over_neg: 716.2586059570312 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 777.0006713867188 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 2165.209228515625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8786, loss_val: nan, pos_over_neg: 694.7314453125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 1236.6641845703125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 14510.240234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 395.4817810058594 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 780.351806640625 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8753, loss_val: nan, pos_over_neg: 645.6394653320312 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 777.11328125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 795.3826293945312 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8861, loss_val: nan, pos_over_neg: 1555.3121337890625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 489.9560852050781 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8817, loss_val: nan, pos_over_neg: 608.2481689453125 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 811.51806640625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 781.5026245117188 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.87, loss_val: nan, pos_over_neg: 603.1493530273438 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 1925.0928955078125 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8742, loss_val: nan, pos_over_neg: 871.7589721679688 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 768.7649536132812 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8998, loss_val: nan, pos_over_neg: 423.856201171875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 416.5549621582031 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 460.1146545410156 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 1254.6834716796875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8735, loss_val: nan, pos_over_neg: 1261.223876953125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 790.5875244140625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8766, loss_val: nan, pos_over_neg: 754.9703979492188 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8832, loss_val: nan, pos_over_neg: 964.3267211914062 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 772.9972534179688 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8906, loss_val: nan, pos_over_neg: 520.5593872070312 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8836, loss_val: nan, pos_over_neg: 878.7791137695312 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8841, loss_val: nan, pos_over_neg: 595.9622802734375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8845, loss_val: nan, pos_over_neg: 743.5711059570312 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 1461.4000244140625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8798, loss_val: nan, pos_over_neg: 496.7515563964844 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8873, loss_val: nan, pos_over_neg: 698.7730712890625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 2480.58447265625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8869, loss_val: nan, pos_over_neg: 1195.5235595703125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 2642.201171875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 1902.3345947265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 1065.9688720703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 1929.9808349609375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 1046.1029052734375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8943, loss_val: nan, pos_over_neg: 409.6826477050781 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8764, loss_val: nan, pos_over_neg: 466.36358642578125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.893, loss_val: nan, pos_over_neg: 763.0640869140625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8716, loss_val: nan, pos_over_neg: 1492.091552734375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 610.5900268554688 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8904, loss_val: nan, pos_over_neg: 1170.1229248046875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 1968.71533203125 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 451.99871826171875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8901, loss_val: nan, pos_over_neg: 665.8754272460938 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8881, loss_val: nan, pos_over_neg: 451.5975646972656 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 616.250244140625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8778, loss_val: nan, pos_over_neg: 580.2553100585938 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 913.3285522460938 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 594.5746459960938 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 1031.8875732421875 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 405.40093994140625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8748, loss_val: nan, pos_over_neg: 350.4618225097656 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 576.0007934570312 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8874, loss_val: nan, pos_over_neg: 479.6439208984375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8831, loss_val: nan, pos_over_neg: 1023.503173828125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 772.7992553710938 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8911, loss_val: nan, pos_over_neg: 579.7166137695312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 2166.1826171875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8791, loss_val: nan, pos_over_neg: 1016.5578002929688 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8764, loss_val: nan, pos_over_neg: 780.373779296875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 743.3592529296875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8754, loss_val: nan, pos_over_neg: 1063.2647705078125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8769, loss_val: nan, pos_over_neg: 835.5501098632812 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8861, loss_val: nan, pos_over_neg: 586.2257690429688 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 687.97021484375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: -3012.112548828125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 657.2936401367188 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.884, loss_val: nan, pos_over_neg: 440.2434387207031 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 1446.939453125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 1335.20068359375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8812, loss_val: nan, pos_over_neg: 1097.125244140625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 1478.6982421875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8765, loss_val: nan, pos_over_neg: 1396.1517333984375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8868, loss_val: nan, pos_over_neg: 834.9288940429688 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 1506.0595703125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 692.2098388671875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 1049.830810546875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 60127.34375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8913, loss_val: nan, pos_over_neg: 2252.122314453125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 757.9573364257812 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8842, loss_val: nan, pos_over_neg: 789.08935546875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 2223.973388671875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8852, loss_val: nan, pos_over_neg: 769.1445922851562 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 617.5262451171875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8813, loss_val: nan, pos_over_neg: 1060.9632568359375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8835, loss_val: nan, pos_over_neg: 487.371826171875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8728, loss_val: nan, pos_over_neg: 1667.1630859375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8868, loss_val: nan, pos_over_neg: 724.9708862304688 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 774.3095092773438 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 697.7914428710938 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 498.39044189453125 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8806, loss_val: nan, pos_over_neg: 847.8060302734375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 835.5964965820312 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8862, loss_val: nan, pos_over_neg: 312.7602233886719 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 556.72607421875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8786, loss_val: nan, pos_over_neg: 592.966552734375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8761, loss_val: nan, pos_over_neg: 586.8353881835938 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 3344.592041015625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 578.3924560546875 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 1291.9083251953125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 640.3035278320312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8753, loss_val: nan, pos_over_neg: 675.20166015625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 696.21923828125 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 2016.207763671875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 618.4938354492188 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 1083.993408203125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8788, loss_val: nan, pos_over_neg: 435.3291015625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8799, loss_val: nan, pos_over_neg: 834.8101806640625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 415.7804260253906 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 485.6708679199219 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 890.8851318359375 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.894, loss_val: nan, pos_over_neg: 430.7198486328125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 1136.433349609375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 835.1781616210938 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 614.4201049804688 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8939, loss_val: nan, pos_over_neg: 411.5190124511719 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8788, loss_val: nan, pos_over_neg: 1943.19970703125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8786, loss_val: nan, pos_over_neg: 963.1671142578125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 908.7750244140625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8795, loss_val: nan, pos_over_neg: 1495.5799560546875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8838, loss_val: nan, pos_over_neg: 589.1356201171875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 660.637451171875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 1093.038330078125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 1350.9490966796875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 1134.8372802734375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8798, loss_val: nan, pos_over_neg: 1083.753662109375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 1057.379150390625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 3474.850830078125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 1367.2208251953125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8813, loss_val: nan, pos_over_neg: 505.1157531738281 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 658.54052734375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 646.701416015625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8806, loss_val: nan, pos_over_neg: 752.0403442382812 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 869.5965576171875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8909, loss_val: nan, pos_over_neg: 1622.5072021484375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 887.3392944335938 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 548.2874755859375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 570.37548828125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8847, loss_val: nan, pos_over_neg: 908.9126586914062 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8831, loss_val: nan, pos_over_neg: 556.7711181640625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8746, loss_val: nan, pos_over_neg: 523.709228515625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8876, loss_val: nan, pos_over_neg: 446.7493896484375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8762, loss_val: nan, pos_over_neg: 578.1092529296875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 1395.4405517578125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 658.7876586914062 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 1498.90771484375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 539.4512939453125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 497.42791748046875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8859, loss_val: nan, pos_over_neg: 504.92724609375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.868, loss_val: nan, pos_over_neg: 661.6161499023438 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 583.1015014648438 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 644.0794677734375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8766, loss_val: nan, pos_over_neg: 900.7996215820312 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8799, loss_val: nan, pos_over_neg: 998.7158813476562 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 1144.8282470703125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 527.4392700195312 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8819, loss_val: nan, pos_over_neg: 636.5350341796875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 883.7391967773438 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 341.1688232421875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8843, loss_val: nan, pos_over_neg: 499.7224426269531 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8716, loss_val: nan, pos_over_neg: 1220.900390625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 1208.5631103515625 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 928.4992065429688 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 834.1294555664062 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 1030.3739013671875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 1012.5994262695312 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 659.5608520507812 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 1037.514892578125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 592.8884887695312 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 774.69091796875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8771, loss_val: nan, pos_over_neg: 788.5719604492188 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 1045.367431640625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8853, loss_val: nan, pos_over_neg: 949.2423706054688 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 1513.0045166015625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 1255.3929443359375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8888, loss_val: nan, pos_over_neg: 857.2841186523438 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 521.552001953125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 685.4611206054688 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8746, loss_val: nan, pos_over_neg: 684.6427612304688 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 802.03173828125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 416.1420593261719 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8812, loss_val: nan, pos_over_neg: 902.6581420898438 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8916, loss_val: nan, pos_over_neg: 866.7811279296875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8809, loss_val: nan, pos_over_neg: 1615.5347900390625 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8787, loss_val: nan, pos_over_neg: 677.650390625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 518.8043823242188 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 847.5595092773438 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8728, loss_val: nan, pos_over_neg: 1173.61328125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 735.4575805664062 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 511.1790466308594 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 420.5030212402344 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 515.8562622070312 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8779, loss_val: nan, pos_over_neg: 607.7361450195312 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 998.930419921875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 1617.5782470703125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 1182.8319091796875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8866, loss_val: nan, pos_over_neg: 752.697021484375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8762, loss_val: nan, pos_over_neg: 1211.912841796875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 1620.480224609375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8836, loss_val: nan, pos_over_neg: 1896.703857421875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 844.7030029296875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8945, loss_val: nan, pos_over_neg: 1035.9677734375 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 827.7975463867188 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 872.3873901367188 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 3385.21435546875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 521.6998291015625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 900.6746215820312 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8761, loss_val: nan, pos_over_neg: 976.9515380859375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8716, loss_val: nan, pos_over_neg: 1358.191650390625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 1873.5877685546875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.875, loss_val: nan, pos_over_neg: 925.1156616210938 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8763, loss_val: nan, pos_over_neg: 859.5145874023438 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8779, loss_val: nan, pos_over_neg: 518.090576171875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.88, loss_val: nan, pos_over_neg: 698.54150390625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 583.1675415039062 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8707, loss_val: nan, pos_over_neg: 721.9589233398438 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 1140.3966064453125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 1027.3287353515625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 729.5177001953125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 654.0177001953125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8817, loss_val: nan, pos_over_neg: 739.8787231445312 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8959, loss_val: nan, pos_over_neg: 373.7986145019531 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 1884.716064453125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8791, loss_val: nan, pos_over_neg: 527.8983154296875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 483.2139892578125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 546.9785766601562 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8707, loss_val: nan, pos_over_neg: 682.0167236328125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 1537.4578857421875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8794, loss_val: nan, pos_over_neg: 761.2460327148438 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 603.7986450195312 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 720.3677368164062 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 1198.104248046875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8721, loss_val: nan, pos_over_neg: 732.8067016601562 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 435.80755615234375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 1013.7472534179688 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8848, loss_val: nan, pos_over_neg: 2241.10986328125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 656.6207885742188 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 1088.485595703125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8805, loss_val: nan, pos_over_neg: 599.6827392578125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8839, loss_val: nan, pos_over_neg: 887.6096801757812 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8977, loss_val: nan, pos_over_neg: 1167.91552734375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8662, loss_val: nan, pos_over_neg: 2340.66650390625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 2420.15673828125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 862.4711303710938 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 593.6859130859375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8936, loss_val: nan, pos_over_neg: 681.8728637695312 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8739, loss_val: nan, pos_over_neg: 923.5479125976562 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 1360.9593505859375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8736, loss_val: nan, pos_over_neg: 1648.7159423828125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 759.2655639648438 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 1086.5457763671875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 1214.4432373046875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 704.3173217773438 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 901.3997192382812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 853.91943359375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 2759.386962890625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8884, loss_val: nan, pos_over_neg: 435.5224609375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 717.5833740234375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8669, loss_val: nan, pos_over_neg: 1542.0455322265625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8871, loss_val: nan, pos_over_neg: 1076.4930419921875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.88, loss_val: nan, pos_over_neg: 1346.0736083984375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 766.791748046875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 1268.6871337890625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8765, loss_val: nan, pos_over_neg: 1132.44189453125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 814.1558837890625 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.877, loss_val: nan, pos_over_neg: 1844.5889892578125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8786, loss_val: nan, pos_over_neg: 778.6900634765625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 1080.357177734375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 1058.2125244140625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 720.4031982421875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 634.36328125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 833.521728515625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.89, loss_val: nan, pos_over_neg: 1418.2235107421875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 640.05029296875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 2277.989990234375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 1005.624267578125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8797, loss_val: nan, pos_over_neg: 2195.054931640625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8736, loss_val: nan, pos_over_neg: 2102.78173828125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 735.283935546875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 775.5753173828125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 2058.017578125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 3263.341064453125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 1246.042724609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 558.9329833984375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 18697.52734375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 850.0838012695312 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 1982.2255859375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8828, loss_val: nan, pos_over_neg: 1465.7752685546875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.88, loss_val: nan, pos_over_neg: 591.0068969726562 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8717, loss_val: nan, pos_over_neg: 734.5999755859375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8879, loss_val: nan, pos_over_neg: 752.003662109375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 1325.592041015625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 755.5380859375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8812, loss_val: nan, pos_over_neg: 564.00244140625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 2884.502685546875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8767, loss_val: nan, pos_over_neg: 1538.300537109375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 926.3811645507812 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8748, loss_val: nan, pos_over_neg: 714.8719482421875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 1031.7647705078125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8798, loss_val: nan, pos_over_neg: 1076.688720703125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 686.18310546875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 566.6961669921875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8713, loss_val: nan, pos_over_neg: 1637.7393798828125 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8794, loss_val: nan, pos_over_neg: 565.842041015625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 1145.291259765625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8785, loss_val: nan, pos_over_neg: 472.1581115722656 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8746, loss_val: nan, pos_over_neg: 1331.8165283203125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.879, loss_val: nan, pos_over_neg: 648.2976684570312 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 431.6482849121094 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.869, loss_val: nan, pos_over_neg: 2480.6533203125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 1147.151123046875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 762.2351684570312 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 708.7041015625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.884, loss_val: nan, pos_over_neg: 561.5471801757812 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 498.4217224121094 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 586.5606689453125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 371.1500549316406 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8717, loss_val: nan, pos_over_neg: 713.1551513671875 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8805, loss_val: nan, pos_over_neg: 411.2530517578125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 467.618408203125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 1548.5411376953125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 685.3568725585938 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8711, loss_val: nan, pos_over_neg: 484.6604919433594 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8832, loss_val: nan, pos_over_neg: 856.5543212890625 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 859.324462890625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 708.947509765625 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8651, loss_val: nan, pos_over_neg: 673.3906860351562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 704.9157104492188 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8813, loss_val: nan, pos_over_neg: 547.4663696289062 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 1103.755615234375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 1194.818359375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8767, loss_val: nan, pos_over_neg: 784.7821655273438 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 408.1007080078125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 1404.1026611328125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8863, loss_val: nan, pos_over_neg: 697.4628295898438 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 573.8173217773438 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8612, loss_val: nan, pos_over_neg: 659.6509399414062 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 814.7359619140625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.875, loss_val: nan, pos_over_neg: 987.1528930664062 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 1018.0877685546875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 616.4728393554688 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:00:40<101121:59:42, 1213.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 477.6563720703125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 794.0293579101562 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 1719.0823974609375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.87, loss_val: nan, pos_over_neg: 1178.047607421875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 2662.276123046875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 848.546630859375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 2977.937744140625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 1501.81982421875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 2237.7099609375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8673, loss_val: nan, pos_over_neg: 945.9117431640625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8841, loss_val: nan, pos_over_neg: 908.1552734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 540.1807861328125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 1497.1142578125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8628, loss_val: nan, pos_over_neg: 1067.9400634765625 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 614.8486328125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8711, loss_val: nan, pos_over_neg: 798.4024047851562 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8864, loss_val: nan, pos_over_neg: 764.3685913085938 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8679, loss_val: nan, pos_over_neg: 1241.781982421875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 1062.1063232421875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8739, loss_val: nan, pos_over_neg: 2775.990966796875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 1044.2943115234375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 1389.7735595703125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 963.5203247070312 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 815.2509155273438 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 856.9861450195312 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 3663.374267578125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 1586.939697265625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 2671.59912109375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 1167.6185302734375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.885, loss_val: nan, pos_over_neg: 578.7720336914062 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 572.447265625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 1149.1322021484375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 751.4505615234375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 5839.91064453125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 6590.07958984375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 1114.8043212890625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 593.6715087890625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 970.7536010742188 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 1953.7076416015625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 593.913818359375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8683, loss_val: nan, pos_over_neg: 611.2682495117188 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8748, loss_val: nan, pos_over_neg: 866.5001831054688 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 954.5956420898438 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 1496.2611083984375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 746.2994995117188 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 839.170654296875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8662, loss_val: nan, pos_over_neg: 625.3839721679688 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 703.031005859375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 801.759765625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 639.7184448242188 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 1197.33740234375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8761, loss_val: nan, pos_over_neg: 1605.1187744140625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 564.3883666992188 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 557.7178955078125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.872, loss_val: nan, pos_over_neg: 1416.8228759765625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 876.7625732421875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 685.10888671875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8694, loss_val: nan, pos_over_neg: 835.5477294921875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 469.7115173339844 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 2550.854248046875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 1079.54833984375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 764.0303344726562 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8797, loss_val: nan, pos_over_neg: 669.1834106445312 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 2199.968505859375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 1159.7567138671875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 558.6080932617188 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 507.4098815917969 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8587, loss_val: nan, pos_over_neg: 830.8667602539062 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8713, loss_val: nan, pos_over_neg: 881.524658203125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 479.4708557128906 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.872, loss_val: nan, pos_over_neg: 786.2526245117188 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8827, loss_val: nan, pos_over_neg: 757.0530395507812 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 684.5350952148438 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 678.0252685546875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8709, loss_val: nan, pos_over_neg: 610.1080322265625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 617.0748291015625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 729.6422729492188 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8814, loss_val: nan, pos_over_neg: 494.8895263671875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 386.9981689453125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 1016.7891845703125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 2037.425048828125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8767, loss_val: nan, pos_over_neg: 866.782470703125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8716, loss_val: nan, pos_over_neg: 571.369873046875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8838, loss_val: nan, pos_over_neg: 837.429443359375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 1212.9505615234375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 475.2962646484375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8886, loss_val: nan, pos_over_neg: 534.6370239257812 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 894.53955078125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 543.5490112304688 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 835.0282592773438 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 1603.3055419921875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 1118.1978759765625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 1289.23193359375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 852.8360595703125 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 634.3867797851562 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8769, loss_val: nan, pos_over_neg: 909.3495483398438 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 1081.18212890625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8687, loss_val: nan, pos_over_neg: 410.4725341796875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 593.5872802734375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 1524.4754638671875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 1553.275390625 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 726.5603637695312 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 1843.21337890625 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 1420.4296875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 623.5288696289062 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 869.1526489257812 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 455.3735046386719 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 442.9191589355469 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 557.091796875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 626.5584716796875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 1076.657470703125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8865, loss_val: nan, pos_over_neg: 294.14593505859375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8794, loss_val: nan, pos_over_neg: 351.2566833496094 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.869, loss_val: nan, pos_over_neg: 502.9093322753906 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8861, loss_val: nan, pos_over_neg: 534.8460693359375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8771, loss_val: nan, pos_over_neg: 383.1411437988281 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 514.4044189453125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8711, loss_val: nan, pos_over_neg: 561.9619140625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.87, loss_val: nan, pos_over_neg: 1423.6097412109375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 1022.906005859375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 382.1278381347656 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8766, loss_val: nan, pos_over_neg: 1033.6185302734375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 586.4481201171875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 1262.3438720703125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 888.1605834960938 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 774.6720581054688 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8738, loss_val: nan, pos_over_neg: 260.92474365234375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 1442.179931640625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 1956.637939453125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 2545.144775390625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 1063.2142333984375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 1282.8973388671875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 1470.332275390625 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 809.011962890625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 918.4461669921875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 833.0892333984375 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 1295.94384765625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8671, loss_val: nan, pos_over_neg: 655.2210693359375 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 501.5638732910156 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 1933.1781005859375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.882, loss_val: nan, pos_over_neg: 566.2686767578125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 1206.968505859375 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 739.9202270507812 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8725, loss_val: nan, pos_over_neg: 1018.89599609375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 798.8308715820312 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 715.2763061523438 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8709, loss_val: nan, pos_over_neg: 574.5341796875 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 677.6611328125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 947.2676391601562 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8888, loss_val: nan, pos_over_neg: 890.0520629882812 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 1788.2813720703125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 1113.1873779296875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.868, loss_val: nan, pos_over_neg: 1439.0660400390625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 933.0491333007812 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 1981.515625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 1303.616943359375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 2238.332763671875 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 2530.030029296875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 727.0206909179688 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 936.6585693359375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 1010.4888916015625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 7785.14208984375 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8851, loss_val: nan, pos_over_neg: 1337.366455078125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 1528.567138671875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 676.5059814453125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 786.450439453125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 833.9268798828125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: -59461.18359375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 1645.48486328125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 833.9556884765625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 1122.115966796875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 867.803466796875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 1166.8868408203125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 337.2309875488281 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 859.5635375976562 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 484.8981628417969 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 545.6294555664062 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 687.2377319335938 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.866, loss_val: nan, pos_over_neg: 1220.123779296875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8809, loss_val: nan, pos_over_neg: 1203.260498046875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8679, loss_val: nan, pos_over_neg: 796.4547729492188 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8694, loss_val: nan, pos_over_neg: 612.5957641601562 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 1111.21240234375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 1432.000732421875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 684.60888671875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.875, loss_val: nan, pos_over_neg: 500.8390197753906 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 633.2129516601562 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8826, loss_val: nan, pos_over_neg: 429.33001708984375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8831, loss_val: nan, pos_over_neg: 770.975341796875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 643.161376953125 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 1347.2919921875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 1394.0677490234375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 754.6333618164062 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 1392.9371337890625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8778, loss_val: nan, pos_over_neg: 1405.0782470703125 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 696.24365234375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 502.4561767578125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8748, loss_val: nan, pos_over_neg: 366.5005798339844 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8761, loss_val: nan, pos_over_neg: 449.7589111328125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8695, loss_val: nan, pos_over_neg: 500.2664489746094 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 1183.5509033203125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 635.6804809570312 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 1418.6212158203125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 652.0280151367188 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 2578.53515625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 824.4312133789062 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 647.6860961914062 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 1139.1634521484375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 475.3586730957031 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 491.5115051269531 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 908.6600952148438 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 901.9602661132812 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8566, loss_val: nan, pos_over_neg: 968.04638671875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 776.8095092773438 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 1501.3624267578125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 2677.43408203125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 1562.9471435546875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8681, loss_val: nan, pos_over_neg: 846.8407592773438 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 1843.5836181640625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 739.7339477539062 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8747, loss_val: nan, pos_over_neg: 422.517333984375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 968.0087890625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 976.1699829101562 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 1336.40673828125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 738.5817260742188 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 1070.813720703125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8742, loss_val: nan, pos_over_neg: 779.9295654296875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 472.6432189941406 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 741.880859375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 1251.5897216796875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1826.177734375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 711.941650390625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 2698.052978515625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8702, loss_val: nan, pos_over_neg: 1962.7630615234375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 1977.1195068359375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 1127.425048828125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 853.52880859375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 670.09326171875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 879.6945190429688 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 558.18798828125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 1209.894775390625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: -18656.80078125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8742, loss_val: nan, pos_over_neg: 1120.5794677734375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.876, loss_val: nan, pos_over_neg: 783.5965576171875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 1140.6614990234375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 9741.515625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.86, loss_val: nan, pos_over_neg: 1077.34716796875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 690.9925537109375 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 1606.4693603515625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 998.3960571289062 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 2306.722900390625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 1280.813232421875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 809.7721557617188 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 1451.816650390625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 2812.684326171875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 7150.8046875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 1720.7137451171875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 761.3158569335938 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8753, loss_val: nan, pos_over_neg: 594.2666625976562 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8728, loss_val: nan, pos_over_neg: 467.0705871582031 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8602, loss_val: nan, pos_over_neg: 718.747802734375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 691.2517700195312 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8642, loss_val: nan, pos_over_neg: 805.7505493164062 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 849.0347900390625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 1102.896484375 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 1051.614013671875 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 958.0662841796875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 1198.4036865234375 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 1239.5999755859375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 1597.984375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 1377.4857177734375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 1256.8863525390625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8778, loss_val: nan, pos_over_neg: 963.946533203125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 769.9324951171875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 945.3192749023438 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 657.7780151367188 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 431.3899841308594 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8662, loss_val: nan, pos_over_neg: 913.3431396484375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8745, loss_val: nan, pos_over_neg: 815.9619750976562 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 1250.4283447265625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 1083.3646240234375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 350.61688232421875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 1185.708984375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 1003.5031127929688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 617.37353515625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8791, loss_val: nan, pos_over_neg: 497.71014404296875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 1295.2978515625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8769, loss_val: nan, pos_over_neg: 1416.2576904296875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 1603.2210693359375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 88965.3671875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8638, loss_val: nan, pos_over_neg: 1692.5369873046875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 1770.0592041015625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 503.6297607421875 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 945.4568481445312 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8643, loss_val: nan, pos_over_neg: 420.9116516113281 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 523.1163330078125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 369.6026306152344 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 449.3805847167969 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 1082.1396484375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 933.8807983398438 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8684, loss_val: nan, pos_over_neg: 756.9476928710938 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 2172.026611328125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.866, loss_val: nan, pos_over_neg: 1386.674072265625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8738, loss_val: nan, pos_over_neg: 1636.6514892578125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8684, loss_val: nan, pos_over_neg: 1258.5318603515625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 825.0850830078125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8732, loss_val: nan, pos_over_neg: 559.5691528320312 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 1327.0709228515625 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 801.2550048828125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 527.059814453125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8717, loss_val: nan, pos_over_neg: 444.6768493652344 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 1803.70703125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 673.9996337890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 737.197998046875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 1863.5009765625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 611.314208984375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8736, loss_val: nan, pos_over_neg: 785.5884399414062 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 805.1036376953125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8726, loss_val: nan, pos_over_neg: 897.2920532226562 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 987.0489501953125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 570.815673828125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 1000.1143188476562 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 794.4368896484375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 1192.51513671875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 725.8656616210938 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 1956.5703125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8702, loss_val: nan, pos_over_neg: 1242.8040771484375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 1181.6202392578125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 672.4028930664062 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 2076.508056640625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 683.8614501953125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8709, loss_val: nan, pos_over_neg: 791.3701171875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 1782.3914794921875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8602, loss_val: nan, pos_over_neg: 2239.5908203125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 1429.97802734375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 2156.559326171875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 1045.8681640625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 621.3092651367188 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 1000.7239379882812 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 704.0995483398438 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 1440.82177734375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 905.9636840820312 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 441.63543701171875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 1659.7518310546875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 552.98828125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8741, loss_val: nan, pos_over_neg: 716.2504272460938 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 1058.012939453125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 2789.0537109375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 668.7394409179688 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 647.5883178710938 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 993.0386962890625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 13885.130859375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 746.6549072265625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 656.4727783203125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 1400.3848876953125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 784.8865356445312 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 446.18511962890625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 506.3474426269531 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: -20533.076171875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8702, loss_val: nan, pos_over_neg: 1046.4820556640625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 1083.21435546875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 996.8700561523438 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.869, loss_val: nan, pos_over_neg: 1083.3056640625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8651, loss_val: nan, pos_over_neg: 1738.7669677734375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 2873.240966796875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 1734.906005859375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 753.566650390625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8681, loss_val: nan, pos_over_neg: 558.563720703125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 916.1072998046875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 468.1242980957031 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 1227.4306640625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.856, loss_val: nan, pos_over_neg: 1237.8170166015625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 2772.85693359375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 3927.457763671875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8694, loss_val: nan, pos_over_neg: 2125.978515625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 2082.35205078125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 1053.1051025390625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 810.9284057617188 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 865.4923706054688 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 1019.4221801757812 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 911.6845092773438 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 1091.4437255859375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 882.06982421875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 532.4381103515625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 2200.023193359375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 1199.4061279296875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 1282.7333984375 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 532.3038330078125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8762, loss_val: nan, pos_over_neg: 805.1534423828125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 2508.30859375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8681, loss_val: nan, pos_over_neg: 567.3161010742188 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 2864.794677734375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8763, loss_val: nan, pos_over_neg: 969.6642456054688 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 1922.887451171875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 1048.4862060546875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 3226.6904296875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 1010.3713989257812 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 1648.681640625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 2097.285400390625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 741.6487426757812 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8727, loss_val: nan, pos_over_neg: 896.4712524414062 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 379.3166198730469 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8811, loss_val: nan, pos_over_neg: 1316.518798828125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 966.327880859375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 2416.502197265625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 729.8995971679688 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 1082.902587890625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8713, loss_val: nan, pos_over_neg: 2171.83056640625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 538.0297241210938 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 927.5718383789062 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 415.75909423828125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 624.77685546875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 2387.4609375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8612, loss_val: nan, pos_over_neg: 975.411865234375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 499.64263916015625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 1172.4501953125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 888.7479858398438 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8679, loss_val: nan, pos_over_neg: 1233.543212890625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 720.7614135742188 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 729.0682373046875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 303.25115966796875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 352.18402099609375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 2200.026123046875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 1106.09716796875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 477.59173583984375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8684, loss_val: nan, pos_over_neg: 368.98651123046875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 1502.4591064453125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 981.894775390625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8779, loss_val: nan, pos_over_neg: 1431.09375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 1200.4302978515625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 888.7437133789062 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 441.31842041015625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 1103.3841552734375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 1439.986083984375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 638.1805419921875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 651.986328125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 683.2112426757812 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 917.3380126953125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 1356.4146728515625 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 927.4094848632812 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 992.440185546875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 898.3355712890625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 687.9768676757812 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 1663.0118408203125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 3039.781005859375 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 2768.551025390625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1335.0140380859375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 1415.3299560546875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.873, loss_val: nan, pos_over_neg: 367.0960998535156 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 938.0399780273438 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 541.017578125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8767, loss_val: nan, pos_over_neg: 449.1734313964844 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8712, loss_val: nan, pos_over_neg: 632.268798828125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 574.1275634765625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 899.8978271484375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 668.8199462890625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 1018.5652465820312 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 720.9541015625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8722, loss_val: nan, pos_over_neg: 546.2363891601562 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 1572.1632080078125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 1393.6021728515625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 2850.35888671875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.869, loss_val: nan, pos_over_neg: 2163.845458984375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8612, loss_val: nan, pos_over_neg: 995.3515625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 1102.8865966796875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 1851.6705322265625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 864.6337280273438 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 815.6845092773438 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 969.779541015625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 521.4043579101562 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 400.93939208984375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 640.8057861328125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 577.8381958007812 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 945.1865234375 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 1418.553955078125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 776.2760009765625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 838.0178833007812 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 1618.5225830078125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8629, loss_val: nan, pos_over_neg: 1300.4332275390625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8713, loss_val: nan, pos_over_neg: 908.8656616210938 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 4271.90087890625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 1271.9227294921875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8603, loss_val: nan, pos_over_neg: 813.3235473632812 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 2052.381103515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8671, loss_val: nan, pos_over_neg: 483.8383483886719 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 923.5383911132812 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 2207.21142578125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 935.1229858398438 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8669, loss_val: nan, pos_over_neg: 971.35888671875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.866, loss_val: nan, pos_over_neg: 675.25146484375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 899.1268310546875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 714.1681518554688 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 797.4077758789062 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 1263.2825927734375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 623.2567138671875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 569.8482666015625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8728, loss_val: nan, pos_over_neg: 966.00927734375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.86, loss_val: nan, pos_over_neg: 792.13427734375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 484.34564208984375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8688, loss_val: nan, pos_over_neg: 1003.8117065429688 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 1080.291015625 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8603, loss_val: nan, pos_over_neg: 3740.99853515625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2412.263427734375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 962.0171508789062 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 1088.31787109375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 5018.31640625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 1000.7982177734375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 515.4277954101562 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 513.6455688476562 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 584.8029174804688 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8629, loss_val: nan, pos_over_neg: 723.0574340820312 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 1383.5950927734375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 1001.5314331054688 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 2611.023681640625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 5964.32861328125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8602, loss_val: nan, pos_over_neg: 1559.3779296875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 738.1897583007812 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 1336.7796630859375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 2590.99951171875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 524.4169311523438 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 611.1683349609375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 1115.2840576171875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 1488.9141845703125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8721, loss_val: nan, pos_over_neg: 654.10302734375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 994.9759521484375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 1108.8602294921875 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 654.64990234375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 1520.331298828125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 1100.7301025390625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 506.74334716796875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 680.587646484375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8688, loss_val: nan, pos_over_neg: 855.2290649414062 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 1055.3658447265625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 700.3935546875 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 707.18701171875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 3900.685546875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 719.4703979492188 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8587, loss_val: nan, pos_over_neg: 2293.4921875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8629, loss_val: nan, pos_over_neg: 1380.30078125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8603, loss_val: nan, pos_over_neg: 1652.6954345703125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 561.9990234375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 589.66650390625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 568.291015625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 717.462158203125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 781.8094482421875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8679, loss_val: nan, pos_over_neg: 454.47784423828125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 627.5396728515625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 1719.44921875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 938.8121337890625 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8661, loss_val: nan, pos_over_neg: 494.4208679199219 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 767.3173217773438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8625, loss_val: nan, pos_over_neg: 705.44921875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 822.6527709960938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 1090.17041015625 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 583.8141479492188 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 375.07080078125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8643, loss_val: nan, pos_over_neg: 452.5231628417969 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8687, loss_val: nan, pos_over_neg: 763.9899291992188 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8703, loss_val: nan, pos_over_neg: 978.269775390625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8554, loss_val: nan, pos_over_neg: 612.7342529296875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8603, loss_val: nan, pos_over_neg: 1050.5047607421875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8684, loss_val: nan, pos_over_neg: 2340.77490234375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 2823.43359375 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 889.4273681640625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 1163.0291748046875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 1139.4224853515625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8792, loss_val: nan, pos_over_neg: 578.0050048828125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 1067.996337890625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8669, loss_val: nan, pos_over_neg: 417.0508117675781 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 2332.037109375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 1289.3026123046875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 1288.5421142578125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 1215.908203125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 2849.412353515625 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8687, loss_val: nan, pos_over_neg: 732.064697265625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 1947.899658203125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 920.4498901367188 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 574.4063110351562 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 623.5784301757812 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 816.2552490234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 1204.3116455078125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 22424.361328125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 909.2352905273438 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 1137.165283203125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 856.8748168945312 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8615, loss_val: nan, pos_over_neg: 2577.539794921875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8709, loss_val: nan, pos_over_neg: 749.630126953125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 608.8043823242188 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 1287.2021484375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8695, loss_val: nan, pos_over_neg: 677.831787109375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 641.5275268554688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 657.8092651367188 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 1619.387451171875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 1017.8948364257812 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 3153.697021484375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1009.790771484375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1130.4248046875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 627.5674438476562 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8735, loss_val: nan, pos_over_neg: 651.3685302734375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 739.046142578125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8715, loss_val: nan, pos_over_neg: 1854.3182373046875 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 997.1016845703125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 923.7322998046875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 1158.1951904296875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 2315.627197265625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 608.8568725585938 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 725.4852294921875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 1172.7200927734375 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.875, loss_val: nan, pos_over_neg: 429.72991943359375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 886.0738525390625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 658.8209228515625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 579.3096923828125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 870.688720703125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 1247.717041015625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 1107.8092041015625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2092.38671875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 531.375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 716.9859619140625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 680.7742919921875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1888.4014892578125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 623.0011596679688 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 365.6333312988281 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8659, loss_val: nan, pos_over_neg: 724.37158203125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 696.378173828125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 680.9209594726562 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 584.9679565429688 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 988.3087768554688 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 1091.1458740234375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 3454.091064453125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 849.639404296875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 555.0194091796875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 672.6910400390625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 666.7943725585938 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 1548.7564697265625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 540.287841796875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.87, loss_val: nan, pos_over_neg: 761.3560180664062 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 637.3497314453125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 935.531005859375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 904.7484741210938 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 709.2093505859375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1040.9075927734375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 1156.2454833984375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 1093.614990234375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 1327.0107421875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 816.5105590820312 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8612, loss_val: nan, pos_over_neg: 562.18017578125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8682, loss_val: nan, pos_over_neg: 756.8865356445312 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 977.7499389648438 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1651.7410888671875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 2562.206787109375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 795.7254638671875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 842.8894653320312 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 1118.6658935546875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8775, loss_val: nan, pos_over_neg: 568.5035400390625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 739.7593994140625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8681, loss_val: nan, pos_over_neg: 828.6812744140625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 673.9986572265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 929.8323364257812 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1397.5504150390625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 8936.7333984375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 2951.4072265625 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 736.4865112304688 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 981.5056762695312 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 2538.6162109375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 483.5758056640625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 543.0457153320312 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 1282.4141845703125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 625.8870849609375 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 880.930419921875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 738.22021484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 1819.142822265625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 1185.6654052734375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 726.3831787109375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 817.401123046875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 1686.3897705078125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1337.8951416015625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 532.8692626953125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 1091.1907958984375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 1966.8863525390625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 1303.33642578125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 456.5073547363281 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8531, loss_val: nan, pos_over_neg: 1795.2291259765625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 1806.85205078125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8584, loss_val: nan, pos_over_neg: 1253.56494140625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 1237.6044921875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8695, loss_val: nan, pos_over_neg: 1209.835205078125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: -40740.015625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8665, loss_val: nan, pos_over_neg: 1355.306396484375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8587, loss_val: nan, pos_over_neg: 1811.041748046875 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 2237.129150390625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 10405.8427734375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8566, loss_val: nan, pos_over_neg: 2285.734375 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 1056.8028564453125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 1243.845458984375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 5569.49755859375 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:20:52<101063:14:32, 1212.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.8567, loss_val: nan, pos_over_neg: 990.2657470703125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 890.4860229492188 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 622.38330078125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: -15714.701171875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 17419.943359375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 2796.2646484375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 2162.3505859375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.861, loss_val: nan, pos_over_neg: -6631.8994140625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 1835.092041015625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 2247.31689453125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 922.8084106445312 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1358.42431640625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 1424.5179443359375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1101.4818115234375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 1280.431640625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 1557.22998046875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 987.06396484375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 682.6641845703125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1324.557373046875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 1194.0455322265625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 2300.761474609375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8566, loss_val: nan, pos_over_neg: 1928.83251953125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 2351.580078125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 891.5654296875 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 1276.997314453125 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 2470.8447265625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 9457.8349609375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 2648.14111328125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 724.62939453125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 2454.123046875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 1177.0797119140625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 565.5756225585938 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 604.1177368164062 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 2075.391845703125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 500.37738037109375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8764, loss_val: nan, pos_over_neg: 373.68695068359375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 560.4662475585938 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8554, loss_val: nan, pos_over_neg: 486.7462463378906 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 787.94189453125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 1639.2933349609375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 948.97705078125 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 676.072265625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 500.76947021484375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 1388.4862060546875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 1740.4005126953125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 909.8276977539062 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 706.75390625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 1120.4056396484375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 6762.71435546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 1208.5843505859375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 586.04638671875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 457.9164123535156 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8647, loss_val: nan, pos_over_neg: 453.6399841308594 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 775.8211669921875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 724.2282104492188 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8643, loss_val: nan, pos_over_neg: 2884.8359375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8632, loss_val: nan, pos_over_neg: 621.3596801757812 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 1038.80859375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 2285.31640625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8593, loss_val: nan, pos_over_neg: 1851.77587890625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 1556.615478515625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 648.609619140625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 2206.445556640625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8716, loss_val: nan, pos_over_neg: 860.6570434570312 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 989.5490112304688 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 1122.7076416015625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 764.15380859375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 1281.9549560546875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 1489.901123046875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 1116.4940185546875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.864, loss_val: nan, pos_over_neg: 720.7067260742188 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 554.144775390625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1472.9820556640625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 915.8121948242188 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 945.3973999023438 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 984.3155517578125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 911.9361572265625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 1005.7189331054688 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 3181.562744140625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 1693.8837890625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8771, loss_val: nan, pos_over_neg: 429.302734375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 957.732177734375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: -14102.3330078125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8623, loss_val: nan, pos_over_neg: 3390.089111328125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 994.1663208007812 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 742.1526489257812 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 437.9605407714844 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 3337.7001953125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 1524.874267578125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 329.7572021484375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 589.10546875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 1865.274169921875 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 1341.544189453125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 663.4594116210938 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2494.513916015625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 715.3324584960938 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2229.806884765625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1334.7022705078125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 632.9441528320312 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8669, loss_val: nan, pos_over_neg: 522.7725830078125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 544.484375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 814.6240844726562 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 765.2051391601562 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8687, loss_val: nan, pos_over_neg: 493.98089599609375 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 615.4321899414062 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 1002.0108032226562 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 1315.365478515625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 4172.04248046875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 2075.489501953125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 440.1073303222656 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 1456.362060546875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 1599.7110595703125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 815.5277709960938 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 1162.514892578125 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 501.4824523925781 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 2639.318603515625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 747.478515625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 727.7275390625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 5353.17236328125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 2101.966552734375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 1061.3525390625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 652.94677734375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 881.3696899414062 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 1424.282470703125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 805.7948608398438 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8676, loss_val: nan, pos_over_neg: 436.8827209472656 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 574.630126953125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 844.21875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 2049.929931640625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 1815.197021484375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 736.0621337890625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 868.0919799804688 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 1178.9649658203125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 770.17578125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 923.5775756835938 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 631.648681640625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 900.3924560546875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 1046.41357421875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 1768.7799072265625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 392.7402648925781 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 589.1753540039062 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 692.13916015625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 456.0323791503906 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 449.14910888671875 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.866, loss_val: nan, pos_over_neg: 715.2093505859375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8702, loss_val: nan, pos_over_neg: 538.4307861328125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 915.9802856445312 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 815.0776977539062 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 895.3670654296875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 638.8202514648438 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 845.609375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 1015.0300903320312 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 689.7772827148438 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 845.3368530273438 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 817.4949340820312 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 953.0387573242188 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8615, loss_val: nan, pos_over_neg: 585.0661010742188 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 610.0814819335938 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 449.20587158203125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 941.8502807617188 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 658.1934814453125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8642, loss_val: nan, pos_over_neg: 368.8119812011719 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 607.8906860351562 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 749.8304443359375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 2455.469970703125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 1452.493896484375 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 1092.357177734375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 988.7848510742188 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8584, loss_val: nan, pos_over_neg: 1961.6651611328125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1345.98876953125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 691.5830688476562 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 733.298095703125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 736.2885131835938 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1044.256103515625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8628, loss_val: nan, pos_over_neg: 846.3567504882812 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 870.6363525390625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 1264.6885986328125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 2022.466552734375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 1560.0777587890625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 2285.04443359375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 699.5908203125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 518.5661010742188 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 656.704833984375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 2189.8779296875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1055.5826416015625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1811.321044921875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 750.9578247070312 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 2551.486083984375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: -45008.6015625 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 852.2757568359375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1180.2880859375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1711.7606201171875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 825.5591430664062 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 955.0908203125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 1485.2183837890625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 1267.8348388671875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 877.2554931640625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 1413.013427734375 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 2418.66796875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 770.933837890625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 749.245849609375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 2187.589111328125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 1101.5457763671875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 614.222412109375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 1356.755126953125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 1105.6810302734375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8584, loss_val: nan, pos_over_neg: 907.0166015625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8677, loss_val: nan, pos_over_neg: 1767.9674072265625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 953.4549560546875 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 1126.2994384765625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 1084.0919189453125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 2024.2928466796875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 2423.86083984375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 807.9063720703125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1190.49755859375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 4379.4208984375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 678.1355590820312 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 1013.3665771484375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8642, loss_val: nan, pos_over_neg: 799.6432495117188 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 590.8684692382812 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 1621.7694091796875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 1865.4617919921875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 1083.6517333984375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 843.4537963867188 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 888.4024658203125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 749.3114624023438 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 1347.6845703125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 1018.9019165039062 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 1949.6077880859375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 1523.921142578125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 1742.69287109375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8554, loss_val: nan, pos_over_neg: 516.1005249023438 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 1134.87548828125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: -27414.873046875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 1826.209228515625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 727.5111694335938 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 1077.93994140625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 1129.1903076171875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 660.2385864257812 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1160.693115234375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 626.3446655273438 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 1052.296875 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.856, loss_val: nan, pos_over_neg: 793.43505859375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 1231.375244140625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 1845.0048828125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 623.7085571289062 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 884.076416015625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 2489.6025390625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8673, loss_val: nan, pos_over_neg: 835.6025390625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 698.3729248046875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 1195.6483154296875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 697.0651245117188 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8695, loss_val: nan, pos_over_neg: 1460.1593017578125 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8714, loss_val: nan, pos_over_neg: 954.5734252929688 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 1012.7747802734375 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 683.7314453125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 544.7039794921875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8702, loss_val: nan, pos_over_neg: 705.5345458984375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 610.73291015625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 976.814208984375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8673, loss_val: nan, pos_over_neg: 481.7931823730469 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 994.4279174804688 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 2732.819091796875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 1152.185302734375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8587, loss_val: nan, pos_over_neg: 967.8566284179688 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1116.791015625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 855.7813720703125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 831.7191772460938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 677.2368774414062 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 960.8050537109375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 613.022705078125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 504.8225402832031 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 1293.3199462890625 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1245.035400390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 579.5342407226562 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 914.92919921875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 906.636474609375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 450.7170715332031 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 621.3795776367188 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 589.8095703125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 700.7158813476562 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 674.7276611328125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 3864.43310546875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 1634.8760986328125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 677.37109375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 977.686767578125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 2596.513671875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 843.9715576171875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 630.2977294921875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 538.6881713867188 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 732.2392578125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 3196.580322265625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 1100.4029541015625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1298.33984375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1787.6795654296875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 888.123779296875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 1334.37451171875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 878.4075317382812 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 1104.996337890625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 913.7185668945312 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 835.3955688476562 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 1304.0380859375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 665.4176025390625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 1040.2208251953125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 830.7847290039062 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 713.987060546875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 992.2066040039062 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1673.1983642578125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 770.9854125976562 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 788.46240234375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 830.10107421875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 904.739013671875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1723.6661376953125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 1366.7747802734375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 1137.745361328125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 7025.46337890625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 1325.4068603515625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 1666.497314453125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8641, loss_val: nan, pos_over_neg: 807.5408935546875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 780.190673828125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 645.4569091796875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 1535.0599365234375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 1046.905029296875 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 873.4486694335938 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 2184.81005859375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 917.0508422851562 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 540.6901245117188 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1233.6602783203125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 2275.0107421875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8699, loss_val: nan, pos_over_neg: 1025.361328125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 1107.6087646484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 1465.178466796875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 869.7947998046875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 1258.106689453125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 1254.6417236328125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 2070.82958984375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 735.72509765625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 468.61419677734375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 847.3524780273438 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 3267.460205078125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 1130.797607421875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 971.0393676757812 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 5399.1279296875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 2092.358154296875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 1560.8258056640625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 1716.756591796875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 943.6446533203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 767.7544555664062 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 643.0239868164062 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 1548.177734375 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 856.85400390625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1139.9248046875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 1857.127197265625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 866.188720703125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 754.0914306640625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 1366.0631103515625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: -17391.919921875 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1667.5555419921875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 1021.8283081054688 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 1667.6214599609375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 578.4743041992188 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 1331.416015625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 1084.206298828125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 1013.6088256835938 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 574.3473510742188 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 1214.850830078125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1017.3134765625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 736.625732421875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 595.0631103515625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8669, loss_val: nan, pos_over_neg: 1810.2081298828125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 3667.264892578125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 776.532958984375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 904.2579956054688 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8519, loss_val: nan, pos_over_neg: 1347.3922119140625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 959.5731811523438 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 692.1729736328125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 903.93798828125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 1412.089599609375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8613, loss_val: nan, pos_over_neg: 464.20367431640625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 1500.1907958984375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 1400.590576171875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1629.8316650390625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 1570.043212890625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 979.7550048828125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8657, loss_val: nan, pos_over_neg: 1243.65234375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 4304.8447265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8528, loss_val: nan, pos_over_neg: 1019.4351806640625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 883.2548828125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 890.1969604492188 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 1526.2083740234375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 998.945068359375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 2862.888427734375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 573.5040283203125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 726.838134765625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 589.2571411132812 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 905.3031005859375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 7038.14501953125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 527.5514526367188 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 1335.8643798828125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1113.1768798828125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8681, loss_val: nan, pos_over_neg: 2137.440673828125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 2221.603271484375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 2817.01416015625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 673.7811889648438 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: -16896.724609375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1861.1068115234375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 1296.914306640625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1327.618896484375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 1116.404541015625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 900.6680908203125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 1216.10693359375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8587, loss_val: nan, pos_over_neg: 708.5369873046875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 1456.1883544921875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 886.2752685546875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1386.5743408203125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 41877.69140625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 2327.8056640625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1869.8380126953125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1073.701904296875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 673.74658203125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 1045.4571533203125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 979.097412109375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 902.7293090820312 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 683.5665283203125 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 1381.4583740234375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 759.915771484375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 1728.2757568359375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 1717.93408203125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 1076.5274658203125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 1543.291015625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 910.7393188476562 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 1241.01123046875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 795.02734375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8585, loss_val: nan, pos_over_neg: 636.9547729492188 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 1071.028076171875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 968.8093872070312 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8594, loss_val: nan, pos_over_neg: 1705.0230712890625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 3220.872314453125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1153.32421875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 568.779541015625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8643, loss_val: nan, pos_over_neg: 754.3909912109375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 1173.4388427734375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8519, loss_val: nan, pos_over_neg: 1406.6661376953125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 3486.528076171875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 1320.318359375 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 1715.0076904296875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 2153.482177734375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 1466.7557373046875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 1510.801025390625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1651.31396484375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 2171.05908203125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 12871.7744140625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1644.7724609375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 1667.16064453125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 4345.62451171875 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 3156.189208984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 2156.570068359375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 1439.8448486328125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 575.1180419921875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.857, loss_val: nan, pos_over_neg: 685.3792724609375 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 503.1434631347656 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 2390.867919921875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 3258.873291015625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 1218.140380859375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 856.9976806640625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1095.9681396484375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 883.5419921875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 804.2744750976562 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2417.8447265625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 628.3271484375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 1155.5721435546875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 744.6858520507812 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 1902.562255859375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 900.0263671875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8582, loss_val: nan, pos_over_neg: 1112.8970947265625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 700.3580932617188 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 816.1149291992188 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 754.9276733398438 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 878.5677490234375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 2020.7386474609375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8617, loss_val: nan, pos_over_neg: 1848.7901611328125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 1137.7354736328125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 742.414306640625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 1137.6912841796875 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 741.1848754882812 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.86, loss_val: nan, pos_over_neg: 769.8004760742188 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1175.1656494140625 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 1273.06884765625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 716.0300903320312 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 853.6819458007812 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 950.6748657226562 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 785.6874389648438 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 728.8490600585938 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8719, loss_val: nan, pos_over_neg: 523.9826049804688 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 801.6768188476562 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 1213.0999755859375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 660.2073974609375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 493.9759216308594 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8562, loss_val: nan, pos_over_neg: 808.6143798828125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 76827.1796875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 1400.0804443359375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 895.1937255859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 1342.33349609375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 816.1654663085938 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 926.6953735351562 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 5810.927734375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 1985.663330078125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 440.2073974609375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8642, loss_val: nan, pos_over_neg: 616.0621948242188 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 555.3961791992188 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 1664.4290771484375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 770.3228759765625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1236.659423828125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 542.312255859375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 803.103515625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 912.8467407226562 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 1249.618896484375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8531, loss_val: nan, pos_over_neg: 587.9019165039062 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 788.7669677734375 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8519, loss_val: nan, pos_over_neg: 841.5741577148438 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 898.1799926757812 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 1409.0654296875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 753.15380859375 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 829.2469482421875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 711.93115234375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 886.7305297851562 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 848.8587036132812 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 662.9840698242188 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8595, loss_val: nan, pos_over_neg: 950.57470703125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 521.75634765625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 733.8276977539062 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 1011.182861328125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 785.7163696289062 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 1048.997802734375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 722.6449584960938 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1908.20458984375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 616.943359375 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 678.9099731445312 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 690.5809936523438 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 549.7026977539062 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 521.3226318359375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8661, loss_val: nan, pos_over_neg: 783.4555053710938 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8619, loss_val: nan, pos_over_neg: 748.7101440429688 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 477.8246154785156 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8628, loss_val: nan, pos_over_neg: 500.2700500488281 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 4273.07958984375 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 575.2681884765625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 464.5142822265625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 846.7391357421875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 1590.2401123046875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 500.3882751464844 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 930.73193359375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 429.3534851074219 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 1760.9927978515625 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 467.7710876464844 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 476.65576171875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 651.609130859375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 1251.1932373046875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 802.3325805664062 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 755.6605834960938 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 1071.744140625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 615.1436157226562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 1078.0614013671875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 1142.4486083984375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 887.6180419921875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 720.6259765625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 917.3073120117188 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 823.982666015625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 507.86749267578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 831.6898193359375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 1183.09619140625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 763.401123046875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 923.4296875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 1349.2861328125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 853.2504272460938 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 639.119140625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 878.2909545898438 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 1114.9808349609375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 689.60302734375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 1707.2991943359375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 957.2685546875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1546.1763916015625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 817.8568725585938 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 923.15966796875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8592, loss_val: nan, pos_over_neg: 839.8607177734375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 419.7574768066406 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 1627.85791015625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 1075.5621337890625 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8658, loss_val: nan, pos_over_neg: 1405.64404296875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 1056.75439453125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8572, loss_val: nan, pos_over_neg: 1378.5416259765625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 73725.6875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 1821.4234619140625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1110.8914794921875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 23111.220703125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 3532.031005859375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 1312.5238037109375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 2263.81005859375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 1483.1563720703125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 816.73583984375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 756.699462890625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 2464.80029296875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1288.96337890625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 1154.556396484375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 951.5519409179688 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1019.5429077148438 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 932.1181030273438 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 786.5353393554688 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 1167.8541259765625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8605, loss_val: nan, pos_over_neg: 2026.33251953125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 750.73876953125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 872.7002563476562 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.86, loss_val: nan, pos_over_neg: 909.31884765625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 519.416748046875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 902.6983032226562 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1169.57470703125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 568.5205078125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 765.6426391601562 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8643, loss_val: nan, pos_over_neg: 500.1331787109375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 2789.590576171875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 1188.944580078125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 505.2261962890625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 1389.2984619140625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 821.8496704101562 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 842.8239135742188 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 854.5538940429688 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.865, loss_val: nan, pos_over_neg: 772.2390747070312 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 797.6494140625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1063.23193359375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 807.9267578125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1412.2197265625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 541.03515625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 811.403076171875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 724.8040771484375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 1216.0828857421875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 4728.87939453125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 1589.09765625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 1028.9986572265625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 7931.35205078125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 1541.576416015625 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 777.2091064453125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 2705.1064453125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1902.2960205078125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8604, loss_val: nan, pos_over_neg: 692.1539306640625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 624.0276489257812 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 1269.26416015625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 1201.808349609375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 1250.0147705078125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 1231.618896484375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 853.3692626953125 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 683.3096923828125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1210.3548583984375 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 2735.858642578125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 1266.1925048828125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 758.1548461914062 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 639.701416015625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 5716.9404296875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 1597.3572998046875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 472.22845458984375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8672, loss_val: nan, pos_over_neg: 1107.115966796875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 1208.59716796875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 763.7188720703125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.858, loss_val: nan, pos_over_neg: 1319.5823974609375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1791.4725341796875 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1333.3572998046875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 518.5567626953125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 756.5975952148438 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 1198.8819580078125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1092.571044921875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 732.0809936523438 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1161.90625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 581.3302001953125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 487.4765319824219 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1115.702880859375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 549.1246337890625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.86, loss_val: nan, pos_over_neg: 1152.7681884765625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8593, loss_val: nan, pos_over_neg: 851.3174438476562 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 2139.293212890625 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 734.7969360351562 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 490.4494323730469 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 1294.958251953125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 871.2943115234375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 1093.8255615234375 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 2341.45947265625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8628, loss_val: nan, pos_over_neg: 1552.68408203125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8567, loss_val: nan, pos_over_neg: 3377.61572265625 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 1192.3505859375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 2101.14501953125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1994.596923828125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1497.4541015625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 1518.7774658203125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8591, loss_val: nan, pos_over_neg: 880.016845703125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 2709.79150390625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 1683.65087890625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 1388.9752197265625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:41:09<101207:28:39, 1214.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 1057.6221923828125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 812.8933715820312 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1076.8714599609375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 965.378662109375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1592.301025390625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 3215.29248046875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1064.081298828125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8536, loss_val: nan, pos_over_neg: 574.6121215820312 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 3953.781982421875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 431.45343017578125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 1312.7552490234375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 759.8007202148438 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 594.4596557617188 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 791.223388671875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 1273.5091552734375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1695.7650146484375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 2728.015869140625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 948.2138671875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 3369.8212890625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 3233.977783203125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 2206.16552734375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 3371.642822265625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 1416.13818359375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8543, loss_val: nan, pos_over_neg: 742.3699340820312 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 1468.26416015625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1657.0089111328125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 542.6722412109375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 2071.1123046875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 2056.492431640625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1624.6624755859375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8528, loss_val: nan, pos_over_neg: 2602.02978515625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 8768.8056640625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1689.5968017578125 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 879.1900024414062 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1285.7149658203125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 1069.75341796875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 2391.458251953125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 1019.5590209960938 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1720.552734375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 2561.069091796875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 1151.271484375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 1660.973876953125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 910.8719482421875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1678.068115234375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1563.2127685546875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 1784.3375244140625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 1516.356689453125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 1194.809326171875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 985.1759033203125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 1420.0277099609375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 1096.1304931640625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 2301.296630859375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 3868.712646484375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8588, loss_val: nan, pos_over_neg: 1442.8094482421875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 3573.365966796875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 987.8228149414062 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 1473.2742919921875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1011.5458984375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 582.1502685546875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 473.23638916015625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 1757.1815185546875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 3908.740478515625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 4049.853759765625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8599, loss_val: nan, pos_over_neg: 1007.3551025390625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8577, loss_val: nan, pos_over_neg: 865.2353515625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1428.7115478515625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 1299.5047607421875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 2771.7529296875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 1015.9013061523438 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 2966.237548828125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 1926.3133544921875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8607, loss_val: nan, pos_over_neg: 489.4376525878906 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 696.7554931640625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 8160.87353515625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 1325.343017578125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 968.40966796875 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 949.89892578125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 1438.8724365234375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1338.6080322265625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 669.3450927734375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 897.6595458984375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 1359.1275634765625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 1465.4713134765625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 476.0060729980469 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 882.8479614257812 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 2128.934814453125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 1696.5609130859375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 462.2732849121094 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 675.8092651367188 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 970.396728515625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 1531.4532470703125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 520.7992553710938 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 710.6119995117188 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 1722.3104248046875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 1209.8192138671875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 582.23193359375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 932.5851440429688 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 836.8814086914062 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 686.6928100585938 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 578.171630859375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 785.448974609375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 858.1932983398438 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 739.8153686523438 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 2136.96728515625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 1666.7596435546875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 7803.82763671875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 1283.1453857421875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 2955.497314453125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 1534.3843994140625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 1025.6883544921875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 3725.1572265625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8488, loss_val: nan, pos_over_neg: 2018.323974609375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 438.420166015625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 559.3363647460938 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 2426.220458984375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 972.989013671875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 1055.107421875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1377.9400634765625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 2070.943359375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1795.5755615234375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 1938.126953125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1211.9373779296875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 923.3412475585938 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 959.0244750976562 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 630.1237182617188 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1089.387451171875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 1007.3682861328125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8584, loss_val: nan, pos_over_neg: 1126.16552734375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 566.3052368164062 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8638, loss_val: nan, pos_over_neg: 800.3206787109375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 1791.05224609375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 6204.82080078125 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1161.7135009765625 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 869.5006713867188 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8602, loss_val: nan, pos_over_neg: 1814.9241943359375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1996.2132568359375 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 1465.2647705078125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 424.26446533203125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 615.5933227539062 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 1079.8631591796875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 980.495849609375 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8559, loss_val: nan, pos_over_neg: 642.5487060546875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1044.8023681640625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1686.26806640625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1796.053466796875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8688, loss_val: nan, pos_over_neg: 783.5614013671875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 1117.5738525390625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 4081.212890625 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 1588.5501708984375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 997.8588256835938 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 430.5079345703125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 3273.06591796875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 591.4287719726562 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1036.111328125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 1229.64208984375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 754.788818359375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 896.333251953125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 675.87890625 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8565, loss_val: nan, pos_over_neg: 1213.676513671875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1354.7913818359375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 741.5882568359375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 946.8748779296875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1715.1715087890625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1149.1319580078125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 631.0869750976562 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 621.5648803710938 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 1812.9053955078125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 1328.2572021484375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 830.0645751953125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8664, loss_val: nan, pos_over_neg: 949.6139526367188 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 2156.6728515625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1640.768798828125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 1659.65185546875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 1169.6544189453125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 925.9622802734375 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 1546.9847412109375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 938.2635498046875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 843.5289916992188 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 1699.4942626953125 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 784.765380859375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 944.63232421875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 1116.6229248046875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 1060.9503173828125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 647.3331909179688 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 3778.91357421875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 957.008056640625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 919.2822875976562 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8598, loss_val: nan, pos_over_neg: 1028.7564697265625 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.854, loss_val: nan, pos_over_neg: 912.9506225585938 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 1611.7303466796875 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 2154.117431640625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 576.1231079101562 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 560.7565307617188 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 583.1829223632812 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 940.2366333007812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 682.7022094726562 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 1092.6939697265625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 582.9950561523438 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 719.7997436523438 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 632.1612548828125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 1709.7452392578125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1463.7921142578125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 5723.30615234375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 837.5090942382812 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 925.1610717773438 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 589.5943603515625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 972.0470581054688 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 1875.8565673828125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1642.5435791015625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 617.8760986328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 3046.87890625 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 4014.678466796875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 4099.57275390625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 1334.632080078125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 780.2532348632812 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 1920.63623046875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 1532.8682861328125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 2023.518798828125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 1792.99658203125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1492.855224609375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 558.754638671875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 552.5487670898438 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 588.9078369140625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 914.9985961914062 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 769.8800048828125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 595.5331420898438 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 610.7822875976562 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 804.3443603515625 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 950.3016357421875 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 1050.5029296875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1775.1866455078125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 984.5164794921875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 662.3372192382812 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 2463.662353515625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1681.6885986328125 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8612, loss_val: nan, pos_over_neg: 514.1181030273438 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 530.4693603515625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 2263.430908203125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 1707.8367919921875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 2933.358154296875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 580.5614624023438 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 795.2323608398438 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8602, loss_val: nan, pos_over_neg: 1006.0386962890625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 2716.715087890625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 844.5442504882812 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 895.2611083984375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 2034.763916015625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 7608.2841796875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 1724.3485107421875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 746.5127563476562 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8625, loss_val: nan, pos_over_neg: 619.9881591796875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 746.5576171875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 1188.7763671875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 1194.098388671875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 805.8406982421875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8574, loss_val: nan, pos_over_neg: 1500.52978515625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 987.3504638671875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1382.546142578125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 5323.97607421875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 835.0402221679688 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1546.0384521484375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1169.6221923828125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 855.9707641601562 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 2318.4560546875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 6654.7470703125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 844.8853759765625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 3458.082763671875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 994.9100341796875 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1640.5782470703125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 1176.1531982421875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 776.1069946289062 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 1122.6456298828125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 1476.704833984375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1161.6676025390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8559, loss_val: nan, pos_over_neg: 1184.859130859375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 3116.924560546875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 940.096435546875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 4292.91064453125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 4492.697265625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8528, loss_val: nan, pos_over_neg: 652.409912109375 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 2752.603759765625 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 3543.845703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 2650.724365234375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 736.9767456054688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 734.1637573242188 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1258.9337158203125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 2557.57421875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 4318.38037109375 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1101.5736083984375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 746.7904663085938 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 677.2022094726562 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1184.30126953125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 699.7957153320312 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1084.4493408203125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 1103.4259033203125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 1018.4379272460938 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 905.2730102539062 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8566, loss_val: nan, pos_over_neg: 756.2088623046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8603, loss_val: nan, pos_over_neg: 563.5831909179688 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 1212.458251953125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 3146.069091796875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 1607.5401611328125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 10880.927734375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 8058.64111328125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 3538.319091796875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 670.3065795898438 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 10178.375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 705.2197875976562 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 1769.45654296875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 1602.74169921875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 3248.80126953125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 1341.7957763671875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 1674.21337890625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 988.1905517578125 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1245.879150390625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 7308.4013671875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 1283.0797119140625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1093.7200927734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1052.3426513671875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 899.9622802734375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1231.1768798828125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 1187.5489501953125 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 1111.3343505859375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 992.2574462890625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1521.9522705078125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 1113.09423828125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 1091.860595703125 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 571.2896118164062 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 693.8104248046875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1456.1539306640625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 2369.964599609375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 852.5890502929688 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 1464.86181640625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1263.586181640625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 978.9681396484375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 11319.54296875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1846.134033203125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 1299.1622314453125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 981.3809814453125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 671.3886108398438 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 952.177490234375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1283.580322265625 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 1575.5335693359375 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 3284.07861328125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 1180.566162109375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 4642.9501953125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 1460.199951171875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1374.2994384765625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 1365.0484619140625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 657.6150512695312 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 848.6399536132812 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 891.4876708984375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 998.218017578125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 871.4863891601562 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 2364.6484375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 974.8067016601562 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 2166.02294921875 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 1486.440185546875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 2264.96630859375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 1732.85498046875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1004.4580688476562 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 488.3896789550781 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 1213.3419189453125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 579.3089599609375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1217.8505859375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 1088.819580078125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8628, loss_val: nan, pos_over_neg: 661.5242919921875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1012.1880493164062 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 1330.382568359375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8567, loss_val: nan, pos_over_neg: 1367.55419921875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 1070.6173095703125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 819.4644775390625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 2478.941650390625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 665.8922119140625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 1096.7891845703125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 2787.26513671875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 518.6580200195312 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 955.1065063476562 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 386.07489013671875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 1024.1273193359375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 2114.562744140625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 664.01318359375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 855.3655395507812 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 702.3399047851562 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 731.8018188476562 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 716.1158447265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 2651.821533203125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 859.7815551757812 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 759.5833740234375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 925.3743896484375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 1161.9417724609375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 976.998291015625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 1126.3114013671875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 7477.30224609375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 708.96875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 2580.00732421875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 884.41357421875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 1316.124755859375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 1418.1689453125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 1150.92236328125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1005.8331298828125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 515.1827392578125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 859.2536010742188 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 2011.67333984375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 1142.7218017578125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 1007.7396850585938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 2403.917236328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 2163.53515625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1852.519287109375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8571, loss_val: nan, pos_over_neg: 1060.402099609375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 1718.448974609375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 14164.7607421875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 1164.5716552734375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 424.1894226074219 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 845.840576171875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1382.846435546875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1214.7398681640625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8534, loss_val: nan, pos_over_neg: 420.0793762207031 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 861.9345092773438 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 1473.4490966796875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 1120.5084228515625 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 690.4702758789062 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 931.590576171875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8551, loss_val: nan, pos_over_neg: 1268.2784423828125 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 604.4370727539062 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 1255.5032958984375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 989.9110717773438 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 1825.8134765625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 757.93896484375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 811.30810546875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 1001.1702270507812 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1091.7833251953125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 937.5111694335938 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 1267.912353515625 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 896.1553344726562 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 330.9153747558594 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 384.09100341796875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 892.2227172851562 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 707.5487060546875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 508.4248962402344 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 661.2335205078125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 1077.508056640625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1170.02587890625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1758.6322021484375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 992.0501098632812 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 687.4091796875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 976.9793701171875 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1383.9559326171875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 451.85577392578125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 595.2119140625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 1359.62939453125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 1259.4954833984375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 867.721923828125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 478.8237609863281 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 409.6856689453125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 691.949951171875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 701.879638671875 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1528.187255859375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1640.5638427734375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 1041.8438720703125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 554.0969848632812 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1422.9473876953125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 1577.6962890625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 1030.205078125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 651.4797973632812 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 526.7039184570312 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 4576.84912109375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1286.2452392578125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 522.7225952148438 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 540.59130859375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 1080.7554931640625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1266.1162109375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 1067.041015625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 945.7678833007812 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 871.4325561523438 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 2697.065185546875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1245.6988525390625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 1630.6802978515625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 1203.2186279296875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 727.7875366210938 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 8659.716796875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 1469.30419921875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 1453.174072265625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8583, loss_val: nan, pos_over_neg: 1131.6903076171875 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 647.4750366210938 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8558, loss_val: nan, pos_over_neg: 1755.243408203125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 1357.5135498046875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 1420.6148681640625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 694.8375244140625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 999.20703125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1080.396728515625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 2413.451416015625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 1544.0191650390625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 2062.038818359375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 783.3958129882812 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1017.4713745117188 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 728.01904296875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 2382.333984375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 531.0665283203125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 498.2035827636719 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 724.2005615234375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 810.3590087890625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 640.7571411132812 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 2080.66650390625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 1174.340087890625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 1963.1268310546875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 1508.380859375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 742.3226318359375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 3914.114501953125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 616.2748413085938 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 7176.27783203125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 1085.7442626953125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 1308.5296630859375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 769.3526611328125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 571.1839599609375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 2913.80419921875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 685.4906616210938 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 3420.19287109375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8563, loss_val: nan, pos_over_neg: 356.4981994628906 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 851.576416015625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 6101.697265625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 3515.239013671875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 620.2879638671875 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 905.2802734375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 1068.173583984375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 787.4843139648438 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 792.3358764648438 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 1114.34765625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1536.880126953125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1177.4876708984375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1605.42431640625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 845.3095703125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 1733.21923828125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 962.434814453125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 2141.603759765625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 3007.76318359375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 962.2841186523438 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 793.9607543945312 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1699.5430908203125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 1632.0062255859375 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 533.4930419921875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 2343.313232421875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 476.7406311035156 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 647.0963134765625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 939.6144409179688 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 760.118408203125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 442.4911193847656 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 721.8358764648438 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 848.374755859375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 1157.37548828125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1122.469482421875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1075.971923828125 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 682.7708129882812 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 1357.33251953125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 2008.1976318359375 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1726.1749267578125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 2633.9541015625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8576, loss_val: nan, pos_over_neg: 358.6419372558594 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 611.6072998046875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 1475.148681640625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 558.4674072265625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 1622.911865234375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 2204.41845703125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 750.2232055664062 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1320.217529296875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 952.3360595703125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 8763.2451171875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 2588.327392578125 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 964.9935302734375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 843.2109985351562 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 1826.6502685546875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 1341.2943115234375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 1759.5965576171875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 10243.71484375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1112.192626953125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1042.5574951171875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 1539.734130859375 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 1506.998291015625 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 830.4540405273438 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1558.7618408203125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1230.3179931640625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 1601.521484375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 1893.5054931640625 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 569.376220703125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 562.5411987304688 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1780.992919921875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 1726.3458251953125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 2523.425537109375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1293.2861328125 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 674.9627075195312 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 812.7957763671875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 1025.54345703125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1189.353515625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1703.7623291015625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1066.1710205078125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 849.9887084960938 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 836.8543090820312 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 2601.620849609375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 458.8791809082031 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 464.3245849609375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 525.2244262695312 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 6690.56298828125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 544.5414428710938 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 582.87158203125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1050.1124267578125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 763.643310546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 865.9407348632812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.859, loss_val: nan, pos_over_neg: 323.0368347167969 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 537.7222290039062 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 1834.01904296875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 12696.423828125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 527.6814575195312 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 849.3571166992188 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 2936.85400390625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 937.2648315429688 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 1016.6365966796875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 1199.1383056640625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 444.30218505859375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 1425.3857421875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1021.7119140625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 2546.08984375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 487.1454772949219 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 656.7208862304688 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 884.4629516601562 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 983.9619140625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 1204.2955322265625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 1629.68115234375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 1265.2557373046875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 721.3748779296875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 1301.7562255859375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 574.038330078125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 635.718994140625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 612.931640625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 695.5693359375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 4271.1474609375 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8559, loss_val: nan, pos_over_neg: 949.6617431640625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 929.9551391601562 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 678.5994262695312 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 1223.6142578125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 698.7080078125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 457.4453430175781 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8306, loss_val: nan, pos_over_neg: 2121.6689453125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 630.11669921875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1058.529296875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 1083.75146484375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1386.825927734375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 651.1551513671875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 6565.60302734375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 553.31982421875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 667.3247680664062 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 1635.6451416015625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 1549.92236328125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 2069.104736328125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.852, loss_val: nan, pos_over_neg: 995.7855224609375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 593.0101318359375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 960.1112060546875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 664.3867797851562 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 672.3787231445312 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1250.6260986328125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 3044.76220703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 1302.038330078125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 643.8697509765625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1329.9010009765625 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 1415.2750244140625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 993.4912719726562 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 638.5060424804688 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 3841.705078125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 553.867431640625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 822.4130859375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1421.8270263671875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 1059.20703125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 726.7360229492188 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 2296.152099609375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 1212.0128173828125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: -9668.1025390625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 5050.65478515625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 935.7396850585938 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 1354.3941650390625 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 901.8035278320312 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 3647.38720703125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 1054.5552978515625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 1591.4019775390625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 1576.4493408203125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 1329.3931884765625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 768.6630859375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 1403.884033203125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1030.9154052734375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 2844.110107421875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 7860.52587890625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 2695.500244140625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 1400.4161376953125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 4084.43896484375 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1465.9296875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 2101.703369140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 1257.408447265625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:01:31<101394:27:37, 1216.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 1743.4515380859375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 739.418701171875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1211.6416015625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1371.131103515625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1261.59716796875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1452.1279296875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 752.4824829101562 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 3965.276123046875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1473.044921875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8488, loss_val: nan, pos_over_neg: 1099.7806396484375 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1310.7889404296875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1576.04443359375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 2325.244873046875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 767.1838989257812 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 726.3505249023438 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 673.0692749023438 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 760.2490844726562 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 702.5913696289062 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 749.71484375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 1036.2174072265625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 753.589599609375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 15341.5556640625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 1381.2684326171875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 727.257568359375 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 4642.4541015625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 1027.220703125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 1532.6019287109375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 940.3411254882812 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 4647.45166015625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 2723.567138671875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.851, loss_val: nan, pos_over_neg: -42753.828125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 4926.1904296875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 3998.9013671875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 1576.9840087890625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 2921.48095703125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1319.206787109375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 2062.644287109375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 1120.095947265625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 887.1357421875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 838.3795776367188 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 937.9559936523438 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 5686.50146484375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 1947.6141357421875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 919.6779174804688 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 1614.4407958984375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 2285.955078125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 608.7490844726562 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1212.878662109375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 1722.5191650390625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1130.6661376953125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 789.9188842773438 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 740.5772705078125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 2224.941162109375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 941.10791015625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1146.990478515625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 1621.4227294921875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 1268.8875732421875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1191.1171875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 1055.34326171875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 512.4226684570312 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 542.4376220703125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1708.7642822265625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 2854.884033203125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 2075.23388671875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 862.5538940429688 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 836.7188110351562 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1100.92919921875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 667.2650756835938 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 1273.4036865234375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1446.971923828125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1220.95068359375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 900.0015258789062 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 616.5150146484375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 938.601318359375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 3498.697021484375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 1212.9439697265625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1405.5660400390625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1380.5538330078125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 2219.158447265625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 1133.0911865234375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 1546.1524658203125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 1368.4000244140625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 673.524169921875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 933.1458129882812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 817.0725708007812 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 1004.926025390625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 2421.841552734375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 3451.90771484375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1020.2647094726562 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 3706.581787109375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 1787.18896484375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 4501.724609375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1841.7266845703125 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 439.12548828125 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1258.6905517578125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 703.1911010742188 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 764.1018676757812 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 1024.1953125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 22549.431640625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1350.39794921875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8296, loss_val: nan, pos_over_neg: 763.7725830078125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 2269.145751953125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1853.1497802734375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 399.2395324707031 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 879.17919921875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 941.8917846679688 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1530.1524658203125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 576.2352294921875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 722.4093627929688 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 1493.439453125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 719.7774047851562 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 2341.753173828125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 6598.1083984375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 625.1155395507812 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 2272.41015625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 1228.43896484375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 3093.96044921875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 736.4481201171875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 1436.93505859375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 2255.443115234375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 2298.844482421875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 502.3417053222656 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 812.9009399414062 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1700.94140625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1264.452392578125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 1809.5347900390625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 3679.792236328125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8557, loss_val: nan, pos_over_neg: 1313.05859375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 3217.63525390625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 954.2801513671875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 711.7762451171875 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 1626.1781005859375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 919.91845703125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 650.5006103515625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 895.6832885742188 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 1183.8465576171875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1474.1923828125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1114.52880859375 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 844.5264892578125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1025.6060791015625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 1077.5152587890625 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 599.2474975585938 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 564.968505859375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 4570.6689453125 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 1191.8184814453125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 413.50030517578125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 622.1387939453125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 787.0501708984375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8307, loss_val: nan, pos_over_neg: 66001.6171875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 1702.288330078125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 670.6129760742188 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 770.4405517578125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 2602.724853515625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8567, loss_val: nan, pos_over_neg: 837.20849609375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 583.5614624023438 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 1780.9071044921875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 648.497802734375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 1033.4066162109375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 1413.0023193359375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 564.0645141601562 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 667.095947265625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 768.2810668945312 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 3840.59326171875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 1238.78271484375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 952.6962280273438 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 784.7505493164062 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 906.1883544921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 1657.81005859375 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 3998.063720703125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 723.7294311523438 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 711.2236938476562 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 515.0897827148438 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8511, loss_val: nan, pos_over_neg: 565.7615966796875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 508.39398193359375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 869.5609130859375 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 513.3482666015625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 871.5748291015625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 517.8762817382812 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 1047.584716796875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 4059.471923828125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 2120.40283203125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 1116.05810546875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 711.1920166015625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1461.0650634765625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 734.5186157226562 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 1806.5595703125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 501.9801940917969 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 557.2926635742188 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8579, loss_val: nan, pos_over_neg: 657.6535034179688 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 647.7032470703125 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 943.82080078125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 1178.1475830078125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 1235.1241455078125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 5143.330078125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 945.0882568359375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 891.3062744140625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 995.66357421875 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 907.9132690429688 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 772.7760620117188 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 1217.9813232421875 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.849, loss_val: nan, pos_over_neg: 1064.520751953125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 8076.97900390625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 5318.078125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 995.0780029296875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1967.4754638671875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 2477.485107421875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 2032.403564453125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 638.8160400390625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 2187.204345703125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 887.8002319335938 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 2598.75927734375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 822.0321655273438 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1963.59228515625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8524, loss_val: nan, pos_over_neg: 675.6785888671875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8334, loss_val: nan, pos_over_neg: 751.2210693359375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 4104.41796875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 2334.60595703125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 958.9895629882812 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 1352.7923583984375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1691.881103515625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 777.745849609375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1321.0068359375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1873.1171875 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 933.3230590820312 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 1023.3056030273438 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 510.6358947753906 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 2711.368408203125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 1102.234375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 2924.66162109375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1209.3544921875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 4738.42041015625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 1112.8612060546875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 2784.0498046875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 2380.15234375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1309.3043212890625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 2206.541748046875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 3998.42578125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 1096.1683349609375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1368.53564453125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 739.1433715820312 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 527.2551879882812 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 3991.280517578125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 3314.78369140625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 1148.453369140625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 1625.111572265625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 51597.640625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 2848.440185546875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 1389.028076171875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 7282.6484375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 3446.6787109375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1164.2916259765625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 1390.736572265625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 1344.116943359375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 1754.6783447265625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 2333.006103515625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 1189.7108154296875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1493.84912109375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 1786.53466796875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1859.330810546875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1752.4013671875 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 666.562255859375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1360.2720947265625 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 910.2697143554688 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 5645.830078125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 954.6658325195312 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1351.786376953125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 532.7813720703125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 747.6508178710938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 460.47320556640625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 1122.483154296875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1808.469970703125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 1327.110595703125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 724.91162109375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 663.7191162109375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 1259.6275634765625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 542.565673828125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 648.2357788085938 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 659.0360717773438 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 1094.95849609375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 636.820068359375 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 1109.0537109375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8504, loss_val: nan, pos_over_neg: 487.6209411621094 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 417.7064514160156 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1106.883544921875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 1096.256103515625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 2034.0523681640625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 1070.9879150390625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 2819.030029296875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 1336.838623046875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 1631.9923095703125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 1175.921142578125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 970.0232543945312 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 1371.7669677734375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 4767.27587890625 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 662.9868774414062 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1288.5191650390625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 403.21978759765625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 766.4055786132812 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 2028.362548828125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 2263.22314453125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 2031.2154541015625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 1275.856689453125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 993.2902221679688 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1610.70751953125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1149.0511474609375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 724.8844604492188 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 471.57550048828125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 606.5151977539062 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 2019.20556640625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1376.6419677734375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8521, loss_val: nan, pos_over_neg: 1082.466796875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 1256.2528076171875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 1804.797607421875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 1862.8365478515625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 2564.861083984375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 7349.6884765625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 2257.492431640625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 20123.384765625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1241.8944091796875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 564.3561401367188 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 800.927490234375 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 957.98583984375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1343.896484375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 804.6836547851562 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 1337.709716796875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 982.8853149414062 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 2056.28564453125 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 968.815673828125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 1384.195068359375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 752.1959838867188 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 1760.92822265625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1151.7520751953125 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 682.4662475585938 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 793.277587890625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1085.0401611328125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 724.0216064453125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1042.4871826171875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1572.233154296875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 1117.2530517578125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 2006.9864501953125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8545, loss_val: nan, pos_over_neg: 476.8416442871094 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 6146.658203125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 1927.0418701171875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 960.3693237304688 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 955.9119262695312 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 489.6526794433594 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 2437.941162109375 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 1315.515625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 736.5601806640625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 1251.9444580078125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 932.0237426757812 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 1009.2078857421875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 3249.70654296875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 992.2445068359375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 1012.60498046875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 534.978515625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1104.4378662109375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: -8854.0302734375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 1341.0927734375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 1153.8631591796875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 751.0879516601562 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1171.0660400390625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 730.8082885742188 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1881.7454833984375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 903.7540283203125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1024.7467041015625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: -35832.6875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 4492.25927734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 1381.12744140625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 841.9917602539062 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 1564.9354248046875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 4912.93408203125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 964.7261962890625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 2711.26318359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 909.8963623046875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 1076.0919189453125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1155.2518310546875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1168.660888671875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 5424.521484375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 2381.7099609375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1161.779052734375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1340.1934814453125 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 16936.111328125 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 4487.5771484375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 1103.5439453125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1058.4803466796875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 557.5634155273438 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 1565.1771240234375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 786.093994140625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1554.4185791015625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 1143.0406494140625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 826.9202880859375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1645.0274658203125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 726.6498413085938 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 799.4009399414062 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 1588.8109130859375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 985.9862060546875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1102.2197265625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 3696.49267578125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 2920.4130859375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 7683.89599609375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 875.8236694335938 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 1293.0294189453125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 651.785400390625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 805.0767211914062 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 556.0234985351562 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 1005.0518798828125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8469, loss_val: nan, pos_over_neg: 506.6867980957031 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 358.644287109375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 1119.9044189453125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 1322.7783203125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 684.631591796875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 990.3994750976562 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 669.677734375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 2357.02001953125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 672.0300903320312 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 3358.75390625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 776.0903930664062 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 971.7811279296875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 938.0903930664062 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 1055.1336669921875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 710.1396484375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 551.3272094726562 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 1678.888671875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1515.125244140625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 602.1163940429688 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 551.432373046875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 726.86767578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 1517.1751708984375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1474.066162109375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 11620.623046875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 1240.7362060546875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1294.0538330078125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 912.1707153320312 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 1162.04638671875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 810.626220703125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 572.8607788085938 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1149.3533935546875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 2316.995849609375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 554.171142578125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 1421.0538330078125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1770.134765625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 1439.0228271484375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 978.5258178710938 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 744.1239013671875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 1135.2247314453125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 2456.808349609375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 640.9864501953125 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1173.798828125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 1531.2044677734375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8506, loss_val: nan, pos_over_neg: 428.639892578125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1436.68310546875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 2328.029052734375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 834.802734375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 692.4008178710938 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 1563.226318359375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 1020.8805541992188 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 1120.3634033203125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 621.0382080078125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 1739.0908203125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1074.07275390625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1196.01611328125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 1293.294921875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 725.3770141601562 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 860.2698974609375 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 867.3518676757812 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 702.8885498046875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 439.9183654785156 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 2534.2509765625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 1693.3250732421875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 1068.96142578125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 620.81982421875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 740.5574340820312 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1671.5545654296875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1855.2388916015625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 1412.2352294921875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 420.5612487792969 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 1121.7440185546875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 725.973876953125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 502.8070373535156 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1259.8740234375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8549, loss_val: nan, pos_over_neg: 639.032470703125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 1053.0364990234375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 1033.5477294921875 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 775.2239379882812 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1572.24267578125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 2152.72265625 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 10286.7890625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 676.541015625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.8526, loss_val: nan, pos_over_neg: 567.3123168945312 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 1256.53564453125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 1803.94140625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 906.0835571289062 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 814.5889282226562 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 537.3554077148438 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1390.926025390625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 900.9149780273438 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 2715.117919921875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 2111.61767578125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1077.8077392578125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 482.7659912109375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8457, loss_val: nan, pos_over_neg: 830.8311767578125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 1696.382080078125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 1371.6787109375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 561.6390380859375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 1248.3275146484375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8334, loss_val: nan, pos_over_neg: 1362.883544921875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 513.4497680664062 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1692.98828125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 6742.00830078125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1603.229248046875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8492, loss_val: nan, pos_over_neg: 1007.4909057617188 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 577.6004028320312 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.829, loss_val: nan, pos_over_neg: 3345.7783203125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 714.6773681640625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8474, loss_val: nan, pos_over_neg: 529.6588745117188 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1166.59130859375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1156.5606689453125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 1274.448486328125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8527, loss_val: nan, pos_over_neg: 2057.244384765625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1478.33642578125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 1782.325439453125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1018.5613403320312 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 599.0192260742188 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 740.2260131835938 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1127.153564453125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 799.2094116210938 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 745.3617553710938 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 1475.7113037109375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 1218.4500732421875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 1277.2637939453125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 1452.4813232421875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 1722.2918701171875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 984.8265991210938 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: 1182.8133544921875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 4018.201416015625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 1796.547607421875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 527.8859252929688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 559.2850341796875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 780.0453491210938 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1756.1129150390625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 1206.9256591796875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1051.1163330078125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 1877.843505859375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 833.9511108398438 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 1705.7230224609375 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 773.8916625976562 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1126.1993408203125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.853, loss_val: nan, pos_over_neg: 1191.332275390625 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1149.7281494140625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 4108.17431640625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1838.83056640625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 1551.0172119140625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 1864.0091552734375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 600.8871459960938 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 695.7516479492188 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8488, loss_val: nan, pos_over_neg: 569.7971801757812 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 733.6417846679688 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 1341.9429931640625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1320.943115234375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1442.031494140625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 1073.5518798828125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1223.2628173828125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 1991.675537109375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 609.9373168945312 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 1097.5234375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 739.952392578125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 810.6028442382812 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 444.4510192871094 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 1462.2484130859375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 1082.253662109375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 916.7149658203125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 746.9292602539062 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 1351.079833984375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 5246.3212890625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 787.2742309570312 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 1515.138916015625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 585.216796875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 1574.80615234375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 1426.1068115234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 753.2371215820312 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 791.1181640625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 1309.847412109375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 567.8126220703125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 987.3882446289062 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 901.7326049804688 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1605.9254150390625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 610.8534545898438 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1869.032958984375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1084.1666259765625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 1757.8238525390625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 1109.1800537109375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 734.133544921875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 1244.0787353515625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 664.230712890625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 926.7698974609375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 424.9821472167969 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 589.1773681640625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8296, loss_val: nan, pos_over_neg: 1162.547119140625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 2558.08837890625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 1900.0303955078125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 2872.786376953125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 2652.37548828125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1261.874755859375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 2666.878662109375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 1317.7750244140625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 2173.73828125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 804.8671875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1141.281494140625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 650.6604614257812 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 1249.8096923828125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 31263.626953125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 1367.86376953125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 933.5635375976562 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1295.4737548828125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1674.797119140625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 974.2593383789062 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.824, loss_val: nan, pos_over_neg: 1031.2010498046875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 975.197998046875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 664.1351928710938 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 2822.88134765625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 4029.37353515625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 612.0430908203125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 1726.0194091796875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1313.8797607421875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 1966.5826416015625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 966.6679077148438 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 695.505859375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 620.0830078125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 1487.78564453125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 2967.538330078125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 1042.9306640625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 992.3560791015625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 549.198974609375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8535, loss_val: nan, pos_over_neg: 848.54638671875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 858.6788940429688 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 1482.7874755859375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 523.3036499023438 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 617.0013427734375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8507, loss_val: nan, pos_over_neg: 649.299560546875 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 1122.4447021484375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1881.0396728515625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 2865.0546875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1739.9892578125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 855.2999267578125 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 4452.46826171875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1575.140380859375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 738.7228393554688 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 500.8532409667969 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8503, loss_val: nan, pos_over_neg: 437.444091796875 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 1454.0986328125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1404.168212890625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 2010.6798095703125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 818.984375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1225.82666015625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 961.5578002929688 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 2263.427978515625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 1113.524658203125 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1152.212646484375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 830.2972412109375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1203.829345703125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 1216.6207275390625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 1095.538330078125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 904.0953369140625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8232, loss_val: nan, pos_over_neg: 1715.8250732421875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 831.3125610351562 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 1237.41357421875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 2021.137451171875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 2191.95751953125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 747.5057983398438 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 2877.027587890625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 1391.1822509765625 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 619.37060546875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 1222.1822509765625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 808.845703125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1575.990234375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 1784.39892578125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1777.7220458984375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1063.0968017578125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 659.4141845703125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 4671.7607421875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 944.3051147460938 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 898.6286010742188 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 524.7130126953125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 872.3123779296875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8505, loss_val: nan, pos_over_neg: 1346.5604248046875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 983.84765625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 730.330810546875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 519.3546752929688 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 595.6885986328125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1398.6279296875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 733.2489624023438 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 975.0786743164062 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 627.0157470703125 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 747.3985595703125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:21:55<101590:09:33, 1219.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.8415, loss_val: nan, pos_over_neg: 1761.6484375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 847.629150390625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 668.6856079101562 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1315.8648681640625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 1841.731689453125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 990.6096801757812 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 832.4381103515625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 553.8651123046875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 686.2616577148438 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 753.4320678710938 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1015.0311279296875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 661.7188110351562 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 689.445068359375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 1562.4739990234375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 2743.70068359375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 1299.06201171875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 727.5330810546875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 779.2245483398438 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 541.3114624023438 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 1032.415771484375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 1498.4886474609375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 1389.9901123046875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 528.2318115234375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 634.77392578125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8448, loss_val: nan, pos_over_neg: 533.5504760742188 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1337.8321533203125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 1592.4945068359375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 781.1649169921875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 801.2142944335938 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 795.419921875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 1898.6163330078125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 2528.939208984375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1645.7230224609375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 677.5701293945312 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 1212.62890625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 719.1747436523438 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 1479.8648681640625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 2809.97119140625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 2322.7333984375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 435.65576171875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1128.478515625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 659.3782958984375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 1189.301513671875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 1180.81005859375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 3702.970947265625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 5204.8037109375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1363.19775390625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 999.1173706054688 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 1508.5704345703125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 1363.313720703125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1613.7344970703125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8296, loss_val: nan, pos_over_neg: 1043.122314453125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 1921.576416015625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 4187.86767578125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 1195.8316650390625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 2230.710205078125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 1954.00146484375 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 5050.609375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 986.0313110351562 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 1796.0316162109375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 1019.7804565429688 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 915.492431640625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 914.9775390625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 957.5809326171875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 793.4308471679688 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1340.0621337890625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1565.2420654296875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 4500.3857421875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1553.133056640625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 607.7257080078125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 590.63623046875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 964.23583984375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 5409.84130859375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 795.6231689453125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1488.961181640625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 584.9472045898438 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 1095.910888671875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8307, loss_val: nan, pos_over_neg: 5362.24658203125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 18750.20703125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 1471.8140869140625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 2532.9736328125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1219.4881591796875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 2077.650390625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 730.125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8266, loss_val: nan, pos_over_neg: 1006.440673828125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 1142.61962890625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 1202.3414306640625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 929.5300903320312 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 544.6387939453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1603.943603515625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 881.1341552734375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1663.866943359375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 1353.1572265625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 1461.322265625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 1188.6748046875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1133.82177734375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 2791.794677734375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1354.8607177734375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 1233.66015625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 1031.0235595703125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 1027.706787109375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 3482.568115234375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 970.1575317382812 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 2635.134033203125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 1039.673828125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 1358.5662841796875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 841.2327880859375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 543.5482788085938 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 1071.1011962890625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 1396.0128173828125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 1227.54345703125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 6888.30419921875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1303.483154296875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 6231.142578125 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 747.044677734375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8241, loss_val: nan, pos_over_neg: 6161.5126953125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1184.8516845703125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 1518.45458984375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 889.4111938476562 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 826.8479614257812 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 923.5333251953125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 599.5157470703125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 782.9646606445312 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 1222.658935546875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 700.052001953125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 764.6180419921875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1393.89892578125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 1993.9515380859375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 2435.685302734375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 2242.87890625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1670.474853515625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 765.7630615234375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 1003.0770263671875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 799.7337036132812 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 2151.2109375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 1122.5819091796875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 548.9436645507812 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 585.3453369140625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 1179.9737548828125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 3364.482177734375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 857.9737548828125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 2394.34765625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 722.4658813476562 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 691.6024169921875 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 1326.10546875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 1152.0628662109375 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1031.2899169921875 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 764.7399291992188 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 1325.958251953125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 3411.70849609375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 658.9818115234375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 891.2991333007812 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 1304.5552978515625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 992.1779174804688 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1053.5877685546875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 2469.464111328125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 672.0791625976562 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 818.2217407226562 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 583.7147827148438 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 3003.04638671875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1787.6475830078125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 1777.50341796875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 919.8094482421875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 1464.7626953125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 961.010498046875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8228, loss_val: nan, pos_over_neg: 1250.36279296875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 1339.177490234375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 828.4066772460938 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8232, loss_val: nan, pos_over_neg: 887.16796875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 1744.5577392578125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1412.7784423828125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 1278.6676025390625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 955.2020874023438 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 2976.02001953125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 823.510009765625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 1298.605224609375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 1732.150634765625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 1291.428955078125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 1665.8131103515625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: -60707.44140625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 1554.58447265625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1891.7781982421875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 1655.1876220703125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 809.3760375976562 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 1361.6754150390625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 4797.89990234375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 198145.796875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 1039.4716796875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 1464.5758056640625 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 2721.74462890625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 1189.2589111328125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 1249.7275390625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1330.2666015625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: -2459762.75 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 2262.915283203125 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8421, loss_val: nan, pos_over_neg: 3761.057861328125 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1405.7359619140625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 1110.99755859375 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 1127.271484375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 926.1417236328125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 1481.15771484375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 757.3014526367188 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 762.8093872070312 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 1027.7452392578125 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1425.1529541015625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 4833.59716796875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 642.9827270507812 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 980.7171630859375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 653.1341552734375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 950.7120361328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 1258.9237060546875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 1219.5751953125 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 630.098876953125 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 957.1484375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 1245.22900390625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 931.77587890625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 1200.107666015625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 1596.6566162109375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 1293.206787109375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 969.8030395507812 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1153.375244140625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 6356.96923828125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 821.7037353515625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 467.15911865234375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 988.1654663085938 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1172.61865234375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 1083.1451416015625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8277, loss_val: nan, pos_over_neg: 1085.3236083984375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 445.5337219238281 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 6826.3935546875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 2780.570556640625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 1579.151611328125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 4622.39501953125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 979.2216796875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 1423.6170654296875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 2039.66015625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 1468.64208984375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 859.6023559570312 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 2108.281982421875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 900.5894775390625 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 605.8192138671875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 935.5167236328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 3305.79736328125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1259.9639892578125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 1052.01708984375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 1438.9298095703125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1050.8411865234375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 2003.5445556640625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 8179.5419921875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 1969.7506103515625 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 2230.55859375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 653.1273803710938 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1955.3834228515625 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8334, loss_val: nan, pos_over_neg: 818.5706787109375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 502.7691650390625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 897.375732421875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 900.4459838867188 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 1227.467529296875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 8030.15234375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1043.615478515625 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 1981.5615234375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 2543.96142578125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: -50524.19921875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 1235.9073486328125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1547.1094970703125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8256, loss_val: nan, pos_over_neg: 1012.4259643554688 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 1187.41259765625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 1226.47021484375 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 695.9686279296875 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 542.2723388671875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 995.2891845703125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 1163.4566650390625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1720.787841796875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8264, loss_val: nan, pos_over_neg: -8633.7861328125 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 1531.134033203125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 1076.798583984375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 752.9918823242188 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 1954.4488525390625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 1292.55078125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1498.4716796875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 806.935302734375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 11439.3232421875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1861.398193359375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 824.8850708007812 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8234, loss_val: nan, pos_over_neg: 1256.382080078125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 761.92138671875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 812.3538208007812 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 2890.362548828125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 1018.8563232421875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 1016.6927490234375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1075.496826171875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 658.88720703125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 982.5597534179688 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 1075.534912109375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 1970.741455078125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: -1070268.0 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 1675.5521240234375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 1448.0419921875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 1622.97900390625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 6712.26708984375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 1190.2586669921875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1033.8724365234375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 1647.6436767578125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 2150.405517578125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 1351.2802734375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: -12729.8212890625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 3316.530029296875 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1088.451904296875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 2370.33837890625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 3306.816162109375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: -143179.9375 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 1078.1593017578125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 1680.9066162109375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1059.6629638671875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 2254.34326171875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8222, loss_val: nan, pos_over_neg: -5055.01123046875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1274.1673583984375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 966.9865112304688 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 1446.6898193359375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 7950.23486328125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 1719.463134765625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 1181.2662353515625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1497.0352783203125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 1859.87109375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 1431.6683349609375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 1141.8099365234375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 817.8656616210938 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 1855.0096435546875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1975.159912109375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 1863.726318359375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 815.93994140625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 1386.44091796875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 571.60693359375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1430.0665283203125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.823, loss_val: nan, pos_over_neg: 1716.1942138671875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 990.9434204101562 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8266, loss_val: nan, pos_over_neg: 6002.3330078125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 3925.250244140625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 896.5948486328125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 534.5431518554688 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8541, loss_val: nan, pos_over_neg: 406.9793395996094 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 5967.85888671875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 2876.667236328125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 1091.6173095703125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 1000.1805419921875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1389.7225341796875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 5642.68798828125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 1812.4332275390625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 1422.02392578125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 1484.1109619140625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1366.99609375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8349, loss_val: nan, pos_over_neg: 1401.152587890625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 1134.2734375 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 888.4265747070312 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 793.2929077148438 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 549.1451416015625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.824, loss_val: nan, pos_over_neg: 1432.6029052734375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 792.779541015625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1258.3050537109375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 654.9765625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 933.96142578125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 734.4993896484375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 4754.86376953125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 718.0896606445312 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 926.6531372070312 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 656.1041259765625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 601.6697387695312 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 1328.614501953125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1271.34326171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 550.5231323242188 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 595.7896728515625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 870.6589965820312 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 1553.2757568359375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 761.0241088867188 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 1653.322265625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8341, loss_val: nan, pos_over_neg: 1313.8892822265625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 4438.86083984375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 731.3092041015625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1104.4454345703125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 875.4684448242188 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 5650.4873046875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 2097.9697265625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 2553.19189453125 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 2389.48876953125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1061.9727783203125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 5086.6318359375 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 14613.775390625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 7143.90576171875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1188.5118408203125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 754.5592651367188 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 732.4410400390625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 2145.82373046875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8277, loss_val: nan, pos_over_neg: 4428.29541015625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 2335.5712890625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 807.7437133789062 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1462.2142333984375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 816.8790283203125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 3157.571533203125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 10389.8642578125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 1039.56640625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 1411.9188232421875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1033.0306396484375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 1429.3548583984375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1495.5675048828125 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1349.6119384765625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 968.7388305664062 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 538.9431762695312 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 1146.631591796875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 2977.4345703125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 1202.6646728515625 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 973.9865112304688 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 2290.251220703125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 759.3386840820312 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1264.01318359375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1873.091552734375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 1296.2037353515625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 4914.7607421875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 1007.9849243164062 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8429, loss_val: nan, pos_over_neg: 730.6224365234375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 959.0465698242188 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 778.1013793945312 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 438.66058349609375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 1097.0416259765625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1644.991943359375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 1974.185302734375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 879.5113525390625 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 727.0352783203125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 960.1184692382812 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.839, loss_val: nan, pos_over_neg: 887.798583984375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 2496.24267578125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 2544.232177734375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 1305.6085205078125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 2110.57373046875 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 1619.4609375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 664.0211791992188 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 1047.1630859375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 961.9776000976562 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8405, loss_val: nan, pos_over_neg: 532.1211547851562 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 2041.6741943359375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 1721.57421875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1077.1104736328125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 987.1314086914062 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 1395.2210693359375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 2772.892333984375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 2245.653076171875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 1157.046630859375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 952.1714477539062 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 996.0139770507812 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 890.0855102539062 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 911.1802368164062 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 1068.9945068359375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 990.7896728515625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 1439.4349365234375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 2637.219482421875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: -3522.8828125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8265, loss_val: nan, pos_over_neg: 1122.0145263671875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8488, loss_val: nan, pos_over_neg: 569.5034790039062 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 2251.709716796875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 1146.0870361328125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 1973.783935546875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 1173.913818359375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 1232.179931640625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 791.0881958007812 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 801.33251953125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1347.19775390625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 745.172607421875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 800.7225341796875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 1167.2314453125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 694.1593627929688 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1386.773193359375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 10693.5712890625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 781.9170532226562 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 802.8883666992188 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 1007.8999633789062 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1021.9421997070312 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 2008.9674072265625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 2343.59423828125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 1269.963134765625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 1868.70068359375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 2880.55029296875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 654.7786865234375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 1016.3472290039062 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.844, loss_val: nan, pos_over_neg: 639.3283081054688 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 2412.0087890625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 1073.372314453125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1233.2598876953125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 723.38330078125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8398, loss_val: nan, pos_over_neg: 3493.52197265625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 2527.289306640625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 1509.697509765625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 7643.07958984375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 3636.474609375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 3924.017822265625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 2563.85546875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 1039.9005126953125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 1003.3331298828125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1237.3165283203125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 1759.2255859375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8223, loss_val: nan, pos_over_neg: 1317.7738037109375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 987.3857421875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 1293.9097900390625 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 804.4463500976562 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 2050.990478515625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 1870.2674560546875 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 3736.455322265625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8334, loss_val: nan, pos_over_neg: 1047.753662109375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 1416.2633056640625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 3251.585205078125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 3652.88037109375 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 1016.6421508789062 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8272, loss_val: nan, pos_over_neg: 1087.659423828125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 1972.091552734375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 1562.8521728515625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 685.718994140625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 853.1524658203125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8296, loss_val: nan, pos_over_neg: -26655.48046875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 2968.875244140625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 650.6043090820312 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 1106.547119140625 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 966.990478515625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 1338.7071533203125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 975.087646484375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 843.1787719726562 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 867.4424438476562 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 862.5328369140625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1421.395751953125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 2698.33935546875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1745.8604736328125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 698.4071655273438 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 1641.277587890625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 4009.8115234375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 1066.58447265625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 1252.3037109375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 2468.428955078125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 623.3859252929688 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 1030.073486328125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 869.266357421875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1131.9852294921875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 1193.368896484375 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 1356.6236572265625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 2253.5126953125 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 1626.3673095703125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 2310.85009765625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 21109.0 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 1035.0045166015625 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 1207.9488525390625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 1540.1676025390625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 1113.260986328125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 1236.3948974609375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1180.516845703125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 796.8729858398438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 1040.9664306640625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 1136.7091064453125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 1145.8642578125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8232, loss_val: nan, pos_over_neg: 1493.8009033203125 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1656.228759765625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 1206.315185546875 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 811.8040771484375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 1414.1636962890625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 4866.7060546875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8432, loss_val: nan, pos_over_neg: 520.3863525390625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 872.5254516601562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 938.2286376953125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.845, loss_val: nan, pos_over_neg: 1623.0904541015625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 1110.549560546875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 922.8544311523438 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1315.188232421875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 4006.410888671875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 826.2622680664062 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 456.5150451660156 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1015.4288940429688 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 600.2960205078125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 599.477783203125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1157.11669921875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 1338.863037109375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 1435.782958984375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 653.0372314453125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 2429.373291015625 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: -35947.359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 795.0707397460938 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1688.2625732421875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 1558.185791015625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1472.51123046875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 839.2440185546875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 964.008544921875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 582.5628662109375 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 618.0391845703125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 775.6982421875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 1321.135986328125 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 1573.0723876953125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 1474.4853515625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 5921.49169921875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 1614.379638671875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 1731.427001953125 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 2333.74560546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8425, loss_val: nan, pos_over_neg: 1027.3389892578125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8225, loss_val: nan, pos_over_neg: 7773.60400390625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 1359.570068359375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 539.8961181640625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 985.8133544921875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 1095.2708740234375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 749.505126953125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 951.4469604492188 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 617.656982421875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 771.454833984375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 1185.55810546875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 1133.5196533203125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 500.0378723144531 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 1632.8798828125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8223, loss_val: nan, pos_over_neg: 1617.293212890625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 1606.521728515625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 939.8297729492188 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1988.569091796875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 2443.702880859375 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 645.6990356445312 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 1714.7530517578125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 734.91357421875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 1882.0306396484375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 1088.9022216796875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1024.0250244140625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 1576.1715087890625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 1016.4878540039062 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.8263, loss_val: nan, pos_over_neg: 1208.8641357421875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 1572.9056396484375 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 953.2872314453125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8412, loss_val: nan, pos_over_neg: 898.5368041992188 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 2985.890380859375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 4512.90625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8277, loss_val: nan, pos_over_neg: 1381.09521484375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 1069.5877685546875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 9562.73828125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 953.3612670898438 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 5319.22802734375 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 2270.462890625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 2973.43701171875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 2319.861328125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 1657.5947265625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 5053.16162109375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 1290.1834716796875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 251213.1875 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 855.7034912109375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1712.7574462890625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 2475.614501953125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 2610.869384765625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 1229.1993408203125 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 1527.9024658203125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 1055.508544921875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 1536.4078369140625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8241, loss_val: nan, pos_over_neg: 2183.315185546875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 1819.6864013671875 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 1590.814208984375 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 1124.2032470703125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8231, loss_val: nan, pos_over_neg: 1780.478271484375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 432.7210998535156 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 1524.92724609375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 2685.72021484375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8454, loss_val: nan, pos_over_neg: 1043.9471435546875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 826.6189575195312 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 2040.1737060546875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1256.52783203125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1131.8607177734375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 1273.167724609375 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 6384.00341796875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 829.2600708007812 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 3262.757568359375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 857.2152099609375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 957.7610473632812 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 949.5421142578125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 903.1853637695312 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 2048.41162109375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 1965.901611328125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8381, loss_val: nan, pos_over_neg: 3658.853759765625 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 1224.573974609375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 1555.9725341796875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 1207.4940185546875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8367, loss_val: nan, pos_over_neg: 1015.4581909179688 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.8277, loss_val: nan, pos_over_neg: 1192.618896484375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8272, loss_val: nan, pos_over_neg: 1493.6177978515625 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 855.3773193359375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 839.56689453125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 678.2215576171875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 912.8176879882812 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 1224.812744140625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: 2728.108642578125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 1864.5848388671875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 6344.6220703125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 1086.114990234375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 1110.6395263671875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 3885.3876953125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 2830.548828125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.823, loss_val: nan, pos_over_neg: 1163.6470947265625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 466.2599182128906 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8358, loss_val: nan, pos_over_neg: 769.7616577148438 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 964.4031982421875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.829, loss_val: nan, pos_over_neg: 1153.53515625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/300000 [2:42:20<101761:22:17, 1221.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Iter: 0/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 517.5589599609375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 579.0269165039062 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 519.8887939453125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 815.5110473632812 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8373, loss_val: nan, pos_over_neg: 1181.8153076171875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 1608.9056396484375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 1737.9708251953125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.829, loss_val: nan, pos_over_neg: 759.5174560546875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 452.32623291015625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 524.4247436523438 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 1023.4647216796875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 568.506591796875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 1587.258056640625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 1000.1834716796875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 905.7734985351562 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 952.4957275390625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 1488.7830810546875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 686.6911010742188 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 1106.8143310546875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 448.60504150390625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8209, loss_val: nan, pos_over_neg: 1021.7305297851562 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8198, loss_val: nan, pos_over_neg: 1479.129150390625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 1708.08544921875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1164.3150634765625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8384, loss_val: nan, pos_over_neg: 501.2030944824219 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 821.1290283203125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 1424.2874755859375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 1231.8868408203125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 1271.27197265625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 3268.97900390625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 1210.770751953125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1490.017822265625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 996.4209594726562 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 831.9703979492188 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1085.8243408203125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 1710.5517578125 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 1741.9383544921875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8317, loss_val: nan, pos_over_neg: 1182.1878662109375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 1091.8980712890625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 1013.3361206054688 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 1097.0220947265625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.829, loss_val: nan, pos_over_neg: 1833.5179443359375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 970.1388549804688 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 908.3738403320312 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 1527.1160888671875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 3713.226806640625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8303, loss_val: nan, pos_over_neg: 1002.7662963867188 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 1350.9642333984375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8348, loss_val: nan, pos_over_neg: 946.3936157226562 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 2767.929443359375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 1036.352294921875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 465.76824951171875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 1233.4478759765625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 642.1516723632812 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 1268.071044921875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 1585.4837646484375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 1540.2589111328125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8385, loss_val: nan, pos_over_neg: 841.6671752929688 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 1201.715087890625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 1285.012451171875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 1505.6329345703125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 1093.800048828125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 13041.5556640625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 7378.42578125 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 3719.414306640625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.83, loss_val: nan, pos_over_neg: -10275.8359375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 710.7628173828125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 681.9032592773438 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8228, loss_val: nan, pos_over_neg: 1237.914306640625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 996.6409912109375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8225, loss_val: nan, pos_over_neg: 48300.58203125 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 10307.873046875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 788.09765625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 5744.2060546875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 5768.9658203125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 3378.9755859375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 8219.5234375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 1156.929443359375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 936.0974731445312 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 638.6007690429688 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 505.7452087402344 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 1935.3756103515625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 4793.634765625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 1347.7156982421875 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 2764.791259765625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8271, loss_val: nan, pos_over_neg: 4849.3212890625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 2893.601806640625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 1916.1798095703125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 3909.74755859375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 1683.8857421875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 936.6182861328125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 952.0680541992188 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 973.3963623046875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 944.804443359375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 813.4931030273438 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 595.38427734375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 2529.684326171875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1399.5233154296875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 2614.8173828125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 908.80322265625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8394, loss_val: nan, pos_over_neg: 669.80615234375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 1867.825927734375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 1100.1444091796875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 1582.431640625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 1550.1439208984375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 4426.49609375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8334, loss_val: nan, pos_over_neg: 3641.882568359375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 64570.015625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 686.9468383789062 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 4581.35009765625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 1537.224853515625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 2592.467041015625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 994.225341796875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 3288.056884765625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 743.179443359375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 1101.3343505859375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 647.8855590820312 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 6539.568359375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8266, loss_val: nan, pos_over_neg: 18801.681640625 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8338, loss_val: nan, pos_over_neg: 781.0001831054688 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 7954.56494140625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 1899.86328125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 2087.241455078125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 2041.374755859375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 2738.51953125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 1313.7398681640625 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8453, loss_val: nan, pos_over_neg: 1387.9622802734375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 946.7952880859375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 1443.090087890625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 1265.0062255859375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 703.76708984375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 2132.165283203125 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 2824.19970703125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8409, loss_val: nan, pos_over_neg: 1106.7989501953125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8336, loss_val: nan, pos_over_neg: 1251.0943603515625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8307, loss_val: nan, pos_over_neg: 1233.095458984375 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss — Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix — Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-Transfer—L2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-Transfer—L2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}—C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE — RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "#                                                     # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "#                                                     # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAENCAYAAAAVPvJNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyGElEQVR4nO3dd3hUZfrG8e9LEgiQ0DuhhBJ6D00soIBgBXSxsXaxt3Vddf256667K7sqlrVQXGworiuCqKAgwiIiQugBAoQeQgshAULaJO/vjxPWGAZIYM7MZHJ/rmsuM3PmZJ7XGebOac9rrLWIiIiUVCnQBYiISHBSQIiIiFcKCBER8UoBISIiXikgRETEKwWEiIh45WpAGGOGGWM2GWOSjTFPelle2xgzwxiz1hizzBjTudiyHcaYdcaY1caYBDfrFBGRkxm3roMwxoQBm4EhQAqwHLjBWruh2HNeAI5Za/9kjGkPvGGtvaRo2Q4g3lqb5kqBIiJyWm5uQfQBkq2126y1ecDHwNUlntMRmA9grU0CWhpjGrpYk4iIlFK4i7+7KbC72P0UoG+J56wBRgGLjTF9gBZADLAfsMBcY4wFJlprJ3l7EWPMWGAsQPXq1Xu1b9/ep4MQEQllK1asSLPW1ve2zM2AMF4eK7k/axzwqjFmNbAOWAV4ipYNsNamGmMaAPOMMUnW2kUn/UInOCYBxMfH24QEHa4QESktY8zOUy1zMyBSgGbF7scAqcWfYK09AtwGYIwxwPaiG9ba1KL/HjDGzMDZZXVSQIiIiDvcPAaxHGhrjIk1xlQGrgdmFX+CMaZW0TKAO4FF1tojxpjqxpjooudUB4YCiS7WKiIiJbi2BWGt9RhjHgC+AcKAKdba9caYe4qWTwA6AO8bYwqADcAdRas3BGY4GxWEAx9Za792q1YRETmZa6e5BoK3YxD5+fmkpKSQk5MToKr8IzIykpiYGCIiIgJdioiUI8aYFdbaeG/L3DwGERRSUlKIjo6mZcuWFG2RhBxrLYcOHSIlJYXY2NhAlyMiISLkW23k5ORQt27dkA0HAGMMdevWDfmtJBHxr5APCCCkw+GEijBGETnZ/iM5zN+435XfXSECIpAyMjJ48803y7zeZZddRkZGhu8LEpGQcPBoLs99uYEL/7GA33yyhpz8Ap+/Rsgfgwi0EwFx3333/eLxgoICwsLCTrne7Nmz3S5NRMqh9Kw8Ji7ayvtLdpJXUMioHk156JK2REac+vvkbCkgXPbkk0+ydetWunfvTkREBFFRUTRu3JjVq1ezYcMGRowYwe7du8nJyeHhhx9m7NixALRs2ZKEhASOHTvG8OHDOf/881myZAlNmzbl888/p2rVqgEemYj4U+bxfN5evI0pi7dzPL+Aq7s14eHBccTWq+7aa1aogPjTF+vZkHrEp7+zY5Ma/PHKTqdcPm7cOBITE1m9ejULFy7k8ssvJzEx8X9nG02ZMoU6deqQnZ1N7969ueaaa6hbt+4vfseWLVuYNm0akydPZvTo0UyfPp0xY8b4dBwiEpyO5uQzZfEO3l68jaM5Hi7v0phHBrelbcNo11+7QgVEMOjTp88vTkV97bXXmDFjBgC7d+9my5YtJwVEbGws3bt3B6BXr17s2LHDX+WKSIBk5Xp478cdTFq0jYzj+Qzt2JBHh8TRoXENv9VQoQLidH/p+0v16j9vDi5cuJBvv/2WH3/8kWrVqjFw4ECvp6pWqVLlfz+HhYWRnZ3tl1pFxP9y8guYunQnby3cyqGsPAa1q89vhrSjS0xNv9dSoQIiEKKjozl69KjXZZmZmdSuXZtq1aqRlJTE0qVL/VydiASLXE8B037axRsLt3LwaC7nt6nHo0Pi6NWidsBqUkC4rG7dugwYMIDOnTtTtWpVGjb8eT6kYcOGMWHCBLp27Uq7du3o169fACsVkUDI8xTynxW7ef27ZPZm5tAntg6v39CDvq3qnnlll4V8L6aNGzfSoUOHAFXkXxVprCLlnaegkM9W7eG1+VtIOZxNz+a1eGxoO85r7d/ODxW6F5OISDApKLTMWrOHV7/dwo5Dx+kaU5PnRnRmYFz9oOuIoIAQEfGDwkLL7MS9vPLtFpIPHKN9o2gm/boXQzo2DLpgOEEBISLiImstczfs5+V5m0nad5S2DaJ486aeDOvUiEqVgjMYTlBAiIi4wFrLwk0HGT9vM+v2ZBJbrzqvXt+dK7o2ISzIg+EEBYSIiA9Za1mcnMb4eZtZtSuDZnWq8uKvujGiexPCw8pXf1QFhIiIjyzddojxczezbEc6TWpG8vyoLlzbK4aIchYMJ5TPqsuRs233DfDKK69w/PhxH1ckIr62Ymc6N729lOsnLWXHoSz+fHUnFjw+kBv6NC+34QAKCNcpIERC15rdGdwyZRnXvPUjm/Yd5f8u78Ci3w3i5v4tqRLu+/bb/qZdTC4r3u57yJAhNGjQgE8++YTc3FxGjhzJn/70J7Kyshg9ejQpKSkUFBTwzDPPsH//flJTUxk0aBD16tVjwYIFgR6KiBRZn5rJy/O28O3G/dSuFsGTw9tzc/8WVKscWl+poTWaM5nzJOxb59vf2agLDB93ysXF233PnTuXTz/9lGXLlmGt5aqrrmLRokUcPHiQJk2a8NVXXwFOj6aaNWsyfvx4FixYQL169Xxbs4iclc37j/LyvM3MSdxHjchwHhsSx60DWhIdGRHo0lxRsQIiwObOncvcuXPp0aMHAMeOHWPLli1ccMEF/Pa3v+WJJ57giiuu4IILLghwpSJS3NaDx3j12y18sTaV6pXDeejiNtxxQStqVg3NYDihYgXEaf7S9wdrLU899RR33333SctWrFjB7Nmzeeqppxg6dCh/+MMfAlChiBS381AWr81PZsaqFKqEh3HPRa0Ze0EralevHOjS/KJiBUQAFG/3femll/LMM89w0003ERUVxZ49e4iIiMDj8VCnTh3GjBlDVFQU77777i/W1S4mEf/ak5HNP+dv4dMVKYRVMtw+IJZ7BramXlSVM68cQhQQLive7nv48OHceOON9O/fH4CoqCimTp1KcnIyjz/+OJUqVSIiIoK33noLgLFjxzJ8+HAaN26sg9QifrAvM4c3FiTz8fJdGAw39W3OfYPa0LBGZKBLCwi1+w4hFWmsIr508Gguby3cytSfdlJYaBnduxkPDGpDk1pVA12a69TuW0TEi/SsPCYu2sr7S3aSV1DIqB5NeeiStjSrUy3QpQUFBYSIVDjZeQW8uTCZKYu3czy/gBHdnWCIrVf9zCtXIAoIEalQDmflccd7y1m5K4PLuzbm0cFtadMgOtBlBaUKERDW2qCdkMNXQulYkohbdqcf55Z3lpFyOJsJY3oyrHPjQJcU1EI+ICIjIzl06BB16/p3nld/stZy6NAhIiMr5pkWIqWxPjWTW99ZTm5+AVPv6Euf2DqBLinohXxAxMTEkJKSwsGDBwNdiqsiIyOJiYkJdBkiQWlJchpjP1hBdGQ4H957HnENtUupNEI+ICIiIoiNjQ10GSISIJ+v3sNv/7OGVvWiePf23jSuGfqnrvpKyAeEiFRckxdt46+zN9Intg6Tb44P+d5JvqaAEJGQU1ho+dvsjby9eDuXdWnE+NHdiYwo//Mz+JsCQkRCSq6ngMf/s5ZZa1K59byWPHNFR8IqheYJKm5zdUY5Y8wwY8wmY0yyMeZJL8trG2NmGGPWGmOWGWM6l3ZdEZGSjuTkc9s7y5m1JpUnh7fnj1cqHM6FawFhjAkD3gCGAx2BG4wxHUs87ffAamttV+Bm4NUyrCsi8j/7j+QwesKPLNuezvjR3bjnotYhe2q7v7i5BdEHSLbWbrPW5gEfA1eXeE5HYD6AtTYJaGmMaVjKdUVEAEg+cIxRby5hV/pxptzam1E9dcq3L7gZEE2B3cXupxQ9VtwaYBSAMaYP0AKIKeW6FK031hiTYIxJCPVrHUTkZCt2HubaCUvI9RTw77H9uTCufqBLChluBoS3bbuS/SDGAbWNMauBB4FVgKeU6zoPWjvJWhtvrY2vX18fDJGKZN6G/dw4eSm1qkbw2b0D6BJTM9AlhRQ3z2JKAZoVux8DpBZ/grX2CHAbgHF2Fm4vulU707oiUrF99NMu/m/mOro0rcmUW3tTt4LN9uYPbm5BLAfaGmNijTGVgeuBWcWfYIypVbQM4E5gUVFonHFdEamYrLWMn7eZ389Yx0Vx9Zk2tp/CwSWubUFYaz3GmAeAb4AwYIq1dr0x5p6i5ROADsD7xpgCYANwx+nWdatWESkfPAWF/N/MRD5evptf9Yrhb6O6EBHm6tn6FVrITzkqIqHheJ6HBz9axfykAzwwqA2PDY3Taaw+oClHRaRcS8/K4/Z3l7M2JYPnRnTm1/1aBLqkCkEBISJBbXf6cW6Zsow9Gdm8NaYXl3ZqFOiSKgwFhIgErcQ9mdz27nLyPIV8eGdf4ltqkh9/UkCISFBavCWNe6auoEZkOB/d05+2muTH7xQQIhJ0Zq5yJvlp0yCKd2/rQ6Oamk43EBQQIhI0rLVM/n4bf5udRL9WdZj4a03yE0gKCBEJCoWFlr98tZEpP2zn8q6NGT+6G1XCNclPICkgRCTgcj0F/OaTNXy1di+3DWjJM5d3pJLmcQg4BYSIBNSRnHzGvp/A0m3pPDW8PWMvbKUL4IKEAkJEAmZfZg63vrOM5APHeOW67ozo4bWrvwSIAkJEAiL5wFFumbKcjON5vHNbby5oq3b9wUYBISJ+l7AjnTveSyAirBL/vrs/nZtqHodgpIAQEb/6Zv0+Hpq2iia1qvLebX1oXrdaoEuSU1BAiIjfTF26kz98nkiXmFpMuSVe8zgEOQWEiLjuxCQ///wumYvbN+D1G3tQrbK+foKd3iERcVV+QSFPz1jHJwkpjI6P4W8juxCuSX7KBQWEiLjmeJ6H+z9cyYJNB3no4jY8OkST/JQnCggRccWhY7nc/l4C61Iy+OvIztzUV5P8lDcKCBHxuV2HjnPLO8tIzchmwpheDNUkP+WSAkJEfCpxTya3vrMcT2EhH93Vl14tNMlPeaWAEBGfWbT5IPdOXUGtapX5+Pa+tGmgSX7KMwWEiPjEjFUpPP6ftbRpEMV7t/ehYQ1N8lPeKSBE5JxYa5m4aBvj5iTRv1VdJt7cixqRmuQnFCggROSsFRRanvtyA+8u2cEVXRvzkib5CSkKCBE5Kzn5Bfzmk9XMXrePO86P5enLOmiSnxCjgBCRMsvMdib5+Wl7Ok9f1oG7LmwV6JLEBQoIESmTfZk53DJlGdvSjvHq9d25ursm+QlVCggRKbXN+49y65RlHMnx8O5tfRjQpl6gSxIXKSBEpFQWbT7IAx+tpEpEGP++ux+dmmiSn1CngBCR07LWMvl75zTWuIbRTL45nmZ1NMlPRaCAEJFTyskv4Mnpa5m5OpXLujTihWu7Ub2KvjYqCr3TIuLVnoxs7v4ggfWpR/jt0DjuH9RGrborGAWEiJxk2fZ07p26glxPIZN/Hc/gjg0DXZIEgAJCRH5h6tKdPDtrPc3qVGPyzb3UcK8CU0CICAB5nkL+OGs905btYmC7+rx6fQ9qVlVPpYpMASEiHDiaw31TV5Kw8zD3DmzNb4e2I0xtMyo8BYRIBbc2JYOx768gIzuPf97Qgyu7NQl0SRIkKrn5y40xw4wxm4wxycaYJ70sr2mM+cIYs8YYs94Yc1uxZTuMMeuMMauNMQlu1ilSUX22MoVrJ/xIWCXD9HvPUzjIL7i2BWGMCQPeAIYAKcByY8wsa+2GYk+7H9hgrb3SGFMf2GSM+dBam1e0fJC1Ns2tGkUqKk9BIePmJPH24u30a1WHN27sSd2oKoEuS4KMm7uY+gDJ1tptAMaYj4GrgeIBYYFo45xcHQWkAx4XaxKp8DKO5/HAR6tYnJzGree15OnLOxAR5urOBCmn3AyIpsDuYvdTgL4lnvM6MAtIBaKB66y1hUXLLDDXGGOBidbaSd5exBgzFhgL0Lx5c99VLxKCkvYdYez7K9iXmcM/runK6N7NAl2SBDE3/2zwdgqELXH/UmA10AToDrxujKlRtGyAtbYnMBy43xhzobcXsdZOstbGW2vj69ev75PCRULR14l7GfXmEnLyC5g2tp/CQc7IzYBIAYp/AmNwthSKuw34zDqSge1AewBrbWrRfw8AM3B2WYlIGRUWWsbP3cQ9U1cS1zCaLx48n14tage6LCkH3AyI5UBbY0ysMaYycD3O7qTidgGXABhjGgLtgG3GmOrGmOiix6sDQ4FEF2sVCUlHc/IZ+8EKXvsumV/1iuHjsf1oWCMy0GVJOeHaMQhrrccY8wDwDRAGTLHWrjfG3FO0fALwHPCuMWYdzi6pJ6y1acaYVsCMosZg4cBH1tqv3apVJBRtT8virvcT2J6WxbNXduSW81qq2Z6UibG25GGB8is+Pt4mJOiSCZGFmw7w4LRVhFcyvHFjT87TzG9yCsaYFdbaeG/LdCW1SAix1jJx0Tb+/nUS7TS5j5wjBYRIiMjOK+CJ6WuZtSaVy7s05oVfdaVaZf0Tl7OnT49ICEg5fJy7P1jBhr1HePzSdtw3sLWON8g5U0CIlHNLtx3ivg9Xku8p5F+3xHNxe03uI76hgBApp6y1TF26kz99sYHmdasx+eZ4WtePCnRZEkJKdR2EMWakMaZmsfu1jDEjXKtKRE4r11PAU5+t45nP13NhXH1m3j9A4SA+V9oL5f5orc08ccdamwH80ZWKROS0DhzJ4YZJS/l4+W7uH9SayTfHUyNSM7+J75V2F5O3INHuKRE/W707g7s/SOBItoc3buzJ5V0bB7okCWGl/ZJPMMaMx5nfwQIPAitcq0pETvLpihR+P2MdDaKrMP3e8+jYpMaZVxI5B6XdxfQgkAf8G/gEyMaZ7EdEXOYpKOTPX2zgt/9ZQ6/mtZn1wPkKB/GLUm1BWGuzgJOmDBURdx3OyuP+j1ayZOshTe4jflfas5jmGWNqFbtf2xjzjWtViQgb9x7hqjcWk7DjMP+4tivPXtVJ4SB+VdpjEPWKzlwCwFp72BjTwJ2SRGT2ur089skaoiPD+ffd/ejRXPM3iP+VNiAKjTHNrbW7AIwxLTl5djgROUeFhZbx8zbz+oJkejSvxcQxvWig+RskQEobEE8Di40x/y26fyFF80CLiG8cycnn0Y9XMz/pANfFN+PPIzpRJTws0GVJBVbag9RfG2PicUJhNfA5zplMIuIDWw8eY+z7Cew4dJw/XdWJm/u3ULM9CbhSBYQx5k7gYZx5pVcD/YAfgYtdq0ykgliQdICHpq0iIrwSU+/oS//WdQNdkghQ+usgHgZ6AzuttYOAHsBB16oSqQCstby5MJnb31tOszrVmPXAAIWDBJXSHoPIsdbmGGMwxlSx1iYZY9q5WplICDue5+F3n67ly7V7uaJrY164thtVK+t4gwSX0gZEStF1EDOBecaYw0CqW0WJhLLd6ccZ+8EKkvYd4Ylh7bnnolY63iBBqbQHqUcW/fisMWYBUBP42rWqRELUj1sPcf9HK8kvKGTKLb0Z1F6XE0nwKnNHVmvtf8/8LBEpzlrLe0t28NxXG2lZNLlPK83fIEFOLbtFXJbrKeCZmYl8kpDC4A4NePm67kRr/gYpBxQQIi5am5LBU5+tY33qER68uA2PDo6jUiUdb5DyQQEh4oIjOfm89M0m3l+6k3pRVZj4615c2qlRoMsSKRMFhIgPWWv5Yu1envtyA2nHcrmlf0t+MzROU4JKuaSAEPGRHWlZPPN5It9vSaNz0xr865Z4usbUCnRZImdNASFyjnI9BUz87zZeX5BM5bBKPHtlR37dvyVhOtYg5ZwCQuQcLElO4/9mJrItLYvLuzbmD1d0pKHac0uIUECInIWDR3P52+yNzFi1h+Z1qvHubb0Z2E4XvUloUUCIlEFhoWXa8l38fU4S2fkFPHhxG+4f1IbICPVRktCjgBAppQ2pR3h65jpW7cqgX6s6/GVEZ9o0iA50WSKuUUCInEFWroeX523mnSU7qFU1gvGjuzGyR9PTN9jz5ELGbsjYARm7oHoDaHMJRFT1W90i50oBIXIK1lrmbtjPs7PWszczhxv6NOOJYe2pVa0yFHjgSIrz5X94J2Ts/OXPR/ee/AsrR0G7y6DzNdD6Ygiv7P9BiZSBAkLEi5T0Y7wy43t2JG9gVO2j3NgfmtrZ8ElRAGTuAVvw8wqmEtRoCrVaQKtBULuF83Ot5s7tUDIkToeNX8C6TyCyJrS/EjqPhNiLIEwX0knwMdbaQNfgM/Hx8TYhISHQZUh5YC1kpTl/9WfsKPrLfxeFh3dyZG8y1Y6nUtl4frlOVKOiL/7mzpd/8Z9rxpTuS96TB9sWwvrPIOkryD0CVetAx6ug0yhoeT5U0gFv8R9jzAprbby3ZdqCkNCVneH8tV/05f/Ln3dBftYvnp5fpQ7bPHXYkteY8Dr96dezB7WatHWCoGaMb44fhFeGuKHOLT8Hts6HxM9g7X9gxbvOsYqOVzu7oZr1hUqlnRVYxPdc3YIwxgwDXgXCgLetteNKLK8JTAWa44TVi9bad0qzrjfagqhg8rJ+ud//f8cCdsLhXZCb+cvnV6lx8l/+tVuQWaUxL/6UwwerDtGkZiTPXtWJof5urJd3HLbMdXZDbZkLnhyIbgKdRkLnUdC0F2jWOXHB6bYgXAsIY0wYsBkYAqQAy4EbrLUbij3n90BNa+0Txpj6wCagEVBwpnW9UUCEmJJnApU8GHw87ZfPD6966l1AtVtAZK1ffMlaa/l0RQrPz0kiMzufO8+P5aFL2lK9SoA3rHOPwqavnd1Qyd9CQZ4zjk4jnd1QjbspLMRnArWLqQ+QbK3dVlTEx8DVQPEveQtEG+d8wSggHfAAfUuxroSiwgLY/DX8NBG2L8L5iBSpFAG1mjlf+B2uKPbl39L5uXr9Un9xbtl/lKdnJrJsezo9m9firyO70KFxDVeGVGZVoqHrr5xbdgZsmu3shvrxDfjhVajTygmKzqOgQUeFhbjGzYBoCuwudj8F54u/uNeBWUAqEA1cZ60tNMaUZl0AjDFjgbEAzZs3903l4n/H02HVB7D8bWcLoUZTOP9RqN/u5yCIbnzO++Sz8wr453dbmLRoG9WrhPP8qC5cF98seCfxqVoLut/o3I6nO2dBJU6HxePh+xehXjsnKDqNgvpxga5WQoybAeHtX1zJ/VmXAquBi4HWwDxjzPelXNd50NpJwCRwdjGdbbESIPsSYdlE5yCtJxtaDIAhz0H7KyDMtx/PBUkH+MOsRHanZzOqZ1N+f1kH6kVV8elruKpaHeh1i3M7dgA2fA7rZ8DCcbDweWjYxTltttMoqBMb6GolBLgZEClAs2L3Y3C2FIq7DRhnnQMhycaY7UD7Uq4r5VVBPiR9CT9Ngl1LnGMHXUdDn7HQqLPPX25fZg5//nI9s9fto1X96ky7qx/9W9f1+ev4VVQD6HOXczuS6oRF4mcw/8/OrUkPJyg6jXR2y4mcBTcPUofjHGi+BNiDc6D5Rmvt+mLPeQvYb6191hjTEFgJdAMyzrSuNzpIHeSOHYSV78LyKXA01dl11Psu6DHG+evYxzwFhbz/405emrsJT6HlwYvbcNeFragSHsLXGWTsgvUznd1Qe1c7j8X0cXZDdRwBNRoHsDgJRgE5i6nohS8DXsE5VXWKtfavxph7AKy1E4wxTYB3gcY4u5XGWWunnmrdM72eAiJI7VkJyyY5X1oFedBqIPS5G+Iude2isNW7M3h6xjrWpx7hwrj6PHd1J1rUre7KawWtQ1udXVDrZ8D+RMA4u/A6j4QOV0NU/UBXKEEgYAHhbwqIIOLJc3Z7LJsIKcudPkTdbnB2idRv59rLZmbn8+I3m5j6007qR1Xhj1d24rIujU7fWK8iOLjZOW028TNI2+S0Bom90NkN1eFKV7bgpHxQQIj/HN0HCVMg4R3IOgB1WjvHFrrf4PQfcom1lllrUnnuy42kZ+Vyc/+WPDY0juhI9Tj6BWvhwAYnKBKnw+HtUCnc6R/VeRS0v9zV90mCjwJC3GUt7F7mbC1s+BwKPdB2qLMbqfXFrreL2J6WxR8+T+T7LWl0aVqTv47sTNeYWq6+Zkiw1jlOkfiZc9wicxeEVYY2Q5ywiBsGVaICXaW4TAEh7sjPcf4KXTYR9q5xWln0GAO974S6rV1/+VxPARMWbuONhclUDqvE45e2Y0y/FoQF6zUNwcxaSElwdkOtn+G0Kw+v6vSM6jTKCfzK1QJdpbhAASG+lZkCy/8FK9+D44egfnvn2ELX6/32F+cPyWk8MzORbWlZXNG1Mc9c0ZGGNSL98tohr7AQdi91tiw2zISsgxBRHdoNd7Ys2g5Ve/IQooCQc2ct7PzBaYGR9BVgnclv+ox1Dnb66SDwwaO5/PWrDcxcnUqLutX489WduShOZ+O4psADOxc7YbFxFmQfhprNoP8D0PPXULmCnRkWghQQcvbysmDtJ7BsMhxYD1VrQ8+bIf4OpwGenxQWWj5atou/f51ETn4B917UmvsGtSEyIoSvaQg2BfmwZR4s+adzgWPVOtD3HmfrUWdBlVsKCCm79O1OX6RVH0BOptPGoe9Y6PIrv8+rvD41k6dnJLJ6dwb9W9XluRGdadNAB08DatdP8MMrTiPBiGrQ61bof78zb4aUK5owSErHWti2wGmBsflr51z5Dlc6fyU27+f3rqHHcj28PG8z7/ywndrVKvPydd0Y0b2prmkIBs37QvNpcGCj02F22STn1vU6GPCwq9e6iP9oC0Kc+QfWfOwcXzi0BarVg/jbIP52qNHE7+UUFFq+WJPK379OYm9mDjf0ac4Tw9pRq1plv9cipZSxy2lHvvJ9yD8O7S53uvE26x3oyuQMtItJvEtLdv7qW/0R5B2FJj2h791Og7dw/3c5tdYyd8N+xs/dzKb9R+nQuAZ/GdGZXi1q+70WOUtZh4q2JiY6B7RbnA/nPwJtBmveiiClgJCfFRZC8jxna2HrfGcSnk4jnWCI8foZcZ21lsXJabw4dzNrdmcQW686jw6J44oujYN3ngY5vdxjztbEj6/DkT3OMazzH3EaBvq4jbucGwWEODOTrf7QORvp8HaIagS974Cet0B0w4CVtWJnOi98s4ml29JpUjOShwe35ZqeMYSHuXv1tfiJJw/W/cc5TpG2yZn4acBD0P0mv5/sIN4pICqyAxudTf41Hzv7hpv1c85G6nBVQC92Wp+ayUtzN/Nd0gHqRVXm/kFtuLFv89BuxV2RFRbC5jmw+GWneWP1+s7JD73vdGbNk4BRQFQ0BR7nH+NPE2HH9xBWxTk9te9YZ8L7ANp68Bjj523mq7V7qREZzt0Xtea2AS2pVlm7HSoEa2HnEicokudB5WjnhIh+92muigBRQFQU+Tnw0wTn+oXM3VAj5ufdSNUDO4NayuHjvPrtFqavTCEyIozbB8Ry14WtqFlVLRsqrH3rYPErTv+nSuHQ7Xo472Go1ybQlVUoCoiK4OAm+PR2Z2KYlhc4LTDaXRbwA4IHjubw5oKtfPjTTgyGMf1acN+g1uVrLmhxV/p252D2qqngyYWOV8GAR6Bpz0BXViEoIEKZtbDiXfj6Kacvzoi3nA6cAZZxPI+Ji7bx7g87yCsoZHR8DA9e3JYmtXRgUk7h2AFnC3jZ25CbCbEXOddStBqoU2RdpIAIVcfT4YuHYOMXzoQvIydAdKOAlnQs18M7i7czadE2juV5uKpbEx4ZHEdsPTV1k1LKOQIr3oEf34Rj+6BxdycoOlzp2hS1FZkCIhTt+AE+u8v5q+uSPzjdNV2emOd0cvILmLp0J28u3Ep6Vh6DOzTksaFxdGhcI2A1STnnyXXOvvvhVUjf6sxOOOAhZ+raAFzIGaoUEKGkwAP//Tt8/yLUbgnX/Cug+2rzCwr5T0IK//xuC3szczi/TT0eGxpHj+a6+ll8pLDA2Upe/LIzA15UI+h/H/S6DSL1B8i5UkCEisM7na2G3T9Btxvhsn9AleiAlHKiX9LL325m56Hj9Ghei8eHtuO8NvUCUo9UANbC9v86QbFtIVSp6Zyl1+9eiGoQ6OrKLXVzDQWJn8EXjwDW2Wrocm1AyijZL6l9o2j+dUs8F7dvoC6r4i5jnAPWrQZC6irnFNnFLztNAnuMgfMehDqxAS4ytGgLItjlZcGc3zmnAMb0hmvednYt+Zm3fkm/GRLH5eqXJIGUlgxLXoM106DQ4/QVG/AINO4a6MrKDe1iKq9SV8P0O+DQVrjgMRj4ZEDaY5Tsl/TI4DhG9WyqfkkSPI7shaVvQsI7TmfiNoOdM59aDNApsmeggChvCgudD/u3zzo9a0ZNdOZ99rOS/ZIeGNSGG9QvSYJZdgYk/AuWvgVZB52t7gGPOBeNBvAsv2CmgChPjh2AmfdC8rfOpCtXv+73+X7VL0nKvfxsp3vxD69Bxk6oF+cERZdfQbgmnipOAVFeJH8LM+5xZni79K8Qf4dfN49TDh/ntflb+HSF+iVJiCjwwIaZzgHt/eugRlPnmqGeN0MVzWsOCojg58mF+X92+tE06OicpdSwo99e/kS/pI9+2gUGxvRVvyQJMdZC8nznrKediyGyljOlbvP+0KAD1IypsMcqdJprMEvb4jTZ27cWet8FQ5/z20Qq6pckFYYx0Hawc9u9HH54BRaP/3l55Who0B7qt3f+SGvQwblFNaywwQEKiMCx1jl1dc7vIDwSrp8G7S/zy0urX5JUaM16w/UfOr3MDiY5k2od2Oj8nPQVrPrg5+dWrQ31O/wcGA06OPcD3D7fXxQQgZCdAV8+AutnOK25R02CGk1cf9kT/ZLeWriVQ1l5DOno9Etq30jtCqQCqlYHWpzn3E6w1jn76X+hUfTfdZ86HWZPqN7g5NBo0B4ia/p/HC5SQPjbrp9g+p3ORO6X/ME5s8LlDpXqlyRSSsY4bTuiGkCri35+3Fo4kvpzYBxIggMbYOX7zlS+J9SIcYLif6HRAeq3c1rxl0MKCH8pLIDvX4KF45wDYnfMhRivx4V895KFli/WpjJ+ntMvqWfzWrw0uhvntVa/JJEyMQZqNnVubQb//HhhIWTu+nmL48RWx/bvoSD3xMpQu0WxXVUdnRCpFxf0XWkVEP6QmQKfjYWdP0CX0XD5S652obTWMm/Dfl4q6pfUoXEN9UsScUOlSk7rm9otod3wnx8v8MDhHc5WxsGirY0DG515uAs9znNMGNRp9ctdVQ06Oo8FoGOCNwoIt22YBbMedD4UIyc68+66aPGWNF6Yu4k1uzNoVa86/7yhh/olifhbWLgzt3a9NsBVPz/uyYNDycV2VW2E/esh6Uuwhc5zKkU4Wxcld1XVbun3CZMUEG7JOw7fPOVMB9qkp9Nkr25r114ucU8m4+YksTg5jSY1I/nHNV3VL0kk2IRXdq5xKnmdU342pG3++djGgY2QshwSpxdbtyrUj3O2MoqfjuviNRwKCDfsWwef3gFpm2DAwzDo/1y7vH93+nFenLuJz1enUrtaBM9c0ZEx/dQvSaRciagKjbs5t+Jyj8HBTb/cVbXtv0732hMqRzvda2/9yudB4WpAGGOGAa8CYcDb1tpxJZY/DtxUrJYOQH1rbboxZgdwFCgAPKe60i+oWAvLJsHcZ6BqLfj1TGg9yJWXSs/K4/Xvkvlg6Q7CKhnuH9Sauy9qTY3I4Nh3KSI+UCUKYno5t+KyD/8cHAeSnDOpXNiKcK3VhjEmDNgMDAFSgOXADdbaDad4/pXAo9bai4vu7wDirbVppX3NgLbayEqDz++HzV9D20thxJtQ3fdnC2XnFTDlh+1MWLiVrDwPo+Ob8cjgOBrVjPT5a4lI6AtUq40+QLK1dltRER8DVwNeAwK4AZh2imXBbesCp8le9mEY/g/oM9bnae4pKGT6yhTGz9vM/iO5DO7QkCeGtaNtw8BMOSoioc/NgGgK7C52PwXo6+2JxphqwDDggWIPW2CuMcYCE621k06x7lhgLEDz5s19UHYZePJgwV+clsL14mDMdGjU2acvYa1l/sYD/P3rJLYcOEaP5rX45w096RPr3xbgIlLxuBkQ3v6EPtX+rCuBH6y16cUeG2CtTTXGNADmGWOSrLWLTvqFTnBMAmcX07kWXWqHtjqzvaWugl63wqXPQ+VqPn2JlbsOM252Est2pNOqXnUmjOnJpZ0a6VoGEfELNwMiBWhW7H4MkHqK515Pid1L1trUov8eMMbMwNlldVJABMSaj+Grx6BSOIz+ADpedeZ1ymDbwWO88M0m5iTuo15UFf4yojPX9W5GhE5ZFRE/cjMglgNtjTGxwB6cELix5JOMMTWBi4AxxR6rDlSy1h4t+nko8GcXay2dnCNOMKz7xJnrdtQk5xxkHzl4NJdX529m2rLdRIZX4tHBcdx5QSzVq+hsZBHxP9e+eay1HmPMA8A3OKe5TrHWrjfG3FO0fELRU0cCc621WcVWbwjMKNqVEg58ZK392q1aSyUlwdmllLEbBj0NFzzms6saj+V6mLxoG5O/30aep5Cb+jbnwYvbUj86uPu0iEho04xyZ1JY4EwusuBvEN3EuSK6uddj7WWWX1DIx8t28er8LaQdy+PyLo357aXtNC+DiPiNZpQ7W0dSnSZ7O76HTqPgipedC+DOkbWWOYn7eOGbTWxPy6JvbB3evqUD3Zud++8WEfEVBcSpJM12Lnzz5MBVr0OPMT65tuGnbYd4fk4Sq3dnENcwiim3xjOonbqsikjwUUCUlJ/ttMpYPhkadYVrp0C9tuf8azfvP8rf5yQxP+kAjWpE8o9ru3JNzxjC1GVVRIKUAqK4Axvh09ud/ib9H3BmfDvHCT32Zmbz8rzNfLoihepVwvndsHbcPiCWyAg10xOR4KaAAKfJXsK/4JunoUo03DQd2g4+83qnkZmdz4T/bmXK4u1YC7cPiOX+QW2oXd2drq4iIr6mgMg5AjPvdSbsaDMYRrzlzEd7lnI9BXzw405eX5BMxvF8RnRvwmND29Gsjm+vshYRcZsCIqKq02Tv0r9B33udKQTPQmGhZdaaVF6cu4mUw9lc0LYeTwxrT+emNX1csIiIfyggwiLgli/POhgAvt9ykHFzklifeoROTWrw/KguXNC2vg+LFBHxPwUEnHU4JO7J5O9fJ/H9ljRialflleu6c1W3Jpr/WURCggLiLOxOP85Lczcxc3UqtTTNp4iEKAVEGRzOyuP1Bcl88ONOjIH7BjrTfNasqmk+RST0KCBKISffmebzrYVbycr18KtezXh0iKb5FJHQpoA4jYJCy/QVzjSf+47kMLhDA343rD1xmuZTRCoABYQX1lq+S3Km+dy8/xjdm9Xi1eu707dV3UCXJiLiNwqIElbtOszzc5JYtj2d2HrVeeumngzrrGk+RaTiUUAU2Z6WxQvfJDF73T7qRVXmuRGduV7TfIpIBVbhAyIr18O4OUlMW7aLyuGVePiSttx1YSuiNM2niFRwFf5bsEp4JZbvSOf6Ps146JK2NIjWmUkiIqCAIDysErMeOJ/K4dqVJCJSnL4VQeEgIuKFvhlFRMQrBYSIiHilgBAREa8UECIi4pUCQkREvFJAiIiIVwoIERHxylhrA12DzxhjDgI7iz1UE8g8zc/FH6sHpJ3lSxf/PWV9jrfHSz52uvvleSxn+vlcxnG6OkuzPJjGci7vibdlFeXzVfJ+ybG4/fk63XOC6fPVwlpb3+sSa23I3oBJp/u5xGMJvnidsj7H2+MlHzvd/fI8llK8P2c9jtKM5XTLg2ks5/KelPXzFEqfrzONxe3Ply/H4va/lVPdQn0X0xdn+Ln4Y756nbI+x9vjJR873f3yPJbS/HwuzvR7Trc8mMZyLu+Jt2UV5fNV8n55Hovb/1a8CqldTOfCGJNgrY0PdB2+ECpjCZVxgMYSjEJlHODeWEJ9C6IsJgW6AB8KlbGEyjhAYwlGoTIOcGks2oIQERGvtAUhIiJeKSBERMQrBYSIiHilgBAREa8UEKVgjBlojPneGDPBGDMw0PWcC2NMdWPMCmPMFYGu5VwYYzoUvR+fGmPuDXQ958IYM8IYM9kY87kxZmig6zlbxphWxph/GWM+DXQtZ6Po38Z7Re/FTYGu51z46r0I+YAwxkwxxhwwxiSWeHyYMWaTMSbZGPPkGX6NBY4BkUCKW7Wejo/GAfAE8Ik7VZaOL8Zird1orb0HGA0E7Fx2H41lprX2LuBW4DoXyz0lH41jm7X2DncrLZsyjmsU8GnRe3GV34s9g7KMxWfvhRuXZwfTDbgQ6AkkFnssDNgKtAIqA2uAjkAX4MsStwZApaL1GgIfluNxDAaux/kiuqI8vydF61wFLAFuLO9jKVrvJaBnCIzj00C9H+c4rqeA7kXP+SjQtZ/LWHz1XoQT4qy1i4wxLUs83AdIttZuAzDGfAxcba19HjjdrpfDQBVXCj0DX4zDGDMIqI7zjyHbGDPbWlvobuUn89V7Yq2dBcwyxnwFfORiyafko/fFAOOAOdbalS6X7JWP/50EjbKMC2fvQAywmiDcu1LGsWzwxWsG3f8EP2kK7C52P6XoMa+MMaOMMROBD4DXXa6tLMo0Dmvt09baR3C+TCcHIhxOo6zvyUBjzGtF78tst4srozKNBXgQZ+vuWmPMPW4WVkZlfU/qGmMmAD2MMU+5Xdw5ONW4PgOuMca8hcs9jnzI61h89V6E/BbEKRgvj53yknJr7Wc4H55gU6Zx/O8J1r7r+1LOWVnfk4XAQreKOUdlHctrwGvulXPWyjqOQ0AwBdypeB2XtTYLuM3fxZyjU43FJ+9FRd2CSAGaFbsfA6QGqJZzESrjAI0lGIXKOEoKpXG5OpaKGhDLgbbGmFhjTGWcA7ezAlzT2QiVcYDGEoxCZRwlhdK43B1LoI/M++HI/zRgL5CPk7Z3FD1+GbAZ5wyApwNdZ0UZh8YSnLdQGUcojysQY1E3VxER8aqi7mISEZEzUECIiIhXCggREfFKASEiIl4pIERExCsFhIiIeKWAEHGRMaaRMeZjY8xWY8wGY8xsY0xcoOsSKQ0FhIhLirq0zgAWWmtbW2s7Ar/HaRsvEvQqarM+EX8YBORbayeceMBauzpw5YiUjbYgRNzTGVgR6CJEzpYCQkREvFJAiLhnPdAr0EWInC0FhIh7vgOqGGPuOvGAMaa3MeaiANYkUmrq5iriImNME+AVnC2JHGAH8Ii1dksAyxIpFQWEiIh4pV1MIiLilQJCRES8UkCIiIhXCggREfFKASEiIl4pIERExCsFhIiIePX/t7lzU5SH738AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.69it/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.10it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.10it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAALFCAYAAADZd8u9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd3gUxRvA8e8QIAkt9BpC7wgCiijyEwSlF0V6kSJFUUC6gFICgqiAIggoSJeqiIAUaSpNVGronRCqJIGQENr8/ti7M5fcJYFckr3j/TzPPcntzezO7u29997s7K7SWiOEEEIIIYQnSJPaDRBCCCGEEMJVJLkVQgghhBAeQ5JbIYQQQgjhMSS5FUIIIYQQHkOSWyGEEEII4TEkuRVCCCGEEB5DklshhBBCCOExJLkVws0opX5RSr2Z2u0wA6VUYaWUVkqlTUTZTkqpP1KiXcLzKaWqK6VOKKUilFLNknlZI5VSC5JzGa6mlDqrlKqT2u0QTyZJboWpWQJklOUL5LJSao5SKlMS5tfJkgwNjDU9WClVMxH14yRTSql8SqlVSqkQy2uFY9XJrpRaopS6bnksVEpledx10FrX11rPfdz6SqmqSqm1SqkwpdQNpdSfSqnOltdqKqWCndSbo5S6a3kvbiilNiqlSj9uO8xIKZVbKfW95b0MV0ptV0o9F6tMW6XUOaXUbaXUSqVU9hivfWZJeG4ppY4qpTrGqjtTKXVMKfVQKdUp1mvllVLrLfuIjvWat1JqlmW5t5RSe5VS9WOVqW1ZZqRSaotSqlCM136xvG/Wx12l1MEYrz+tlPrdss7BSqmPErGtOimlHsSab4RSKn+sMgctbbqslPpaKZU1xusjlVL3LOt0Syl1XCn1lVIqXyKW73RfTSGjga+01pm01itTsR0OPcoPv5SglHrfsg+EK6VmK6W8U7tNwnNJcivcQWOtdSbgaaAS8EES53cDGJyUBDOWh8A6oLmT18cA2YCiQDEgDzDSRct+JEqp54HNwDagOJADeBuoH1+9GCZY3osCwEVgVnK0MxVlAvYAVYDswFxgjfUHlVKqHDAD6IDxPkYC02LUvw00BvyAN4EvlFIvxHh9P/AO8I+DZd8DlgJdHbyWFrgAvGSZ94fAUusPKaVUTuAHy/TswF/AEmtlyw+iTNYHsANYFmP+i4DfLHVfAt5WSjVxtpFi2BlzvpZHiKVN/YFPgIGWNlcDCgEblVLpY8xjidY6s2XZrwF5gb8Tk+AmJJkTu0JAUDLOP9mlVOKrlKoLDAFqA4UxYuGolFi2eEJpreUhD9M+gLNAnRjPJwBrLP9Xw/iSDsNIGmrGKNcJOA3cAs4A7WJM/wP4GRgRo3ywtT7Gj74hwCngX4yEI7vltfOABiIsj+djzCOt5bXCsdbhF+CdGM97AesTWG8fYIFl+WEYCVcey2tbgbdirM92YJKl3GngBcv0C8BV4M0Y8/0DmBrPcmsCwU5emwOMifG8AXA7Ee/ho7bRD5gHXAPOAcOBNJbXvIDPgOuW+fSybPO0MerOAi5hJN9jAK+Y7/1j7IM3gSqW/z8GFsV4rRhwF8jspO4qoL+D6X8AnZzUKQ7oRLTrANDc8n93YEeM1zICUUBpB/UKAw+AIjGmRQJlYzxfBnyQiPfV4fYEsmB8PlrGmp7J8n53sTwfCSyIVcYL4/P8WTzLtq7fQ/77LOa3zG85xmfnJvAWUBXYadn3LgFfAeljzEsDPYETQCgwFVAx3ottQLhln1timX7Ksuwoy7K9MT6XYzBiUgRGjMkBLLS0ZQ8xYgPGZ2CPZd57gBdivFbEstxbwEZLmxc42x5OtlGcWIX9Z/GGpb3FMH7w/mtZx4VA1hjzOQsMsOxv4Rg/mnwsr+UEVlu27Q3gd/77rJ7FErsxfjx9HGOetYHLj/pZlIc8EvuQnlvhNpRS/hg9jCeVUgWANRjBOTtG8F2hlMqllMoIfAnU10aP0AvAvliz+xB4P+Yh5Rh6A80werDy898XHsD/LH+zaqOXamcimj4VaKSUyqaUyobRw/tLAnXexEjUCmJ8QfbE+CJ15DmML54cGF8ii4FnMb6Y2wNfKaUyKaUyYHzBLU9Em+Nl2cZtgJOJrJKoNlrKTsFY96IY70FHoLPltW5AI4we/GeAN2ItZy5w3zLfSsCrGAnOY1FKPQ2k57/1LIeReAGgtT6FkdyWdFDX17KOLu/dU0rlsSzTOu/Y7bqNkYCVc1C9I/C71vpMjGmTgY5KqXRKqVIY+8mvSWjiCxg/0H6IOVFrHYGx77/irKLW+gHwE1AjnjK3MWJBiI7VYww0xdjHs2Ikag+A9zESsecxEqt3Ys2yEcZ7VRFoCdS1TA8ENmAcefHH2DfRWhfDSB4bW5YdbSnfGqNXvwBG0rgT+A4jRh0BRoAxVAkjfn2J8ZmYiHGEIIdlPouAvy1tDsSIBzbKGFLk7DHEUsxZrHoO44dhbmAsoIBxGLGuDEbMGRlr+7QE6mEk3RUwkmSA/hgdA7kwjmQMxUioY7PbPy3/54mxvkK4lCS3wh2sVErd4r9evhEYCdFarfVarfVDrfVGjEOxDSx1HgLllVK+WutLWmu7BENrvQ/jS2uwg+X1AIZprYMtX1ojgTeScAjvH4wE6V/L4wH2h7IduYfxpVdca/1Aa/231vqmk7JntNbfWZKCJRhfTqO11tFa6w0YyVdxjC/oNBi9V49rgFIqDKNH6UWML/LESFQblVJeQCuMXsNbWuuzwOcxltMSmKy1vqC1voHxpQzYEr76QF+t9W2t9VWMHqrWj7OilmEr84FRWutwy+RMGL1XMYUDmR3MYjrGl/j6x1l+PO1Kh5G0zdVaH32MdnXE6IWPaTXGD4Uo4CgwS2u9JxHNqRYrsTplmZ4TuK61vu+gziXL6/EJwUgIH8dOrfVKS1yIsnx2dmmt71v2pxkYP5piGq+1DtNanwe2YAyBAuNzWAjIr7W+o7VO6ITE77TWpyz7yy/AKa31r5btsAzjBxdAQ+CE1nq+pV3fY2z3xkqpAIxE+0PL5+M3jF5gG6111nge4xNoY4jWeopluVFa65Na642WZV3DSLRjb58vtdYhls/cz7G2Tz6gkNb6ntb6d621o+Q29v5p/d/R/ilEkklyK9xBM0sPbE2gNMYXYyGgRcwvVoxkK5+lV6cVRm/nJaXUGuX4xKePMMYW5o01vRDwY4z5HsFISPM8ZvuXAccxAnkWjB61hM58no+RFC1WxslNEyxJjSNXYvwfBaC1jj0tE0YP9EOML6PH9ZnWOivGoe0ooFQi6yW2jTkxfgici/HaOYyeMDB6ly7Ees2qEJAO4z23vnczMHqoHoml1/VnYJfWelyMlyIw3sOYsmAk+zHrfwqUxzgs7+jL/rEopdJg7Bt3gXcfo10vYoxpXR5jWnaMMeOjMXpbCwJ1lVKxezcd2RUrsSpmmX4dyOnkB2E+y+vxKYBxmPtxxNw/UEqVVEqttpzMdBNjaEns5PpyjP8jMfZFgEEYPZt/KqWClFJdElh27H3a0T4Oxn4cc9+F//bz/ECoJY7FfM1VYm+f3EqpxUqpi5bts4DEb59PMY5qbFBKnY7Raxxb7P3T+v8tB2WFSDJJboXb0Fpvw+hx+gwjQM+P9cWa0dprobVer7V+BeOL9CjwjYP5HcU4bDo01ksXMIY0xJy3j9b6Io4PuSWkIjDD0psYgdGj1yC+CpZekFFa67IYh3gbYfS4PTatdSTGYVJnJ749yrzOA30wTpjyTer8YrjOf71lVgEY42fB6PUrGOs1qwtANJAzxvuWRWvt6NC8U5azuFdaltkj1stBGO+ntWxRjPGWx2NMG4XRg/xqPL3tj0wppTDGE+fBGGt7L552ZcQ4LB57SMSbwA+W/dCqKPBAaz3P0psXjDFsJN59NAE7Md6L12OtQ0aMbbPJWUVLAt8YY/xmfJx9FmNP/xojBpTQWmfB+LyrBOZtzEjry1rrblrr/Bj7wjSlVPHE1E1ACPb7OPy3n18Cslm2VczXbFTcK1TEfFjjWWK3zzjLtAqW7dOexG+fW1rr/lrrohjvWT+lVG0HRe32T8v/V7TW/yZmOUI8KkluhbuZjDFe7w+MQ3h1lVJeSikfy6WB/JVSeZRSTSxfDtEYvQYPnMxvFMZ4zqwxpk0HxirLpZQs43ibWl67htH7WTTmTJRSPhhJDoC35bnVHuAtpZSvJRHsjv34sziUUrWUUk9ZDtPfxEj4nK3DoxgEdFJKDbSOd1NKVVRKLY69PrEecb7sLENBQizr4xKWYQtLMbZ/Zst70I//erqXAr0t73M2jBP/rHUvYQw1+VwplUUplUYpVUwpFfsQq1OW3vHlGL1sHbXWD2MVWYix39Ww7F+jMZLFW5b6HwBtgVccfXErpdJb9g0FpLNs2zSW15TltfSW5z7K/nJJX2OMiWystY49/vpHjGE4zS3z+Ag4EGPYgrU3ugVxhyQctyy+rWWb5cU48hHvPhofy2H5UcAUpVQ9ZYzlLYxxFCMYo/fZjqVMGeB7jN7liQks5gqQQynll0C5zBifoQjLEZy3E7seSqkWyhjrD8aRD41rPodrgZKWbZ5WKdUKKAus1lqfwxhiNcqyv7yIkTja6LhXqIj5+NhSzGGsciAzRowMU8a5DAMTKG+jlGqklCpuiQ83MbaNo+0zD+iqlCpr+dwOJ+5+KITLSHIr3IplTNg8oC/GiSNDMYL4BYygnMby6I+ReN3AGD/m8BCrNk6qmY9x9rXVFxhnuW9QxljfXRgnYVh7P8cC2y2HvqtZ6ljPmgajlyhm8tEF4zB+MEbPTFH+OyHDGeuh45sYwyK2kfBQhgRprXcAL1sep5VSN4CZGF+2VgUs7Y/5KIZjnwKDlGuvWfkexiW1TmP8iFkEzLa89g3GcI39GGOZf4hVtyNGcngYIxlZzqMNw7D2kr+K8WVv7Q2rAaCNsds9MZLcqxiJQcx962OMXrYTKm5PGhjJd5RlOTMt/1tP/ClkeW7tbY0CjgFYkvweGGMdL8eYdztLu65h9MiPtaz3c8Qda9wMY6zjlpgTLb3Lr2OcdBWKcfLlIcu8EvK8g57DZy3znYDx+fwMYz/ejfE5ra3/OwELoJVSKgLjjPtVGOPSq+j/ThBzyJK4f4+xH4epGNfXjWUAxg+OWxj7zxIn5Rx5Fthtad8qoI+2PxHvsVh++DTCiFP/YvzobKS1tg7XaIvxHt7AOMdg3mMsw1msim0UUBlj31hD3M9UfEpgnHgYgdFbP01rvdVBW9ZhXOlmC8YQi3NYTq4TIjlYL3cihBBCCCGE25OeWyGEEEII4TEkuRUilSil2jk5IcTt7nqklJruZF2mp3bbYrOMl3V4Mk5qt81sUvt9VUoNdbL8hK4TLYR4gsmwBCGEEEII4TGk51YIIYQQQngMSW6FEEIIIYTHkORWCCGEEEJ4DEluhRBCCCGEx5DkVgghhBBCeAxJboVTlssAfZja7RBCiCeRMm4pHpza7RDC3Uhy66GUUmeVUnWSMg+tdU+tdaCr2vSoLPdd/8tyXctLSqlfLPdZd1b+faXUZaVUuFJqdny3hFVKzVRKHVNKPVRKdUqWFRBCCBNTSqVXSo1USp1QSt22fG/MVkoVdlLe2/L6TUus7RfPvPMppVYppUKUUtrZPIVIDpLcPqGUUmlTuw3xsQTNycDHQB4gAJgGNHVSvi4wBKgNFAaKYtwz3Zn9wDvAP65qsxBCuJnlQBOgLeAHVAT+xoijjowESgCFgFrAIKVUPSdlHwLrgOYubK8QiSLJrQdSSs3HSAZ/tvR6DlJKFbb8eu6qlDoPbLaUXRajt/M3pVS5GPOZo5QaY/m/plIqWCnVXyl11dKT2jmZ2u8HjAZ6aa1/0Frf1lrf01r/rLUe6KTam8AsrXWQ1joUCAQ6OVuG1nqq1noTcMfV7RdCCCul1BCl1PJY075QSn1p+b+zUuqIUuqWUuq0UqpHCrWrDvAK0FRrvUdrfV9rHW6JjbOcVOsIBGqtQ7XWR4BvcBJntdZXtNbTgD3J0X4h4iPJrQfSWncAzgONtdaZtNYTYrz8ElAGqGt5/gvGL/HcGL2YC+OZdV6MX/cFgK7AVKVUNhc3H+B5wAf40VkBpdSLSqmwGJPKYfTGWu0H8iilciRD+4QQIrG+BxoopbIAKKW8gJbAIsvrV4FGQBagMzBJKVU5BdpVB/hTa33BWQFLYr7a8n82ID9x42w5R3WFSE2S3D55Rlp6QqMAtNaztda3tNbRGIecKlp6Th25B4y29KKuBSKAUsnQxhzAda31fWcFtNZ/aK2zxpiUCQiP8dz6f2bXN08IIRJHa30Oo+OgmWXSy0Ck1nqX5fU1WutT2rAN2ADUSIGm5QAuxVdAaz1ea93I8jST5W/sOCsxVpiOJLdPHtuvdKWUl1JqvFLqlFLqJnDW8lJOJ3X/jZVwRvJfwLNRStWxDIdIzGOso+UAOR9xXHAERs+HlfX/W48wDyGESA6LgDaW/9vyX68tSqn6SqldSqkblqNRDXAeg22UUqMeIc46Ghf7L5DvEdYhwvI3dpyVGCtMR5Jbz6UTMb0txgladTCGGxS2TFdJWrDWv1qGQyTmMczBLHZijIVt9giLDcI4GcKqInBFa/3v46+JEEK4xDKgplLKH3gNS3JruaLLCuAzII/laNRaEhGDtdYjHiHOrnMwi1+BqpY2JchyLsMl4sbZoMTUFyIlSXLrua5gXDEgPpmBaIxf8BkwrkyQ6rTW4cBHGGN6mymlMiil0ll6OCY4qTYP6KqUKmsZGzYcmONsGZZL4PhgfImkU0r5KKXk8yCEcDmt9TVgK/AdcMZyMhZAesAbuAbcV0rVB15NoTb9CmwEflRKVVFKpVVKZVZK9VRKdXFSbR4wXCmVTSlVGuhG/HHWB2P9ALwtz4VIdvJl7rnGYQShMKXUACdl5gHngIvAYWBXSjUuIVrriUA/jCT1GsZwineBlQBKqRpKqYgY5dcBE4AtGOt0DhhhfV0Z18gdGmMRG4Ao4AVgpuX//yXfGgkhnnCLMI6S2YYkaK1vAb2BpUAoxtG0VSnYpjcweoqXYIyfPQQ8g9Gri1JqqFLqlxjlRwCnMOLrNuDTmL3CliEQMccLR/HfcIajludCJDultbOj10IIIYQQQrgX6bkVQgghhBAeQ5JbIcQTz3JL0atKqUNOXldKqS+VUieVUgdS6DqkQgjh0ZIr9kpyK4QQxkkxzm4jClAf42YnJYDuwNcp0CYhhPB0c0iG2CvJrRDiiae1/g24EU+RpsA8y4X2dwFZlVKPco1QIYQQsSRX7JXkVgghElaAGDdAAYIt04QQQiSfx4q9j3IHqMdy8eJFuRwDUK1atdRugikEBwendhOEiWitk3TDEOtsEiqglOqBcUjLaqbWeuYjLMNRO00d244cOWLq9qWU1q1bp3YTTOHgwYOp3QRTkCtE/ccF8de0sTfZk1shhEhOifmysgTTRwmosQUDBWM89wdCkjA/IYRwa2aOvTIsQQjh1rTWCT5cYBXQ0XLmbjUgXGt9yRUzFkIId2Tm2Cs9t0IIt+aKAKqU+h6oCeRUSgVj3IkpnWX+0zHu4tQAOAlEAp2TvFAhhHBjZo69ktwKIdzaw4cPEyzj5eUV7+ta6zYJvK6BXo/UMCGE8GBmjr2S3Aoh3JqcICKEECnPzLFXklshhFtLTO+BEEII1zJz7JXkVgjh1szceyCEEJ7KzLFXklshhFszc4AVQghPZebYK8mtEMKtmfnQmBBCeCozx15JboUQbs3MvQdCCOGpzBx7JbkVQrg1MwdYIYTwVGaOvZLcCiHcmpkPjQkhhKcyc+yV5FYI4dbM3HsghBCeysyxV5JbIYRbM3PvgRBCeCozx15JboUQbs3MvQdCCOGpzBx706R2AxLj6tWrjBw5ksaNG9OoUSM++ugjrly5kqi6V65cYfz48bRu3Zr69evTsWNHZs2aRVRUlF258PBwJkyYwGuvvUa9evV455132LNnT3KsTpLky5eP6dOnExQUxOHDh5k5cyb58+dPVN3BgwezcOFCDhw4wIULF2jRooXDct26dWP27Nn89ddfXLhwgffff9+Vq+CUv78/y5YtIywsjPDwcFasWEHBggUTVdfb25sJEyYQEhJCZGQkO3bsoEaNGnHKKaUYMmQIZ86cISoqin379vH666/HKdexY0eWL1/O2bNn0Vrz3XffOVxuo0aNWLhwIceOHePBgwds2bLl0VY6hSVlG5uV1jrBh3h8165d45NPPqFt27a0adOG8ePHc+3atUTX/eKLL3jrrbdo2bIl77zzDgsXLuTOnTtO6/z22280a9aMrl27umoVXCJPnjx89tln/PHHH2zfvp2JEyeSN2/eRNV97733mD59Otu2bWP//v00adLEYTk/Pz8GDRrEmjVr2L17N2vXruWDDz4gW7ZsrlwVh/z9/Vm6dCmhoaGEhYWxfPnyR46/Fy9e5Pbt22zfvj3e+Hv69GkiIyPZu3evw/g7a9YsgoKCCAsL4+bNm+zdu5d3332XNGnsU5Y0adIwfPhwTp06RVRUFMeOHaNPnz6PtwGSmcTelGX65PbOnTv079+f8+fPM3jwYD744AMuXrxIv3794iSosUVFRTFw4EAOHDhA586d+fjjj2nQoAHLli3j008/tZW7e/cu/fv3Z8+ePXTv3p1Ro0aRO3duhg4dyr59+5J5DRPPx8eHJUuWULx4cfr160ffvn0pUqQIS5cuxdfXN8H6nTp1wsfHh19//TXecm3atCFnzpxs2LDBVU1PkK+vL5s3b6Z06dK8+eabdOjQgRIlSrBlyxYyZMiQYP1Zs2bRrVs3PvroIxo1asSlS5dYv349FStWtCsXGBjIyJEj+eqrr6hfvz67du1i2bJl1K9f365c+/btKVasGBs3biQ8PNzpcps1a8bTTz/Nrl27CA4OfryVTyFJ3cZm9fDhwwQf4vFER0fz0UcfcfHiRXr37k3fvn0JCQlh+PDh8SaoYMTuESNGEBQURNu2bfnwww+pU6cOP/30E1OmTHFYJyIigtmzZ6dIMvcofHx8+OabbyhSpAgffvghw4YNIyAggG+//TZRsbdNmzZ4e3vz22+/xVvuiy++oH79+syZM4devXoxZ84c6tWrxxdffOGqVXHI19eXTZs2Ubp0aTp16kTHjh0pUaIEmzdvTlRs+Pbbb3nrrbcYMWIEjRs35tKlS6xbt85h/B0xYgRTp06lQYMG7N69m6VLl8aJv76+vnz11Ve0bNmS5s2bs2nTJiZPnszEiRPtyk2bNo1hw4Yxe/ZsGjduzPLly/n0008ZNmxY0jeKC0nsTXmmH5awZs0aLl26xNy5cylQoAAARYsWpUOHDqxevdpp7yPAoUOHCA4O5pNPPuHZZ58FoFKlSty8eZOlS5dy584dfHx82LZtG6dPn2bixIk8/fTTAFStWpVu3boxY8YMvv7662Rfz8Ro27YtAQEB1KxZk7NnzwJw5MgRfvvtN9q3b88333wTb/2yZcuitaZw4cLxbrfatWujtcbLy4sOHTq4chWc6tatG0WLFqVUqVKcOnUKgAMHDnDixAl69OjBpEmTnNatUKEC7dq1o3PnzsyZMweAbdu2ERQUxOjRo2natCkAuXLlYsCAAYwfP57PP/8cgK1bt1K8eHHGjx/PL7/8Yptn3bp1bb8669WrF2+7reV+//33x98AKSAp29jMpGc2+WzYsIErV64wdepU8uXLB0DhwoV5++23Wb9+ve2z5ciRI0cICQlhxIgRVKpUCYCnnnqKiIgIVq5cSXR0NN7e3nZ15s6dS+HChcmWLRsHDhxIvhV7RK+//jr+/v40bdqUCxcuAHDixAlWrVrFG2+8wfz58+OtX716dbTWFCxY0GmvbaFChahUqRKjR49mxYoVAPz1119orRk+fDiFChXi3Llzrl0xC2tsKF26tF1sOH78eKLjb5cuXezi76FDhxg1ahTNmjUDjPjbv39/PvnkE7v4W6xYMcaNG2cXf9u2bWu3jI0bN5IvXz46d+5M3759AShYsCBdu3ZlzJgxjB07FoBff/2VLFmyMHToUKZNm0ZoaKgrNk+SSexNeabvud2xYwdlypSxJbZgHJovX74827dvj7fu/fv3AciYMaPd9EyZMtl1mR8+fBhvb2+7X5lKKapUqcKxY8cSfQguub3yyiv8888/tsQW4MKFC/z111+8+uqrCdZP7I6YGjtskyZN2LVrl+2DD3D27Fm2b98e7xeote7du3dZsmSJbdqDBw9YvHgxdevWJX369ICRsHp7e7NgwQK7+gsWLKBChQoULlzYNs3M2+pxJWUbm5mZew/c3Z9//knJkiVtiS0Yh+fLlCnDn3/+GW9da/yN3TOVMWNGh4csjxw5wrZt2+jRo4eLWu86NWvWtA3nsrp48SL79u2jZs2aCdZPTJxIly4dALdv37abfuvWLYA4h+RdqXHjxk5jg7Nk3MpZ/F2yZEmi4u/ChQvjxF9Hbty4YdunwOiA8vLyskuKAdatW4evr2+c3uDUJLE35Zk+uT179ixFihSJM71w4cIJ/oqtUqUK/v7+zJw5k7NnzxIVFcU///zDDz/8QOPGjW2Hk7y8vEibNi1KKbv61g9lzGQyNZUsWZJjx47FmX78+HFKlCiRCi1ynXLlynHo0KE404OCgihbtmyCda1jaGPX9fb2pnjx4rZyd+7c4eTJk3HKAQkux90lZRubmZnHfbm7CxcuEBAQEGd6wYIF7RI9RypWrEj+/PmZN28eFy5cICoqigMHDrB69Wrq1q2Lj4+Prez9+/eZNm0ar732ml0ibRbFihWzS0ysTp06RdGiRV2yjJMnT/LXX3/RvXt3ypYti6+vL+XLl6d79+78/vvvnDlzxiXLcaRcuXK2OBjT4cOHE4wNZcuWTbb46+XlhZ+fH6+//jodO3a06+F88OABYAwrjCk6OhqA8uXLx9vulCSxN+UlOCxBKVUaaAoUADQQAqzSWh9J5rYBxq/WTJkyxZmeOXNm2y9aZ9KnT88XX3zByJEj6dKli216gwYN6N27t+15wYIFuX37NufOnaNQoUK26dYP3c2bN5O6Gi6RNWtWh+M/w8LC8PPzS4UWuU727NkdHkK6ceNGguPv4qtrfd36NywsLMFyniop29jMPDV5Te3YC8YYWGfxNyIiIt666dOn5+OPP+aTTz7hvffes01/5ZVX6N69u13ZH374gXv37tG8eXPXNNzF/Pz8HH4PhIeHkyVLFpct591332Xs2LF8//33tmm//fYbAwYMcNkyHDFj/G3YsCE///wzYPQQfvLJJ4wZM8b2urWjp1q1anbnxjz//PMO55eaJPamvHiTW6XUYKANsBiwHoPyB75XSi3WWo9P5vZZ2/FY9e7evUtgYCChoaF88MEH5M6dm6NHjzJ//ny8vLxsVwGoXbs2c+fOZfz48QwcOJAcOXKwevVq25iv5Dwc9Kgc7UyPu33M5nHXTSmVqLqJLefJPHH9PXHYgVlir6UtcaYl5kvt7t27fPbZZ4SHh9O3b19y5crFiRMnWLJkCV5eXvTs2ROAS5cusXz5coYMGWI7WmZGKfHZ+eijj3jqqacIDAzk9OnTFC1alLfffpvPPvuM3r17J2syYbb4+/vvv/Pss8/i5+dH7dq16d+/v238MRjDWDZs2MDIkSM5ffo0u3fvplatWrarJZgtLkjsTVkJ9dx2Bcppre/FnKiUmggEAQ4DrFKqO9AdYPz48bRv3/6xG+ish/bWrVtkzpw53rpr165l3759zJ8/3zZmt2LFimTMmJGJEyfSpEkTihUrRqZMmRg5ciSffPIJb731FgD58+fnzTff5LvvvjPNL8Dw8HCyZs0aZ7qfn1+8Z/S7g9DQUIfbOVu2bAmeFHDjxg2Hh06tv4itPQPOfiXHLuepkrKNzczMvQdJkOTYO3LkSFq2bJmkRmTMmNFh/HXWoxvTr7/+yqFDh/j6669tQw3KlStHhgwZmDZtGnXr1qVIkSJ88803PPXUU5QsWdLWG3z//n201kRERJAuXbo4J56ltJs3bzo8OpYlSxaXHdmrUaMGDRo0oFu3brbxzP/88w/BwcHMmDGDl156ia1bt7pkWbGZMf7evHmTv//+G4DNmzdz9+5dhg8fzrRp0wgJCQGgS5cuLFiwgHXr1gHGd+TgwYOZPn06ly5dirfdKUlib8pLKLl9COQHYg9uzWd5zSGt9UxgJsDFixeTtPaFChVyOOY19hACR86cOUPmzJntTkYDKFOmjG0exYoVA4wzPhcsWMDFixd5+PAh/v7+LFmyBG9vb0qWLJmUVXCZ48ePO2xLiRIlOHHiRCq0yHWCgoIoV65cnOlly5bl8OHDCdZ97bXX8PX1tRv3VbZsWaKjo21jvIKCgvDx8Ykzfs465imh5bi7pGxjMzNzgE2CJMfeI0eOJHnDBAQEOBxbe+HChQSv0Xnu3DkyZcoUZwyt9fyA4OBgihQpwoULF7h27ZrDTpD27dvTqFEjW6dDajl16pTtuyKmokWLcvr0aZcsw7pdYo99tY7VLFq0aLIlt87GfpYpUybB2HD48OEUib9//fUXXl5eFClSxJbchoSE8PLLL5MvXz6yZ8/OqVOnqFChAgB//PFHItY8ZUjsTXkJHW/vC2xSSv2ilJppeawDNgEpcqXkF154gcOHD9t2ZoDLly9z6NAhXnjhhXjrZsuWjVu3bnHx4kW76UeOGEPWcubMaTddKYW/vz8BAQFER0ezZs0aXnnllURdxzAlbNy4kcqVK9v9Svb39+eZZ55h48aNqdiypFu1ahXVqlWzO3mwUKFCVK9enVWrViVYN3369HaXN/Py8qJVq1Zs2LDBdsLBunXriI6Opl27dnb127dvz8GDB01z4mBySco2NjMzn7GbBH1J5dgL8Oyzz3Ls2DEuX75sm3blyhWOHj1qu7yiM1mzZiUiIiJOD9rx48eB/8ZEDhgwgMDAQLtHpUqVyJIlC4GBgTRs2NDFa/Xotm7dylNPPWXXUZI/f36efvpptm3b5pJlXL9+HYh7ItRTTz0FGDczSi4///yz09hgHffqjLP427Jly0TF33bt2iUq/r700ks8fPjQ4Y+JS5cuERQUxJ07d+jTpw9HjhxJth8Cj0Nib8pTCWXeSqk0QFWMkxoUEAzs0Vo/SMwCktpzGxUVRbdu3fD29radFPbdd98RFRVldwHty5cv0759ezp27EjHjh1t09566y2yZ89Ou3btyJ07N8eOHWPBggX4+/szbdo023jab775hpIlS+Ln58fFixdZsmQJadKk4csvv3TJCQPVqlVL8jx8fX3ZsGEDd+7c4dNPP0VrzYABA8iYMSOvvvoqkZGRABQoUIA//viDyZMn2138u1q1amTPnp1cuXIxZswY5syZw86dOwFjCIdVhQoV8Pf3J02aNHz99df8/PPPrF69GjAODyV08fb4OLvRQYYMGdi/fz9RUVEMHz4crTWBgYFkzpyZChUq2C6PExAQwKlTpxg9ejSBgYG2+t9//z1169Zl4MCBnDlzhrfffptGjRrxwgsvsHfvXlu5cePG0bdvX4YOHco///xDq1at6NGjB02bNrWtIxg9FtYehRkzZnDgwAGmTp0KGNdwtH4RBQQE2L7kAwMDefjwISNGjABgz549nD9//rG3lasldhunJK11kgednTp1KsEYU6xYMbcb3JbU2OuKnts7d+7Qt29f0qdPT7t27VBKsWjRIqKiopg8ebIt/l69epWePXvSqlUrWrVqBRhJcN++fcmWLRtvvPEGuXLl4uTJkyxdupT8+fPz6aefOj2f4YsvvuDAgQPMmjUrqatA69atkzwPX19fli5dSnR0NF999RVaa3r16kXGjBl54403bD2W+fLlY/Xq1cycOZMZM2bY6lepUoVs2bKRM2dOPvjgAxYvXmy7A6b1pjoZM2Zk5cqVALYr/BQuXJiePXty7949XnvttQRvXBSfgwcPOn0tQ4YM7Nu3j6ioKD788EO01owePZrMmTNTsWJFu/h78uRJ248Qq0WLFlG3bl0GDRrEmTNn6NmzJ40aNaJ69epx4m+fPn0YNmyYLf52796dZs2a2eJvgwYN6NSpE6tXr+b8+fNkzpyZ+vXr061bN7755hveeecd2/x69uzJnTt3OHPmDHnz5qVjx468+OKL1KlTx+kdRlOjt9GMsReSHn/NHHsTvFqC1vohsCsF2uKQr68vn3/+OdOmTWPcuHForalcuTK9evWK06Ma+5dC3rx5+eqrr5g7dy6zZ88mPDyc3Llz07BhQ9q3b28XWENDQ5k6dSphYWFkzZqVF198kU6dOrn0TNikioqKolWrVowYMYLJkyejlGL79u2MHDnSltiC0QOdNm3aOF8c/fr1s51JCsYdyzp16gRgd4ixU6dOdr/CGzduTOPGjQHjTNTkuBNXZGQkL7/8MpMmTWL+/Pkopdi0aRN9+/a1++A7W7fOnTszduxYxowZQ9asWdm/fz/16tWzC6wAw4YNIyIigj59+pA3b16OHTtGy5Yt7RJbgJYtWzJy5Ejb81q1alGrVi3AuOaltbemVq1atguXWy1fvhwwtuPcuXOTtF1cKbHb2N24ac9sglI79oJxZ67AwEBmzZrF5MmT0VpToUIFunbtahd/tdZx4m+ePHmYMGEC33//PQsXLuTWrVvkzJmTV199lRYtWpjqRN2EWDtZBg4cyNixY1FKsXv3bj799FO7hNMan2KfKPT222/b9XS3bt3alnRbr69++/Zt2rdvz9tvv03nzp3JmTMn169fZ9u2bUyfPj1JiW1CIiMjqV27NhMnTmTevHm22PD+++8nKv526dKFsWPHEhgYaIu/9evXdxp/e/fubYu/rVq1sou/p06dIk2aNAQGBpI7d27CwsI4ceIEb775pt1VJMDoIR48eDCFChUiMjKSrVu38vzzz5vuUL/E3pSXYM9tUiW159ZTuKLn1hOY/Ra1ImW5ouf2+PHjCcaYkiVLul3PbVK5oufWE7ii59YTxNdz+yQx8zjRlJbU+Gvm2Gv62+8KIUR85MtKCCFSnpljryS3Qgi3ZuZDY0II4anMHHsluRVCuDUz9x4IIYSnMnPsleRWCOHWzNx7IIQQnsrMsdd9TlcVQggHtNYJPhJDKVVPKXVMKXVSKTXEwet+SqmflVL7lVJBSqnOLl8ZIYRwE2aOvZLcCiHcmisCrFLKC5gK1AfKAm2UUrFv2dQLOKy1rgjUBD5XSqV37doIIYR7MHPslWEJQgi35qJDY1WBk1rr0wBKqcVAUyDmBTM1kFkZFzHNBNwA7rti4UII4W7MHHsluRVCuDUXndRQALgQ43kw8FysMl8Bq4AQIDPQynKjBSGEeOKYOfbKsAQhhFtLzP3NlVLdlVJ/xXh0jzUbRxcajx256wL7gPzA08BXSinz3MJQCCFSkJljr/TcCiHcWmJ6D7TWM4GZ8RQJBgrGeO6P0UsQU2dgvDYWeFIpdQYoDfz5SA0WQggPYObYKz23Qgi35qIzdvcAJZRSRSwnKrTGOAwW03mgNoBSKg9QCjjtwlURQgi3YebYKz23Qgi35oqTGrTW95VS7wLrAS9gttY6SCnV0/L6dCAQmKOUOohxKG2w1vp6khcuhBBuyMyxV5JbIYRbc9VdcrTWa4G1saZNj/F/CPCqSxYmhBBuzsyxV5JbIYRbM/MtIIUQwlOZOfZKciuEcGtmvgWkEEJ4KjPHXkluhRBuzcy9B0II4anMHHsluRVCuDUz9x4IIYSnMnPsTfbktmrVqsm9CLewalXsK1s8mRo3bpzaTTCFS5cupXYTPIaZew9SU/PmzVO7CaYwfPjw1G6CKYwbNy61m2AKQUFBqd0Ej2Hm2Cs9t0IIt2bmACuEEJ7KzLFXklshhFsz86ExIYTwVGaOvZLcCiHcmpl7D4QQwlOZOfZKciuEcGtm7j0QQghPZebYK8mtEMKtmbn3QAghPJWZY68kt0IIt2bmACuEEJ7KzLFXklshhFsz86ExIYTwVGaOvZLcCiHcmpl7D4QQwlOZOfZKciuEcGtmDrBCCOGpzBx7JbkVQrg1Mx8aE0IIT2Xm2CvJrRDCrZm590AIITyVmWOvJLdCCLdm5t4DIYTwVGaOvZLcCiHcmpl7D4QQwlOZOfZKciuEcGtmDrBCCOGpzBx7JbkVQrg1Mx8aE0IIT2Xm2JsmtRuQFPnz52fmzJkcOXKEo0eP8s0335A/f/5E1R0yZAiLFi3i0KFDXLx4kZYtWyZza5PPv//+y+TJk+natStdu3Zl0qRJXL9+PVF1r1+/ztdff817771Hp06d6NevH0uXLuXOnTvJ3GrXs+4PR48e5dixY3z77bcUKFAgUXWHDBnC999/z6FDhwgJCUn1/cHf359ly5YRFhZGeHg4K1asoGDBgomq6+3tzYQJEwgJCSEyMpIdO3ZQo0aNOOWUUgwZMoQzZ84QFRXFvn37eP311+OUmz17NocPHyY8PJxbt26xb98+3n33XdKk+S98ZM6cmQ8//JDt27dz/fp1QkND2b59O02bNn38jZBIWusEH+Lx5c2bl0mTJrF7927+/PNPvvjiC/Lly5eoun379uWbb75hx44dHD58mGbNmjktmzt3bsaMGcNvv/3Gvn372LBhA++//76L1iLpMmTIwIsvvsgbb7xBixYtqFGjBhkyZEh0/SxZsvDiiy/y+uuv07JlSxo1akSpUqXsyjRp0oS2bdvGefj7+7t6dR5bnjx5+Pzzz9mxYwc7d+5k0qRJ5M2bN1F1e/fuzYwZM/j99985ePCgw/jQtGlTDh486PSRI0cOV6+SHX9/f5YuXUpoaChhYWEsX778kWPvxYsXuX37Ntu3b4839p4+fZrIyEj27t3rMPZu3ryZhw8fxnn06dPHVsYae//44w+uXbvGjRs3+OOPP5742Ou2ya2Pjw9Lly6lWLFi9O3bl969e1OkSBGWLVuGr69vgvU7d+6Mj48Pv/76awq0NvlER0czZswYQkJC6NmzJ2+//TaXL19mzJgxCSaod+7c4eOPP+bo0aO0aNGCgQMHUqtWLdasWcPMmTNTaA1cw9fXl6VLl1K8ePHH2h+6dOlimv3B19eXzZs3U7p0ad588006dOhAiRIl2LJlS6K+TGfNmkW3bt346KOPaNSoEZcuXWL9+vVUrFjRrlxgYCAjR47kq6++on79+uzatYtly5ZRv379OO2ZMmUKLVq04PXXX+fXX3/liy++YOLEibYyAQEBvPPOO2zbto327dvTqlUrjh8/zsqVK3nnnXdcs2GccBT8Yz/E4/Hx8eG7776jaNGiDB06lCFDhlCoUCG+++67RH2u2rVrh4+PD1u3bo23XP78+VmyZAmFChXi448/5q233mLq1Kncv3/fRWuSNF5eXtSuXZssWbKwa9cuduzYQebMmalduzZeXl4J1s+ePTt169YlTZo0/Pnnn2zdupUjR46glIpTNiQkhPXr19s9rly5khyr9ch8fHyYNWsWRYoUYfjw4QwdOpRChQoxe/bsRO0Pbdu2xdvbm23btjkt89tvv9GuXTu7R/v27QkNDeXgwYP8+++/rlwlO76+vmzatInSpUvTqVMnOnbsSIkSJdi8eXOiYu+3337LW2+9xYgRI2jcuDGXLl1i3bp1DmPviBEjmDp1Kg0aNGD37t0sXbo0TuwF2L9/P88//7zdY/HixbbXAwICePvtt/ntt9/o0KEDrVu35vjx4/z4449PdOx122EJ7dq1IyAggP/973+cPXsWgCNHjvDHH3/QoUOHBJOz0qVLo7WmcOHCtGjRIgVanDw2b97M1atX+fzzz22/ngMCAujXrx+bNm2iYcOGTuseP36cy5cvM2TIECpUqABAuXLliIiIYM2aNURHR+Pt7Z0i65FUbdu2pVChQtSoUcO2Pxw+fJjt27cnan8oVaqUbX9I7V7bbt26UbRoUUqVKsWpU6cAOHDgACdOnKBHjx5MmjTJad0KFSrQrl07OnfuzJw5cwDYtm0bQUFBjB492vZrPleuXAwYMIDx48fz+eefA7B161aKFy/O+PHj+eWXX2zzbNOmjd0yNm7cSP78+enSpQt9+/YF4MyZMxQtWpSoqChbuQ0bNlCwYEEGDx7MtGnTkrxdnJGe2eTzxhtv4O/vT8OGDTl//jwAx44d45dffqFly5bMnTs33vpVq1ZFa01AQEC8vbYjRozgypUrdO7c2ZbQ/vXXXy5bj6QqXrw4GTNmZPXq1URERAAQFhZG48aNKVGiBEePHo23frVq1bh8+TK///67bdrVq1cdlo2Ojk7WBC4pmjdvjr+/P40bN+bChQuA8T2yevVqWrRowbx58+Kt//zzz6O1pmDBgk57FkNDQwkNDbWbVrlyZbJly5ascQT+i72lS5e2i73Hjx9PdOzt0qWLXew9dOgQo0aNsu3/uXLlon///nzyySd2sbdYsWKMGzfOLvYC3Lp1i927dztd7pkzZyhWrJjD2Dto0KAnNva6bc/tq6++yj///GNLZAAuXLjAnj17ePXVVxOsb+Y35VH8888/lChRwu6wUO7cuSlZsiR///13vHWtXyKxf3FnzJgx1Q8pPKr49oe6desmWN9M69qkSRN27dplC64AZ8+eTdRh/iZNmnD37l2WLFlim/bgwQMWL15M3bp1SZ8+PQB169bF29ubBQsW2NVfsGABFSpUoHDhwvEu599//7XrVYuMjLQLrlZ//fVXoocKPS4zHxpzdy+//DL79++3JbYAFy9eZO/evbz88ssJ1k/Mti9YsCA1atRg4cKFpumpja1AgQL8+++/tsQW4Pbt21y7di3BoU958uQha9asCSbA7qBmzZocOHDAltiCsT/s27ePWrVqJVj/cT+L1rgWO/FztcaNGzuNvU2aNElUG2PH3iVLliQq9i5cuDBRsTc2Z7H377//fqJjr9smtyVLluTYsWNxph8/fpySJUumQotSR3BwsMPxWP7+/ly8eDHeuuXLlydv3rx8//33BAcHc+fOHYKCgli3bh21a9fGx8cnuZrtcqVKlXL45XHs2DG32x/KlSvHoUOH4kwPCgqibNmyCda1jqGNXdfb25vixYvbyt25c4eTJ0/GKQc4XI6Xlxd+fn68/vrrvPnmm3bDEpz53//+l+xf6mY+NObuihcvHmcfATh58iTFihVzyTIqVaoEGD2W3377Lfv27WPnzp2MGzcOPz8/lywjqfz8/AgLC4szPTw8PME25sqVCzA+P6+++iqtW7fm9ddfp0qVKg6HNBQoUICWLVvSqlUrXn31VVONt41vfyhatGiyLNPb25tXX32Vbdu2ER4enizLsCpXrpwtBsZ0+PDhBGNv2bJlkyX2VqpUidDQUKKjo9m3bx9dunRJ1LrUqFHjiY69bjssIWvWrA6DTVhYmGkCYkqIiIggY8aMcaZnypSJ27dvx1s3ffr0jBgxgsmTJzNo0CDb9Fq1atGpUydXNzVZZc2a1WHgc8f9IXv27HEOywHcuHGDbNmyPXZd6+vWv44+P7HLWTVs2JDVq1cDRkAbP348Y8aMibct3bp14/nnn6ddu3bxlksq6ZlNPn5+fg4/V+Hh4WTJksUly8idOzcAY8aMYdWqVXzzzTcEBATw/vvvU6xYMVq1apXq73H69Om5e/dunOl379619cg5Yz0yVr16dY4fP86+ffvInj07FSpUIEOGDHZDFS5evMiNGzeIiIjAx8eHkiVL8r///Y8dO3bYHZVKLX5+fty8eTPO9Js3b7psf4jt5ZdfJnPmzKxatSpZ5h+T2WLv77//zqJFizh+/DhZs2alQ4cOfPvtt+TLl4+xY8c6bYs19rZv3z7eNidVan8u4/PYya1SqrPW+jtXNuZROdqwjgboezpH65yYne7u3btMmTKFmzdv8s4775AjRw5OnTrFjz/+SJo0aejatWtyNDfZeNL+8LjropRKVN3ElrP6/fffeeaZZ/Dz86N27doMGDAArTXDhw93WP6ll17iyy+/ZN68eSxatCjBdieFmQNscjBD7HXl58p61Y0///zT9oNp9+7d3Lp1i4kTJ/Liiy/aJYDuxrqtzp49y8GDBwFjvK1SikqVKpElSxZbwhh7KFlwcDCvvvoqFStWNEVyCyn/eWvSpAn//vtviu0DZoq9I0aMsHu+atUqVqxYwdChQ5k8ebLDDqyXXnqJL7744omPvUkZljDK2QtKqe5Kqb+UUn8l1Hv4uMLDwx3+knLW0+CpMmbMaDcOzOr27dsOe3Rj2rp1K4cPH2bQoEG8+OKLlClThkaNGtGuXTs2bdrEuXPnkqvZLhceHk7WrFnjTHfH/SE0NDROzylAtmzZHPYMxHTjxg2nda2vW/86+vzELmd18+ZN/v77bzZv3sywYcP4+OOPGTJkiMMxXc888wyrVq1i8+bNKfIDycyHxpJJomJvQvtKYjg77B4zIUsqay/Wzp077abv2LEDgDJlyrhkOUnhrIfWWY9uTNHR0QBcvnzZbrr1eXw9glprzp8/T8aMGU0xTOzmzZvJvj/ElDNnTqpVq8batWt58OCBy+cfmxljb2yLFy/G19eXp556Ks5rzzzzDD/99BObN2/mrbfeinc+rmDm2BtvcquUOuDkcRDI46ye1nqm1voZrfUzCSVYj8vZ2NoSJUpw/PjxZFmmGfn7+xMcHBxn+sWLFxM80eHChQtkzJiRPHns30rrWLqExuyaybFjx+JcMxKMsdnutj8EBQVRrly5ONPLli3L4cOHE6xbpEiROCcJli1blujoaNs4r6CgIHx8fOKMm7SO90poOX/99RdeXl4UKVLEbnr58uVZv349+/bto3nz5ilygpCrTmpQStVTSh1TSp1USg1xUqamUmqfUipIKeX8ekZJ5IrYm9Bh1MRwNra2WLFidifdJHUZ4LwXyAw/Tpwl+Yn58Wx93cy9XIkV3/5w+vRply+vUaNGpE2blp9++snl83bE2XkNZcqUSTAmHj58OEVir7WHN/b+VL58edatW8e+fft44403nvjYm1DPbR6gI9DYwSNVr1WyYcMGKleuTEBAgG2av78/zz77LBs3bkzFlqWsKlWqcPLkSbvrIF67do3jx49TpUqVeOv6+flx+/btOD0K1g+ho1+hZhXf/rBhw4ZUbNmjW7VqFdWqVbNLHAsVKkT16tUTHHe2atUq0qdPb3d5Oy8vL1q1asWGDRtsvUzr1q0jOjo6znjY9u3bc/DgwQQPgb700ks8fPjQ7gutePHibNy4kdOnT9OoUaMUuxGIK3oPlFJewFSgPlAWaKOUKhurTFZgGtBEa10OSM5rCJoi9m7ZsoWKFSvandSUP39+KlWqxJYtW1yyjP3793Pt2jVefPFFu+nW545OrkxpFy9eJGfOnHZHwzJmzEiuXLkS7AQICQnhwYMHcY5yWG+EEd9lv5RSBAQEcPv2bVPcWGfr1q1UqFAhzv7w9NNPu2x/iKlJkyYcO3bM4cnjyeHnn392Gnt//vnneOs6i70tW7ZMVOxt165domJvmzZtiIyMtA1xASP2btiwgdOnT9O4cWOJvSQ85nY1kElrvc9Bg7Ym2OpktHDhQjp16sTs2bOZMGECWmsGDRpESEgI8+fPt5UrUKAAO3bsYNKkSUyePNk2vVq1auTIkcN2JmuFChVs41fWrFmTouuSFLVq1WLDhg1MnDiRFi1aoJRi2bJlZM+endq1a9vKXbt2jffff5/XX3/ddieUl156iV9++YUJEybQrFkzcuTIwenTp1m5ciVFihRxq6sMLFy4kM6dO/Pdd9/Z9oeBAwc63B+sd9WJec1C6/5gPbmlYsWKqbY/fPPNN7z77rv89NNPDB8+HK01gYGBXLhwgRkzZtjKBQQEcOrUKUaPHk1gYCBgJAqLFy9m8uTJpEuXjjNnzvD2229TpEgRu2B67do1Jk2axAcffMCtW7f4559/aNWqFS+//LLd5cYaNGhA586d+fnnnzl//jyZM2emfv36dO/enRkzZnDp0iXAOCN848aNtpMUY/d+7N27N8HDt4/LRT1iVYGTWuvTAEqpxUBTIGY3SlvgB631ectyHV+o1DVMEXuXL19Ou3bt+Oqrr/jyyy/RWvPee+9x+fJlli5daiuXP39+1q1bx9dff83XX39tm/7MM8+QPXt2cubMCRhnikdGRgLYfnQ+ePCAiRMnMm7cOEaMGMHGjRsJCAigT58+7N69m127dqXU6jp18uRJSpYsyUsvvcT+/fsB4zsjMjLS7qz3DBky0KRJEw4dOmRLyu/evUtQUBDly5fn3r17XL58mRw5clC+fHlOnz5tG1ZWqFAh/P39CQkJ4fbt2/j6+lKiRAly5MjB9u3bU36lHVixYgVt2rThyy+/ZMqUKWiteffdd7ly5QrLli2zlcuXLx9r165lxowZTJ8+3Tb9mWeeIVu2bA73h9idUmXKlKFEiRJ8+umnKbBmhm+++YZevXqxcuVKPvzwQ7TWjB492mHsPXnyJIGBgXFi76RJk2yxt2fPnhQpUsTuxK5r164xefJkhgwZEif2xrwW9IsvvsjgwYP58ccfOXv2LH5+fnTs2JGmTZsyZMgQ23bLlSsXGzZsIH369IwcOVJir0W8ya3W2umAOa1120Q0OtlERUXRsmVLRo4cyZdffolSij/++IMRI0bY3nQwfvmmTZvW7lahAP379+eFF16wPe/cuTOdO3cGSPQtW83Ax8eHYcOGMX/+fL7++mu01pQrV46OHTvGGaMV+5dUrly5GDVqFCtWrGDp0qXcunWLHDly2BKc2NvMzJztDx999FGi9ocBAwY43R+S+1qBsUVGRvLyyy8zadIk5s+fj1KKTZs20bdvX7sTCJytS+fOnRk7dixjxowha9as7N+/n3r16rF37167csOGDSMiIoI+ffqQN29ejh07RsuWLW1XRQA4deoUadKkYcyYMeTOnZuwsDBOnDhBx44d+f77723lypYta7s+o6MfA4ULF062MdwuCrAFgAsxngcDz8UqUxJIZ0kuMwNfaK3jv2r9YzJL7I2KiqJz584MHjyY8ePHo5Ri165djBs3zu5zBTjcF999912qVq1qe2694xTYX/Lop59+4uHDh7z11lu89tprhIeHs3r16ngvmp+SHjx4wKZNm6hcubItTly+fJl//vnH7vCvUoo0adLEOTno0KFD3L9/nxIlSlC6dGnu3LnDkSNH7HqlIyIi8Pb25umnn8bb25v79+9z48YNtmzZYvsRmdqioqLo2rUrgwYN4uOPP0Ypxe7du/nkk0/sLoFljU2xt8M777zDs88+a3vepk0b201iYo8hbdKkCffu3UvRzoXIyEhq167NxIkTmTdvni32vv/++4mKvV26dGHs2LEEBgbaYm/9+vWdxt7evXvbYm+rVq3sYu+lS5dIkyYNo0aNImfOnNy7d48DBw7Qtm1buzuUxYy9MetbFSlS5ImMvSq5xwEVKFDA/QcauUBKXMbEHTRu3Di1m2AKZvmySm1a6ySfdj9z5swEY0yPHj16AN1jVtNa225bp5RqAdTVWr9led4BqKq1fi9Gma+AZ4DagC+wE2iotTbloO6yZctK7AWnV/R40owbNy61m2AKjq5j+6R6+PBhkuKvmWOv217nVgghIHG9B5ZgGt89mIOBgjGe+wMhDspc11rfBm4rpX4DKgKmTG6FECI5mTn2us9xZyGEcMBFl6PZA5RQShVRSqUHWgOxD7f8BNRQSqVVSmXAOHR2xKUrI4QQbsLMsVd6boUQbs0VQ6u01veVUu8C6wEvYLbWOkgp1dPy+nSt9RGl1DrgAPAQ+FZrnfqn8gshRCowc+yV5FYI4dZcdd6A1notsDbWtOmxnn8KpNzp20IIYVJmjr2S3Aoh3JoZLvIvhBBPGjPHXkluhRBuzRPu/CSEEO7GzLFXklshhFszc++BEEJ4KjPHXkluhRBuzcy9B0II4anMHHsluRVCuDUzB1ghhPBUZo69ktwKIdyamQ+NCSGEpzJz7JXkVgjh1szceyCEEJ7KzLFXklshhFszc4AVQghPZebYK8mtEMKtmfnQmBBCeCozx15JboUQbs3MvQdCCOGpzBx7JbkVQrg1M/ceCCGEpzJz7JXkVgjh1szceyCEEJ7KzLFXklshhFszc4AVQghPZebYm+zJbUhISHIvwi00aNAgtZtgCn/88UdqN8EUqlevntpN8BhmPjSWmo4cOZLaTTCFsWPHpnYTTGHcuHGp3QRTGDBgQGo3wWOYOfZKz60Qwq2ZufdACCE8lZljryS3Qgi3ZubeAyGE8FRmjr2S3Aoh3JqZew+EEMJTmTn2SnIrhHBrZg6wQgjhqcwceyW5FUK4NTMfGhNCCE9l5tgrya0Qwq2ZufdACCE8lZljryS3Qgi3ZuYAK4QQnsrMsVeSWyGEWzPzoTEhhPBUZo69ktwKIdyamXsPhBDCU5k59kpyK4Rwa2buPRBCCE9l5tgrya0Qwq2ZufdACCE8lZljryS3Qgi3ZuYAK4QQnsrMsVeSWyGEWzPzoTEhhPBUZo69ktwKIdyamXsPhBDCU5k59qZJ7QYIIURSPHz4MMFHYiil6imljimlTiqlhsRT7lml1AOl1BsuWwkhhHAzZo69qZrc+vv7s2zZMsLCwggPD2fFihUULFgwUXW9vb2ZMGECISEhREZGsmPHDmrUqBGnnFKKIUOGcObMGaKioti3bx+vv/56nHIdO3Zk+fLlnD17Fq013333XZwymTNn5sMPP2T79u1cv36d0NBQtm/fTtOmTR995R9T/vz5+fbbbzlx4gQnT55k9uzZFChQIFF1vb29+eijjzhw4ABnz55lzZo1VKtWLU657NmzM3nyZIKCgjh79iy//PILNWvWdPGaJM21a9f4+OOPadmyJS1atGDs2LFcvXo1UXWvXr3KxIkT6dy5M82bN6d79+7Mnz+fO3fu2JXr0qULjRo1ivPYuXNncqxSgvLnz8+sWbM4efIkp06d4rvvvnuk937EiBEcPHiQc+fOsXbtWofvfbZs2RgzZgx79uzh3Llz7Nmzh3HjxpEjRw67cl988QV//PEHp06d4syZM2zZsoWuXbuSJk3KhxStdYKPhCilvICpQH2gLNBGKVXWSblPgPUuXo0U5W6xN7YiRYpw+/ZttNYUK1YsUe1Oqrx58zJp0iR27drF7t27mTx5Mvny5UtU3T59+jBz5ky2b99OUFAQzZo1i1OmWbNmBAUFOX3kzJnTxWv0eMLCwpg3bx4ffvghw4cPZ+7cuYSGhia6/pUrV5g/fz4jRozggw8+YMKECfz+++92ZW7fvs3SpUsZOXIkH3zwAV9++SXHjh1z9aokSd68efnyyy/5+++/+eeff/jqq68SvT/069eP2bNns3v3bo4fP85rr73msNzmzZs5fvx4nEedOnVcuSqPzcyxN9WGJfj6+rJ582aio6N588030VozZswYtmzZQoUKFYiMjIy3/qxZs2jYsCEDBw7k9OnT9OrVi/Xr1/P888+zf/9+W7nAwEAGDBjAsGHD+Pvvv2ndujXLli2jUaNG/PLLL7Zy7du3J1euXGzcuJEWLVo4XGZAQADvvPMO3333HYGBgTx8+JA2bdqwcuVKevXqxbRp01yzcZzw9fVlxYoV3L17l969e6O1ZsiQIfzwww/UqlUrwW02adIk6tSpw+jRozl37hydO3dm8eLFNGzYkKCgIADSp0/PihUryJ49O4GBgVy9epW2bduyYMECWrZsyY4dO5J1HRPjzp07DB06lHTp0vH++++jlGL+/PkMHTqUr776Ch8fn3jrDh8+nAcPHtje8+PHj7No0SJCQkIYPHiwXfnKlSvTtm1bu2n+/v7Jsl7x8fX15YcffiA6Opr33nvP9t7/+OOP1KxZM8H3fvLkydSpU4dRo0Zx7tw5unTpwpIlS2jYsCGHDh2ylZs/fz5FixZlwoQJHD9+nFKlSjF48GAqVqxIgwYNbOV8fHyYNWuWLSGpVasWY8eOpUiRIgwfPjzZtoMjLjo0VhU4qbU+DaCUWgw0BQ7HKvcesAJ41hULTQ3uGHtjmzZtGuHh4WTIkOHxNsIj8vHxYfbs2dy9e5ehQ4eitaZ3797Mnj2b119/naioqHjrt2vXjqNHj7Jt2zannSHbtm2jTZs2dtOUUkydOpXg4GCuX7/usvV5XHfv3mXGjBl4eXnRqlUrANavX8/06dPp378/6dOnj7f+hQsXmDFjBsWKFaNFixb4+Phw/fp1oqOjbWXu37/P9OnTiYyMpGHDhmTOnJk///yT2bNn07179xT7MRMfHx8f5s2bx927dxk8eDBaa/r27cv8+fNp3LhxgvtD+/btOXr0KFu3bnWa2Fr99ttvTJkyxW7amTNnkrwOrmDm2JtqyW23bt0oWrQopUqV4tSpUwAcOHCAEydO0KNHDyZNmuS0boUKFWjXrh2dO3dmzpw5gBEYgoKCGD16tC145MqViwEDBjB+/Hg+//xzALZu3Urx4sUZP368XYCtW7eu7Y2qV6+ew+WeOXOGokWL2u24GzZsoGDBggwePDjZk9v27dtTqFAhXnjhBc6ePQvA4cOH2blzJx06dGDGjBlO65YtW5bmzZvTp08fFi9eDMCOHTv47bffGDx4MB07dgSgcePGlC1bltdee82WyG7evJktW7bw0UcfOd02KWn9+vVcuXKF6dOnkz9/fgAKFy5M9+7d+eWXX+INFocPHyYkJITRo0dTuXJlwNifIiIi+OGHH7hz545dcpwlSxZKly6dvCuUCDHfe2tgO3z4MLt27aJjx45Mnz7dad1y5crRvHlzevfubffe//777wwaNMj23hctWpSqVavSv39/5s+fbyv38OFDPv30U4oVK2b7rPbo0cNuGVu3biVPnjy0bds2xZNbF53UUAC4EON5MPBczAJKqQLAa8DLuHFy646xN6Y2bdpQqVIlxo0bx+TJkx9nEzyyN954A39/fxo1asT58+cBOH78OGvXrqVly5bMnTs33vrPPfccWmsCAgKcJrehoaFxekArV65MtmzZmDp1qmtWJIl2797Nv//+y6BBg2w9yfnz5+eTTz5h586dvPTSS07rPnz4kCVLllC8eHE6depkm168eHG7cvv37+fy5cv07NnTlsiWKlWKiRMnsmbNGnr37u36FXtELVu2pGDBgtStW9e2Pxw7dowNGzbQunXrBI8+VKlSxbY/JJTchoaG2v1oNBMzx95UG5bQpEkTdu3aZQuuAGfPnk3UYf4mTZpw9+5dlixZYpv24MEDFi9eTN26dW2/HuvWrYu3tzcLFiywq79gwQIqVKhA4cKFbdMS8wskMjLS4S+yv/76y5ZkJae6devy999/2xJbgPPnz/Pnn38m+KVQt25d7t69y08//WSb9uDBA1auXEnNmjVt26xKlSq2Q40xbd26lUqVKpE3b17XrdBj2r17N6VKlbLb5nnz5qVs2bLs3r073rr3798HiNPjkzFjRlMPjre+9zF/sbviva9Vq5btvbf+vXXrll398PBwgASHHISGhtq2b0pKzKExpVR3pdRfMR7dY81GOZp1rOeTgcFa6wfJsiIpxB1jr1XWrFmZOHEiAwYMICwsLNH1kqpWrVocOHDAlsgAXLx4kb1791KrVq0E6z9ubGnatCl3795l7dq1j1Xf1Q4fPkxAQIDdEIns2bNTuHBhDh+O3dFm7/Tp01y5coX//e9/8ZY7f/486dKlo2jRorZpSilKlizJhQsXbPEoNdWuXZt9+/bZ7Q/BwcH8888/1K5dO8H6Zv6ueRRmjr2pltyWK1fO7nCoVVBQEGXLxhluEaeudRxX7Lre3t62X4LlypXjzp07nDx5Mk45IMHlJNb//vc/jh496pJ5xadUqVIOl3Ps2DFKliwZb93SpUtz/vz5ONvs2LFjeHt7U6RIEcD4JeYoQbl7965tPqnt/PnzFCpUKM70gIAAu2DjyNNPP03+/PmZM2eObXvs37+fVatWUb9+/ThDGv7880+aN29Os2bN6N+/f6qNty1duvRjv/elSpVy+N4fPXrU7r0/evQoO3bsoF+/flSsWJGMGTNSqVIl+vfvz6+//sqJEyfizNvLy4ssWbLQqFEjWrVqFW8PcnJJTIDVWs/UWj8T4zEz1myCgZiDTv2BkFhlngEWK6XOAm8A05RSzZJrvZKLO8feCRMmcPTo0ThJc3IrXry4w/3/1KlTyXaY3Nvbm7p167Jt2zZTJHQAly9fdtjBkSdPHq5cuRJvXesP8/v37zNlyhQGDx7MyJEjWblyJffu3bOVS5MmDV5eXihln/OkTZvW1obU5mx/OHHiRJye6KR6+eWX2b9/P4cOHWLp0qWmGW8L5o69CQ5LUEqVxug23q21jogxvZ7Wel1C9Z3Jnj27w0HoN27cIFu2bI9d1/q69a+jX/exyyVFt27deP7552nXrl2S55WQrFmzOgxyYWFhZM2a9bHrWl8HOHnyJFmyZKFEiRJ2H95nnnkGIMH3JiVERESQKVOmONMzZ85MRESEgxr/SZ8+PRMmTODjjz/mnXfesU1/9dVX6dmzp13ZqlWrUqJECfLkyUNYWBirV69m7Nix9O/fP1G9Na6UNWtWh/tyaGhogu99tmzZHNaN/d4DtG3blqlTp7Jx40bbtA0bNvDWW2/Fqf/KK6+wcOFCwPhR9OWXXzJx4sQE18XVXHRobA9QQilVBLgItAbsBltrrYtY/1dKzQFWa61XumLhjkjstVe9enU6duxIpUqVHrluUvn5+XHz5s0408PDw8mSJUuyLLN27dpkzpzZ7ohLaouKinI4zjlDhgwJjjO1br8FCxZQvXp1GjRowIULF9iwYQNhYWG2oQq5cuXizp07XLlyhTx58tjqnzt3DiDBMeEpIaX2hy1btnDw4EGCg4PJkSMH7du3Z9q0aQwYMIBVq1a5bDmPy8yxN97kVinVG+gFHAFmKaX6aK2tn7SPgccOsJYGO1pmgvWUUomqm9hyj+ull17iyy+/ZN68eSxatMgl80yIq7dZbD/88AMDBw5kypQpvP/++1y5coUOHTrYzqw380WbE7N+d+/e5ZNPPiE8PJz+/fvbTij7/vvv8fLyolevXraysZPd559/ngEDBjB37twUT24hae99Yqd//vnnVKlShQEDBnD8+HFKlizJoEGDmDVrFu3bt7drw65du3jllVfIkiULNWrU4J133kFrzbhx4x5hrZLOFYf4tNb3lVLvYpyJ6wXM1loHKaV6Wl5P0S5pib320qVLx4wZM5g0aRJHjhx5rHkkVUofSm7atCn//vsvv/32W4ou93EkZttYy1SuXJm6desCUKxYMbTWrF271pbMVqpUiQ0bNrBkyRJatGhBlixZ2LVrl63n11Xf30mVnLmFVWBgoN3zjRs3smzZMvr372+K5NbMsTehnttuQBWtdYRSqjCwXClVWGv9BY7HSSRaaGiow1/v2bJlS/CyIjdu3CAgIMBhXevr1r+OeiJil3sczzzzDKtWrWLz5s107dr1sefzKMLDwx320vn5+SU4/iwsLMzhZaOs87PWv3nzJl26dGHKlCls3boVMA4nffbZZwwZMiTBQ08pIVOmTA57aJ316Ma0YcMGDh48yDfffGO7bEv58uXJkCEDX331FfXr17cb6xWTl5cX1atXZ86cOdy4ccMlPf+JFR4e7nBfdtajG1NoaKjD997Pzw/4772vU6cOzZs3p3nz5rZL8+zatYtz586xbNky6taty7p1/+VUt27dsp3o8Pvvv3Pv3j369evHd999l6KHDl31g0trvRZYG2uaw8Cqte7kkoU6J7E3hr59+5I9e3a+/PJL235r7UHMnDmz05jgKuHh4bblxuSsBy+pcubMSbVq1Vi0aBEPHphniLevr6/DntOoqCh8fX3jrWt9v2IPoypZsiRr164lJCSEPHny4OvrS8eOHVmyZIntSFCOHDl45ZVXWL9+fbL1lD+KmzdvOtwfsmTJkiz7g9XDhw/55ZdfGDRoELly5eLatWvJtqzEtscVkiP2JpTcelkPh2mtzyqlamIE2ULEE2AtA4ZjDxq2ExQURLly5eJML1u2bIID04OCgnjttdfw9fW1OxRStmxZoqOjbeO8goKC8PHxsTvL21oOSHA5zpQvX57169ezb98+mjdvnmIn0Rw7doxSpUrFmV6yZEmOHz8eb92jR49Sv379ONusZMmSREdH252otHv3bqpWrUqRIkXw8vLi1KlT9OrVi8jISA4cOOC6FXpMzsbWnj9/3uEXb0xnz54lU6ZMca5HaA24Fy5ccJrcxpTSvQdHjx597Pf+2LFjNGjQIM57X6pUKbv3vkyZMgDs3bvXrv4///wDQIkSJeyS29j27duHl5cXhQoVStHk1lNOzohFYm+stuXLl4+QkNhD8Yz9dd++fck6XOHUqVMOx1IWLVrUbv1cpXHjxqRNm9ZUQxLA+dja2EMInNV1xPr5jRlTixYtypAhQ7h+/Tpaa3LmzMm2bdtIly5doq/tnZxOnDhBiRIl4kwvXrx4nHHmrmbdTmaIe2ZogzMJnVB2WSn1tPWJJdg2AnICTzmrFHMAsbMyq1atolq1araTWQAKFSpE9erVE+xuX7VqFenTp7e7JqL1unsbNmywnfy0bt06oqOj44yHbd++PQcPHrS76kBiFS9enI0bN3L69GkaNWoU58L/yWn9+vVUqVLF7mSqggULUrVqVdavj/+6xuvXryd9+vQ0btzYNs3Ly4umTZuybds22zaL6cyZM5w8eRJfX1/at2/P8uXLTTHe6bnnnuPo0aN2CdSVK1c4cuQIVatWjbdutmzZiIiIiPMlaU0QY9+sIKYHDx7wxx9/kCtXrhQfe+yK975Jkya2adb3fuvWrbb33noTDOsl0qyqVKkCJHwixwsvvMDDhw8f63OVFIk5qcENSeyNYfz48dSsWdPuMX78eMC4hqyjMeGuZL0GcMxrXOfPn59KlSqxZcsWly+vSZMmHDt2LEVOVH4U5cqV4/z58/z777+2aTdu3ODs2bMJniRYunRp0qZNG+dmDNbYG/v64UopcuXKRe7cubl37x67d++mcuXKeHt7u2htHt/mzZupWLGi3Y1PChQoQOXKldm8eXOyLdfLy4t69epx8eJFU1z32MyxN6Ge246AXbek1vo+0FEp5fyiqonwzTff8O677/LTTz8xfPhwtNYEBgbaLvJsFRAQwKlTpxg9erRt/Mn+/ftZvHgxkydPJl26dJw5c4a3336bIkWK2AXTa9euMWnSJD744ANu3brFP//8Q6tWrXj55ZfjXPKmTJkytg+nr68vhQoVonnz5oBxHcfr16/bLjSePn16RowYEefDvHfvXodJoqssWLCALl26MHfuXMaPH4/WmsGDBxMSEsK8efNs5fz9/dm9ezeff/657bBOUFAQK1euJDAwkHTp0nH+/HnefPNN240pYho2bBj79+/nxo0bFClShHfeeYd79+4xduzYZFu3R1G3bl1Wr15NYGAgHTp0sN3EIWfOnNSvX99W7urVq7z11lu0adPGdnH0OnXqsHLlSkaOHEmrVq3IlSsXJ06cYPHixRQvXtz2nm7bto1du3bxzDPPkCtXLkJDQ1mzZg0nT55k4MCBKb7OCxYsoGvXrnbv/ZAhQxy+93/++Seff/657fqihw4d4scffyQwMJC0adNy/vx5OnXqREBAAG+//bat7po1a2w3wpg4caKtd2LAgAEEBwfbLkdUp04d2rRpw4YNGwgODiZTpkzUrl2bDh06MG/evBQfumLmceBJILGX/2LvsWPH4iRF1suJ7d69O1l6T2Navnw5bdu2ZcqUKXz55ZcAvPfee1y+fJlly5bZyuXLl49169Yxffp0vv76a9v0Z555huzZs9suoVWuXDlbR8GGDRvsllWmTBlKlizJhAkTknWdHsdzzz3H9u3bmTNnDnXr1kUpxfr168maNavdHQ9DQ0MZP348derU4ZVXXgGMyy3WqlWLTZs22Xr1g4OD2bhxI1WqVLG7vNjatWvx9/cnY8aMXL9+nW3btuHl5WV3I5nUtHTpUtvJXZMnT7bdxOHy5cu2a4mD8QPo119/ZerUqXbXKn722WfJnj07uXLlAuCpp56y7Q/WzoqGDRtSp04dtm3bxqVLl8iZMyft2rXjqaee4v3330/BtXXOzLE33uRWax0cz2vbk7LgyMhIXn75ZSZNmsT8+fNRSrFp0yb69u3L7du3beWUUqRNmzbONTY7d+7M2LFjGTNmDFmzZmX//v3Uq1cvziHVYcOGERERQZ8+fcibNy/Hjh2jZcuWrF692q5cy5YtGTlypO15rVq1bCcN1axZk23btlG2bFlbQF2zZk2cdSpcuLDtjM7kEBkZSfPmzRk9ejRfffUVSil+//13PvzwQ7seVWfbrE+fPnzwwQcMGTKELFmycPjwYdq0acPBgwftyuXKlYvAwEBy5szJ9evX+eWXX5gwYUKKXlcyPj4+PowdO5Zvv/3WlsBVrFiRbt262Y370lrHub91njx5+Pzzz1m0aBHz58/n5s2b5MyZk3r16tGqVSvbNsuTJw/h4eF899133Lp1C29vb0qUKMGoUaNsPZkpKTIyktdff53AwECmTp1qe++HDx+eqM9Lnz59GDp0KB988AFZsmQhKCiI1q1b2733ERER1K9fn4EDB9KrVy/bIcj169fz6aef2pZz9uxZ0qRJw5AhQ8iZMyc3b97k9OnTvPvuu/zwww8ps0FicNOe2XhJ7LWPvaktKiqKLl26MHjwYMaPH49Sil27djF+/HiHsTf2sKVevXrZHVVq27at7c6HsYeING3alHv37sXZTmaQPn16evTowapVq2xJXPHixWnSpIldj6o19sb+bL7yyit4e3uzc+dOtm3bRubMmalZs2acy1tFRESwatUq23kU5cuX59VXX02xO9IlJCoqio4dOzJ06FA+/fRTwDg/YezYsYn6Lu7duzfPPffffQrat29P+/btgf+GyAUHB5M9e3YGDRqEn58fd+7c4eDBg3Tp0oU//vgjuVcxUcwce1VyN04pZd61T0G5c+dO7SaYglk+lKmtevXqqd0EU7h69WqSBy+3bds2wRizaNEic5xinYIk9hpcdT1zd5fSVzExqwEDBqR2E0zj+PHjSYqLZo69qXb7XSGEcAUz9x4IIYSnMnPsleRWCOHWzBxghRDCU5k59kpyK4Rwa2Y+qUEIITyVmWOvJLdCCLdm5t4DIYTwVGaOvZLcCiHcmpl7D4QQwlOZOfZKciuEcGtm7j0QQghPZebYK8mtEMKtmTnACiGEpzJz7JXkVgjh1sx8aEwIITyVmWOvJLdCCLdm5t4DIYTwVGaOvZLcCiHcmpkDrBBCeCozx15JboUQbs3Mh8aEEMJTmTn2SnIrhHBrZu49EEIIT2Xm2CvJrRDCrZm590AIITyVmWOvJLdCCLdm5t4DIYTwVGaOvZLcCiHcmpkDrBBCeCozx15JboUQbs3Mh8aEEMJTmTn2SnIrhHBrZu49EEIIT2Xm2CvJbQq5evVqajfBFCpVqpTaTTCF06dPp3YTPIaZew9E6jty5EhqN8EU+vbtm9pNMIV169aldhM8hpljryS3Qgi3ZubeAyGE8FRmjr2S3Aoh3JqZA6wQQngqM8deSW6FEG7NzIfGhBDCU5k59kpyK4Rwa2buPRBCCE9l5tgrya0Qwq2ZOcAKIYSnMnPsTZPaDRBCiKR4+PBhgo/EUErVU0odU0qdVEoNcfB6O6XUActjh1KqostXRggh3ISZY6/03Aoh3Joreg+UUl7AVOAVIBjYo5RapbU+HKPYGeAlrXWoUqo+MBN4LskLF0IIN2Tm2CvJrRDCrbnopIaqwEmt9WkApdRioClgC7Ba6x0xyu8C/F2xYCGEcEdmjr0yLEEI4da01gk+EqEAcCHG82DLNGe6Ar8kodlCCOHWzBx7pedWCOHWEhNAlVLdge4xJs3UWs+MWcTRrJ3MqxZGgH3xEZophBAexcyxV5JbIYRbS8yhMUswnRlPkWCgYIzn/kBI7EJKqQrAt0B9rfW/j9ZSIYTwHGaOvTIsQQjh1lx0aGwPUEIpVUQplR5oDayKWUApFQD8AHTQWh93+YoIIYQbMXPslZ5bIYRbc8VJDVrr+0qpd4H1gBcwW2sdpJTqaXl9OvARkAOYppQCuK+1fibJCxdCCDdk5tgrya0Qwq256kLiWuu1wNpY06bH+P8t4C2XLEwIIdycmWOvJLdCCLdm5rvkCCGEpzJz7PXYMbf+/v4sW7aMsLAwwsPDWbFiBQULFky4okkkpf3e3t5MmDCBkJAQIiMj2bFjBzVq1IhTTinFkCFDOHPmDFFRUezbt4/XX389TrmOHTuyfPlyzp49i9aa7777Lsnr9ygKFCjAggULuHjxIiEhISxatAh//8RdYtTb25sxY8Zw8uRJrl27xqZNm6hevXq8dVq0aEFERATHjh2L89ovv/xCREREnMc777zzWOuWVFeuXGH48OHUq1ePunXrMmzYMK5cuZKouiEhIQwfPpz69evzyiuv0Lt3b44ePRqn3OLFixk8eDBNmzalRo0azJ4929WrkSSuukuOcA13ir3+/v4sXbqU0NBQwsLCWL58+SPH2YsXL3L79m22b98eb5w9ffo0kZGR7N27N06cfemll+Ldf597zv569T4+PowYMYJjx44RFRXFpUuXWLVqFenSpXv8jZFI+fLlY+rUqezfv5/9+/fz9ddfkz9//kTVHTBgAHPnzuXvv//m9OnTNG/ePE6ZjBkzMmXKFDZv3syhQ4fYt28fP/zwA02bNnX1qiTJtWvXGDduHK1ataJly5Z8/PHHXL16NVF1r169yqRJk+jcuTPNmzenR48ezJ8/nzt37tiV69q1K40bN47z2LlzZ3Ks0iMzc+z1yJ5bX19fNm/eTHR0NG+++SZaa8aMGcOWLVuoUKECkZGRqd3EeCW1/bNmzaJhw4YMHDiQ06dP06tXL9avX8/zzz/P/v37beUCAwMZMGAAw4YN4++//6Z169YsW7aMRo0a8csv/11Grn379uTKlYuNGzfSokWLZFtvR3x9fVmzZg13796lR48eaK356KOPWLt2LdWqVUtwW0ybNo26desyfPhwzp49S/fu3Vm5ciUvv/wyBw8ejFPez8+P8ePHc/nyZafzPHjwIL1797abdu7cucdbwSS4c+cOffv2JV26dAwdOhSlFN9++y29e/dmzpw5+Pr6Oq0bHh5Or169yJAhAwMGDMDHx4clS5bQu3dvZs6cSeHChW1lV69eTYYMGahRowY//fRTCqzZozFz78GTxp1ir6+vL5s2bSI6OppOnTqhtSYwMJDNmzdTsWLFBNv67bff0rBhQwYNGsTp06d55513WLduHS+88EKcONu/f3+GDx9ui7NLly6lcePGtjj7zz//8PzzzztcRvbs2dmzZ49tWtq0aVm7di1FihRh/PjxHD58mFy5cvHKK6/g5eXFvXv3XLSF4vLx8WHhwoVER0czYMAAtNb079+fhQsX0qBBA6KiouKt37FjR44cOcLmzZsdJrYA6dKl48GDB0yfPp3g4GDSp09Pw4YNmTRpEjly5DDFj+s7d+4wbNgw0qVLR9++fVFKsWDBAoYNG8aUKVPw8fGJt+6HH37I/fv3bd+tJ06cYNGiRYSEhDB48GC78pUrV6ZNmzZ20xLbuZPczBx7PTK57datG0WLFqVUqVKcOnUKgAMHDnDixAl69OjBpEmTUrmF8UtK+ytUqEC7du3o3Lkzc+bMAWDbtm0EBQUxevRo26/fXLlyMWDAAMaPH8/nn38OwNatWylevDjjx4+3S27r1q1r24nr1auXHKvsVOfOnSlSpAiVKlXi9OnTABw6dIj9+/fTpUsXvvrqK6d1y5cvT6tWrejZsycLFiwA4Pfff2fPnj0MHz6cVq1axakzZswYDh48yOXLl6lVq5bD+d66dcvuyya1/Pzzz4SEhLBw4UJbsCtWrBht27blp59+onXr1k7rrly5ktDQUKZMmWKrW7lyZVq1asXs2bMZPXq0rey8efNIkyYN9+/fl+RWxMudYq+1raVLl7Zr6/HjxxMdZ7t06WIXZw8dOsSoUaNo1qwZYMTZ/v3788knn9jF2WLFijFu3DhbnL116xa7d++2W0ZAQABlypRh4sSJdj1g/fv3p3LlypQvX57g4GDb9B9++CHJ2yQhrVu3pmDBgtSpU8f2g/7o0aNs3ryZtm3bMmvWrHjrV6xYEa01hQoVcprchoWF0bdvX7tpW7dupUiRIrRo0cIUye2GDRu4cuWKXa914cKF6dGjB+vWrbO9/44cPnyYkJAQRo0aReXKlQFjf7p16xY//vgjd+7csUuOs2TJQunSpZN1fR6XmWOvRw5LaNKkCbt27bIFLICzZ8+yfft20x3acCQp7W/SpAl3795lyZIltmkPHjxg8eLF1K1bl/Tp0wNGwurt7W1L+qwWLFhAhQoV7HruUnMHbtCgAX/++actsQWjl3TXrl00atQo3roNGzbk7t27rFixwjbtwYMHrFixgjp16ti2hVW1atVo1aoV/fr1c+1KJJM//viDsmXL2v2Kz58/P+XLl+ePP/6It25QUBD+/v52dX19falQoQI7duzg/v37tulp0pg7TJj50NiTxp1ib+PGjZ22tUmTJvHWdRZnlyxZkqg4u3DhwjhxNrYOHTqQJk0a5s6dazf97bffZvny5XaJbUqpU6cOe/futTtSFRwczN9//02dOnUSrJ+U75KwsLBk7ZV+FLt376ZUqVJ2wzHy5s1LmTJl2LVrV7x1rbE1Q4YMdtMzZsxo6mTRETPHXnN/az2mcuXKcejQoTjTg4KCKFu2bCq06NEkpf3lypWzjaGNXdfb25vixYvbyt25c4eTJ0/GKQeYZjuVKVOGI0eOxJl+5MiRBH/NlilThrNnz8bZFkeOHMHb25tixYrZpqVNm5YpU6bwxRdf2CXSjlSsWJGLFy8SGhrKrl276Nix4yOskeucPXuWokWLxplepEgRzp49G29dLy8v0qaNe+Amffr0REdHExIS5xrapuWiay0KF3Cn2FuuXDlbvIvp8OHDCba1bNmyyR5nO3TowN9//23XxoIFCxIQEMDp06eZOXMmYWFhREZGsnHjRipWrBj/CrtAiRIlOH487mVGT5w4YVtnV/Ly8iJr1qy0bt2aGjVqpPj5Hs6cP3+egICAONMDAgK4cOGCgxr/efrpp8mfPz9z5szh/PnzREVFsX//fn7++Wfq1asXZ0jDn3/+SfPmzXnttdcYMGCAacbbgrljb4LDEpRSVQGttd6jlCoL1AOOWi7dYErZs2cnNDQ0zvQbN26QLVu2VGjRo0lK++Ora33d+jcsLCzBcqktW7ZsDtcnNDSUrFmzJlg3vnWMuS379etH+vTp+eyzz+Kd5/bt21myZAknT57Ez8+Ptm3bMm3aNPLmzcuECRMSXiEXunnzJpkzZ44zPUuWLERERMRbt2DBguzZs4fw8HD8/PwA41e49YfEzZs3Xd/gZOKpPbMSe5OXmeNstWrVKFmyJH369LGbbu0pHDRoEHv27KFNmzZ4e3szcuRItmzZQsWKFRNMrpLCz8/PYWwICwuzxRFX6dChA6NGjQLg7t27BAYG8uOPP7p0GY8rIiKCTJkyxZmeOXPmBGNv+vTp+eSTTxg3bhy9evWyTX/11Vfp2bOnXdmqVatSokQJ8uTJQ1hYGKtXr+bjjz+mX79+TofNpSQzx954k1ul1AigPpBWKbUReA7YCgxRSlXSWo9N/iY+Hke/GCwX/3ULj9t+pVSi6ia2nBkk97YoWrQoAwcOpE2bNkRHR8c7zzFjxtg9X7NmDd9//z0DBw5k6tSp3L59O8F2JbfE/Fpu1qwZK1asYMyYMfTt2xdvb2/mz5/PpUuXAHPuB854Ys+sxN6UYdY4++abb3L37l0WLVpkN906RCgyMpImTZrYeo7/+usvTpw4Qa9evRgyZEiC7U+KlHp/16xZw759+8iWLRt16tRhxIgRPHjwgO+//97ly3ocjtY5MbHo7t27TJgwgfDwcPr160euXLk4fvw4ixcvxsvLy+7KOz169LCrW61aNQYMGMC8efNMkdyaOfYm1HP7BvA04A1cBvy11jeVUp8CuwFTBtjQ0FCHv4id9QKaTVLaf+PGDYeHS6w9EdYeA2e9E7HLpbawsDCH2yJr1qwOe0RiCg0NdXhWqXUdrdvy008/Zdu2bezZs8fW+5A+fXqUUvj5+REdHR3nEi0xLVu2jMaNG1OuXDn+/PPPxK5akmXOnJlbt27FmX7r1i2HvQox5c+fnw8//JBJkybZTjwrWbIkLVq0YPHixeTMmTNZ2pwczBxgk0BibzIza5xNnz49LVq0YM2aNfz77792r1mfb9++3W5IRHBwMEePHuXpp5+Ot91JdfPmTYc9tH5+foSHh7t0WTdu3LBtn99++w0fHx8++OADli1bZndOQGrIlCmTw9jrrEc3po0bN3Lw4EFmzpxJvnz5AOPk54wZM/LVV19Rv359ihQp4rCul5cXL774InPmzOHGjRupfoTVzLE3oTG397XWD7TWkcAprfVNAK11FOC0P1op1V0p9ZdS6i8XtjXRgoKCKFeuXJzpZcuW5fDhw6nQokeTlPYHBQVRpEiROJeBKlu2LNHR0baxX0FBQfj4+NiNO7WWA0yznZyNrS1durTDa7LGrlu4cOE426J06dJER0fbTiQpXbo09erV4+LFi7ZHy5YtyZ8/PxcvXrQdGnPG+gs+pT/oRYoU4cyZM3Gmnz17Nt4TVaxq1qzJDz/8wPz581m8eDGzZs0iKiqK3LlzkydPnmRocfIw80kNSSCxN5k5GwdcpkyZBNt6+PDhZIuzTZo0IXv27MybNy/Oa9Zr5TrrPU3uff348eOULFkyzvTixYvHGVfsagcPHiRTpkym+OEdEBDA+fPn40y/cOFCgtdJPnv2LJkyZbIltlbW7ZrQsBLre2+GoyFmjr0JJbd3lVLWU/qqWCcqpfyIJ8BqrWdqrZ9Jrfuur1q1imrVqtn9+ilUqBDVq1dn1apVqdGkR5KU9q9atcr2y9/Ky8uLVq1asWHDBu7evQvAunXriI6Opl27dnb127dvz8GDBxM8ISmlrFmzhqpVq9olawEBAVSrVo01a9YkWDd9+vS89tprtmleXl40b96cTZs22bZFp06dqF+/vt1j48aNXL9+nfr16zNjxox4l9OiRQsiIyMdnpySnKpXr267rIzVpUuXOHjwIC+++GKi5uHl5UXhwoUpUKAA169fZ/PmzfFexsaMzHxSQxJI7E1mP//8s9O2/vzzz/HWdRZnW7Zsmag4265dO6dxtmPHjly/ft1hfLt//z5r1qyhRo0admfbFyxYkFKlSvHXX8n7m2bTpk08/fTTdglcgQIFqFKlCr/++muyLvu5554jIiIiTm92aqhatSrHjh2zux76lStXOHLkSJwbbsSWLVs2IiIi4py0a71pUI4cOZzWffDgAdu3bydXrlymGMNu5tir4lu4Uspbax1nEKJSKieQT2sd9yr4ccum+NplyJCB/fv3ExUVxfDhw20X586cOTMVKlQwxbjI+CS2/QEBAZw6dYrRo0cTGBhoq//9999Tt25dBg4cyJkzZ3j77bdp1KgRL7zwAnv37rWVGzduHH379mXo0KH8888/tGrVih49etC0aVNWr15tK1emTBlbT8OMGTM4cOAAU6dOBYxrO16/fj3R65YxY8ZH3hY7d+7kzp07jB49Gq01H374IZkyZaJatWq2bVGwYEEOHjzI+PHjGT9+vK3+nDlzqF27NsOHD+fcuXO89dZb1KtXj9q1a9tdaD226dOnU6tWLUqVKmWb9sILL9CvXz9WrVrF+fPnyZIlC23btqVRo0a2Q/yJldAVGRIjKiqKzp074+3tzVtvvWW7iUNkZCRz5syxffldvnyZ1q1b8+abb9K5c2fA+JKcNm0aTz/9NBkzZuTMmTMsWLCAAgUKMHnyZLs7HR09epRLly6htWbEiBHUqlXLNt7r+eefj/eC5QnJnTt3krsfChYsmGCMuXDhQup3czwCib2u46yHK0OGDOzbt4+oqCg+/PBDtNaMHj2azJkzU7FiRbs4e/LkSQIDA+3i7KJFi6hbty6DBg3izJkz9OzZk0aNGlG9evU4cbZPnz4MGzbMFme7d+9Os2bN7OIsGNfFDQ4OZvr06XFOJrMqU6YMu3fv5q+//mLixIn4+Pjw0UcfkStXLipWrOj0LlmJOZqTEOtNdaKjo/n888/RWtOvXz8yZsxIgwYNbDe+yJ8/P1u3bmXKlClMmTLFVr9q1arkyJGDnDlzMmrUKObNm2e7vq/1mr9t2rShUqVKbN++nUuXLpEtWzYaNGhA48aN+eSTTxLsbEjIunXrklQfjBsx9O7dm/Tp09O+fXvbTRyioqKYMmWKrUf/6tWrdOvWjdatW9tuxHDlyhXee+89smXLRsuWLcmVKxcnT55k8eLFFChQgM8//5w0adKwbds2du/ezTPPPEPOnDkJCwtjzZo1HD58mIEDB/K///0vyetRsmTJJMVFM8feeMfcOgqulunXgcRnNCksMjKSl19+mUmTJjF//nyUUmzatIm+ffuaPrGFxLdfKUXatGnjXIe0c+fOjB07ljFjxpA1a1b2799PvXr17AIuwLBhw4iIiKBPnz7kzZuXY8eO0bJlyzgBt2XLlowcOdL2PGZyU7NmTbZt2+biLfCfyMhIGjZsyCeffMI333yDUoqtW7cyePDgRG2Lnj17MmLECD766CP8/Pw4ePAgr732WryJrTOXL18mTZo0DB8+nBw5cnDv3j0OHTpE586dWbZsWZLX9VH5+vryxRdfMGXKFMaMGYPWmipVqtC7d2+7Xh2tNQ8ePIjzKzo4OJhff/2ViIgIcuXKRcOGDenQoUOcW3iuWLHC7gthy5YtbNmyBYClS5fGObyW0ty0ZzZeEnuTX2RkJLVr12bixInMmzfP1tb3338/UbGlS5cujB07lsDAQFucrV+/vtM427t3b1ucbdWqVZw4C0aPbrp06eJc2zamI0eOULt2bcaPH8/ixYu5d+8eW7Zs4bXXXkv07V8fV1RUFO3bt2f48OF8/vnnKKXYsWMHgYGBdnd0c7bN+vbtS7Vq1WzPO3bsaLuUovWyhseOHeOVV17hgw8+wM/Pj9DQUE6dOkXXrl1tcSe1+fj4MGbMGL799lsmTpwIGDdi6Natm91QFa01Dx8+tItRefLk4bPPPmPRokUsWLCAmzdvkjNnTurWrUurVq1s2yxPnjyEh4fz3XffcevWLby9vSlRooTdzR9Sm5ljb7w9ty5ZQCr0HgjzetSeW0/lip5bT+CKntsCBQokGGMuXrzoVj23riCx12CGsYlm4IqeW0/gip5bT5HUnlszx16PvP2uEOLJ4aYnjAkhhFszc+yV5FYI4dbMfGhMCCE8lZljryS3Qgi3ZubeAyGE8FRmjr2S3Aoh3JqZew+EEMJTmTn2SnIrhHBrZg6wQgjhqcwceyW5FUK4NTMfGhNCCE9l5tgrya0Qwq2ZufdACCE8lZljryS3Qgi3ZuYAK4QQnsrMsVeSWyGEWzPzoTEhhPBUZo69ktwKIdyamXsPhBDCU5k59kpyK4Rwa2buPRBCCE9l5tgrya0Qwq2ZufdACCE8lZljryS3Qgi3ZuYAK4QQnsrMsVeSWyGEWzPzoTEhhPBUZo69aVK7AUIIkRRa6wQfiaGUqqeUOqaUOqmUGuLgdaWU+tLy+gGlVGWXr4wQQrgJM8de6bkVQrg1V/QeKKW8gKnAK0AwsEcptUprfThGsfpACcvjOeBry18hhHjimDn2Ss+tEMKtuaj3oCpwUmt9Wmt9F1gMNI1VpikwTxt2AVmVUvlcuzZCCOEezBx7JbkVQrg1FwXYAsCFGM+DLdMetYwQQjwRzBx7k31YgtZaJfcyEqKU6q61npna7Uhtsh0Msh0MnrIdHj58mGCMUUp1B7rHmDQz1ro7mkfsyJyYMqYhsdc8ZDsYZDv8xxO2hZlj75PSc9s94SJPBNkOBtkOhidmO2itZ2qtn4nxiP2lEgwUjPHcHwh5jDLC3hOzjyVAtoNBtsN/nohtkVqx90lJboUQIj57gBJKqSJKqfRAa2BVrDKrgI6WM3erAeFa60sp3VAhhPAgyRJ75WoJQognntb6vlLqXWA94AXM1loHKaV6Wl6fDqwFGgAngUigc2q1VwghPEFyxd4nJbl163EtLiTbwSDbwSDbIQat9VqMIBpz2vQY/2ugV0q3y83JPmaQ7WCQ7fAf2RYWyRF7lZlvnyaEEEIIIcSjkDG3QgghhBDCY3h8cpvQbd2eBEqp2Uqpq0qpQ6ndltSklCqolNqilDqilApSSvVJ7TalBqWUj1LqT6XUfst2GJXabRKeR2KvxF4rib0Gib0px6OHJVhu63acGLd1A9rEuq2bx1NK/Q+IwLjDR/nUbk9qsdzRJJ/W+h+lVGbgb6DZE7g/KCCj1jpCKZUO+APoY7nzixBJJrHXILHXILHXILE35Xh6z21ibuvm8bTWvwE3UrsdqU1rfUlr/Y/l/1vAEZ7AO0xZbmEYYXmazvLw3F+5IjVI7EVir5XEXoPE3pTj6cmt3C5TOKSUKgxUAnanclNShVLKSym1D7gKbNRaP5HbQSQbib3CIYm9EntTgqcnt251u0yRMpRSmYAVQF+t9c3Ubk9q0Fo/0Fo/jXGnl6pKqSf2kKlIFhJ7RRwSeyX2phRPT27ldpnCjmWc0wpgodb6h9RuT2rTWocBW4F6qdsS4WEk9go7EnvtSexNXp6e3Cbmtm7iCWEZzD8LOKK1npja7UktSqlcSqmslv99gTrA0VRtlPA0EnuFjcReg8TelOPRya3W+j5gva3bEWCp1joodVuV8pRS3wM7gVJKqWClVNfUblMqqQ50AF5WSu2zPBqkdqNSQT5gi1LqAEYSslFrvTqV2yQ8iMReg8ReG4m9Bom9KcSjLwUmhBBCCCGeLB7dcyuEEEIIIZ4sktwKIYQQQgiPIcmtEEIIIYTwGJLcCiGEEEIIjyHJrRBCCCGE8BiS3AohhBBCCI8hya0QQgghhPAYktwKIYQQQgiPIcmtEEIIIYTwGJLcCiGEEEIIjyHJrRBCCCGE8BiS3AohhBBCCI8hya2wUUpNV0p9mNrtEEKIJ5FSqqZSKji12yGEu5Pk1kMopc4qpeokZR5a655a60BXtelRKaXaKqX+UkpFKKUuKaV+UUq9GE/595VSl5VS4Uqp2Uop73jKPq2U+lspFWn5+3SM18orpdYrpa4rpbSLV0sIIUxBKZVeKTVSKXVCKXXb8r0xWylV2El5b8vrNy2xtl8C82+rlDpnmfdKpVT2GK+1VErtsMTgra5dMyHsSXL7hFBKpU3tNsTHEjQnAx8DeYAAYBrQ1En5usAQoDZQGCgKjHJSNj3wE7AAyAbMBX6yTAe4BywFurpkZYQQwpyWA02AtoAfUBH4GyOOOjISKAEUAmoBg5RS9RwVVEqVA2YAHTBieCRGDLe6gRHjxydxHYRIkCS3HkApNR8jGfzZ0us5SClVWCmllVJdlVLngc2Wssti9Hb+ZglI1vnMUUqNsfxfUykVrJTqr5S6aulJ7ZxM7fcDRgO9tNY/aK1va63vaa1/1loPdFLtTWCW1jpIax0KBAKdnJStCaQFJmuto7XWXwIKeBlAa31Maz0LCHLdWgkhnkRKqSFKqeWxpn2hlPrS8n9npdQRpdQtpdRppVSPFGpXHeAVoKnWeo/W+r7WOlxrPdUS/xzpCARqrUO11keAb3AeZ9sBP2utf9NaRwAfAq8rpTIDaK1/1VovBUJcuV5COCLJrQfQWncAzgONtdaZtNYTYrz8ElAGqGt5/gvGL/HcwD/AwnhmnRfj130BjF7NqUqpbC5uPsDzgA/wo7MCSqkXlVJhMSaVA/bHeL4fyKOUyuGgejnggNY65pCDA5bpQgjhSt8DDZRSWQCUUl5AS2CR5fWrQCMgC9AZmKSUqpwC7aoD/Km1vuCsgCUxX235PxuQn7hx1lnctIvJWutTwF2gZBLbLcQjk+TW84209IRGAWitZ2utb2mtozEOOVW09Jw6cg8YbelFXQtEAKWSoY05gOta6/vOCmit/9BaZ40xKRMQHuO59f/MDqrHLmst76isEEI8Nq31OYyOg2aWSS8DkVrrXZbX12itT2nDNmADUCMFmpYDuBRfAa31eK11I8vTTJa/seOss7gpcVaYhiS3ns/2K10p5aWUGq+UOqWUugmctbyU00ndf2MlnJH8F/BslFJ1LMMhEvMY62g5QM5HHBccgdHzYWX9/1YiylrLOyorhBBJtQhoY/m/Lf/12qKUqq+U2qWUumE5GtUA5zHYRik16hHirKNxsf8C+R5hHSIsf2PHWWdxU+KsMA1Jbj2Hs7P8Y05vi3GCVh2M4QaFLdNVkhZsjKXKlMjHMAez2Anc4b+ejsQIwjgZwqoicEVr/a+TshWUUjHXswIyxlYIkTyWATWVUv7Aa1iSW8sVXVYAnwF5LEej1pKIGKy1HvEIcXadg1n8ClS1tClBlnMZLhE3zjqLm3YxWSlVFPAGjidmeUK4kiS3nuMKxhUD4pMZiMb4BZ8B48oEqU5rHQ58hDGmt5lSKoNSKp2lh2OCk2rzgK5KqbKWsWHDgTlOym4FHgC9LZe2edcy3XqSnVJK+QDpLc99VDyXFRNCiPhora9hxJ3vgDOWk7HAiDHewDXgvlKqPvBqCrXpV2Aj8KNSqopSKq1SKrNSqqdSqouTavOA4UqpbEqp0kA3nMfZhUBjpVQNpVRGjJOEf9Ba3wLbkUMfjJN701jibDoXrqIQNpLceo5xGEEoTCk1wEmZecA54CJwGNiVUo1LiNZ6ItAPI0m9hjGc4l1gJYAlYEbEKL8OmABswVinc8AI6+vKuEbuUEvZuxi9wh2BMKAL0MwyHYzL3ETxX49EFHDM9WsphHiCLMI4SmYbkmBJ9HpjXHowFONo2qoUbNMbGD3FSzDGwx4CnsHo1UUpNVQp9UuM8iOAUxjxdRvwacxeYcsQiBoAWusgoCdGknsVozPlnRjz6oARW7/GGGMchXH1BSFcTtmfQC6EEEIIIYT7kp5bIYQQQgjhMSS5FUI88ZRxi9GrSqlDTl5XSqkvlVInlVIHUui6pEII4dGSK/ZKciuEEMZJMg5vK2pRH+PmJyWA7hjjBoUQQiTNHJIh9kpyK4R44mmtfwNuxFOkKTDPcuH9XUBWpdSjXDNUCCFELMkVeyW5FUKIhBUgxg1RgGDLNCGEEMnnsWLvo9wR6rGcPn1aLscA1KlTJ7WbYApnzpxJ7SYIE9FaJ+kGItbZJFRAKdUD45CW1Uyt9cxHWIajdpo6th05csTU7Uspr7/+emo3wRSOHj2a2k0QJuOC+Gva2Jvsya0QQiSnxFzO0BJMHyWgxhYMFIzx3B8IScL8hBDCrZk59sqwBCGEW3v48GGCDxdYBXS0nLlbDQjXWl9yxYyFEMIdmTn2Ss+tEMKtueJGNEqp74GaQE6lVDDGnZnSWeY/HeOuTg2Ak0Ak0DnJCxVCCDdm5tgrya0Qwq25ondAa90mgdc10CvJCxJCCA9h5tgrya0Qwq3JLcSFECLlmTn2SnIrhHBrZg6wQgjhqcwceyW5FUK4NRedtCCEEOIRmDn2SnIrhHBrZu49EEIIT2Xm2CvJrRDCrZk5wAohhKcyc+yV5FYI4dbMfGhMCCE8lZljryS3Qgi3ZubeAyGE8FRmjr2S3Aoh3JqZew+EEMJTmTn2SnIrhHBrZu49EEIIT2Xm2CvJrRDCrZk5wAohhKcyc+x1i+T22rVrzJgxg71796K1plKlSvTo0YPcuXMnWPfq1avMmzePAwcOcPPmTXLmzEmNGjVo1aoVPj4+AGzcuJGJEyc6ncfChQvJnj27y9YnKfLly8fw4cN58cUXAdixYweBgYGEhIQkWHfAgAE89dRTlC9fnmzZsjFw4EBWrFhhVyZjxoyMHz+ecuXKkTt3bu7fv8/p06eZO3cuP/30U7KsU0rw9/dn0qRJvPLKKyil+PXXX+nbty8XLlxI7aalKE/cDmY+NOYJrl27xuzZs9m/fz9aaypWrEjXrl3JlStXououWrSIgwcP2uJv9erVad68uS3+xvbbb78xceJEcuTIwaxZs1y9Oo8tb968DBkyhBdeeAGlFDt37mTcuHFcunQpwbp9+/alfPnylCtXjqxZs/LBBx+wcuVKh2Vz585N7969+d///oefnx9Xr15l7dq1TJo0ycVrlDI8MeY8Dk/cDmaOvaZPbu/cucOQIUNIly4d/fv3RynFvHnzGDx4MF9//bXTAGmtO3ToUO7fv0+HDh3InTs3x48fZ8GCBYSEhPDBBx8A8OyzzzpMbkeOHEnevHlNk9j6+PiwcOFCoqOjGTBgAFpr+vfvz8KFC2nQoAFRUVHx1u/YsSNHjhxh8+bNNG/e3GGZdOnS8eDBA6ZPn05wcDDp06enYcOGTJo0iRw5cjB79uzkWLVk5evry+bNm4mOjubNN99Ea82YMWPYsmULFSpUIDIyMrWbmCI8dTuYuffA3UVHR/PRRx+RLl06evfujVKKhQsXMnz4cL744osE4++IESO4f/8+bdu2JVeuXJw4cYLFixcTEhLCwIED49SJiIhg9uzZZMuWLTlX65H5+PgwZ84c7t69ywcffIDWmj59+jBnzhyaNWuWYOxt3749R44cYevWrTRr1sxpufz587No0SKCg4P5+OOP+ffff8mfPz+FChVy8RqlDE+NOY/KU7eDmWOv6ZPbdevWcfnyZb755hvy588PQJEiRejatStr167l9ddfd1o3KCiIixcvMmbMGKpUqQJAxYoVuXXrFitWrODOnTv4+PiQNWtWsmbNalf30KFD3Lx5k/bt2yfbuj2q1q1bU7BgQerUqcO5c+cAOHr0KJs3b6Zt27YJ9nJUrFgRrTWFChVymtyGhYXRt29fu2lbt26lSJEitGjRwi2T227dulG0aFFKlSrFqVOnADhw4AAnTpygR48ebtsj8qg8dTuYuffA3W3YsIErV64wdepU8uXLB0DhwoV5++23Wb9+PU2bNnVa98iRI4SEhDBixAgqVaoEwFNPPUVERAQrV64kOjoab29vuzpz586lcOHCZMuWjQMHDiTfij2iFi1a4O/vT4MGDTh//jwAx44dY926dbRs2ZK5c+fGW//ZZ59Fa01AQEC8ye3IkSO5cuUKnTp14v79+65chVThqTHnUXnqdjBz7E2T2g1IyK5duyhdurQtsQXj8FDZsmXZuXNnvHWtwSFDhgx20zNlypTgL45ff/2VtGnT8tJLLz1my12vTp067N2715bYAgQHB/P3339Tp06dBOsn5VdWWFgY9+7de+z6qalJkybs2rXLFlQAzp49y/bt2+P9cvY0nrodtNYJPsTj+fPPPylZsqQtsQXIkycPZcqU4c8//4y3rrP4mzFjRofvy5EjR9i2bRs9evRwUetdp1atWuzfv9+W2AJcvHiRvXv3Urt27QTrJ2YfLFiwIDVq1GDhwoUekdiC58acR+Wp28HMsdf0ye358+cdHpIpVKiQXaBxpFKlShQoUIDZs2dz7tw5oqKi2LdvHytXrqRBgwZOD6lFR0fz+++/89xzz5ElSxaXrIcrlChRguPHj8eZfuLECYoXL+7y5Xl5eZE1a1Zat25NjRo1+O6771y+jJRQrlw5Dh06FGd6UFAQZcuWTYUWpQ5P3Q5mDrDu7sKFCwQEBMSZXrBgwQTHClasWJH8+fMzb948Lly4QFRUFAcOHGD16tXUrVvXLv7ev3+fadOm8dprr9kl0mZRvHhxTpw4EWf6yZMnKVasmEuWUblyZcAYzjFr1iz279/Prl27GD9+fJwji+7CU2POo/LU7WDm2JvgsASlVGmgKVAA0EAIsEprfSSZ2wbArVu3yJQpU5zpmTNnJiIiIt666dOn57PPPmPMmDH07NnTNr1evXq88847Tuvt3LmTyMjIRPWGpiQ/Pz9u3rwZZ3pYWBh+fn4uXVaHDh0YNWoUAHfv3iUwMJAff/zRpctIKdmzZyc0NDTO9Bs3bphubF9y8tTtYOZDY0mR2rEXjDGwSYm/H3/8MZ988gnvvfeebforr7xC9+7d7cr+8MMP3Lt3z+lwqdTmLPaGh4e7rAPEeoLe2LFjWbVqFTNnziQgIIB+/fpRrFix/7N339FRVH8fx9+XQBJKCKETQjBUIUoXKYJSpEjvVYoK2KhSA/wQQpUmSkeKNBFsgEjv0kUIEEjovUMSWiCEzPPHJvtks5u+yc6u39c5eySzU+4dZz97986dGdq2bWt3P9QcNXOSy1H3g56zN8HGrVJqCNABWAXEnIPyAn5SSq3SNG1iGpcvphxm05LyIY+IiGDChAmEhoYyaNAg8uTJQ3BwMCtXriRDhgwmgRvbtm3bcHd356233kp12a3NUr0t7Z/U2rBhA8ePH8fDw4O6desyatQoXr16xU8//WT1baWH9NpveueI+8HevvCTQi/ZG10Ws2lJzd8pU6YQFhZGv379jBeU/fzzzzg5ORk7HG7dusUvv/zC0KFDcXZ2tnr5rSWtj7MMGQwnUg8fPoy/vz8Ahw4d4smTJ0ybNo133nmHvXv3pmkZ0oIjZk5KOOJ+0HP2JtZz+zHgq2mayWBLpdQ0IBBI84DNli0bjx8/NpseX49CbJs3b+bEiRMsXLjQOGb3zTffJGvWrHz33Xc0atSIIkWKmCzz8OFDjh07RtOmTXFycrJeRazg0aNHFnto3d3dCQsLs+q2Hj58yMOHDwHDrXlcXV0ZNmwYa9assbvxYCEhIRbveOHh4WHx17SjctT9oOeATQWbZy8YxsemNH+3bdvGqVOnmDNnjnGoga+vL1myZGH27NnUr18fHx8fFixYwJtvvkmJEiWMvcGRkZFomsaTJ0/IlCmT2YVn6S2h7LXUo5sSoaGhgOH2jrHt27cPgFKlStld49ZRMye5HHU/6Dl7ExtzGwV4WpheIPo9i5RSPZVS/yil/kltT1/hwoVNLqCKcfXqVYtjwWK7fPky2bJlM7kYDaBkyZLGdcS1Y8cOoqKidDckAeDs2bOUKFHCbHqxYsU4f/58mm775MmTZMuWjdy5c6fpdtJCYGAgvr6+ZtNLly7N6dOnbVAi23DU/RAVFZXoyw6lOntXr16d6kJ4e3tbHFt77do1ChUqlOCyV65cIVu2bGZjaIsXLw4YLoaNWdfRo0fp3Lmz8bV3714ePnxI586dWbZsWarrkVrnz5+3eF1D0aJFTS4SSu02IP4Ggz0ex46aOcnlqPtBz9mbWOO2H7BdKbVRKTU/+rUJ2A70jW8hTdPma5pWSdO0Sh06dEhVAd9++22CgoJMbpR9584dTp8+TZUqVRJc1sPDgydPnpg94CAoKAjAYkNt+/bt+Pj4WO0iAWvavn075cqVM/lSKViwIBUrVmTbtm1puu23336bJ0+e8ODBgzTdTlpYt24dVapUwcfHxzitcOHCVK9enXXr1tmwZOnLUfeDni9qSIV+pDJ727Ztm+pCvPXWWwQHB3P79m3jtDt37hAUFJTosK0cOXLw5MkTs4ccxFwUG9OTNXDgQPz9/U1e5cuXJ3v27Pj7+9OoUaNU1yO1du7cSdmyZfHy8jJO8/T0pHz58uzYscMq2wgICODevXvUqFHDZHrMA3ssXZCkd46aOcnlqPtBz9mrEtu4UioDUBnDRQ0KuA4c0TTtVVI2cPHixVTV7vnz53z++ee4uLjQpUsX40McwsPDmT17NpkzZwYMgfvRRx/RsWNHOnXqZJz22WefkTNnTtq1a0fevHk5d+4cK1euxMvLi2+//dY4zgkMv5x79+5Njx49Erx/bkpYoyc4c+bMbNiwgRcvXjB16lQ0TWPAgAFkzZqVDz74wHgjaE9PT3bt2sX333/P999/b1y+cuXK5MqVi9y5czN69GiWLl3KoUOHANi4cSMAHTp0oHz58uzbt49bt27h4eHBBx98QJMmTZg0aRLz5s1LVR0uXbqUquVTIkuWLAQEBBAeHs6IESPQNA1/f3/c3NwoU6YMT58+Tfcy2YIe94OmaakedHbhwoVEM6Zo0aJ2N7gttdl75syZVH+zPH/+nH79+uHs7EynTp1QSrFy5UrCw8P59ttvjfl79+5dPv30U9q1a0e7du0AQ/7269cPDw8PWrduTZ48eTh//jyrV6/G09OTyZMnm+RvbDNmzDAOKUsta2R55syZ+f3333nx4gUzZsxA0zT69OlD1qxZad68uUn2bt68mTlz5jB79mzj8m+99RYeHh7kzp2bkSNHsmLFCuOt1LZs2WKcr1mzZkycOJFVq1axdetWChcuTN++fQkKCqJbt26pqkNMp0560mPm2IJe90Nq81fP2Zvo3RI0TYsCDqZDWSxydXVl4sSJzJ8/n8mTJwNQrlw5evXqZQzWGFFRUSa/FPLly8f06dNZsWIFS5cu5dGjR+TJk4eGDRvSvn17s2Ddtm0bTk5O1KpVK+0rlgLh4eF07tyZESNGMHXqVJRSxsfvxn7CiVKKjBkzmtWvX79+Jr3dXbp0oUuXLgDGscfBwcG8//77DBs2DHd3d0JCQrhw4QIff/wxO3fuTIdaWt+zZ8+oXbs206dPZ9myZSil2L59O/369fvPhCs47n6w057ZRNk6e8GQv/7+/ixcuJBvv/0WTdMoU6YMH3/8sUn+appmdhoyX758fPPNN/z000+sWLGCx48fkzt3burVq0ebNm3ibdjqUXh4ON27d2fo0KFMmjTJ5PG7cZ8ulTFjRrMLhb788ksqV65s/LtTp07GTphSpUoZp69duxZN0/jkk09o2bIlYWFhrF+/3m5v8u+omZNcjrof9Jy9ifbcplZqe24dhR7H8NqCLXpuhX5Zo+f23LlziWZM8eLF7a7nNrWs0XPrCKx9Fs5e2aLnVuhbavNXz9mr+8fvCiFEQuzxQhshhLB3es5eadwKIeyank+NCSGEo9Jz9krjVghh1/TceyCEEI5Kz9krjVshhF3Tc++BEEI4Kj1nrzRuhRB2Tc8BK4QQjkrP2Ws/92IRQggLrPWUHKVUA6VUsFLqvFJqqIX33ZVS65VSAUqpQKVUd6tXRggh7ISes1cat0IIu2aNp+QopZyAWUBDoDTQQSlVOs5sXwCnNU0rC7wHTFVKOVu3NkIIYR/0nL3SuBVC2DUrPQKyMnBe07SLmqZFAKuAZnE3Bbgpwx36swEPgUhr1kUIIeyFnrNXxtwKIeyala7YLQhci/X3deDtOPPMBNYBNwE3oF30U8SEEOI/R8/ZKz23Qgi7lpTeA6VUT6XUP7FePeOsxtJTdOJ2O9QHjgOeQDlgplIqu9UrJIQQdkDP2Ss9t0IIu5aU3gNN0+YD8xOY5TpQKNbfXhh6CWLrDkzUDOfaziulLgGvA4eTVWAhhHAAes5e6bkVQtg1K437OgIUV0r5RF+o0B7DabDYrgJ1AJRS+YCSwEUrVkUIIeyGnrNXem6FEHbNGvda1DQtUin1JbAZcAIWaZoWqJT6NPr9uYA/sEQpdRLDqbQhmqbdT/XGhRDCDuk5e6VxK4Swa9Z6BKSmaX8Bf8WZNjfWv28C9ayyMSGEsHN6zl5p3Aoh7Jqen5IjhBCOSs/ZK41bIYRds1bvgRBCiKTTc/ZK41YIYdf03HsghBCOSs/Zm+aN2/fffz+tN2EXFixYYOsi6ELPnnFvcfffdOnSJVsXwWHoOWBtqVWrVrYugi74+/vbugi6MHr0aFsXQRcCAwNtXQSHoefslZ5bIYRd0/OpMSGEcFR6zl5p3Aoh7Jqeew+EEMJR6Tl7pXErhLBreu49EEIIR6Xn7JXGrRDCrum590AIIRyVnrNXGrdCCLum54AVQghHpefslcatEMKu6fnUmBBCOCo9Z680boUQdk3PvQdCCOGo9Jy90rgVQtg1PQesEEI4Kj1nrzRuhRB2Tc+nxoQQwlHpOXulcSuEsGt67j0QQghHpefslcatEMKu6bn3QAghHJWes1cat0IIu6bn3gMhhHBUes5eadwKIeyangNWCCEclZ6zVxq3Qgi7pudTY0II4aj0nL3SuBVC2DU99x4IIYSj0nP2SuNWCGHX9Nx7IIQQjkrP2ZvB1gVIigIFCjBz5kyOHz/O8ePHmT17NgUKFEjSsl999RVLlizhn3/+4cKFC7Rq1cpsnqxZs/Ldd9+xY8cOTp48ybFjx/j1119p1qyZtauSag8fPmTBggUMGDCAAQMGMG/ePB4+fJjocn/++Seff/65xVefPn3iXe7IkSN8/vnn+Pn5WbMaqZbWx0RcTZo04cKFC/z999+pLXqKeXl5sXr1akJCQggNDeWXX36hUKFCSVrWxcWFb775hhs3bvD06VP27dtHjRo1zOZTSjF06FAuXrzIs2fPOHbsGC1btrS4zhw5cjB9+nQuX75MeHg4V69eZdGiRamqY0pompboS6Rc/vz5mT59OocOHeLw4cPMmDEjyZ+1fv36sWDBAvbv38/p06dp3rx5vPPmzZuXsWPHsmfPHo4fP86WLVvo37+/lWqRepkzZ6ZKlSo0a9aMZs2aUbVqVTJnzpzk5d3c3KhSpQpNmjShRYsW1K9fn2LFihnfL1y4MK1bt4735eLikhbVSrZ8+fIxdepU9u/fz4EDB5g+fTr58+dP0rJ9+vRh3rx57N27l5MnT1r8jm3WrBknT56M95UrVy5rV8mE3nI2RtWqVYmMjCQqKgonJyfj9MKFCxMVFRXvq127dsnbAcmg5+zVfc+tq6sry5cvJyIigkGDBqFpGgMGDGDFihU0atSI8PDwBJfv0qULZ86cYefOnfEePJkyZeLVq1fMmTOHGzdu4OzsTKNGjZg2bRo5c+Zk8eLFaVG1ZIuIiGDGjBlkzJiRLl26oJRi/fr1fPvttwwfPjzB8KtevTq+vr4m0168eMHMmTMpU6aMxWWePXvGr7/+Svbs2a1aj9RKj2MiNjc3N4YPH87du3etVYVky5w5M9u3b+fFixd069YNTdPw9/dnx44dlC1blmfPniW4/A8//ECjRo0YPHgwFy9e5PPPP2fTpk1Uq1aNgIAA43z+/v589dVXjBgxgqNHj9K+fXtWr15NkyZN2Lhxo3G+HDlysHfvXjRNY+TIkVy+fBlPT0+qV6+eZvsgPtJ4TTuurq4sXryYiIgI/Pz80DSNPn36sHjxYlq0aJHoZ61Tp04EBQWxa9euBBu2np6erFixguvXrzN+/Hju379PwYIF8fb2tnKNUsbJyYmaNWsSFRXFkSNH0DSNN954g3fffZetW7fy6tWrBJf38PCgZs2a3Lt3j6NHj/Ly5UuyZctGxoz//xV869YtduzYYbZs9erVefr0KS9evLB6vZLL1dWVhQsXEhERwYgRI9A0jd69e7No0SJatWqV6PHQsWNHgoKC2L17d7ydR3v27KFTp04m05RSfP/991y/fp0HDx5YrT5x6S1nY2TMmJG5c+dy584dsx+Wt27domrVqmbL+Pv7884777Bly5YU7o3E6Tl7dd+4bd++PYUKFeL999/nypUrAAQFBbF9+3Y6dOiQaE9RuXLl0DSNwoULx9uQCQ0NNesh2LVrF6+99hpt2rTRTeP277//5v79+4waNYq8efMCULBgQb7++mv+/vtv6tSpE++yHh4eeHh4mEw7dOgQUVFRvP322xaX+f333ylYsCDu7u4EBQVZryKplB7HRGxDhw7lzJkz3Lt3j2rVqlmlDsnVo0cPihQpwuuvv86FCxcAOHHiBGfPnqVXr15Mnz493mXLlClDp06d+Oijj1iyZAkAu3fv5tSpU4wePdrY6MiTJw9fffUVkyZNYurUqYDhc1C0aFEmTJhgEroTJkwgW7ZslClThsePHxun//zzz1aueeL0fGrM3rVu3RovLy8aNWrE1atXAQgODmbjxo20bduWH3/8McHlK1eujKZpeHt7J9i4HTVqFHfu3KF79+5ERkYC8M8//1itHqnl4+NDtmzZ2LRpE0+fPgUgLCyMBg0aUKRIEc6dO5fg8pUqVeLu3bscOHDAOO3evXsm80RERJidhcudOzcuLi6cPn3aSjVJnVatWuHl5UWTJk24du0aAGfPnuXPP/+kTZs2LF26NMHlq1atiqZpFCpUKN7GbUhICCEhISbTKlSogIeHB7Nnz7ZOReKht5yNMWjQIJRSLF682OwsakREBIcOHTKZljlzZipXrsz69evN9qU16Tl7dT8soU6dOhw/ftzYiAG4fv06R48epW7duokun5pfFqGhobx8+TLFy1vbyZMn8fHxMTZswRB+RYoUMflVmFQHDx4ke/bslC5d2uy9CxcucPjw4TQ9pZFS6XlMVKxYkWbNmvH111+npKhW06RJEw4ePGgMXIDLly+zb98+mjZtmuCyTZs2JSIiwqTh+erVK37++Wfq16+Ps7MzAPXr18fFxYXly5ebLL9ixQrKlCnDa6+9BkCWLFn48MMPWbhwoUnD1lb0fGrM3tWuXZuAgABjwxbgxo0bHDt2jNq1aye6fFL2faFChahRowYrVqwwNmz1xtPTkwcPHhgbtmA4s/XgwQM8PT0TXDZPnjy4u7sn2gC2pHDhwrx69crYkLS19957jxMnTpiU58aNGxw/fpxatWolunxKP4sxGWap4WdNesrZGEWKFMHPz48vvvgiye2Rli1bkj179kR/bKSWnrNX943b4sWLc/bsWbPp586dMxmvZC1OTk7kyJGD9u3bU6NGDeMvMD24deuWxSAtUKAAt2/fTta6QkJCOHv2LG+99ZbJ+B0wfCBXrlzJ+++/b9KQ1ov0OiYyZszI2LFjWbBggUlD2hZ8fX0JDAw0m3769GmLP05iK126NJcuXTI7ZRgYGIiLi4txn/n6+vL8+XPOnz9vNl/MesDQ4M+SJQt37txh9erVPH36lEePHvHbb7+ZBXN60HPA2rtixYqZHQ8A58+fp2jRolbZRvny5QHDMKkffviB48ePc+DAASZMmIC7u7tVtpFa2bNn59GjR2bTHz16lOiwrdy5cwOQIUMGatWqRcuWLWncuDFly5YlQ4b4v4IzZMiAl5cXt27dIiIiInUVsJKEjociRYqkyTZdXFyoV68eu3fvJiwsLE22EUNPORtj9uzZ/PLLL+zduzfJ9ejSpQt37txh06ZNSV4mJfScvSlu3CqluluzIPFxd3e3eECHhYVZPfg+/PBDzp49y9GjRxk1ahT+/v78/vvvVt1Gajx9+pQsWbKYTc+aNWuiY4HiOnToEJqmWRySsGXLFiIjI6lfv36Ky5qW0uuY6NWrFy4uLsyZM8dq60ypnDlzWjy99PDhQ7PhJslZNub9mP+GhoYmOl/MD6zJkyfz6tUrmjVrRq9evShfvjw7d+4kW7ZsSa+YFSR0MUXMy5GkV/ZCwp81a43Fj/kBPXbsWC5fvkyvXr2YNm0a7777LgsWLEApZZXtpIazs7PFBmZERASZMmVKcFlXV1cAqlSpwp07d9i7dy9nz57Fx8cn3iFhYBhylilTJpv/sI7N3d09xY38lKpduzZubm6sW7cuTdYfm55yFgxj1itVqsTgwYOTXAdPT09q167NypUrEx0Lnlp6zt7UjLkdDaTLYFRLrf+0CLwNGzZw/PhxPDw8qFOnDqNGjSIqKoqffvrJ6tuyppT8Ojp06BCFChXCy8vLZPrdu3fZtGkTPXv2TDS0bSmtj4nChQvz+eef89lnn+mm1ySldVZKJWnZpM4X09t06dIlOnToYJx+4cIFDh48SOfOnZk7d26i5bKW/2DPbLplb3ys+VmLOZ4OHz7M2LFjAUM+PX78mGnTpvHOO+8kq9dKb2L21ZUrV4xjZ+/du4dSijfffBM3NzeLw3sKFy7M8+fPk31WLq2l9+etadOmPHjwIN2OAb3krIeHB1OmTGH48OFm47MT8uGHH+Lk5JToeHhr0HP2Jti4VUqdiO8tIF8Cy/UEeoLhlExqftE9evSIHDlymE3Pnj271U9RPHz40Pjrac+ePWTOnJmhQ4eyZs0aXYwFy5Ili8Ue2mfPnlns0Y3P5cuXuXPnDq1btzZ7b82aNZQoUQIfHx/jtiIjI9E0jWfPnpExY0bj2CFbSY9j4n//+x8HDhzg2LFjuLm5AYa7aiilcHNzIyIiIl2vXg4JCTH5RR/Dw8Mj0QsGHj58aPGq85ieiJhjPr7eibjzxVytvH37dpP5Dh8+TFhYmPE0c3pxtJ5ZsE725s+fP9HepsTEdzYkvtP0KRHTixX7YiuA/fv3A1CqVCmbN24jIiIs5p6zs3Oi4yBjfhzHvdvKnTt3ePPNN8mRI4dZ49bV1ZW8efNy4cIFXTUgHj16lObHQ2y5c+emSpUq/PTTT2neCwn6ytmxY8cah37F7POYswDu7u48f/7cYnvgww8/5NixY5w4EV+EWI+eszexntt8QH0g7v9VBeyPbyFN0+YD8wGKFi2aqk/muXPnKF68uNn0+Mb+WNPJkydp1aoVuXPn1sWv5wIFCnDr1i2z6bdv307yfQbBcCFZhgwZeOutt8zeu3XrFg8fPmTgwIFm7w0cOJBatWrRpk2b5BXcytLjmChWrBheXl4cP37c7L3jx4+zePFiYy9TeggMDLQ45qtUqVKJXkl9+vRpWrRoQebMmU3Gg5UuXZoXL14Y91lgYCCurq4ULVrU5IKKmO3GbCdmbFh8X7rpHXjW+vJXSjUAZgBOwA+apk20MM97wLdAJuC+pmnvWmXj5lKdvaVLl071jolvbG3cYyS12wD9HE+WxHfaPSmNusTet1Rvb29vMmTIwOXLl5NVzrSW0PFw8eJFq2+vcePGZMyYkbVr11p93ZboKWdLlSpFmTJlLN767P79+/zxxx9md/upVKkSpUuXTrf7Q+s5exMbc/snkE3TtCtxXpeBXcmtQEps27aNcuXKmdxEuWDBglSsWNGs58jaKleuzJMnT9L0vnrJUaZMGS5dusT9+/eN0x48eMCFCxfivVdtXJGRkRw9epQ33njD2CMZ28cff0y/fv1MXqVLlyZbtmz069ePd99Nq+/ypEuPY6Jv37507NjR5LVnzx4ePHhAx44dWbZsmVW2k1Tr16+nSpUq+Pj4GKcVLlyY6tWrs379+gSXXbduHc7OziY/SpycnGjbti1btmwx9ixt2rSJFy9emN1jslOnTpw8edL4RXvjxg2OHDnC+++/bzJflSpVcHd358iRI6mparJZ46IGpZQTMAtoCJQGOiilSseZJwcwG2iqaZovkJa/8myevQA7d+6kbNmyJsOXPD09jeOrrSEgIIB79+7xzjvvmEyP+fvUqVNW2U5q3Lx5k5w5c5I1a1bjtCxZspArVy5u3ryZ4LK3b9/m1atX5Mtn2uEe87elHsHChQsTGhqa5hdQJdeuXbsoU6aM2fFQrlw5qx0PsTVt2pTg4GCCg4Otvm5L9JSz/fv3p1atWiavmAvc69aty8iRI83K0LVrV16+fMnKlStTUv1k03P2Jthzq2naxwm81zHRUlvBzz//TJcuXZg3bx7Tpk1D0zT69+/PrVu3TMbCenp6snPnTr7//ntmzpxpnF65cmVy5sxJnjx5AHjjjTeMt3OJuZKwQ4cOlCtXjn379nH79m1y5MhBo0aN+OCDD5g0aZJubgdWvXp1du/ezdy5c2nSpInxIQ4eHh4mXwwPHjxg1KhRfPDBB3zwwQcm6zh58iRPnz6N90KG2B/qGAcPHiRjxoyUKFHCuhVKofQ4Jiz12LZq1criPQXTw4IFC/jiiy/4448/GDlyJJqmMWbMGK5du8a8efOM83l7e3P+/Hn8/f3x9/cHDI2HVatWMX36dDJlysSlS5f49NNP8fHxoXPnzsZl7927x7fffsvQoUN5/Pgx//77L+3ataN27dpm9ygdNmwYmzZtYs2aNSxcuJA8efIwduxYzpw5k27BGsNKPXuVgfOapl0EUEqtApoBsbtrOgK/aZp2FUDTtDR7qoceshfgl19+oVOnTsycOZPvvvvOeNP+27dvs3r1auN8np6ebNq0iTlz5phcgFmpUiVy5sxpvGOAr6+v8VRqzM3lX716xbRp05gwYQKjRo1i69ateHt707dvXw4dOsTBgwfTq7rxunTpEsWKFaNatWrGxnZMXWL3WGbJkoUGDRpw5swZzpw5AxiGJQQFBVGqVCkiIyO5e/cuHh4elC5dmsuXL5vcXgwMD0hxd3dP0e0d09qvv/5Khw4d+O677/j+++/RNI0vv/ySO3fusGbNGuN8BQoU4K+//mLevHkm4+8rVaqEh4eHxeNh69atJtsqVaoUxYsXZ/LkyelQMwM95ayl///vvfceYLh/btxhGhkzZqRdu3Zs3LgxWWN0U0PP2av7hziEh4fTqVMnRowYwZQpU1BKceDAAfz9/U3GmyilyJgxo9mtVfr27UuVKlWMf3fp0oUuXboAGE+vBAcHU7duXYYNG4a7uzshISFcuHCBjz/+mF27dqV9JZPIxcWFvn378ssvv/Djjz+iaRolS5akTZs2xrE4MeK7UvHQoUNkzZqVN998M72KbXXpcUzozbNnz6hTpw7Tpk1j6dKlKKXYvn07/fv3N/lyjK/OH330EePGjcPf358cOXIQEBBAw4YNOXbsmMl8w4cP58mTJ/Tp04f8+fMTHBxMu3bt+PPPP03m27FjB02bNmX06NH89ttvPH36lA0bNjB48GCeP3+edjvCAiudGisIxL6Z6HUg7i/AEkAmpdQuwA2YoWla2t5I0sbCw8Pp3r07Q4YMYeLEiSilOHjwIBMmTDAb72fpuPvyyy+pXLmy8e9OnToZe6xin/5du3YtUVFRfPLJJ7Ro0YKwsDD+/PPPBG+an55evXrF7t27KVu2rLE+d+/eJSAgwKyRkSFDBrOLg86cOUNkZCRFixalRIkShIeHExwcbGwAxxbzONXY9xbWi/DwcD7++GMGDx7M+PHjUUpx6NAhJk2aZHIqPiaH4u6Hzz//3GQ4XIcOHYwXpcb9TmratCkvX75kw4YNaVgjU3rL2eRo3LgxuXPnTvN728am5+xVaT1YPbVjbh3F/PnzbV0EXejZs6eti6ALly5dsnURdCEqKirVl93Pmzcv0Yz59NNPexF9oVW0+dHjUwFQSrUB6mua9kn03x8ClTVN6x1rnplAJaAOkBk4ADTSNM38pss6YI0xt45gzJgxti6CLowePdrWRdAFS/ex/a9Kbf7qOXt133MrhBAJScoP9NgXWsXjOlAo1t9eQNzBlNcxXMjwFHiqlNoDlAV02bgVQoi0pOfs1f0TyoQQIiFWekrOEaC4UspHKeUMtAfi3jV+LVBDKZVRKZUFw6kz8/PKQgjxH6Dn7JWeWyGEXbPGRQ2apkUqpb4ENmO4Hc0iTdMClVKfRr8/V9O0M0qpTcAJIArDLWtsfym/EELYgJ6zVxq3Qgi7Zq3rBjRN+wv4K860uXH+ngyk3+XbQgihU3rOXmncCiHsmp6e4CSEEP8Ves5eadwKIeyaHp5gJYQQ/zV6zl5p3Aoh7Jqeew+EEMJR6Tl7pXErhLBreu49EEIIR6Xn7JXGrRDCrum590AIIRyVnrNXGrdCCLum54AVQghHpefslcatEMKu6fnUmBBCOCo9Z680boUQdk3PvQdCCOGo9Jy90rgVQtg1PfceCCGEo9Jz9krjVghh1/TceyCEEI5Kz9krjVshhF3Tc8AKIYSj0nP2SuNWCGHX9HxqTAghHJWes1cat0IIu6bn3gMhhHBUes7eNG/cXrx4Ma03YRc++eQTWxdBF1avXm3rIuhCmzZtbF0Eh6Hn3gNbOnPmjK2LoAujRo2ydRF0YcqUKbYugi707dvX1kVwGHrOXum5FULYNT33HgghhKPSc/ZK41YIYdf0HLBCCOGo9Jy90rgVQtg1PZ8aE0IIR6Xn7JXGrRDCrum590AIIRyVnrNXGrdCCLum54AVQghHpefslcatEMKu6fnUmBBCOCo9Z680boUQdk3PvQdCCOGo9Jy90rgVQtg1PfceCCGEo9Jz9krjVghh1/TceyCEEI5Kz9krjVshhF3Tc8AKIYSj0nP2SuNWCGHX9HxqTAghHJWes1cat0IIu6bn3gMhhHBUes5eadwKIeyannsPhBDCUek5e6VxK4Swa3ruPRBCCEel5+zNYOsCCCFEamialugrKZRSDZRSwUqp80qpoQnM95ZS6pVSqrXVKiGEEHZGz9mb7j237777Lrt27TKbHhoaioeHR7zLVaxYkZ49e1KzZk28vb25f/8+e/fuZcSIEVy+fNmqZfTy8mL69Om8//77KKXYtm0b/fr149q1a8Z5ChcuHO92c+TIQVhYmFXLFKNAgQKMHDmS6tWro5Ri3759+Pv7c/PmzUSXHThwIGXKlOGNN97Aw8ODgQMH8uuvv5rMkzVrViZNmoSvry958+YlMjKSixcv8uOPP/LHH3+kSZ1S4sGDByxfvpxTp06haRpvvPEGnTt3Jnfu3Aku9+uvv/L7779bfC9TpkwsXrzY+Pfjx4/56aefOHbsGM+fP8fb25tWrVpRpkwZq9YlNWKOh3feecd4PIwZMyZJx8OgQYN48803efPNN43Hwy+//GIyj4+PD126dKFKlSp4e3vz9OlTAgICmDZtGmfOnEmraiWLNU6NKaWcgFnA+8B14IhSap2maactzDcJ2JzqjTqopOSnPcqfPz9DhgyhatWqKKU4cOAAkyZN4tatW4ku27dvX3x9ffH19SVHjhwMHz7cLE+bN2/OuHHj4l3Hu+++y/3791NbjVQLCQnhjz/+IDg4GE3TKFmyJC1atEjw+xtg48aNbN5s+WOTMWNGpkyZYvx7586dnD9/nmvXrvHo0SPq169Pw4YNrVqP1MqfPz9+fn7G7+L9+/czbty4JB0PAwYM4I033sDX1xcPDw+GDBkS7/dSjEaNGjF9+nRu375NzZo1rVWNVNFz9tpsWELv3r05cuSI8e/IyMgE52/fvj2+vr589913BAYGUrBgQUaOHMk///xDuXLluH79ulXKlTlzZnbs2MGLFy/o2rUrmqYxduxYdu7cSZkyZXj27JnJ/OPHj2fdunUm0x4/fmyVssTl6urKihUriIiIYODAgYDhQ7Jy5UoaNmxIeHh4gst37dqVM2fOsGPHDlq1amVxnkyZMhEZGcmcOXO4fv06zs7ONG7cmOnTp5MzZ04WLVpk9Xol14sXLxg/fjyZMmWiV69eKKVYs2YN48ePZ/z48bi6usa77HvvvUfZsmVNpj1//pzJkydTvnx547SXL18yfvx4Hj9+TPv27cmRIwe7du1i6tSpDBkyhNKlS6dZ/ZLK1dWVlStXGo8HTdP46quv+Omnn2jQoEGSjofTp08neDzUqFGDKlWq8OuvvxIYGEj27Nnp1asXf/zxB61ateLUqVNpUbVksdKpscrAeU3TLgIopVYBzYDTcebrDfwKvGWNjTqa5OanvXB1dWXRokVERETg5+eHpmn06dOHRYsW0bJly0Q/a506dSIoKIjdu3fTrFkzi/Ps3r2bDh06mExTSjFr1iyuX7+ui4ZtREQEs2bNImPGjHTs2BGlFH/99RczZ85k8ODBuLi4xLts1apVKVWqlNn65s6dyxtvvGEy/cCBA7i6uvLGG2+wf//+NKlLari6urJ06VIiIiIYMmQImqbRr18/li1bRpMmTRI9Hjp37kxQUBC7du2iRYsWiW7Pzc0NPz8/7t69a60qWIWes9dmjdszZ85w6NChJM8/adIksw/3vn37uHTpEj169GDUqFFWKVePHj0oUqQIJUuW5MKFCwCcOHGCc+fO0atXL6ZPn24y/8WLF5NVj9Ro37493t7e1KlThytXrgCG/bhz5046duzIwoULE1y+TJkyaJpG4cKF423MhIaG0q9fP5Npu3btwsfHhzZt2uiicbtz507u3r3L5MmTyZ8/PwCFChVi4MCB7Nixgw8++CDeZXPlykWuXLlMpv3999+8evWKGjVqGKcdOnSIa9eu4efnZ2zIlilTBj8/P1atWsWYMWPSoGbJ06FDB7y9valdu7bJ8bBr164kHQ9vvvlmosfD+vXrWbp0qcm0/fv38/fff9O9e3e++uor61QmFZISsEqpnkDPWJPma5o2P9bfBYHYXYvXgbfjrKMg0AKojTRuLUpuftqL1q1b4+XlRePGjbl69SoAZ8+e5a+//qJt27b8+OOPCS7/9ttvo2ka3t7e8TZuQ0JCCAkJMZlWoUIFPDw8mDVrlnUqkkoHDhzgwYMH+Pn5kSdPHgA8PT0ZN24c+/fvp1atWvEumyNHDnLkyGEy7ciRI0RFRfHWW6Yfp6FDh5IhQwZevXqly8Zt27ZtKVSoEPXr1zceD8HBwWzZsoX27dubnAG0pGLFisbjISmN28GDBxMUFMS9e/eoVq2aVepgDXrOXrsZc2vpV+vVq1e5d+8eBQsWNJmeOXNmJk6cyMWLF3nx4gUXL17Ez88PpVSi22natCkHDx40BjPA5cuX2bdvX7yhlF7q1q3LsWPHjA0ZgOvXr3P06FHef//9RJdPza+skJCQRHvX08u///5LsWLFjA1bgLx581KiRAn+/fffZK9v7969uLu7mww3uHDhAs7OziY9DUop3nzzTS5evMjDhw9TVwkrSOh4qFevXqLLJ+V4iPtlC4YzE5cuXTLZ/7YUFRWV6EvTtPmaplWK9ZofZzWWwiHuDvoWGKJp2qs0qYgD0HN+pkatWrU4ceKEsSEDcOPGDY4dO5Zggy5GSrO3WbNmRERE8Ndff6VoeWs7deoUr732mrFhC4YOAx8fnxSdxTly5Ahubm68/vrrJtMzZNB306ROnTocP37c5Hi4fv06//77L3Xq1El0+eQcDxUqVKBp06aMHj06RWVNS3rOXpsdQStWrCAyMpL79++zYsUKChUqlOx1vP766+TLl89k7J+TkxObN2/mk08+YcaMGTRs2JAffviBkSNHMnny5ETX6evra/FDGhgYaPFU9IQJE3j58iWhoaGsXbvW7PSKNZUoUYKzZ8+aTT979izFihWz+vacnJzIkSMHHTp0oGbNmon+Gk0vN27cwMvLy2x6wYIFuXHjRrLW9eDBA06fPk21atVwcnIyTldK4eTkZPaDKGNGw8kOaw2DSY30Ph5iuLu7U6JECc6fP59m20gOK13UcB2IHUJeQNyBy5WAVUqpy0BrYLZSqrkVquAwkpuf9qJYsWKcO3fObPqFCxcoWrRommzTxcWF+vXrs3v37jS7hiO5bt++bfFHbf78+bl9+3ay1hUaGsq5c+eoWLGiSfbag/iOh3Pnzlk1ezNmzIi/vz8LFy40aUjrhZ6zN9FhCUqp1zF0Gx/SNO1JrOkNNE3blJSSxxYWFsaUKVPYvXs3jx49onz58vj5+XHgwAHKly/PvXv3krQeJycn5s6dy927d01Ov3bo0IEaNWpQs2ZN9u7dC8COHTsAGDVqFJMmTUpwGzlz5rTYW/Xw4UOTAfMvXrxg7ty5bNmyhXv37vH666/j5+fH/v37qVy5MkFBQUmqR3K4u7tbDLmwsDDc3d2tuq0uXboYfylGREQwZswYfvvtN6tuI6WePHlC1qxZzaZny5aNp0+fJmtd+/btQ9M0kyEJYLhQKzw8nBs3bpicGYhp0D158gRbi+94CA0NtfrxENvo0aNRSuliiApY7V6LR4DiSikf4AbQHugYewZN03xi/q2UWgL8qWnaH9bYuCXWzt70kNT8tDfu7u48evTIbHpYWBjZs2dPk23WqVMHNzc31q5dmybrT4lnz56RJUsWs+lZsmRJdJxpXEeOHEHTNCpXrmyt4qWb9DoeevTogbOzM3PnzrXaOq1Jz9mbYM+tUqoPsBbDQN5TSqnY55XGJ6PwRsePH2fQoEH8+eef7NmzhxkzZtCgQQPy5ctHnz59kryemTNnUq1aNTp37kxoaKhxeoMGDbh8+TL79+/HycnJ+NqyZQvOzs5UqVIFwOS9uL8aLf3aiNuDd/v2bT777DN+//13/v77b3744Qdq1qyJpmkMHz48GXskeZJSNmv4888/adq0KV27duXnn3/m66+/NrvYwZYs1Tklp/7+/vtvChcujLe3t8n0atWqkT17dubNm8e1a9d4/Pgxa9euNf5o0ctps/Q6HmJ8/vnnNG/enP/9738mwyFsyRq9B5qmRQJfYrgS9wywWtO0QKXUp0qpT9O4CmbSInvTS3ofk+klve/p2axZMx48eMCePXvSdbvp5ciRI3h5eeHp6WnroqRIWh/n3t7efPbZZ4wZM4aIiAirrdea9Jy9ifXc9gAqapr2RCn1GvCLUuo1TdNmYHmcBGBxAHGCjh07xtmzZ80Glcdn/Pjx9OzZk65du7J161aT9/Lmzctrr70W7/jQmIuJ4r7/3nvvsXv3bkJCQsiZM6fZch4eHhZ7JGK7fv06f//9d5LrkVyPHj0yG5APkD17dquftnr48KFxXOmePXvInDkzfn5+rFmzxuZjb7NmzWqx5/Tp06cWe3Tjc+HCBW7evEnnzp0tbqNPnz7MmzePYcOGAYZjq2XLlvzyyy8W/z+kt7CwMIvliK9HN7U6derE4MGDmTx5MmvWrLH6+lPKWo0OTdP+Av6KM81il4mmad2sstH4pUv2Wltq8lPP4js7Fl8PXmrlzp2bKlWqsHLlSl690s8Q78yZM1u848WzZ8/InDlzktdz5coV7t69m6SLqfTo0aNHFo+H7NmzW+14GDlyJAcPHuT48eO4ubkBhrsZKaVwc3MjIiKCFy9eWGVbKaXn7E2scesUczpM07TLSqn3MIRsYRII2OgBw/MBlFJJqr1SKkk7ys/Pj2HDhtG7d2+WL19u9v6DBw+4ePEibdu2tbh8zL1pK1WqZDI9ODgYMIwN8/X1NVuudOnSnD4d984U5pJaj5Q4e/YsxYsXN5tevHjxNB//ePLkSVq3bk3u3LmTPbbK2ry8vCyOrY07hCAxe/fuxcnJKd6rT19//XWmTZvGnTt3iIqKIn/+/GzYsAFnZ2dee+21lBbfas6dO5dux0OLFi3w9/dn/vz5urlyO4aeHwGZCumWvdaU2vzUqwsXLlgcS1mkSBGTi+espUmTJmTMmFFXQxLAMFzLUv7HNxY3PkeOHCFDhgxUrFjRmsVLN/Flb7FixayWvUWLFsXLy4ujR4+avXf06FGWLFnC+PG2PYmj5+xN7NzqbaVUuZg/osO2MZAbeNNahahYsSIlSpRI9JZavXv3Zty4cfj5+TFz5kyL82zatIlChQrx5MkTjh49avZ68OABgNn0mJ7AdevWUaVKFXx8jEM8KFy4MNWrVze7n21chQoVonr16ml2a7Bt27ZRvnx5k4vvChYsSMWKFdm2bVuabDPG22+/zZMnT4z7z5YqVKjA+fPnTe75d+/ePc6dO0eFChWStI7IyEgOHjxI2bJlExwjpZQif/78eHp6EhERwc6dO6levXqC99JNL5aOBy8vLypWrGh2RiM16tevz+TJk1m1apXNw9QSaz0lR2fSJXutLTX5qWcx9+mNfSGrp6cn5cuXZ+fOnVbfXtOmTQkODk6TazdSw9fXlytXrpjcvejBgwdcunQpyRdTR0ZG8u+//1K6dGmyZcuWVkVNUzt27KBs2bJm38UVKlQwXuOTWv3796dz584mrz179vDw4UM6d+5ssXMvvek5exPrue0CmJyDjh4f0UUpNS8lG1y+fDmXLl3i33//JTQ0lPLlyzNs2DBu3LjB999/DxjGmly4cIExY8bg7+8PQLt27fj222/ZuHEjO3bs4O23//82aI8ePTLeMWHFihV0796d7du3M3XqVAICAnB2dqZo0aI0bdqU5s2bJzjwfcGCBXz55ZesXbuWESNGoGka/v7+XLt2jXnz/r/KU6ZMIUOGDBw4cIB79+5RsmRJhg0bRlRUVJo1AFatWkWXLl2YP38+06ZNQ9M0BgwYwK1bt1i5cqVxvoIFC7Jr1y6+++474z4FQwM1Z86cxtu4xL6p+saNGwHDBXnly5dn37593L59mxw5ctCoUSM++OADJk6cyMuXL9Okbsnx3nvvsWXLFqZNm0abNm0Aw5PHcubMSe3atY3z3b9/nwEDBtCiRQuz01/Hjh3jyZMnZheSxfbzzz/j4+NDtmzZuHPnDhs2bCBjxoy0a9cubSqWTD/99BNdunRhwYIFTJ061fgQB0vHw+7du/nuu+/47rvvjNPjHg9vvvmm8YK8mOOhcuXKfPfddwQFBfHLL7+YPOgiIiKCwMDA9KhqgvTce5AKVs/e9JDU/LQ3v/zyCx07duT77783foZ69+7N7du3TYboFChQgE2bNjF37lzmzJljnF6pUiVy5sxpfIKir6+vMXu3bNlisq1SpUpRokQJvvnmm7SuVrJVrVqVv//+m4ULF/LBBx8YH+Lg4eFhcgbs4cOHjB07lnr16tGgQQOTdQQGBvLs2bMEh+9dvXqVhw8fGhtHd+7c4fjx44DhLICzs7P1K5cMq1evpnPnzsyePZtvv/3W+BCH27dvs2rVKuN8np6ebNu2jVmzZpmc8XrrrbfMsjfmeIh5iltAQIDZdlu2bElERASHDx9Oy+olmZ6zN8HGraZp8d7vSNO0fSnZ4KlTp+jQoQO9e/cmS5Ys3L59m99++41Ro0YZewWVUmTMmNHkop0GDRqQIUMGGjZsaPYYvl27dhnvNRgZGUn9+vUZOnQoPXv2xMfHh6dPn3LhwgU2bNiQ6MDsZ8+eUbt2baZPn86yZctQSrF9+3b69etnciV+YGAgn332Gd26dcPNzY379++zY8cORo8ebfH2TNYQHh5Op06dGDFiBFOnTjU+8m/MmDFm46Di7j+Afv36GS+oA8MdEbp06QJg7GkJDg7m/fffx8/PD3d3d0JCQjh//jwfffRRmvRQpISrqyt+fn6sWLHC+AXi6+tL586dTXpUNU0z3msvrr1795ItWzaTxlpcYWFhLFu2jEePHpE9e3YqVapEq1atdNPbEB4eTseOHRk5ciTTpk2L93iw9HkCQ89A7OOha9eudO3aFcA47KJatWq4uLjwxhtvmN0t4/r167zzzjtpVLuks9Oe2QSlRfamh6Tmp70JDw/no48+YsiQIUycOBGlFAcPHmTixIkWP2txLyz64osvTO4K0LFjRzp2NFwQHncYR7NmzXj58iV//vlnGtYoZVxcXPjiiy/4/fffjT2HxYsXp0WLFiZPJ4vJXkufzSNHjpAlSxaLw1di7N271+QJpsePHzc2bkeOHGn2IJ70Fh4eTpcuXfDz8zPeYvTgwYOMGzcuSdnbp08fkw66mJ5ZMNzi0V7oOXtVWhfOFuO+9EgPYzT1YPXq1bYugi7E9Dj/112+fDnVlxd37Ngx0YxZuXKl/V+un0ySvQb2fH9da5oyZYqti6ALffv2tXURdOPs2bOpykU9Z6/NHr8rhBDWoOdTY0II4aj0nL3SuBVC2DU9nxoTQghHpefslcatEMKu6TlghRDCUek5e6VxK4Swa3o+NSaEEI5Kz9krjVshhF3Tc++BEEI4Kj1nrzRuhRB2Tc+9B0II4aj0nL3SuBVC2DU99x4IIYSj0nP2SuNWCGHX9BywQgjhqPScvdK4FULYNT2fGhNCCEel5+yVxq0Qwq7pufdACCEclZ6zVxq3Qgi7pufeAyGEcFR6zl5p3Aoh7Jqeew+EEMJR6Tl7pXErhLBreg5YIYRwVHrOXmncCiHsmp5PjQkhhKPSc/ZK41YIYdf03HsghBCOSs/ZK41bIYRd03PACiGEo9Jz9krjVghh1/R8akwIIRyVnrNXGrfp5PLly7Yugi40aNDA1kXQhX/++cfWRXAYeu49ELZ35swZWxdBF3r16mXrIujCtm3bbF0Eh6Hn7JXGrRDCrum590AIIRyVnrNXGrdCCLum594DIYRwVHrOXmncCiHsmp4DVgghHJWes1cat0IIu6bnU2NCCOGo9Jy90rgVQtg1PfceCCGEo9Jz9mawdQGEECI1oqKiEn0lhVKqgVIqWCl1Xik11ML7nZRSJ6Jf+5VSZa1eGSGEsBN6zl7puRVC2DVr9B4opZyAWcD7wHXgiFJqnaZpp2PNdgl4V9O0EKVUQ2A+8HaqNy6EEHZIz9krjVshhF2z0qmxysB5TdMuAiilVgHNAGPAapq2P9b8BwEva2xYCCHskZ6zV4YlCCHsWlJOjSmleiql/on16hlnNQWBa7H+vh49LT4fAxutXRchhLAXes5e6bkVQti1pPQeaJo2H8OprPgoS4tZnFGpWhgC9p2klE8IIRyRnrNXGrdCCLtmpdvRXAcKxfrbC7gZdyalVBngB6ChpmkPrLFhIYSwR3rOXhmWIISwa5qmJfpKgiNAcaWUj1LKGWgPrIs9g1LKG/gN+FDTtLNWr4gQQtgRPWev9NwKIeyaNS5q0DQtUin1JbAZcAIWaZoWqJT6NPr9ucD/gFzAbKUUQKSmaZVSvXEhhLBDes5eadwKIeyatZ6So2naX8BfcabNjfXvT4BPrLIxIYSwc3rOXmncCiHsmp6fkiOEEI5Kz9nrsGNuvby8WLNmDaGhoYSFhfHrr79SqFChxBe0gdSU1cXFhW+++YabN2/y7Nkz9u/fT40aNczmU0oxdOhQLl26RHh4OMePH6dly5Ym8+TPn5/x48dz5MgRQkNDuXv3Ltu2bbO4vgkTJhAQEEBISAhPnz7lzJkzjBgxgsyZM6dsJyTA09OTxYsXc+nSJS5fvsyPP/5IwYIJ3Snk/7m4uPD1118TGBjI9evX2bRpE1WrVjWZp0OHDjx48CDeV968eY3zfv/99xw4cIDLly9z5coVdu/eTY8ePciQwTYfpXv37jF27FhatmxJy5YtGTNmDHfv3k3Ssnfv3mXKlCl8+OGHNGvWjI8//pglS5bw/Plz4zxbtmyhQYMG8b4ePnyYVlVLMiuN+xJWYk/ZGx8vLy9Wr15NSEgIoaGh/PLLL8nO5Bs3bvD06VP27duXYCZfvHiRZ8+ecezYMbNMfvfddxO8zdLbb6f/M0QKFCjA3LlzOXXqFIGBgcybNw9PT88kLTt48GCWL19OQEAAV69epXXr1hbn++STT1i0aBH//PMPV69epX///tasglXcu3ePCRMm0K5dO9q2bcv48eOTlb3Tp0+ne/futGrVil69erFs2TKT7AX4+OOPadKkidnrwIEDaVGlZNNz9jpkz23mzJnZsWMHL168oGvXrmiaxtixY9m5cydlypTh2bNnti6iUWrLunDhQho1asSgQYO4ePEiX3zxBZs3b6Zq1aoEBAQY5/P392fgwIEMHz6co0eP0r59e9asWUPjxo3ZuNFwy7iKFSvSrl07Fi9ezMGDB3F2dubzzz9n165dNG3alA0bNhjXlz17dhYvXkxwcDAvXrygWrVqDB8+nEqVKtG8eXOr7p8//viDiIgIvvjiCzRNw8/Pj7Vr11KzZs1E98+MGTOoV68eo0aN4sqVK3z88cesWbOGBg0acOrUKcDQgKtfv77ZsitXruTKlSsmgeXq6sqCBQu4dOkSmqZRu3Ztxo8fj4+PD35+flard1I8f/6cIUOGkClTJgYOHIhSih9//JEhQ4YwZ84cXF1dE1x22LBhREZG0qVLF/LmzcvZs2dZtmwZN2/eNNalcuXKTJ8+3WRZTdP4+uuvyZ8/Pzlz5kzTOiaFtU6NidSzp+yNT+bMmdm+fTsvXrygW7duaJqGv78/O3bsoGzZsonW4YcffqBRo0YMHjyYixcv8vnnn7Np0yaqVatmlslfffUVI0aMMGby6tWradKkiTGT//33X7Mf4zHbyJkzJ0eOHLFu5RPh6urKqlWriIiIYMCAAWiaxqBBg/j555+pV68e4eHhCS7frVs3Tp8+zfbt2+Nt2IKhw+HJkyds3ryZDz/80NrVSLXnz58zfPhwMmXKRL9+/VBKsXz5coYPH87333+faPaOHDmSyMhIOnfuTJ48eTh37hwrV67k5s2bDBkyxGT+ChUq0KFDB5NpXl76eH6MnrPXIRu3PXr0oEiRIpQsWZILFy4AcOLECc6dO0evXr3MvqxtKTVlLVOmDJ06daJ79+4sWbIEgN27dxMYGMiYMWNo1qwZAHny5GHgwIFMnDiRqVOnArBr1y6KFSvGxIkTjUH6999/U6JECV69emXcxubNmwkMDGTw4MEmjdsvvvjCpCw7duwgS5YsDBs2jFy5cvHggXXukvThhx/y2muv8fbbb3Pp0iUAAgMDOXLkCF27dmXOnDnxLuvr60ubNm3o3bs3K1euBGDfvn3s37+foUOH0rlzZwBjD21sVapUIVeuXEyaNMlkeo8ePUz+3rVrF/nz56dTp07p3rjdtGkTt2/f5ocffjD2nPj4+PDRRx+xYcMGWrVqFe+ygYGB3Lhxg3HjxlGxYkUAypYty+PHj/nll194/vw5rq6u5MiRgxw5cpgse+rUKR49emTcf7YmPbP6YU/ZG5+YOrz++usmdTh79mySM/mjjz4yyeRTp04xevRo4w//PHny8NVXXzFp0iSTTC5atCgTJkwwZvLjx485dOiQyTa8vb0pVaoU06ZNS/fGRceOHfH29ua9997jypUrAAQFBbF79246derEDz/8kODyvr6+aJpG4cKFE2zc1q1bF03TcHJy0mXjdsuWLdy5c4c5c+YYs/e1116jV69ebNq0KcEOntOnT3Pz5k1Gjx5NhQoVAMNx8/jxY37//Xdj9sbInj07r7/+eprWJ6X0nL0OOSyhadOmHDx40BhMAJcvX2bfvn3GBp9epKasTZs2JSIigp9//tk47dWrV6xatYr69evj7OwMQP369XFxcWH58uUmyy9fvpwyZcrw2muvARAWFmbSsI1Z3/Hjx5M0DCCmgfjy5ctE502qhg0b8s8//xgbtgBXr17l0KFDNGzYMMFlGzRoQEREBL///rtx2qtXr/jtt9+oXbu2cf9Y0r59e168eMFvv/2WaBlDQkKIjIxMQm2s6+DBg7z++usmpwTz58+Pr68vBw8eTHDZmPJmyZLFZHrWrFkTDaytW7eSKVMm3nvvvZQV3MqS8pQckT7sKXvj06RJk3jr0LRp0wSXjS+Tf/755yRl8ooVK0wy2ZIPP/yQDBky8OOPP6agdqnz/vvvc+zYMWPDFuDatWv8888/1KtXL9Hlk9oY0nOjCeDQoUOULFnSLHtLlSqVptmrN3rOXods3Pr6+hpPOccWGBhI6dKlbVCi+KWmrL6+vsYxtHGXdXFxoVixYsb5nj9/zvnz583mAxLcTqZMmahatSpnzpyx+L6TkxNZs2alTp06DBgwgIULF/Lo0aMEy50cJUuWtLjt4OBgSpYsmeCyr7/+OlevXjXbP0FBQbi4uODj42NxOVdXV5o1a8aWLVsICQmxOI+TkxPZs2enSZMmtG/fntmzZyexRtZz5coVChcubDa9cOHCXL16NcFly5cvT8GCBVm0aBFXrlwxjsP+448/aNSoUbyn1V68eMHevXupXLky2bNnt0o9UkvP477+a+wpe+Pj6+trzMbYTp8+nWgdSpcuneaZ/OGHH3L06FGLZUxrxYsXJzg42Gz62bNnKV68eLqXx1auXr2Kt7e32XRvb2+uXbtmYYn/V65cOTw9PVmyZInx+ykgIID169fToEEDs+w9fPgwrVq1okWLFgwcOFA3421B39mb6LAEpVRlQNM07YhSqjTQAAiKvnWDLuXMmdNio+Thw4d4eHjYoETxS01ZE1o25v2Y/4aGhiY6nyVff/01Xl5edOrUyey9uF9kP/74Iz17xn1sdOp4eHgQFhZmNj0kJMTsdLmlZS3VO2ZafPv3gw8+IHv27Kxatcri+/Xq1eOnn34CDL9cZ8yYYTy1mJ4eP36Mm5ub2fRs2bLx+PHjBJd1dnZm6tSp+Pv706tXL+P0Bg0a8Pnnn8e73P79+3n27Bl169ZNecGtzFEbr5K9tqHnTK5SpQolSpSgb9++CZYjreTIkcNiHoeGhuLu7m6DEtnGkydPyJYtm9l0Nzc3njx5kuCyzs7OTJo0iQkTJpgM76tXrx6ffvqpybyVK1emePHi5MuXj9DQUP7880/Gjx/PgAEDqFWrlnUqkwp6zt4EG7dKqVFAQyCjUmor8DawCxiqlCqvadq4tC9iylja6dE3/9WdlJZVKZWkZZM6X1wdOnRg6NCh+Pv78/fff5u9f/78eSpVqkTWrFmpVq0aw4YNI2PGjFYfi5nW+yeu9u3bc+/ePbZu3Wrx/QMHDlCnTh2yZ89OzZo1jRe6jRun24+DmYiICMaPH09oaCiDBg0ib968BAcHs3LlSpycnOjdu7fF5bZt24a7uzuVK1dO5xLHzxGHHUj22pZeM7lr165EREQYryGwBUf4/2sNluqclMZeREQE33zzDWFhYQwYMIA8efJw9uxZVq1ahZOTk0nnQuyOBzD8uBk4cCBLly7VReNWz9mbWM9ta6Ac4ALcBrw0TXuklJoMHAIsBqxSqidg3S68ZAgJCbH4y9fDwyPe08y2kpqyPnz40OKpkZjehZhegPh6HOLOF1vjxo1ZsmQJCxcu5Ouvv7a4/RcvXnD06FEA9uzZw61bt1iyZAnff/+92UUQKRUaGmqxhzZHjhwWez5iCwkJsXhVaUwPg6X9my9fPt59910WLFhgNv44xuPHjzl+/DhgqHdERAQDBw5k0aJF3Lp1K+EKWVF8PbRPnjyx2KMb26ZNmzhx4gSLFi0yjht78803yZo1KzNmzKBRo0YUKVLEZJkHDx5w7NgxmjVrhpOTk/Uqkkp67j1IBcleG9FrJjs7O9OmTRs2bNhgtQt2kyssLMxiHru7u1vs0XVUCWWvpR7d2LZu3crJkyeZP38+BQoUAOCNN94ga9aszJw5k4YNG8Y7ZM7JyYl33nmHJUuW8PDhQ5vfrUbP2ZvYmNtITdNeaZr2DLigadojAE3TwoF4m+yaps3XNK2SrR5NGRgYiK+vr9n00qVLc/r0aRuUKH6pKWtgYCA+Pj5m95YtXbo0L168MI7nCgwMxNXVlaJFi5rNB5htp3bt2qxZs4bff//d7JdjQv755x8A47gyawgODrZ4pWiJEiUsjv2KLSgoCG9vb7P9U7JkSV68eGFykVqMNm3akDFjxniHJFhy/PhxnJycLH6ppaXChQubXNgR48qVK4mW5fLly2TLls3s/pQx45gtjdndsWMHUVFRuhqSAPq+qCEVJHttJL7xwaVKlUq0DqdPn06TTAbDxWo5c+Zk6dKlyaqPNZ09e5YSJUqYTS9evDjnzp2zQYlsw9vb22JGXrt2LdH7Icdkb0zDNkbMfk1szG5Mg1IPveV6zt7EGrcRSqmYS/oqxkxUSrmTQMDa2rp166hSpYrJr5/ChQtTvXp11q1bZ8OSmUtNWdetW2f8NR/DycmJdu3asWXLFiIiIgBDL92LFy/Mxs127tyZkydPcvnyZeO0KlWqsHbtWrZv307nzp2T9cvs3XffBTC5yji1Nm7cSKVKlUwunCpUqBBvv/02mzZtSnDZTZs24ezsbHKVtpOTEy1atGDnzp3G/RNbu3btOHXqlMWLYuJTrVo1oqKiLDY001KVKlUICgoy6S2+ffs2p0+fpkqVKgku6+HhwZMnT7h586bJ9KCgIABy585ttsz27dvx8fEx+0K2NT1f1JAKkr02sn79+njrsH79+gSXjS+T27Ztm6RM7tSpk1kmx+jSpQv37983uSVjetu2bRvly5c3+fHs5eVFpUqV4h3G5YgqV65McHAwt2/fNk67c+cOZ86cSfTBGvFlb0xnTa5cueJd9tWrV+zbt488efLoYgy7nrNXJbRxpZSLpmkvLEzPDRTQNO1kohtQKt1rlyVLFgICAggPD2fEiBHGm3C7ublRpkwZnj59mt5FildSy+rt7c2FCxcYM2YM/v7+xuV/+ukn6tevz6BBg7h06RKfffYZjRs3plq1ahw7dsw434QJE+jXrx9+fn78+++/tGvXjl69etGsWTP+/PNPwNBrt3//fh49ekS3bt3MnpYSM9TgzTffZMqUKaxZs4aLFy/i4uJCzZo16du3Lzt37qRRo0bx1je5p1GyZMnC7t27ef78OePHj0fTNIYNG0a2bNmoWbOmcf94eXlx9OhRJk+ezJQpU4zLL1iwgNq1azNq1CiuXr1K9+7dqVevHg0bNuTEiRMm2ypTpgw7d+5kxIgRFu+f+/7779OxY0c2b97M9evXyZYtG3Xr1qVLly4sXbqUgQMHJrleMb3cqfH8+XM+++wzXFxc6Nq1KwBLly4lPDycOXPmGHuP7ty5Q/fu3enUqZPxy/T27dt8/vnneHh40L59e+NDHH766ScKFizIjBkzTJ66du7cOXr37k2PHj0SvH9ucvn4+KS6+6FQoUKJZsy1a9ds382RDJK91pPcHq4sWbJw/PhxwsPDGTlyJJqmMWbMGNzc3ChbtqxJJp8/fx5/f3+TTF65ciX169dn8ODBXLp0iU8//ZTGjRtTvXp1s0zu27cvw4cPN2Zyz549ad68uTGTY+TJk4fr168zd+7cFF9MZo0b/2fOnJnNmzfz/PlzJk+eDMBXX31FtmzZqFevnvEBFwULFmTv3r3MmDGDGTNmGJd/++23yZUrF3ny5MHf358lS5YYb53111//f51kmTJl8PLyIkOGDMyePZs///zTuE927Nhh9t2UHNu2bUvxsjGeP39Onz59cHZ2pnPnzsaHOISHh/P9998bs/fu3bv06NGD9u3bGx/EcOfOHXr37o2Hhwdt27YlT548nD9/nlWrVlGwYEGmTp1KhgwZ2L17N4cOHaJSpUrkzp2b0NBQNmzYwOnTpxk0aBA1a9ZMdT1KlCiRqlzUc/YmOObWUrhGT78P3E+TElnBs2fPqF27NtOnT2fZsmUopdi+fTv9+vXTVcMWkl5WpRQZM2Y0e8xr9+7dGTduHGPHjiVHjhwEBATQoEEDkxAFGD58OE+ePKFv377kz5+f4OBg2rZtaxKiVapUIWfOnOTMmZNdu3aZlTXmS+LOnTvcv38fPz8/8ufPz7Nnz7h48SIDBw5M9CbeyfXs2TOaN2/OuHHjmDNnDkop9uzZg5+fX5L2T+/evRk+fDh+fn64u7sTGBhI27ZtzRq2YLiQ7OXLl/zyyy8Wy3L58mUyZMiAn58fuXPnJiwszPgEol9//dWq9U4KV1dXJk2axLx585g8eTKaplGuXDl69eplclpU0zSzU0T58+dn+vTpLF++nB9//JFHjx6RJ08eGjZsSPv27c3247Zt23BycqJ27drpVr+kstNhBwmS7LWdZ8+eUadOHaZNm8bSpUuNdejfv3+SMuejjz5i3Lhx+Pv7GzO5YcOG8WZynz59jJncrl07s4YtGHp0M2XKZJN728YWHh5O+/bt+d///se3336LUop9+/YxevRokye3xbdvBgwYYPLEtW7dutGtWzcAk97grl27mvR+N27cmMaNGwOGM2XXr19Pi+olmaurK2PHjuWHH35g2rRpgKFB3qNHD4vZG7sTMV++fEyZMoWVK1eyfPlyHj16RO7cualfvz7t2rUz7rN8+fIRFhbG4sWLefz4MS4uLhQvXtzk4Q+2pufsTbDn1iobsEHvgdAvWw+A1wtr9Nw6Amv03Hp6eiaaMTdv3rSrnltrkOw10MPYRD3QyyNbbc0aPbeOIrU9t3rOXod8/K4Q4r/DTsfUCiGEXdNz9krjVghh1/R8akwIIRyVnrNXGrdCCLum594DIYRwVHrOXmncCiHsmp57D4QQwlHpOXulcSuEsGt67j0QQghHpefslcatEMKu6TlghRDCUek5e6VxK4Swa3o+NSaEEI5Kz9krjVshhF3Tc++BEEI4Kj1nrzRuhRB2Tc+9B0II4aj0nL3SuBVC2DU99x4IIYSj0nP2SuNWCGHX9BywQgjhqPScvdK4FULYNT2fGhNCCEel5+yVxq0Qwq7pufdACCEclZ6zVxq3Qgi7pueAFUIIR6Xn7M1g6wIIIURqREVFJfpKCqVUA6VUsFLqvFJqqIX3lVLqu+j3TyilKli9MkIIYSf0nL3SuBVC2DVN0xJ9JUYp5QTMAhoCpYEOSqnScWZrCBSPfvUE5li3JkIIYT/0nL3SuBVC2DUr9R5UBs5rmnZR07QIYBXQLM48zYClmsFBIIdSqoB1ayOEEPZBz9mb5mNuNU1Tab2NxCilemqaNt/W5bA12Q8Gsh8MHGU/REVFJZoxSqmeGH7xx5gfp+4FgWux/r4OvB1nNZbmKQjcSlaB04lkr37IfjCQ/fD/HGFf6Dl7/ys9tz0Tn+U/QfaDgewHg//MftA0bb6maZViveJ+qVgK6bjn1JIyjzD1nznGEiH7wUD2w//7T+wLW2Xvf6VxK4QQCbkOFIr1txdwMwXzCCGESLo0yV5p3AohBBwBiiulfJRSzkB7YF2cedYBXaKv3K0ChGmapsshCUIIYSfSJHv/K/e5tetxLVYk+8FA9oOB7IdomqZFKqW+BDYDTsAiTdMClVKfRr8/F/gL+AA4DzwDutuqvHZEjjED2Q8Gsh/+n+wL0i57lZ5vwiuEEEIIIURyyLAEIYQQQgjhMKRxK4QQQgghHIbDN24Te6zbf4FSapFS6q5S6pSty2JLSqlCSqmdSqkzSqlApVRfW5fJFpRSrkqpw0qpgOj9MNrWZRKOR7JXsjeGZK+BZG/6cegxt9GPdTsLvI/hVhJHgA6app22acHSmVKqJvAEwxM+3rB1eWwl+okmBTRN+1cp5QYcBZr/B48HBWTVNO2JUioT8DfQN/rJL0KkmmSvgWSvgWSvgWRv+nH0ntukPNbN4Wmatgd4aOty2Jqmabc0Tfs3+t+PgTMYnnLynxL9CMMn0X9min457q9cYQuSvUj2xpDsNZDsTT+O3riN75Ft4j9OKfUaUB44ZOOi2IRSykkpdRy4C2zVNO0/uR9EmpHsFRZJ9kr2pgdHb9zK4zKFGaVUNuBXoJ+maY9sXR5b0DTtlaZp5TA86aWyUuo/e8pUpAnJXmFGsleyN704euNWHpcpTESPc/oVWKFp2m+2Lo+taZoWCuwCGti2JMLBSPYKE5K9piR705ajN26T8lg38R8RPZh/IXBG07Rpti6PrSil8iilckT/OzNQFwiyaaGEo5HsFUaSvQaSvenHoRu3mqZFAjGPdTsDrNY0LdC2pUp/SqmfgANASaXUdaXUx7Yuk41UBz4Eaiuljke/PrB1oWygALBTKXUCQyNkq6Zpf9q4TMKBSPYaSPYaSfYaSPamE4e+FZgQQgghhPhvceieWyGEEEII8d8ijVshhBBCCOEwpHErhBBCCCEchjRuhRBCCCGEw5DGrRBCCCGEcBjSuBVCCCGEEA5DGrdCCCGEEMJhSONWCCGEEEI4DGncCiGEEEIIhyGNWyGEEEII4TCkcSuEEEIIIRyGNG7/w5RSc5VSI21dDiGE+C9SSr2nlLpu63II4WikcWunlFKXlVJ1U7MOTdM+1TTN31plSi6lVEel1D9KqSdKqVtKqY1KqXcSmL+/Uuq2UipMKbVIKeWSwLzllFJHlVLPov9bLqnrUkp9GV2uF0qpJdaoqxBCpDellLNS6mul1Dml1NPo741FSqnX4pnfJfr9R9H5OCCR9XdUSl2JXvcfSqmcSV2XUmq+UipYKRWllOpmjfoKEUMatw5KKZXR1mVISHTQfQuMB/IB3sBsoFk889cHhgJ1gNeAIsDoeOZ1BtYCywEP4EdgbfT0pKzrJjAWWJTiCgohhO39AjQFOgLuQFngKIbss+RroDhQGKgFDFZKNbA0o1LKF5gHfIghw59hyPCkrisA+Bz4N/nVEiIRmqbJy85ewDIgCggHngCDMTTSNOBj4CqwJ3reNcBtIAzYA/jGWs8SYGz0v98DrgNfAXeBW0D3NCq/e3S52yRjmZXA+Fh/1wFuxzNvPeAGoGJNuwo0SM66MDRwl9j6/7e85CUv/b4w/FD+Jc60GcB30f/uDpwBHgMXgV6x5nsPuJ5G5aob/R1RKBnL3ADqxfrbH1gVz7zjgZWx/i4KRABuyVkX8DfQzdb/H+XlWC/pubVDmqZ9iKGx1kTTtGyapn0T6+13gVJA/ei/N2L49ZwXwy/kFQmsOj+GhmdBDI3kWUopDysXH6Aq4Ar8Ht8MSql3lFKhsSb5YvilHyMAyKeUymVhcV/ghKZpWqxpJ6KnJ3ddQgiRkJ+AD5RS2QGUUk5AWww/osHQWdAYyI6hoTtdKVUhHcpVFzisadq1+GZQSg1VSv0Z/W8PwBPzbPS1tCxxclTTtAsYGrclUrAuIaxKGreO52tN055qmhYOoGnaIk3THmua9gLDaaKySin3eJZ9CYzRNO2lpml/YehdLZkGZcwF3Nc0LTK+GTRN+1vTtByxJmXD0PscI+bfbhYWjztvzPxu8byf0LqEECJemqZdwdBx0Dx6Um3gmaZpB6Pf36Bp2gXNYDewBaiRDkXLheEMXLw0TZuoaVrj6D+zRf83bjbGl4sJ5Wxy1yWEVUnj1vEYf6UrpZyUUhOVUheUUo+Ay9Fv5Y5n2QdxGpzP+P+QMlJK1Y2+CCwpr3GWtgPkTua44CcYej5ixPz7cRLmjZn/cTzvJ7QuIYRIzEqgQ/S/O/L/vbYopRoqpQ4qpR5Gn436gPgz2EgpNToZOWtpXOwDoEAy6vAk+r9xszG+XEwoZ5O7LiGsShq39ktLwvSOGC7QqothuMFr0dNVqjasaduih0Mk5TXcwioOAM/5/56OpAjEcDFEjLLAHU3THsQzbxmlVOx6lomentx1CSFEYtYA7ymlvIAWRDduo+/C8iswBcgXfTbqL5KQwZqmjUpGzm6ysIptQOXoMiVK07QQDD29cbMx0PISpjmqlCoCuABnU7AuIaxKGrf26w6Gq/wT4ga8wPALPguGCwBsTtO0MOB/GMb0NldKZVFKZYru4fgmnsWWAh8rpUpHj+cageGCOEt2Aa+APtG3o/kyevqOpKxLKZVRKeUKOAFOSilXvd99QghhO5qm3cOQO4uBS5qmnYl+yxlDg+8eEKmUaojhgtf0KNM2YCvwu1KqYnSuuSmlPlVKfRTPYkuBEUopD6XU60AP4s/ZFUATpVQNpVRWYAzwm6ZpMb2zCa4r+jZlrhga+pmic1baJMIq5ECyXxMwBEeoUmpgPPMsBa5guGr1NHAwvQqXGE3TpgEDMDQs72EYTvEl8AdAdGA+iTX/JuAbYCeGOl0BRsW8rwz3yPWLnjcCQ69wFyAU+AhoHj090XVFlykcw1XQnaP/PcJ6tRdCOKCVGM6SGYckRDf0+gCrgRAMZ9PWpWOZWmPoKf4Zw5jXU0AlDL26KKX8lFIbY80/CriAIRN3A5Nj9wpHD4GoAaBpWiDwKYZG7l0MnSmfJ3VdGMYehwPVgPnR/65plVqL/zxlekG5EEIIIYQQ9kt6boUQQgghhMOQxq0Q4j8v+jGhd5VSp+J5XymlvlNKnVdKnUin+5QKIYRDS6vslcatEEIYLnSx+JjRaA0xPAylONATmJMOZRJCCEe3hDTIXmncCiH+8zRN2wM8TGCWZsDS6BvxHwRyKKWScw9RIYQQcaRV9krjVgghEleQWA9IAa5HTxNCCJF2UpS9aX7vznPnzsntGICmTZvaugi6EBQUZOsiCB3RNC1VDxSJWU1iMyilemE4pRVjvqZp85OxDUvl1HW2BQUF6bp86aV169a2LoIuBAbK8xOEKSvkr26zV25ML4Swa0m5nWF0mCYnUOO6DhSK9bcXcDMV6xNCCLum5+yVYQlCCLumaVqiLytYB3SJvnK3ChCmadota6xYCCHskZ6zV3puhRB2zRoBqpT6CXgPyK2Uuo7h6UqZotc/F8NTnj4AzgPPgO6p3qgQQtgxPWevNG6FEHYtKioq0XmcnJwSfF/TtA6JvK8BXySrYEII4cD0nL3SuBVC2DV5hLgQQqQ/PWevNG6FEHYtKb0HQgghrEvP2SuNWyGEXdNz74EQQjgqPWevNG6FEHZNzwErhBCOSs/ZK41bIYRd0/OpMSGEcFR6zl5p3Aoh7Jqeew+EEMJR6Tl7pXErhLBreu49EEIIR6Xn7JXGrRDCrum590AIIRyVnrNXGrdCCLum54AVQghHpefslcatEMKu6fnUmBBCOCo9Z680boUQdk3PvQdCCOGo9Jy9dtG4vXfvHgsWLOD48eNomka5cuXo0aMHefPmTXTZu3fvsnz5ck6ePMmjR4/IlSsXNWrUoE2bNri6uhrn++ijj7h7967Z8sOHD6dq1apWrU9q5M+fn6FDh1KtWjWUUhw4cIAJEyZw69atRJft168fb7zxBr6+vuTIkYNhw4bxxx9/WJw3b9689OnTh5o1a+Lu7s7du3f566+/mD59upVrlD68vLyYPn0677//Pkoptm3bRr9+/bh27Zqti5auHHE/6DlgHcG9e/dYuHAhAQEBaJpG2bJl+eSTT8iTJ0+Sll2xYoUxf3Pnzk316tVp3bq1Sf7GtmfPHqZOnUquXLlYtGiRtauTYvnz52fw4MFUrVoVpRQHDx5k4sSJ3L59O9Fl+/bti6+vL6VLlyZHjhwMHz6ctWvXmszTrFkzxo0bF+863n33XR48eJDqeqQ3R8yclHDE/aDn7NV94/b58+f4+fmRKVMm+vfvj1KKZcuW4efnx8yZM+MNyJhlR4wYwatXr+jcuTN58uTh7NmzrFy5kps3bzJkyBCT+StUqEDHjh1Npnl5eaVJvVLC1dWVJUuWEBERwbBhw9A0jb59+7JkyRKaN29OeHh4gst37tyZM2fOsGvXLpo3bx7vfJ6enqxcuZLr168zfvx4Hjx4gKenJ4ULF7ZyjdJH5syZ2bFjBy9evKBr165omsbYsWPZuXMnZcqU4dmzZ7YuYrpw1P2g51Nj9u7FixeMHDmSTJky0bdvX5RSrFixghEjRjBjxoxE8/d///sfkZGRdOrUidy5c3P+/Hl++uknbt68yeDBg82WefLkCQsXLsTDwyMtq5Vsrq6uLFy4kIiICIYPH46mafTu3ZvFixfTsmXLRLO3Y8eOBAUFsXv3bpo1a2Zxnj179ph9/yilmDlzJtevX7fLhq2jZk5yOep+0HP26r5xu3nzZu7cucPcuXPx9PQE4LXXXqNnz55s3LiRFi1axLvs6dOnuXnzJmPGjKFChQoAlClThidPnvDbb7/x/Plzk3DOnj07r7/+etpWKBXatGmDl5cXH3zwAVevXgUgODiYTZs20bZtW3788ccEl3/rrbfQNA1vb+8EG7dff/01d+7coVu3bkRGRlqzCjbRo0cPihQpQsmSJblw4QIAJ06c4Ny5c/Tq1ctue6OTy1H3g557D+zdli1buHPnDrNnz6ZAgQKAIX8//fRTNm/eHG9DDeDMmTPcvHmTr7/+mvLlywOG/H38+DF//PEHL168wMXFxWSZH3/8kddee42cOXMSEBCQdhVLptatW+Pl5UXjxo2NPW1nz55lw4YNtGnThqVLlya4fJUqVdA0jUKFCsW7z0JCQggJCTGZVqFCBTw8PJg1a5Z1KpLOHDVzkstR94OeszeDrQuQmEOHDlGyZEljwxYMp4dKly7NoUOHElw2pmGWJUsWk+lZs2bV9f+U+NSqVYuAgABjwxbgxo0bHDt2jDp16iS6fFLqXKhQIWrUqMGKFSscomEL0LRpUw4ePGgMFYDLly+zb9++BL+cHY2j7oeoqKhEXyJlDh8+TIkSJYwNW4B8+fJRqlSpVOdv3DyKOav06aefWqn01vPee+9x4sQJk1PIMdlbq1atRJdP6fdNs2bNiIiIYOPGjSla3tYcNXOSy1H3g56zV/eN26tXr1o8He7t7W3SyLOkXLlyeHp6smTJEq5evUp4eDgBAQGsW7eOhg0bmp1SO3z4MK1ataJ58+Z89dVXHDhwwKp1Sa1ixYpx7tw5s+nnz5+naNGiVtlGTA/38+fPjePsYsaW5ciRwyrbSG++vr6cOnXKbHpgYCClS5e2QYlsw1H3Q0xDKaGXSJmE8jexsYJly5bF09OTH3/80Zi/J06c4M8//6RBgwYm+RsZGcmsWbNo0aKFSUNaL+LL3gsXLlgte+NycXGhXr167N69m7CwsDTZRlpz1MxJLkfdD3rO3kSHJSilXgeaAQUBDbgJrNM07Uwalw0wjMHKli2b2XQ3NzeePHmS4LLOzs588803jB8/ns8//9w4vV69ema9A5UrV6Z48eLky5eP0NBQ/vzzT8aNG8dXX32VpF/m6cHd3Z1Hjx6ZTQ8LCyN79uxW2UbMRSLjxo1j3bp1zJ8/H29vbwYMGEDRokVp27at3TUWcubMaXa6D+Dhw4e6G9uXlhx1P9jb8ZhUts5eMORv1qxZzaZny5YtSfk7YcIEJk2aRO/evY3T33//fXr27Gky72+//cbLly9p3bq1dQpuZemRvXHVrl0bNzc3swvP7ImjZk5yOep+0HP2Jti4VUoNAToAq4DD0ZO9gJ+UUqs0TZuYxuWLV1J2akREBJMmTSIsLIyvvvrKeEHZTz/9hJOTE1988YVx3riN3apVqzJw4EB+/PFH3TRuIe0PpgwZDJ35hw8fxt/fHzAMDXny5AnTpk3jnXfeYe/evWlahrRgab8ppWxQEttyxP3giMMO9JS9lo6PpObv5MmTCQ0NpX///sb8/fnnn3FycuKzzz4D4NatW6xZs4Zhw4bh7Oxs9fKnpbT87DRr1owHDx7YZd7G5oiZkxKOuB/0nL2J9dx+DPhqmvYy9kSl1DQgELAYsEqpnkBPgDFjxtC+ffsUFzC+HoL4enRj27JlCydPnmTBggXGU11vvPEGWbJkYebMmTRs2JAiRYpYXNbJyYnq1auzZMkSHj58SM6cOVNcB2t59OgR7u7uZtPj61VIidDQUAD2799vMn3fvn0AlCpVyu7CNiQkxOL/Pw8PD4u/ph2Vo+4HPfcepEKqs3f06NG0bds2VYXImjWrxfx9+vRpovm7detWTp06xdy5c4356+vrS9asWZk1axYNGjTAx8eHBQsW8Oabb1KiRAnjtiIjI9E0jSdPnpApUyazC8/S26NHjyz20GbPnt1q2Rtb7ty5qVKlCitXruTVq1dWX396cdTMSS5H3Q96zt7EGrdRgCdwJc70AtHvWaRp2nxgPsC5c+dSVfv4xtZevXoVb2/vBJe9fPky2bJlMxvDVaJECQCuXbsWb+M2Nr38ujp//jzFihUzm160aFGTgeqp3QbEf9Dq+ZdafAIDA/H19TWbXrp0aU6fPm2DEtmGo+4HezwmkyDV2RsUFJTqb5748vfatWsUKlQowWWvXLliMX+LFy9uXIePjw/Xrl3j7t27dOrUyWwdnTp1okmTJnzyySepqEXqpUf2xtakSRMyZsxo10MSwHEzJ7kcdT/oOXsTu6CsH7BdKbVRKTU/+rUJ2A70TfPSAW+//TZBQUEmN8q+c+cOZ86coXLlygku6+HhwZMnT7h586bJ9LNnzwKQK1eueJd99eoVf//9N3ny5NHNmJidO3dStmxZk3vvenp6Ur58eXbs2GGVbQQEBHDv3j1q1KhhMv2dd94BsDgoXu/WrVtHlSpV8PHxMU4rXLgw1atXZ926dTYsWfpy1P2g54saUqEfNs5eMFyLEBwcnKr8jfuAmbj5O3DgQMaOHWvyKl++PNmzZ2fs2LE0atTIyrVKvpj7kcbN3nLlyrFr1y6rb69JkyYEBwcTHBxs9XWnJ0fNnORy1P2g5+xViW1cKZUBqIzhogYFXAeOaJqWpHMlqe25ff78Ob1798bZ2ZkPP/zQ+BCH8PBwZs6cSebMmQHDk8g++eQTOnToQIcOHQBDCH/55Zd4eHjQrl078uTJw7lz51i1ahUFCxZk2rRpZMiQgd27d3Pw4EEqVapEnjx5CAkJYcOGDZw+fZpBgwbx7rvvpqYKgOFWIKmVOXNmfv/9d168eMGMGTPQNI0+ffqQNWtWmjdvbrwRtKenJ5s3b2bOnDnMnj3buPxbb72Fh4cHuXPnZuTIkaxYsYLDhw3D+bZs2WKcr1mzZkycOJFVq1axdetWChcuTN++fQkKCqJbt26pqkNQUFCqlk+JLFmyEBAQQHh4OCNGjEDTNPz9/XFzc6NMmTI8ffo03ctkC3rcD5qmpfq0yIULFxLNmKJFi+rj9EsypDZ7rdFz+/z5c/r27YuLi4uxZ3XlypWEh4czY8YMk/zt1asX7dq1Mw5Du3PnDn379sXDw4M2bdoYH+KwevVqPD09mTJlinGMf1wzZswgICDAKk8os8ZFapkzZ+bXX3/l+fPnfP/998aHOGTJksXkIQ4FChRg48aNzJ07l7lz5xqXr1SpkjF7hw8fzsqVKzly5AhgGL4RW6lSpVizZg3ffPNNovfPTY7AwECrrSup9Jg5tqDX/ZDa/NVz9iZ6twRN06KAg+lQFotcXV0ZN24cP/zwA1OnTgUMt5jp0aOHMVjB8Asi7n3V8uXLx9SpU1m5ciXLli0zPv6xQYMGtGvXzhis+fLlIywsjMWLF/P48WNcXFwoXrw4o0ePpmLFiulb4QSEh4fTvXt3hg4dyqRJk0wevxv3CScZM2Y0G07x5ZdfmvS2dOrUyfiFVapUKeP0tWvXomkan3zyCS1btiQsLIz169fb7Y2mnz17Ru3atZk+fTrLli1DKcX27dvp16/ffyZcwXH3g55PjaWGrbMXDPk7duxYFi5cyPTp042P3/34448t5m/szpJ8+fLxzTffsGrVKpYvX87jx4/JnTs39evXp02bNvE2bPUoPDycjz76iCFDhjBhwgTj43cnTZpk8nQypRQZM2Y0q9sXX3zBW2+9Zfy7Y8eOxqeRvfHGGybzNmvWjJcvX7Jhw4Y0rFH6cNTMSS5H3Q96zt5Ee25TK7U9t47CGj23jsAWPbdCv6zRc3v27NlEM6ZEiRJ213ObWtbouXUEer29WHqzRc+t0LfU5q+es1f3j98VQoiE6Ln3QAghHJWes1cat0IIu2anF4wJIYRd03P2SuNWCGHX9BywQgjhqPScvdK4FULYNT2fGhNCCEel5+y1n8tVhRDCAmvda1Ep1UApFayUOq+UGmrhfXel1HqlVIBSKlAp1d3qlRFCCDuh5+yVxq0Qwq5ZI2CVUk7ALKAhUBrooJQqHWe2L4DTmqaVBd4DpiqlnK1bGyGEsA96zl4ZliCEsGtWOjVWGTivadpFAKXUKqAZEPvZmBrgpgw3kM4GPAQirbFxIYSwN3rOXmncCiHsmpUuaigIXIv193Xg7TjzzATWATcBN6Bd9IMWhBDiP0fP2SvDEoQQdi3myYQJvZRSPZVS/8R69YyzGks3Go+b3PWB44AnUA6YqZTKbvUKCSGEHdBz9krPrRDCriWl90DTtPnA/ARmuQ4UivW3F4Zegti6AxM1wwbPK6UuAa8Dh5NVYCGEcAB6zl7puRVC2DUrXbF7BCiulPKJvlChPYbTYLFdBeoAKKXyASWBi1asihBC2A09Z6/03Aoh7Jo1LmrQNC1SKfUlsBlwAhZpmhaolPo0+v25gD+wRCl1EsOptCGapt1P9caFEMIO6Tl7pXErhLBr1npKjqZpfwF/xZk2N9a/bwL1rLIxIYSwc3rOXmncCiHsmp6fkiOEEI5Kz9krjVshhF3T8/PNhRDCUek5e6VxK4Swa3oOWCGEcFR6zl5p3Aoh7JqeT40JIYSj0nP2pnnjtlGjRmm9CbswadIkWxdBF4YNG2brIujC2bNnbV0Eh6Hn3gNbatGiha2LoAujRo2ydRF0Ydy4cbYugi6cOnXK1kVwGHrOXum5FULYNT0HrBBCOCo9Z680boUQdk3Pp8aEEMJR6Tl7pXErhLBreu49EEIIR6Xn7JXGrRDCrum590AIIRyVnrNXGrdCCLum594DIYRwVHrOXmncCiHsmp4DVgghHJWes1cat0IIu6bnU2NCCOGo9Jy90rgVQtg1PfceCCGEo9Jz9krjVghh1/TceyCEEI5Kz9krjVshhF3Tc++BEEI4Kj1nrzRuhRB2Tc8BK4QQjkrP2SuNWyGEXdPzqTEhhHBUes5eadwKIeyannsPhBDCUek5e6VxK4Swa3oOWCGEcFR6zl5p3Aoh7JqeT40JIYSj0nP2ZrB1AZIif/78fPfddxw9epR///2XmTNnUqBAgSQtO2DAABYtWsShQ4c4e/YsLVq0SHSZRo0acfbsWfbs2ZPaoltdaGgoy5cvZ9SoUYwaNYply5YRGhqa5OXv3r3LihUrGDNmDCNGjGDKlCn8/fffJvM8ffqUdevW8c033zBixAgmTZrE2rVrefLkiZVrk3L58+dnxowZHDlyhH/++YfvvvsuycdE//79WbhwIQcPHiQoKCjBYyJv3ryMGzeOvXv3cuLECbZt28aAAQOsVY14eXl5sXr1akJCQggNDeWXX36hUKFCSVrWxcWFb775hhs3bvD06VP27dtHjRo1zOZTSjF06FAuXrzIs2fPOHbsGC1btkxw3VWrViUyMpKoqCicnJxM3mvcuDHLly8nKCiIyMhIduzYkfQKp4KmaYm+RMrlz5+fb7/9lsOHD3PkyJFkfdb69evHDz/8wIEDBzhz5gzNmzePd968efMyduxY9uzZQ0BAAFu3bqV///5WqkXqZcmSherVq9OyZUtatWpF9erVyZIlS5KXz549O9WqVaNFixa0bt2aDz74gBIlSpjM06RJE9q3b2/2KliwoLWrk2L58uVj6tSp7N+/nwMHDjB9+nTy58+fpGX79OnDvHnz2Lt3LydPnqRZs2Zm8zRr1oyTJ0/G+8qVK5e1q2TCy8uLNWvWEBoaSlhYGL/++muys/fmzZs8e/aM/fv3J5i9ly5dIjw8nOPHj5tlb/78+Rk/fjxHjhwhNDSUu3fvsm3bNovry5AhA/369ePkyZM8efKEmzdv8ttvv/Hmm2+mbCckkZ6zV/eNW1dXV5YuXUqRIkUYMmQIgwYNonDhwixbtozMmTMnunznzp1xdXVl165dSdqem5sbfn5+3L17N5Ult76IiAgWLFjAvXv3aNu2LW3btuX+/fvMnz+fiIiIRJe/fv06s2bNIjIyklatWtG9e3dq1KhhcgBqmsbSpUsJCAigZs2adO/enZo1axIQEMDSpUt10VBwdXVlyZIl+Pj4MHToUAYPHsxrr73Gjz/+mORjwsXFJdFjomDBgqxZs4bXXnuNcePG8fHHHzNz5kwiIyOtVBPLMmfOzPbt23n99dfp1q0bXbp0oXjx4uzYsSNJX6Y//PADn3zyCaNGjaJJkybcunWLTZs2UbZsWZP5/P39GTVqFLNmzeKDDz7g0KFDrF69moYNG1pcb8aMGZk7dy537tyx+H7z5s0pV64cBw8e5Pr168mveApFRUUl+hIpE/NZK1KkCMOGDWPIkCEULlyYJUuWWPWz5unpyerVq3nttdcYP348n3zyCTNnzuTVq1dWqknqODk5UatWLdzc3Dh06BAHDx7Ezc2N2rVrm/3Is8TDw4P3338fJycnDh8+zJ49ewgODkYpZTbvrVu32Lp1q8lLL99Hrq6uLFy4EB8fH0aMGIGfnx+FCxdm0aJFSToeOnbsiIuLC7t37453nj179tCpxKfzJAAAS7JJREFUUyeTV+fOnQkJCeHkyZM8ePDAmlUykTlzZnbs2MHrr79O165d+fDDDylevDg7d+5MUvYuXLiQHj168L///Y/GjRtz69YtNm/ebDF7v/76a2bOnEnDhg05ePAga9asMcneihUr0q5dO9auXUvr1q3p1q0bz58/Z9euXTRq1MhsfVOmTOGPP/6gSZMm9O3bl6JFi7Jz5840/WGk5+zV/bCEtm3bUqhQIerXr8/Vq1cBCA4OZsuWLbRv357FixcnuHzFihXRNA1vb+8k9doOHjyYoKAg7t27R7Vq1axSB2s5fPgwDx8+5KuvviJ37twAFChQgClTpnDo0CGLv+hiREVFsXr1aooWLUqXLl2M04sWLWoy3/3797ly5QotWrTg7bffNs6jlOKPP/7g/v375MmTJw1ql3Rt2rShUKFCNGzY0OSY2Lx5M+3atWPJkiUJLl+pUiXjMZFQT9LXX3/NnTt36Nq1q7FBe+TIEWtVI149evSgSJEivP7661y4cAGAEydOcPbsWXr16sX06dPjXbZMmTJ06tSJjz76yLgfdu/ezalTpxg9erSxvnny5OGrr75i0qRJTJ06FYBdu3ZRtGhRJkyYwMaNG83WPWjQIJRSLF68GD8/P4vljvnxk55nPfTwg8tRtWnTBi8vLz744AOTz9qmTZto27YtP/74Y4LLv/XWW8n6rHXr1i3NfzymRNGiRcmaNSt//fWX8QxWaGgojRo1olixYgQHBye4fJUqVbhz547JWbL4GqwvXrxI0wZcarRq1QovLy+aNGnCtWvXADh79ix//vknbdq0YenSpQkuX7VqVTRNo1ChQhZ7bQFCQkIICQkxmVahQgU8PDyYPXu2dSoSj5jsLVmypEn2njt3LsnZ2717d5PsDQwMZMyYMcb65smTh4EDBzJx4kST7C1WrBgTJ040Zu/ff/9NiRIlTH7gbd68mcDAQAYPHsyGDRuM07t168bPP//MyJEjjdNOnDhBUFAQjRo1Yv78+dbZQXHoOXt133Nbp04djh8/bgxWMPRA/vvvv9SpUyfR5ZOz8ytUqEDTpk0ZPXp0isqa1s6cOYO3t7exYQuQM2dOChcuzOnTpxNc9uLFi9y9ezfBBjBg/CC5urqaTI/5Va6Hg7l27doEBASYHBM3btzg2LFjVjsmChUqRI0aNVi+fHm6f9k2adKEgwcPGsMV4PLly+zbt4+mTZsmuGzTpk2JiIjg559/Nk579eoVP//8M/Xr18fZ2RmA+vXr4+LiwvLly02WX7FiBWXKlOG1114zmV6kSBH8/Pz44osvePnypcVt2+rY0POpMXtXq1atdPusrVixQpcNWzCcxXnw4IHJ0KynT59y//79RHvG8ubNi7u7e6INYHvw3nvvceLECWPDFgzHw/Hjx6lVq1aiy6f0sxiTa5Z+dFtT06ZN483e+BrjccsYN3tXrVqVpOxdvny5SfaGhYWZnbl49eoVx48fNzvmnJ2defTokcm0mOGKGTKkXTNPz9mr+8ZtsWLFOHfunNn0c+fOUaxYMattJ2PGjPj7+7Nw4UKTINeTO3fukC9fPrPp+fLlS/S01eXLlwGIjIxk1qxZ+Pn54e/vz7p160waK/ny5cPHx4ft27dz/fp1Xrx4wbVr19i+fTslS5Ykb968Vq1TSiR0TMTtiU6pChUqAIZelIULF3LixAkOHTrExIkTyZEjh1W2ER9fX18CAwPNpp8+fZrSpUsnuGzp0qWN47hiCwwMxMXFxfiZ8fX15fnz55w/f95svpj1xDZ79mx++eUX9u7dm+z6pDU9nxqzd/F91s6fP2/1z9rz589ZuHAhAQEBHDx4MF0+a0mVPXt2wsLCzKaHhYWRPXv2BJeNOdOVIUMG6tatS9u2bWnevDkVKlSwOKTB09OT1q1b06ZNG+rWraur8bbFihUzywwwHA9FihRJk226uLhQr149du/ebfH/gTX5+vpy6tQps+mBgYGJZq+vr2+aZG9smTJlomrVqpw5c8Zk+uzZs+ncuTNNmzbFzc0NHx8fZs+ezbVr10wa29am5+zV/bAEd3d3s18kkLRQSY4ePXrg7OzM3LlzrbZOawsPD7c4rilz5sxmH6i4Hj9+DMDKlSupWrUqDRo04MaNG2zdupXQ0FDjUAWlFN27d+fnn39m5syZxuVff/11OnXqZMXapJy7u3uKv2iSKqYRP27cONauXcv8+fMpXLgwAwYMoFixYrRp0ybNfpXmzJnT7LQcwMOHD/Hw8EjxsjHvx/zX0oWIcecD6NSpE5UqVaJUqVJJrkN6kp7ZtJMe+RvT+Bs3bhzr1q1j/vz5eHt7M2DAAIoWLUrbtm1t/v/Y2dnZ4nUNERERxh65+MRkdrVq1Th37hwnTpzAw8ODN998kyxZspgMVbhx4wYPHz7k6dOnuLi4UKJECWrUqMGBAwe4cuWKdSuVAvEdD48ePbLq93FstWvXxs3NjXXr1qXJ+mPTW/bG9fXXX+Pl5WX2XTxq1ChevHjBb7/9ZvzBFBwczHvvvWexTNZi689lQlLcuFVKddc0LeEBr1ZiaQdaGoifUt7e3nz22Wd88cUXSbowy5ZSWu+YfVi+fHnq1asHGMaRRUVFsWnTJpNe4V9//ZWrV6/SokUL8uTJw71799i6dSvLly+na9euaXqaIzWseUzE1PHw4cP4+/sDcOjQIR4/fsz06dN555130rQXM6XHvFIqScsmdT4PDw+mTJnC8OHDuXfvXqLbt4X/Ws9semYvpP0XWHyftSdPnjBt2rQ0/6yltZjP1JUrV4y9gnfv3kUpRbly5ciePbuxwfjvv/+aLHvjxg3q1q1L2bJlddG4hfRv0DRt2pQHDx6k2zGgl+yNq0OHDgwdOhR/f3+zOxx9+umnjBgxgrFjx7Jz505y587N0KFD2bJlCzVq1ODWrVuJlj8l9Jy9qWmlxDswVSnVUyn1j1Lqn9SeRnj06BHu7u5m02MHQmqNHDmSgwcPcvz4cdzc3HBzcyNTpkwopXBzc8PFxcUq20mtzJkz8+zZM7Pp8fXoxhZzpWfcoRzFixcHMB78QUFBBAQE0K5dO95++22KFCnC22+/Tbt27QgODjY7HWIL6XFMxPyy3r9/v8n0ffv2AQmfOkqtkJAQi7/ePTw8Ev0V/vDhw3iXjXk/5r+WeiLizjd27Fju3LnD6tWrcXd3x93d3Tge293dPVm3Qkoreh73lUaSlL3JuUVgfOL7rMXXg5cSiX3W9HDG4OXLlxZ7aOPr0Y3txYsXANy+fdtkeszfCfUIaprGtWvXyJIli9l1ELaQHtkbW+7cualSpQp//fVXutw5Q0/ZG1vjxo1ZsmQJCxcu5OuvvzZbbvr06UyZMoWvv/6a3bt38+uvv1KvXj3y5MnDoEGDEix3aug5exPsuVVKnYjvLcB88Gc0TdPmA/MBSpQokaranTt3ztgAiy2+sT8pUbRoUby8vDh69KjZe0ePHmXJkiWMHz/eKttKjbx581q8DdOdO3cSHQsb0ysb36/DmOkxgevl5WXyfsx9/vTQe3f+/HmL462LFStmciFAasSMM4zvw5mWv1jjG99VqlSpRC8cPH36NC1atDAbqlK6dGlevHhh/MwEBgbi6upK0aJFTfZZzHZjtlOqVCnKlClj8ert+/fv88cffyR6b9y0Zq0AVUo1AGYATsAPmqZNtDDPe8C3QCbgvqZp71pl4+bbSXX2lipVKtU7Jr7PWtzjJrXbANt81pIqLCwsxY38+Dp4YjLXnn58xTfWumjRoly8eNHq22vcuDEZM2Zk7dq1Vl+3JYGBgfj6+ppNL126dKLZGxgYaNXsjVG7dm3WrFnD77//Tq9evcy2W6JECVxdXc3u5BMSEsKFCxfS9MehnrM3sZ7bfEAXoImFV7rcq2THjh2ULVvW5CbKBQsWpEKFCla7SXz//v3p3LmzyWvPnj08fPiQzp07m13VaCulS5fm2rVrJg2Nhw8fcuXKlUQP4BIlSpAxY0bOnj1rMj3m75iLFrJlywZgcjUsYLzILq3GVSVHzDERuwFesGBBypcvb7VjIiAgwOLdJWL+PnnypFW2Y8n69eupUqUKPj4+xmmFCxemevXqrF+/PsFl161bh7OzM23atDFOc3Jyom3btmzZssXYy7Rp0yZevHhhNnarU6dOnDx50ngBYv/+/alVq5bJK+Y2N3Xr1jW59YytWOOiBqWUEzALaAiUBjoopUrHmScHMBtoqmmaL9Am7nqsyObZC7Bz506zz5qnp6fVP2v37t0z+6y98847ABYv8ElvN27cIFeuXGTNmtU4LWvWrOTOnZsbN24kuOytW7d49eqV2YMOYv621FMXQymFt7c3T58+5fnz56mogXXs2rWLMmXKmB0P5cqVY+fOnVbfXtOmTQkODk63O02sW7cu3uxNbMxvfNnbrl27JGVv586dTbIXDLeQW7t2Ldu3b6dz584WG5MxHVKVK1c2me7h4UGxYsUSPT5TQ8/Zm9iY2z+BbJqmHbdQoF2JltoKVq9eTefOnZk9ezbffvstmqbRr18/bt++zapVq4zzeXp6sm3bNmbNmsWsWbOM09966y1y5sxpvGjhzTffNJ7a37x5M2AI17hatmxJREQEhw8fTsvqJUvlypU5cOAAS5cupV69eiil2LJlCzly5DDekxYMv9gmT55M7dq1qVu3LmAI4vfee48dO3bg4uJC0aJFuXHjBtu3b6dChQrG24u98cYbbNmyhdWrV1OnTh3jmNtt27bh7u5u8VdteluzZg2dOnUyOSb69u3L7du3Ta4M9fT0ZMuWLcyePdvk/ogxx0TsOsc9Jl69esW0adOYOHEiX3/9NVu3bsXb25t+/foZb+KeVhYsWMAXX3zBH3/8wciRI9E0jTFjxnDt2jXmzZtnnM/b25vz58/j7+9vHKsYEBDAqlWrmD59OpkyZeLSpUt8+umn+Pj40LlzZ+Oy9+7d49tvv2Xo0KE8fvyYf//9l3bt2lG7dm2T+5Fa+my89957gOEejrFPFXp7e/PWW28BkCtXLqKiomjVqhVguD9wWt2FxEq9B5WB85qmXQRQSq0CmgGxu1E6Ar9pmnY1ertpeWd9m2cvGD5rHTt2ZNasWcyYMQNN0+jTpw+3b99m9erVxvk8PT3ZvHkzc+bMMfuseXh4WPysbdmyBTB81qZOncrEiRMZNWoUW7dupXDhwvTt2zfNP2tJdeHCBYoXL06NGjU4efIkmqYZv0ti975lyZKFxo0bExgYaLz6PSIigtOnT+Pr60tkZCR37twhZ86cxqvrY24v5u3tTcGCBbl16xbPnj3D1dWV4sWLkzNnTrMhG7by66+/0qFDB7777ju+//57NE3jyy+/5M6dO6xZs8Y4X4ECBfjrr7+YN2+eyUXalSpVMjkefH19jcfD1q1bTbZVqlQpihcvzuTJk9OhZgYLFizgyy+/ZO3atYwYMQJN0/D397eYvRcuXGDMmDFm2fvtt98as/ezzz7Dx8fHpCF77949pk+fzrBhw8yyN/btxkqWLMmGDRu4f/8+kydPpmLFiiZlPXToEGAYy71+/XoGDRpEVFQUu3fvJleuXAwePBgXFxfmzJmTZvtLz9mbYONW07SPE3ivYxIKnWrh4eF06dIFPz8/40F+8OBBxo0bZzL+VClFxowZzS526tOnj0nDL6ZnFjB79KHeOTs706NHD9avX8/q1avRNI1ixYrRuHFjk3HBmqYRFRVlduDVqVMHFxcXDh48yN69e3Fzc6NmzZom96t0dXXl888/Z9u2bezevZvHjx/j5uZGqVKlqFu3ri7GH4eHh9OtWzeGDRvGN998g1KKAwcOMGHChCQdE7179zb5lRvzFBww3BUixh9//EFUVBSffPIJLVu2JDQ0lPXr1zNt2rQ0rd+zZ8+oU6cO06ZNY+nSpSil2L59O/379+fp06eJ1u+jjz5i3Lhx+Pv7kyNHDgICAmjYsCHHjh0zmW/48OE8efKEPn36kD9/foKDg2nXrh1//vlnispdq1Yts4eqxHzhde/ePdEb/qeUlU5bFwRin664DrwdZ54SQKboxqUbMEPTtITvWp9CesheMHzWunfvztChQ5k0aVK8nzUw3E4x7rCnL7/8Mt7PWuyzTWvXrkXTNONnLSwsjPXr1yd40/z09OrVK3bu3En58uWpUqUKYBgOduzYMZN78yqlyJAhg9l+CAwMJDIykmLFilGyZEmeP39OUFCQyS3/nj59iqurK+XKlcPZ2ZnIyEgePnzIrl27zMbr2kp4eDgff/wxgwcPZvz48SilOHToEJMmTTI5FR+TTXH3w+eff278AQyGi6Q6dOgAYPao2KZNm/Ly5UuThxWktWfPnlG7dm2mT5/OsmXLjNnbr1+/JGVv9+7dGTduHGPHjjVmb4MGDeLN3r59+xqzt23btibZW6VKFXLmzEnOnDktPuEv9r5t164dX331FR06dOCrr77i0aNH/Pvvv7zzzjsWh1tai56zV6X1eJ/Ujrl1FJMmTbJ1EXRh2LBhti6CLsQdHvJfFRUVlepbXMyfPz/RjOllGKzWM/Zi0eNTAVBKtQHqa5r2SfTfHwKVNU3rHWuemUAloA6QGTgANNI0TZf/M60x5tYRjBo1ytZF0IVx48bZugi6oIdhLnqhaVqq8lfP2av7+9wKIURCkvIDPfaFVvG4DhSK9bcXcNPCPPc1TXsKPFVK7QHKArps3AohRFrSc/bq84alQgiRRFZ6Ss4RoLhSykcp5Qy0B+JeQbIWqKGUyqiUyoLh1Jnt740nhBA2oOfslZ5bIYRds8bQKk3TIpVSXwKbMdyOZpGmaYFKqU+j35+radoZpdQm4AQQheGWNXKOUwjxn6Tn7JXGrRDCrlnrugFN0/4C/oozbW6cvycD6Xf5thBC6JSes1cat0IIu6aHm/wLIcR/jZ6zVxq3Qgi7Zk9PeBJCCEeh5+yVxq0Qwq7pufdACCEclZ6zVxq3Qgi7pufeAyGEcFR6zl5p3Aoh7JqeA1YIIRyVnrNXGrdCCLum51NjQgjhqPScvdK4FULYNT33HgghhKPSc/ZK41YIYdf03HsghBCOSs/ZK41bIYRd03PvgRBCOCo9Z680boUQdk3PASuEEI5Kz9krjVshhF3T86kxIYRwVHrOXmncCiHsmp57D4QQwlHpOXulcSuEsGt6DlghhHBUes7eNG/cnjt3Lq03YReGDx9u6yLowpw5c2xdBF3o2bOnrYvgMPR8asyWgoKCbF0EXRg/fryti6AL33zzja2LoAu9e/e2dREchp6zV3puhRB2Tc+9B0II4aj0nL3SuBVC2DU99x4IIYSj0nP2SuNWCGHX9Nx7IIQQjkrP2SuNWyGEXdNzwAohhKPSc/ZK41YIYdf0fGpMCCEclZ6zVxq3Qgi7pufeAyGEcFR6zl5p3Aoh7Jqeew+EEMJR6Tl7pXErhLBreu49EEIIR6Xn7JXGrRDCruk5YIUQwlHpOXulcSuEsGt6PjUmhBCOSs/ZK41bIYRd03PvgRBCOCo9Z680boUQdk3PASuEEI5Kz9krjVshhF3T86kxIYRwVHrOXmncCiHsmp57D4QQwlHpOXsz2LoAQgiRGlFRUYm+kkIp1UApFayUOq+UGprAfG8ppV4ppVpbrRJCCGFn9Jy96da49fLyYs2aNYSGhhIWFsavv/5KoUKFkrSsi4sL33zzDTdv3uTZs2fs37+fGjVqmM2nlGLo0KFcunSJ8PBwjh8/TsuWLS2u85NPPuHMmTM8f/6coKAgevXqZXE+V1dXRo0axdmzZ3n+/Dm3b99m/fr1ZMqUyWS+Tz/91Li+K1euMGbMGDJmtH7HeP78+Zk+fTqHDh3i8OHDzJgxgwIFCiRp2X79+rFgwQL279/P6dOnad68ebzz5s2bl7Fjx7Jnzx6OHz/Oli1b6N+/v5VqkXoPHz5k3rx59OvXj379+jF37lwePnyY6HLr16/n008/tfj68ssvTeb18/OzON/x48fTqFbJlz9/fr7//nv+/fdfjh07xqxZs5J8PAwYMIDFixdz+PBhzp07F+9nJbbGjRtz7tw59u7dm9qiW42maYm+EqOUcgJmAQ2B0kAHpVTpeOabBGy2cjXSjD1mb4YMGRgxYgQXL17k+fPnnD17lr59+1pcX5cuXfjnn38ICwvj7t27bNmyhXfeeSdJ9UuOfPnyMXXqVPbt28f+/fuZNm0a+fPnT9Kyffr0Ye7cuezZs4cTJ07QtGlTi/O5u7szZMgQ/vrrLw4fPszGjRsZNmwYHh4e1qxKqoSEhLB48WKGDh3KkCFDWLRoESEhIYkut3HjRmNex30NHDjQZN6dO3eyYMEC/ve//9GvXz82btyYVtVJsQIFCjBz5kyOHTvG8ePHk5W9X331FUuWLOHIkSOcP38+ydl7/vx5/v7779QW3Wr0nL3pMiwhc+bM7NixgxcvXtC1a1c0TWPs2LHs3LmTMmXK8OzZswSXX7hwIY0aNWLQoEFcvHiRL774gs2bN1O1alUCAgKM8/n7+zNw4ECGDx/O0aNHad++PWvWrKFx48YmH45PPvmEefPmMWHCBLZt20adOnWYPXs2Sinmzp1rnC9jxoxs3LgRHx8fJkyYwOnTp8mTJw/vv/8+Tk5OvHz5EoChQ4cybtw4pk+fzqZNmyhXrhyjR4+mQIEC9OjRw2r70dXVlcWLFxMREYGfnx+aptGnTx8WL15MixYtCA8PT3D5Tp06ERQUxK5duxJs2Hp6erJixQquX7/O+PHjuX//PgULFsTb29tqdUmNiIgIpk+fTqZMmejWrRsA69atY9q0aYwcORIXF5d4l33nnXfw9fU1W993331HmTJlzOYvXbo0jRs3NpmWL1++1FfCClxdXVm2bBkREREMHjwYTdPo378/y5cvp3HjxokeDx9++CFnzpxh586dSQpXNzc3/Pz8uHv3rrWqYBVWOjVWGTivadpFAKXUKqAZcDrOfL2BX4G3rLHRtGav2Tt79my6deuGv78/hw4dolatWkyZMoVs2bIxbtw443w9evRg/vz5zJkzh6FDh5IlSxYGDBjA1q1bqVq1qtV+iLq6uvLDDz/w8uVLRowYgaZp9O7dm4ULF9K6detEP2sdOnQgODiYPXv2xNuwBfjuu+8oXLgws2fP5uLFixQtWpQvvviC0qVL8+GHH1qlLqkRERHBrFmzyJgxIx07dkQpxV9//cXMmTMZPHhwgtlbtWpVSpUqZba+uXPn8sYbb5hMP3DgAK6urrzxxhvs378/TeqSGrGzd9CgQQD079+fFStW0KhRozTJ3uHDh0v2JiN706Vx26NHD4oUKULJkiW5cOECACdOnODcuXP06tWL6dOnx7tsmTJl6NSpE927d2fJkiUA7N69m8DAQMaMGUOzZs0AyJMnDwMHDmTixIlMnToVgF27dlGsWDEmTpxoDFgnJyfGjRvHsmXLGDFihHE+T09P/P39+eGHH4iMjAQMv64qVKiAr68v169fN5bpt99+M/7bxcUFPz8/li5davz1uW3bNjRN45tvvmH69OmcPh33/1HKtG7dGi8vLxo1asTVq1cBCA4OZuPGjbRt25Yff/wxweUrV66Mpml4e3sn2LgdNWoUd+7coXv37sZ98c8//1ilDtawd+9e7t+/z+jRo8mbNy9g6J363//+x969e6lbt+7/tXfn8TXc+x/HX18hEbuIIggp6RL78lOKtqKWblp1awu9SWspokKtVVc1QXXB7bVUUL21lOK6VVStaW8VtYZGhBC1xB6JkESE+f1xnGlOTjZykjPn+Dwfjzw4k+/M+c7k5J3vfOc738lx3YoVK1r1guzatYu7d+/SqlUrq/JlypTh0Ucfte0O2EiPHj2oWbMmHTt2tPg8bN68mZ49e7Jo0aJc12/atKn+echPwI4ePZqjR49y+fJlnn76aZvsgy3Y6KaG6sCZTK/PAk9lLqCUqg50BfxxkMatI2ZvzZo16devH6GhoXpDdsuWLZQrV47x48czZ84cvacwMDCQ3377jcGDB+v13rZtG1evXqV79+42a9x269aNGjVq0KVLF86cMX1Mjh8/zg8//MDf/vY3Fi9enOv6Tz/9NJqmUbNmzRwbt7Vq1aJJkyZMmjSJ1atXA6bcvXv3LhMmTKB27dqcOnXKJvvzoHbu3MnVq1d5//33qVy5MmDqDJk8eTK//fYb7dq1y3HdChUqUKFCBYtle/bs4e7du/zf/1n+Oo0dO5ZixYpx584dQzZuM2fvn3/+CcDRo0fZsmULvXr14quvvsp1/SZNmqBpGrVq1cpX9o4ZM4ajR49y6dIlWrdubZN9sAUjZ2+RDEvo0qULu3bt0sMV4NSpU+zYsUMPyNzWTU9PZ8WKFfqyO3fusHz5cjp16oSrqysAnTp1ws3NjSVLllisv2TJEho2bEjt2rUB09njI488YlVu8eLFeHp6WlzOGjx4MCtXrrRo2GZVv359ypYta3XZZOPGjRQrVizXRuT98vf3JzIyUm/IAJw7d44DBw7g7++f5/r5OcuqWbMmbdu2ZenSpXrD1mgOHTqEj4+P3rAF8PT0pE6dOha9Sfm1a9cuypUrh5+f1ZUQQ/P39+fgwYMWn4ezZ8+yf//+XBv4Zvdz1t20aVNeffVVPvzwwwepaqHKz6UxpdQApdTeTF8DsmxGZbfpLK9nAmM0TbtTKDtSCBwxe1u0aIGLi0u2meru7s4LL7ygL3N1deX69esW5VJSUrh9+zbFitnuz9tzzz3HoUOH9IYtmLL34MGDuTbozPLzu2Ye6nbz5k2L5cnJyYBp6Ie9/fHHH9SuXVtv2AJUqlQJHx8f/vjjj/ve3p49eyhbtixPPPGExXJb/uwKQ/v27Tl48KDesAXJXqNlb5F8gurVq5ftBz8qKirPBkW9evX0cVxZ13Vzc6Nu3bp6ubS0NGJjY63KAfr7mC9JZ61P1nI1a9bE29ubkydPEh4eTlJSEqmpqWzZsoVGjRrp6925YzrW6enpFtu7desWgNXlloKoW7eu1f4BxMbGUqdOHZu8R5MmTQBT/RcsWMDBgwfZuXMnU6dOpXz58jZ5j4I6f/481atXt1perVo1zp8/f1/bunbtGjExMfof1KwOHTrE0KFDCQ4OZtq0aYYab+vr68vx48etlh8/flz/vbCF4sWLExYWxoIFCywa0kaRn5saNE0L1zSteaav8CybOQtkHohaA4jPUqY5sFwpdQr4GzBHKfVaYe2XLThi9t5Pps6ZM4fnn3+et956i/Lly+Pl5cWsWbO4ffs2CxcuzHX/7kedOnWyzd4TJ07Y7MpObGwse/fuZcCAAfj5+eHu7k79+vUZOHAg//vf/4iLi7PJ+xTEhQsXsh1nXLVqVS5cuHBf20pMTOT48eM0a9Ys2+w1Ml9fX44dO2a1vDCyd/LkySxYsMCiIW0URs7ePBu3SqknlFLtlVJlsizvnNe6Zh4eHtkOOE9ISMhzoHxu65q/b/43MTExX+UAq21mLefl5QWYLgc8+uij9OzZk169elG5cmUiIiL0GzKOHz/OnTt3aNmypcX2zJe4zduzhfLly5OUlGS1PCkpiXLlytnkPcy9oWFhYZw6dYqBAwcyffp0nn32WebPn2+I3oObN29SqlQpq+WlS5fOcwxhVrt370bTNKufH5guy/bs2ZN3332XoKAgihcvzpdffsnu3bsfuO62VBSfB4ABAwbg6upqMSbSSGxxUwOwB/BVSvkopVyBnsDaLO/jo2labU3TagOrgMGapv3Xxruje1izNyYmBiBfmbpo0SIGDBjA7NmzSUxM5Ny5c7z22mt06NAh2xO/B1W+fHmrHmKw/e/akCFDOHXqFMuXL2f37t0sW7aMs2fPMmLECJu9R0GkpKRkm72lSpXKc5xpVnv27EHTNFq0aGGr6hWZnD4PiYmJhZK9c+fOtdk2bcnI2ZvrmFul1LvAECAaWKiUGqZp2vf3vj0F2Jifmt+rXHbbz3M9pVS+1r2fcjnVJzPzZZGUlBReeeUV/Rd37969xMbGMmTIEMaOHcvNmzf56quvCA4O5sCBA2zcuJEmTZowdepUMjIyimSSY1s2OM37/fvvvxMWFgaYGoDJyclMnz6dNm3aGOpO+cweZHD7rl27qFmzJjVq1LD6Xs+ePS1eN2nShGnTpvHf//6Xp556yqq8PRT2PIPe3t4MGjSIwYMHW/WkGYUtjoGmaRlKqWBMd+K6AF9pmhallHrn3veLtGX/MGdvdHQ0mzZtYtKkSZw8eVK/oSwkJASwHOfXpUsXZs+ezbx581i7di3u7u4MGzaMDRs20K5dO71X2BYe9Djej4kTJ9KwYUM++ugj4uLi8PHxYfDgwXz++ecMHTrU0POK3q89e/ZQo0YNvSPJ0RT256FWrVoMHjxYsvcBszevG8r6A800TbuhlKoNrFJK1dY07Z9kP04iW9euXcu2B7NixYp5TiGSkJCQ7V365l4H81l/Tj0R2ZUD09l/5sso5vqZv3/16lUAduzYYXFGevbsWY4ePapfvgfTjWeVKlVi2bJlFCtWjNTUVP7xj38wevTo+75MnpukpKRshwaUK1cu27PIB2Hugdm5c6fFcvOg/ieffNLujdtSpUpl20ObU69CTuLi4rhw4QJvvPFGvsoXK1aMpk2bsmbNmhx/FkXp+vXrVjdoQM69Cg9iwoQJ7Nq1i4MHD1K2bFngr7GBZcuWJT09Xb9cbC+2OoHUNG0DsCHLsmyDVdO0QJu8ac4e2uwFCAoKYunSpfz0k2nWn6SkJEaPHs28efMsMjU8PJxVq1bpDV+ATZs2cfToUUJDQ/N1s05+XL9+vdCzt23btrz44ov0799fvzq0b98+zp49S3h4OM8++ywRERE2ea8H5e7unmP2uru753s7f/75J5cuXaJr1662rF6RyenzYOvs3blzJwcOHJDstVwemJ9t5tW4ddE07ca9DZ5SSj2HKWRrkUvA3hswrA8ajoqKspp+CUxjrPKaSSAqKoquXbvi7u5u0cj08/Pj1q1b+jioqKgoSpYsSZ06dSxunjCP4zK/j/lMvl69ehYBm7XcyZMnSUlJyfHsLPMPNTk5mW7duuHp6UnVqlU5deoUpUqV4tNPP7XpnHQ5ja3Nus8FfQ/I+YzMCI/b8/LyIj4+65Ac01jc/M4zCKZe22LFijnkZTHIeXxXTmOzH0TdunWpUaMG+/fvt/re/v37+frrry2mZrIHZ+rNyuShzV6A+Ph42rVrR7Vq1fDw8ODEiRP6VH3mTK1SpQpVqlRhz549FvW+ffs2kZGRVtNOFcSJEyeyzd5HH32UkydP2uQ9fH19AesxyebXjz76qN0bt9WqVct2bG1OY3FzsmfPHooVK0azZs1sWb0ic/z4cf3nlVlhZO+BAwesvnfgwAEWLVok2ZuLvMbcXlBKNTa/uBe2LwOeQIOcVso8gBhMc5C2bNkSHx8fvUytWrVo3bo1a9euzWkzmNd1dXW16F1zcXGhR48ebNq0Se+u37hxI7du3SIgIMBi/T59+nD48GF9CpWdO3dy+fLlbMtdvXqVHTt2AJCRkcH69etp27atRW9gzZo1efzxx60CFeDKlSv88ccf3Lhxg+HDh3P58mVWrlyZ6/7dj+3bt9OoUSOLS+heXl40adKE7du32+Q9IiMjuXz5stUk6ObXD3JHrK01bNiQuLg4Ll++rC+7cuWKxR/AvGRkZLB37159tov8uHPnDvv27cPDw8PuvbZgmvKocePGFhPyV69enaZNm7J161abvMfw4cMJCAiw+Prll19ISEggICAgzymQioKtnpJjMA9t9mZ2/vx5oqKiSEtLIyQkhOjoaL2Bd+3aNdLS0qxOTkuUKEHjxo05d+5crvt3PyIiImjYsKHFjaxeXl40btzYZg3OK1euANY3ITdoYPpxG2GO03r16vHnn3/qdQXTVc64uLh83zydkZHB/v378fPzo0yZMnmvYEBbt24t9OwNCQnJNXuzzjpiD0bO3rx6bt8ELOaD0jQtA3hTKTUvv28yf/58goOD+f777/UJsENDQzlz5gzz5v21GW9vb06cOMFHH31EaGgoYGpsLV++nJkzZ1KiRAni4uIYNGgQPj4+FiF5+fJlZsyYwbhx40hOTmb//v306NEDf39/iylvMjIymDBhAnPmzOHcuXNs2bIFf39/3nrrLYYOHao/mAFM459+//131q9fz+eff64/rSwxMZFZs2bp5bp3746HhwcxMTFUrFiRrl270qNHD7p168aNGzfye5jytGrVKgICApg1axZffPGFPpH4hQsX+O677/RyXl5ebNy4kblz51oMRG/evDkeHh54enoCpqAyX2LatGkTYGrATZ8+nalTpzJx4kQ2b96Mt7c3w4YNY/fu3ezatctm+/Og2rRpQ0REBHPnzqVLly4opVi7di0eHh4WT0+6evUqEyZM4KWXXuKll16y2Mbhw4e5efNmtnPbgqlnITIykvr161OxYkWuX7/Ozz//zOnTp3n77bcLdf/ya8WKFfTp04e5c+cyY8YMNE0jJCSECxcusHz5cr2cl5cXW7duZfbs2Raf2xYtWlh8HurXr69/HjZuNA3pzG52iG7dupGens7vv/9eiHuXf0buPSiAhzp733nnHdLS0oiLi6Nq1ar8/e9/p02bNrRv317/eaenpzN//nyGDh1KQkIC69atw93dneDgYHx8fCyGKhTU6tWr6dmzJ1988QX/+te/ANPNXxcvXrTowKhWrRrr169n3rx5Fse3WbNmeHh4UKlSJcCUvebe8M2bNwOmBtPQoUOZPHky4eHh+pjbd955h/Pnz9us0VQQrVq14tdff2XhwoW8+OKL+kMcKlasaDH3dUJCAmFhYXTs2JHOnS3vf4yKiiIlJcVqbtvMTp8+TUJCgv6zvnjxop5Ffn5++jR09rJixQr69u3Ll19+aZG958+f59tvv9XLeXl5sW3bNmbNmpVt9pqnVGvQoEG+svf1118nPT3dMDc1Gzl7c23capqW4wSvmqZZn2bnICUlBX9/f2bMmMHixYtRSrF161ZCQkIs5vRTSlG8eHGrOe6CgoKYPHkyYWFhVKhQgcjISDp37mzVXT9+/Hhu3LjBsGHDqFq1KjExMXTv3p1169ZZlJs3bx6apvHee+8xatQoTp8+TXBwsNUdidHR0fj7+zNt2jRWrFjB7du32b59O6+99prFWbSmaQwePJg6deqQkZHBrl27eO6552w++XRqaipBQUGMGTOGjz/+GKUUu3btYurUqVbjoLI7jsHBwRa9HOazQcBiWqDvv/+eu3fv0q9fP7p27UpSUhLr1q3LdcL3ouTm5sbw4cNZuXIlX3/9NZqm8cQTT/DGG29QsmRJvZymaTmePe7cuZPSpUvrvSJZVapUieTkZFavXs3NmzdxdXWldu3aDB06NNvLvPaQmppK3759GT9+PJ999hlg2q/JkydbfB7Mv1dZb3Z49913LW6M69u3r/4UpOwuuRmVkQP2QT3s2evi4sLYsWOpVasWKSkpRERE0LJlS6uhFMOHDycmJoZ+/foRFBREWloaUVFRdOzYUW802kJqair9+vVj9OjRTJkyBaUUu3fv5pNPPrEYspHTcRw8eLBFY65Xr1706tULQL/adPPmTfr06cOgQYMICgrC09OTK1eu8PPPPzN37tz7no2gMLi5uTFkyBDWrFmj9xz6+vrStWtXi6eTmbM3u9/NPXv2UKpUqVxz9H//+5/F1dGDBw/qjb0JEyboJwn2kpqaSp8+fayyNywsLNvszfp5GDZsWI7Za8upxAqbkbNXFXbllFLG3fsiZMvxX45s9uzZ9q6CIQwYkHUe64fT8ePHC3x7ce/evfPMmGXLltl/DrsiJtlrktMJ7MNm2rRp9q6CIQwdOtTeVTCM2NjYAuWikbO3SB6/K4QQhcXIvQdCCOGsjJy90rgVQjg0IwesEEI4KyNnrzRuhRAOzUFnQxBCCIdm5OyVxq0QwqEZufdACCGclZGzVxq3QgiHZuTeAyGEcFZGzl5p3AohHJqRew+EEMJZGTl7pXErhHBoRg5YIYRwVkbOXmncCiEcmpEvjQkhhLMycvZK41YI4dCM3HsghBDOysjZK41bIYRDM3LvgRBCOCsjZ680boUQDs3IvQdCCOGsjJy90rgVQjg0IwesEEI4KyNnrzRuhRAOzciXxoQQwlkZOXulcSuEcGhG7j0QQghnZeTslcatEMKhGTlghRDCWRk5e6VxK4RwaEa+NCaEEM7KyNkrjVshhEMzcu+BEEI4KyNnrzRui0h0dLS9q2AIAQEB9q6CIURERNi7Ck7DyL0Hwv4OHz5s7yoYwoABA+xdBUPYvn27vavgNIycvdK4FUI4NCP3HgghhLMycvZK41YI4dCMHLBCCOGsjJy90rgVQjg0I18aE0IIZ2Xk7JXGrRDCoRm590AIIZyVkbNXGrdCCIdm5N4DIYRwVkbO3mL2roAQQhSEpml5fuWHUqqzUipGKRWrlBqbzfcDlFKH7n39ppRqZPOdEUIIB2Hk7JWeWyGEQ7PFpTGllAswG+gAnAX2KKXWapp2JFOxOOBZTdOuKaVeAMKBpwr85kII4YCMnL3SuBVCODQbXRprAcRqmnYSQCm1HHgV0ANW07TfMpXfBdSwxRsLIYQjMnL2yrAEIYRDs9GlserAmUyvz95blpO3gR8LUG0hhHBoRs5e6bkVQji0/ASoUmoAkPkRTeGapoVnLpLdpnPYVjtMAdvmPqophBBOxcjZK41bIYRDy8+lsXthGp5LkbNAzUyvawDxWQsppRoCC4AXNE27en81FUII52Hk7JVhCUIIh2ajS2N7AF+llI9SyhXoCazNXEAp5Q38B+iradoxm++IEEI4ECNnr/TcCiEcmi1uatA0LUMpFQz8BLgAX2maFqWUeufe978E/gFUAuYopQAyNE1rXuA3F0IIB2Tk7JXGrRDCodnqKTmapm0ANmRZ9mWm//cD+tnkzYQQwsEZOXulcSuEcGhGfgSkEEI4KyNnr9OOua1RowYrV64kMTGRpKQkVq9eTc2aNfNe0cD1cnNz45NPPiE+Pp6UlBR+++032rZta1VOKcXYsWOJi4sjNTWVgwcP8vrrr2e7zX79+hEdHU1aWhpHjx5l4MCBVmUWLVqU7ViaGTNmWJRr3bo1ixYt4vDhw9y+fZu4uLh87VdevLy8CA8P5+jRo8TExLBgwQKqV89tppC/uLm5MWHCBA4cOMCJEydYu3YtTz1lPfezh4cH06dP5/Dhw5w4cYJ169bx7LPPWpVzd3fnww8/ZN++fZw8eZKtW7fStWvXAu/jg7p8+TJTp06lR48edO/enSlTpnDp0qV8rXvp0iVmzJhBUFAQ3bp1Y+DAgSxevJi0tDSLcm+//TavvPKK1dfOnTsLY5fu2927d/P8EkVHstd22Tt16lQiIyO5du0aN2/eJDo6mg8++AB3d3ersm+++SZ79+4lKSmJS5cusWnTJtq0sf2EHtWqVePLL78kKiqKI0eOEB4ejpeXV77WHTNmDEuXLuXQoUOcOXOGN954I9ty/fv356uvvmLv3r2cOXOG4cOH23IXbOLy5ctMmTKFN954g7/97W+EhYXdV/ZOnz6dwMBAXn/9dfr3788333xjlb0AV65cYebMmQQEBPDqq6/y1ltv8fXXX9t4bx6MkbPXKXtu3d3d2bZtG7du3eLvf/87mqYRFhbG9u3badiwISkpKQ5Zr4ULF/LSSy8xatQoTp48yZAhQ/jpp59o1aoVkZGRernQ0FBGjhzJ+PHj2bdvHz179mTlypW8/PLL/PjjX9PD9evXj3nz5jF16lS2bNlC+/btmTNnDkopvvzyS4v3vnTpEl26dLFYdv78eYvX7du3p23btuzduxdN0yhbtuyDHiqdu7s73333Henp6YSEhKBpGqNHj2blypW0b9+e1NTUXNf//PPPad++PaGhoZw+fZrAwECWLVtGly5diIqKAsDV1ZXvvvsODw8PPaB69erFN998Q8+ePS0acQsWLKBZs2Z88sknnDhxghdeeIHZs2dTrFgxVq9eXeD9vR9paWmMHz+eEiVKEBISglKKJUuWMH78eP71r39RsmTJXNedMGECGRkZ9OnTh8qVK3P8+HGWLVtGfHw8Y8aMsSjftGlTevXqZbGsRg1jPMPAyL0HDxvJXttmb7ly5Vi0aBExMTHcunWLp59+mvHjx9O8eXNee+01vVz//v0JDw9n7ty5jB07llKlSjFixAg2b95Mq1atOHjwoE2OY8mSJVmxYgXp6emMGDECTdMYNWoU3333HR06dMgzjwMDAzly5AhbtmzJsWEL0KtXL27cuMGmTZvo27evTepuS2lpabz//vuUKFGCESNGALB48WLGjRvH7Nmz88ze8ePHc+fOHYvsXbp0KfHx8Ywd+9fTZy9evMioUaOoUqUK77zzDhUqVODixYtWf3vtxcjZ65SN2/79+/Poo4/y+OOPc+LECQAOHTrE8ePHGThwoFWPoyPUq2HDhgQEBBAUFKSftf38889ERUXx0Ucf8eqrrwJQuXJlRo4cyccff8znn38OQEREBHXr1uXjjz/WA9bFxYXJkyezePFiPvjgA72cl5cXoaGhLFiwgIyMDP3909PT2b17d677FxoaykcffQSYftFt0WvQu3dvatWqRdu2bTl16hQAR44cYceOHfTt25fw8JxnGPHz8+P1119n+PDhrFixAoCdO3cSERHBqFGjCAwMBODll1/Gz8+Pbt266Q3Z7du3s2XLFj744ANeeuklAFq0aEG7du0ICQnhu+++A0w/g2rVqjF+/HjWrFlTpGeqmzZt4uLFi8ydO1fvOalduzYDBw5k48aNFn/8sjpy5Ajx8fFMmjSJpk2bAqbPWHJyMmvWrCEtLc0ioMuVK8cTTzxRqPvzoKRn1jgke22bvUOGDLGoy7Zt2yhVqhTjxo2jUqVKXL1qmhEpMDCQ3377jcGDB1uUvXr1Kt27d7dZ47Z37954e3vz3HPP6XkcHR3NL7/8Qp8+fZg/f36u6/v5+aFpGrVr1861cdu+fXs0TcPFxcWQjduffvqJCxcuMG/ePD17fXx86N+/Pz/++GOuV/PM2RsaGqpnb6NGjUhOTuY///mPRfbOmjWLSpUqMXXqVIoXNzXXGjRoUMh7l39Gzl6nHJbQpUsXdu3apYcYwKlTp9ixY4ceRI5Wry5dupCenq430gDu3LnD8uXL6dSpE66urgB06tQJNzc3lixZYrH+kiVLaNiwIbVr1wagVatWPPLII1blFi9ejKen5wM1TAvjLK5jx47s379fD1KAM2fOsGfPHjp16pTnuunp6axd+9esInfu3OH777/n2Wef1Y9Zs2bNSE1NtbrM/ssvv9CkSROqVq0KoAfRtm3bLMpFRERQtWpVmjVr9sD7+SB2797N448/bnFJsGrVqjz55JPs2rUr13XNfzxLlSplsbx06dKGPhvPjo2moxE2INlb+NlrbtDevn1bX+bq6sr169ctyqWkpHD79m2KFbPdn/kOHTpkm8d79+6lY8eOea6f399Fo//O5pS9fn5+Nsve8+fPs3//fl555RW9YWs0Rs5ep2zc1qtXjz/++MNqeVRUFH5+fnaokUlB6lWvXj19HFfWdd3c3Khbt65eLi0tjdjYWKtygP4+9erVA7CqT9ZyZo888giXL1/m9u3bxMTEMHr0aJuGZk4ef/xxjh49arU8JiaGxx57LM91z5w5Y3XMYmJicHNz0//Y3Llzx+IPhdmtW7f07ZjLAVZls5YrKqdPn8bb29tqube3N2fOnMlmjb80btwYLy8vvv76a06fPk1qaiqRkZH88MMPdO7c2eqy2u+//063bt3o2rUrI0eONMx4WzB2wD5sJHttn71g6u0tXbo07du3Z8SIESxcuNCiMTtnzhyef/553nrrLcqXL4+XlxezZs3i9u3bLFy4MNf9ux+PPfYYMTExVsuPHTuGr6+vzd7H6P78809q1apltdzb25vTp0/nuq45exctWmSRvWvXruWFF17Qs/fIkSOA6cRl/PjxvPrqq3Tv3p3PP//c6kTGXoycvXmeDiilWgCapml7lFJ+QGfg6L2pGwzJw8ODa9euWS1PSEigYsWKdqiRSUHqldu65u+b/01MTMxXOcBqm1nLARw8eJB9+/YRFRVFyZIl6dq1K1OnTsXX15f+/fvnWu+CqlChAklJSVbLExMTKV++fJ7rZncszMsqVKgAwIkTJyhXrhx169a1+MNk7ok1/2zMvT5NmzZl+/bternmzZtbbK+o3LhxgzJlylgtL1u2LDdu3Mh1XVdXV6ZNm8bUqVMtLn127NiRd955x6JsixYt8PX1pUqVKiQmJrJu3TqmTJnCiBEjaNeunW12pgCMfGmsICR7bcdRsxesG+b//ve/GTBggEWZRYsWAaZGrrkxe/78eTp06MDx48dz3b/7UZA8diYFzd5PP/2UKVOmMGjQIH15p06dLF6be+hnzpyJv78/3bt3Jz4+nn//+9+cPn2aGTNmFEkHU26MnL25Nm6VUhOBF4DiSqnNwFNABDBWKdVE07TJhV/FB5PdGcO9yX/t6kHrpZTK17r3Uy6n+mT1z3/+0+L1jz/+yI0bNxg+fDjTpk2z6qmwtcI+ZmvWrOG9997jn//8J++99x6XLl0iICCAli1bAn/9Av/8888cO3aM0NBQhg0bRmxsLC+++KJ+WdMeZ6nZHYf81CM9PZ1PPvmEpKQkRowYQeXKlTl27BjLly/HxcXFYuxe1ru4W7ZsyciRI/nmm28M0bh1xp5ZyV7bc8TsBYiNjaV58+aULl2ap59+mnHjxlG8eHH69Omjl+nSpQuzZ89m3rx5rF27Fnd3d4YNG8aGDRto166d3itsC0b9+Ra1gmTvxx9/TGJiIu+99x6PPPIIMTExfPvtt7i4uOidDeZtNWjQQM/jRo0aUbp0aaZNm8b+/fv1jhV7MXL25tXs/xvQGngGGAK8pmnaR0AnoEch1+2BXbt2zersF0w9cNmdgReVgtQrISEhx3XN3zf/m11PRHblwLqXwPza/P2cfPvttwCF/suVlJSUbY9o+fLls+1ByCwxMTHbY2HuYTD3sly/fp1+/frh4eHBtm3b+OOPP+jZs6d+U8jFixcB07CE/v37k5qayg8//EB0dDRjxoxh6tSpFuWKSpkyZUhOTrZanlOvQmabN2/m8OHDTJw4kXbt2lG/fn1ef/113n77bX788cdcp3FzcXGhTZs2XLlyJc/PSVEw8nQ0BSDZa0OOnL23bt1i3759/PLLL3z88ce8++67BAQEWExpGB4ezqpVqwgJCWHbtm2sX7+el156ieTkZEJDQ3Pdv/tRkDx2JgXJ3k2bNnH48GEmTZqEv78/9evXp1u3bvTr148NGzZw8uRJwHQTL0CTJk0s1je/zjx+3F6MnL15NW4zNE27o2laCnBC07TrAJqmpQI51lopNUAptVcptdeGdc23qKgofVxTZn5+fvo4FnsoSL2ioqLw8fGxmt/Qz8+PW7du6b2n5qEDderUsSoHf43jMZ/JZ61P1nI5ud/ehwcVExOT7VjWxx57jGPHcn/EdExMDDVr1rQ6Zo899hi3bt2yuCni999/p1WrVrRu3ZpnnnmGNm3akJGRQWpqKocPH9bLHT9+nA4dOtCiRQuee+45mjdvrs9tuGfPngLs6f3LaXzXmTNn8py/89SpU5QpU4Zq1apZLDePY85rzK75526EHhsjj/sqAMleG3Km7N271/SjNY/1rVKlClWqVLHKn9u3bxMZGcmTTz6Z6/bux7Fjx7K918HX19emwx+MLrfsze4+iMzym73m7eSUsZK9ucurcZuulDLf0qffCq6UKk8uAatpWrimac3zevZvYVm7di0tW7bEx8dHX1arVi1at25tcee8I9Vr7dq1uLq6Wkyf4uLiQo8ePdi0aRPp6ekAbNy4kVu3bhEQEGCxfp8+fTh8+LDeoNu5cyeXL1/OttzVq1fZsWNHrvXp3bs3d+/eLfQG3aZNm2jatKlFYNSoUYP/+7//Y9OmTXmu6+rqyssvv6wvc3FxoUuXLvzyyy/6McssLi6O2NhY3N3d6d27N6tWrcp2DsyzZ8/qjeugoCAiIiL4888/H3Q3H0iLFi2IiYnhwoUL+rKLFy8SHR2d7YMqMqtYsSI3btwgPj7eYrn5ZpFKlSrluO6dO3fYsWMHlStXtus4SjMjB2wBSPYapF5Gy17zw2XMPXfXrl0jLS2NFi1aWJQrUaIEjRs35ty5c7lu735s3rw52zxu3rw5mzdvttn7GN1TTz3F0aNHLeabvXjxIkeOHLFZ9j7xxBNUrFiRffv2WZQzv87rhuqiYOTszeuGsmc0TbsFoGla5kAtAfy90GpVQPPnzyc4OJjvv/+eDz74AE3TCA0N5cyZM8ybN8/w9fL29ubEiRN89NFH+iWlyMhIli9fzsyZMylRogRxcXEMGjQIHx8fi5C8fPkyM2bMYNy4cSQnJ7N//3569OiBv7+/xZQ3GRkZTJgwgTlz5nDu3Dm2bNmCv78/b731FkOHDtVnBPD29mbx4sUsX76c2NhY3Nzc6Nq1K4GBgcybN0+/hALg6empB6+3tzelSpWiW7dugKk3Ijo6+r6P2dKlSwkKCmLRokV88skn+qTh8fHxLF68WC9XvXp1du7cyYwZM/Q5K6Oiovj++++ZNGkSJUqU4PTp07z55pvUrFmT4OBgi/cZN24chw4dIiEhAR8fHwYNGkRGRoY+5MAsODiYc+fOceHCBapXr05gYCDVq1e3yzRHnTp1Yv369YSFhdGnTx/9IQ6enp507txZL3fp0iX69+9Pz5499QcxtG/fnv/+979MmjSJ7t27U7lyZWJjY1m+fDl169bVe3t+/vlndu/eTfPmzfH09CQxMZH169cTGxvLqFGjinyfs+Ogww7yItlrh3oZKXsbNGjAZ599xsqVKzl58iRubm4888wz+lha85RT6enpzJ8/n6FDh5KQkMC6detwd3cnODgYHx8fQkJCbHYcly1bRmBgIAsXLuTTTz9F0zRGjhxJfHy8xdRm1atX59dff2XmzJkW92y0bNkSDw8PKleuDJjmEL558yYAGzb8dZ9kw4YNqVGjhn7DlK+vLy+++CJgmooxuyd5FaXOnTuzbt06QkND6du3r0X2vvDCC3q5S5cu8fbbb9OrVy969+4NwPPPP8+aNWuYOHEiPXr00LP322+/pW7dunoPvouLC4GBgcyYMYNZs2bx9NNPEx8fzzfffEODBg1o1KiRXfY9MyNnb66NW3O4ZrP8CnClUGpkAykpKfj7+zNjxgwWL16MUoqtW7cSEhKi/yIZuV5KKYoXL251J2RQUBCTJ08mLCyMChUqEBkZSefOnTlw4IBFufHjx3Pjxg2GDRtG1apViYmJoXv37qxbt86i3Lx589A0jffee49Ro0Zx+vRpgoODmTt3rl4mOTmZhIQExowZQ5UqVdA0jejoaN59913mzJljsb169eqxatUqi2Xm1x9++CGTJk2672OWmppK9+7d+fDDD/niiy9QSvHrr7/yj3/8w6JHNadjNnz4cMaMGcPo0aMpV64cR44cISAgwGKoAZgmYJ80aRKenp5cuXKFjRs38tlnn1nd/VyqVCn9WFy/fp3t27czYMAAq7PwolCyZEnCwsJYsGAB06dPB0x/FPr3729xCVXTNO7evWtxFl2lShU+++wzli1bxpIlS7h+/Tqenp506tSJHj166MexSpUqJCUlsWjRIpKTk3Fzc8PX19fi4Q/25qA9s7mS7LVPvYyUvRcvXuTKlSu8//77VK1alZSUFE6ePMnIkSNZsGCBxfaGDx9OTEwM/fr1IygoiLS0NKKioujYsaNNe1RTU1Pp0aMHEydOZObMmSil2LFjBx9++GG+8njEiBG0atVKfx0YGKg/TCfzUKrAwECLnnLzI7/BNE/w2bNnbbZPD6JkyZJMmTKF+fPn6/dmNGrUiAEDBuQre6dPn87SpUtZvHixnr2dO3e2yF4wNYSLFSvGqlWr2Lx5M2XLlqVdu3YEBgYaZliCUanCrpxSyrh7L4pc1nFGD6uIiAh7V8EQHnvssQIndPXq1fPMmHPnztn/L0ERk+wVmRnlcdn2lnkax4dd3bp1C5SLRs5eYz72Qggh8snIl8aEEMJZGTl7pXErhHBoRr40JoQQzsrI2SuNWyGEQzNy74EQQjgrI2evNG6FEA7NyL0HQgjhrIycvdK4FUI4NCMHrBBCOCsjZ680boUQDs3Il8aEEMJZGTl7pXErhHBoRu49EEIIZ2Xk7JXGrRDCoRm590AIIZyVkbNXGrdCCIdm5N4DIYRwVkbOXmncCiEcmpEDVgghnJWRs1cat0IIh2bkS2NCCOGsjJy90rgVQjg0I/ceCCGEszJy9krjVgjh0IwcsEII4ayMnL3SuBVCODQjXxoTQghnZeTsLWbvCgghREFompbnV34opTorpWKUUrFKqbHZfF8ppb649/1DSqmmNt8ZIYRwEEbOXum5FUI4NFv0HiilXIDZQAfgLLBHKbVW07QjmYq9APje+3oKmHvvXyGEeOgYOXul51YI4dBs1HvQAojVNO2kpmnpwHLg1SxlXgW+0Ux2ARWUUtVsuzdCCOEYjJy90rgVQjg0GwVsdeBMptdn7y273zJCCPFQMHL2FvqwBE3TVGG/R16UUgM0TQu3dz3sTY6DiRwHE2c5Dnfv3s0zY5RSA4ABmRaFZ9n37LaRNZnzU8YwJHuNQ46DiRyHvzjDsTBy9j4sPbcD8i7yUJDjYCLHweShOQ6apoVrmtY801fWPypngZqZXtcA4h+gjLD00HzG8iDHwUSOw18eimNhr+x9WBq3QgiRmz2Ar1LKRynlCvQE1mYpsxZ4896duy2BJE3Tzhd1RYUQwokUSvbKbAlCiIeepmkZSqlg4CfABfhK07QopdQ7977/JbABeBGIBVKAIHvVVwghnEFhZe/D0rh16HEtNiTHwUSOg4kch0w0TduAKUQzL/sy0/81YEhR18vByWfMRI6DiRyHv8ixuKcwslcZ+fFpQgghhBBC3A8ZcyuEEEIIIZyG0zdu83qs28NAKfWVUuqSUuoPe9fFnpRSNZVS25VS0UqpKKXUMHvXyR6UUiWVUr8rpSLvHYdJ9q6TcD6SvZK9ZpK9JpK9RcephyXce6zbMTI91g3oleWxbk5PKfUMcAPTEz7q27s+9nLviSbVNE3br5QqC+wDXnsIPw8KKK1p2g2lVAngV2DYvSe/CFFgkr0mkr0mkr0mkr1Fx9l7bvPzWDenp2naL0CCvethb5qmndc0bf+9/ycD0TyET5i69wjDG/delrj35bxnucIeJHuR7DWT7DWR7C06zt64lcdlimwppWoDTYDddq6KXSilXJRSB4FLwGZN0x7K4yAKjWSvyJZkr2RvUXD2xq1DPS5TFA2lVBlgNRCiadp1e9fHHjRNu6NpWmNMT3ppoZR6aC+ZikIh2SusSPZK9hYVZ2/cyuMyhYV745xWA0s1TfuPvetjb5qmJQIRQGf71kQ4GcleYUGy15Jkb+Fy9sZtfh7rJh4S9wbzLwSiNU2bbu/62ItSqrJSqsK9/7sDzwNH7Vop4Wwke4VOstdEsrfoOHXjVtO0DMD8WLdo4DtN06LsW6uip5T6FtgJPK6UOquUetvedbKT1kBfwF8pdfDe14v2rpQdVAO2K6UOYWqEbNY0bZ2d6ySciGSviWSvTrLXRLK3iDj1VGBCCCGEEOLh4tQ9t0IIIYQQ4uEijVshhBBCCOE0pHErhBBCCCGchjRuhRBCCCGE05DGrRBCCCGEcBrSuBVCCCGEEE5DGrdCCCGEEMJpSONWCCGEEEI4jf8H2bGtOpPNH8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "c_lst = [1e-1, 1e-2, 1e-3]\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train — C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val — C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-2)).fit(features_train, y_labeled_train)\n",
    "\n",
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
