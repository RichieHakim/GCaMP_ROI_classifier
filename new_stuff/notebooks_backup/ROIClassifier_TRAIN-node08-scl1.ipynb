{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(_[0], _[1].requires_grad) for _ in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "base_dir = '/n/data1/hms/neurobio/sabatini/josh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_SYT = data_labeled['SYTmasks']\n",
    "# labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "# non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "# labels_SYT = labels_SYT[non_nan]\n",
    "# masks_SYT = masks_SYT[non_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjEklEQVR4nO2de5xlVXXnv+veuvWuflTTDU13A4pIRGdE0kF8RUZGgxpHjUFARzFB0UQzIaNGwsSIGSeDjkKM+sGgoqigovh+jQQffBwRbQgiBBU0Df1+VnXXu+reu+aPszu5XZ61qupW1a2Ss76fT33q3r3vPnudfc4659z9u2ttUVWCIHjkU1pqA4IgaA3h7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFoTDOLiIfFJG3zvKz3xWRVxt1IiIfFZEBEfnRwlo5d0Tk5SLyraW2Y7kiIioij1mivi8WkT9dir7zeEQ6u4i8SkS+31imqq9T1f+5AJt/OvBsYKOqnjmfDXkXldmiqjeo6nNm2d+vjUuRSeOvIvLEaeVfTOVnp/dXiMgnG+pVREZEZFhEdojIVSJSnraNNwNvB94oIr923olIv4h8IW3nIRF5mWPnRSJyp4gcFpHtIvIuEWmb6/4+Ip19kTkR2KqqI0ttSDMHfLFZjjbNwC+AVx55IyJrgLOAfTO0e6Kq9gLnAC8DXtOwjYuAPwF+F3gG8Ici8vpp7T8ATALHAi8HrhGRxxt9dQOXAscAT059vmkW+3Y0qrqkf8BbgB3AEPBz4JxUfgXwOeAzqe6uNMBH2l0G/DLV/Qvw4lT+OGAcqAHDwGAq/xjwjvR6NfBVsgM6kF5vbNj2d4FX59h68bRtvz2VvwZ4EDgIfBk4vqHNU4EfA4fS/6em8v+VtjOetvX+VK7AfwN+BewH/g9QSnWvAv4fcHXq6x2p7PsN/SnwOuCBtG8fAMQZl+el8RtKx+FNzrF6DXB/w5ifkcq3puN4DzABtAH/BbgPGEzj+biG7WwF/iptYwD4KNCZ6s4GtgOXp/3fCry8oW0H8G7gYWAP8EGgq6H+zcAuYCfwx2k8HmPsz3eBv0n9lVPZG4BrUtnZDefiJ6eN8WMa3n+24fg9P+3Xpob6dcA/A+el9z1kjv7Yhs98Arhylj7z34GvzNnXltjRTwW2kZwDOAk4uWGAp4A/BCpkV7J/BSqp/jzgeLKnk/OBEWB9g1N8f1pfH+PfnX0N8BKyK2ZfOlhfnMnZ87YNPCudlGekE/F9wG2prj+dzK8gc4AL0/s1Vj/pRPpOansC2Z3n1Q19V4E/S9vryrFHyS5eq1L7fcC5zrjsAp7RcBE8w9jv88guBr9DdvF4DHBig/PeDWxKNj02HY9np2P3l2QXw/aGz9+bPt9PdgE7cmzOTvt4VRrPZ6ZtnZrq/57sgtqfjt1XgP+d6s4luwA8gcyhbmRmZ3818C3guansR8BTmKWzA6cBu4GL53DePwkYm1b2JmbpwMAXmeWFofFvqR/ja2QH9DQRqajqVlX9ZUP9nar6OVWdIjv4nWSPWKjqZ1V1p6rWVfUzZHeyWX2HVtUDqnqzqo6q6hDZXfaZTe7Dy4HrVPUuVZ0gu2M9RUROIrvKP6Cqn1DVqqp+CvgZ8IIZtvlOVT2oqg+TndwXNtTtVNX3pe2NGe2vVNXB1P47wOlOX1Nk479CVQdU9S7jc68G3qWqP9aMB1X1oYb6f1DVbcmm84Gvqeot6di9m+wi8NSGz78/ff4g2fg37iPAW1V1QlW/B3wNeKmICNnTxV+k8RkC/g64ILV5KfBRVb1Xs69ZVzj73cjHgVeKyKnAKlW9fRZt7hKRAbKLzYfJnk5mSy/Zk14jh8guXi4i8kfAZrIxnRNL6uyq+iDZd5ErgL0i8mkROb7hI9saPlsnu9oeDyAirxSRu0VkUEQGya7mx8ymXxHpFpF/TBMjh4HbgFXTJ1lmyfHAv530qjoMHAA2TK9LPJTqPLY1vH4obSevzmJ3w+tRspPL4iVkj/IPicj3ROQpxuc2kX1tsmi0a/qY1FP9BuPz0/dxQI+eEzlSv5bsaezOhuP+zVR+pN/p250Nnyd7Qvszssfp2XCGqq5W1ZNV9a/TPs6WYWDFtLIVZF+PTETkRcCVZE8h++fQH7AMJuhU9UZVfTrZxJcC72yo3nTkhYiUgI3AThE5EfgQ2ferNaq6iuyxUI5sdoZu30j2FeLJqrqCbCKFhvZzYWey/YidPWRfE3ZMr0uckOo8Ozc1vD4hbecI8wlT/LW26U79QrLvlV8EbjLabgNOnuW2p4+JkO3TjobPePu4Oo3j9Pr9wBjweFVdlf5WajZRBtlXkunbnRFVHQW+QTapNltnnw+/ANpE5JSGsieSzXHkIiLnkp3zL1DVnzbT6ZI6u4icKiLPEpEOssmjMbJH+yP8toj8QZrhvZRs8ueHZN/HlDRjmh5tntDQbg+wUUTaja77Ul+DItIPvG0eu3Ej8Ecicnraj78D7lDVrcDXgceKyMtEpE1Ezif7jvfVBjsfnbPNN4vIahHZBPw52STlQnDUuIhIe9LpV6bH7cMcPf6NfBh4k4j8dvqtwWPSRTePm4Dni8g5IlIhu7hOAD9o+MzrRWRjGv/L+fV9fHuy7xnA7wOfTXfPDwFXi8i6tA8bROT3Gvp9lYicJiLdzO24Xg48Mx23RSU9tXwe+FsR6RGRpwEvxLjQiMizgBuAl6hq07/tWOo7ewfZY8l+skfPdWSDfoQvkX3/OzLJ9QeqOqWq/wK8B7id7AT+D2STPEf4NtlVcreI5D3u/D3Zd8j9ZBePbza7A6p6K/BW4GayO8vJpO+QqnqA7ER9I9mj/V8Cv9/wCPZeMllmQET+Ydp+30k26fU14CPN2jeNvHF5BbA1fZ15HfBf8xqq6mfJvlvfSPa4+UWySbK8z/48bed9ZGP8ArI70mTDx24kmxj7Vfp7R0PdbrJjvpPsJH+dqv4s1b2FbLLvh8nmfyJ7SkNVv0F2bL+dPvPtGcaj0eadqtrK3yD8Kdk5uBf4FPAnqnofgIickDT8I08mbwVWAl9P5cMi8o25dihpdm/ZISJXkM145p58j1RERIFT0nzGIxIR2UqmMPxTTt3ZZDPfG1ts1iOepb6zB0HQIsLZg6AgLNvH+CAIFpa4swdBQWhp0EK7dGgnPTN/cJlSX51vuzqXTHF+alEaaC6WprrOHkNt4pcClT22HVPHOcfLeSi09rtt35LHDy07rOPZzLGcOnSQ6thIbst5OXsS+t8LlIEPq+qV3uc76eHJcs58ulxShp9zVm55tcM+KpVR29t7br6jKTv2nv9Us65emfv2jrv6B2bdzovsvsRS5IG2kfwrwdoPzuaXqMVizwX5Y6xNeOeDN1xl1jX9GJ9+WvoB4LlkPxS5UEROa3Z7QRAsLvP5zn4m8KCq/ir9WOLTZL8CCoJgGTIfZ9/A0UEH28kJ8BCRS0Rki4hsmWJiHt0FQTAf5uPseV9U8wItrlXVzaq6uULHPLoLgmA+zMfZt3N0hNFGjo5cCoJgGTGf2fgfA6eIyKPIQhcvIMvF9YilVDW0Jmc2vjy58D9aWvd+e/Z8x1vyZ3Y9CXD3X9gz7p6sWLNiCoHKcH75jsvsvjZcae/XQjN0fr6yAv4+j66zK8WTIh3lwgqsLo/bG1x7Tb6q8ZCTGrFpZ1fVqoi8Afi/ZNLbdUeidoIgWH7MS2dX1a+TxWwHQbDMiZ/LBkFBCGcPgoIQzh4EBSGcPQgKwm/aUj1LSmkqXwqRuqO5LEK6gOHznmzWlar55VNORvKylX0eP/Kq2mvv3Gg5v6ErQTXJ8EttGc06Np5MNrTRvgeWpux23Xvmkk363+n79A+bajdX4s4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBB+o2fjD19oz8LW25zgFGNWHWDgsfb1b/Uv8mdbR4+127RN2H3tvtQOCvFmdgdPnfs1utpp21FzIo/L4/Y4ekJDrSu/tjSZWzwj3ox73VmOc+y4/Epvny1FA6BntzPj7gxIfRl4WtzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFIRlIAjMzOGX5csutUoT6+MAtXannVN18LT8yvZDdptqZ3N9jffb1+F6m63xTPXNPfLGC05xl69ygkJqnfnl9W7bvqELbHltzBkPqy+w88m58tqu5gJa1JEAS84YW+f3ihsXNkAm7uxBUBDC2YOgIISzB0FBCGcPgoIQzh4EBSGcPQgKQkult+q6HnPh+c4BW+7QkqFRNae8uXnVPBlqcnW+bOQtgzSxyu6s3mHLUN07HCMdda1tLL9dtc8eX5lybHTkpLIzVvXu/P7Kw/b9ZeQ4245ql91X+2G7bqrXqrDbHD7RtrHvYe88tbfpRWGay4otMPNydhHZCgwBNaCqqpsXwqggCBaehbiz/ydV3b8A2wmCYBGJ7+xBUBDm6+wKfEtE7hSRS/I+ICKXiMgWEdlSHbOXkw2CYHGZ72P801R1p4isA24RkZ+p6m2NH1DVa4FrAbqP3dSamYggCH6Ned3ZVXVn+r8X+AJw5kIYFQTBwtP0nV1EeoCSqg6l188B/tZrU2+DsWPzb+6TK+zrTu/2/Db1itOZ9wzh1PXstCsnV+eXV1fZGlTloK1d1St2XyPOQ1D7gD1WVSMizpPXPMlIPJmy7m0z3w6vr+GTbFmrNOH05chaGJvUbruJJ+l6EpqXVNJLcNlmJPW0ouGguYi4+TzGHwt8QbKzoQ24UVW/OY/tBUGwiDTt7Kr6K+CJC2hLEASLSEhvQVAQwtmDoCCEswdBQQhnD4KC0PqEk4ai5CVKPHxyfnnHAS+SyDah5Kz1Zkk1AJ1786+NI45kVF1p13Vvs2W5sXXNJT2sGWu6edF8XqJETyrzJMzSeH7DWo+X3dKuqvfYnVXXOoZM5NvRvt/e6VK1yXBKBy070qEY9i/wT9Dizh4EBSGcPQgKQjh7EBSEcPYgKAjh7EFQEFo6G1+agu5d+bOSE/12u6qxZJAVVANQGbZnP9sP2XXjaxw7jBnhyqA9s1vtsWfVp5wZ5pITuDLZ78zUG5usrbTlCRl1gnXW2O3qziy4DOZHKZVX2snfamPODPmQfarWnX2zZvgn19qqQNc2py8n+MpbKqs8YY/V+Jp8I1c8vLDT8XFnD4KCEM4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBBaHggjmi8nWMsWgZ3rzJLkAKZ6nboVZpWbF86qUyPvG4A4QRWTa5ygEC8vXM0Jqqjk6z/i2KhdtmbU3jNpt3OUobW/NZBb3tc+YbZ5cNc6s67m3ZasQBKgfV++nNe92x7DtjFnrBw7Bk+167Rsb7Nrb74tvTfZeebGX5Cf21W/d7vZJu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkJLpTepQ8VYyLU06cgdhpWjleaWNPJkkMqY3bBtLL+81m73NbnalrVqnXZdpc+WvGpVZ6msvvHc8v5uw3hg92CfWdfTZUtl45N2CNiartHc8n2jPWab2oSTDM+RG8uH7NPYUuW8KMth20Rqvc4SVc654+W1q3pLUVl2tOdvT0tOXsaZNioi14nIXhG5t6GsX0RuEZEH0n9jFbQgCJYLs3mM/xhw7rSyy4BbVfUU4Nb0PgiCZcyMzp7WWz84rfiFwPXp9fXAixbWrCAIFppmJ+iOVdVdAOm/+TtHEblERLaIyJbquPGFPQiCRWfRZ+NV9VpV3ayqm9s6nZmPIAgWlWadfY+IrAdI//cunElBECwGzUpvXwYuAq5M/780X0NqXbZkUDes7Jg+k9DYxkkMOHKCF9XkLOXkSCtNYUTzAdTrdl89hrwGMDrakVve5uyXqm3H2IStK5ZK9jgeGMvXkzy5rtzpJLd05MaaE8WoJUPOcyLltN2uKw870uyII695yUVtldWmiRWqZiO9fQq4HThVRLaLyMVkTv5sEXkAeHZ6HwTBMmbGO7uqXmhUnbPAtgRBsIjEz2WDoCCEswdBQQhnD4KCEM4eBAWhpVFvWoLJvnzNwJPKrAg2N7LN2bP2Qbvh+Hp7LbKqIcnIpBNpNNHc9VQcaWh0pNOs6+7Jl+W62u39am+zE1/WHVmup93WjDrK+TLa8Hi+NAjQv9L+heWh4S6zbtKJiKsbkq44a+m1HbaPWXnC0bycKk+Ws9bnm3j+75hNSlNGIycLaNzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFITWrvWmtmQgdlAW4/1Gcj0nP2HJVppoy8+FCEDlgD0k9Y5822u9tnRVc9ZRkw67nThRak5OQR69Oj8UcLxm79eJvXb44L7xXrszh72j+UksH792t9nm4ISdefGwIzeW252knlZkYbcT3ViydWAV+/5Y73Si5Zy1DHu3GX05B7rrSz/KLS+pfXLHnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgILR0Nr7eAUMnGZXeZcf4cb/Yk9nUnSWZvAAaz46SFTxx2B7G2go7r1qpzVn+qWLv3PGrDpt13W35wSkn9+4z23SUbBs3dQ6YdQNT9uz5aSvyZ91/MWxmHWfPkL0MlZfvrqvbXqKq1pF/QKcmnWPmBdYYikxWaVeJPcSMbMjvb2ydbeOGr9jbs4g7exAUhHD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQ8kAYUy5zZAsLL3gGJ3davWLLJ9U1dgSNtOW303EnIscJWimX7R3w6rrabBtXtY/llpecnHbPX3m3WXdKJX97AAccieoTA2fllrc5B+3k/v1m3e4Re42nwVE7P13VWDaqr9fer8lOe3xH9tqLk7YfsM+DkjNWNUPO0za7zfa/empu+dR1P7RtMGsSInKdiOwVkXsbyq4QkR0icnf6e95M2wmCYGmZzWP8x4Bzc8qvVtXT09/XF9asIAgWmhmdXVVvA5z1UoMg+E1gPhN0bxCRe9Jj/mrrQyJyiYhsEZEttRE7L3gQBItLs85+DXAycDqwC3iP9UFVvVZVN6vq5nKPPbkRBMHi0pSzq+oeVa2pah34EHDmwpoVBMFC05T0JiLrVXVXevti4F7v80coTUHPjvy68bWONGEsu1TtseUkLTt1TgQVhlSTtTNkI0fW8vLMdXbYEs/KrvxlnAB62+wor4OT+ZFox/cNmm2OL9t5y9aV7Rx0HWLLVyd0HMgtf3is32wzXrNzv3nS4dSULXlNHc5fbmrgkL0MFU5OO2upppnq6oZsCyCGLFd3zuG6cVi8vIwzOruIfAo4GzhGRLYDbwPOFpHTyXZvK/DambYTBMHSMqOzq+qFOcUfWQRbgiBYROLnskFQEMLZg6AghLMHQUEIZw+CgtDahJNtMHZsvsxQ7XakMkO2MBNAAm0H7TovWq5uqz9MnJwvh7X32hJam5NUsla3r7VlZ/knbyknS77aP2VLaA9V7YiyVaVhs263k/BzXPPt8JJbevR32vLgvpK9bz3H5LebGLcPdHXIkQDHnOWfnCSnpfw8oIB9Poq1dJWHc27HnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgIISzB0FBaG3CScFMwNh/n92sVjGighyZzItEqzuJ/CbMNBwgA/naSm2PHUE12WNrIdpty1C9nXZkm6qdF6CjnL/Nat0Oh/rK4Olm3Q8qdsKRzpItOd4/sj63fKzJyLYHDxxj1lUq9jiWjW1W2+z7XK3LuQc6x6x20D4P2obtbZpSsBNFVzakPE9Wjjt7EBSEcPYgKAjh7EFQEMLZg6AghLMHQUFo6Wx8eRJ6H86fYqx7lhiXpHq7Pas+udLenJXTDkAdO0rj+f15eb/cwAQnSObwaKdd53R3xvHbc8t3j/eZbR7bu9es2zJ4glm3ttMOkjk0lW//o3ryc9MB7J+wA1rq/faxbneCa/aM5u/3oQFb0dBR+4CWh526McfGIbOKmjGJ7/qElwvPIO7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICsJsVoTZBHwcOI5MSLpWVd8rIv3AZ4CTyFaFeamqDnjbUrFlBi81WbXTCIRxrO9wFpkePc6uK03a8km9I1/vcKW8ilPnLFs0NulIPJ128rcHB+2AEYu+ih1088uD9vb2dtpy3sBIV275fdiDv6rHXk5qz0E7T54XQHP6pnwpsm7kQgTY/dAas65sr8rl1qmTTk6Mc985LIhxCjhDMas7exV4o6o+DjgLeL2InAZcBtyqqqcAt6b3QRAsU2Z0dlXdpap3pddDwP3ABuCFwPXpY9cDL1okG4MgWADm9J1dRE4CngTcARx7ZCXX9H/dglsXBMGCMWtnF5Fe4GbgUlX1frE5vd0lIrJFRLZUx+xECEEQLC6zcnYRqZA5+g2q+vlUvEdE1qf69UDuD6xV9VpV3ayqm9u67N8jB0GwuMzo7CIiZEs036+qVzVUfRm4KL2+CPjSwpsXBMFCMZuot6cBrwB+KiJ3p7LLgSuBm0TkYuBh4LyZNiR1aDPUlakeW5uwItHaDzUZvVZzdBBHulDj0qgVJ7TNQUZseU3LjiGO9GbhLTV1z778fHEA7W12X23OElVTk/kHoKvLXgdpzwE7VFGd4WjvtnPh7RvLj6Q7cMh+yhRnfCdXOUuOOXntvKWcLBnNO7+t89TaFszC2VX1+5hpIjlnpvZBECwP4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAWh5cs/WfKV1GyZoW3UaOMoXo7SRJvzQ76aneeR7h35osTIRltCq/XZWkjlsG3kVK89HrUxu7/BSn60WXenLXmNjucvawWwfrX9Y0lrqSmAqfH8U6s6YZ9ylS5bQvMYG7Xt37o//1fcbb12XzLgLFE15ci2DlMr7ONpJaocOsnenlTz29TsoYg7exAUhXD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQWulNsaPKHEWjZKhGlTEv6s1Zd+uw3W6iZLcbO85IOOnIa+UR+3pqyZAA7YecdezElt4m2/Nlo0lHnupZaSd6HJ4wMoQCg7V8mQ9ARvJPLS9CcHLc0T2ddjJuj4eVQLRqSFcArLQlxfJeW5bzzuHKYbuya0/+eeUlYS3V8sdju5OkMu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAWhpbPx5QMj9H/09ty6/a99itmu/7r8Nh6Dr7S35wXdjBxvz5pWV+TPgLYN2rPBXrBOZchZasqZ9MXuDoxcZyVnNnti3O5s0sglBzB5wJk9N3LolYedsXJmyEWdnfby0w3mb3Oqz8t56OQG9FQjJ46nbAse7pJNZptFWv4pCIJHAOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVhRulNRDYBHweOA+rAtar6XhG5AngNsC999HJV/Xqzhhzzj3OX15pl4Lccea3PlqjKQ/nXxmPusfWO8X77ejphr3aEttnblAlHNjIOaa1kb6/uSV6r7Nx1pUlnuSMniMNs48hG3rJGXt41S7Hr2WG3Ge+3x2P8OCfoacI51mvsnes4lF/uqY2WNOtJg7PR2avAG1X1LhHpA+4UkVtS3dWq+u5ZbCMIgiVmNmu97QJ2pddDInI/sGGxDQuCYGGZ03d2ETkJeBJwRyp6g4jcIyLXicjqhTYuCIKFY9bOLiK9wM3Apap6GLgGOBk4nezO/x6j3SUiskVEtkzhRNYHQbCozMrZRaRC5ug3qOrnAVR1j6rWVLUOfAg4M6+tql6rqptVdXMFO+tJEASLy4zOLiICfAS4X1Wvaihf3/CxFwP3Lrx5QRAsFLOZjX8a8ArgpyJydyq7HLhQRE4niznaCrx2EexzGT7vyXbdBi+Cyllqathud9Jf58uDB//YjrDzaB+y68acgLL2QWfZKCMyz0t4V293libaZhviLr9lnFm1LkdSdOS1tlFHLu2xDam3G+0cma97r105tcIeR08CLDty6dAJ+eW92207qp352/PyGs5mNv775KfSa1pTD4Kg9cQv6IKgIISzB0FBCGcPgoIQzh4EBSGcPQgKQmuXf3I4/LKzzDpPTrAoOz/W69ll102sdsKGDFz7HHlqaoVdVzaWLQI/osxK2lhrIppvJqyllTLyZSN1kjJ649h5wJahOg/M3Q5vaSVPUlz1M7tucoWTQNSR5WrGb81Gj7W317Mzf78i4WQQBOHsQVAUwtmDoCCEswdBQQhnD4KCEM4eBAWhpdJbvb+Hod+zJTYLSwrxpJqufU50lRP1dtzVc0986Uk1Hu2Ddt2kl4zS2W8zgs1JKllyos28Nec8mceKUvPWt5tc6RwzZ4ybWSvNw1uzzaNzwDbEk+UsmXjSkWatNQm94xV39iAoCOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVh2US9eQkATWnFaaOeBGEvX9YU5Ym5JwYEXwKU+tyj7wBKU/ntSmNzbwOgzhpxVSd55Ip/NSocCa3WYdsxdqzdru8hZx07Y700T770jotHvWTb33nQ3vHRtfnGtDnHbKo3v9xb6y3u7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFYcbZeBHpBG4DOtLnP6eqbxORfuAzwElkyz+9VFUHvG2VDo7Q9+kfztfmf2PofDuopjxpz6iWagsbObHyBnufBl5lLw01dowzC27MImeVdpUVVNG531EFnBnyiVXODPN+Z4ytYBLH9hVb7cqhE5xAnqm5B9DUy854OIFBXtDNyk/OPYgKwIp3GbrAPr+HTsi/T883B90E8CxVfSLZ8sznishZwGXArap6CnBreh8EwTJlRmfXjOH0tpL+FHghcH0qvx540WIYGATBwjDb9dnLaQXXvcAtqnoHcKyq7gJI/9ctmpVBEMybWTm7qtZU9XRgI3CmiDxhth2IyCUiskVEtkzhJHMPgmBRmdNsvKoOAt8FzgX2iMh6gPR/r9HmWlXdrKqbKxjZ8IMgWHRmdHYRWSsiq9LrLuA/Az8DvgxclD52EfClRbIxCIIFYDaBMOuB60WkTHZxuElVvyoitwM3icjFwMPAeYtoZy59n1k4GW+xaB+2da2R9ba+5i1f1bXX1lfKpgxlt6lVnPxo47YdHp58ZeFJoqsesOuaOQ88WWsh5eH54NnRZ5Rv0xGzzYzOrqr3AE/KKT8AnDNT+yAIlgfxC7ogKAjh7EFQEMLZg6AghLMHQUEIZw+CgiDaZL6tpjoT2Qc8lN4eA+xvWec2YcfRhB1H85tmx4mqujavoqXOflTHIltUdfOSdB52hB0FtCMe44OgIISzB0FBWEpnv3YJ+24k7DiasONoHjF2LNl39iAIWks8xgdBQQhnD4KCsCTOLiLnisjPReRBEVmyRJUislVEfioid4vIlhb2e52I7BWRexvK+kXkFhF5IP1fvUR2XCEiO9KY3C0iz2uBHZtE5Dsicr+I3Ccif57KWzomjh0tHRMR6RSRH4nIT5Idb0/l8xsPVW3pH1AGfgk8GmgHfgKc1mo7ki1bgWOWoN/fBc4A7m0oexdwWXp9GfDOJbLjCuBNLR6P9cAZ6XUf8AvgtFaPiWNHS8cEEKA3va4AdwBnzXc8luLOfibwoKr+SlUngU+TZaotDKp6G3BwWnHLs/UadrQcVd2lqnel10PA/cAGWjwmjh0tRTMWPKPzUjj7BmBbw/vtLMGAJhT4lojcKSKXLJENR1hO2XrfICL3pMf8Rf860YiInESWLGVJMxhPswNaPCaLkdF5KZw9LwfSUul/T1PVM4DnAq8Xkd9dIjuWE9cAJ5MtCLILeE+rOhaRXuBm4FJVPdyqfmdhR8vHROeR0dliKZx9O7Cp4f1GYOcS2IGq7kz/9wJfIPuKsVTMKlvvYqOqe9KJVgc+RIvGREQqZA52g6p+PhW3fEzy7FiqMUl9DzLHjM4WS+HsPwZOEZFHiUg7cAFZptqWIiI9ItJ35DXwHOBev9Wisiyy9R45mRIvpgVjIiICfAS4X1Wvaqhq6ZhYdrR6TBYto3OrZhinzTY+j2ym85fA/1giGx5NpgT8BLivlXYAnyJ7HJwie9K5GFhDtmbeA+l//xLZ8Qngp8A96eRa3wI7nk72Ve4e4O7097xWj4ljR0vHBPiPwD+n/u4F/iaVz2s84ueyQVAQ4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkI4exAUhP8PBaNlzNKPnB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAADnCAYAAACjZ7WjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABZvElEQVR4nO29aZAc533f/+me7rnvY+97sbu470PgARK8SZGOJeosWYot20qcSpVjv8gbVexKOalU5UVS+SuJK6mKneiILEuMSJEUKR7gARA3QAALYLEL7H3Mzu7M7NzHzvV/AU+blHDtcqYXAp5PFaooEZz5TvfT3+fs31eqVCoIBAKB4LMhr7UAgUAguBcQZioQCAQ1QJipQCAQ1ABhpgKBQFADhJkKBAJBDVBu9S8lSarZVn+lUpFW+98KHUKH0PHbqeV+0iFGpgKBQFADhJkKBAJBDRBmKhAIBDVAmKlAIBDUgHvGTCVJQpZlJOkzrdt/Zg2KoqAoyprquFtQFAWTyYQsr30zk2UZg8GwphpUVcXtdmOxWO6K9iFJ0prrcDgc2O32NdXwST5LW73lbv4df4iiUCqV0Ps9f1mWsdlseDwe7HY7RqORTCbDxMQEy8vLumoxGo2YzWYURaFcLlMoFMhms5TLZV113C34fD56e3vxer1Eo1HGxsYIh8O661BVlUAgQH9/P3a7naNHjxKNRnXX4XQ6OXjwIM3NzaTTaQYHB7ly5Qq5XE53LbIsY7VacbvdVCoVYrEY6XRadx0DAwM8++yzmEwmXnrpJcbHxymVSrrrgOvXxO124/f7SafThMNh8vn8ij5j1WZqNBpxOBy43W4CgQCZTIbh4eEVC/gsmM1m9u3bR29vL4lEglwuh8lkoqmpibNnz5JKpXTRYTKZaG9vp7u7m+XlZebn50kkEqiqSiqVolgs6qIDwOv10tTUhKqqjI6O6nYNPonFYmHPnj18/vOfZ/v27cRiMX75y1/ywx/+kGQyqZsOm83GAw88wIYNG9i6dSsulwuPx8OhQ4eYm5vTtfPfs2cPe/fuxWg0srCwQEdHBx6Phw8++EDXDldVVVwuF01NTbS0tGCz2ZienmZoaEg3QzUajWzcuJEXX3yRz33uc/T09PDggw/yox/9iPfee4+FhQVddBgMBjZs2IDdbqdSqaAoivbPIyMjTE5OrqiNrMpM/X4/27Ztw+/343K5NBP56U9/yuXLl3VrHG63m23bthEIBLh8+TKxWIxSqcTGjRsplUqcPHmSQqFQVw2SJBEIBHj22Wf51re+xbFjx3jttdeYmJigUqlQKBR0HbUrikJ3dzdOpxOLxcLMzAzBYFDXHt9ut7NhwwZaWlpQFIUtW7bQ1NTE4cOHuXjxom46PB4Pe/fuJZPJcOXKFZqamujv76dYLPLuu+/q9tACtLe3I8sylUoFo9GI1WrFarXq9v1w3cQ8Hg8ej4dAIEBnZyddXV00NjaSyWRYWFggk8mQyWTqqkOWZfx+P4lEgmPHjjEyMsLAwADf+ta3CAQCvPLKK0xPT9dVA1yfPe3cuZPl5WVCoRCFQoF8Po/b7WbDhg3k83kWFhbu+Nm5rZmqqoosy5TLZWRZxmw2s337dnp7ezGbzfj9fvr7+2lubiYcDjM1NUUikfjMP/R2SJKEx+Nhw4YNNDQ0EI1GiUQiJBIJLBYLgUAAm81GLBaru5ZSqUQoFOL8+fMEg0HMZjMWi4VUKqX7mpTT6eTBBx/kkUce4cSJE5w9e5bBwUEGBwd16+RMJhMmk4mRkREuX75MV1cX69atw+/3I0mSLh2LJEl0dXXR0tLCzMwMAJVKhUAgwMaNG/n44491NVNJknA6nRSLRaxWK9FolHw+r2v7UFUVRVEwGAw4HA5aWlo4ePAgXq8XSZJ4++23626kAIVCgWg0yvj4OKqq4nQ6icVi2Gw2/H4/69evJxwOk81m66rDaDTicrmoVCrk83ntt9tsNjo7O8nlciwvLxOJRO7o825rpr8+RS2VSszMzODxeHC73RQKBYxGI21tbXR0dOByuXQx06oWWZbZu3cvhUKBZDLJ1NQU2WyW+fl53abX2WyW8+fPE4lEMBgM2kNSqVR0X0tubW3FbreTyWTw+Xx4vV7cbrfWIepBPp/XRsTZbJaFhQWmpqZ0X3JYXFxkeXmZffv2kUgkcDgceDweksmkrssNAAsLC2zatIlCocD7779PPB7XfcaQy+Uol8uUSiWy2SzRaJRUKsXy8jKzs7PMz8/rYqalUon5+Xk6OjoolUoYDAbtXsViMQwGA36/n9nZ2bq22cXFRebn53niiSfYtm2bdk2KxaI2Kl3J+vptzfTXjaBYLDI9Pc26des09w6FQly6dIkTJ04Qj8dX/qtWQaVSYW5ujldeeQVVVens7OTAgQMcP36cI0eOcOnSJV0W9yuVCrlcjkQiweTkJIpy/ZJWpwx6rpcCnD17litXruByubDb7czPz5NKpXR/aKemprDZbBgMBhYWFkilUszPz+vWsVQqFYaHh/nZz37Gv/yX/5J9+/ZhNpu5fPkyH3zwAaFQSBcdVYaGhojH47S3t2M2m4lEIszNzemqoVQqEYvFMBqNpNNp5ufn+fnPf87c3BzHjx/XtbOLxWJMT0/T3t6OxWIhn8+TTqfJZrNkMhnNZOtppvl8nuPHj9PU1MSLL75IT08PV65cYXR0lKNHjxIOh1fUXqVb/eVbvc+6fv16uru7KRaLeL1eisUi77///k2HxPV4r1aSJMxmMy6Xix07dtDX18eZM2c4derUTXfz66GjeqrAbDZrF79UKpHL5cjn8zdsEHf7e8afRYeiKPT39+P3+7HZbNjtdmKxGB988IGu9wX+cZPhW9/6Fk1NTfziF7/g9ddfv+kUsl46VFXld3/3d3n++eeZmZnhBz/4AVeuXLnpZ9Xz3XyTyaSdgKnO6OLx+E073Hrem+oOevXIWCqVYm5ujlAo9Bt66qXDZDKxZcsWHn74YbLZLENDQ5w5c+amncvNdKzaTD95prN6Xq1Sqdx0JFZv8zAYDJjN5tseR6qXDlmWUVWVSqWiTe/XQsdKqZcOp9OJ2WzGYDAgSRL5fP6Wa0/1vh7V866FQuGWs4V66ujt7eWBBx4gGAxy5MiRW86c6l3opHomWpIkCoXCLUdgerTVT/pJuVy+oZ5661BVFUmSKBaLq3p2V22mK+VeNw+hQ+i4nQ5FUTCbzRSLxdsuQYmqUb99OmpyaF8gENyeYrG4Jud+Bfqw9u/5CQQCwT2AMFOBQCCoAcJMBQKBoAbccgNKIBAIBHeGGJkKBAJBDRBmKhAIBDVApJMKHULHPabjbtJyP+kQI1OBQCCoAcJMBQKBoAYIMxUIBPc1kiRhMpk+8+fcU2Z6NwSECT6NuB+Cu51KpbL2ZlrNf1rr1Ee4XjWqubkZt9u9ZhokScJgMNwVaZx3Aw6HA5fLJa7HJ6hW0QL9OxqDwaDVDxWd3Kepxeh01YVOPB4PTzzxBP39/bz99ttcuHBhTZIWPxnB0NnZydzcHMlkUreizJIkaUWQm5ubaW9vJx6PMzMzw+LiYt0zqG6kR1VVAK0k4lq8mOHxeNi9ezd2u52xsTGuXr2qSxX3GyHLspY0sFZpsR6Ph4aGBjo7O4lGoywuLlIsFgkGg7ppMhgMPProo7S2tnL27FmmpqaYm5vTLRnj1zGZTNjtdkwmE+VymaWlJV0DOavY7XY6OztRVZWxsTHi8fiq7smqzLSaA/X1r3+dxx57jI6ODv76r/+a4eHhuue2fBKLxUJfXx8+nw+3243D4aBYLDI3N8fi4qJuOvx+P08//TQ7duygsbERk8nE3Nwcr7/+Om+++aZu16TaOKt1RCuVCplMhnQ6rWtH5/f7+dznPqfVl92yZQtdXV28++67ulZNqna0FotFCzfMZrNafIdeqKrKgQMH6OnpQVEU8vk8lUqFM2fOMD8/r5sOSZLw+Xz84R/+Id/5zncYHx9ncnKSN998k3feeUfXCGxJkuju7ub5559n//79zMzM8Ld/+7dcunRJ9wGIx+OhubmZ5uZment7uXjxIiMjIysekK3KTB0OB+vXryebzXLu3Dnsdjs7duwgkUgwMTGhS0O12Wxs27aN3bt3azn1JpMJg8FAIpEglUrpYmKSJNHS0sL69evJ5/OMjIzQ29vLI488QmNjI5FIhFOnTpHL5eo+QjQajbjdbnw+Hw6Hg3K5TDQaJR6PE41GyWazdW+oVquVzZs343a7tcgUVVXZuHEj4+PjDA4O6jJSlmUZj8dDT08PTU1NzM7OagF6BoOBbDar2+zF4/HQ3t5OLpcjEomQzWbp6OigsbERWZZ1i5QpFouMj48TiURQFIVUKkVPTw//7t/9O3p7e/lP/+k/6TYyNJlMrFu3jl27dtHT00NHRwcXL15kenr6jgPsaoHRaMRkMpHP50mlUjQ2NvLUU0/hcDj4+OOPb5oMcSNWbKaSJOH1eqlUKhw7dgy4fpOWl5dpbm4mEonokgNVLBaRZZne3l78fj+RSIR8Pk8sFiMajXLt2jVdzNRisWC32zl//rw2xVYUhc2bN3PgwAGi0SjlclnLpLpZjMlnpZryuHHjRjZv3kyxWGR+fp5yuUyxWMRgMFAqlZiYmKj5d1cxGAw0NDTQ1tbG8vIyJpOJUqmk5fu0t7dz+fJlXUxMlmXsdjsvvPACzzzzDN/73vdIJpMsLy9TLBZRVVW3sEOPx8PGjRuJRCKEw2EKhQK5XA6r1arr2mWpVOLq1avMzMyQzWYJBoMYDAbS6TRbtmzB5XLplthaXUcPh8McO3YMu92Oy+XC7XYTjUZ1W5qqxg0Vi0VKpRJGo5HHHnuMnTt38t/+23/j0qVLdzybWrGZVqeO8/Pz2gNaNQebzYbH49ElwC2fz3P16lUWFhZ4+OGH8Xg8ZDIZLZtdj00xSZJobGzEYrEQj8dxuVwYjUaMRiOFQoGPP/6YN998kwsXLpBKpTAYDKiqWpfe32q10tnZyde//nUefvhhfvaznzEyMkIsFtM6uHqPOkqlEslkElVVaW9vp1AoEIvFKJVKWtvw+XxEIpG6G1mxWCQej3Pt2jWGhoa0EYYsyxgMBm0jSK/Y6Q0bNpBIJJiZmdFihZeWlnRfww0Gg5w7dw63262Z6szMjJZiq5eZlstlwuEws7Oz2Gw2xsbGmJmZ0TX4Ef4xfbm6LFYdfOTz+RU/M6ua5kciES3uuRodqygKsViMRCKhWwMJh8McOXKE9evX89BDD2mL2LOzs8Risbp/v9Fo1DLHP5lbYzKZGBoa4qWXXuK1114jnU4D1PW6FItFMpkM77//PleuXGFkZITJyUmi0aiW+qgHS0tLjI6O8tRTT7F582ZCoRAXL15kcnKSy5cvk0wmkSQJo9Go6a6XocXjcQ4dOsTw8LA2eyqVShSLRQqFgm7ttBotvX37dqamprBarSQSCYaGhnQ306WlJc6fP89XvvIV5ufntVGgw+HAarXqpiOfzzM9Pc2RI0dwu91UKhVCoRCRSETXDdPq9a+a59zcHK+99hpjY2NMTEysaFlsVWaayWQYHh4mEAhoD0UulyMYDOq6G1cqlThz5gySJHHx4kVUVeX48eNcunRpRWsdq8FgMGC1WgmHw2SzWWw2G5lMBpvNRjKZJBaLceTIEc1I6006nWZkZISpqSnsdjuKomgmquemYLlc5uOPP+bll1+mXC5jsVi4fPkyb731FlNTU58yD1mWMRqNdZtFlMtlgsEgiUQCk8mkGWomk9HVxCKRCIcPH6a1tZWBgQEcDgeHDx9mbm5uTU4XnDhxgq6uLpxOJy0tLRiNRqLRqK6bg5VKhWAwSC6Xw263k8vliMfjup8IMhqNLC0tkUqlsNlsLC4ukkwmCYfDK9bymQL1qlOmtU44NJvN+Hw+fD4fY2Njt2wUtdJhNpu10U31ZYFPnqdUFOWWm071vB6fTIv9h++66d+tlw6j0aidMV1aWrpl5/YPI/u6FrGork3ebtRTr+uxbt06Hn/8cVRV5dq1a1y4cIFgMFiX9nE7LdW1fbfbTUNDAwAzMzM3nVXWu8DInS631FqHJElYLBbtdMXt0lFvp+OeSietruGutY47Qei4v3TIsozX6yWTyZDNZutq6rfTslLu9XtTKx33VDqp3ovXAsGdUt1wEdy7iPf8BAKBoAYIMxUIBIIaIMxUIBAIaoBIJxUIBIIaIEamAoFAUAOEmQoEAkENEGYqEAgENUBEPQsdQsc9puNu0nI/6RAjU4FAIKgBwkwFAoGgBggzFdQdkRp796Io99Qb5WvKZzJTo9FIS0sLbW1tWCyWWmlaFdXCy2uZhOn3++ns7BSJnP9ANa21mtG11lSrJd0N9+Zu6VzW+r6oqorH48Hr9a6pjk9WwFstq+qWDAYDXq+Xnp4e1q1bh9vtZm5ujnfeeYdkMrlqMavV4nQ6aW1tJRAIMDs7y8jIiK4a4HqjrNaGdLlcpFIp5ubmdK/PqCgKfr8fs9kMXC9MHI/Hdcs7gusPSDWCohrwFw6HWVpa0k1DlUAggMvlwmaz4fV6aWho4Ny5c4yMjOie2irLMi6XS4tz0TP08UZYLJaa5MWvltbWVvbu3Yvb7SYYDHLmzJk1uSZ2ux2/34/dbtcKRK+maNKqzNRmszEwMEBLS4vW2z/00EO4XC5+8Ytf6JZy6Ha78fv92oPS3t6Ow+EgGAzqauqKotDQ0ICqqhQKBYxGI93d3TQ3N/Pxxx/rFnGsKArbt29n//79eDwe1q1bhyRJHDp0iEOHDjE1NaWLgVitVnbt2oXL5SKZTJLJZHC5XCiKopupy7LM1q1b+b3f+z18Ph92u522tjYSiQQ//OEPmZyc1K2jMxqNtLe309raqkXaxONx3UIffx2TyURzczOtra3k83ld46artLa28swzz9DW1sbCwgIOh4Pe3l5isZiu6aRGo5Gmpia6urro6ekhnU7z8ccf65NOKkkSLpeL1tZWLBYL2WyWdDqN3W5n165dvP/++7qYqdlspq2tjZ6eHpxOJ4qikM1mtTjbVCqlayiXw+FAVVVt2tLV1UVjYyPxeJyLFy/qoqOjo4M9e/ZQLBaZnZ3Fbrfz/PPPs3XrVjKZDKFQSBcDURRFS9+cmZlhaWkJi8WCx+PRbeQhyzJdXV1IkkQwGKS9vR2Px0NLSwsdHR26TvWbm5v5yle+QiKR4OLFi2SzWex2O16vl9nZWd10VPF6vXR2dvLUU09RKBQIh8N1DVr8daxWKzt27GD9+vXE43EWFxeJRCI0NTXR09Oj26zBYrHQ3NxMQ0MDW7Zs4Stf+QrhcBiLxUImk2FycnJFOlZlpjabTZsiSJKE0+mkv79f13qNkiQRCAR4/PHHGRgYYGxsjFOnTpHNZmlqaiIUCunW6yuKoq3FWSwWmpqa2LlzJzt37mR4eJiRkZG6x6ioqsrmzZsxmUzMz8+TzWbJZDIUi0W2bNnC8vKybqMPo9HIxo0b2bhxI8eOHaNcLrO8vKxrxlC1ino8HiebzdLQ0IDD4cBsNiNJkq7LHna7nSeffFLLwqq2S7/fvyajQpvNRk9PDwcOHCAcDjMwMMD8/LxuI/VisUggEMDn85HL5TCbzVQqFfL5vK5Bh6qqYrVacTqd2O12VFXVOlu/37/ia7KqdNLqD60ahNvtprW1lYmJCV1inqvfXSgU2LZtG83NzVy9ehVVVbWHqDpq1gNJkjRDtVgs2pSloaEBs9msS1KqyWTCbDZrM4VisUi5XGZ4eJjp6WlOnjxZd0OvYrFY6O3txWq14vP5tJwsv9/P9PS0buZRKBRIJpOUSiXi8TjpdJp0Os3MzIyuBlZNsVVVlaGhIWKxmJaeuhaFhhYXF5mfn+fVV18lmUxSLpexWq26mWmlUqFYLOL1egkEAvT29vLWW29pSbp63ZtUKkU8Hsfv9zM8PMyPfvQjzGazltq60ud2VWa6tLREqVTC6/ViMpno6OhAURRGRkZ0C5ArlUpMTk7y0UcfsX//fkwmE1arVYtS1vNhyWazWg56VUcoFOLs2bMcO3ZMl0aayWQYGxvTRqd2ux2fz0c+n+e9994jGAzWXUOVUqmE1WrF5XJpi/upVIpAIIAsy7rdm2oWerlcJp1OMz4+zsLCAseOHdNtZFodBR8+fJhNmzbR3t6upYImEok1MdNkMsng4CDBYBBFUTQtelEqlTh16hSNjY3s27cPl8tFX18f4+Pjuj631fQDk8lELpdjYWEBRVHIZDKk0+kV35tVZUApisLOnTt59NFH6e3tpa2tjdnZWb7//e9z7NixG+6E1eNVMFVV6e3tZceOHbjdbmKxGJOTk8zPzzMzM3PDkVi9Xklrb29n06ZNtLa24na7iUQiHDlyhLGxMd1CyqxWKx0dHRiNRoxGI1arlampqVuuh9VDh8lk4tFHH2X37t1kMhnC4TBTU1OMjIwwPz9/w0Zaax2yLNPf38+BAwcIBAI0NTXR1tbG97//fX7+85/f9LPqEdpmtVqx2Wxs27YNr9fLxMQEExMTRCKRm5q6Xq+T2mw2crncLXev6/XMtLS08OCDD7J//35UVeX111/n0KFDN51B1UuHxWKhoaFBO95ZKBSIRqMkk8kb3p+aB+oZjUY6OjrYsmULZrOZCxcuMDY2dtOpdT2Dymw2G1arlXK5TCKRuGUmer10VHf0A4EA6XSaSCRCLBbTPZ30k+fk/iH185afVc/7oiiKtv5VXXbQU0d1M/KZZ55hw4YNXL16lZdeeumWJz3q+f539SxjuVyua/DjnWhZCfW8JiaTifb2dtra2hgbG2NqampNdMiy/KkE29W01c+cTmo2m5Fl+baJi3d7kYJa6biThFQ9dNwp94OO6siwUqncdpP0Xrged5OWO9VhNBqpVCq3PBZ1t9+beyrqWegQOoSOu0vL/aRj7d+rEwgEgnsAYaYCgUBQA4SZCgQCQQ0Q6aQCgUBQA8TIVCAQCGqAMFOBQCCoAcJMBQKBoAaIdFKho+4vMaiqetv6BPfL9dBDx92k5W7VUX3jaTVFoMU5U8GaITY5BXcbgUAAp9NZ088UZiqoK3dD3pJA8OtIkkRHR0dNs7hENOE9jJ7l7m6GwWAQhiq46wiFQgBavd1a8JlauSzLmM1mHA6HLgWQ73aq4X5+vx+v17um16SaiLDWfLIaz63+Tq359epZwtB/E0VRMBqN9+W1qVQqhEIhyuUyHo+nJp+5qpGp0WjUco/sdjuyLLOwsMDCwkJNRP02YrFY6O7uZtu2bfh8PsxmM8ePH79pfdd6YrVa6evrQ1VVzp8/r2tA2a9jNptvW4i51p2OLMu43W7tujc2NmK1WllcXCQajeoaYmexWPD7/TQ0NGCz2bSCxOPj4+Tzed10fBJZlnE4HBiNRi2xIp/P695OAZxOJw0NDeTzeUKhkG5pEPCPhe537drF4uLiZw6cXJWZWq1Went7tdFXNSAsEAiwuLhIIpHQLQLB6/WyYcMG4vE4Y2NjdU0CNZlMN6yV6nK52Lt3L21tbaxbtw6r1UpraytWq5WLFy8Si8XqpumTOJ1OHnzwQXbt2sXWrVtZXFzk7//+7zl+/PiaPLjVgsjpdJrBwcEbmlg98uPL5TK5XI5169axadMm+vv7KRaLRCIRLQFBr6RWSZL4xje+wWOPPcbg4KBW2f3q1aucOXOGkZERXZdiFEXB7Xbjdru10pmpVApJkshms7pq2bx5M//iX/wLent7OX78OKdOneLUqVPaFFwPKpUKmzZtYseOHRw7dozx8XHGx8dXFfy4YjNVVZWGhgb6+vqw2+2kUingutFURwN6xiwfPHiQ7373u4yPj/M3f/M3vP/++3WNTqnmLMH1G6EoChs2bGD//v1YLBacTidWq5VKpUJzczO9vb18/PHHdW+ksiyzYcMG/vAP/xCn06kVIn7hhRdQFIX3339f15FHQ0MDn//85/niF79IJBLhJz/5CYcPH9baiyRJWnZWPSJE8vk8VquVL3zhC1gsFj788EPS6TRNTU0cOHCA119/XZcU3eXlZYLBIJcuXeLEiRMkk0kt+8jlctX9+6tUR+ttbW00NjYiyzLhcJhyuUyhUNDW1/UYtauqyt69e/nLv/xLWltbOXfunBaEuXHjRpaWlnQbodrtdq1AtdPp5MqVK+zatYuPPvqIiYkJbDYbJpOJ2dlZLQLnZqwqndRqteL1evH7/cRiMS1dMJvNUiwWdR2qJ5NJzTxbWlro6+tjaGioLiOxfD6PoiiYTCZtatra2srTTz/Nhg0baG9vx2q1Eo/HtZH59u3bGR8fr/uDK0kSnZ2dbNq0iVgsxpUrV0gmk3g8Hj73uc9x+vRp3cIOHQ4HX/3qV/mn//Sfap3sH//xH+N0Ojly5Ig2ui+VShSLxbqNEC0WCxs2bGBhYYFUKkU0GiUcDmO1WmlubiYej9e9gykWi5w5c4aWlhZMJhOZTEb7oyj67f/KskxPTw/f/e53KZVKHD58WGsT1Y5Nr/y0xsZGfv/3f5/du3dz6dIlpqamtAFYa2srLS0tukVPOxwO8vk8V65cwefzYTQaeeqpp/ja177Gz3/+c06fPs3k5CQWi4VisXjLme+K72a5XKZcLtPS0sLevXtZXFzk2rVrJBIJJiYmSKVSuk4VPv74Y37605/i8Xi0B8Vut9dtWlssFikWi1oKavX7/H4/TU1N+Hw+5ufntaTWRCKh20ZUuVwmFoshSRLRaJRQKITNZiMajerWwRkMBvbu3csXvvAFGhsbKZVKTE1NYTAYePTRR5menmZkZIRMJkMul6NSqdRtqj87O8uvfvUrXC4XpVJJi1CRZRm73X7HqQiflVgspi2FVbO5mpqamJ2drctvvxHVtdp3330Xi8WixRgvLy+zvLystWs9lj7C4TCXL19mx44dhEIhJEnSlh0qlQoXL16su4Yqy8vLxGIxpqenSaVSGI1G4vE4hUKBkydPcuLEiTtuIys201KpRCQSIZVKsW7dOnp7eymVSly+fJmZmZlb5h7Vg0gkwi9/+Ut6eno009DjAalUKmQyGYaGhvjJT36CyWTC6XSiKAqFQoHFxUUOHz7Mhx9+SCQS0UXP9PQ07733HpIksbCwQCwWY2lpiWvXrulippIk4XQ6eeqpp1i3bh3BYJBEIkEoFCKbzTI2Nsa1a9d+4yhKPdpLpVJhYWGBoaEh1q1bh8FgwGazkU6nSaVShEIh3TbmQqEQk5OTPPbYY8iyjN/vJ5FIrGpdbrVUO5ef//znNDc3YzKZyOfzmokWCgUKhYIuz24ul+Pv/u7vANiyZQuNjY10dHRgMBi06bVeZLNZEokETqeTUqmE0+nk0qVLzMzMMDg4uCIvWVXU8/z8PG+99RYmk4nW1lYmJiYYHBxckx3KcrnM6Oio1sMVCgVdd2vz+TynT5+mUqlQKpXYuHEj586d45VXXuHChQvaGmG9KZfLjI+P8/HHH+P3+8lkMsTjcVKpFCMjI3XtYKpHj1RVxWazYbFYKJVKpFIpIpEIyWSSaDTK4cOHa3am706IxWLaOmU1X2h+fp7R0VFdO/1CocDg4CBf+9rX2L9/P+l0mv/wH/4D586d021kWtWxuLhIpVLR9jdKpRL5fF63DeMqwWCQv/7rv2bTpk089thjbNy4kUwmw6FDh3RbjoLrEemhUAiHw0G5XMblcmEymRgeHl7xs7vqDCiHw4HT6USSJPL5POl0+pahevfi+72fpLom9eSTTzI+Ps6HH354y/WVeqVxWiwWvF4viqKwvLzM0tKSNp3WQ4fFYuGb3/wmf/qnf0oikWBqaorJyUmOHDnCu+++e9PNwXrdF1VVcTgc2v9OpVK3HKXXS4fVauXJJ5/k2WefZXh4mB/84Ae37Fjq+W6+2WzG4/FgMBhIJBK3XZqr97NrMpkwGo3aBpjeycJms5mmpib8fj/Nzc34fD7eeecdZmZmVqRDBOrVUIeiKOzbtw+z2cypU6dIJBJromMl1COvfv/+/fz5n/85Xq+X48eP89Zbb3HmzJn78np8EpPJRFtbG5FIhEQiUTcDuxMt1Rc6MpnMbUfo98O9gesdryzLWK1WAJaWllakQ5hpjXU4nU56enoIBoO3PC93r14PRVHw+Xxs2LCBQqHAyMgI0Wi0rjnxd/P1WAsdd6Kl+tbTnWwW3wvXRA8d4t38GpNIJJicnNQ2o+pxhvJuplwus7CwQC6XI5PJrOnbV4Kbs9Y1G+5FhJnWgVgsRqlUwm63k06n7ytDqT6k1eM2AsH9gjDTOlCpVEgkEiiKcl/W8qye37wff7vg/kWkkwoEAkENuP9qbwkEAkEdEGYqEAgENUCYqUAgENQAkU4qdAgd95iOu0nL/aRDjEwFAoGgBggzFQgEghogzFQguI8wGo26FqW+n/hMV7Va9LhSqazZ62mSJGE0GqlUKhSLxbvmNblqIeL7EVmWsdlsWjzG5OTkmoXHwfUCI3a7nUKhcMtiK/XEaDTi9XqRJIlwOLxmb8UZDAa8Xi+xWEy7J/drO601qzJTSZIwmUzYbDYURSGXy5HNZnWNK6lSLTlntVq10LRkMrkmpmq323G73ZjNZhRFYWJiQrc6kZIkYbfbtSiQtbgXcN1I+/r66OjowGQy0djYSF9fH+fPn79pSbN6oqoqfr8fj8eD2WxmampK9xRdo9HI/v37+frXv47f7+fVV1/ljTfeWLM037a2Nvbv38/CwgKLi4sEg0Fdc9s+iaqquFwu8vn8mmmoRtZXnxu73U6lUllxltyqzNRsNtPR0cG+ffsIBAKcPXuWS5cuEY1GdX0f22Aw4HK58Hq9tLa20tbWRiaT4aOPPmJ6elq3ADmTyURvby979+6lqakJj8dDJpPhRz/6EaOjo7r0/Iqi8KUvfYmNGzfy4YcfMj09rT0seo6CrFYrPT09WkZYT08PfX199Pf38+677zI8PKzbKFWWZbxeLw6HA6vVis/nw+Vycfz48bqGLv46DoeDL37xi3z5y19mfn4egKamJl5//XUuX76sezrp5s2b+bM/+zPK5TJHjhzh//2//3fbEom1pjogCwQCPPvss7S0tPCzn/2Ma9eu6V6o2mAw4PF4sNlseL1ezGYzwWCQycnJFWlZsZlW83Meeughvv3tb9PU1MQvfvELCoUC58+f17V3MRqNuFwunE4nZrOZlpYWdu/ejd/v5wc/+IEu6ZMGg4F169bxwgsvEAgECIVCzM/PYzKZ2L9/P5lMhvn5+bo/MMVikWAwyJe+9CXS6TR2u53Ozk7Gx8cZGhrSzVC9Xi92ux2Hw8GWLVvo6elhamqKfD5Pb28v8XicyclJXbRU48eNRqO2Vuj1evH5fLqaabFYRJZlRkdHeffdd5mfn8dsNtPX18fIyIiuswij0aglMZjNZnp6evjc5z7H0tISw8PDuqVU2Gw2bDYbTqeT9vZ2HnzwQS5duqTFcevZwRiNRgKBAOvWrcPr9ZJMJonFYivObluVmZrNZnw+H4VCgZmZGdxuNwMDA0xOTpLJZHQZEUqShMPhwO1243A4MJvNWhql2Wzm7bffJplM1tVEqnk+/f392vqg1WrVYnRNJhNbt25leXm57nEdlUqF48ePazlMkUgEt9vN5z//efr6+jh27BihUKju90ZVVaxWK4FAgO3btxMIBJAkSetk9Zy52O12mpubkWVZM5GmpiZaWlqYmZnR7YEtFovMzs5y+PBhLl26RDqdxu1209HRQVNTE1NTU7rogOvGoaoq58+f13KfDAYDra2tLCws6JJOCmjPZbFY5MMPP+TixYsEg0GMRiM2m41UKlX3GV11qbKvr4+DBw+yZcsWwuEwFy9eZHl5ecXXYVWBesVikcXFRYaHh5FlmVwuR3NzMy6Xi4WFBV2n1xaLhUqlokV0zM7OEo/HUVVVC7erB2azGVmWMZlMOBwOGhoa6OrqYnJykunpaeD6lLcavKcH8XicCxcuaOuDZrOZxsZGnn76aR5++GFef/11Pvzww7pOszOZDMViUcuGd7vdbNq0iWQyic1m0y2pVZZlGhoa2L59Ow0NDSQSCYrFIoqi6PKgfpJCocDc3BzxeJzZ2VkKhQKqqtLQ0IDFYtFNh6qqOJ1OYrEYsixrI+ZsNkupVEJVVYxGoy7T7GpmWqFQYGFhgUgkQi6Xo1QqYTAY6r6B+8nIeqfTSWdnJw899BCnT5/m2LFjJBKJFT8nqwrUSyQSDA8P43a78fv92tRO7119g8GAoigYDAYMBoO2wXDu3DktrrVeVBvc7Owsx48fp6enhz179miRtZlMhsnJSUZHR3WbOlUqFaLRKLIsa2Xwzp8/z/Hjx7lw4QKhUKju65Xz8/OcOHECh8PBlStX6OjoIJ1Ok0wmCQQC2lS/3qFp5XKZVCpFQ0MDX/ziF7WI6aGhIS1UTi+Wl5eZnp6mv7+fcrlMsVgkl8sRi8V0C1yE69dkamqKt99+m/b2dtxutxaLvrCwQCqV0m29sto+qzNZSZIol8vkcjldlqQqlQrJZFL73r//+79naGiIRCLB1atXicVi9R+ZwvXRx/DwMOVyme7ublwuF6FQSPcNqHQ6TSgU0gysuj44PDysm5ZSqcTIyAj/9b/+V4aGhnjqqafI5/OcO3eO06dPs7CwoOuDm81mWVxc/FScsR5R01UqlQrXrl1jaWmJs2fPsmvXLgwGgxYj3N/fD8Dx48fr3slUp9ZtbW34fD4tk/1m2T71ZHx8nK1bt2oxzwaDgVAopGvcc6lUIpvNMj4+TiwWw+12Y7VateNaeu535PN5bWRaKBSQJEnrZPQy9GKxSDQaJZVKEQwGOX36NAaDAVmWV7WOveoMqOpunMlk0s543upITj3eq1UUBUmSUFVVM05ZlrVp/41+Wz3f71VVlZaWFmw2G/Pz8ywtLd23aa1VquuUbrdbmz0sLy9z4cKFT5l8vXRUj2dVj89dunTplqPieiZgPv/882zbto10Ok04HObIkSMMDw/XvJ3eTss//HvtGa7+s97JsZ/U8onvuunf0+uZud0SgwjUEzrWTIfBYMBkMlX/G62z++TMQQ8dNpsNVVWJxWI3/Tv11OF2u+nt7aVQKDA/P08kErnp/oIodPLbp0OYqdBxX+m4XcjhvXA97iYt95MO8W6+4L5ChPwJ6oUwU4FAIKgBwkwFAoGgBoh0UoFAIKgBYmQqEAgENUCYqUAgENQAYaYCgUBQA+6pdNLW1lYWFxdv+SrY3X5WTei4d3SoqookSat6NVGcM/3t03HPjExVVUWW75mfI7gHKJVKIhLkPuKecR9VVTEYDKLxCm6Jw+HQ7bsqlcqn3jsX3NvcM2ZaraYuuHuolgK8W6gG6+lJtTyk4N7nnsh8lSQJl8uFqqprOjJVVRWz2UyhUNA9xwauXwdFUbTSasFgcM2C9VRVxefzoSgKiURCKxq9VsiyTFtbGwaDgWAwqMt3VioVrRB0uVy+a2ZN1WpRsixTKpVuWmFNb03V2qJrhaqqlEqlVWv4zGaqqirAmkXXAjidTnp6eshms2uyblqNWvD5fFitVnK5HKFQiEQioVsjlSSJnp4eDhw4wLZt23C5XHz00Ue8/vrruplHFZvNRm9vL+3t7VpibDgcJhqN6h61bDAYaGhoYOvWrezfv59Tp04xMjKi2/cXi0UMBgMWi4VsNnvT9vBZH+SV0N/fz/PPP4/D4WB2dpZjx45x8eLFun/vzagmVZjNZiYnJ3UtmA3Xi990dnayfft2ZmdnGRkZWVV+3KrN1OfzsWfPHtrb27l27Rrnzp0jFovp2sPJsozb7Wbz5s10dXWRSCS4du1a3fOWPvn9TqcTn8+H2+3Wenu3200gEGBycpJgMKhLjIvT6eSZZ56ho6NDM/EvfOELbNy4kf/yX/6LbiF2Ho+HJ554gp07dxKJRJiamkKWZWw2G7IsUygUdA1t2717N/v372fLli3s2bOH3t5ezp07x+zsrC4a4HohZIvFgs1mI51OU6lUUBQFWZYpl8tIkqSbkTY0NPDcc88xMDBAKpXS0jKqkT96Y7PZ2LhxIx0dHSiKQkdHB4ODg7rGgvf29vLCCy+wbds2JiYmaG1t5ejRo8zPz6/Iz1Zlpk6nk29/+9t84xvfIJfL8d577wHoGhcryzLt7e309fXhdru1XJuOjg4ikYgupl4102r8gyzLKIqiJaW2tLRw6NAhXSrdBwIBnE4nExMTZLNZHA4HFouFAwcOEAqF+M//+T/Xfcqvqirbt2/nn/2zf4bRaOSDDz741Hqhw+HQpvt6zGRaW1t5/PHHMZvNJJNJ4vE4u3fvZv369czNzena8edyOS3gLxAI0NLSQrlc1jocPSruGwwGtm3bRnd3t1bIPZfLaWm2elJ9Vjdt2kRvby8+n49cLsfo6KhuU31Jkmhvb+fgwYPs2rWLYrGI2WymubmZBx54gBMnTqzI1FdspkajkZ6eHp577jna29v58MMPSSQSGI1GLBaLbmbqcrnYvHkz7e3t5HI5lpaWKBaLeDweLBaLbiF25XKZUqlEqVRCURQtpKs6Wg4Ggxw7dqzuo9NEIsHS0pJWfDmXy7G4uEipVOKRRx7hBz/4AXNzc3XVoCgKXV1dDAwMaNOkaiHoUqn0qZyweDxe1zwqWZYJBALE43GCwSA+nw9Zltm9ezeBQEBbL9QLSZIwm8088sgjfPWrX8XhcDA3N8fIyAjvvfcemUym7tNbRVFYt24dLS0tOBwOJiYmGB0dJZlM0t3dzdjYmC6dnCzLbN++nccff5zW1lYaGhqwWq1MTU1x9uxZFhYW6q4Brt8Tj8dDS0sLxWKRdDqNqqr4/X5UVWV8fLy+ZlooFJicnOSXv/wlMzMzXL58mYmJCVKplK6N0+l00tvbS3Nzs/ZwptNppqentXXcelMqlYjFYpjNZu1YlizLuFwuHA4He/bsYefOnVy6dKnuSyDxeJxIJMLAwAANDQ2YTCZcLpdm8OvWrSMajdZ1Y6xUKjE3N8fp06exWCzkcjkqlYp2eL1QKGjhevUeJVcqFVKpFDMzMyQSCaanp0mlUgQCAYxGo+5Hlqr3fs+ePTz88MNMTk5qkeDVyPLqEkA9MZvNtLe34/P5gOthf9Uk30AgUPcOF67PYB544AH27duH0WjE5/MhSRKjo6OMjo7qtlFZHXRU26WiKNqzUygU8Pv9mEymO+70V5VOurS0xP/+3/+bzZs343a7SSQSBINBXYPKJEnC5/OxadMmPB4PANPT07zxxhtaREa9qT6wc3NzFItFnE4npVIJq9XK1atXmZ+f58iRI7oF+y0tLWG1Wlm/fj1ms5lAIIDf7+e9994jnU5rm2P11HDhwgX+v//v/2PXrl1ks1kURcHlcpFKpZifnycYDOqyZlqpVAgGg3R2dlIul0mn01po2uLiou4bldUHd3p6mqmpKdLpNNFolLm5OdLptC7Hp0qlEkNDQ5w7d45t27Zp+WnVuHa9YqeXl5c5ffo0TzzxBFu3bsXpdHLs2DHeeust3db24fo9icfjjI+PUywW6erqYu/evQwODjI1NaWFQN4pq96AWlxc5IMPPsDr9VIqlUgkErqOTKs9SkdHB729vaiqSj6fp1Ao6KoDrqe1hkIhAC13/Ny5cwwNDTE+Pq7L2lzVyBYWFti3bx8PPvgguVyOv/mbv+Hll18mEonUfTRYKpUIBoMsLi4SDAbp7u7G4XCQz+eZnZ1lampKt+UXgGg0SjKZpLOzk2QySTgc5ty5c7pNI29EdY20ml8/MzNDLperewQ3oEV/V6eulUqFfD5PLpcjm82yvLysbYrVk0qlwvnz53nttddwu92cP3+ev/3bv+XSpUu6nwpaWlriyJEjdHV1MTExQTgcJpFIMDQ0xKVLl1b0zPzWZkBZrVYef/xxXnjhBfr7+0kmk7z11lu8/fbbjI6O3vSm1PP9XoPBgNVqxel0ArCwsLAmOlRVxel0YrFYCIfDtxyN1kuHqqp4vV4sFgv5fJ5EInHT9Mt66mhoaKC5uVlbArqdadW7fWzbto0XX3wRm81GNBrV4smvXLnyqTXTer2bX13eWEkHX69r4vf72blzJ2fOnLmjTdp63htFUbBYLJhMJm3JcqXP7m+tmUqSRGdnJ21tbdpwvRqvfKuRqR7FEu7kAPLdXrRB6KiPDrvdTmdnJw6HA7vdTi6XY3x8nGAw+Kn2cj8UOjGbzZhMpltGb+uhY6Xcc2YK13t6VVVZXl6+46nJ3X5DhI57W0d186u6MVcul8nn87/Rfu8HM73XdPxWv05aPZIkEPy2YDAYKBQK2jlPwb3DPVPoRCC426nWTljL988F9UOYqUCgI8Vicc2Ligjqg0gnFQgEghogRqYCgUBQA4SZCgQCQQ0QZioQCAQ14J5KJxU6hA6h4+7Scj/pECNTgUAgqAE1MVOHw7HmKYzVSu4CgUCwFtTEfYxG45omMFajQu4WM13rjkUgEOjPZ3afalEPRVm7N1MtFgs7d+7E7/evmQa4burV4rttbW33vanKsozVasXn8+FyudbselQTW6vRMoJPc79fE6PRyMDAAO3t7Z8pLv4zOaDNZqO7u5vNmzczPT3Nxx9/rGu9SrheheeBBx7gS1/6Eh0dHbzyyiu6hnFVMZlMDAwM4PV6sdls5PN5MpnMqlIOV0vVzCuVCpVKhWKxuGbxylarlZaWFrq7u/F6vcRiMU6dOqXr9VAUBY/Hw8DAALt27UKSJE6ePMnp06fX7L34ahX3u+WVUovFQmtrK9euXVtrKWuCzWbjxRdf5Hd+53fI5/McOnSIX/3qV6vykFWbaWdnJy+88AIPPPAA/f39GAwGXn75ZV5++WUtKqLehV6tViv9/f1s2bIFWZbp7+/nySef1OJ89Xxg2traeO6557RYY4PBQFNTE7FYTLcHx2g0apEpsixrSQCxWIxsNqubDqfTSX9/v5ba6vF4cLvdlEoljh49qkuHW01i2LZtG9/85jd5+umnURSFt956i7/6q7/i8uXLur3WKcsyDQ0N7N+/n4cffphQKMTx48e5cuUKS0tLK67oXgscDge9vb1s2bKFqampNTHTzs5Otm3bRqlU4uLFiywtLekaBa6qKo8//jgbNmzg2rVrxONx2tra+NrXvsabb77J1atXV1S0e0VmWp3St7S08MUvfpGenh4ymQzLy8t0dnbyyCOPMDU1xfj4uC4Vs6uRGEajkcXFRSKRCKqq0tnZqVUx1wOz2czjjz/Orl27OHr0qJa15HQ6sdvtujSQamCbzWbD4/FoyY/5fJ433niDq1ev3rI4c61QFIWNGzeyefNmKpUKpVKJZDJJPp/H4XDQ3NzM6Oho3XVUtRgMBsLhMMPDwzgcDrxeL3v27GFiYkKX66GqKvv27eORRx5hz5499PT0YDAY2LFjB6+88grHjh1jZmZG1xlEU1MTf/Inf8KePXtIJBL88pe/xGAw6FqBLRAI8NRTT9HS0oLRaKS/v5+5uTmOHj3K4uIi+Xy+7h3MwMAABw8e1KKHqoF6bW1tvPjii/zqV7/izJkzd+xltzRTp9Op/SBZlpEkCYfDwfPPP09XVxfhcBij0Ui5XGZiYgKr1YrRaNRtRFjVls1mSaVSmM1mvF4vi4uLNDU13bbKfK3w+/0cPHiQlpYWzGYziqJQLBYxmUy6JrZWp/eVSgWn08lDDz3Epk2bmJ+fZ3x8XBcNfr+fAwcO8MgjjzA5Ocn09LSWmrq0tITH49G1jSSTSU6ePMnU1BQejwer1UqhUMBisehipoFAgIcffphAIKDNWPx+P1arVQs81HvK/+yzz/JHf/RHDA0NMTw8jNPppKGhgWAwqJsGh8NBU1MTfr8fh8PB1q1bSSaTtLS0MDU1xfnz5+s+Wrbb7VgsFmRZZnl5GbfbjcFgoKGhAZ/Px+zsLJOTk3d8XW5ppp9sbFXjqoaC9fb2Isuylu9TjZF1u92YTCZdTKxYLBKPx4nH4/h8PjZv3ozD4aBYLBIMBnWbOhmNRjweD62trTQ3N5NIJEilUrrlw8M/RipX/4RCIV5//XWOHj3K5cuXdckYgusjZJvNpkUqG41GFhYWtA4lEonoshFVTV/IZrMEg0Gi0SgNDQ04nU5CoZBuI8FyuaxFYmSzWdLpNCaTiVAoRCQSIZfL6W6mlUqFyclJLl26xPj4ONlsVvdNqKph/tmf/RldXV3Mz8+Tz+eJxWIEg0Fd7s/c3ByFQoHm5mZtryMQCBAIBBgfH0dVVaxW6x1/3i3N9EbD/lwux4kTJ+jq6qKzs5NwOEwmk0FRFC5cuMDJkyd1M5BcLkc0GiUWi1EsFlEUhZ6eHqxWq3Zz9CCTyXDkyBFtnc7v95PJZLQUSr1YXl4mk8lgMpkIBoOagU1OTup2LRYXF3nppZfYtm0bW7Zswe12E4/HsVqtmEwmlpaWdBuV5vN54vE4ZrOZQqGA0WikWCySSqV0M7BYLMbZs2cxm82USiWy2SxGo5FwOMzs7OwdZR/VmlOnTvHcc89po+JYLPap/Ck9KBaL/OpXv2Lfvn3Mzc3xve99j+npaa2D0YNQKMTly5e1QZDb7cbtdmO1WhkaGmJ+fn5FG6arji3p6OjgmWeewel0ksvlMBgMnDlzhmPHjt3QhOv1KpjVaqW9vZ2Ojg7a2trw+/189NFHnDlz5oYGUg8dJpOJxsZGtm3bhtvtZnl5mUgkwtDQEHNzczccIdfrelQ3oaxWq1bVfWFh4aZmWi8dO3fu5Ctf+QpNTU3Mz89z9epVTpw4wejo6A2jnuulw+l00tHRgdPp1EYZi4uLjI2NkUwmddPR3NxMb28vmzZtorW1lcuXL/P+++8TCoVq3j5up8VkMvHFL36Rvr4+Tp06xccff8z8/PxNP6uer3E+8MADmEwmjhw5cttBWD1y5BobG9m0aRO9vb0EAgFt8/bq1au89957jI+P/4af1TwDymg00t3drYlSFIXx8fGbjsTqeUNkWcZoNGpnxNLp9E0X0+udcFilXC6vWaCeqqooiqIlLN7qHtdLhyRJWCwWWlpacLvdhEIhZmdnb3pN6nk9PB4PnZ2dGI1GUqkU0WiUhYWFG2qpdztVFAVVVbHb7UQikZtOZ+v9bn5Vx50sRdU7sbVSqdzRTKFeOmRZxmAwaD5is9kACIfDN7w/NTVTSZIwmUyUy2Vtyna7vO27vUiB0HFv6zCbzVr44q3Oeep1PQwGA+Vy+aYdnSh08tunY1XnTKtrUJ907bvlELJAcCNyuZxua3F3ggiCvPdYlZnmcjmRYyMQCASfYFXnIYSRCgQCwae5vyscCAQCQY0Q6aQCgUBQA8TIVCAQCGqAMFOBQCCoAcJMBQKBoAbUJJ20+ibFWrxps1KEDqHjXtdxN2m5n3TUZGQqDuzfmvs9vkQguB+oiZlKknTf58jcCrPZvNYSBILfwGKxrGl2271GTRzQYDBgsVhq8VH3HEajEbPZLDobwV1HY2Mj69atW2sZ9ww1ecKrVfgFn0aWZWw2m671M+9G7oaORFXVu6KNVisU3S3oHYB5L/OZxviyLGOxWHC73bqmTt5Ih9lsJpvNrumrrrIsax2LJEl4PB4ymYxuxbI/iclk0uJT1ioNU1EU/H4/drudxcVF4vG47hpkWaaxsZHGxkYKhQKTk5O6F0KuYjQa2bJlCwAXLlxYk3bxSS1+v59wOLxmGu5WJElalY+s2EyrwVsul4t169bR29tLuVzm6NGja1IAxWAw0NLSgsfjIRQKEQ6Hda/Io6oqra2tdHV10dTUhN1uJ5fLMTs7y8mTJ3XVoigK69ev54tf/CIdHR1cuHCBl19+mampKV11+P1+du7cSV9fH6VSidHRUY4dO6a7ke3du5cDBw4QiURIJBKsW7eO06dPMzs7q6sOr9fLk08+yXe+8x0A/vIv/5IjR47oqqGKwWBgy5YtHDx4UIt00TMV9G7DbrfT39+PLMuYTCYkSeLcuXMrbqsrNlOz2cyWLVt47rnn2L17Nw0NDQwNDWlFd/Usc2az2diyZQvr1q3D5XIBMDY2xoULF3SLN5Ykie7ubh5//HGampro6Ohg/fr1qKrKO++8w8jIiG7RJbIss3v3bv71v/7X7Nu3j1gsBsD777+vm5lKksTAwABf+tKX8Pv9DA0NsbCwgMFgwOFw6Gqm7e3t/NEf/REAv/jFL4hGo2zYsIE///M/59/8m3+j2xTXaDTy7LPP8tRTTzE9PY3P5+M73/kOiUSCwcFB3QcgLpeL/v5+vF4vdrudxx9/nLNnzxIKhe6qMoV6sXv3bv7gD/6Acrmsxcq88cYbvPLKKyvKolqVmb744os888wzFAoFAoEA2WyWjo4OrFZr3W9GNXrCYrHwzDPP0NfXx9jYGNFoFK/Xy9NPP8327dv56U9/ytjYWF21wPUHZf369ZTLZa5evUoymcRqtfLII4/w6KOPcujQIRYXF3XJPWpsbOTLX/4y7e3tfPTRR0xOThKJRLSYDD1CytxuN1/4whd48cUXOXnyJAsLCywuLlIoFPD5fCwsLOgyczAYDGzduhWr1cqPf/xjPvjgA5qbm9m1axf9/f34/X7dOpiGhga6u7s5ffo04XAYt9tNT08PX/jCF0in04yNjelqqAaDgWQySTgcpqWlhYGBAdrb2xkeHubixYt1H7Xb7XaamppwuVzYbDbcbjdNTU0sLS1x4cIFxsfHdcsJ8/l8vPDCC6xfv56TJ08yOztLa2srjz76KEePHl1RYuuKzdTn82EymRgfHyeVSnHp0iVyuRwWiwWn08nS0lJdG0a5XMZisWiZ1wDxeJxkMonRaKRUKqGqqi6bPpIk4ff7aWxsZG5ujlQqpaWStrS00N/fz8MPP8zo6Cizs7N17WgURWHz5s0Ui0Veeukl4vE45XIZq9WK2+3WbfPFbrfT09NDe3s7Z86coVwuUywWyefzGAwGLU6l3lQqFUKhEC+99BJHjhwhmUzywAMP8NWvflULbtOLSqVCOp0mGAySTCYpFAosLS3R3t7Oxo0bCYfDuq4nV3PbvF4vn//853nzzTeJRqM0NTVx9uzZun9/uVzG7XbT3NyMz+fj0Ucf5YEHHuCdd965YeZSvZAkiaamJhoaGrTU5ap/7dy5k/Xr16+o81+RmSqKgtPpJBqNoigK6XSaQqGAqqpaBni9qVZMv3TpEoODg3zzm99k27ZtnD59mmg0SrlcJhqN6jKFq1QqpFIpwuGwZhILCwtUKhVGRka0aIpqxEs9UVWVbDbLuXPnCAaDmM1mDAYDHR0dxGIx3TagqtHfExMTvxEhbDAYsNvtuiSllstlZmZmsNvt9PX1USwWaW9vJxKJcOjQIV03fxKJhDbaq1QqqKpKLpfj2rVrDA4O3jDYr560tbXR2NjIlStXeOONN5AkiUKhwPj4uLY0VE+y2SwLCwsEAgFMJhOVSoWZmRmGh4dZXFzUdbNUkiSmpqaYm5tjenqaxcVFwuEwkiSRTqfx+Xwkk8kbhkD+OnfsfgaDAZvNRi6XY2hoiGg0qo12FEVheXkZRVGQZVmXniUej/Pyyy+zdetWnnjiCdra2sjn8+TzeRYXF+/ox9eCZDJJKBRi3759VCoVotEopVKJq1evcvHiRQ4fPszo6Gjdpy3ZbJahoSH8fj8Wi4VkMonFYkFVVYLBoG69/dLSEu+88w52ux1VVfH7/eRyObLZLJlMBlVVb5sXViuqJ0waGhqIxWJcuHCBa9euMTk5qauZplIpLl++TGdnJwaDQQt+HBoaYmpqSlfzUFWVtrY2WltbmZ6e5uTJkzQ2NpLL5bhy5You16VSqTA7O4ssyySTSYLBICaTiatXrzI/P6/bkkelUiGTyRAIBEin08iyTKFQYHZ2llOnTjE7O7siLXdspqVSSVvfiUQidHZ20t3djaqqRCIRrl69Sjgc1vVc5eTkJP/9v/93VFVl69atABw6dIgTJ07osj4I10dA165dY8eOHaxfv55gMMj8/DyvvfaadrpAr8YRiUQIBoPs3buXVCqF1WrF4/HoMtqoUigUOHnyJOFwmA0bNuB0OjGbzSwtLTE6Oko0GtXteiwvLzM/P09fXx+Li4vMzs7i9/uJxWK6rlFWKhXGxsbw+/34/X6KxSLT09MMDw/r8pxIkoTNZsNkMmGz2RgeHv7U7CAYDHL06FEWFhbqrqVKqVRiamqKUCikJZRWl4P0ZHZ2lh//+MesX7+eRCJBLBZjamqKpaWlFX/WqtNJrVYrjY2N5PN5YrEYmUyGSqWiRcguLy9/Kn2xnjGtPT09PPbYYxgMBt5++21GR0frkvp4Mx2KorBu3Tq6urqYmZlhdHT0tsfE6nU9zGYzmzdvpr29HbfbTSaT4e23377pOeB6Rj1X43MBbe30ZtRLx/bt23G5XMzMzNDR0UFTUxMLCwtMTk4yMTHxG5rqWUyjvb2dQCBANBplfn7+lmvotSp04nA4cLlc5HI5bb22+v+3trbidDoJh8O6PzOroV46qmv55XKZUql02w6uplHPVYxG4w1z2auH1iuVSt3NtIrH48FoNN52zaVeOlRVRVXVO16r1aOBGo1GTCYThULhpg/uvf6gVDPQ0+m0tq5fLBYpl8uk0+nfaCv1zoiHO0smrZWZ3uo7qyayvLwsKr7VQMdnMtNaCLgTfht0VB/StdaxUoSOe0/H3aTlftKx9i9NCwQCwT2AMNMaodeGl0AguDsRZioQCAQ1QEQ9CwQCQQ0QI1OBQCCoAcJMBQKBoAbUJJ30TrjbjzUIHULHvaLjbtJyP+kQI1OBQCCoAcJMBQKBoAYIMxUIBIIaIMxUINCRalTI3ZCUKqgtn8lMq2mca4EkSbhcLlRVXZPvv1upPqSSJIkI7puwVtdEVVVaWlrYs2cPXq9X3Bvuvujrz8KqS+N7vV56enpwu90Eg0GmpqZ0rxju8/l44IEHiMfjZDIZpqam1ixyWpZlHA4HxWJRK0eoB9XKP5VKBY/Hg8vl0qJbDAYD6XSaWCxGPp/XNT3W5XLh8Xi0guHFYpHl5WUtYkYv7HY7LpcLs9mMxWLB6/USi8W4ePGirkWZDQYDra2tuN1uAoEAzc3NlEolLeZGT2RZxuVyaRX2M5mM7om+cD0vbPPmzbS0tGhlCa9du/ZbG+q3KjO12Wxs27aNhx56iIceegi3282rr77KD3/4QyYnJ3V5YCuVCl6vl29961vYbDYaGxsJBoP8j//xP3jnnXd0zyT3eDz8wR/8AT09Pbz33nu89957umSSl8tlZFmmubmZzZs343K5iMfj5PN5lpeXkWUZRVEIBoNcuXJFl6Ayi8XC888/T3t7O6FQiOXlZcxmM5Ikcfz4cS5evFh3DXA9YPBP//RP2bx5MzMzMwAMDAxw+fJlvvvd7+oab+zxeGhoaMDj8dDT00M8HieVSmGxWEin07pq8fv99PX10dDQgNvtJhqNcuTIEV1zsRobG3nyySd55JFHtHSISqXC//yf/5NXX31V1w7GYDDQ29vLpk2bcDgcTE1NMTg4uOJC5iueoxsMBrq7u2lqaiIejxMKhXC73XzjG99g69atuk37ZVnWilOPjo4yODjIwMAA//7f/3sOHDig+/JDX18fTzzxBA888ADf+MY3+NrXvkZDQ0Pdv7dSqZDNZolEIlQqFS0jS5IkTCYTRqORQCBAIBDQ5ZpUo54DgQDFYhGbzYbdbkdRFCwWi67tY8OGDezbtw+bzYYkSeTzeUKhEM3NzezYsUOXzLIqdrud9vZ2bTbX0tKC1+vFZrPpOipUFAW3243VasVqtbJjxw7+7b/9t3z5y1/GZDLposHj8bB37166u7sJh8Ncu3aN6elpnE4njzzyCG63Wxcd8I/t5MUXX+Rf/at/xV/8xV/wve99j6985Ssrbh8rbtlOp5O+vj6ampqQZZlgMMilS5fI5/N4PB7d1oEkScJoNDI3N8fc3BxXrlzh0KFDpNNpfvd3fxefz6eLjioej4epqSneeustrl27xqZNm3j88cd1W9NNJpOMj49rvakkSZjNZtxuNw6HA0mSdJnWKopCe3s70WiUhYUFLQeq2l5SqVTdNXxSx+nTpzl//jzLy8vk83mCwSDlcpkNGzbovt7e0dHBM888Q3d3t5ZqazabdR2FKYqC0WgkHo8zPz/P9PQ0hUKBPXv20NjYqIsGo9GI2WwmGAwyPj5OOBwmm81SLBZZv349AwMDuq2jejwetm/fTm9vL8VikUgkooVkrvR5WXHXXP2R1UiKWCympRrqOVWB62XvGhoaUBSFfD6vZes4nU66u7tZXFzUTUsymcRgMJDP57XY6eofPZYcyuUy4XCYQCCgrRO2trbS0tJCOp3mwoULuo2AyuUyBoMBs9lMa2srHR0deDweTp06pVsbKZVKTE9P09vbi6IoWK1WZFnG7XZrJlbvjr+6XlwNsdu5cyfbtm2jVCphMplIpVKMj4/raqb5fJ5KpYLZbKZQKHD16lV+9rOf3TZGpZbkcjlSqRSFQgG73U53dzcDAwN0dXWxtLSEz+fTJZhTkiQURSGVShEMBkkkEuTzea5du8aHH3644u9fsZnG43GuXr2Ky+XCYrGQzWZJJBIYjUYmJyd1W9QvlUoMDg7y0EMPsX37dm0TyuFwaDlUenL58mUuXrxIf38/mUyGyclJhoaGdF1Ml2WZpqYmenp66OnpYcOGDTgcDl599VXdInSLxSKzs7Ps3r0bn89HX18f27ZtI5VK8eqrr+pqpidOnKC1tZW9e/dit9vp7+/Hbrdz9uxZjh49WvPwNoPBgMViwWazaZ17Pp+nUCgwOTnJD3/4Q86cOcPnPvc5ZFkmEokwPT2t6zS/UqlQKpXw+XzaaPDChQta4rAepNNp0um0NmtyuVw0NTVhNps5fPgw165d06WDqVQqhEIhTp48iaqqdHV1sbi4yDvvvEMoFFrx563YTAuFAleuXCGTyTAwMEBDQwOSJDExMcHo6KiuO6QTExP8r//1v/jjP/5jNm/ejNfrZWJigp/97GcMDg7qpgOuxwr/+Mc/5sCBAySTScbGxnR/UEqlEplMBlmW8fl8BAIBZmZmOHr0KHNzc7ptDF69epW5uTl6e3tJp9McP36cS5cu8f777+u6MZjNZvnwww/xer24XC5mZ2c5fPgwP/nJT+piHDabDYfDQSqVIh6Pf+rfTU9PMzMzw5EjR3jrrbfo7e3lwoULpNPpmuu4HdVBj9frZXl5mdnZWcLhsG5ttVQqMTMzQ09PD42NjaiqysjICN///vf5v//3/+oa9wwQCoV45513tIj01Z42WXUGVHXNsqGhAYvFQiwWu2VUbD1TMK1WK01NTSiKQigUIpFI3NTU610sobpoXSqVdA8pqx7P6u7upru7m0AgwPj4OKdOnSIej99QT72uR39/Pw6Hg2w2y/LyMgsLC7eMAK/nfbFarQQCATKZDLFY7JaG/ll0WCyWislk+g0j/XUkScLpdFIul2/64Na70En1HDLcPuCvHvfG6XTS1dWF0WikXC6TSqWYmZm5ZSDl3V7oRATq3YM6qsscRqORXC53y+lsPdNa7yQ2t946Vspn0WE2myvlcvmORt/VLPt0Ol3zTu4fPv+uuCa36vglSVrRaPhubyPCTIUOoeMe03E3abmfdIh38wUCgaAGCDMVCASCGiDMVCAQCGqASCcVCASCGiBGpgKBQFADhJkKBAJBDRDppEKH0HGP6bibtNxPOsTIVCAQCGqAMFOBQCCoAcJMBQKBoAYIMxUIBIIasKrcBkVRKJfLWoGGtTqrWq0YpSgKiqIQi8XWJBjsRkiStGbXpZoaq3dQ292IwWDAaDRqRTWWl5fX7L5U9ciyrBWHXiuqz8xva3hdragWUs/n8yQSCQqFwqrbx4rNVJIk7HY7TqcTQKssv7y8rPvDa7Va8fv9OBwO7HY74XCYYDC4JjUiP4nFYqG5uZlkMqlrtX8Ak8nEnj17aGlp4cSJE8zMzKxJByPLMmazmXK5rFV31xur1cqDDz7IwYMHkWWZ6elpTp06xeDgINlsVlctqqrS3t7OunXrcDgcxGIxPvroozUxs/7+fg4cOEAgEODdd9/lwoULa2qqkiTh8XgAWFpa0q2tyLJMa2srXV1dmM1mlpeXmZyc5OrVq6uqu7viqlGqqhIIBGhvb9eiIKrV1aenp29a7q3WxxqqiZzVeGO/348kSczPz3PlyhVisVjNddhstkqlUqFSqWgpn5IkaXHLdrsdr9fLvn37eO655/i7v/s73njjjRs21Hoc8zAajbz44os8/vjjWgLC4cOHefvtt29qqPU6btLV1cXTTz+N0+lkenqa48ePMzExcdPPqrUOVVV59tlnefDBB3E6nSwuLlIsFvF6vZw5c4Zf/vKXN0zjrFftzoMHDzIwMIDD4cBmsxGNRnnttde4cOHCDcsU1utoVGNjI3/1V39FU1MTs7OzTE1NceXKFU6fPs3MzIyuNW/b29vZvXs3PT09tLa2Ui6XOX36NG+//bYu98Zms7F3714CgQDZbJZKpYLD4SAcDvPhhx+u2MtWPDKt5tqUSiWMRiPt7e3s2bOHcDjM//k//4dr167pVm3fYrHgdDpxOp1YrVbMZjMej4disciVK1dqPo369YtrMBhwuVxahfVq/MLAwIBWFNlkMunW62/fvp0/+ZM/YW5ujvHxcWw2G//kn/wTZmZmdItXrrJhwwaeeuopUqkUPT09bNq0iZ/85CdcunRJl5GH3W6npaWFK1eukM1mMZvNmM1mXC4XBw8eZHBwULdo45aWFp5//nnMZjPJZBKHw0FzczOjo6NcunRJt+fFZrPx7W9/m4aGBsbHx5mYmCAWi9HQ0MDTTz/NO++8o1tUe2dnJy+88ALbt2+nv7+fzs5OJEkiFovxzjvv1P37VVWlu7sbr9eLwWCgWCySy+XweDw88cQTZDIZTpw4saLZ9oo3oMrlMsVikWw2q0UKd3d388wzz7Bp0yZt+l9vKpUKxWIRl8tFS0sLjY2N+Hw+fD4fdrsdi8VS88C0Uqmk/SmXy5RKJYrFojYlqFYNHxoa4ic/+QnDw8O6TbFVVeXBBx+ku7tbCzdMJpP4/X6ee+45jEajLjo+qadQKGipoF1dXfze7/2ebjG+1eTcxcVF8vk8iqJgs9moVCr4fD76+/t1ScCUJImGhgba2tpobW3F5/PR29vLY489RktLi25pvgCbNm3ihRdeoFAoEIvFSKfT5HI5SqUSvb29DAwM6JKd1tDQwMGDB+no6MBoNBIKhTh27BivvPIKs7OzuiwXGo1Gmpqa8Hg8BAIB/H4/LpcLt9vNxo0beeKJJ1bcVlc8Ml1eXiabzZJOp7FYLITDYU6cOIGiKGQyGcxmM7Is1723rVQqJBIJXC4Xu3btorW1lXw+z9WrVykWixgMBq3HqRflcplsNoskSaRSKRRF0QLj0uk0yWRS1/XKTCZDsVjEZDJpozCHw8GOHTvw+/3Mzc3ppmVqaop0Oo3T6cThcGjTOL0ifCuVCna7XYs2bmtro6+vj/7+flRV1c3EZFnG4/GQSqWIRqNEo1HC4TDvvvsu7733nm77DA6HA4fDQaVSYf369YyMjGgbuK2traiqyvT0tLZ8VS+MRiN79+5l165d2O12FhcXsVgsDAwMEIvFyGQyt4wuqRXFYpFYLIbdbmfDhg2kUilCoRCBQEAL+lupjhWbaaVS+VRujcFgYHl5mXQ6zfz8vK7mEY/HCYVCtLS08OCDD3L+/Hk+/PBDksmkbg9LtfGpqqqdciiXy+RyOS06Vg8KhQJvvPEGzz77LOvWrSORSNDT00NXVxeZTAaLxaKLjipjY2OcPn2a3//936ejo4OFhQVee+01lpaWdPl+m81Gd3c3nZ2dmM1mWlpaaG1tpbm5mStXrhAMBnVpq5VKhdnZWc6fP4/NZiMQCBCJRBgcHNQ1zTeZTHLs2DH+4i/+gi9/+cs4HA7a2towmUzYbDbefPNNxsbG6q6jWCwSjUYpFou43W6mpqaYnJwkl8tpz44e5PN5BgcHyWQy2O129uzZw/79+3G73UQiEY4dO7bijuUzBeqpqorNZsNkMmkGksvlbiiiXovYjY2NPP/88/T29jI4OMjg4CDhcJhMJkMymfyN9Z966bDZbDidTkwmE4VCgXQ6TSqVuunIo146du/eze/8zu/g8XgwGo2kUik++OADjh49Sjgc1k0HgM/n44UXXmDnzp3aNO5mvX0tdRgMBtra2mhvb9eyhvx+Pw0NDRgMBpaWlvjggw+YmZmpq44qFouFjRs30tXVRX9/PyaTiTfeeIMTJ07c9LPq+W6+1+ulubmZtrY2uru7mZyc5IMPPtDl3sD10XpHRwcbNmzQ9hai0SiFQoFsNkswGNR1I8zv9/PQQw/xz//5P6enp4df/OIX/Mf/+B9vGhBatwwoWZYxGAy3DU+r14VQFAW3261N6QuFwk0NvZ46ZFnGZrNhs9mA61PudDqt+y56tZNTVVXLSC8Wi586F6yHjirV84yFQuGWI8F6PLCA1iaraZzVGcvN0mPr2T4MBgNOpxOPx3PbI3x6FDqpHl8rlUprErr4ySWfO5kl1LOtqqrKQw89xKOPPqp1dDfzRhGop4OOauM0m80Ui0VtDVNvHStB6Lj3dNxNWn6bdHg8Hvbt28fJkyeJRqMr1rGqN6AEN6ZcLmsGWh2tCwSC3w5SqRTz8/Or3oQTZloH6r0jKhAIak+hUCCVSq3q7ScQhU4EAoEAuH5sq3rudjUIMxUIBAKuzygTicSqz/6KdFKBQCCoAWJkKhAIBDVAmKlAIBDUAGGmAoFAUAOEmQoEAkENEGYqEAgENUCYqUAgENSA/x8Tz7hF7X6kLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.15, 0.15), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(1.0, 1.0), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=scl1'\n",
    "model.forward = model.forward_latent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.539, loss_val: nan, pos_over_neg: 1.0591704845428467 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.0583, loss_val: nan, pos_over_neg: 3.4122021198272705 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 6.6349, loss_val: nan, pos_over_neg: 6.16873025894165 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.462, loss_val: nan, pos_over_neg: 27.448928833007812 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.3978, loss_val: nan, pos_over_neg: 28.65560531616211 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.3227, loss_val: nan, pos_over_neg: 31.759992599487305 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.272, loss_val: nan, pos_over_neg: 43.032222747802734 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.2386, loss_val: nan, pos_over_neg: 64.26173400878906 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.2282, loss_val: nan, pos_over_neg: 68.04695892333984 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.2025, loss_val: nan, pos_over_neg: 84.34514617919922 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.1723, loss_val: nan, pos_over_neg: 97.43470001220703 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.1589, loss_val: nan, pos_over_neg: 104.25337982177734 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.1465, loss_val: nan, pos_over_neg: 100.4830551147461 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.1162, loss_val: nan, pos_over_neg: 188.6045684814453 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.1021, loss_val: nan, pos_over_neg: 277.2494812011719 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.0924, loss_val: nan, pos_over_neg: 227.0287628173828 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.0787, loss_val: nan, pos_over_neg: 212.0416717529297 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.0614, loss_val: nan, pos_over_neg: 220.44960021972656 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.0487, loss_val: nan, pos_over_neg: 255.9558868408203 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.0391, loss_val: nan, pos_over_neg: 301.6666564941406 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.0257, loss_val: nan, pos_over_neg: 248.2299346923828 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.0127, loss_val: nan, pos_over_neg: 446.485595703125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.0101, loss_val: nan, pos_over_neg: 515.9564819335938 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.9957, loss_val: nan, pos_over_neg: 670.380126953125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.9963, loss_val: nan, pos_over_neg: 492.6869812011719 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.9804, loss_val: nan, pos_over_neg: 520.086181640625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.9736, loss_val: nan, pos_over_neg: 586.4039306640625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.9727, loss_val: nan, pos_over_neg: 1101.8399658203125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.9566, loss_val: nan, pos_over_neg: 2460.12646484375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.9554, loss_val: nan, pos_over_neg: 824.3259887695312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.954, loss_val: nan, pos_over_neg: 714.6239624023438 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.9498, loss_val: nan, pos_over_neg: 811.2545776367188 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.9413, loss_val: nan, pos_over_neg: 452.0338439941406 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.9324, loss_val: nan, pos_over_neg: 612.6111450195312 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.9257, loss_val: nan, pos_over_neg: 1357.3521728515625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.9293, loss_val: nan, pos_over_neg: 463.7580261230469 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.9241, loss_val: nan, pos_over_neg: 431.4842529296875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.9209, loss_val: nan, pos_over_neg: 683.9564208984375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.9101, loss_val: nan, pos_over_neg: 880.228759765625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.9173, loss_val: nan, pos_over_neg: 309.3966369628906 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.9134, loss_val: nan, pos_over_neg: 349.4871826171875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.9096, loss_val: nan, pos_over_neg: 292.2322082519531 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.9021, loss_val: nan, pos_over_neg: 303.9170837402344 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.9044, loss_val: nan, pos_over_neg: 223.17074584960938 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8972, loss_val: nan, pos_over_neg: 614.7269287109375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8955, loss_val: nan, pos_over_neg: 455.8093566894531 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8974, loss_val: nan, pos_over_neg: 442.62994384765625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8894, loss_val: nan, pos_over_neg: 345.3471374511719 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8883, loss_val: nan, pos_over_neg: 352.8155212402344 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8822, loss_val: nan, pos_over_neg: 799.648193359375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 1105.177978515625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 613.6830444335938 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 422.37652587890625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 630.216796875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 275.9462890625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8695, loss_val: nan, pos_over_neg: 1217.2406005859375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8653, loss_val: nan, pos_over_neg: 858.3905639648438 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 984.2132568359375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 633.0803833007812 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8624, loss_val: nan, pos_over_neg: 469.5979919433594 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 667.4114990234375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 1070.2200927734375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8522, loss_val: nan, pos_over_neg: 1046.255859375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8502, loss_val: nan, pos_over_neg: 2954.041748046875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.8523, loss_val: nan, pos_over_neg: 434.0217590332031 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 693.3618774414062 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 1354.54638671875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 629.07421875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 388.3677978515625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 469.2252502441406 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 359.6401062011719 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 407.4078063964844 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 406.1896667480469 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 299.4556884765625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8389, loss_val: nan, pos_over_neg: 392.82330322265625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 410.0077819824219 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8379, loss_val: nan, pos_over_neg: 267.39263916015625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 515.9583129882812 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8353, loss_val: nan, pos_over_neg: 231.5220184326172 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 362.4643859863281 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 235.3614959716797 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 412.7865295410156 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8231, loss_val: nan, pos_over_neg: 283.61053466796875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8276, loss_val: nan, pos_over_neg: 505.81304931640625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 433.9123229980469 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 451.1730651855469 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8221, loss_val: nan, pos_over_neg: 737.2960205078125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 281.8869323730469 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 459.01019287109375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 392.1014099121094 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 272.3049621582031 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 481.13214111328125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 280.2845458984375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8133, loss_val: nan, pos_over_neg: 378.0141296386719 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 228.20228576660156 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8116, loss_val: nan, pos_over_neg: 476.0284118652344 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 283.3215026855469 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8126, loss_val: nan, pos_over_neg: 252.16876220703125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 272.88494873046875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 284.25701904296875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 197.28567504882812 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 275.7304382324219 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 221.133056640625 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 202.0402374267578 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 196.330322265625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8011, loss_val: nan, pos_over_neg: 336.5147399902344 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 292.11883544921875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 245.75254821777344 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 242.7032470703125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 230.75149536132812 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 322.1445007324219 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 253.11441040039062 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 236.46673583984375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 449.6138916015625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 236.97312927246094 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 206.96820068359375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 303.0175476074219 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 302.0340270996094 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 317.5784606933594 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 566.7125854492188 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 366.2213439941406 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 292.4945373535156 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 351.0152587890625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 561.3176879882812 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 223.51243591308594 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 313.134033203125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 327.4864501953125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 247.0108184814453 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 450.4153747558594 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 214.62083435058594 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 229.69866943359375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 445.2557373046875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 274.4985046386719 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 280.2571105957031 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 387.3305358886719 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 285.9170227050781 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 353.0759582519531 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 289.26220703125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 241.57569885253906 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 333.3772277832031 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 238.17678833007812 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 349.5067443847656 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 351.0407409667969 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 276.3603210449219 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 380.2336730957031 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 278.848876953125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 354.4880676269531 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 250.54859924316406 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 252.77847290039062 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 454.88958740234375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 287.68603515625 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 522.801513671875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 288.0786437988281 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 278.1844482421875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 238.36431884765625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 245.9996795654297 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 446.9671630859375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 203.57498168945312 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 319.3038024902344 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 293.9490661621094 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 280.6375427246094 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 281.28961181640625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 273.0424499511719 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 443.0677490234375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 266.17626953125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 324.44268798828125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 333.0598449707031 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 281.7242736816406 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 405.7974548339844 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 344.9261779785156 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 481.53680419921875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 261.0337219238281 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 341.19989013671875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 288.5988464355469 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 261.7371826171875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 300.3514099121094 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 446.3343505859375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 318.4781799316406 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 399.8107604980469 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 570.9931030273438 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 282.2618103027344 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 765.285888671875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 411.7437744140625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 290.22503662109375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 345.719970703125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 494.11151123046875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 360.5890197753906 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 503.9565734863281 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 574.0564575195312 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 580.3006591796875 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 543.9219970703125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 453.84088134765625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 343.22247314453125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 657.8081665039062 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 699.5778198242188 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 435.004150390625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 431.5851745605469 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 585.9666748046875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 482.0037841796875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 363.23876953125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 311.08990478515625 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 702.5650024414062 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 264.4759521484375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 326.3577880859375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1122.3818359375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 351.5509033203125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 461.26971435546875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 527.4051513671875 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 587.7734375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 457.62200927734375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 458.5024108886719 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 522.9188842773438 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 412.9024963378906 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 380.289306640625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 630.7931518554688 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 438.6168518066406 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 391.0953674316406 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 488.6028747558594 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 730.878662109375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 396.7507019042969 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 509.6579895019531 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 593.4190063476562 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 515.050537109375 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 360.1600341796875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 658.0533447265625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 506.0106201171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 455.7396545410156 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 412.2106628417969 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 595.0899658203125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 381.5625305175781 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 388.6249084472656 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 620.2337646484375 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 299.41912841796875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 263.11529541015625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 441.39544677734375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 313.1983337402344 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 277.2629699707031 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 434.26617431640625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 353.3232421875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 346.2769470214844 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 347.4309387207031 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 252.1709442138672 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 458.9493408203125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 308.8638916015625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 463.05419921875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 273.8628234863281 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 306.80889892578125 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 346.7381591796875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 456.7558288574219 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 506.2754821777344 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 337.66046142578125 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 707.8040161132812 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 534.4109497070312 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 357.9922790527344 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 592.9376831054688 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 376.7240905761719 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 396.0650634765625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 484.5465393066406 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 550.333984375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 340.58984375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 359.25250244140625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 480.56036376953125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 344.3847351074219 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 269.52001953125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 394.50537109375 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 328.4510803222656 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 375.74334716796875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 309.855712890625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 479.0 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 368.1222839355469 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 413.83917236328125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 642.80322265625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 404.04638671875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 460.0336608886719 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 577.565185546875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 410.9854736328125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 754.56298828125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 399.96063232421875 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 361.617919921875 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 402.2992858886719 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 266.67010498046875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 264.00042724609375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 285.35736083984375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 327.36956787109375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 425.0357360839844 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 309.2012939453125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 290.6806640625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 322.08056640625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 336.3354797363281 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 363.9482421875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 364.5467224121094 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 312.830322265625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 491.2886962890625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 617.9505615234375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 321.5306701660156 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 505.686279296875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 730.7528076171875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 967.4829711914062 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 509.4280090332031 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 366.3042907714844 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 456.64447021484375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 512.4690551757812 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 595.38671875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 469.9124755859375 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 431.3029479980469 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 737.4884643554688 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 536.807861328125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 546.3999633789062 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 345.6302795410156 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 1147.4093017578125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1477.8702392578125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 365.3201904296875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 961.9419555664062 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 489.55267333984375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 613.4428100585938 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: 390.5010986328125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 490.5531921386719 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 725.5540771484375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 752.8965454101562 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 406.74853515625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 794.9226684570312 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 932.2721557617188 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 301.6490783691406 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 739.5684204101562 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 456.42071533203125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 407.7880554199219 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 515.2813110351562 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 345.67901611328125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 358.2624816894531 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 368.5274963378906 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 521.365966796875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 467.7925720214844 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 682.3539428710938 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 771.6129760742188 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 284.3634033203125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 656.9957275390625 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 434.2204284667969 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 903.4214477539062 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 443.8840026855469 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 280.33721923828125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 1204.7369384765625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7404, loss_val: nan, pos_over_neg: 698.19921875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7412, loss_val: nan, pos_over_neg: 508.0596008300781 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7405, loss_val: nan, pos_over_neg: 620.3408813476562 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 749.8292846679688 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 1066.90087890625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 368.0664978027344 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 870.7378540039062 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 411.9220275878906 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 556.2747192382812 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7378, loss_val: nan, pos_over_neg: 1407.787353515625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 405.31787109375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7392, loss_val: nan, pos_over_neg: 517.110107421875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 520.7637329101562 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7412, loss_val: nan, pos_over_neg: 588.3126831054688 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 486.49334716796875 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7414, loss_val: nan, pos_over_neg: 581.1214599609375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 700.2105712890625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7379, loss_val: nan, pos_over_neg: 705.2399291992188 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 531.97314453125 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7395, loss_val: nan, pos_over_neg: 813.309326171875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 821.7017822265625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7365, loss_val: nan, pos_over_neg: 1879.73291015625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7416, loss_val: nan, pos_over_neg: 516.0938110351562 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7407, loss_val: nan, pos_over_neg: 734.952880859375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7385, loss_val: nan, pos_over_neg: 719.61962890625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 821.7662353515625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 662.0809936523438 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7354, loss_val: nan, pos_over_neg: 1638.9449462890625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 894.9892578125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7416, loss_val: nan, pos_over_neg: 491.62921142578125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7369, loss_val: nan, pos_over_neg: 802.8861083984375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 504.1235656738281 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7396, loss_val: nan, pos_over_neg: 625.4390869140625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 601.2865600585938 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7352, loss_val: nan, pos_over_neg: 734.437255859375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 468.51324462890625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7367, loss_val: nan, pos_over_neg: 621.6590576171875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7395, loss_val: nan, pos_over_neg: 985.517822265625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7385, loss_val: nan, pos_over_neg: 536.2523803710938 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7388, loss_val: nan, pos_over_neg: 758.0587768554688 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 466.6829528808594 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7368, loss_val: nan, pos_over_neg: 610.5921630859375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7386, loss_val: nan, pos_over_neg: 935.64111328125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.74, loss_val: nan, pos_over_neg: 612.3444213867188 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7401, loss_val: nan, pos_over_neg: 531.3342895507812 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 510.5530090332031 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: 738.3092651367188 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7371, loss_val: nan, pos_over_neg: 493.2787780761719 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7409, loss_val: nan, pos_over_neg: 347.7613525390625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7393, loss_val: nan, pos_over_neg: 1207.890869140625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7408, loss_val: nan, pos_over_neg: 420.1558532714844 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 322.1138610839844 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 513.3722534179688 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7377, loss_val: nan, pos_over_neg: 448.2732238769531 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 336.7034912109375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7347, loss_val: nan, pos_over_neg: 393.0996398925781 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7398, loss_val: nan, pos_over_neg: 439.3735656738281 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7388, loss_val: nan, pos_over_neg: 459.6409606933594 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7387, loss_val: nan, pos_over_neg: 331.9013977050781 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 622.97412109375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.737, loss_val: nan, pos_over_neg: 417.8021240234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7388, loss_val: nan, pos_over_neg: 343.50921630859375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.734, loss_val: nan, pos_over_neg: 547.3052978515625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7374, loss_val: nan, pos_over_neg: 398.31689453125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 331.8992004394531 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7382, loss_val: nan, pos_over_neg: 458.6885986328125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7383, loss_val: nan, pos_over_neg: 269.2931823730469 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 321.76080322265625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7362, loss_val: nan, pos_over_neg: 400.8684387207031 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7393, loss_val: nan, pos_over_neg: 295.5303039550781 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 289.1219482421875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.735, loss_val: nan, pos_over_neg: 784.9268188476562 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7362, loss_val: nan, pos_over_neg: 632.5701904296875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7384, loss_val: nan, pos_over_neg: 482.22247314453125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.739, loss_val: nan, pos_over_neg: 276.8829345703125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7375, loss_val: nan, pos_over_neg: 556.292724609375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7354, loss_val: nan, pos_over_neg: 847.6172485351562 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7366, loss_val: nan, pos_over_neg: 519.1558837890625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7349, loss_val: nan, pos_over_neg: 847.6354370117188 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7375, loss_val: nan, pos_over_neg: 542.0857543945312 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7352, loss_val: nan, pos_over_neg: 833.90283203125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7342, loss_val: nan, pos_over_neg: 625.9154663085938 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7323, loss_val: nan, pos_over_neg: 795.3714599609375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7355, loss_val: nan, pos_over_neg: 449.9903564453125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7374, loss_val: nan, pos_over_neg: 553.9844360351562 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7342, loss_val: nan, pos_over_neg: 753.424072265625 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7331, loss_val: nan, pos_over_neg: 1185.5721435546875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.735, loss_val: nan, pos_over_neg: 591.6067504882812 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7384, loss_val: nan, pos_over_neg: 516.52392578125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7375, loss_val: nan, pos_over_neg: 575.0034790039062 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7338, loss_val: nan, pos_over_neg: 691.2520751953125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7386, loss_val: nan, pos_over_neg: 657.5989379882812 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7392, loss_val: nan, pos_over_neg: 430.93310546875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7364, loss_val: nan, pos_over_neg: 495.0800476074219 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7328, loss_val: nan, pos_over_neg: 802.14404296875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7353, loss_val: nan, pos_over_neg: 410.50213623046875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7377, loss_val: nan, pos_over_neg: 488.4307861328125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7346, loss_val: nan, pos_over_neg: 527.7510986328125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7356, loss_val: nan, pos_over_neg: 734.3026733398438 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7357, loss_val: nan, pos_over_neg: 626.9853515625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7394, loss_val: nan, pos_over_neg: 612.1488037109375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.735, loss_val: nan, pos_over_neg: 588.1910400390625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7363, loss_val: nan, pos_over_neg: 572.389892578125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7305, loss_val: nan, pos_over_neg: 666.3535766601562 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.734, loss_val: nan, pos_over_neg: 901.5465087890625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7366, loss_val: nan, pos_over_neg: 459.16729736328125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7346, loss_val: nan, pos_over_neg: 565.418212890625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7324, loss_val: nan, pos_over_neg: 724.3079223632812 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7358, loss_val: nan, pos_over_neg: 852.400146484375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7363, loss_val: nan, pos_over_neg: 339.9190673828125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7359, loss_val: nan, pos_over_neg: 581.3364868164062 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7368, loss_val: nan, pos_over_neg: 672.2257690429688 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7352, loss_val: nan, pos_over_neg: 684.8591918945312 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7371, loss_val: nan, pos_over_neg: 295.47900390625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7353, loss_val: nan, pos_over_neg: 800.2689208984375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.734, loss_val: nan, pos_over_neg: 456.06439208984375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7344, loss_val: nan, pos_over_neg: 715.5205688476562 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7383, loss_val: nan, pos_over_neg: 379.54449462890625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7319, loss_val: nan, pos_over_neg: 817.0052490234375 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.738, loss_val: nan, pos_over_neg: 534.65576171875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7317, loss_val: nan, pos_over_neg: 532.7260131835938 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7351, loss_val: nan, pos_over_neg: 588.37158203125 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.732, loss_val: nan, pos_over_neg: 671.19775390625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7314, loss_val: nan, pos_over_neg: 761.51708984375 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7362, loss_val: nan, pos_over_neg: 566.3494873046875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7333, loss_val: nan, pos_over_neg: 654.0646362304688 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7354, loss_val: nan, pos_over_neg: 543.4183959960938 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7339, loss_val: nan, pos_over_neg: 540.4757080078125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7326, loss_val: nan, pos_over_neg: 579.3526000976562 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7311, loss_val: nan, pos_over_neg: 1119.7066650390625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7327, loss_val: nan, pos_over_neg: 676.17041015625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7358, loss_val: nan, pos_over_neg: 660.483642578125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7319, loss_val: nan, pos_over_neg: 599.829345703125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7358, loss_val: nan, pos_over_neg: 477.3998107910156 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7342, loss_val: nan, pos_over_neg: 582.5753173828125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7321, loss_val: nan, pos_over_neg: 777.0112915039062 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7319, loss_val: nan, pos_over_neg: 583.9583740234375 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7327, loss_val: nan, pos_over_neg: 352.8017578125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.732, loss_val: nan, pos_over_neg: 660.1007080078125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7338, loss_val: nan, pos_over_neg: 822.5420532226562 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7344, loss_val: nan, pos_over_neg: 417.790283203125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7296, loss_val: nan, pos_over_neg: 922.619384765625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7335, loss_val: nan, pos_over_neg: 331.11505126953125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7354, loss_val: nan, pos_over_neg: 548.8278198242188 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7299, loss_val: nan, pos_over_neg: 2497.592041015625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7346, loss_val: nan, pos_over_neg: 376.6065368652344 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7317, loss_val: nan, pos_over_neg: 781.731689453125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7351, loss_val: nan, pos_over_neg: 496.5908508300781 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7348, loss_val: nan, pos_over_neg: 620.7470703125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7372, loss_val: nan, pos_over_neg: 715.229248046875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7304, loss_val: nan, pos_over_neg: 456.14837646484375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7343, loss_val: nan, pos_over_neg: 403.50994873046875 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7355, loss_val: nan, pos_over_neg: 421.1068420410156 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7317, loss_val: nan, pos_over_neg: 654.1019287109375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7314, loss_val: nan, pos_over_neg: 892.4197998046875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7331, loss_val: nan, pos_over_neg: 267.09619140625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7318, loss_val: nan, pos_over_neg: 506.8706359863281 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7343, loss_val: nan, pos_over_neg: 516.0744018554688 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.732, loss_val: nan, pos_over_neg: 415.524169921875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7308, loss_val: nan, pos_over_neg: 674.7249145507812 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7335, loss_val: nan, pos_over_neg: 433.6458435058594 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7344, loss_val: nan, pos_over_neg: 375.4068908691406 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7341, loss_val: nan, pos_over_neg: 410.5307922363281 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7328, loss_val: nan, pos_over_neg: 443.7552795410156 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7308, loss_val: nan, pos_over_neg: 639.9332275390625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7335, loss_val: nan, pos_over_neg: 385.2304382324219 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7302, loss_val: nan, pos_over_neg: 486.89947509765625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7364, loss_val: nan, pos_over_neg: 390.7122497558594 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7338, loss_val: nan, pos_over_neg: 675.8160400390625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7314, loss_val: nan, pos_over_neg: 597.0640869140625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7327, loss_val: nan, pos_over_neg: 533.892822265625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7284, loss_val: nan, pos_over_neg: 595.048583984375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7293, loss_val: nan, pos_over_neg: 913.5850830078125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7307, loss_val: nan, pos_over_neg: 604.1970825195312 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7322, loss_val: nan, pos_over_neg: 463.2020263671875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7338, loss_val: nan, pos_over_neg: 418.80206298828125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7334, loss_val: nan, pos_over_neg: 672.2793579101562 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7294, loss_val: nan, pos_over_neg: 657.4190063476562 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7308, loss_val: nan, pos_over_neg: 475.393310546875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7302, loss_val: nan, pos_over_neg: 556.376220703125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7298, loss_val: nan, pos_over_neg: 727.3208618164062 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.731, loss_val: nan, pos_over_neg: 920.9088134765625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7286, loss_val: nan, pos_over_neg: 735.2327880859375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7279, loss_val: nan, pos_over_neg: 527.2052612304688 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7261, loss_val: nan, pos_over_neg: 879.5336303710938 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7284, loss_val: nan, pos_over_neg: 1076.2464599609375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7256, loss_val: nan, pos_over_neg: 595.0841064453125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7309, loss_val: nan, pos_over_neg: 810.4369506835938 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7299, loss_val: nan, pos_over_neg: 1441.4207763671875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7323, loss_val: nan, pos_over_neg: 717.3233642578125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.731, loss_val: nan, pos_over_neg: 846.59716796875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7267, loss_val: nan, pos_over_neg: 1074.2528076171875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7294, loss_val: nan, pos_over_neg: 665.0122680664062 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7256, loss_val: nan, pos_over_neg: 1861.4638671875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7317, loss_val: nan, pos_over_neg: 598.5588989257812 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7288, loss_val: nan, pos_over_neg: 562.4393920898438 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7275, loss_val: nan, pos_over_neg: 796.8399047851562 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.729, loss_val: nan, pos_over_neg: 736.375244140625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7306, loss_val: nan, pos_over_neg: 1509.65185546875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7317, loss_val: nan, pos_over_neg: 829.5645141601562 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7287, loss_val: nan, pos_over_neg: 631.697998046875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7286, loss_val: nan, pos_over_neg: 751.9541015625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7322, loss_val: nan, pos_over_neg: 665.5253295898438 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.73, loss_val: nan, pos_over_neg: 591.216552734375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7312, loss_val: nan, pos_over_neg: 787.8892211914062 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7309, loss_val: nan, pos_over_neg: 1156.1607666015625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7277, loss_val: nan, pos_over_neg: 557.246337890625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7306, loss_val: nan, pos_over_neg: 545.974365234375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7277, loss_val: nan, pos_over_neg: 996.7695922851562 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7291, loss_val: nan, pos_over_neg: 681.7997436523438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7282, loss_val: nan, pos_over_neg: 380.638427734375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7247, loss_val: nan, pos_over_neg: 798.6785888671875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7311, loss_val: nan, pos_over_neg: 1048.9501953125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7289, loss_val: nan, pos_over_neg: 707.6974487304688 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7312, loss_val: nan, pos_over_neg: 510.0243835449219 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7308, loss_val: nan, pos_over_neg: 636.1278686523438 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7282, loss_val: nan, pos_over_neg: 712.0975341796875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7276, loss_val: nan, pos_over_neg: 609.810546875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7274, loss_val: nan, pos_over_neg: 1115.1885986328125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7267, loss_val: nan, pos_over_neg: 485.426513671875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7288, loss_val: nan, pos_over_neg: 688.3009033203125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7284, loss_val: nan, pos_over_neg: 637.0734252929688 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7319, loss_val: nan, pos_over_neg: 538.97998046875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7318, loss_val: nan, pos_over_neg: 527.198486328125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7274, loss_val: nan, pos_over_neg: 772.5509033203125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7301, loss_val: nan, pos_over_neg: 578.3518676757812 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7239, loss_val: nan, pos_over_neg: 1189.6669921875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.73, loss_val: nan, pos_over_neg: 584.364990234375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7303, loss_val: nan, pos_over_neg: 503.8854675292969 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7282, loss_val: nan, pos_over_neg: 528.725830078125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7307, loss_val: nan, pos_over_neg: 549.5789794921875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7297, loss_val: nan, pos_over_neg: 661.6387329101562 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7302, loss_val: nan, pos_over_neg: 522.10791015625 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7305, loss_val: nan, pos_over_neg: 348.2144775390625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7271, loss_val: nan, pos_over_neg: 459.2705383300781 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7297, loss_val: nan, pos_over_neg: 558.4307861328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7258, loss_val: nan, pos_over_neg: 640.1914672851562 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7268, loss_val: nan, pos_over_neg: 742.21826171875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.73, loss_val: nan, pos_over_neg: 633.6007080078125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7287, loss_val: nan, pos_over_neg: 1134.4051513671875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7311, loss_val: nan, pos_over_neg: 1052.178466796875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7294, loss_val: nan, pos_over_neg: 521.4296875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7296, loss_val: nan, pos_over_neg: 737.7168579101562 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7299, loss_val: nan, pos_over_neg: 436.0391540527344 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7249, loss_val: nan, pos_over_neg: 1015.3366088867188 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7272, loss_val: nan, pos_over_neg: 735.9109497070312 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.727, loss_val: nan, pos_over_neg: 563.27099609375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7298, loss_val: nan, pos_over_neg: 781.3292236328125 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7293, loss_val: nan, pos_over_neg: 691.3270263671875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7248, loss_val: nan, pos_over_neg: 757.7919921875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7276, loss_val: nan, pos_over_neg: 683.4126586914062 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7259, loss_val: nan, pos_over_neg: 1230.6024169921875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7279, loss_val: nan, pos_over_neg: 502.1765441894531 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7299, loss_val: nan, pos_over_neg: 878.4274291992188 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7251, loss_val: nan, pos_over_neg: 636.5341186523438 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7293, loss_val: nan, pos_over_neg: 650.2142333984375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7274, loss_val: nan, pos_over_neg: 494.1809997558594 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7301, loss_val: nan, pos_over_neg: 609.0757446289062 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7275, loss_val: nan, pos_over_neg: 434.2086486816406 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7253, loss_val: nan, pos_over_neg: 920.002197265625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 683.6043701171875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.728, loss_val: nan, pos_over_neg: 683.123779296875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.732, loss_val: nan, pos_over_neg: 400.69757080078125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7249, loss_val: nan, pos_over_neg: 1104.2783203125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7277, loss_val: nan, pos_over_neg: 594.6380615234375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7293, loss_val: nan, pos_over_neg: 410.6400146484375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7279, loss_val: nan, pos_over_neg: 617.0905151367188 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.725, loss_val: nan, pos_over_neg: 1109.583740234375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7277, loss_val: nan, pos_over_neg: 717.6412963867188 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 486.46533203125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7272, loss_val: nan, pos_over_neg: 618.8316650390625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.724, loss_val: nan, pos_over_neg: 1330.2181396484375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7278, loss_val: nan, pos_over_neg: 1341.548583984375 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7285, loss_val: nan, pos_over_neg: 742.7931518554688 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7246, loss_val: nan, pos_over_neg: 699.1760864257812 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7246, loss_val: nan, pos_over_neg: 594.0716552734375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7302, loss_val: nan, pos_over_neg: 683.0083618164062 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7273, loss_val: nan, pos_over_neg: 533.4546508789062 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7251, loss_val: nan, pos_over_neg: 807.3934326171875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7243, loss_val: nan, pos_over_neg: 771.5084228515625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7269, loss_val: nan, pos_over_neg: 517.92333984375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7249, loss_val: nan, pos_over_neg: 1182.9315185546875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7275, loss_val: nan, pos_over_neg: 1061.04638671875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7274, loss_val: nan, pos_over_neg: 559.7033081054688 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7241, loss_val: nan, pos_over_neg: 945.4563598632812 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7266, loss_val: nan, pos_over_neg: 559.22802734375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7289, loss_val: nan, pos_over_neg: 622.6484985351562 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7212, loss_val: nan, pos_over_neg: 935.3316040039062 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7281, loss_val: nan, pos_over_neg: 829.3524780273438 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7235, loss_val: nan, pos_over_neg: 1584.8353271484375 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7257, loss_val: nan, pos_over_neg: 1322.90234375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.729, loss_val: nan, pos_over_neg: 984.1172485351562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7234, loss_val: nan, pos_over_neg: 743.7785034179688 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7255, loss_val: nan, pos_over_neg: 923.9146728515625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7236, loss_val: nan, pos_over_neg: 901.7841796875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7265, loss_val: nan, pos_over_neg: 700.320068359375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7245, loss_val: nan, pos_over_neg: 853.8114013671875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7262, loss_val: nan, pos_over_neg: 878.4488525390625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 874.0011596679688 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7266, loss_val: nan, pos_over_neg: 599.066162109375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7227, loss_val: nan, pos_over_neg: 1636.4317626953125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 1150.8218994140625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7266, loss_val: nan, pos_over_neg: 600.4916381835938 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7266, loss_val: nan, pos_over_neg: 997.9525146484375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7261, loss_val: nan, pos_over_neg: 610.28271484375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7244, loss_val: nan, pos_over_neg: 1287.3665771484375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7238, loss_val: nan, pos_over_neg: 993.3485717773438 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7244, loss_val: nan, pos_over_neg: 648.752685546875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7253, loss_val: nan, pos_over_neg: 875.347900390625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7275, loss_val: nan, pos_over_neg: 690.896728515625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7241, loss_val: nan, pos_over_neg: 641.4546508789062 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.723, loss_val: nan, pos_over_neg: 781.1408081054688 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7224, loss_val: nan, pos_over_neg: 857.6116943359375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7235, loss_val: nan, pos_over_neg: 1510.5062255859375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7257, loss_val: nan, pos_over_neg: 447.9764099121094 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7272, loss_val: nan, pos_over_neg: 466.90496826171875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.723, loss_val: nan, pos_over_neg: 797.11962890625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.725, loss_val: nan, pos_over_neg: 621.0033569335938 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.723, loss_val: nan, pos_over_neg: 940.7646484375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7209, loss_val: nan, pos_over_neg: 880.6488647460938 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 658.9462280273438 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7243, loss_val: nan, pos_over_neg: 996.556396484375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7239, loss_val: nan, pos_over_neg: 561.369384765625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7278, loss_val: nan, pos_over_neg: 360.3359680175781 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7204, loss_val: nan, pos_over_neg: 925.653564453125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.724, loss_val: nan, pos_over_neg: 494.117919921875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.726, loss_val: nan, pos_over_neg: 680.9471435546875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7231, loss_val: nan, pos_over_neg: 555.7525024414062 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 510.5920104980469 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7237, loss_val: nan, pos_over_neg: 722.6217041015625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7234, loss_val: nan, pos_over_neg: 819.5274658203125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7196, loss_val: nan, pos_over_neg: 1076.7066650390625 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7259, loss_val: nan, pos_over_neg: 587.0259399414062 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 659.52490234375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7244, loss_val: nan, pos_over_neg: 630.25 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7208, loss_val: nan, pos_over_neg: 948.5831298828125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7219, loss_val: nan, pos_over_neg: 874.9744262695312 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7253, loss_val: nan, pos_over_neg: 847.9725952148438 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7243, loss_val: nan, pos_over_neg: 777.5987548828125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7272, loss_val: nan, pos_over_neg: 840.8661499023438 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 685.6819458007812 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7253, loss_val: nan, pos_over_neg: 569.7026977539062 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7238, loss_val: nan, pos_over_neg: 449.96307373046875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7246, loss_val: nan, pos_over_neg: 636.9287719726562 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7209, loss_val: nan, pos_over_neg: 1175.2218017578125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7192, loss_val: nan, pos_over_neg: 747.0642700195312 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7245, loss_val: nan, pos_over_neg: 529.7506713867188 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7219, loss_val: nan, pos_over_neg: 722.8091430664062 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7192, loss_val: nan, pos_over_neg: 1560.957763671875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 1281.3231201171875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7239, loss_val: nan, pos_over_neg: 467.2031555175781 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.725, loss_val: nan, pos_over_neg: 928.3290405273438 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 545.3551025390625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7231, loss_val: nan, pos_over_neg: 738.8671264648438 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [20:22<101881:31:56, 1222.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.7224, loss_val: nan, pos_over_neg: 910.0470581054688 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7234, loss_val: nan, pos_over_neg: 760.316650390625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7239, loss_val: nan, pos_over_neg: 588.9041137695312 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7213, loss_val: nan, pos_over_neg: 786.6533203125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7211, loss_val: nan, pos_over_neg: 1197.9869384765625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7229, loss_val: nan, pos_over_neg: 506.4033508300781 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 587.5899658203125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7259, loss_val: nan, pos_over_neg: 482.2904968261719 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 789.901123046875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7244, loss_val: nan, pos_over_neg: 641.1178588867188 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7221, loss_val: nan, pos_over_neg: 1039.2593994140625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7267, loss_val: nan, pos_over_neg: 459.91815185546875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7181, loss_val: nan, pos_over_neg: 1057.1983642578125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7218, loss_val: nan, pos_over_neg: 786.6361083984375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 982.4757080078125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.724, loss_val: nan, pos_over_neg: 462.848876953125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7261, loss_val: nan, pos_over_neg: 490.6835632324219 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 1137.30419921875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7251, loss_val: nan, pos_over_neg: 505.5022888183594 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.725, loss_val: nan, pos_over_neg: 656.0309448242188 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 305.04217529296875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7201, loss_val: nan, pos_over_neg: 586.762451171875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7264, loss_val: nan, pos_over_neg: 426.2132873535156 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7222, loss_val: nan, pos_over_neg: 804.377197265625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.726, loss_val: nan, pos_over_neg: 372.1019287109375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.721, loss_val: nan, pos_over_neg: 578.5755004882812 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7255, loss_val: nan, pos_over_neg: 444.1268615722656 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7244, loss_val: nan, pos_over_neg: 500.0577392578125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7208, loss_val: nan, pos_over_neg: 595.7642822265625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.723, loss_val: nan, pos_over_neg: 463.1060791015625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7256, loss_val: nan, pos_over_neg: 461.52008056640625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7217, loss_val: nan, pos_over_neg: 390.980224609375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7213, loss_val: nan, pos_over_neg: 787.6574096679688 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7233, loss_val: nan, pos_over_neg: 484.6296081542969 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7226, loss_val: nan, pos_over_neg: 423.0000915527344 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 694.2551879882812 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 594.49609375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7273, loss_val: nan, pos_over_neg: 473.2497863769531 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7239, loss_val: nan, pos_over_neg: 658.2620239257812 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7231, loss_val: nan, pos_over_neg: 670.7003784179688 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7234, loss_val: nan, pos_over_neg: 608.1233520507812 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7241, loss_val: nan, pos_over_neg: 418.09197998046875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7183, loss_val: nan, pos_over_neg: 1203.699951171875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7242, loss_val: nan, pos_over_neg: 659.4899291992188 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.721, loss_val: nan, pos_over_neg: 469.25897216796875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7204, loss_val: nan, pos_over_neg: 677.2725830078125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7197, loss_val: nan, pos_over_neg: 452.20001220703125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.727, loss_val: nan, pos_over_neg: 391.5101623535156 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7193, loss_val: nan, pos_over_neg: 1007.5447998046875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7216, loss_val: nan, pos_over_neg: 791.5819702148438 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7213, loss_val: nan, pos_over_neg: 857.80322265625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7254, loss_val: nan, pos_over_neg: 456.61920166015625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 717.4957885742188 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 909.3751220703125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 1040.1834716796875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7224, loss_val: nan, pos_over_neg: 675.7108764648438 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7215, loss_val: nan, pos_over_neg: 471.3040466308594 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 483.0034484863281 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7173, loss_val: nan, pos_over_neg: 776.5433959960938 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 638.2114868164062 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7217, loss_val: nan, pos_over_neg: 432.30645751953125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7226, loss_val: nan, pos_over_neg: 491.112548828125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7225, loss_val: nan, pos_over_neg: 1332.092041015625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7233, loss_val: nan, pos_over_neg: 478.91802978515625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7227, loss_val: nan, pos_over_neg: 465.51080322265625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 982.61328125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.716, loss_val: nan, pos_over_neg: 1160.0926513671875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7245, loss_val: nan, pos_over_neg: 623.2583618164062 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7177, loss_val: nan, pos_over_neg: 751.2324829101562 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 1275.5821533203125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 2276.025146484375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7189, loss_val: nan, pos_over_neg: 1172.447509765625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 1051.7904052734375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7222, loss_val: nan, pos_over_neg: 943.3270874023438 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 1488.7781982421875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 2067.16015625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 1406.091796875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7179, loss_val: nan, pos_over_neg: 1371.6378173828125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7169, loss_val: nan, pos_over_neg: 2680.896484375 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 1250.2646484375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7238, loss_val: nan, pos_over_neg: 354.7132873535156 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7205, loss_val: nan, pos_over_neg: 695.4063720703125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 2476.572998046875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7217, loss_val: nan, pos_over_neg: 1009.2698364257812 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7253, loss_val: nan, pos_over_neg: 480.10986328125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.72, loss_val: nan, pos_over_neg: 804.0542602539062 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 856.45849609375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7202, loss_val: nan, pos_over_neg: 821.912353515625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7229, loss_val: nan, pos_over_neg: 445.024169921875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 669.8375854492188 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 814.5357666015625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7198, loss_val: nan, pos_over_neg: 755.0322875976562 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.716, loss_val: nan, pos_over_neg: 2291.211181640625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7193, loss_val: nan, pos_over_neg: 764.79052734375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 669.9075317382812 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7185, loss_val: nan, pos_over_neg: 844.9244995117188 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.719, loss_val: nan, pos_over_neg: 1076.16259765625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7217, loss_val: nan, pos_over_neg: 1034.1268310546875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7197, loss_val: nan, pos_over_neg: 1113.0850830078125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7215, loss_val: nan, pos_over_neg: 825.9788208007812 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 954.874755859375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 1297.8477783203125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7202, loss_val: nan, pos_over_neg: 889.207763671875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 633.9117431640625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7212, loss_val: nan, pos_over_neg: 968.341796875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7218, loss_val: nan, pos_over_neg: 615.6743774414062 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7196, loss_val: nan, pos_over_neg: 1063.06787109375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7174, loss_val: nan, pos_over_neg: 881.935546875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7184, loss_val: nan, pos_over_neg: 813.5584106445312 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.72, loss_val: nan, pos_over_neg: 1733.8917236328125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 777.2348022460938 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 496.4673767089844 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7208, loss_val: nan, pos_over_neg: 785.4602661132812 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7185, loss_val: nan, pos_over_neg: 770.2031860351562 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7188, loss_val: nan, pos_over_neg: 447.9727783203125 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7212, loss_val: nan, pos_over_neg: 524.6341552734375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 606.4093627929688 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 572.754150390625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7214, loss_val: nan, pos_over_neg: 678.708984375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.722, loss_val: nan, pos_over_neg: 526.1351318359375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7205, loss_val: nan, pos_over_neg: 641.2806396484375 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7192, loss_val: nan, pos_over_neg: 580.47802734375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7208, loss_val: nan, pos_over_neg: 565.9879150390625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 1121.9505615234375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7221, loss_val: nan, pos_over_neg: 586.4942016601562 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 788.1053466796875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7193, loss_val: nan, pos_over_neg: 459.34051513671875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 398.5336608886719 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7232, loss_val: nan, pos_over_neg: 700.2377319335938 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.72, loss_val: nan, pos_over_neg: 594.988037109375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 562.4017944335938 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7235, loss_val: nan, pos_over_neg: 577.1458740234375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 651.27197265625 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7268, loss_val: nan, pos_over_neg: 596.9608764648438 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.721, loss_val: nan, pos_over_neg: 651.0581665039062 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7159, loss_val: nan, pos_over_neg: 605.3883666992188 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7236, loss_val: nan, pos_over_neg: 488.9671630859375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7201, loss_val: nan, pos_over_neg: 832.2407836914062 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7182, loss_val: nan, pos_over_neg: 1250.0555419921875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7223, loss_val: nan, pos_over_neg: 639.3797607421875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7242, loss_val: nan, pos_over_neg: 524.75439453125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7225, loss_val: nan, pos_over_neg: 657.4696655273438 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7238, loss_val: nan, pos_over_neg: 479.6464538574219 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7217, loss_val: nan, pos_over_neg: 803.9370727539062 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7193, loss_val: nan, pos_over_neg: 568.0469970703125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7226, loss_val: nan, pos_over_neg: 472.8731384277344 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7242, loss_val: nan, pos_over_neg: 568.8855590820312 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 507.12872314453125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7229, loss_val: nan, pos_over_neg: 547.2486572265625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7218, loss_val: nan, pos_over_neg: 392.889404296875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 456.8824157714844 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7197, loss_val: nan, pos_over_neg: 625.3101806640625 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7247, loss_val: nan, pos_over_neg: 446.5815734863281 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7163, loss_val: nan, pos_over_neg: 707.9343872070312 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7232, loss_val: nan, pos_over_neg: 805.9146728515625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7231, loss_val: nan, pos_over_neg: 598.7901000976562 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7173, loss_val: nan, pos_over_neg: 877.3646240234375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7188, loss_val: nan, pos_over_neg: 703.498779296875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7188, loss_val: nan, pos_over_neg: 804.2910766601562 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7165, loss_val: nan, pos_over_neg: 779.2637939453125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7204, loss_val: nan, pos_over_neg: 1367.180419921875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 1062.7896728515625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7202, loss_val: nan, pos_over_neg: 841.7180786132812 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 819.1884765625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7183, loss_val: nan, pos_over_neg: 860.32958984375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7157, loss_val: nan, pos_over_neg: 1153.017333984375 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7157, loss_val: nan, pos_over_neg: 1419.2498779296875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7187, loss_val: nan, pos_over_neg: 2791.263671875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7176, loss_val: nan, pos_over_neg: 825.39794921875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 928.4703979492188 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 618.1041259765625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 3087.47509765625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 777.0484619140625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 1060.4366455078125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 1319.9810791015625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 1077.0128173828125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 1157.350830078125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 577.5460205078125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 734.4800415039062 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 2557.86181640625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.72, loss_val: nan, pos_over_neg: 710.7623291015625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7176, loss_val: nan, pos_over_neg: 1206.80908203125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7181, loss_val: nan, pos_over_neg: 995.915283203125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7168, loss_val: nan, pos_over_neg: 1811.8531494140625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 1330.46923828125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 804.551025390625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 998.448974609375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 914.770263671875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.719, loss_val: nan, pos_over_neg: 723.4653930664062 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7207, loss_val: nan, pos_over_neg: 541.1144409179688 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 555.5396118164062 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7179, loss_val: nan, pos_over_neg: 894.3678588867188 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7169, loss_val: nan, pos_over_neg: 563.2567749023438 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 692.333984375 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7157, loss_val: nan, pos_over_neg: 880.0309448242188 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7184, loss_val: nan, pos_over_neg: 699.592529296875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 570.5567626953125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7183, loss_val: nan, pos_over_neg: 609.2029418945312 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 655.0595703125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7192, loss_val: nan, pos_over_neg: 484.9619140625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7209, loss_val: nan, pos_over_neg: 422.30548095703125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 546.9911499023438 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 1154.6153564453125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7216, loss_val: nan, pos_over_neg: 651.701904296875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7173, loss_val: nan, pos_over_neg: 772.9673461914062 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7208, loss_val: nan, pos_over_neg: 999.3005981445312 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 775.4342041015625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7189, loss_val: nan, pos_over_neg: 1852.1573486328125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7199, loss_val: nan, pos_over_neg: 798.4254760742188 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.719, loss_val: nan, pos_over_neg: 664.62158203125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7179, loss_val: nan, pos_over_neg: 787.2542114257812 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7155, loss_val: nan, pos_over_neg: 999.7974853515625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7182, loss_val: nan, pos_over_neg: 1219.106689453125 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7161, loss_val: nan, pos_over_neg: 615.0973510742188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 805.8816528320312 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7165, loss_val: nan, pos_over_neg: 650.2110595703125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7155, loss_val: nan, pos_over_neg: 962.0265502929688 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 805.9874877929688 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7175, loss_val: nan, pos_over_neg: 627.2451782226562 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7189, loss_val: nan, pos_over_neg: 683.3186645507812 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7176, loss_val: nan, pos_over_neg: 748.48779296875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 533.2110595703125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7173, loss_val: nan, pos_over_neg: 819.2064819335938 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7174, loss_val: nan, pos_over_neg: 565.5133056640625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 857.1070556640625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7156, loss_val: nan, pos_over_neg: 730.1956787109375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 787.9039916992188 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7168, loss_val: nan, pos_over_neg: 1047.0670166015625 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 625.5616455078125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7161, loss_val: nan, pos_over_neg: 850.3759155273438 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 721.4481201171875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7173, loss_val: nan, pos_over_neg: 953.1342163085938 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 798.886474609375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7146, loss_val: nan, pos_over_neg: 920.7434692382812 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 444.59381103515625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7191, loss_val: nan, pos_over_neg: 882.666748046875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7177, loss_val: nan, pos_over_neg: 741.6567993164062 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7169, loss_val: nan, pos_over_neg: 667.87646484375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7176, loss_val: nan, pos_over_neg: 572.8579711914062 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7216, loss_val: nan, pos_over_neg: 557.6672973632812 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7184, loss_val: nan, pos_over_neg: 553.2474975585938 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7172, loss_val: nan, pos_over_neg: 620.2957153320312 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 605.6256713867188 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 458.30584716796875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 765.685302734375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7187, loss_val: nan, pos_over_neg: 848.8617553710938 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7163, loss_val: nan, pos_over_neg: 620.1201171875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 680.6721801757812 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7176, loss_val: nan, pos_over_neg: 478.6773681640625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 874.2620239257812 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7159, loss_val: nan, pos_over_neg: 847.3983764648438 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7206, loss_val: nan, pos_over_neg: 514.2268676757812 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7188, loss_val: nan, pos_over_neg: 673.8624877929688 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.716, loss_val: nan, pos_over_neg: 793.7957763671875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 859.5841674804688 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7149, loss_val: nan, pos_over_neg: 825.6593627929688 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7179, loss_val: nan, pos_over_neg: 633.5982666015625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7146, loss_val: nan, pos_over_neg: 1045.8646240234375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 899.9774169921875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 480.70263671875 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 816.4745483398438 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7184, loss_val: nan, pos_over_neg: 455.6304931640625 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7175, loss_val: nan, pos_over_neg: 602.599365234375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7182, loss_val: nan, pos_over_neg: 499.9713439941406 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7168, loss_val: nan, pos_over_neg: 467.28802490234375 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7187, loss_val: nan, pos_over_neg: 1041.9375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7174, loss_val: nan, pos_over_neg: 607.2183837890625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 728.3156127929688 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 702.2898559570312 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7209, loss_val: nan, pos_over_neg: 508.26531982421875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7197, loss_val: nan, pos_over_neg: 717.037353515625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 953.5800170898438 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7182, loss_val: nan, pos_over_neg: 758.020263671875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7163, loss_val: nan, pos_over_neg: 576.5368041992188 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7157, loss_val: nan, pos_over_neg: 744.99560546875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7181, loss_val: nan, pos_over_neg: 479.87548828125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7134, loss_val: nan, pos_over_neg: 579.2138671875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7203, loss_val: nan, pos_over_neg: 582.162841796875 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7162, loss_val: nan, pos_over_neg: 565.9987182617188 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 708.0296020507812 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 634.1072998046875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 882.322509765625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7185, loss_val: nan, pos_over_neg: 567.576416015625 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 815.3131103515625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7195, loss_val: nan, pos_over_neg: 528.5642700195312 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7155, loss_val: nan, pos_over_neg: 881.4750366210938 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 968.9425048828125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 1361.82470703125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7158, loss_val: nan, pos_over_neg: 829.8595581054688 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.716, loss_val: nan, pos_over_neg: 747.659912109375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7153, loss_val: nan, pos_over_neg: 1111.5328369140625 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7156, loss_val: nan, pos_over_neg: 870.3244018554688 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7172, loss_val: nan, pos_over_neg: 469.2447509765625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.716, loss_val: nan, pos_over_neg: 1000.784912109375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7175, loss_val: nan, pos_over_neg: 603.88330078125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7168, loss_val: nan, pos_over_neg: 622.2921142578125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7172, loss_val: nan, pos_over_neg: 606.5565795898438 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.72, loss_val: nan, pos_over_neg: 735.865966796875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 853.2332763671875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 2018.94091796875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7165, loss_val: nan, pos_over_neg: 496.27301025390625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7158, loss_val: nan, pos_over_neg: 628.5947265625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 640.3613891601562 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 625.7013549804688 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7157, loss_val: nan, pos_over_neg: 1006.2200927734375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 848.0629272460938 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 727.5369262695312 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 849.88330078125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7171, loss_val: nan, pos_over_neg: 1415.430908203125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 696.2574462890625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 856.0325317382812 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 1361.2542724609375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.714, loss_val: nan, pos_over_neg: 1376.3077392578125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 2338.99365234375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 1365.5123291015625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 870.1096801757812 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.715, loss_val: nan, pos_over_neg: 771.5743408203125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 802.1326293945312 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 3708.70458984375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 1476.6241455078125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7158, loss_val: nan, pos_over_neg: 1500.9229736328125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 1834.433349609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7158, loss_val: nan, pos_over_neg: 1241.611083984375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 1052.518310546875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.717, loss_val: nan, pos_over_neg: 931.6768188476562 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 1272.65283203125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7182, loss_val: nan, pos_over_neg: 960.916748046875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7155, loss_val: nan, pos_over_neg: 1025.226318359375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 2993.139404296875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7194, loss_val: nan, pos_over_neg: 1506.474853515625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7155, loss_val: nan, pos_over_neg: 1051.2105712890625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 1934.575439453125 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 568.7666015625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 1094.7091064453125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 1267.1053466796875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 831.8464965820312 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7183, loss_val: nan, pos_over_neg: 690.29541015625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 1104.861328125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 765.7662963867188 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 1186.79833984375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7126, loss_val: nan, pos_over_neg: 1146.9339599609375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 874.32861328125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7126, loss_val: nan, pos_over_neg: 2010.4317626953125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 1489.1763916015625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 644.7227783203125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 1176.2069091796875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 1424.352783203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 861.4488525390625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 1199.45166015625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7164, loss_val: nan, pos_over_neg: 604.2830810546875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 892.8360595703125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 595.3475952148438 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 977.6948852539062 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 904.151611328125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.715, loss_val: nan, pos_over_neg: 686.9278564453125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7163, loss_val: nan, pos_over_neg: 650.5709228515625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 1441.90478515625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 1487.567138671875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7174, loss_val: nan, pos_over_neg: 612.3265380859375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 907.9139404296875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7141, loss_val: nan, pos_over_neg: 1689.1539306640625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7138, loss_val: nan, pos_over_neg: 660.7245483398438 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7153, loss_val: nan, pos_over_neg: 1226.8211669921875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 846.3869018554688 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 1365.3348388671875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7165, loss_val: nan, pos_over_neg: 1072.6063232421875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 939.2860717773438 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7147, loss_val: nan, pos_over_neg: 1160.4974365234375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 929.0136108398438 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7178, loss_val: nan, pos_over_neg: 644.8366088867188 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 1317.464111328125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 1691.4901123046875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 850.779052734375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 881.3777465820312 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.714, loss_val: nan, pos_over_neg: 908.3267822265625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 1418.3387451171875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 1146.36962890625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 978.8583374023438 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1124.472412109375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 2358.41162109375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 1213.357421875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 1098.1502685546875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 786.0906372070312 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7174, loss_val: nan, pos_over_neg: 1025.472900390625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 1214.8902587890625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7141, loss_val: nan, pos_over_neg: 1026.8038330078125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7123, loss_val: nan, pos_over_neg: 1025.4332275390625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 478.278564453125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 911.8980102539062 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 920.7747192382812 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 829.3825073242188 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 564.667724609375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 1083.1630859375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 793.6530151367188 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7168, loss_val: nan, pos_over_neg: 897.4254150390625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 817.1785888671875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 1124.9544677734375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7119, loss_val: nan, pos_over_neg: 911.992431640625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7186, loss_val: nan, pos_over_neg: 1079.8045654296875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1379.0565185546875 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7146, loss_val: nan, pos_over_neg: 751.3389282226562 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7156, loss_val: nan, pos_over_neg: 726.471923828125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7149, loss_val: nan, pos_over_neg: 854.5551147460938 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7167, loss_val: nan, pos_over_neg: 1099.6927490234375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 717.430419921875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1629.219482421875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7141, loss_val: nan, pos_over_neg: 776.5237426757812 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 917.9895629882812 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.715, loss_val: nan, pos_over_neg: 2110.270263671875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7161, loss_val: nan, pos_over_neg: 487.0697937011719 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 1131.0479736328125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7163, loss_val: nan, pos_over_neg: 955.0955810546875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 1221.6317138671875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 1239.253173828125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 1082.0458984375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 1184.0135498046875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 837.6395874023438 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 903.6385498046875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 624.9810180664062 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 703.492919921875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7147, loss_val: nan, pos_over_neg: 834.8377075195312 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 1257.7110595703125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7119, loss_val: nan, pos_over_neg: 1099.934326171875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 800.556884765625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.715, loss_val: nan, pos_over_neg: 1113.3538818359375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.718, loss_val: nan, pos_over_neg: 723.3716430664062 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 780.3013305664062 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 846.0137939453125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7149, loss_val: nan, pos_over_neg: 623.6739501953125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 1287.31640625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 898.4916381835938 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 733.2327880859375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 794.87158203125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 638.9127807617188 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 510.86871337890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 729.8963623046875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 793.9425048828125 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7154, loss_val: nan, pos_over_neg: 700.6710815429688 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7123, loss_val: nan, pos_over_neg: 703.0570068359375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.714, loss_val: nan, pos_over_neg: 618.8052368164062 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 1417.12646484375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 1546.01953125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7147, loss_val: nan, pos_over_neg: 1313.8326416015625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 860.2230224609375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 1126.3736572265625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7112, loss_val: nan, pos_over_neg: 1786.95458984375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1000.7144775390625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 918.3480834960938 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1796.546142578125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 1369.808837890625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 1839.4708251953125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 1394.7442626953125 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 565.5894165039062 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 643.30908203125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 923.1185913085938 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7138, loss_val: nan, pos_over_neg: 947.3455810546875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 777.6195678710938 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.715, loss_val: nan, pos_over_neg: 688.8344116210938 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7149, loss_val: nan, pos_over_neg: 533.8722534179688 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 1015.0076904296875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 752.8316650390625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 812.86328125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 767.8255615234375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 2244.49169921875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 915.9103393554688 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 893.5072631835938 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7143, loss_val: nan, pos_over_neg: 1237.036865234375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 905.5567626953125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7153, loss_val: nan, pos_over_neg: 803.7886352539062 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 1573.2259521484375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 1939.6968994140625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 828.37890625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 1028.8927001953125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 1002.7783813476562 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 688.7389526367188 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 1090.7158203125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 1133.5802001953125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 964.5078735351562 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 814.675048828125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7149, loss_val: nan, pos_over_neg: 953.6229248046875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 1496.8447265625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7153, loss_val: nan, pos_over_neg: 760.2486572265625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 557.2671508789062 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 821.6854858398438 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.713, loss_val: nan, pos_over_neg: 814.3030395507812 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 1466.63818359375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7134, loss_val: nan, pos_over_neg: 850.7380981445312 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 835.000732421875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 1370.33056640625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 1235.3182373046875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 566.9857177734375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 796.52734375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 1520.4219970703125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7123, loss_val: nan, pos_over_neg: 747.1314697265625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 880.7538452148438 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 886.5988159179688 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7166, loss_val: nan, pos_over_neg: 631.122314453125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 800.24267578125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7145, loss_val: nan, pos_over_neg: 792.1820068359375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 2134.152587890625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 862.02978515625 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 1265.029296875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.713, loss_val: nan, pos_over_neg: 832.3786010742188 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 888.5696411132812 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.713, loss_val: nan, pos_over_neg: 1045.8643798828125 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 839.94091796875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 3311.609130859375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1257.5535888671875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 654.093994140625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 1185.9595947265625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7113, loss_val: nan, pos_over_neg: 1356.86328125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7126, loss_val: nan, pos_over_neg: 867.1554565429688 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 573.2090454101562 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 968.0399169921875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 707.5830078125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7152, loss_val: nan, pos_over_neg: 1064.944580078125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7139, loss_val: nan, pos_over_neg: 841.6915283203125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 638.9423217773438 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 1451.1522216796875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 996.7366943359375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 857.26171875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 557.72021484375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 857.5738525390625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 711.2704467773438 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 1287.247802734375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7123, loss_val: nan, pos_over_neg: 1282.439453125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 1663.4888916015625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7126, loss_val: nan, pos_over_neg: 567.5162353515625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 621.929443359375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 1173.9407958984375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 1111.69970703125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 884.4176025390625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 730.1370849609375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 619.6897583007812 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 1136.6339111328125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 982.3706665039062 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 632.4293212890625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 1095.93017578125 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 1269.4271240234375 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 1291.05322265625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 473.7215270996094 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 910.6219482421875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 1716.044921875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 1197.288330078125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 450.61151123046875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 578.7276000976562 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 824.4755249023438 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 948.53125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 711.3695068359375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 1596.2943115234375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 537.3421630859375 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1297.5714111328125 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.713, loss_val: nan, pos_over_neg: 737.8707885742188 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 907.364990234375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 811.1826782226562 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 797.6886596679688 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 897.4403686523438 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7133, loss_val: nan, pos_over_neg: 751.7489624023438 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 876.272216796875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 586.4628295898438 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 793.3255615234375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 1036.301025390625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 786.980224609375 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7147, loss_val: nan, pos_over_neg: 838.4161376953125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 709.8489379882812 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 750.314697265625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 895.213623046875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 701.404052734375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 781.6773681640625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7123, loss_val: nan, pos_over_neg: 806.4867553710938 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 993.8915405273438 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 476.35736083984375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7148, loss_val: nan, pos_over_neg: 507.99346923828125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 1381.4317626953125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 819.7828369140625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 915.4071655273438 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 1354.9322509765625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 847.72021484375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 958.8701171875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 1005.298583984375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 1059.4642333984375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7115, loss_val: nan, pos_over_neg: 1000.363525390625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 882.8455810546875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 690.9060668945312 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 827.229736328125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 657.5593872070312 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 602.4476928710938 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 802.2133178710938 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 1781.85400390625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 981.8010864257812 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7153, loss_val: nan, pos_over_neg: 636.3497924804688 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.714, loss_val: nan, pos_over_neg: 552.3321533203125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 823.3447875976562 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 811.369384765625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 577.0676879882812 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 1502.27099609375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 576.518798828125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 802.0316772460938 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7128, loss_val: nan, pos_over_neg: 690.572509765625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 953.2337646484375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 697.0953979492188 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 703.5176391601562 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 975.4774169921875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 1068.3499755859375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 878.3484497070312 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 653.2013549804688 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 675.8939208984375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 2705.383544921875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 1572.3984375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 586.952392578125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 735.7757568359375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7113, loss_val: nan, pos_over_neg: 735.4239501953125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 1683.779052734375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7151, loss_val: nan, pos_over_neg: 440.2469177246094 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 1246.51806640625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 856.7133178710938 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 482.7614440917969 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 986.4403686523438 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 667.038818359375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 1551.8974609375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 1319.7425537109375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 617.3592529296875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7137, loss_val: nan, pos_over_neg: 728.0228271484375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 833.2728881835938 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 874.4877319335938 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 1994.850341796875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1489.2294921875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 619.8143310546875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1411.4754638671875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 1158.388427734375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 894.25634765625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1045.7674560546875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 522.8936157226562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1642.55029296875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1224.1109619140625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 1126.8065185546875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 639.6080322265625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 840.9818115234375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1138.7677001953125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 1148.1700439453125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 650.5845336914062 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 584.7374267578125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7134, loss_val: nan, pos_over_neg: 484.1093444824219 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 568.8124389648438 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 896.7522583007812 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7169, loss_val: nan, pos_over_neg: 559.0078125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 684.4794921875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 709.6908569335938 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7136, loss_val: nan, pos_over_neg: 713.8984375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 547.3809204101562 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 720.1573486328125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 779.9279174804688 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 791.0984497070312 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7113, loss_val: nan, pos_over_neg: 587.409423828125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 704.0819091796875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 757.3458862304688 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 1298.996826171875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 910.2495727539062 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 1112.0860595703125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 701.157470703125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 661.1856689453125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 852.8970947265625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7113, loss_val: nan, pos_over_neg: 992.0645751953125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 714.0220947265625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1984.2445068359375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 687.245849609375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.713, loss_val: nan, pos_over_neg: 798.0160522460938 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7113, loss_val: nan, pos_over_neg: 924.4708251953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 688.3316650390625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 580.9290771484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 825.8161010742188 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7142, loss_val: nan, pos_over_neg: 448.4935607910156 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 685.82568359375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 783.1661376953125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 1739.9910888671875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 703.815185546875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 1558.060791015625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7132, loss_val: nan, pos_over_neg: 537.52685546875 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 488.5296630859375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 682.9415283203125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 664.3716430664062 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1166.2633056640625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 766.8655395507812 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 749.2306518554688 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 633.4615478515625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 472.12933349609375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1495.1641845703125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 834.737060546875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 904.2552490234375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7129, loss_val: nan, pos_over_neg: 451.2237548828125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 775.0525512695312 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 1297.3377685546875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 977.6561279296875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 637.4329223632812 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 727.321533203125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [40:39<101597:39:42, 1219.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 596.5917358398438 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 749.1849975585938 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1097.8807373046875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 1051.348876953125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 1031.9130859375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 673.9230346679688 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 1101.17431640625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 782.6641845703125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 922.27392578125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7144, loss_val: nan, pos_over_neg: 489.356201171875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 828.0240478515625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1252.446533203125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 646.3556518554688 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 845.0199584960938 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 927.581787109375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1121.561767578125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 949.5933837890625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 505.2004089355469 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 816.4784545898438 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 1155.4388427734375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 1931.5194091796875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 692.4602661132812 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 647.196044921875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 727.68896484375 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 2004.8465576171875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 792.0315551757812 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7112, loss_val: nan, pos_over_neg: 1191.766845703125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 1369.9866943359375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 907.0806274414062 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 1739.926025390625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 1053.539794921875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 1336.68310546875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 805.7808227539062 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 718.0416870117188 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 761.522216796875 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 2104.132568359375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 902.726318359375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 913.6054077148438 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 936.1779174804688 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 762.58740234375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 1222.5408935546875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 790.7820434570312 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 660.9495849609375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 1357.5455322265625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 1437.5316162109375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 535.6690673828125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 489.4368591308594 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 998.1935424804688 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7118, loss_val: nan, pos_over_neg: 1092.00927734375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 622.5584716796875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7146, loss_val: nan, pos_over_neg: 1043.9305419921875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1537.7098388671875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7117, loss_val: nan, pos_over_neg: 838.932373046875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7131, loss_val: nan, pos_over_neg: 801.1484985351562 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 860.3329467773438 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1736.303955078125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 816.90380859375 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 1061.090087890625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 686.1688842773438 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7127, loss_val: nan, pos_over_neg: 633.4924926757812 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 1005.7517700195312 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 528.6473999023438 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1377.390625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 776.69482421875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 958.7656860351562 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1160.940185546875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 520.1412353515625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 527.7688598632812 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 668.5697631835938 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 1106.2928466796875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 980.095458984375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 699.91552734375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7108, loss_val: nan, pos_over_neg: 765.9263305664062 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7116, loss_val: nan, pos_over_neg: 835.131591796875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7114, loss_val: nan, pos_over_neg: 1360.7252197265625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 1012.2850952148438 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 932.34326171875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 496.29248046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 620.1654663085938 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 1124.765869140625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 1284.9454345703125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7125, loss_val: nan, pos_over_neg: 717.5924072265625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 831.5381469726562 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 615.9906005859375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1334.21142578125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1629.6142578125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7106, loss_val: nan, pos_over_neg: 927.1744995117188 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 673.95361328125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1097.4510498046875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 798.8763427734375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 1338.888671875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7124, loss_val: nan, pos_over_neg: 608.12890625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 854.4386596679688 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 531.4779052734375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1639.318359375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 702.0794677734375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 898.0543212890625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1606.513916015625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 705.1275024414062 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 906.371337890625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7107, loss_val: nan, pos_over_neg: 668.5762939453125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 835.80224609375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 720.3618774414062 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 899.64404296875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 619.44482421875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 1139.6463623046875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 777.6593627929688 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 802.2880249023438 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 844.2015991210938 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1380.129638671875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 836.4494018554688 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 1090.927001953125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 570.5625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 817.3662109375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 731.547607421875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1169.9649658203125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 558.87255859375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 666.1212768554688 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 546.1926879882812 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1119.7139892578125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 847.191650390625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 684.9761352539062 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7079, loss_val: nan, pos_over_neg: 612.2483520507812 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 653.7844848632812 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7112, loss_val: nan, pos_over_neg: 653.2659912109375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 956.6780395507812 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 2584.283447265625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 855.5491333007812 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 984.25244140625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.711, loss_val: nan, pos_over_neg: 682.3468017578125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 999.27099609375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1672.721435546875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1146.50341796875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1006.5851440429688 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1028.7486572265625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 2095.853515625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1440.9844970703125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 814.2662963867188 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 1194.4468994140625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 1136.8433837890625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 927.2514038085938 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1277.8389892578125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 598.0260620117188 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 1177.7198486328125 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 847.0182495117188 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1632.9915771484375 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 980.6083984375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 1115.677001953125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 753.0805053710938 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 1278.658447265625 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1381.3013916015625 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.712, loss_val: nan, pos_over_neg: 1836.3712158203125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 903.9476928710938 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 985.9781494140625 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 1319.3232421875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 1057.5472412109375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 834.8726196289062 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 1909.446533203125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 2282.4384765625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 895.748046875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 2836.277587890625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 1616.021240234375 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 1443.645751953125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 798.9285888671875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1444.3468017578125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 1144.2596435546875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 876.1807861328125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 2790.619140625 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 1687.9901123046875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 5472.08740234375 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 950.2416381835938 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1131.5732421875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 2005.1126708984375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 990.990234375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1094.32470703125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 779.6544189453125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 654.8622436523438 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 1103.97412109375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 2139.697265625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1995.90185546875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 597.5008544921875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 675.9367065429688 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1321.638427734375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1451.406982421875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1240.368896484375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1077.3201904296875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1413.89208984375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 3702.7294921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 1105.9500732421875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 2101.824462890625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 1197.9967041015625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 876.68310546875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 703.75390625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 1233.7459716796875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 890.0921630859375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7135, loss_val: nan, pos_over_neg: 550.7957763671875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 786.1317749023438 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7101, loss_val: nan, pos_over_neg: 727.023681640625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 564.876953125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 977.5384521484375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 668.413818359375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 894.6598510742188 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7121, loss_val: nan, pos_over_neg: 519.017578125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 490.40045166015625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 859.9979248046875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 664.004150390625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7109, loss_val: nan, pos_over_neg: 960.7360229492188 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 772.4507446289062 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 663.7689819335938 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 815.2861938476562 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 668.276611328125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 884.5106201171875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 1091.447265625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7079, loss_val: nan, pos_over_neg: 730.1029052734375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7111, loss_val: nan, pos_over_neg: 719.2302856445312 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 881.6685791015625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 936.8165893554688 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 798.5408325195312 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 1055.8681640625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7111, loss_val: nan, pos_over_neg: 2129.017578125 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7103, loss_val: nan, pos_over_neg: 685.44189453125 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 922.9400024414062 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 721.1275634765625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1521.9493408203125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 904.105712890625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7079, loss_val: nan, pos_over_neg: 1362.3402099609375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 621.4930419921875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7093, loss_val: nan, pos_over_neg: 555.288330078125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1501.951416015625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 665.019287109375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 650.564208984375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1146.640869140625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7105, loss_val: nan, pos_over_neg: 792.8001708984375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 702.750732421875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 705.8387451171875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 1163.6297607421875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 704.5771484375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 543.5099487304688 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 848.8514404296875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1343.6409912109375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 879.5195922851562 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 753.2459106445312 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 717.6357421875 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7099, loss_val: nan, pos_over_neg: 778.9183959960938 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1021.3573608398438 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1393.7900390625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1260.1129150390625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 969.6696166992188 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 902.3311767578125 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 1630.4183349609375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 1057.4849853515625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1449.4478759765625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1089.34375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1483.9595947265625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 872.0125122070312 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7104, loss_val: nan, pos_over_neg: 551.6278686523438 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 2032.414794921875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7079, loss_val: nan, pos_over_neg: 968.7130126953125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 1164.606689453125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7097, loss_val: nan, pos_over_neg: 575.3568725585938 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1081.1783447265625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 808.6788940429688 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 955.3399658203125 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 1854.985595703125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 665.795166015625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 1545.4420166015625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 1330.9818115234375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 818.701416015625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 853.4935913085938 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 839.9154052734375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1762.4781494140625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 1174.51318359375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 803.2550048828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 1273.2794189453125 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 2087.6640625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 3147.44482421875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1526.5262451171875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1137.8177490234375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 1086.1058349609375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 2091.223388671875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1204.4383544921875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 1490.49560546875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 854.497802734375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1002.150634765625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7102, loss_val: nan, pos_over_neg: 917.1445922851562 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 810.1991577148438 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 974.8551025390625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1696.673095703125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1809.4058837890625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1490.947509765625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 742.835693359375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7079, loss_val: nan, pos_over_neg: 1525.4443359375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1720.5687255859375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 735.8154296875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 740.7290649414062 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 811.5096435546875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1808.0394287109375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1858.7611083984375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 823.9097290039062 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 994.3821411132812 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1053.6929931640625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 1393.0155029296875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 1387.0780029296875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 951.7915649414062 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 776.214111328125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 1706.2978515625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 821.201416015625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7095, loss_val: nan, pos_over_neg: 777.454833984375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 883.5653686523438 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 607.9634399414062 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 841.401611328125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1249.780517578125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 675.079345703125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 727.4449462890625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 1161.30712890625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 990.6929931640625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 1099.4990234375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 1442.6187744140625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 700.4071655273438 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1363.3743896484375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1115.4337158203125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1064.9678955078125 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 815.0595092773438 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1468.5423583984375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1023.4678344726562 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 1365.607666015625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 3677.9921875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 2416.173828125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 2432.5634765625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7089, loss_val: nan, pos_over_neg: 1068.674072265625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 750.964111328125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 1385.327392578125 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1281.6279296875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 2047.8543701171875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1161.1246337890625 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1243.458251953125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 1196.1298828125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 1083.269287109375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.71, loss_val: nan, pos_over_neg: 1438.6904296875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 1180.7532958984375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 2161.244140625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1226.111083984375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 869.4873046875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 902.7815551757812 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 2603.1962890625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1935.3409423828125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1474.1102294921875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1159.5869140625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1026.7833251953125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 811.2511596679688 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1646.4306640625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1470.018310546875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 769.6103515625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 885.4452514648438 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1194.7757568359375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1106.6171875 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 684.36181640625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1489.540283203125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1092.4755859375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1541.20458984375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1363.20263671875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 823.4775390625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1063.3294677734375 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 1430.6820068359375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1685.497314453125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 738.4329223632812 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1783.90087890625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 1170.8687744140625 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 1547.5875244140625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 1065.9593505859375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 769.3052978515625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1582.71044921875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1857.46923828125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1191.5869140625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 795.420654296875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 862.3073120117188 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 586.6792602539062 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 858.6049194335938 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 817.7006225585938 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 769.5978393554688 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 908.5963745117188 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 1169.72509765625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7083, loss_val: nan, pos_over_neg: 668.7379760742188 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 802.4619140625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 544.0197143554688 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1465.2799072265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1339.0123291015625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 592.23828125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 744.542724609375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 990.6934814453125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 903.799072265625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 1083.194091796875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 873.5279541015625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1022.9308471679688 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 716.7078247070312 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 791.7723999023438 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 1085.50146484375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7088, loss_val: nan, pos_over_neg: 706.63720703125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 1178.4571533203125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1197.6075439453125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1575.0421142578125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 1248.1998291015625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 860.3549194335938 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1208.2091064453125 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1897.1116943359375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 782.8346557617188 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 933.8847045898438 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 936.1902465820312 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1188.828857421875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1209.0911865234375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1405.62451171875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 734.5578002929688 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1103.42578125 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1115.65283203125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 1884.1497802734375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 688.3697509765625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1596.03466796875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1007.587158203125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 659.340087890625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 1473.58544921875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 808.1079711914062 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 985.8690795898438 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1324.5531005859375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 1333.1351318359375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 2823.363525390625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1459.6707763671875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 869.4323120117188 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1699.8560791015625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 2140.279296875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7069, loss_val: nan, pos_over_neg: 893.0177001953125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1083.11474609375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.708, loss_val: nan, pos_over_neg: 1407.237060546875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1121.08740234375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1521.313720703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 938.9989013671875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7122, loss_val: nan, pos_over_neg: 609.0653076171875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1039.7996826171875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 839.9945068359375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 2096.846923828125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1042.117431640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1007.0840454101562 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1042.0615234375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1272.091796875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1749.8145751953125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 1370.51416015625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 667.6150512695312 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 747.0621337890625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 680.58984375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 1135.431884765625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 4298.50439453125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 800.5081787109375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 529.5325317382812 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 669.6528930664062 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 1155.3592529296875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1995.8775634765625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 1275.89892578125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 885.5494995117188 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 955.8452758789062 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1701.75390625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1940.29296875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1116.4097900390625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 541.3190307617188 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 473.2097473144531 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1122.4088134765625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1031.03466796875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 993.5203857421875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 748.145263671875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.709, loss_val: nan, pos_over_neg: 546.3617553710938 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 1308.9471435546875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 885.311279296875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 653.4698486328125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 653.23095703125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7096, loss_val: nan, pos_over_neg: 810.5413208007812 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 841.0040893554688 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1349.6097412109375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 728.6146240234375 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 975.9068603515625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1459.344970703125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1748.2451171875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 879.974853515625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1396.9991455078125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 772.7175903320312 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 814.7318115234375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1632.528564453125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1558.913330078125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 939.8006591796875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7076, loss_val: nan, pos_over_neg: 707.9426879882812 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 794.5685424804688 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1086.757080078125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 822.69970703125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1158.332275390625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 931.0258178710938 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 770.8046264648438 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1176.981689453125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1397.314697265625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1068.0855712890625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 876.2448120117188 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1837.564697265625 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1622.3380126953125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1083.6588134765625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1070.4267578125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1037.3980712890625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 859.7412719726562 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 778.2101440429688 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1049.642822265625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1525.4974365234375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 2105.32958984375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 4316.25927734375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 749.3087768554688 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1004.580810546875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1635.7314453125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1049.3590087890625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1404.025390625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1170.186279296875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 1692.4625244140625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 643.2181396484375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1575.7147216796875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 674.0848388671875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 906.878173828125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1005.9882202148438 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 941.8352661132812 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1129.79345703125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1260.95947265625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 982.924560546875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1972.296142578125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1111.3521728515625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1047.6217041015625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1296.483642578125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 645.3322143554688 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1012.8549194335938 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 906.2485961914062 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 828.4228515625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 1018.2127685546875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1619.8074951171875 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 652.9146118164062 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 752.09423828125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 843.6179809570312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1653.2476806640625 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 848.01416015625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 733.8109130859375 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1322.9285888671875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1056.9830322265625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1000.821044921875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 988.8541259765625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 764.0076904296875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 785.6561889648438 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7077, loss_val: nan, pos_over_neg: 1014.3096313476562 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 850.2019653320312 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 746.718505859375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 849.1590576171875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 642.7809448242188 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 874.7010498046875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1408.748046875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 665.449462890625 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 844.9638671875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1238.7174072265625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 522.6755981445312 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 593.294921875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 618.3743286132812 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 796.3343505859375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1229.17529296875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1055.345458984375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 938.2819213867188 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 837.275634765625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1901.2579345703125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 599.2966918945312 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 801.0098876953125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1248.6357421875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1092.8197021484375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 822.1093139648438 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1475.846435546875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7091, loss_val: nan, pos_over_neg: 855.234619140625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1095.45947265625 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 911.2034912109375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1124.5628662109375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 1624.753173828125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 550.748779296875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1099.4676513671875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 832.6326293945312 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1004.4449462890625 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 852.7164306640625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1002.455810546875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 700.2894287109375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 936.972412109375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 1494.9117431640625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 644.4807739257812 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1293.408203125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1356.0986328125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7098, loss_val: nan, pos_over_neg: 529.6727905273438 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 2212.351806640625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7092, loss_val: nan, pos_over_neg: 749.107177734375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 18604.380859375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1924.3035888671875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1133.8739013671875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1606.564208984375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 614.6019287109375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1521.7681884765625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1583.2056884765625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 1121.288330078125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 659.376220703125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 1890.5853271484375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 642.4374389648438 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 972.9492797851562 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1182.222412109375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1151.310546875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1594.97900390625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 835.05078125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 619.4322509765625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 523.045166015625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1555.6083984375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1006.05517578125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 984.7991333007812 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 700.2279663085938 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1161.2469482421875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 930.1527099609375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 787.1986694335938 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 756.9960327148438 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 937.9326171875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 781.1389770507812 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1498.8226318359375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1219.7708740234375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 749.8764038085938 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 562.3413696289062 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 846.5160522460938 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1321.4344482421875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7081, loss_val: nan, pos_over_neg: 865.7256469726562 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 602.3550415039062 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 615.3099975585938 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 783.96044921875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 3567.345458984375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1761.118896484375 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7087, loss_val: nan, pos_over_neg: 804.5143432617188 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 624.396728515625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 828.1222534179688 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1404.0596923828125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1050.8238525390625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 789.5386352539062 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1008.6640625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 2943.376220703125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 719.3353881835938 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1323.0494384765625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 729.8629150390625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7065, loss_val: nan, pos_over_neg: 679.6173095703125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 834.585693359375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 730.1830444335938 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7074, loss_val: nan, pos_over_neg: 850.6067504882812 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1651.9227294921875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1009.9429931640625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7066, loss_val: nan, pos_over_neg: 488.3876953125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7072, loss_val: nan, pos_over_neg: 767.8733520507812 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1214.8114013671875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1737.6865234375 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 888.6203002929688 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 669.3662719726562 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1657.5009765625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 790.8016357421875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1198.3306884765625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1165.2845458984375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 667.6196899414062 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 643.889404296875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 2370.61474609375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 2045.0623779296875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1071.9591064453125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1779.504150390625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 1073.6749267578125 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 4990.81005859375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 2315.192138671875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1306.14208984375 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 747.2717895507812 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7085, loss_val: nan, pos_over_neg: 1560.3118896484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1335.6580810546875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1090.6568603515625 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 796.0112915039062 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 929.8478393554688 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1597.16748046875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1822.34228515625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 3372.1142578125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 854.8535766601562 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1275.0672607421875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1953.94921875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 921.0333251953125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 2587.884033203125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1579.416259765625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1166.0306396484375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1271.1600341796875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1253.9154052734375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 3925.359130859375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1461.2591552734375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 2811.120849609375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1618.4803466796875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1519.313720703125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1023.8822021484375 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 887.17919921875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1678.21826171875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 2153.132080078125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:00:56<101525:31:13, 1218.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1216.7386474609375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1248.86279296875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1293.0836181640625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1608.5714111328125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 791.5162353515625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1373.355224609375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1252.102294921875 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 699.5995483398438 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 1155.4427490234375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 903.2520141601562 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7075, loss_val: nan, pos_over_neg: 621.572509765625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 902.7415161132812 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 887.8201293945312 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 827.6951293945312 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 1075.6151123046875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1169.8465576171875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1166.1368408203125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1140.0699462890625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 2339.228515625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 3724.678955078125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1179.1583251953125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7078, loss_val: nan, pos_over_neg: 734.8576049804688 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1438.7484130859375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 928.4097900390625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 873.5755004882812 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 876.0936889648438 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1102.1611328125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1556.2520751953125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1341.791259765625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 977.2308349609375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1136.6651611328125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 10452.939453125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 2648.587646484375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 2155.281982421875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 820.7731323242188 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1088.52392578125 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1375.030029296875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1803.803955078125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1147.69677734375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 1005.873291015625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1063.0533447265625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 721.6592407226562 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1208.5577392578125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1107.3719482421875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1540.3951416015625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1071.93896484375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1583.1895751953125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 877.7852172851562 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1419.549072265625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 839.2547607421875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1053.091552734375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 802.3837280273438 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 995.6190185546875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 908.4887084960938 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1411.8428955078125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 3892.0068359375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1139.4412841796875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1392.2183837890625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1288.559326171875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1012.6026611328125 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1023.3289184570312 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 767.8637084960938 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 973.865234375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 953.8046875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 1233.3648681640625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1151.5943603515625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 889.97021484375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 577.4459228515625 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1145.4984130859375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 640.5794067382812 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1848.781494140625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1059.6346435546875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 944.6529541015625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 979.5408325195312 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 2041.14208984375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1403.461181640625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1118.3106689453125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1329.152587890625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1032.783203125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 767.5209350585938 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1037.6585693359375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 978.1127319335938 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1562.99072265625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1191.731689453125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 810.43310546875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 687.6922607421875 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1797.145751953125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1388.471435546875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1028.6689453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 859.1168212890625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1414.287109375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 864.851806640625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7094, loss_val: nan, pos_over_neg: 809.4099731445312 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 1520.3984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1125.439697265625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1440.5546875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1624.698486328125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 2826.135009765625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1158.6162109375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1314.255126953125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7067, loss_val: nan, pos_over_neg: 1460.41845703125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 23126.333984375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7082, loss_val: nan, pos_over_neg: 1197.712646484375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 3469.539794921875 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 3636.629638671875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 2979.527587890625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1705.6337890625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1508.5755615234375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 2564.369140625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1080.601806640625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1284.060546875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1527.8740234375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1720.7015380859375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1184.8314208984375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 925.2708740234375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 6080.03271484375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1194.884521484375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1212.3232421875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1419.226318359375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1892.3128662109375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1221.9072265625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1037.0938720703125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 861.3970947265625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1863.9757080078125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1656.50927734375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 842.8095092773438 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 693.256103515625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 3074.8388671875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1259.4451904296875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 936.1034545898438 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 1096.271728515625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 568.5660400390625 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1072.61328125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1560.530517578125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 972.4644775390625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7086, loss_val: nan, pos_over_neg: 1136.16748046875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 879.0419311523438 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1500.7607421875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1310.9111328125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 819.7770385742188 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 927.8618774414062 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 2283.25390625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1678.5128173828125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1262.3497314453125 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1674.5390625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1468.07470703125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 900.7266235351562 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1413.6689453125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 2364.23779296875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 1015.2114868164062 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 943.885986328125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1607.478515625 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7054, loss_val: nan, pos_over_neg: 510.1249084472656 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 721.96923828125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 2623.933349609375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1180.227783203125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 803.6761474609375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1031.8704833984375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1156.379638671875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 901.0643920898438 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 2241.491455078125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 1346.067138671875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 7870.35009765625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1209.8597412109375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 829.4833984375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1150.8184814453125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1715.551025390625 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1018.4676513671875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 495.9579772949219 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1198.2176513671875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1310.325439453125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1497.8316650390625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1654.59619140625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1315.9254150390625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1423.2061767578125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 702.9444580078125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 760.9514770507812 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 3393.9326171875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 2612.52734375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 714.0859985351562 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 852.4857177734375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 854.2993774414062 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1474.2197265625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1481.4403076171875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 938.9686889648438 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1223.9190673828125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1103.4261474609375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7084, loss_val: nan, pos_over_neg: 1005.03076171875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1322.5003662109375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1206.9207763671875 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 825.7449340820312 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1147.5186767578125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 4779.38916015625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1198.3404541015625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 673.2864379882812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 800.7540893554688 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 804.8651733398438 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 779.562744140625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 910.0870971679688 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1154.9344482421875 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1025.1868896484375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 922.7103271484375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 3438.536376953125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 973.029052734375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 1266.6195068359375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 738.7264404296875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 654.9597778320312 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 848.5651245117188 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1280.686767578125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 540.3800659179688 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 616.7562255859375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7071, loss_val: nan, pos_over_neg: 530.6998901367188 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 844.0418701171875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2782.25634765625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 937.7635498046875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1011.2093505859375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 2907.515380859375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1390.501220703125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 2344.3662109375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 906.4346923828125 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 973.4155883789062 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 984.2807006835938 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 885.4307861328125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 688.0291137695312 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 662.0551147460938 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 910.1251220703125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 1025.374755859375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1230.5263671875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1015.30712890625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 803.4353637695312 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1920.20703125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 962.3142700195312 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 885.9393920898438 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 28514.0390625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1191.613525390625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 890.1990356445312 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7068, loss_val: nan, pos_over_neg: 1429.3603515625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1066.3719482421875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 2733.507080078125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1194.6031494140625 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1322.5821533203125 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 805.0592041015625 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1799.8887939453125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1667.6043701171875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1696.4517822265625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1112.2474365234375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1433.0614013671875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1177.8046875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1704.7364501953125 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1120.8848876953125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 2004.078857421875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1350.681396484375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 747.0523681640625 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 858.4243774414062 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.707, loss_val: nan, pos_over_neg: 1277.7071533203125 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 2710.94873046875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 562.32080078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 780.70556640625 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1228.752685546875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 2046.8558349609375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1590.189697265625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 2438.907958984375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1472.3477783203125 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1195.428466796875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1152.627685546875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2362.2978515625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 2412.146484375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 859.4102172851562 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 2134.267333984375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1242.1824951171875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 7817.69287109375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1921.951171875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 1042.6534423828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1161.9151611328125 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 728.0498046875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1046.3359375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 1078.7969970703125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 2447.530517578125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 1456.3341064453125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1518.5888671875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1273.224609375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1180.289306640625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 2140.4736328125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 804.5253295898438 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1065.682373046875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7064, loss_val: nan, pos_over_neg: 988.1835327148438 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 661.2169799804688 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1415.756103515625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1121.1400146484375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 852.2019653320312 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7053, loss_val: nan, pos_over_neg: 712.3053588867188 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1055.3145751953125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 2035.0052490234375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1203.5867919921875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 874.4415283203125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 782.2097778320312 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1995.629150390625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 972.9759521484375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 986.9927368164062 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1228.217529296875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 2270.31494140625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7059, loss_val: nan, pos_over_neg: 2460.07763671875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1196.06884765625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 811.7247924804688 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1458.987060546875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1138.0491943359375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1607.778076171875 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 968.190673828125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1004.5831909179688 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1109.1558837890625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 952.3356323242188 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1029.2462158203125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 744.1431274414062 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1302.1634521484375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1250.4527587890625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1843.1845703125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1152.388671875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1310.2818603515625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1467.9171142578125 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1900.0201416015625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1449.0318603515625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 812.062744140625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 875.6671752929688 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 859.2577514648438 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1265.4490966796875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 927.357666015625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 855.8307495117188 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1275.855224609375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7062, loss_val: nan, pos_over_neg: 749.803466796875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 960.9705200195312 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1313.2095947265625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 988.7447509765625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 658.1904907226562 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 771.7538452148438 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 945.0037231445312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 887.0016479492188 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1041.6395263671875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 744.1748657226562 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 613.604248046875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1705.590576171875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1090.0675048828125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 681.6402587890625 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1019.2980346679688 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 3043.8505859375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1343.2806396484375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 781.3299560546875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 803.6015625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 2270.857666015625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1583.5479736328125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1739.9283447265625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 716.3430786132812 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 2023.9986572265625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2487.644287109375 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1748.429443359375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1370.80908203125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 1683.29150390625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1537.7935791015625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 649.5958251953125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1115.8406982421875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3144.556884765625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1639.750732421875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1153.377685546875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1285.1373291015625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1451.7255859375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2576.44189453125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1386.0159912109375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1148.705078125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1168.0013427734375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 2114.47021484375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1441.498046875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1332.82666015625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 691.3773803710938 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1936.6915283203125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1356.8438720703125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1104.63623046875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1847.8778076171875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1087.55859375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1728.557373046875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 630.9349975585938 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1054.7998046875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 803.8193359375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 913.1686401367188 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1104.423583984375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 780.5673828125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1194.7723388671875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 672.513671875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1460.379150390625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1118.5526123046875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 998.322509765625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1015.1450805664062 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7042, loss_val: nan, pos_over_neg: 699.8860473632812 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 1114.6798095703125 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1829.271484375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 2196.59765625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 2146.760009765625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1254.9183349609375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 713.8425903320312 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1849.614013671875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 903.4545288085938 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1084.1944580078125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 880.8136596679688 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7055, loss_val: nan, pos_over_neg: 632.6796264648438 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1356.024169921875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 765.6887817382812 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1075.740966796875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 753.4410400390625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 1190.6055908203125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1712.6602783203125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1199.9947509765625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 913.7982177734375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 1017.2267456054688 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1274.9654541015625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1479.198974609375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1010.1128540039062 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1076.92236328125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1251.9764404296875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 2336.892822265625 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1595.9991455078125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1049.984375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 723.1724853515625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 932.3294067382812 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1383.703125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1415.96435546875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1475.148681640625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1672.01708984375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1730.17431640625 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 2080.95947265625 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1666.6746826171875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 2920.159912109375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 4353.208984375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1569.9434814453125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: -57664.16796875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 991.940673828125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 791.5186157226562 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1878.5479736328125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1234.87744140625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1344.640869140625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1087.00146484375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 771.67138671875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1615.2471923828125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1117.92529296875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1257.697265625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 952.3096923828125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1262.8624267578125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7056, loss_val: nan, pos_over_neg: 966.6295776367188 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 895.576904296875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2315.7626953125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1022.4959106445312 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7057, loss_val: nan, pos_over_neg: 709.9044189453125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 830.6472778320312 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1350.0650634765625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1105.32373046875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 745.806396484375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 695.83203125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 895.0779418945312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 10204.2451171875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1886.13623046875 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1116.0743408203125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 941.4493408203125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 2002.8756103515625 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1532.4150390625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1342.2608642578125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1265.8128662109375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1078.2977294921875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1091.697998046875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 986.5150756835938 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1345.1240234375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1528.1180419921875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1204.90478515625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 765.1224975585938 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 823.136962890625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1012.3219604492188 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1735.775634765625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1646.1910400390625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7046, loss_val: nan, pos_over_neg: 782.0852661132812 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1720.1597900390625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7058, loss_val: nan, pos_over_neg: 1776.1173095703125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 836.9471435546875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 4433.00732421875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1134.556396484375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1508.35107421875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1043.3350830078125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 592.4642333984375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 1275.9652099609375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1102.982666015625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1255.189697265625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 957.5075073242188 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1357.6341552734375 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 907.610595703125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1671.904052734375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1036.1602783203125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 837.1270141601562 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1601.2769775390625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2541.187255859375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 877.475341796875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 912.88232421875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7073, loss_val: nan, pos_over_neg: 764.505859375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 711.2171630859375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 799.1546020507812 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 956.7129516601562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 790.6526489257812 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 595.6060791015625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1309.89111328125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 675.568115234375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1217.2252197265625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1020.2464599609375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 908.7950439453125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1412.044677734375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 877.196533203125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1588.9013671875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 2273.684326171875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 773.4221801757812 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 985.85302734375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 2837.52880859375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1200.9490966796875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1077.196533203125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7038, loss_val: nan, pos_over_neg: 1071.2330322265625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 925.1204223632812 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2010.8363037109375 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1143.178466796875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 973.7110595703125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1151.860595703125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1397.0076904296875 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 10735.5947265625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1261.7542724609375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1034.7484130859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1321.92919921875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 1186.527099609375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1036.969482421875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 7377.31494140625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1017.8760375976562 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1177.1053466796875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 774.586181640625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 869.0755615234375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1027.535400390625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1976.6085205078125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1013.2615356445312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 2110.69091796875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 836.6331787109375 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1377.28369140625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1133.728515625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1131.677734375 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1325.7830810546875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1038.333740234375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1118.627685546875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 796.4326171875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2378.962158203125 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 782.1729736328125 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 973.9797973632812 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 731.4177856445312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 973.03857421875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1626.3311767578125 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1783.611572265625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1672.0792236328125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1103.3123779296875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7061, loss_val: nan, pos_over_neg: 1052.4305419921875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1245.1219482421875 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 894.40869140625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1256.473388671875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 868.508056640625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1510.2867431640625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 931.5433959960938 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1332.7989501953125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2086.86962890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1532.6307373046875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1747.9979248046875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1947.399169921875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1600.9974365234375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1644.8778076171875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7051, loss_val: nan, pos_over_neg: 1830.671142578125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 946.9385375976562 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 714.926513671875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2608.760498046875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1072.57568359375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1359.73974609375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 2763.44580078125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 939.75732421875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1151.8524169921875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2501.5830078125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1031.161865234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1522.2255859375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 753.8230590820312 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1139.3958740234375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1310.4442138671875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2351.009033203125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1370.843994140625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1571.930908203125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1344.8280029296875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1089.4166259765625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 934.4860229492188 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 791.4343872070312 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1116.148193359375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 3967.73779296875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1175.55029296875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1383.9002685546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1598.5299072265625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 969.65966796875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 693.9368896484375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1922.9840087890625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 767.0831298828125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1325.3399658203125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1579.1851806640625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 983.2369384765625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1225.254150390625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1015.8204345703125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1308.838134765625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1652.76513671875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 1847.7667236328125 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1555.8626708984375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1353.5010986328125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 919.8553466796875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1359.5018310546875 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 1693.9229736328125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 946.7076416015625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1241.2266845703125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1438.3233642578125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1316.67919921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1851.449951171875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 3352.66943359375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1917.2716064453125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 2031.646728515625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1565.75048828125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1161.6898193359375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 993.7491455078125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 3405.883544921875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2040.6051025390625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 2445.699462890625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1393.72412109375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1302.0089111328125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 999.6220092773438 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 2010.03466796875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1754.79150390625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1560.807861328125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1104.06298828125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 955.3717041015625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 988.7054443359375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1499.2274169921875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1780.5845947265625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 987.4049072265625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1239.0218505859375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1068.2130126953125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1670.496337890625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1544.40380859375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 2134.290283203125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 913.3794555664062 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1267.1810302734375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2101.788330078125 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1008.6427001953125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 982.0283203125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1061.93603515625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7063, loss_val: nan, pos_over_neg: 789.9653930664062 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1060.3184814453125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1175.314208984375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1387.4786376953125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.706, loss_val: nan, pos_over_neg: 900.4613037109375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 794.8316040039062 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 2245.79833984375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2200.506591796875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1046.4429931640625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1155.3819580078125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1652.8980712890625 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 610.2318725585938 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1402.8470458984375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1204.55908203125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 3360.308349609375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1071.248291015625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1290.64794921875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2251.155029296875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1815.5667724609375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 797.260498046875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 685.5366821289062 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 895.8861083984375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1153.8746337890625 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1200.654052734375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 627.10205078125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1113.15234375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1890.9990234375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 861.00927734375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 680.01708984375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 781.450927734375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 807.5241088867188 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 972.0863647460938 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1353.636962890625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 792.3676147460938 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1014.5196533203125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 739.9453735351562 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1197.9859619140625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1224.616455078125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 692.2127075195312 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1270.053466796875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 3610.11767578125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 888.3012084960938 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 788.2687377929688 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1612.98974609375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1850.848388671875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:21:15<101540:50:45, 1218.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1250.5992431640625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1761.4781494140625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 713.4094848632812 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1284.0623779296875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3361.99462890625 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 2943.10205078125 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 735.3368530273438 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 778.0721435546875 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 1008.6463623046875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 2416.265380859375 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 804.6087036132812 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1021.2711181640625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1904.921630859375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 3024.02099609375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1092.632080078125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 828.7857666015625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 836.1724853515625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1089.486572265625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1533.886474609375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1856.014404296875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2569.00244140625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1060.597412109375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1085.6724853515625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 1007.7828979492188 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7041, loss_val: nan, pos_over_neg: 2888.35888671875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 759.4686889648438 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1062.29248046875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 945.53076171875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1467.5233154296875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 3586.184326171875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1581.326904296875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 689.2476806640625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1289.389892578125 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1728.3812255859375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1056.67578125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 4575.32958984375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1733.8116455078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7037, loss_val: nan, pos_over_neg: 1133.6990966796875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1119.721923828125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 3072.47705078125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2434.22998046875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 2458.431884765625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3131.841796875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1362.135498046875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1904.3028564453125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2833.2451171875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1599.4490966796875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1123.0802001953125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1658.49560546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1943.0013427734375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2736.59326171875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2105.531005859375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2591.85205078125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1167.81982421875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1923.6082763671875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1685.72265625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1437.0401611328125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1319.5946044921875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7034, loss_val: nan, pos_over_neg: 725.79248046875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 740.1192626953125 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 852.33740234375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1392.0567626953125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2294.012939453125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 662.5732421875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 754.60791015625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 571.5272827148438 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 2442.23828125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 3205.66259765625 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1661.825439453125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1079.8760986328125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 777.1056518554688 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 614.7864379882812 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1852.1649169921875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1179.450927734375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1282.1202392578125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1217.732666015625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.704, loss_val: nan, pos_over_neg: 1237.2149658203125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1152.6607666015625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 969.0693969726562 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2068.105712890625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1514.386962890625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 552.5244140625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 834.8471069335938 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1921.7470703125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7049, loss_val: nan, pos_over_neg: 693.4208984375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 906.4271240234375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7044, loss_val: nan, pos_over_neg: 629.1396484375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1372.61962890625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1488.8692626953125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1237.6944580078125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2350.956787109375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1774.3975830078125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1362.221435546875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1768.94775390625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 8813.744140625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1025.994384765625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1786.5479736328125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1750.95361328125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2551.70751953125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2545.22607421875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1447.04931640625 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1905.6029052734375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1185.954345703125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2057.6728515625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 11204.525390625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1298.96484375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 939.1848754882812 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1327.1923828125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 4089.4111328125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1987.6529541015625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1366.877685546875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 852.9673461914062 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1269.32421875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2193.38818359375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1535.16796875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1273.5201416015625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 10307.27734375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1020.9119873046875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 2416.1220703125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1038.8072509765625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1467.82666015625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7045, loss_val: nan, pos_over_neg: 882.0748901367188 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1302.05859375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 819.5454711914062 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1142.6781005859375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2728.882080078125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1656.6942138671875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 738.7754516601562 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 840.6326904296875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 3425.812255859375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1640.089111328125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1176.1749267578125 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 940.9053344726562 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1016.722900390625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 2478.862060546875 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3059.68505859375 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 990.1534423828125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1778.505126953125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 3239.7392578125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 835.5379028320312 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7043, loss_val: nan, pos_over_neg: 977.6946411132812 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1534.5404052734375 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1163.5753173828125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1812.744384765625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 3832.765869140625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2342.070556640625 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 776.3103637695312 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 846.5159912109375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: -20395.5859375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1662.691162109375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1472.1099853515625 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 821.8391723632812 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1822.665771484375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 2948.755126953125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 3086.560791015625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1027.9708251953125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7052, loss_val: nan, pos_over_neg: 892.898681640625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1824.3338623046875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1499.1871337890625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1582.72802734375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1524.465087890625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1111.1072998046875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1744.76806640625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1383.048828125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1132.3133544921875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 1661.290283203125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 929.7550048828125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2212.997314453125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1334.40283203125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 951.824951171875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 737.6062622070312 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2416.757080078125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1243.3199462890625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1012.833740234375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1100.5411376953125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1568.6136474609375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1069.0362548828125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1409.2078857421875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 796.8528442382812 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1107.3336181640625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1229.85986328125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1463.75830078125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1385.7725830078125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1003.830078125 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2631.756103515625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1358.87353515625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.705, loss_val: nan, pos_over_neg: 851.4231567382812 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1528.6578369140625 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1343.0018310546875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 743.2804565429688 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1836.8446044921875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1167.49755859375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1051.9901123046875 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1386.87939453125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 893.5021362304688 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1777.4141845703125 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 2689.70166015625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 983.6351928710938 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1879.252197265625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1345.9134521484375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 5455.25732421875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2453.544921875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 6008.861328125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 949.5325927734375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 3487.9619140625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 3914.618408203125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1494.51220703125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1673.556396484375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1198.620849609375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1087.5858154296875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1780.380859375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1135.3726806640625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2083.535888671875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1009.9306640625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1264.7320556640625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 2939.8603515625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1347.093017578125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1398.9364013671875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1264.0245361328125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 2003.984130859375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 729.7112426757812 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1242.730712890625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 2552.01806640625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1328.5823974609375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 930.2683715820312 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 746.74951171875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 2163.813720703125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1235.135498046875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1450.9462890625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7026, loss_val: nan, pos_over_neg: 1471.3055419921875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 970.7135620117188 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1151.07861328125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7048, loss_val: nan, pos_over_neg: 1151.0443115234375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 2744.623046875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2043.3597412109375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1094.0103759765625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1507.72998046875 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1339.8756103515625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 2261.534912109375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 2348.404296875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 992.7486572265625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1619.114501953125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1089.871826171875 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1513.794189453125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 3744.973388671875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 1584.2742919921875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 4429.72900390625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 912.7260131835938 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1758.6351318359375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1541.1502685546875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1189.7484130859375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1504.556640625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1825.8486328125 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2026.5914306640625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1576.8775634765625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1793.652099609375 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1229.4468994140625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2757.888427734375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 3115.696044921875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 767.23095703125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1452.168212890625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1344.3524169921875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1437.407958984375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1504.202880859375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1663.432373046875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 2284.75390625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1628.2369384765625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1805.311279296875 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 2034.8880615234375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1756.224365234375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1103.3935546875 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1461.03466796875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1004.1943969726562 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1569.2222900390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1150.2933349609375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 955.0171508789062 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1610.0928955078125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1488.499755859375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2117.217041015625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1006.9425048828125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2878.5673828125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 3799.906982421875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2407.95361328125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1364.9317626953125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 4277.35400390625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 3773.4033203125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2500.718505859375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1330.0211181640625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1844.981689453125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 5054.7373046875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1151.0382080078125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 93540.828125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1210.1923828125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 3651.653076171875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2057.168212890625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 3463.54248046875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2663.916015625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2724.4423828125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1141.8037109375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 821.0526733398438 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: -2077657.625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1779.3328857421875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1536.3548583984375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 787.7614135742188 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 840.66455078125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1371.3497314453125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2638.015869140625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1551.6033935546875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 2419.76513671875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 730.1053466796875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 1217.7364501953125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1381.1048583984375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2145.266845703125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2907.695556640625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1558.4830322265625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1602.9136962890625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1489.2359619140625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1883.1602783203125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2143.5302734375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2069.05419921875 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1719.79443359375 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1618.7177734375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1875.0748291015625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2031.38720703125 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1734.278076171875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 2827.4970703125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3903.181396484375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1463.765625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 761.263916015625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1137.9244384765625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1209.9693603515625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 2138.717041015625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1893.5301513671875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1853.431396484375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1175.608154296875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 746.1936645507812 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 4007.514404296875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1058.9117431640625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 923.9360961914062 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1702.21875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 4403.4560546875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1982.986083984375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 6852.0771484375 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 3661.08544921875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1259.3587646484375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1238.2587890625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 3295.248779296875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1797.7479248046875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2943.659912109375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 3249.735595703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 968.978271484375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 3144.433837890625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1334.872314453125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1597.7430419921875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1371.0606689453125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1515.553466796875 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2524.65625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 2120.008056640625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1629.822265625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 3169.289794921875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1463.451416015625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 1966.57470703125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1603.0494384765625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2004.465087890625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1326.279541015625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1666.9849853515625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 797.1912231445312 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1215.7601318359375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2589.262939453125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1114.7032470703125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 901.9671630859375 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1822.4259033203125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7035, loss_val: nan, pos_over_neg: 961.878662109375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 686.154296875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1649.1451416015625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1832.0882568359375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1038.7801513671875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 704.3739013671875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1642.7486572265625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 2049.932861328125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1349.71142578125 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1144.49560546875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 778.0532836914062 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 881.079345703125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 921.5860595703125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1320.67236328125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 845.42626953125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1397.3778076171875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1089.6893310546875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1789.2110595703125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1656.2733154296875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2267.16650390625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2089.132080078125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1200.6571044921875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1630.460205078125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 3807.4697265625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1474.6668701171875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 946.5175170898438 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1344.064697265625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1029.030517578125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 3945.16650390625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1136.5068359375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 2876.183349609375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1341.6732177734375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1174.77734375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 966.1019287109375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 5558.115234375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1009.0573120117188 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1262.99267578125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1982.156005859375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1288.228271484375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 2081.453369140625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7028, loss_val: nan, pos_over_neg: 1143.8255615234375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1701.8128662109375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1395.6239013671875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1099.6136474609375 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 7928.6123046875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2223.035888671875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2088.140869140625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1454.681640625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 978.484375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1157.8218994140625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 3298.100341796875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2905.012939453125 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1472.3240966796875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2792.054443359375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1063.1258544921875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 4279.5498046875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1419.00244140625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1462.185302734375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2190.286865234375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1026.0438232421875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1597.7120361328125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 933.1008911132812 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1117.14306640625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2149.84912109375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 836.1614990234375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1630.1456298828125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1165.9959716796875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 988.6520385742188 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1261.8818359375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 4967.28662109375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 959.5552978515625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1062.339599609375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1499.8795166015625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1458.627685546875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1567.82080078125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1506.78955078125 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1520.9044189453125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1357.40869140625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7022, loss_val: nan, pos_over_neg: 821.3261108398438 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 797.3070678710938 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 820.080322265625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1999.4207763671875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 6979.96142578125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1270.17724609375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1664.68115234375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1983.328125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1311.287109375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 7772.64599609375 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2176.03076171875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1534.5152587890625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2425.114990234375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1806.11279296875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1866.646484375 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1850.9725341796875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1845.92529296875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1455.8177490234375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 3435.3603515625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1261.58056640625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2727.696044921875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1686.5093994140625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1502.9666748046875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 853.5552978515625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1566.5780029296875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1988.1287841796875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 8186.9365234375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2418.0576171875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7031, loss_val: nan, pos_over_neg: 1525.8157958984375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 3055.70751953125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2171.016357421875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1265.947021484375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2227.0458984375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 3309.677978515625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1058.953369140625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1317.28564453125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1636.8009033203125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1819.8385009765625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1646.85546875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1255.5439453125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1481.6092529296875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1220.7801513671875 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 5438.2099609375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 5750.53857421875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 911.3296508789062 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1271.9033203125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1250.87109375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 3481.92626953125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2069.491943359375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 929.3262939453125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1381.7579345703125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 994.4439697265625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 4469.05908203125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1832.64111328125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1158.012451171875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1807.0281982421875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2553.509033203125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 731.1437377929688 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1935.8604736328125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 6591.7724609375 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1239.3951416015625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1140.0341796875 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2283.61572265625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1877.943359375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1487.6341552734375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1186.279052734375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1783.26123046875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 786.5811157226562 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1797.40966796875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1189.7042236328125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1093.3006591796875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1288.687255859375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 976.7664184570312 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2106.759033203125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2290.680908203125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 828.4044189453125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1400.823974609375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1083.7779541015625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1346.5703125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1160.0665283203125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1210.9554443359375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1114.1312255859375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1056.080810546875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 986.75537109375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1115.88525390625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1988.233642578125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7027, loss_val: nan, pos_over_neg: 1511.268310546875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2346.306884765625 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1428.783447265625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1127.3104248046875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 722.3778076171875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1426.579833984375 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1012.5075073242188 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1790.3233642578125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1835.638671875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 641.46923828125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 719.68359375 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1329.4862060546875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1055.9581298828125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 964.5020751953125 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1186.490478515625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 703.6182250976562 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1025.5469970703125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 923.7987670898438 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2143.656982421875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1308.70751953125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 918.2246704101562 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1698.5394287109375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1104.431884765625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1056.5576171875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1470.8607177734375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2664.219970703125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1525.6798095703125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1497.8536376953125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2152.9248046875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1544.14697265625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1928.62646484375 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 2595.1796875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 6355.79052734375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1800.82470703125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1466.4158935546875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 3060.0341796875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 851.5563354492188 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1520.0137939453125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2075.176025390625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 1264.9754638671875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1131.1632080078125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7032, loss_val: nan, pos_over_neg: 1194.4398193359375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1386.2547607421875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1526.4444580078125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 981.4615478515625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1306.30615234375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 849.2942504882812 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2074.45947265625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1620.2413330078125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 980.0863647460938 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1017.5872802734375 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1539.73779296875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 982.8958740234375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1727.3311767578125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 919.9456787109375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1081.3857421875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1088.599853515625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1518.3975830078125 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1050.5174560546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 964.181396484375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2647.587646484375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 857.8303833007812 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 600.9998779296875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2464.89111328125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 4397.5869140625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1484.7276611328125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2392.638427734375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1040.0400390625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2749.711181640625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 852.9126586914062 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1751.321533203125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7024, loss_val: nan, pos_over_neg: 919.5913696289062 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1167.463623046875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1223.2890625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 722.6275024414062 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1390.0352783203125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1265.7615966796875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1315.91796875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 665.3855590820312 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2957.916748046875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 853.182861328125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1278.693359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2764.149169921875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 655.6978759765625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1400.3525390625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 4183.044921875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1705.3134765625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1190.9715576171875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1125.0419921875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1636.858154296875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1217.1533203125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1267.505859375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1959.1595458984375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2858.988037109375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1937.6353759765625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1979.6187744140625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1232.285400390625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1535.208740234375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 4378.34228515625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 16591.986328125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2552.5693359375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2005.6287841796875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1573.4239501953125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1158.4210205078125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1323.862548828125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1284.7425537109375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 3649.7734375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1554.207275390625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1521.8980712890625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1173.1302490234375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 2527.71728515625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1009.3170776367188 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1246.78369140625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 4594.712890625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 6529.91259765625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1929.131103515625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1120.0311279296875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 1430.4781494140625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1162.923828125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1115.33740234375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1821.8135986328125 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2584.311279296875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 962.2327270507812 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1193.0146484375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1926.1708984375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1294.9044189453125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2017.02392578125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 5283.10693359375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1322.026123046875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 850.6361083984375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2564.409912109375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 3286.215087890625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 807.3023071289062 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 757.4526977539062 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1401.4937744140625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1256.1895751953125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 2651.279296875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1161.8486328125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1251.131591796875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2709.549560546875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 7215.6376953125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1145.1220703125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1441.9893798828125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2148.0234375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 962.123291015625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1119.488525390625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1479.30322265625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1945.65673828125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 987.9127807617188 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 990.8665771484375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 4068.741943359375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1951.8922119140625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1572.6146240234375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1103.0379638671875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1070.993408203125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1221.95263671875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1141.6678466796875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7033, loss_val: nan, pos_over_neg: 1555.3492431640625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1200.588623046875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:41:31<101458:51:30, 1217.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 948.5049438476562 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1125.4866943359375 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1739.0802001953125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2107.21044921875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 957.59521484375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1103.5155029296875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1360.6513671875 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 882.6831665039062 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1408.296875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 793.5508422851562 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 974.2828369140625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1790.78564453125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1753.1053466796875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1169.3331298828125 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7036, loss_val: nan, pos_over_neg: 965.5284423828125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2157.317626953125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1259.24951171875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1963.6583251953125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1125.7652587890625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1567.4981689453125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 4230.74853515625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1161.108642578125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 820.7852172851562 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 556.2471923828125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2639.35400390625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1750.561279296875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 3845.405517578125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2267.98046875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 990.8222045898438 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2398.255859375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1635.2069091796875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1041.3360595703125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 919.1785888671875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 707.9661254882812 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1668.748291015625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2023.6712646484375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 859.4447631835938 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1688.3482666015625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1648.730224609375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 821.2672729492188 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1701.9471435546875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1379.6861572265625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2076.221435546875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1103.7286376953125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1490.7147216796875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 2193.56640625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 973.0989379882812 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1096.616455078125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1484.27099609375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 1048.99169921875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1025.9906005859375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1403.4329833984375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 913.5438232421875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1860.606689453125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1732.2000732421875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1349.095703125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 807.7711791992188 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1000.0445556640625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1375.2166748046875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1694.5911865234375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2900.265869140625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2736.99365234375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1489.27197265625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1308.5347900390625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1954.8653564453125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1035.7318115234375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1589.5076904296875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 5801.97412109375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1673.7872314453125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1291.8433837890625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1556.0126953125 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1696.0501708984375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1617.0401611328125 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1393.1375732421875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1175.6981201171875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 2133.5380859375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1677.2655029296875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1428.396240234375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1642.6053466796875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1194.4127197265625 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 7976.25634765625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7018, loss_val: nan, pos_over_neg: 947.6583251953125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1088.5933837890625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 4990.1982421875 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7019, loss_val: nan, pos_over_neg: 1158.763671875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1564.6177978515625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1101.27001953125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 2269.269775390625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1220.983154296875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2486.58984375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1645.1192626953125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1833.6234130859375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2913.693115234375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1484.6209716796875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1296.7012939453125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2463.12451171875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 5815.55712890625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1185.132568359375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1741.233154296875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1011.5430908203125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 4209.6123046875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1529.324462890625 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2474.748046875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1193.6427001953125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1236.065185546875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 2726.712646484375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2882.394287109375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1648.1114501953125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1390.1307373046875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1668.553466796875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1128.7021484375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2080.798095703125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1374.699462890625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1988.688232421875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 772.7191772460938 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 968.2367553710938 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1262.7506103515625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1421.5645751953125 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 771.7379150390625 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 884.4859619140625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 915.740234375 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 985.3906860351562 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2607.155029296875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1322.4908447265625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 859.486083984375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1726.71044921875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 2074.2490234375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1056.715576171875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 639.8411254882812 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 732.1244506835938 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1668.2205810546875 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1173.7098388671875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 841.4036254882812 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1580.7164306640625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2040.4857177734375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1460.490478515625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1962.9544677734375 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1483.394775390625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1238.734619140625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1418.476806640625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 10815.9990234375 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1267.6649169921875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1246.274658203125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1155.6507568359375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1438.767578125 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2152.4892578125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 5472.05859375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1397.4642333984375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 709.4962158203125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1214.18603515625 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1577.5257568359375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1808.226318359375 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 756.9754028320312 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1190.064208984375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 841.9357299804688 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 2136.09765625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1623.200927734375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1640.9749755859375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7039, loss_val: nan, pos_over_neg: 810.5061645507812 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 814.3351440429688 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1542.5335693359375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1752.3255615234375 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1102.295654296875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 8068.458984375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1891.530029296875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1633.9520263671875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2393.159423828125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1225.12890625 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1363.1986083984375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1219.621826171875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 806.47607421875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1238.1767578125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1224.5987548828125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1066.54541015625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1759.4207763671875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2303.168212890625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1495.8026123046875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 4758.48486328125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1477.830078125 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1569.8062744140625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1632.3958740234375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1947.528076171875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2162.64404296875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1766.9525146484375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1951.5513916015625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 2037.48486328125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1370.343994140625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1559.8150634765625 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1956.32421875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 1228.03662109375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2882.693359375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.702, loss_val: nan, pos_over_neg: 9466.71875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 29124.59375 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 843.019775390625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7025, loss_val: nan, pos_over_neg: 1158.767333984375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1088.8056640625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1917.450439453125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 2597.0693359375 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1316.3157958984375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1778.5721435546875 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 2333.94921875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.703, loss_val: nan, pos_over_neg: 935.5195922851562 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1860.97705078125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2741.7705078125 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 723.6273193359375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 2048.16943359375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1245.903564453125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1311.1136474609375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 10024.7880859375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 3696.791015625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 2080.9033203125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 141244.640625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1501.1370849609375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1501.5206298828125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2072.92138671875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1778.385498046875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1885.8023681640625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2321.809326171875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1234.1226806640625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1257.358642578125 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1399.83837890625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1316.056640625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1899.987548828125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 941.7249145507812 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1118.946044921875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 736.97900390625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 755.2059326171875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1019.2156372070312 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1171.2684326171875 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 962.8072509765625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1013.8490600585938 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 963.6951904296875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 958.8027954101562 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2146.6455078125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1760.103515625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 3516.69287109375 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1609.4058837890625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2458.462158203125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1640.805419921875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1208.0489501953125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2004.8192138671875 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2843.719970703125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1339.530029296875 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1240.5252685546875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 5110.50927734375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1672.8839111328125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1414.5592041015625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 818.0432739257812 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2026.344482421875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7029, loss_val: nan, pos_over_neg: 1357.2900390625 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1573.3011474609375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1077.4039306640625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1137.184814453125 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1166.15966796875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1021.9363403320312 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1413.1763916015625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1024.7652587890625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1004.7926635742188 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2319.562744140625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1674.0550537109375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2002.4814453125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1876.57763671875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 6086.8779296875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1711.4476318359375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 2049.694091796875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 956.4172973632812 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1097.841796875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2155.20068359375 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2390.322021484375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1308.3780517578125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1852.6463623046875 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 1526.729736328125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 3560.796630859375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1446.25341796875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1292.5035400390625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1260.2913818359375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 2849.70458984375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 2233.1806640625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 3163.482421875 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 3181.4951171875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1707.678955078125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 3350.509521484375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 4344.64404296875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2529.198974609375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2847.341064453125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2091.041748046875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 3670.41064453125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 3193.647216796875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1100.71923828125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 5257.94140625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2357.0654296875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1365.5274658203125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1403.5142822265625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1701.617919921875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1315.7205810546875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2324.78759765625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 947.5322265625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2112.392578125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 988.1465454101562 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 856.9434814453125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1121.1329345703125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 884.532470703125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 2033.2332763671875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1067.807861328125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1665.901611328125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1022.072998046875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 908.3836059570312 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 882.4720458984375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1701.01123046875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 4133.72119140625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 938.7411499023438 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 941.979248046875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 815.1088256835938 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1448.751953125 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2200.944091796875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1881.955810546875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 11135.6171875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1801.960693359375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1190.2750244140625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1170.2430419921875 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1753.172607421875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 963.8641357421875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1266.23681640625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1243.528564453125 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 3457.065673828125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1215.428955078125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3789.006103515625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1626.1241455078125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1111.915771484375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 979.913330078125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2218.54296875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1644.1402587890625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 15207.126953125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1477.9052734375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2171.9677734375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2370.783203125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2565.626220703125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2287.1767578125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2930.740234375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1935.8470458984375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1214.9969482421875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 3026.875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1036.3572998046875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1022.5684814453125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1537.411376953125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2948.16845703125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2176.655517578125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1382.9078369140625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1992.3416748046875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 2065.4375 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2477.971923828125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 893.5416870117188 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 12545.7861328125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7009, loss_val: nan, pos_over_neg: 778.1060791015625 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1731.3143310546875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1269.1953125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1826.9462890625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1050.1590576171875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1383.3929443359375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2000.24365234375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 2386.516357421875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1240.3509521484375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1797.5948486328125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 4749.46630859375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2840.77978515625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2142.25634765625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 4646.57568359375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1490.169921875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 998.8054809570312 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2402.93017578125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1601.9189453125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1398.499755859375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1211.9984130859375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 3842.080078125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 6382.28515625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1062.90380859375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1044.1473388671875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1665.56201171875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1777.8826904296875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2123.6123046875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1616.310546875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 796.9889526367188 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1276.5086669921875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1569.3292236328125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 3195.661376953125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 6923.05224609375 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1192.0291748046875 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1627.2412109375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 912.9943237304688 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 1105.899658203125 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2386.123779296875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2062.8251953125 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1254.022216796875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1651.7440185546875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1645.8006591796875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1751.4443359375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1252.4718017578125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1262.091064453125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2540.53076171875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 858.0095825195312 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 810.8004150390625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1173.51904296875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2338.5625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1273.62255859375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1464.8203125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 5416.02880859375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 793.11962890625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1207.6175537109375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1938.0546875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1067.3939208984375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 3174.024169921875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1461.2381591796875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 848.43212890625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1088.735595703125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 929.757568359375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1447.0924072265625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2848.151123046875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 5176.1474609375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 826.5458984375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1677.6136474609375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1713.5867919921875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1000.947021484375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1226.0140380859375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 5306.810546875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 791.8560791015625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 3032.811279296875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1165.176513671875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1250.6612548828125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1068.6082763671875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1841.871826171875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 4696.2412109375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2614.72216796875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 898.552490234375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2125.384033203125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 5226.86962890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1555.9737548828125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2378.718505859375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1374.6949462890625 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2332.575927734375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1473.8642578125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1242.42041015625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 3983.933837890625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 912.181396484375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2399.10986328125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1526.6475830078125 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1843.4730224609375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1440.5330810546875 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1782.558837890625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 3338.583740234375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1627.008544921875 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2682.829833984375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 4911.1953125 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2043.7637939453125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1664.1337890625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1784.5091552734375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 3828.777099609375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1338.8760986328125 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1254.529296875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2073.3095703125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1443.0498046875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2972.618896484375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1183.525634765625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1949.0716552734375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1352.2423095703125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1493.258056640625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1000.4359741210938 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1852.7275390625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 3539.84375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1307.864990234375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2716.35400390625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 671.776611328125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1804.046142578125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1391.432373046875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1590.759521484375 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 936.94677734375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2653.5703125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3477.65478515625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 3651.072509765625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1382.412353515625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1578.610595703125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 966.8950805664062 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 3429.134033203125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1999.6585693359375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1100.890625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2424.81640625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1665.5299072265625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1024.4658203125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1840.395751953125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1413.7159423828125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1462.3077392578125 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 843.5865478515625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1502.14697265625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1554.1724853515625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1984.684814453125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1302.680419921875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1064.4110107421875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 657.3882446289062 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1532.53662109375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 994.1768188476562 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1637.9642333984375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1657.7889404296875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 4120.6591796875 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1033.24560546875 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1082.1363525390625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1386.780029296875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1986.994873046875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1703.1881103515625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1392.5145263671875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 735.8599243164062 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1555.446533203125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3601.846923828125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2561.408935546875 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 920.5619506835938 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 581.2342529296875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 812.1276245117188 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1551.373291015625 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1199.1661376953125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 3264.48193359375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2205.54345703125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1144.1746826171875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 885.5380249023438 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1502.0545654296875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1285.3408203125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2060.84619140625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1258.7264404296875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1488.001708984375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 3422.0166015625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1464.12158203125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1529.7733154296875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 17217.4765625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2186.370849609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2365.560546875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2502.173583984375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2725.182861328125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 4024.8369140625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 5845.52392578125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1105.982666015625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1716.5302734375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2108.99072265625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 8237.0791015625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2444.941650390625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 1924.9913330078125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 3475.254150390625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 1765.534423828125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2670.0693359375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1937.419677734375 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1663.74853515625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2376.2216796875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1667.803955078125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7014, loss_val: nan, pos_over_neg: 1187.9197998046875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 2386.069091796875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1554.7891845703125 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1666.787841796875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2083.510498046875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1704.0955810546875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1081.3406982421875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1113.020751953125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 886.8159790039062 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2269.281005859375 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1215.5877685546875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1562.73974609375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1314.7725830078125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1825.4400634765625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1233.27099609375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2645.806640625 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1453.29296875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 968.189697265625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1281.65380859375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1255.7999267578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3430.85400390625 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1902.3360595703125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1401.1065673828125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1054.01220703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 1019.5987548828125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2283.2978515625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1582.6973876953125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1430.8658447265625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 678.9813842773438 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1698.4053955078125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1052.239013671875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1792.7005615234375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1370.5391845703125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 5518.3955078125 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1589.825927734375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1164.957763671875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1043.926513671875 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1250.755126953125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2558.552001953125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1512.44384765625 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1766.10888671875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1295.8336181640625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 893.41455078125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1065.05859375 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1729.599609375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 5026.5908203125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1674.0504150390625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1095.673095703125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 961.7598876953125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1032.7205810546875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1478.511962890625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2610.13623046875 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2617.67138671875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1615.98388671875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2003.921630859375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1298.38671875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 3235.802734375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1911.9381103515625 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1750.4456787109375 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1874.0894775390625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7016, loss_val: nan, pos_over_neg: 1229.868896484375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1174.68115234375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7047, loss_val: nan, pos_over_neg: 799.3450927734375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 15195.14453125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 4957.52392578125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2090.808349609375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1451.0531005859375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2623.948486328125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1717.1763916015625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2153.046142578125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2911.872314453125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2155.240234375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1256.8377685546875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 820.387939453125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 2958.896728515625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1203.802490234375 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2541.365234375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2250.052001953125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1127.3653564453125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1623.3336181640625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 819.3224487304688 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 855.7372436523438 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2207.15576171875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 987.7542114257812 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1752.764404296875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1984.430419921875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1396.6240234375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2287.57568359375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1264.372314453125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1354.984375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1242.0013427734375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2087.1767578125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2085.631103515625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 3519.77587890625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 2280.44873046875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2007.7841796875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1849.062255859375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1565.9683837890625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 3069.63623046875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1804.74072265625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 3031.603271484375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1186.918701171875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1570.2918701171875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2460.065185546875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1462.41064453125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2677.601318359375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1710.9171142578125 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 824.2815551757812 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1068.173583984375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 937.395263671875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2541.827392578125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 2671.8154296875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1785.164306640625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 839.2399291992188 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1703.939697265625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2357.978759765625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 5699.2294921875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1305.5933837890625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1443.3935546875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1258.566650390625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1265.78271484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1576.3052978515625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1831.284423828125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1850.6429443359375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1542.1087646484375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 4091.21533203125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2716.3359375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1537.649169921875 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 3115.55126953125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 3454.013671875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1520.91015625 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1920.608154296875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2715.8955078125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 12858.3056640625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1345.55810546875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1871.1754150390625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1252.691650390625 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1623.929443359375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1896.5159912109375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7017, loss_val: nan, pos_over_neg: 996.758544921875 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7003, loss_val: nan, pos_over_neg: 3549.553955078125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 2986.348388671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1720.966796875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1356.6461181640625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1869.76953125 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1974.759765625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:01:51<101533:05:27, 1218.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2862.262451171875 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1292.2564697265625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 3329.11865234375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1674.24560546875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1389.4676513671875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 839.7831420898438 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1239.19189453125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2349.85205078125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2753.0751953125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1390.4801025390625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 847.5797729492188 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2206.005615234375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2898.156494140625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 10736.208984375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2828.79736328125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2337.598388671875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1415.884033203125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1435.4556884765625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1135.2205810546875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2031.5772705078125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 3303.340087890625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1376.7646484375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2166.71484375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1074.156494140625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1748.4403076171875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1388.488037109375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2089.0791015625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 770.93017578125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1377.39599609375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1625.0921630859375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2470.447998046875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1680.4168701171875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 839.4918212890625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1569.0428466796875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 3447.266357421875 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1472.9130859375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 3992.248046875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 890.821533203125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1518.464599609375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 5801.087890625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2207.47802734375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1633.171630859375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1181.0753173828125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 3943.433837890625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 989.1270141601562 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 830.7294311523438 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2262.6953125 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1176.43310546875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1400.4315185546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 962.36181640625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1312.8375244140625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2713.28125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2412.8427734375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1695.8359375 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1961.4063720703125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1393.295166015625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1225.7696533203125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1520.8951416015625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1289.607666015625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1558.0926513671875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1885.7518310546875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2764.200927734375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.701, loss_val: nan, pos_over_neg: 1276.3631591796875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2061.22802734375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1655.2235107421875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2088.10986328125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 755.66015625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3239.05419921875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2709.146484375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 977.9491577148438 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1549.59765625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1104.923583984375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1099.406005859375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1068.32421875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1125.2078857421875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1967.2001953125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 2625.9873046875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2163.23779296875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1089.73779296875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 965.6351928710938 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1554.4798583984375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2529.39013671875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1491.3377685546875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1147.5010986328125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1045.3831787109375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1255.2802734375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1139.737060546875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1342.826904296875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1969.137939453125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 1215.09130859375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1947.610595703125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 886.8580322265625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: -29698.255859375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2355.418212890625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 856.7619018554688 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1169.836181640625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1002.4020385742188 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2150.19677734375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1591.4256591796875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2718.290283203125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2092.6357421875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1116.446044921875 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1104.5057373046875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1062.0762939453125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1666.0499267578125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2890.33837890625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2131.051513671875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1009.8106689453125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 749.9761352539062 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1473.7020263671875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1979.1734619140625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2573.92236328125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 2262.786376953125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 1316.87353515625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1441.2435302734375 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 3699.941650390625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 4921.65185546875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 3922.76904296875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2277.148193359375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1835.218994140625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2987.977294921875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 3846.555908203125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 3399.52392578125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1942.549072265625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 4769.62158203125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 6533.06982421875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1345.792724609375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2268.831787109375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1050.8692626953125 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 926.5509033203125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2167.6728515625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1274.565185546875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1338.7276611328125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 876.3544311523438 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1079.8919677734375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 724.3643798828125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1082.571533203125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1564.5506591796875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1328.83984375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1124.73486328125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 732.7306518554688 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1038.23583984375 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1577.8974609375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1773.7838134765625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 957.836181640625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1270.43017578125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1397.4613037109375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 696.9216918945312 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 845.2636108398438 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1046.89013671875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1226.4517822265625 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1015.493408203125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 1325.5435791015625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1122.744873046875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 897.4169311523438 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1190.43994140625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1655.27490234375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1162.0706787109375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 742.4033813476562 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2807.681884765625 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2379.619384765625 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 3441.66845703125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1444.4534912109375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1962.5732421875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1491.302734375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2376.75634765625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 4714.1103515625 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2797.638671875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1514.968017578125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1834.79638671875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 747.7465209960938 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1963.107177734375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 8081.3115234375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2285.1279296875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 4273.06591796875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2015.2181396484375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1998.762451171875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 3578.807861328125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 8974.474609375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 9136.8115234375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1117.665283203125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1660.4921875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2282.071044921875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1366.3529052734375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1287.1993408203125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1104.978515625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 4234.33740234375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1516.907958984375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1750.7486572265625 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 2454.99658203125 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1402.854248046875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1563.5218505859375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1973.759765625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2023.7030029296875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1524.7093505859375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1185.1953125 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1732.31787109375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1812.906494140625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7023, loss_val: nan, pos_over_neg: 1006.4635620117188 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1281.0068359375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2159.65478515625 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 917.4813232421875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 818.6766967773438 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1306.4468994140625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2752.539306640625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1594.2532958984375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1058.0125732421875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 820.9760131835938 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1562.267578125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 2365.203369140625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1247.58251953125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1219.637451171875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2601.09033203125 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1825.23486328125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1194.32861328125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1917.3485107421875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: -38978.296875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1822.73779296875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 4799.005859375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2299.86279296875 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 618.4356689453125 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1906.8463134765625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 7721.07275390625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 933.1946411132812 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1484.593505859375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1498.4140625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1565.8280029296875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1597.637939453125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1032.1400146484375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1834.0511474609375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1398.0750732421875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 2077.069580078125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 3074.59814453125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1307.12646484375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1215.333251953125 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1257.884033203125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1447.0150146484375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 1064.90869140625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2213.2490234375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2293.74365234375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 9107.6220703125 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2886.39013671875 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1076.8021240234375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1015.8445434570312 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1419.420654296875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 3929.064208984375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1384.57177734375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1984.099609375 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 3666.67529296875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1208.0264892578125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2057.59228515625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2089.930908203125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1132.704833984375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1635.718017578125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1802.374755859375 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1005.5789794921875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1908.4466552734375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2393.525634765625 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1063.6539306640625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1579.4697265625 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2666.71630859375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2061.130859375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1344.4814453125 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 779.3829345703125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1840.938232421875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1022.7713623046875 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 3476.9580078125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1137.2506103515625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1300.3665771484375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1772.1015625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1468.826416015625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1418.0096435546875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 3504.012451171875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1451.0697021484375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1668.1739501953125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 18593.513671875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2269.423828125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 952.6631469726562 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 991.3829956054688 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1276.6611328125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1754.1134033203125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1628.81494140625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 3871.2333984375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2968.18310546875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2980.400146484375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1101.3951416015625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1633.021240234375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1386.760498046875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1326.4063720703125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1061.49853515625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2368.666015625 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2419.364990234375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1806.3726806640625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1184.197021484375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1510.447021484375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1498.8504638671875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 764.895263671875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 827.8438720703125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 4842.4755859375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2178.580322265625 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1800.66650390625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2372.342529296875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2339.378173828125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1779.1158447265625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1626.7449951171875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1387.48046875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2385.35302734375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1055.0472412109375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2628.671142578125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1150.0174560546875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7011, loss_val: nan, pos_over_neg: 1248.0625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1127.343994140625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1695.7080078125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1212.4864501953125 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 922.7269287109375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 748.4955444335938 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1620.4085693359375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1301.9786376953125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1635.1026611328125 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1040.0679931640625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 791.8021850585938 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1887.3870849609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1152.513427734375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1248.8717041015625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1050.0322265625 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 3173.55810546875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1832.8865966796875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 905.7536010742188 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1753.662353515625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2127.940185546875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1490.9722900390625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1626.6708984375 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1786.1776123046875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1160.3172607421875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 3210.7041015625 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1646.7462158203125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1761.8709716796875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1524.893310546875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1239.0869140625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1486.6759033203125 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 694.6752319335938 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2690.184814453125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1225.8131103515625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 906.6416625976562 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2013.4970703125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 3598.97119140625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 4207.34033203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2229.85302734375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 933.4751586914062 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1187.1661376953125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1671.52880859375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1201.6927490234375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1761.2685546875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 3241.858154296875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 672.4142456054688 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1455.304931640625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1513.7978515625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: -6807.8095703125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2454.568115234375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2356.074951171875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2306.484130859375 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1239.410888671875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 19451.4609375 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2490.57763671875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1259.5863037109375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2308.9384765625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1638.72265625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1324.796875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1519.9119873046875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1392.58984375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1269.5927734375 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 855.817138671875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 3698.697021484375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 11195.361328125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1114.525634765625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 964.6547241210938 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1494.1270751953125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1195.3856201171875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1819.8746337890625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1629.11328125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2132.7685546875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1361.4022216796875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 906.392333984375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1047.337890625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2230.21435546875 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1042.7705078125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 901.5350341796875 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1085.219482421875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1061.3232421875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 824.1470947265625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1220.6099853515625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1568.891845703125 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1026.312744140625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 818.6865234375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 606.2022705078125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2210.83837890625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1332.513427734375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1085.71044921875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1287.326171875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3556.6767578125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1630.0758056640625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 924.1084594726562 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1678.7239990234375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 171909.125 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2084.028564453125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 3794.208740234375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1126.0665283203125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1174.9251708984375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 931.1735229492188 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1775.1453857421875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2569.028076171875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2987.11962890625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 961.3277587890625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1185.8311767578125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2381.448974609375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1273.46923828125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2699.4453125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 6804.1826171875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: -15803.2646484375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 1047.759765625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1162.687744140625 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1330.7388916015625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2094.0634765625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1255.4130859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 7153.0908203125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2287.855712890625 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 2400.68701171875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1500.5517578125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1488.471923828125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1779.3565673828125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2429.05810546875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1610.31884765625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 2873.109130859375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1830.218017578125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1706.1943359375 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 576.1351928710938 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1288.5582275390625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1681.501953125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 4785.73828125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 3023.79541015625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 896.7869262695312 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 3055.051513671875 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2099.76611328125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 851.2821044921875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1582.86962890625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1927.146484375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1675.0889892578125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1166.5601806640625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 3154.386962890625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 927.315185546875 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2914.861328125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 986.2313232421875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1183.4417724609375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1895.7452392578125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1274.646484375 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 3336.93896484375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 4658.08251953125 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1658.8514404296875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1136.6646728515625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1217.801513671875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1293.1409912109375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 2511.5478515625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 3315.426025390625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1836.1102294921875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 885.3203125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 851.8101806640625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7002, loss_val: nan, pos_over_neg: 1376.2601318359375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 919.49169921875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1178.71533203125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1505.6630859375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1249.696533203125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 709.2232666015625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1112.787841796875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1625.880859375 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1424.867919921875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1350.2666015625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1343.858154296875 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1256.9227294921875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2025.8271484375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1106.937744140625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1462.786376953125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3676.3017578125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 3233.371337890625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2977.000244140625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1367.0640869140625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1014.0814208984375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1897.5074462890625 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7001, loss_val: nan, pos_over_neg: 1319.515380859375 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2217.004150390625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1584.9488525390625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1207.2587890625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1140.40234375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 7941.91064453125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 5743.61181640625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1557.3419189453125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1676.0592041015625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 4295.560546875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1259.7874755859375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2898.221923828125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2079.457763671875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1512.763671875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.6931, loss_val: nan, pos_over_neg: 5589.8828125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7015, loss_val: nan, pos_over_neg: 927.1359252929688 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1279.219970703125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2490.450927734375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2123.737548828125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7006, loss_val: nan, pos_over_neg: 710.3663940429688 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1540.2176513671875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1963.1385498046875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2023.798095703125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3893.126708984375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 871.1213989257812 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1158.4576416015625 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1593.96826171875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 2400.111572265625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 4395.49951171875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 7135.58984375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1557.8751220703125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 4030.2529296875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2526.705810546875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2841.50927734375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1404.9630126953125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1454.85400390625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 2054.85595703125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1879.472412109375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2175.01953125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1080.9794921875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 2120.469970703125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7021, loss_val: nan, pos_over_neg: 1165.149169921875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 910.445068359375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1097.6578369140625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1745.6888427734375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 868.8402709960938 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1088.377685546875 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1463.6697998046875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 962.0068969726562 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1321.6312255859375 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1515.4228515625 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 984.923828125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1389.7442626953125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 579.5194091796875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 874.9623413085938 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2037.21484375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 798.4614868164062 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2020.8038330078125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1802.1533203125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1116.3026123046875 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 732.9300537109375 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1410.2606201171875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1759.8424072265625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1311.9033203125 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2795.218994140625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 3284.304931640625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1097.389892578125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1321.6585693359375 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1836.165283203125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1433.501708984375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1371.0390625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 3624.10009765625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 2240.22412109375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7013, loss_val: nan, pos_over_neg: 899.104248046875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1696.0408935546875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 3150.1611328125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 4528.736328125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1645.883544921875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1495.620849609375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1534.7178955078125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1426.32666015625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2321.564453125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 905.988525390625 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 6214.77197265625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1429.6688232421875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1277.985107421875 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 2294.287841796875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1439.112548828125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 909.6763916015625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2978.4462890625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 4047.28955078125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1293.4398193359375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1836.123779296875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1570.91015625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 3623.443359375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1218.7025146484375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1167.4273681640625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1839.7325439453125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 4213.5712890625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1277.8072509765625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1004.6454467773438 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 978.3860473632812 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7012, loss_val: nan, pos_over_neg: 1083.2232666015625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1451.48583984375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1427.0726318359375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 881.0973510742188 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 887.8287353515625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 3727.5732421875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1790.393310546875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1769.73681640625 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1245.533935546875 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1695.0389404296875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 917.7813110351562 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1738.6409912109375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.6996, loss_val: nan, pos_over_neg: 1209.58935546875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1136.0133056640625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1218.5758056640625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1358.156982421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1219.82568359375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1226.955810546875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 785.955078125 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 874.7452392578125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 2023.19482421875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 3217.5634765625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 974.4564819335938 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1125.8245849609375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 834.9561767578125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1588.913818359375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2135.37548828125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2069.016845703125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2740.476318359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 720.9988403320312 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1435.058349609375 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1127.396728515625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1541.603759765625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2304.18798828125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1471.298583984375 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 966.8472290039062 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 1137.57421875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 972.6168823242188 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 4134.73193359375 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1759.913330078125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1190.694580078125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 862.6492309570312 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1017.841064453125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 3004.9736328125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3041.386962890625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1604.041015625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 920.1067504882812 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 672.8178100585938 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1098.4696044921875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1274.8116455078125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1792.4071044921875 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1761.558349609375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1164.9705810546875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 869.9764404296875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2156.756103515625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1708.0457763671875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1440.0311279296875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1273.1722412109375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2013.137451171875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 3136.672607421875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1319.04931640625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 992.6837768554688 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1682.2725830078125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2119.691162109375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1205.8306884765625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1491.388671875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1978.5865478515625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2438.149169921875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 825.2892456054688 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1990.559326171875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1254.241455078125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1637.823974609375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 958.2951049804688 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1742.4305419921875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1233.2275390625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 814.030517578125 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 1134.49169921875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1158.4783935546875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1796.924560546875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 962.9688720703125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1709.10302734375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1944.2369384765625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1600.5208740234375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1145.6629638671875 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 5145.78466796875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2210.199462890625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2052.78955078125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 4978.78759765625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 941.9934692382812 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 951.2413330078125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1367.3331298828125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 864.7525634765625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: -6202.6982421875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 4714.8759765625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 6013.72412109375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1237.8577880859375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1496.9261474609375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1500.2572021484375 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1047.7392578125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1737.603271484375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2962.8779296875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1702.4256591796875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1049.45703125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1120.27392578125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2026.49658203125 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2311.1337890625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:22:10<101556:28:14, 1218.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 803.3729248046875 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1446.2982177734375 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1047.9871826171875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2088.4404296875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2478.0029296875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1251.5682373046875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1434.1904296875 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 977.9278564453125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 781.8062133789062 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2361.873779296875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1941.3499755859375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1356.923095703125 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1666.8359375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 897.4364624023438 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 45795.53515625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1612.1580810546875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1678.857666015625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2326.896728515625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1021.2984619140625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1332.16162109375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2183.05810546875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2156.40234375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 3139.60791015625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1322.6998291015625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1107.6031494140625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1825.70654296875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 4391.75244140625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1612.1090087890625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 804.4468383789062 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 890.4625244140625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3690.506103515625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.6998, loss_val: nan, pos_over_neg: 888.718017578125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1366.2003173828125 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 662.6223754882812 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1094.19384765625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 3313.18310546875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 3496.142822265625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1393.377685546875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 919.581787109375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 940.5121459960938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.6991, loss_val: nan, pos_over_neg: 1460.8453369140625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2542.2998046875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3699.055908203125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1300.1939697265625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 857.2188110351562 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1105.5877685546875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1027.2288818359375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1341.023681640625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 3883.252685546875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2167.164306640625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 896.613037109375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1818.522216796875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1609.1700439453125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1481.0108642578125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1021.0370483398438 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 5263.75634765625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 6808.44482421875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1578.042236328125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2962.625244140625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 2773.849609375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2173.672119140625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1430.3768310546875 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 7428.86865234375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2297.165283203125 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1755.388671875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1720.8291015625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2158.0068359375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 903.825439453125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1284.33056640625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1511.7081298828125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 1633.322021484375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 4306.55224609375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1578.7230224609375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 808.1678466796875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1962.1837158203125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2484.75341796875 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 997.6626586914062 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1483.201416015625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3119.616943359375 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 643.7008666992188 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1788.544189453125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 4639.56884765625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1428.7857666015625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 968.9744262695312 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1866.558837890625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1159.349853515625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2957.515380859375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1798.0765380859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1196.470703125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1589.2747802734375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1309.49658203125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1455.563720703125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 12838.0712890625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1099.8358154296875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1479.8372802734375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1283.3553466796875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1239.6583251953125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1316.1943359375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 3046.88427734375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2145.67138671875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1186.659423828125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 7035.65185546875 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 950.4025268554688 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1274.2481689453125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1561.5582275390625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1499.4952392578125 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2287.37060546875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 3869.448486328125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1271.7828369140625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 842.0997314453125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 795.366455078125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2161.333984375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 2773.726318359375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2543.41015625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 865.9911499023438 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1931.32080078125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1485.3223876953125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1752.0643310546875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 13048.2626953125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2157.300537109375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1553.099853515625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2254.5029296875 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 3048.173095703125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2176.3037109375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 881.1658325195312 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1751.17138671875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1430.50830078125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1519.16162109375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1096.016357421875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2678.57568359375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1492.184814453125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 685.22509765625 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1137.6600341796875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1114.04638671875 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1850.7364501953125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 13879.615234375 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1090.7442626953125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 928.3295288085938 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 971.3296508789062 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1432.3636474609375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1501.7159423828125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 4541.97998046875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2303.359375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2082.3486328125 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 8503.4912109375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 3337.268798828125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.694, loss_val: nan, pos_over_neg: -50885.78515625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.6925, loss_val: nan, pos_over_neg: 8455.2646484375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2506.437255859375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3972.74951171875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2603.083251953125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 1283.776123046875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1527.786865234375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1475.0362548828125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 1835.7384033203125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 3382.748291015625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1693.6539306640625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 3311.923828125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1572.562744140625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2303.9970703125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1580.645751953125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1787.4752197265625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2986.542236328125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.6932, loss_val: nan, pos_over_neg: 44336.75 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2028.7315673828125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2801.57421875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2024.2247314453125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 967.6940307617188 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2566.055908203125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3422.046875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 4014.870361328125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1924.219482421875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 1767.567138671875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1017.8932495117188 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 13423.3935546875 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1500.723876953125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2208.48681640625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.6923, loss_val: nan, pos_over_neg: -15510.5712890625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2648.38916015625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1361.873291015625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1051.0087890625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1466.3104248046875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2781.331787109375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1209.153076171875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1193.339111328125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1606.54541015625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 2052.96142578125 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1449.8226318359375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1504.3203125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1406.31298828125 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 3739.88671875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1294.09375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1042.3140869140625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7008, loss_val: nan, pos_over_neg: 821.2376098632812 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 757.0191650390625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 819.1458740234375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1090.3656005859375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1345.952392578125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2116.600341796875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 946.2613525390625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 813.2537841796875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.6987, loss_val: nan, pos_over_neg: 1390.41015625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2296.1572265625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1609.361328125 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1433.220703125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 3764.663818359375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1915.9599609375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1426.6375732421875 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2345.9423828125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1443.957763671875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2465.709228515625 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1749.1181640625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2744.102294921875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.6995, loss_val: nan, pos_over_neg: 938.8483276367188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 3287.239013671875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2180.471923828125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 3563.79833984375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 870.9401245117188 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 685.129638671875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1834.7357177734375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2138.8505859375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 3278.299072265625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1437.961669921875 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1263.04736328125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1016.3358154296875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1245.0345458984375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 5341.0048828125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1187.0567626953125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2497.26025390625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2256.118896484375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2082.569580078125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.6926, loss_val: nan, pos_over_neg: 3258.708740234375 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1608.3377685546875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 1237.214599609375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 37729.56640625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 1942.847900390625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 1924.078125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1950.4998779296875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1397.286376953125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 2392.658935546875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2563.7509765625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2504.589111328125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1834.8040771484375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 2729.3583984375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1346.721435546875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1568.0294189453125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1549.3271484375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 3025.357421875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7004, loss_val: nan, pos_over_neg: 2017.5875244140625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2721.17138671875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1311.206787109375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 4361.77978515625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1707.6527099609375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1376.04638671875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1997.848388671875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1822.3128662109375 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1726.1856689453125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2535.527099609375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2600.978759765625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1214.465576171875 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 5634.962890625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 1633.5421142578125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1738.201416015625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 3866.706787109375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 2101.90869140625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 956.6407470703125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 809.71337890625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3695.450439453125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1573.9609375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2642.89501953125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1433.6275634765625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1375.13525390625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: -5740.25927734375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1395.3939208984375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1338.3956298828125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 4256.67724609375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 2504.853271484375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 9488.1005859375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2585.556396484375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2145.020751953125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1624.58935546875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1588.470703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 15007.2490234375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1339.853515625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2112.3359375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 8435.046875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1810.5322265625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1566.5263671875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: -11055.126953125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 824.7587280273438 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 3059.1875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 3057.887451171875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 968.2662353515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 15104.181640625 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1064.609619140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 1147.64892578125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1936.3460693359375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2814.94873046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: -40326.4765625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1497.0008544921875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 2729.55712890625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1783.66259765625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1914.935546875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1523.0313720703125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 13536.6728515625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1313.08642578125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1263.7320556640625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 875.3085327148438 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1735.3707275390625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 3925.619140625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 39846.25390625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1493.5438232421875 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: -1279683.875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2431.4912109375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1627.50537109375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2927.663330078125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 8957.736328125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2213.830322265625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2259.59375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1577.2818603515625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 3386.051513671875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1085.74609375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 7356.39892578125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 4033.3388671875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 3222.75146484375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2311.0615234375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 180641.46875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1586.1324462890625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2567.90576171875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2485.349853515625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1828.2032470703125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.6934, loss_val: nan, pos_over_neg: 8572.5576171875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1046.6883544921875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 1839.766357421875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2039.812744140625 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2846.87548828125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1912.736083984375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 700.1458129882812 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2164.29248046875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 4019.656982421875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1811.1409912109375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1864.9901123046875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1611.2615966796875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2677.7578125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1839.919189453125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 1271.036865234375 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.6994, loss_val: nan, pos_over_neg: 1133.9263916015625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1019.649169921875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1912.2861328125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1419.8690185546875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 982.164794921875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 967.7962036132812 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.6927, loss_val: nan, pos_over_neg: 2726.232421875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1103.4591064453125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1501.7357177734375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1458.337158203125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1894.1802978515625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1158.2720947265625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1000.0759887695312 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1641.72998046875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1106.9969482421875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1820.0048828125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 5301.70166015625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1610.5867919921875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 3374.451904296875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 1736.9490966796875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1367.395751953125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1931.3572998046875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2834.66259765625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 3309.6044921875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2900.34326171875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2144.2509765625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 6146.884765625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1478.3924560546875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2619.830322265625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 812.71142578125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2189.566162109375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2336.865234375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.6993, loss_val: nan, pos_over_neg: 1357.4901123046875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2902.568603515625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1503.6915283203125 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2195.9794921875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 991.89013671875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7, loss_val: nan, pos_over_neg: 644.6279296875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1812.317626953125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 10231.529296875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3583.76025390625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 3767.900390625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1475.9404296875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1003.5004272460938 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 3180.054931640625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3518.138916015625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 3169.2041015625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 39650.890625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1916.4425048828125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.6936, loss_val: nan, pos_over_neg: 3086.669189453125 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 974.7407836914062 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1813.4906005859375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.6932, loss_val: nan, pos_over_neg: 1582.7581787109375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1457.16845703125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 2382.77294921875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 2247.50537109375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 3573.743408203125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1063.3179931640625 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 3244.885986328125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1080.533447265625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2303.26806640625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 5931.380859375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 8123.19580078125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1227.1319580078125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 4689.3310546875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1244.9544677734375 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 1675.5633544921875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1883.1610107421875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 3692.54150390625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1768.2677001953125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.6931, loss_val: nan, pos_over_neg: 3528.985595703125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 953.8190307617188 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1338.1009521484375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2036.7962646484375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 1459.8609619140625 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 2403.210205078125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1031.820068359375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1093.1187744140625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 3146.32275390625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1847.7733154296875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1945.49267578125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.6973, loss_val: nan, pos_over_neg: 1377.54931640625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.699, loss_val: nan, pos_over_neg: 1091.6922607421875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2231.58544921875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1742.7735595703125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1702.7041015625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2306.2265625 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 8772.9423828125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1179.053466796875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 1807.1405029296875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 3140.6728515625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 6731.9736328125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 3011.995849609375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 880.0873413085938 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 938.9287109375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1259.0933837890625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 6885.86474609375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 9387.380859375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 6691.87353515625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1927.849853515625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1161.859619140625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 2680.85302734375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1343.833740234375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1353.9715576171875 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 1471.36572265625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.6989, loss_val: nan, pos_over_neg: 1179.1484375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1601.0286865234375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2899.9228515625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3343.597900390625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1905.138427734375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1797.0941162109375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 3503.151123046875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7005, loss_val: nan, pos_over_neg: 897.4645385742188 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1920.5767822265625 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 2442.15087890625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: -11170.0146484375 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 16218.7470703125 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1584.9561767578125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2553.6513671875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2048.514404296875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1864.82958984375 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 6277.4482421875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 945.2333984375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.6933, loss_val: nan, pos_over_neg: 4246.7138671875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.6936, loss_val: nan, pos_over_neg: 4002.6904296875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 4178.67431640625 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.696, loss_val: nan, pos_over_neg: -31104.453125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1366.5545654296875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2001.3543701171875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2277.37353515625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.6928, loss_val: nan, pos_over_neg: -48351.515625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2925.13623046875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 1469.6298828125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1099.7215576171875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 3023.666259765625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1922.3878173828125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1585.568115234375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1131.945556640625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1137.8931884765625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.6925, loss_val: nan, pos_over_neg: 3454.3466796875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1453.3775634765625 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1306.125732421875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2259.055419921875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1382.8355712890625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 2721.239990234375 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 3168.69384765625 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: -102156.1875 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1489.6031494140625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 3078.4921875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2024.4329833984375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 1462.9376220703125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2257.178955078125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 3984.95703125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 6149.41064453125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1851.5770263671875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2145.306640625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1163.2215576171875 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 2292.94140625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1029.9979248046875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 2579.193115234375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1182.4400634765625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 5463.84326171875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1307.459228515625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1626.126220703125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3394.27734375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 2731.541015625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2906.765380859375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.6922, loss_val: nan, pos_over_neg: 6856.548828125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1757.294189453125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 3503.5048828125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 2025.8150634765625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2691.410888671875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 3781.498046875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.6933, loss_val: nan, pos_over_neg: 43783.01953125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.6936, loss_val: nan, pos_over_neg: 1688.02978515625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1356.2904052734375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2464.606689453125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 2045.867919921875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2582.2197265625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 1484.5262451171875 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3766.173095703125 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1931.830322265625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 4329.7607421875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1611.6661376953125 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2446.110595703125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.6936, loss_val: nan, pos_over_neg: 193860.75 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 2106.793212890625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2035.1885986328125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 2165.307373046875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1395.2779541015625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 3076.984619140625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 1384.9090576171875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 19208.263671875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2364.355712890625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2713.466552734375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.6931, loss_val: nan, pos_over_neg: 2452.046875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 2621.9501953125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 2252.224853515625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 4212.8623046875 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1611.635009765625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1191.46728515625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 4105.931640625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1190.7152099609375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 17833.837890625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 921.712890625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2266.97802734375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2634.232177734375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1036.1776123046875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1343.9859619140625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1770.9420166015625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 733.548583984375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1302.0770263671875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2036.2711181640625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 2279.1171875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1484.76123046875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1389.392822265625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 784.1943969726562 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1113.6279296875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2498.169677734375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1943.5443115234375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 1411.39306640625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 1594.5302734375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1968.8734130859375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 3533.939208984375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 5553.9775390625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2495.908935546875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1036.7034912109375 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 1962.187744140625 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1253.04931640625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 1613.88671875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2479.151611328125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.6926, loss_val: nan, pos_over_neg: 5515.76220703125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1770.861328125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1702.6024169921875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1832.7225341796875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2092.76318359375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2038.5830078125 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1161.1373291015625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.6925, loss_val: nan, pos_over_neg: 2324.10009765625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 3086.133056640625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 3108.396728515625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 3160.869873046875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1683.5693359375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1581.4398193359375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 787.419189453125 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2652.235595703125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 1631.064208984375 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1928.4090576171875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1270.7142333984375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1255.597900390625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 1415.690673828125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1644.1446533203125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.6988, loss_val: nan, pos_over_neg: 1860.7022705078125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: -9929.87109375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1091.4437255859375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 1555.8082275390625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 3156.619384765625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.6992, loss_val: nan, pos_over_neg: 1114.0704345703125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2002.20703125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1144.980224609375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.6999, loss_val: nan, pos_over_neg: 3228.95263671875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.6933, loss_val: nan, pos_over_neg: 3805.115478515625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 1138.0216064453125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 1169.5538330078125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2432.650390625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 1749.62158203125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2514.338623046875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1706.2103271484375 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 3423.52392578125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1239.214111328125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1080.8701171875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 2420.3818359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 4769.34326171875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1387.9024658203125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1464.3583984375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1804.085205078125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 1489.351806640625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2230.67138671875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1405.2242431640625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2053.728759765625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1665.52783203125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1885.662841796875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 2488.689453125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1750.830322265625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 4071.6064453125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1091.706787109375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 3601.047119140625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 4884.267578125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2395.783447265625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1112.84765625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.6977, loss_val: nan, pos_over_neg: 2621.6455078125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 3324.960205078125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2943.555419921875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.6932, loss_val: nan, pos_over_neg: 6363.46630859375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1458.951171875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.693, loss_val: nan, pos_over_neg: 5645.14990234375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 2667.41552734375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 6038.52587890625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 3407.505615234375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 3626.056884765625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 2083.714111328125 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2149.781005859375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 5794.35107421875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2058.92138671875 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: -107907.859375 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 3373.402587890625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 3764.373046875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1754.766357421875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1714.1966552734375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.6935, loss_val: nan, pos_over_neg: 3307.146728515625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1077.0198974609375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 892.3670043945312 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1033.7763671875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 2803.80712890625 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2544.307861328125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.6983, loss_val: nan, pos_over_neg: 815.6600341796875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1481.056640625 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1371.062744140625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 2234.71435546875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1312.139892578125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2608.176025390625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1330.489501953125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 1173.101806640625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 4880.51318359375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 3885.10498046875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.6971, loss_val: nan, pos_over_neg: 1866.1993408203125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1580.052490234375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2864.209716796875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 2417.54345703125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 2404.944091796875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2574.6826171875 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1449.054443359375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1403.1856689453125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 931.2113037109375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.6951, loss_val: nan, pos_over_neg: 1094.8291015625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1610.4429931640625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1284.273681640625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2434.5654296875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 905.9727172851562 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1265.8870849609375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7007, loss_val: nan, pos_over_neg: 862.0979614257812 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1526.529541015625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1424.0616455078125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 2098.031494140625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1461.3819580078125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1177.9693603515625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 1861.85498046875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3788.331787109375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2116.96435546875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/300000 [2:42:26<101480:10:45, 1217.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Iter: 0/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 3340.52197265625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: -8112.169921875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1227.8505859375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.6942, loss_val: nan, pos_over_neg: 1268.9921875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2945.553466796875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 2972.888916015625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2300.343017578125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 1347.25390625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1671.2364501953125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.6923, loss_val: nan, pos_over_neg: 8167.576171875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 1254.9443359375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 1619.13916015625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 3676.87548828125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.6934, loss_val: nan, pos_over_neg: 2639.572998046875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.6939, loss_val: nan, pos_over_neg: 2623.50830078125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 1816.6705322265625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1109.6705322265625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1452.7728271484375 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2563.231689453125 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2811.912109375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1104.1337890625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 2018.063232421875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 3428.840087890625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1135.236572265625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2748.76025390625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1050.0819091796875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1125.59423828125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1491.374267578125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.6928, loss_val: nan, pos_over_neg: 2347.5732421875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1409.6357421875 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 894.4263916015625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 1174.117919921875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1200.85400390625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.6985, loss_val: nan, pos_over_neg: 1043.2608642578125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1183.3541259765625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 2456.1494140625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2867.753662109375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1191.531982421875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1034.2540283203125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 1117.188232421875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.6974, loss_val: nan, pos_over_neg: 1027.91015625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1388.4739990234375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 1101.333740234375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1534.398193359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1575.8880615234375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1155.8729248046875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.6946, loss_val: nan, pos_over_neg: 2343.455810546875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.698, loss_val: nan, pos_over_neg: 971.1682739257812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.6934, loss_val: nan, pos_over_neg: 2492.349609375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1930.1546630859375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 1271.523193359375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3750.822509765625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2025.643310546875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2449.6611328125 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 1724.3563232421875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 767.1361694335938 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2941.64306640625 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 2771.345703125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 1252.866455078125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.6997, loss_val: nan, pos_over_neg: 895.1224975585938 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.6972, loss_val: nan, pos_over_neg: 1206.693115234375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.6969, loss_val: nan, pos_over_neg: 1533.72802734375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1367.919921875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 2576.62060546875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 1280.5400390625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 1336.236328125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.6941, loss_val: nan, pos_over_neg: 3216.433837890625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1213.8409423828125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.6986, loss_val: nan, pos_over_neg: 946.7637939453125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2070.366455078125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 1007.4472045898438 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 1053.10546875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.6949, loss_val: nan, pos_over_neg: 2314.40185546875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.6962, loss_val: nan, pos_over_neg: 2016.0455322265625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2291.309814453125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.6957, loss_val: nan, pos_over_neg: 1362.5850830078125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.6944, loss_val: nan, pos_over_neg: 1422.3929443359375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.6961, loss_val: nan, pos_over_neg: 2333.3046875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2170.71875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 3628.296142578125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.6979, loss_val: nan, pos_over_neg: 2166.00244140625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 19649.07421875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.695, loss_val: nan, pos_over_neg: 2768.595458984375 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.6954, loss_val: nan, pos_over_neg: 1521.6304931640625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1247.0091552734375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 2216.25634765625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 1539.5264892578125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 1869.4749755859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.6978, loss_val: nan, pos_over_neg: 1177.8243408203125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1723.2452392578125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.6966, loss_val: nan, pos_over_neg: 2501.076416015625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 2753.3359375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.6963, loss_val: nan, pos_over_neg: 869.1339721679688 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.6931, loss_val: nan, pos_over_neg: 2413.721435546875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 2985.2197265625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2982.520751953125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.6938, loss_val: nan, pos_over_neg: 3090.700927734375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.6967, loss_val: nan, pos_over_neg: 4561.25341796875 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 2006.265380859375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.6955, loss_val: nan, pos_over_neg: 1532.2933349609375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 2756.5009765625 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.6976, loss_val: nan, pos_over_neg: 1307.698486328125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.6982, loss_val: nan, pos_over_neg: 2873.484130859375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.6947, loss_val: nan, pos_over_neg: 3496.88720703125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.6968, loss_val: nan, pos_over_neg: 82326.46875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 6619.763671875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: 1473.9217529296875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 3302.04541015625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 5158.05908203125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.6937, loss_val: nan, pos_over_neg: 2791.361572265625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.6945, loss_val: nan, pos_over_neg: 4548.75341796875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.6952, loss_val: nan, pos_over_neg: -51819.65234375 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.6943, loss_val: nan, pos_over_neg: 4314.83642578125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 1880.4046630859375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1731.0516357421875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.6975, loss_val: nan, pos_over_neg: 2867.78564453125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.6965, loss_val: nan, pos_over_neg: 3613.0537109375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.6953, loss_val: nan, pos_over_neg: 1800.22216796875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.6964, loss_val: nan, pos_over_neg: 2920.7900390625 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.6936, loss_val: nan, pos_over_neg: 2034.629150390625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.6956, loss_val: nan, pos_over_neg: 1939.59423828125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 3878.39208984375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.6984, loss_val: nan, pos_over_neg: 1245.9453125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.6948, loss_val: nan, pos_over_neg: 13955.7236328125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.6981, loss_val: nan, pos_over_neg: 1226.145751953125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.6959, loss_val: nan, pos_over_neg: 1731.3487548828125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.6958, loss_val: nan, pos_over_neg: 2331.70751953125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.694, loss_val: nan, pos_over_neg: 5483.2880859375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.697, loss_val: nan, pos_over_neg: 7673.6962890625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.696, loss_val: nan, pos_over_neg: 3590.700927734375 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss  Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix  Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE  RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "#                                                     # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "#                                                     # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:04<00:00, 12.38it/s]\n",
      "100%|| 50/50 [00:02<00:00, 17.63it/s]\n",
      "100%|| 50/50 [00:01<00:00, 25.95it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "c_lst = [1e-1, 1e-2, 1e-3]\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train  C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val  C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-2)).fit(features_train, y_labeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
