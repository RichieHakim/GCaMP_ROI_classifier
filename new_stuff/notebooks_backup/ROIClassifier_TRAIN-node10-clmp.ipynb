{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "base_dir = '/n/data1/hms/neurobio/sabatini/josh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_SYT = data_labeled['SYTmasks']\n",
    "# labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "# non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "# labels_SYT = labels_SYT[non_nan]\n",
    "# masks_SYT = masks_SYT[non_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjEklEQVR4nO2de5xlVXXnv+veuvWuflTTDU13A4pIRGdE0kF8RUZGgxpHjUFARzFB0UQzIaNGwsSIGSeDjkKM+sGgoqigovh+jQQffBwRbQgiBBU0Df1+VnXXu+reu+aPszu5XZ61qupW1a2Ss76fT33q3r3vPnudfc4659z9u2ttUVWCIHjkU1pqA4IgaA3h7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFoTDOLiIfFJG3zvKz3xWRVxt1IiIfFZEBEfnRwlo5d0Tk5SLyraW2Y7kiIioij1mivi8WkT9dir7zeEQ6u4i8SkS+31imqq9T1f+5AJt/OvBsYKOqnjmfDXkXldmiqjeo6nNm2d+vjUuRSeOvIvLEaeVfTOVnp/dXiMgnG+pVREZEZFhEdojIVSJSnraNNwNvB94oIr923olIv4h8IW3nIRF5mWPnRSJyp4gcFpHtIvIuEWmb6/4+Ip19kTkR2KqqI0ttSDMHfLFZjjbNwC+AVx55IyJrgLOAfTO0e6Kq9gLnAC8DXtOwjYuAPwF+F3gG8Ici8vpp7T8ATALHAi8HrhGRxxt9dQOXAscAT059vmkW+3Y0qrqkf8BbgB3AEPBz4JxUfgXwOeAzqe6uNMBH2l0G/DLV/Qvw4lT+OGAcqAHDwGAq/xjwjvR6NfBVsgM6kF5vbNj2d4FX59h68bRtvz2VvwZ4EDgIfBk4vqHNU4EfA4fS/6em8v+VtjOetvX+VK7AfwN+BewH/g9QSnWvAv4fcHXq6x2p7PsN/SnwOuCBtG8fAMQZl+el8RtKx+FNzrF6DXB/w5ifkcq3puN4DzABtAH/BbgPGEzj+biG7WwF/iptYwD4KNCZ6s4GtgOXp/3fCry8oW0H8G7gYWAP8EGgq6H+zcAuYCfwx2k8HmPsz3eBv0n9lVPZG4BrUtnZDefiJ6eN8WMa3n+24fg9P+3Xpob6dcA/A+el9z1kjv7Yhs98Arhylj7z34GvzNnXltjRTwW2kZwDOAk4uWGAp4A/BCpkV7J/BSqp/jzgeLKnk/OBEWB9g1N8f1pfH+PfnX0N8BKyK2ZfOlhfnMnZ87YNPCudlGekE/F9wG2prj+dzK8gc4AL0/s1Vj/pRPpOansC2Z3n1Q19V4E/S9vryrFHyS5eq1L7fcC5zrjsAp7RcBE8w9jv88guBr9DdvF4DHBig/PeDWxKNj02HY9np2P3l2QXw/aGz9+bPt9PdgE7cmzOTvt4VRrPZ6ZtnZrq/57sgtqfjt1XgP+d6s4luwA8gcyhbmRmZ3818C3guansR8BTmKWzA6cBu4GL53DePwkYm1b2JmbpwMAXmeWFofFvqR/ja2QH9DQRqajqVlX9ZUP9nar6OVWdIjv4nWSPWKjqZ1V1p6rWVfUzZHeyWX2HVtUDqnqzqo6q6hDZXfaZTe7Dy4HrVPUuVZ0gu2M9RUROIrvKP6Cqn1DVqqp+CvgZ8IIZtvlOVT2oqg+TndwXNtTtVNX3pe2NGe2vVNXB1P47wOlOX1Nk479CVQdU9S7jc68G3qWqP9aMB1X1oYb6f1DVbcmm84Gvqeot6di9m+wi8NSGz78/ff4g2fg37iPAW1V1QlW/B3wNeKmICNnTxV+k8RkC/g64ILV5KfBRVb1Xs69ZVzj73cjHgVeKyKnAKlW9fRZt7hKRAbKLzYfJnk5mSy/Zk14jh8guXi4i8kfAZrIxnRNL6uyq+iDZd5ErgL0i8mkROb7hI9saPlsnu9oeDyAirxSRu0VkUEQGya7mx8ymXxHpFpF/TBMjh4HbgFXTJ1lmyfHAv530qjoMHAA2TK9LPJTqPLY1vH4obSevzmJ3w+tRspPL4iVkj/IPicj3ROQpxuc2kX1tsmi0a/qY1FP9BuPz0/dxQI+eEzlSv5bsaezOhuP+zVR+pN/p250Nnyd7Qvszssfp2XCGqq5W1ZNV9a/TPs6WYWDFtLIVZF+PTETkRcCVZE8h++fQH7AMJuhU9UZVfTrZxJcC72yo3nTkhYiUgI3AThE5EfgQ2ferNaq6iuyxUI5sdoZu30j2FeLJqrqCbCKFhvZzYWey/YidPWRfE3ZMr0uckOo8Ozc1vD4hbecI8wlT/LW26U79QrLvlV8EbjLabgNOnuW2p4+JkO3TjobPePu4Oo3j9Pr9wBjweFVdlf5WajZRBtlXkunbnRFVHQW+QTapNltnnw+/ANpE5JSGsieSzXHkIiLnkp3zL1DVnzbT6ZI6u4icKiLPEpEOssmjMbJH+yP8toj8QZrhvZRs8ueHZN/HlDRjmh5tntDQbg+wUUTaja77Ul+DItIPvG0eu3Ej8Ecicnraj78D7lDVrcDXgceKyMtEpE1Ezif7jvfVBjsfnbPNN4vIahHZBPw52STlQnDUuIhIe9LpV6bH7cMcPf6NfBh4k4j8dvqtwWPSRTePm4Dni8g5IlIhu7hOAD9o+MzrRWRjGv/L+fV9fHuy7xnA7wOfTXfPDwFXi8i6tA8bROT3Gvp9lYicJiLdzO24Xg48Mx23RSU9tXwe+FsR6RGRpwEvxLjQiMizgBuAl6hq07/tWOo7ewfZY8l+skfPdWSDfoQvkX3/OzLJ9QeqOqWq/wK8B7id7AT+D2STPEf4NtlVcreI5D3u/D3Zd8j9ZBePbza7A6p6K/BW4GayO8vJpO+QqnqA7ER9I9mj/V8Cv9/wCPZeMllmQET+Ydp+30k26fU14CPN2jeNvHF5BbA1fZ15HfBf8xqq6mfJvlvfSPa4+UWySbK8z/48bed9ZGP8ArI70mTDx24kmxj7Vfp7R0PdbrJjvpPsJH+dqv4s1b2FbLLvh8nmfyJ7SkNVv0F2bL+dPvPtGcaj0eadqtrK3yD8Kdk5uBf4FPAnqnofgIickDT8I08mbwVWAl9P5cMi8o25dihpdm/ZISJXkM145p58j1RERIFT0nzGIxIR2UqmMPxTTt3ZZDPfG1ts1iOepb6zB0HQIsLZg6AgLNvH+CAIFpa4swdBQWhp0EK7dGgnPTN/cJlSX51vuzqXTHF+alEaaC6WprrOHkNt4pcClT22HVPHOcfLeSi09rtt35LHDy07rOPZzLGcOnSQ6thIbst5OXsS+t8LlIEPq+qV3uc76eHJcs58ulxShp9zVm55tcM+KpVR29t7br6jKTv2nv9Us65emfv2jrv6B2bdzovsvsRS5IG2kfwrwdoPzuaXqMVizwX5Y6xNeOeDN1xl1jX9GJ9+WvoB4LlkPxS5UEROa3Z7QRAsLvP5zn4m8KCq/ir9WOLTZL8CCoJgGTIfZ9/A0UEH28kJ8BCRS0Rki4hsmWJiHt0FQTAf5uPseV9U8wItrlXVzaq6uULHPLoLgmA+zMfZt3N0hNFGjo5cCoJgGTGf2fgfA6eIyKPIQhcvIMvF9YilVDW0Jmc2vjy58D9aWvd+e/Z8x1vyZ3Y9CXD3X9gz7p6sWLNiCoHKcH75jsvsvjZcae/XQjN0fr6yAv4+j66zK8WTIh3lwgqsLo/bG1x7Tb6q8ZCTGrFpZ1fVqoi8Afi/ZNLbdUeidoIgWH7MS2dX1a+TxWwHQbDMiZ/LBkFBCGcPgoIQzh4EBSGcPQgKwm/aUj1LSmkqXwqRuqO5LEK6gOHznmzWlar55VNORvKylX0eP/Kq2mvv3Gg5v6ErQTXJ8EttGc06Np5MNrTRvgeWpux23Xvmkk363+n79A+bajdX4s4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBB+o2fjD19oz8LW25zgFGNWHWDgsfb1b/Uv8mdbR4+127RN2H3tvtQOCvFmdgdPnfs1utpp21FzIo/L4/Y4ekJDrSu/tjSZWzwj3ox73VmOc+y4/Epvny1FA6BntzPj7gxIfRl4WtzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFIRlIAjMzOGX5csutUoT6+MAtXannVN18LT8yvZDdptqZ3N9jffb1+F6m63xTPXNPfLGC05xl69ygkJqnfnl9W7bvqELbHltzBkPqy+w88m58tqu5gJa1JEAS84YW+f3ihsXNkAm7uxBUBDC2YOgIISzB0FBCGcPgoIQzh4EBSGcPQgKQkult+q6HnPh+c4BW+7QkqFRNae8uXnVPBlqcnW+bOQtgzSxyu6s3mHLUN07HCMdda1tLL9dtc8eX5lybHTkpLIzVvXu/P7Kw/b9ZeQ4245ql91X+2G7bqrXqrDbHD7RtrHvYe88tbfpRWGay4otMPNydhHZCgwBNaCqqpsXwqggCBaehbiz/ydV3b8A2wmCYBGJ7+xBUBDm6+wKfEtE7hSRS/I+ICKXiMgWEdlSHbOXkw2CYHGZ72P801R1p4isA24RkZ+p6m2NH1DVa4FrAbqP3dSamYggCH6Ned3ZVXVn+r8X+AJw5kIYFQTBwtP0nV1EeoCSqg6l188B/tZrU2+DsWPzb+6TK+zrTu/2/Db1itOZ9wzh1PXstCsnV+eXV1fZGlTloK1d1St2XyPOQ1D7gD1WVSMizpPXPMlIPJmy7m0z3w6vr+GTbFmrNOH05chaGJvUbruJJ+l6EpqXVNJLcNlmJPW0ouGguYi4+TzGHwt8QbKzoQ24UVW/OY/tBUGwiDTt7Kr6K+CJC2hLEASLSEhvQVAQwtmDoCCEswdBQQhnD4KC0PqEk4ai5CVKPHxyfnnHAS+SyDah5Kz1Zkk1AJ1786+NI45kVF1p13Vvs2W5sXXNJT2sGWu6edF8XqJETyrzJMzSeH7DWo+X3dKuqvfYnVXXOoZM5NvRvt/e6VK1yXBKBy070qEY9i/wT9Dizh4EBSGcPQgKQjh7EBSEcPYgKAjh7EFQEFo6G1+agu5d+bOSE/12u6qxZJAVVANQGbZnP9sP2XXjaxw7jBnhyqA9s1vtsWfVp5wZ5pITuDLZ78zUG5usrbTlCRl1gnXW2O3qziy4DOZHKZVX2snfamPODPmQfarWnX2zZvgn19qqQNc2py8n+MpbKqs8YY/V+Jp8I1c8vLDT8XFnD4KCEM4eBAUhnD0ICkI4exAUhHD2ICgI4exBUBBaHggjmi8nWMsWgZ3rzJLkAKZ6nboVZpWbF86qUyPvG4A4QRWTa5ygEC8vXM0Jqqjk6z/i2KhdtmbU3jNpt3OUobW/NZBb3tc+YbZ5cNc6s67m3ZasQBKgfV++nNe92x7DtjFnrBw7Bk+167Rsb7Nrb74tvTfZeebGX5Cf21W/d7vZJu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkJLpTepQ8VYyLU06cgdhpWjleaWNPJkkMqY3bBtLL+81m73NbnalrVqnXZdpc+WvGpVZ6msvvHc8v5uw3hg92CfWdfTZUtl45N2CNiartHc8n2jPWab2oSTDM+RG8uH7NPYUuW8KMth20Rqvc4SVc654+W1q3pLUVl2tOdvT0tOXsaZNioi14nIXhG5t6GsX0RuEZEH0n9jFbQgCJYLs3mM/xhw7rSyy4BbVfUU4Nb0PgiCZcyMzp7WWz84rfiFwPXp9fXAixbWrCAIFppmJ+iOVdVdAOm/+TtHEblERLaIyJbquPGFPQiCRWfRZ+NV9VpV3ayqm9s6nZmPIAgWlWadfY+IrAdI//cunElBECwGzUpvXwYuAq5M/780X0NqXbZkUDes7Jg+k9DYxkkMOHKCF9XkLOXkSCtNYUTzAdTrdl89hrwGMDrakVve5uyXqm3H2IStK5ZK9jgeGMvXkzy5rtzpJLd05MaaE8WoJUPOcyLltN2uKw870uyII695yUVtldWmiRWqZiO9fQq4HThVRLaLyMVkTv5sEXkAeHZ6HwTBMmbGO7uqXmhUnbPAtgRBsIjEz2WDoCCEswdBQQhnD4KCEM4eBAWhpVFvWoLJvnzNwJPKrAg2N7LN2bP2Qbvh+Hp7LbKqIcnIpBNpNNHc9VQcaWh0pNOs6+7Jl+W62u39am+zE1/WHVmup93WjDrK+TLa8Hi+NAjQv9L+heWh4S6zbtKJiKsbkq44a+m1HbaPWXnC0bycKk+Ws9bnm3j+75hNSlNGIycLaNzZg6AghLMHQUEIZw+CghDOHgQFIZw9CApCOHsQFITWrvWmtmQgdlAW4/1Gcj0nP2HJVppoy8+FCEDlgD0k9Y5822u9tnRVc9ZRkw67nThRak5OQR69Oj8UcLxm79eJvXb44L7xXrszh72j+UksH792t9nm4ISdefGwIzeW252knlZkYbcT3ViydWAV+/5Y73Si5Zy1DHu3GX05B7rrSz/KLS+pfXLHnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgILR0Nr7eAUMnGZXeZcf4cb/Yk9nUnSWZvAAaz46SFTxx2B7G2go7r1qpzVn+qWLv3PGrDpt13W35wSkn9+4z23SUbBs3dQ6YdQNT9uz5aSvyZ91/MWxmHWfPkL0MlZfvrqvbXqKq1pF/QKcmnWPmBdYYikxWaVeJPcSMbMjvb2ydbeOGr9jbs4g7exAUhHD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQ8kAYUy5zZAsLL3gGJ3davWLLJ9U1dgSNtOW303EnIscJWimX7R3w6rrabBtXtY/llpecnHbPX3m3WXdKJX97AAccieoTA2fllrc5B+3k/v1m3e4Re42nwVE7P13VWDaqr9fer8lOe3xH9tqLk7YfsM+DkjNWNUPO0za7zfa/empu+dR1P7RtMGsSInKdiOwVkXsbyq4QkR0icnf6e95M2wmCYGmZzWP8x4Bzc8qvVtXT09/XF9asIAgWmhmdXVVvA5z1UoMg+E1gPhN0bxCRe9Jj/mrrQyJyiYhsEZEttRE7L3gQBItLs85+DXAycDqwC3iP9UFVvVZVN6vq5nKPPbkRBMHi0pSzq+oeVa2pah34EHDmwpoVBMFC05T0JiLrVXVXevti4F7v80coTUHPjvy68bWONGEsu1TtseUkLTt1TgQVhlSTtTNkI0fW8vLMdXbYEs/KrvxlnAB62+wor4OT+ZFox/cNmm2OL9t5y9aV7Rx0HWLLVyd0HMgtf3is32wzXrNzv3nS4dSULXlNHc5fbmrgkL0MFU5OO2upppnq6oZsCyCGLFd3zuG6cVi8vIwzOruIfAo4GzhGRLYDbwPOFpHTyXZvK/DambYTBMHSMqOzq+qFOcUfWQRbgiBYROLnskFQEMLZg6AghLMHQUEIZw+CgtDahJNtMHZsvsxQ7XakMkO2MBNAAm0H7TovWq5uqz9MnJwvh7X32hJam5NUsla3r7VlZ/knbyknS77aP2VLaA9V7YiyVaVhs263k/BzXPPt8JJbevR32vLgvpK9bz3H5LebGLcPdHXIkQDHnOWfnCSnpfw8oIB9Poq1dJWHc27HnT0ICkI4exAUhHD2ICgI4exBUBDC2YOgIISzB0FBaG3CScFMwNh/n92sVjGighyZzItEqzuJ/CbMNBwgA/naSm2PHUE12WNrIdpty1C9nXZkm6qdF6CjnL/Nat0Oh/rK4Olm3Q8qdsKRzpItOd4/sj63fKzJyLYHDxxj1lUq9jiWjW1W2+z7XK3LuQc6x6x20D4P2obtbZpSsBNFVzakPE9Wjjt7EBSEcPYgKAjh7EFQEMLZg6AghLMHQUFo6Wx8eRJ6H86fYqx7lhiXpHq7Pas+udLenJXTDkAdO0rj+f15eb/cwAQnSObwaKdd53R3xvHbc8t3j/eZbR7bu9es2zJ4glm3ttMOkjk0lW//o3ryc9MB7J+wA1rq/faxbneCa/aM5u/3oQFb0dBR+4CWh526McfGIbOKmjGJ7/qElwvPIO7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICsJsVoTZBHwcOI5MSLpWVd8rIv3AZ4CTyFaFeamqDnjbUrFlBi81WbXTCIRxrO9wFpkePc6uK03a8km9I1/vcKW8ilPnLFs0NulIPJ128rcHB+2AEYu+ih1088uD9vb2dtpy3sBIV275fdiDv6rHXk5qz0E7T54XQHP6pnwpsm7kQgTY/dAas65sr8rl1qmTTk6Mc985LIhxCjhDMas7exV4o6o+DjgLeL2InAZcBtyqqqcAt6b3QRAsU2Z0dlXdpap3pddDwP3ABuCFwPXpY9cDL1okG4MgWADm9J1dRE4CngTcARx7ZCXX9H/dglsXBMGCMWtnF5Fe4GbgUlX1frE5vd0lIrJFRLZUx+xECEEQLC6zcnYRqZA5+g2q+vlUvEdE1qf69UDuD6xV9VpV3ayqm9u67N8jB0GwuMzo7CIiZEs036+qVzVUfRm4KL2+CPjSwpsXBMFCMZuot6cBrwB+KiJ3p7LLgSuBm0TkYuBh4LyZNiR1aDPUlakeW5uwItHaDzUZvVZzdBBHulDj0qgVJ7TNQUZseU3LjiGO9GbhLTV1z778fHEA7W12X23OElVTk/kHoKvLXgdpzwE7VFGd4WjvtnPh7RvLj6Q7cMh+yhRnfCdXOUuOOXntvKWcLBnNO7+t89TaFszC2VX1+5hpIjlnpvZBECwP4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAWh5cs/WfKV1GyZoW3UaOMoXo7SRJvzQ76aneeR7h35osTIRltCq/XZWkjlsG3kVK89HrUxu7/BSn60WXenLXmNjucvawWwfrX9Y0lrqSmAqfH8U6s6YZ9ylS5bQvMYG7Xt37o//1fcbb12XzLgLFE15ci2DlMr7ONpJaocOsnenlTz29TsoYg7exAUhXD2ICgI4exBUBDC2YOgIISzB0FBCGcPgoLQWulNsaPKHEWjZKhGlTEv6s1Zd+uw3W6iZLcbO85IOOnIa+UR+3pqyZAA7YecdezElt4m2/Nlo0lHnupZaSd6HJ4wMoQCg7V8mQ9ARvJPLS9CcHLc0T2ddjJuj4eVQLRqSFcArLQlxfJeW5bzzuHKYbuya0/+eeUlYS3V8sdju5OkMu7sQVAQwtmDoCCEswdBQQhnD4KCEM4eBAWhpbPx5QMj9H/09ty6/a99itmu/7r8Nh6Dr7S35wXdjBxvz5pWV+TPgLYN2rPBXrBOZchZasqZ9MXuDoxcZyVnNnti3O5s0sglBzB5wJk9N3LolYedsXJmyEWdnfby0w3mb3Oqz8t56OQG9FQjJ46nbAse7pJNZptFWv4pCIJHAOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVhRulNRDYBHweOA+rAtar6XhG5AngNsC999HJV/Xqzhhzzj3OX15pl4Lccea3PlqjKQ/nXxmPusfWO8X77ejphr3aEttnblAlHNjIOaa1kb6/uSV6r7Nx1pUlnuSMniMNs48hG3rJGXt41S7Hr2WG3Ge+3x2P8OCfoacI51mvsnes4lF/uqY2WNOtJg7PR2avAG1X1LhHpA+4UkVtS3dWq+u5ZbCMIgiVmNmu97QJ2pddDInI/sGGxDQuCYGGZ03d2ETkJeBJwRyp6g4jcIyLXicjqhTYuCIKFY9bOLiK9wM3Apap6GLgGOBk4nezO/x6j3SUiskVEtkzhRNYHQbCozMrZRaRC5ug3qOrnAVR1j6rWVLUOfAg4M6+tql6rqptVdXMFO+tJEASLy4zOLiICfAS4X1Wvaihf3/CxFwP3Lrx5QRAsFLOZjX8a8ArgpyJydyq7HLhQRE4niznaCrx2EexzGT7vyXbdBi+Cyllqathud9Jf58uDB//YjrDzaB+y68acgLL2QWfZKCMyz0t4V293libaZhviLr9lnFm1LkdSdOS1tlFHLu2xDam3G+0cma97r105tcIeR08CLDty6dAJ+eW92207qp352/PyGs5mNv775KfSa1pTD4Kg9cQv6IKgIISzB0FBCGcPgoIQzh4EBSGcPQgKQmuXf3I4/LKzzDpPTrAoOz/W69ll102sdsKGDFz7HHlqaoVdVzaWLQI/osxK2lhrIppvJqyllTLyZSN1kjJ649h5wJahOg/M3Q5vaSVPUlz1M7tucoWTQNSR5WrGb81Gj7W317Mzf78i4WQQBOHsQVAUwtmDoCCEswdBQQhnD4KCEM4eBAWhpdJbvb+Hod+zJTYLSwrxpJqufU50lRP1dtzVc0986Uk1Hu2Ddt2kl4zS2W8zgs1JKllyos28Nec8mceKUvPWt5tc6RwzZ4ybWSvNw1uzzaNzwDbEk+UsmXjSkWatNQm94xV39iAoCOHsQVAQwtmDoCCEswdBQQhnD4KCEM4eBAVh2US9eQkATWnFaaOeBGEvX9YU5Ym5JwYEXwKU+tyj7wBKU/ntSmNzbwOgzhpxVSd55Ip/NSocCa3WYdsxdqzdru8hZx07Y700T770jotHvWTb33nQ3vHRtfnGtDnHbKo3v9xb6y3u7EFQEMLZg6AghLMHQUEIZw+CghDOHgQFYcbZeBHpBG4DOtLnP6eqbxORfuAzwElkyz+9VFUHvG2VDo7Q9+kfztfmf2PofDuopjxpz6iWagsbObHyBnufBl5lLw01dowzC27MImeVdpUVVNG531EFnBnyiVXODPN+Z4ytYBLH9hVb7cqhE5xAnqm5B9DUy854OIFBXtDNyk/OPYgKwIp3GbrAPr+HTsi/T883B90E8CxVfSLZ8sznishZwGXArap6CnBreh8EwTJlRmfXjOH0tpL+FHghcH0qvx540WIYGATBwjDb9dnLaQXXvcAtqnoHcKyq7gJI/9ctmpVBEMybWTm7qtZU9XRgI3CmiDxhth2IyCUiskVEtkzhJHMPgmBRmdNsvKoOAt8FzgX2iMh6gPR/r9HmWlXdrKqbKxjZ8IMgWHRmdHYRWSsiq9LrLuA/Az8DvgxclD52EfClRbIxCIIFYDaBMOuB60WkTHZxuElVvyoitwM3icjFwMPAeYtoZy59n1k4GW+xaB+2da2R9ba+5i1f1bXX1lfKpgxlt6lVnPxo47YdHp58ZeFJoqsesOuaOQ88WWsh5eH54NnRZ5Rv0xGzzYzOrqr3AE/KKT8AnDNT+yAIlgfxC7ogKAjh7EFQEMLZg6AghLMHQUEIZw+CgiDaZL6tpjoT2Qc8lN4eA+xvWec2YcfRhB1H85tmx4mqujavoqXOflTHIltUdfOSdB52hB0FtCMe44OgIISzB0FBWEpnv3YJ+24k7DiasONoHjF2LNl39iAIWks8xgdBQQhnD4KCsCTOLiLnisjPReRBEVmyRJUislVEfioid4vIlhb2e52I7BWRexvK+kXkFhF5IP1fvUR2XCEiO9KY3C0iz2uBHZtE5Dsicr+I3Ccif57KWzomjh0tHRMR6RSRH4nIT5Idb0/l8xsPVW3pH1AGfgk8GmgHfgKc1mo7ki1bgWOWoN/fBc4A7m0oexdwWXp9GfDOJbLjCuBNLR6P9cAZ6XUf8AvgtFaPiWNHS8cEEKA3va4AdwBnzXc8luLOfibwoKr+SlUngU+TZaotDKp6G3BwWnHLs/UadrQcVd2lqnel10PA/cAGWjwmjh0tRTMWPKPzUjj7BmBbw/vtLMGAJhT4lojcKSKXLJENR1hO2XrfICL3pMf8Rf860YiInESWLGVJMxhPswNaPCaLkdF5KZw9LwfSUul/T1PVM4DnAq8Xkd9dIjuWE9cAJ5MtCLILeE+rOhaRXuBm4FJVPdyqfmdhR8vHROeR0dliKZx9O7Cp4f1GYOcS2IGq7kz/9wJfIPuKsVTMKlvvYqOqe9KJVgc+RIvGREQqZA52g6p+PhW3fEzy7FiqMUl9DzLHjM4WS+HsPwZOEZFHiUg7cAFZptqWIiI9ItJ35DXwHOBev9Wisiyy9R45mRIvpgVjIiICfAS4X1Wvaqhq6ZhYdrR6TBYto3OrZhinzTY+j2ym85fA/1giGx5NpgT8BLivlXYAnyJ7HJwie9K5GFhDtmbeA+l//xLZ8Qngp8A96eRa3wI7nk72Ve4e4O7097xWj4ljR0vHBPiPwD+n/u4F/iaVz2s84ueyQVAQ4hd0QVAQwtmDoCCEswdBQQhnD4KCEM4eBAUhnD0ICkI4exAUhP8PBaNlzNKPnB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAADnCAYAAACjZ7WjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABZvElEQVR4nO29aZAc533f/+me7rnvY+97sbu470PgARK8SZGOJeosWYot20qcSpVjv8gbVexKOalU5UVS+SuJK6mKneiILEuMSJEUKR7gARA3QAALYLEL7H3Mzu7M7NzHzvV/AU+blHDtcqYXAp5PFaooEZz5TvfT3+fs31eqVCoIBAKB4LMhr7UAgUAguBcQZioQCAQ1QJipQCAQ1ABhpgKBQFADhJkKBAJBDVBu9S8lSarZVn+lUpFW+98KHUKH0PHbqeV+0iFGpgKBQFADhJkKBAJBDRBmKhAIBDVAmKlAIBDUgHvGTCVJQpZlJOkzrdt/Zg2KoqAoyprquFtQFAWTyYQsr30zk2UZg8GwphpUVcXtdmOxWO6K9iFJ0prrcDgc2O32NdXwST5LW73lbv4df4iiUCqV0Ps9f1mWsdlseDwe7HY7RqORTCbDxMQEy8vLumoxGo2YzWYURaFcLlMoFMhms5TLZV113C34fD56e3vxer1Eo1HGxsYIh8O661BVlUAgQH9/P3a7naNHjxKNRnXX4XQ6OXjwIM3NzaTTaQYHB7ly5Qq5XE53LbIsY7VacbvdVCoVYrEY6XRadx0DAwM8++yzmEwmXnrpJcbHxymVSrrrgOvXxO124/f7SafThMNh8vn8ij5j1WZqNBpxOBy43W4CgQCZTIbh4eEVC/gsmM1m9u3bR29vL4lEglwuh8lkoqmpibNnz5JKpXTRYTKZaG9vp7u7m+XlZebn50kkEqiqSiqVolgs6qIDwOv10tTUhKqqjI6O6nYNPonFYmHPnj18/vOfZ/v27cRiMX75y1/ywx/+kGQyqZsOm83GAw88wIYNG9i6dSsulwuPx8OhQ4eYm5vTtfPfs2cPe/fuxWg0srCwQEdHBx6Phw8++EDXDldVVVwuF01NTbS0tGCz2ZienmZoaEg3QzUajWzcuJEXX3yRz33uc/T09PDggw/yox/9iPfee4+FhQVddBgMBjZs2IDdbqdSqaAoivbPIyMjTE5OrqiNrMpM/X4/27Ztw+/343K5NBP56U9/yuXLl3VrHG63m23bthEIBLh8+TKxWIxSqcTGjRsplUqcPHmSQqFQVw2SJBEIBHj22Wf51re+xbFjx3jttdeYmJigUqlQKBR0HbUrikJ3dzdOpxOLxcLMzAzBYFDXHt9ut7NhwwZaWlpQFIUtW7bQ1NTE4cOHuXjxom46PB4Pe/fuJZPJcOXKFZqamujv76dYLPLuu+/q9tACtLe3I8sylUoFo9GI1WrFarXq9v1w3cQ8Hg8ej4dAIEBnZyddXV00NjaSyWRYWFggk8mQyWTqqkOWZfx+P4lEgmPHjjEyMsLAwADf+ta3CAQCvPLKK0xPT9dVA1yfPe3cuZPl5WVCoRCFQoF8Po/b7WbDhg3k83kWFhbu+Nm5rZmqqoosy5TLZWRZxmw2s337dnp7ezGbzfj9fvr7+2lubiYcDjM1NUUikfjMP/R2SJKEx+Nhw4YNNDQ0EI1GiUQiJBIJLBYLgUAAm81GLBaru5ZSqUQoFOL8+fMEg0HMZjMWi4VUKqX7mpTT6eTBBx/kkUce4cSJE5w9e5bBwUEGBwd16+RMJhMmk4mRkREuX75MV1cX69atw+/3I0mSLh2LJEl0dXXR0tLCzMwMAJVKhUAgwMaNG/n44491NVNJknA6nRSLRaxWK9FolHw+r2v7UFUVRVEwGAw4HA5aWlo4ePAgXq8XSZJ4++23626kAIVCgWg0yvj4OKqq4nQ6icVi2Gw2/H4/69evJxwOk81m66rDaDTicrmoVCrk83ntt9tsNjo7O8nlciwvLxOJRO7o825rpr8+RS2VSszMzODxeHC73RQKBYxGI21tbXR0dOByuXQx06oWWZbZu3cvhUKBZDLJ1NQU2WyW+fl53abX2WyW8+fPE4lEMBgM2kNSqVR0X0tubW3FbreTyWTw+Xx4vV7cbrfWIepBPp/XRsTZbJaFhQWmpqZ0X3JYXFxkeXmZffv2kUgkcDgceDweksmkrssNAAsLC2zatIlCocD7779PPB7XfcaQy+Uol8uUSiWy2SzRaJRUKsXy8jKzs7PMz8/rYqalUon5+Xk6OjoolUoYDAbtXsViMQwGA36/n9nZ2bq22cXFRebn53niiSfYtm2bdk2KxaI2Kl3J+vptzfTXjaBYLDI9Pc26des09w6FQly6dIkTJ04Qj8dX/qtWQaVSYW5ujldeeQVVVens7OTAgQMcP36cI0eOcOnSJV0W9yuVCrlcjkQiweTkJIpy/ZJWpwx6rpcCnD17litXruByubDb7czPz5NKpXR/aKemprDZbBgMBhYWFkilUszPz+vWsVQqFYaHh/nZz37Gv/yX/5J9+/ZhNpu5fPkyH3zwAaFQSBcdVYaGhojH47S3t2M2m4lEIszNzemqoVQqEYvFMBqNpNNp5ufn+fnPf87c3BzHjx/XtbOLxWJMT0/T3t6OxWIhn8+TTqfJZrNkMhnNZOtppvl8nuPHj9PU1MSLL75IT08PV65cYXR0lKNHjxIOh1fUXqVb/eVbvc+6fv16uru7KRaLeL1eisUi77///k2HxPV4r1aSJMxmMy6Xix07dtDX18eZM2c4derUTXfz66GjeqrAbDZrF79UKpHL5cjn8zdsEHf7e8afRYeiKPT39+P3+7HZbNjtdmKxGB988IGu9wX+cZPhW9/6Fk1NTfziF7/g9ddfv+kUsl46VFXld3/3d3n++eeZmZnhBz/4AVeuXLnpZ9Xz3XyTyaSdgKnO6OLx+E073Hrem+oOevXIWCqVYm5ujlAo9Bt66qXDZDKxZcsWHn74YbLZLENDQ5w5c+amncvNdKzaTD95prN6Xq1Sqdx0JFZv8zAYDJjN5tseR6qXDlmWUVWVSqWiTe/XQsdKqZcOp9OJ2WzGYDAgSRL5fP6Wa0/1vh7V866FQuGWs4V66ujt7eWBBx4gGAxy5MiRW86c6l3opHomWpIkCoXCLUdgerTVT/pJuVy+oZ5661BVFUmSKBaLq3p2V22mK+VeNw+hQ+i4nQ5FUTCbzRSLxdsuQYmqUb99OmpyaF8gENyeYrG4Jud+Bfqw9u/5CQQCwT2AMFOBQCCoAcJMBQKBoAbccgNKIBAIBHeGGJkKBAJBDRBmKhAIBDVApJMKHULHPabjbtJyP+kQI1OBQCCoAcJMBQKBoAYIMxUIBPc1kiRhMpk+8+fcU2Z6NwSECT6NuB+Cu51KpbL2ZlrNf1rr1Ee4XjWqubkZt9u9ZhokScJgMNwVaZx3Aw6HA5fLJa7HJ6hW0QL9OxqDwaDVDxWd3Kepxeh01YVOPB4PTzzxBP39/bz99ttcuHBhTZIWPxnB0NnZydzcHMlkUreizJIkaUWQm5ubaW9vJx6PMzMzw+LiYt0zqG6kR1VVAK0k4lq8mOHxeNi9ezd2u52xsTGuXr2qSxX3GyHLspY0sFZpsR6Ph4aGBjo7O4lGoywuLlIsFgkGg7ppMhgMPProo7S2tnL27FmmpqaYm5vTLRnj1zGZTNjtdkwmE+VymaWlJV0DOavY7XY6OztRVZWxsTHi8fiq7smqzLSaA/X1r3+dxx57jI6ODv76r/+a4eHhuue2fBKLxUJfXx8+nw+3243D4aBYLDI3N8fi4qJuOvx+P08//TQ7duygsbERk8nE3Nwcr7/+Om+++aZu16TaOKt1RCuVCplMhnQ6rWtH5/f7+dznPqfVl92yZQtdXV28++67ulZNqna0FotFCzfMZrNafIdeqKrKgQMH6OnpQVEU8vk8lUqFM2fOMD8/r5sOSZLw+Xz84R/+Id/5zncYHx9ncnKSN998k3feeUfXCGxJkuju7ub5559n//79zMzM8Ld/+7dcunRJ9wGIx+OhubmZ5uZment7uXjxIiMjIysekK3KTB0OB+vXryebzXLu3Dnsdjs7duwgkUgwMTGhS0O12Wxs27aN3bt3azn1JpMJg8FAIpEglUrpYmKSJNHS0sL69evJ5/OMjIzQ29vLI488QmNjI5FIhFOnTpHL5eo+QjQajbjdbnw+Hw6Hg3K5TDQaJR6PE41GyWazdW+oVquVzZs343a7tcgUVVXZuHEj4+PjDA4O6jJSlmUZj8dDT08PTU1NzM7OagF6BoOBbDar2+zF4/HQ3t5OLpcjEomQzWbp6OigsbERWZZ1i5QpFouMj48TiURQFIVUKkVPTw//7t/9O3p7e/lP/+k/6TYyNJlMrFu3jl27dtHT00NHRwcXL15kenr6jgPsaoHRaMRkMpHP50mlUjQ2NvLUU0/hcDj4+OOPb5oMcSNWbKaSJOH1eqlUKhw7dgy4fpOWl5dpbm4mEonokgNVLBaRZZne3l78fj+RSIR8Pk8sFiMajXLt2jVdzNRisWC32zl//rw2xVYUhc2bN3PgwAGi0SjlclnLpLpZjMlnpZryuHHjRjZv3kyxWGR+fp5yuUyxWMRgMFAqlZiYmKj5d1cxGAw0NDTQ1tbG8vIyJpOJUqmk5fu0t7dz+fJlXUxMlmXsdjsvvPACzzzzDN/73vdIJpMsLy9TLBZRVVW3sEOPx8PGjRuJRCKEw2EKhQK5XA6r1arr2mWpVOLq1avMzMyQzWYJBoMYDAbS6TRbtmzB5XLplthaXUcPh8McO3YMu92Oy+XC7XYTjUZ1W5qqxg0Vi0VKpRJGo5HHHnuMnTt38t/+23/j0qVLdzybWrGZVqeO8/Pz2gNaNQebzYbH49ElwC2fz3P16lUWFhZ4+OGH8Xg8ZDIZLZtdj00xSZJobGzEYrEQj8dxuVwYjUaMRiOFQoGPP/6YN998kwsXLpBKpTAYDKiqWpfe32q10tnZyde//nUefvhhfvaznzEyMkIsFtM6uHqPOkqlEslkElVVaW9vp1AoEIvFKJVKWtvw+XxEIpG6G1mxWCQej3Pt2jWGhoa0EYYsyxgMBm0jSK/Y6Q0bNpBIJJiZmdFihZeWlnRfww0Gg5w7dw63262Z6szMjJZiq5eZlstlwuEws7Oz2Gw2xsbGmJmZ0TX4Ef4xfbm6LFYdfOTz+RU/M6ua5kciES3uuRodqygKsViMRCKhWwMJh8McOXKE9evX89BDD2mL2LOzs8Risbp/v9Fo1DLHP5lbYzKZGBoa4qWXXuK1114jnU4D1PW6FItFMpkM77//PleuXGFkZITJyUmi0aiW+qgHS0tLjI6O8tRTT7F582ZCoRAXL15kcnKSy5cvk0wmkSQJo9Go6a6XocXjcQ4dOsTw8LA2eyqVShSLRQqFgm7ttBotvX37dqamprBarSQSCYaGhnQ306WlJc6fP89XvvIV5ufntVGgw+HAarXqpiOfzzM9Pc2RI0dwu91UKhVCoRCRSETXDdPq9a+a59zcHK+99hpjY2NMTEysaFlsVWaayWQYHh4mEAhoD0UulyMYDOq6G1cqlThz5gySJHHx4kVUVeX48eNcunRpRWsdq8FgMGC1WgmHw2SzWWw2G5lMBpvNRjKZJBaLceTIEc1I6006nWZkZISpqSnsdjuKomgmquemYLlc5uOPP+bll1+mXC5jsVi4fPkyb731FlNTU58yD1mWMRqNdZtFlMtlgsEgiUQCk8mkGWomk9HVxCKRCIcPH6a1tZWBgQEcDgeHDx9mbm5uTU4XnDhxgq6uLpxOJy0tLRiNRqLRqK6bg5VKhWAwSC6Xw263k8vliMfjup8IMhqNLC0tkUqlsNlsLC4ukkwmCYfDK9bymQL1qlOmtU44NJvN+Hw+fD4fY2Njt2wUtdJhNpu10U31ZYFPnqdUFOWWm071vB6fTIv9h++66d+tlw6j0aidMV1aWrpl5/YPI/u6FrGork3ebtRTr+uxbt06Hn/8cVRV5dq1a1y4cIFgMFiX9nE7LdW1fbfbTUNDAwAzMzM3nVXWu8DInS631FqHJElYLBbtdMXt0lFvp+OeSietruGutY47Qei4v3TIsozX6yWTyZDNZutq6rfTslLu9XtTKx33VDqp3ovXAsGdUt1wEdy7iPf8BAKBoAYIMxUIBIIaIMxUIBAIaoBIJxUIBIIaIEamAoFAUAOEmQoEAkENEGYqEAgENUBEPQsdQsc9puNu0nI/6RAjU4FAIKgBwkwFAoGgBggzFdQdkRp796Io99Qb5WvKZzJTo9FIS0sLbW1tWCyWWmlaFdXCy2uZhOn3++ns7BSJnP9ANa21mtG11lSrJd0N9+Zu6VzW+r6oqorH48Hr9a6pjk9WwFstq+qWDAYDXq+Xnp4e1q1bh9vtZm5ujnfeeYdkMrlqMavV4nQ6aW1tJRAIMDs7y8jIiK4a4HqjrNaGdLlcpFIp5ubmdK/PqCgKfr8fs9kMXC9MHI/Hdcs7gusPSDWCohrwFw6HWVpa0k1DlUAggMvlwmaz4fV6aWho4Ny5c4yMjOie2irLMi6XS4tz0TP08UZYLJaa5MWvltbWVvbu3Yvb7SYYDHLmzJk1uSZ2ux2/34/dbtcKRK+maNKqzNRmszEwMEBLS4vW2z/00EO4XC5+8Ytf6JZy6Ha78fv92oPS3t6Ow+EgGAzqauqKotDQ0ICqqhQKBYxGI93d3TQ3N/Pxxx/rFnGsKArbt29n//79eDwe1q1bhyRJHDp0iEOHDjE1NaWLgVitVnbt2oXL5SKZTJLJZHC5XCiKopupy7LM1q1b+b3f+z18Ph92u522tjYSiQQ//OEPmZyc1K2jMxqNtLe309raqkXaxONx3UIffx2TyURzczOtra3k83ld46artLa28swzz9DW1sbCwgIOh4Pe3l5isZiu6aRGo5Gmpia6urro6ekhnU7z8ccf65NOKkkSLpeL1tZWLBYL2WyWdDqN3W5n165dvP/++7qYqdlspq2tjZ6eHpxOJ4qikM1mtTjbVCqlayiXw+FAVVVt2tLV1UVjYyPxeJyLFy/qoqOjo4M9e/ZQLBaZnZ3Fbrfz/PPPs3XrVjKZDKFQSBcDURRFS9+cmZlhaWkJi8WCx+PRbeQhyzJdXV1IkkQwGKS9vR2Px0NLSwsdHR26TvWbm5v5yle+QiKR4OLFi2SzWex2O16vl9nZWd10VPF6vXR2dvLUU09RKBQIh8N1DVr8daxWKzt27GD9+vXE43EWFxeJRCI0NTXR09Oj26zBYrHQ3NxMQ0MDW7Zs4Stf+QrhcBiLxUImk2FycnJFOlZlpjabTZsiSJKE0+mkv79f13qNkiQRCAR4/PHHGRgYYGxsjFOnTpHNZmlqaiIUCunW6yuKoq3FWSwWmpqa2LlzJzt37mR4eJiRkZG6x6ioqsrmzZsxmUzMz8+TzWbJZDIUi0W2bNnC8vKybqMPo9HIxo0b2bhxI8eOHaNcLrO8vKxrxlC1ino8HiebzdLQ0IDD4cBsNiNJkq7LHna7nSeffFLLwqq2S7/fvyajQpvNRk9PDwcOHCAcDjMwMMD8/LxuI/VisUggEMDn85HL5TCbzVQqFfL5vK5Bh6qqYrVacTqd2O12VFXVOlu/37/ia7KqdNLqD60ahNvtprW1lYmJCV1inqvfXSgU2LZtG83NzVy9ehVVVbWHqDpq1gNJkjRDtVgs2pSloaEBs9msS1KqyWTCbDZrM4VisUi5XGZ4eJjp6WlOnjxZd0OvYrFY6O3txWq14vP5tJwsv9/P9PS0buZRKBRIJpOUSiXi8TjpdJp0Os3MzIyuBlZNsVVVlaGhIWKxmJaeuhaFhhYXF5mfn+fVV18lmUxSLpexWq26mWmlUqFYLOL1egkEAvT29vLWW29pSbp63ZtUKkU8Hsfv9zM8PMyPfvQjzGazltq60ud2VWa6tLREqVTC6/ViMpno6OhAURRGRkZ0C5ArlUpMTk7y0UcfsX//fkwmE1arVYtS1vNhyWazWg56VUcoFOLs2bMcO3ZMl0aayWQYGxvTRqd2ux2fz0c+n+e9994jGAzWXUOVUqmE1WrF5XJpi/upVIpAIIAsy7rdm2oWerlcJp1OMz4+zsLCAseOHdNtZFodBR8+fJhNmzbR3t6upYImEok1MdNkMsng4CDBYBBFUTQtelEqlTh16hSNjY3s27cPl8tFX18f4+Pjuj631fQDk8lELpdjYWEBRVHIZDKk0+kV35tVZUApisLOnTt59NFH6e3tpa2tjdnZWb7//e9z7NixG+6E1eNVMFVV6e3tZceOHbjdbmKxGJOTk8zPzzMzM3PDkVi9Xklrb29n06ZNtLa24na7iUQiHDlyhLGxMd1CyqxWKx0dHRiNRoxGI1arlampqVuuh9VDh8lk4tFHH2X37t1kMhnC4TBTU1OMjIwwPz9/w0Zaax2yLNPf38+BAwcIBAI0NTXR1tbG97//fX7+85/f9LPqEdpmtVqx2Wxs27YNr9fLxMQEExMTRCKRm5q6Xq+T2mw2crncLXev6/XMtLS08OCDD7J//35UVeX111/n0KFDN51B1UuHxWKhoaFBO95ZKBSIRqMkk8kb3p+aB+oZjUY6OjrYsmULZrOZCxcuMDY2dtOpdT2Dymw2G1arlXK5TCKRuGUmer10VHf0A4EA6XSaSCRCLBbTPZ30k+fk/iH185afVc/7oiiKtv5VXXbQU0d1M/KZZ55hw4YNXL16lZdeeumWJz3q+f539SxjuVyua/DjnWhZCfW8JiaTifb2dtra2hgbG2NqampNdMiy/KkE29W01c+cTmo2m5Fl+baJi3d7kYJa6biThFQ9dNwp94OO6siwUqncdpP0Xrged5OWO9VhNBqpVCq3PBZ1t9+beyrqWegQOoSOu0vL/aRj7d+rEwgEgnsAYaYCgUBQA4SZCgQCQQ0Q6aQCgUBQA8TIVCAQCGqAMFOBQCCoAcJMBQKBoAaIdFKho+4vMaiqetv6BPfL9dBDx92k5W7VUX3jaTVFoMU5U8GaITY5BXcbgUAAp9NZ088UZiqoK3dD3pJA8OtIkkRHR0dNs7hENOE9jJ7l7m6GwWAQhiq46wiFQgBavd1a8JlauSzLmM1mHA6HLgWQ73aq4X5+vx+v17um16SaiLDWfLIaz63+Tq359epZwtB/E0VRMBqN9+W1qVQqhEIhyuUyHo+nJp+5qpGp0WjUco/sdjuyLLOwsMDCwkJNRP02YrFY6O7uZtu2bfh8PsxmM8ePH79pfdd6YrVa6evrQ1VVzp8/r2tA2a9jNptvW4i51p2OLMu43W7tujc2NmK1WllcXCQajeoaYmexWPD7/TQ0NGCz2bSCxOPj4+Tzed10fBJZlnE4HBiNRi2xIp/P695OAZxOJw0NDeTzeUKhkG5pEPCPhe537drF4uLiZw6cXJWZWq1Went7tdFXNSAsEAiwuLhIIpHQLQLB6/WyYcMG4vE4Y2NjdU0CNZlMN6yV6nK52Lt3L21tbaxbtw6r1UpraytWq5WLFy8Si8XqpumTOJ1OHnzwQXbt2sXWrVtZXFzk7//+7zl+/PiaPLjVgsjpdJrBwcEbmlg98uPL5TK5XI5169axadMm+vv7KRaLRCIRLQFBr6RWSZL4xje+wWOPPcbg4KBW2f3q1aucOXOGkZERXZdiFEXB7Xbjdru10pmpVApJkshms7pq2bx5M//iX/wLent7OX78OKdOneLUqVPaFFwPKpUKmzZtYseOHRw7dozx8XHGx8dXFfy4YjNVVZWGhgb6+vqw2+2kUingutFURwN6xiwfPHiQ7373u4yPj/M3f/M3vP/++3WNTqnmLMH1G6EoChs2bGD//v1YLBacTidWq5VKpUJzczO9vb18/PHHdW+ksiyzYcMG/vAP/xCn06kVIn7hhRdQFIX3339f15FHQ0MDn//85/niF79IJBLhJz/5CYcPH9baiyRJWnZWPSJE8vk8VquVL3zhC1gsFj788EPS6TRNTU0cOHCA119/XZcU3eXlZYLBIJcuXeLEiRMkk0kt+8jlctX9+6tUR+ttbW00NjYiyzLhcJhyuUyhUNDW1/UYtauqyt69e/nLv/xLWltbOXfunBaEuXHjRpaWlnQbodrtdq1AtdPp5MqVK+zatYuPPvqIiYkJbDYbJpOJ2dlZLQLnZqwqndRqteL1evH7/cRiMS1dMJvNUiwWdR2qJ5NJzTxbWlro6+tjaGioLiOxfD6PoiiYTCZtatra2srTTz/Nhg0baG9vx2q1Eo/HtZH59u3bGR8fr/uDK0kSnZ2dbNq0iVgsxpUrV0gmk3g8Hj73uc9x+vRp3cIOHQ4HX/3qV/mn//Sfap3sH//xH+N0Ojly5Ig2ui+VShSLxbqNEC0WCxs2bGBhYYFUKkU0GiUcDmO1WmlubiYej9e9gykWi5w5c4aWlhZMJhOZTEb7oyj67f/KskxPTw/f/e53KZVKHD58WGsT1Y5Nr/y0xsZGfv/3f5/du3dz6dIlpqamtAFYa2srLS0tukVPOxwO8vk8V65cwefzYTQaeeqpp/ja177Gz3/+c06fPs3k5CQWi4VisXjLme+K72a5XKZcLtPS0sLevXtZXFzk2rVrJBIJJiYmSKVSuk4VPv74Y37605/i8Xi0B8Vut9dtWlssFikWi1oKavX7/H4/TU1N+Hw+5ufntaTWRCKh20ZUuVwmFoshSRLRaJRQKITNZiMajerWwRkMBvbu3csXvvAFGhsbKZVKTE1NYTAYePTRR5menmZkZIRMJkMul6NSqdRtqj87O8uvfvUrXC4XpVJJi1CRZRm73X7HqQiflVgspi2FVbO5mpqamJ2drctvvxHVtdp3330Xi8WixRgvLy+zvLystWs9lj7C4TCXL19mx44dhEIhJEnSlh0qlQoXL16su4Yqy8vLxGIxpqenSaVSGI1G4vE4hUKBkydPcuLEiTtuIys201KpRCQSIZVKsW7dOnp7eymVSly+fJmZmZlb5h7Vg0gkwi9/+Ut6eno009DjAalUKmQyGYaGhvjJT36CyWTC6XSiKAqFQoHFxUUOHz7Mhx9+SCQS0UXP9PQ07733HpIksbCwQCwWY2lpiWvXrulippIk4XQ6eeqpp1i3bh3BYJBEIkEoFCKbzTI2Nsa1a9d+4yhKPdpLpVJhYWGBoaEh1q1bh8FgwGazkU6nSaVShEIh3TbmQqEQk5OTPPbYY8iyjN/vJ5FIrGpdbrVUO5ef//znNDc3YzKZyOfzmokWCgUKhYIuz24ul+Pv/u7vANiyZQuNjY10dHRgMBi06bVeZLNZEokETqeTUqmE0+nk0qVLzMzMMDg4uCIvWVXU8/z8PG+99RYmk4nW1lYmJiYYHBxckx3KcrnM6Oio1sMVCgVdd2vz+TynT5+mUqlQKpXYuHEj586d45VXXuHChQvaGmG9KZfLjI+P8/HHH+P3+8lkMsTjcVKpFCMjI3XtYKpHj1RVxWazYbFYKJVKpFIpIpEIyWSSaDTK4cOHa3am706IxWLaOmU1X2h+fp7R0VFdO/1CocDg4CBf+9rX2L9/P+l0mv/wH/4D586d021kWtWxuLhIpVLR9jdKpRL5fF63DeMqwWCQv/7rv2bTpk089thjbNy4kUwmw6FDh3RbjoLrEemhUAiHw0G5XMblcmEymRgeHl7xs7vqDCiHw4HT6USSJPL5POl0+pahevfi+72fpLom9eSTTzI+Ps6HH354y/WVeqVxWiwWvF4viqKwvLzM0tKSNp3WQ4fFYuGb3/wmf/qnf0oikWBqaorJyUmOHDnCu+++e9PNwXrdF1VVcTgc2v9OpVK3HKXXS4fVauXJJ5/k2WefZXh4mB/84Ae37Fjq+W6+2WzG4/FgMBhIJBK3XZqr97NrMpkwGo3aBpjeycJms5mmpib8fj/Nzc34fD7eeecdZmZmVqRDBOrVUIeiKOzbtw+z2cypU6dIJBJromMl1COvfv/+/fz5n/85Xq+X48eP89Zbb3HmzJn78np8EpPJRFtbG5FIhEQiUTcDuxMt1Rc6MpnMbUfo98O9gesdryzLWK1WAJaWllakQ5hpjXU4nU56enoIBoO3PC93r14PRVHw+Xxs2LCBQqHAyMgI0Wi0rjnxd/P1WAsdd6Kl+tbTnWwW3wvXRA8d4t38GpNIJJicnNQ2o+pxhvJuplwus7CwQC6XI5PJrOnbV4Kbs9Y1G+5FhJnWgVgsRqlUwm63k06n7ytDqT6k1eM2AsH9gjDTOlCpVEgkEiiKcl/W8qye37wff7vg/kWkkwoEAkENuP9qbwkEAkEdEGYqEAgENUCYqUAgENQAkU4qdAgd95iOu0nL/aRDjEwFAoGgBggzFQgEghogzFQguI8wGo26FqW+n/hMV7Va9LhSqazZ62mSJGE0GqlUKhSLxbvmNblqIeL7EVmWsdlsWjzG5OTkmoXHwfUCI3a7nUKhcMtiK/XEaDTi9XqRJIlwOLxmb8UZDAa8Xi+xWEy7J/drO601qzJTSZIwmUzYbDYURSGXy5HNZnWNK6lSLTlntVq10LRkMrkmpmq323G73ZjNZhRFYWJiQrc6kZIkYbfbtSiQtbgXcN1I+/r66OjowGQy0djYSF9fH+fPn79pSbN6oqoqfr8fj8eD2WxmampK9xRdo9HI/v37+frXv47f7+fVV1/ljTfeWLM037a2Nvbv38/CwgKLi4sEg0Fdc9s+iaqquFwu8vn8mmmoRtZXnxu73U6lUllxltyqzNRsNtPR0cG+ffsIBAKcPXuWS5cuEY1GdX0f22Aw4HK58Hq9tLa20tbWRiaT4aOPPmJ6elq3ADmTyURvby979+6lqakJj8dDJpPhRz/6EaOjo7r0/Iqi8KUvfYmNGzfy4YcfMj09rT0seo6CrFYrPT09WkZYT08PfX199Pf38+677zI8PKzbKFWWZbxeLw6HA6vVis/nw+Vycfz48bqGLv46DoeDL37xi3z5y19mfn4egKamJl5//XUuX76sezrp5s2b+bM/+zPK5TJHjhzh//2//3fbEom1pjogCwQCPPvss7S0tPCzn/2Ma9eu6V6o2mAw4PF4sNlseL1ezGYzwWCQycnJFWlZsZlW83Meeughvv3tb9PU1MQvfvELCoUC58+f17V3MRqNuFwunE4nZrOZlpYWdu/ejd/v5wc/+IEu6ZMGg4F169bxwgsvEAgECIVCzM/PYzKZ2L9/P5lMhvn5+bo/MMVikWAwyJe+9CXS6TR2u53Ozk7Gx8cZGhrSzVC9Xi92ux2Hw8GWLVvo6elhamqKfD5Pb28v8XicyclJXbRU48eNRqO2Vuj1evH5fLqaabFYRJZlRkdHeffdd5mfn8dsNtPX18fIyIiuswij0aglMZjNZnp6evjc5z7H0tISw8PDuqVU2Gw2bDYbTqeT9vZ2HnzwQS5duqTFcevZwRiNRgKBAOvWrcPr9ZJMJonFYivObluVmZrNZnw+H4VCgZmZGdxuNwMDA0xOTpLJZHQZEUqShMPhwO1243A4MJvNWhql2Wzm7bffJplM1tVEqnk+/f392vqg1WrVYnRNJhNbt25leXm57nEdlUqF48ePazlMkUgEt9vN5z//efr6+jh27BihUKju90ZVVaxWK4FAgO3btxMIBJAkSetk9Zy52O12mpubkWVZM5GmpiZaWlqYmZnR7YEtFovMzs5y+PBhLl26RDqdxu1209HRQVNTE1NTU7rogOvGoaoq58+f13KfDAYDra2tLCws6JJOCmjPZbFY5MMPP+TixYsEg0GMRiM2m41UKlX3GV11qbKvr4+DBw+yZcsWwuEwFy9eZHl5ecXXYVWBesVikcXFRYaHh5FlmVwuR3NzMy6Xi4WFBV2n1xaLhUqlokV0zM7OEo/HUVVVC7erB2azGVmWMZlMOBwOGhoa6OrqYnJykunpaeD6lLcavKcH8XicCxcuaOuDZrOZxsZGnn76aR5++GFef/11Pvzww7pOszOZDMViUcuGd7vdbNq0iWQyic1m0y2pVZZlGhoa2L59Ow0NDSQSCYrFIoqi6PKgfpJCocDc3BzxeJzZ2VkKhQKqqtLQ0IDFYtFNh6qqOJ1OYrEYsixrI+ZsNkupVEJVVYxGoy7T7GpmWqFQYGFhgUgkQi6Xo1QqYTAY6r6B+8nIeqfTSWdnJw899BCnT5/m2LFjJBKJFT8nqwrUSyQSDA8P43a78fv92tRO7119g8GAoigYDAYMBoO2wXDu3DktrrVeVBvc7Owsx48fp6enhz179miRtZlMhsnJSUZHR3WbOlUqFaLRKLIsa2Xwzp8/z/Hjx7lw4QKhUKju65Xz8/OcOHECh8PBlStX6OjoIJ1Ok0wmCQQC2lS/3qFp5XKZVCpFQ0MDX/ziF7WI6aGhIS1UTi+Wl5eZnp6mv7+fcrlMsVgkl8sRi8V0C1yE69dkamqKt99+m/b2dtxutxaLvrCwQCqV0m29sto+qzNZSZIol8vkcjldlqQqlQrJZFL73r//+79naGiIRCLB1atXicVi9R+ZwvXRx/DwMOVyme7ublwuF6FQSPcNqHQ6TSgU0gysuj44PDysm5ZSqcTIyAj/9b/+V4aGhnjqqafI5/OcO3eO06dPs7CwoOuDm81mWVxc/FScsR5R01UqlQrXrl1jaWmJs2fPsmvXLgwGgxYj3N/fD8Dx48fr3slUp9ZtbW34fD4tk/1m2T71ZHx8nK1bt2oxzwaDgVAopGvcc6lUIpvNMj4+TiwWw+12Y7VateNaeu535PN5bWRaKBSQJEnrZPQy9GKxSDQaJZVKEQwGOX36NAaDAVmWV7WOveoMqOpunMlk0s543upITj3eq1UUBUmSUFVVM05ZlrVp/41+Wz3f71VVlZaWFmw2G/Pz8ywtLd23aa1VquuUbrdbmz0sLy9z4cKFT5l8vXRUj2dVj89dunTplqPieiZgPv/882zbto10Ok04HObIkSMMDw/XvJ3eTss//HvtGa7+s97JsZ/U8onvuunf0+uZud0SgwjUEzrWTIfBYMBkMlX/G62z++TMQQ8dNpsNVVWJxWI3/Tv11OF2u+nt7aVQKDA/P08kErnp/oIodPLbp0OYqdBxX+m4XcjhvXA97iYt95MO8W6+4L5ChPwJ6oUwU4FAIKgBwkwFAoGgBoh0UoFAIKgBYmQqEAgENUCYqUAgENQAYaYCgUBQA+6pdNLW1lYWFxdv+SrY3X5WTei4d3SoqookSat6NVGcM/3t03HPjExVVUWW75mfI7gHKJVKIhLkPuKecR9VVTEYDKLxCm6Jw+HQ7bsqlcqn3jsX3NvcM2ZaraYuuHuolgK8W6gG6+lJtTyk4N7nnsh8lSQJl8uFqqprOjJVVRWz2UyhUNA9xwauXwdFUbTSasFgcM2C9VRVxefzoSgKiURCKxq9VsiyTFtbGwaDgWAwqMt3VioVrRB0uVy+a2ZN1WpRsixTKpVuWmFNb03V2qJrhaqqlEqlVWv4zGaqqirAmkXXAjidTnp6eshms2uyblqNWvD5fFitVnK5HKFQiEQioVsjlSSJnp4eDhw4wLZt23C5XHz00Ue8/vrruplHFZvNRm9vL+3t7VpibDgcJhqN6h61bDAYaGhoYOvWrezfv59Tp04xMjKi2/cXi0UMBgMWi4VsNnvT9vBZH+SV0N/fz/PPP4/D4WB2dpZjx45x8eLFun/vzagmVZjNZiYnJ3UtmA3Xi990dnayfft2ZmdnGRkZWVV+3KrN1OfzsWfPHtrb27l27Rrnzp0jFovp2sPJsozb7Wbz5s10dXWRSCS4du1a3fOWPvn9TqcTn8+H2+3Wenu3200gEGBycpJgMKhLjIvT6eSZZ56ho6NDM/EvfOELbNy4kf/yX/6LbiF2Ho+HJ554gp07dxKJRJiamkKWZWw2G7IsUygUdA1t2717N/v372fLli3s2bOH3t5ezp07x+zsrC4a4HohZIvFgs1mI51OU6lUUBQFWZYpl8tIkqSbkTY0NPDcc88xMDBAKpXS0jKqkT96Y7PZ2LhxIx0dHSiKQkdHB4ODg7rGgvf29vLCCy+wbds2JiYmaG1t5ejRo8zPz6/Iz1Zlpk6nk29/+9t84xvfIJfL8d577wHoGhcryzLt7e309fXhdru1XJuOjg4ikYgupl4102r8gyzLKIqiJaW2tLRw6NAhXSrdBwIBnE4nExMTZLNZHA4HFouFAwcOEAqF+M//+T/Xfcqvqirbt2/nn/2zf4bRaOSDDz741Hqhw+HQpvt6zGRaW1t5/PHHMZvNJJNJ4vE4u3fvZv369czNzena8edyOS3gLxAI0NLSQrlc1jocPSruGwwGtm3bRnd3t1bIPZfLaWm2elJ9Vjdt2kRvby8+n49cLsfo6KhuU31Jkmhvb+fgwYPs2rWLYrGI2WymubmZBx54gBMnTqzI1FdspkajkZ6eHp577jna29v58MMPSSQSGI1GLBaLbmbqcrnYvHkz7e3t5HI5lpaWKBaLeDweLBaLbiF25XKZUqlEqVRCURQtpKs6Wg4Ggxw7dqzuo9NEIsHS0pJWfDmXy7G4uEipVOKRRx7hBz/4AXNzc3XVoCgKXV1dDAwMaNOkaiHoUqn0qZyweDxe1zwqWZYJBALE43GCwSA+nw9Zltm9ezeBQEBbL9QLSZIwm8088sgjfPWrX8XhcDA3N8fIyAjvvfcemUym7tNbRVFYt24dLS0tOBwOJiYmGB0dJZlM0t3dzdjYmC6dnCzLbN++nccff5zW1lYaGhqwWq1MTU1x9uxZFhYW6q4Brt8Tj8dDS0sLxWKRdDqNqqr4/X5UVWV8fLy+ZlooFJicnOSXv/wlMzMzXL58mYmJCVKplK6N0+l00tvbS3Nzs/ZwptNppqentXXcelMqlYjFYpjNZu1YlizLuFwuHA4He/bsYefOnVy6dKnuSyDxeJxIJMLAwAANDQ2YTCZcLpdm8OvWrSMajdZ1Y6xUKjE3N8fp06exWCzkcjkqlYp2eL1QKGjhevUeJVcqFVKpFDMzMyQSCaanp0mlUgQCAYxGo+5Hlqr3fs+ePTz88MNMTk5qkeDVyPLqEkA9MZvNtLe34/P5gOthf9Uk30AgUPcOF67PYB544AH27duH0WjE5/MhSRKjo6OMjo7qtlFZHXRU26WiKNqzUygU8Pv9mEymO+70V5VOurS0xP/+3/+bzZs343a7SSQSBINBXYPKJEnC5/OxadMmPB4PANPT07zxxhtaREa9qT6wc3NzFItFnE4npVIJq9XK1atXmZ+f58iRI7oF+y0tLWG1Wlm/fj1ms5lAIIDf7+e9994jnU5rm2P11HDhwgX+v//v/2PXrl1ks1kURcHlcpFKpZifnycYDOqyZlqpVAgGg3R2dlIul0mn01po2uLiou4bldUHd3p6mqmpKdLpNNFolLm5OdLptC7Hp0qlEkNDQ5w7d45t27Zp+WnVuHa9YqeXl5c5ffo0TzzxBFu3bsXpdHLs2DHeeust3db24fo9icfjjI+PUywW6erqYu/evQwODjI1NaWFQN4pq96AWlxc5IMPPsDr9VIqlUgkErqOTKs9SkdHB729vaiqSj6fp1Ao6KoDrqe1hkIhAC13/Ny5cwwNDTE+Pq7L2lzVyBYWFti3bx8PPvgguVyOv/mbv+Hll18mEonUfTRYKpUIBoMsLi4SDAbp7u7G4XCQz+eZnZ1lampKt+UXgGg0SjKZpLOzk2QySTgc5ty5c7pNI29EdY20ml8/MzNDLperewQ3oEV/V6eulUqFfD5PLpcjm82yvLysbYrVk0qlwvnz53nttddwu92cP3+ev/3bv+XSpUu6nwpaWlriyJEjdHV1MTExQTgcJpFIMDQ0xKVLl1b0zPzWZkBZrVYef/xxXnjhBfr7+0kmk7z11lu8/fbbjI6O3vSm1PP9XoPBgNVqxel0ArCwsLAmOlRVxel0YrFYCIfDtxyN1kuHqqp4vV4sFgv5fJ5EInHT9Mt66mhoaKC5uVlbArqdadW7fWzbto0XX3wRm81GNBrV4smvXLnyqTXTer2bX13eWEkHX69r4vf72blzJ2fOnLmjTdp63htFUbBYLJhMJm3JcqXP7m+tmUqSRGdnJ21tbdpwvRqvfKuRqR7FEu7kAPLdXrRB6KiPDrvdTmdnJw6HA7vdTi6XY3x8nGAw+Kn2cj8UOjGbzZhMpltGb+uhY6Xcc2YK13t6VVVZXl6+46nJ3X5DhI57W0d186u6MVcul8nn87/Rfu8HM73XdPxWv05aPZIkEPy2YDAYKBQK2jlPwb3DPVPoRCC426nWTljL988F9UOYqUCgI8Vicc2Ligjqg0gnFQgEghogRqYCgUBQA4SZCgQCQQ0QZioQCAQ14J5KJxU6hA6h4+7Scj/pECNTgUAgqAE1MVOHw7HmKYzVSu4CgUCwFtTEfYxG45omMFajQu4WM13rjkUgEOjPZ3afalEPRVm7N1MtFgs7d+7E7/evmQa4burV4rttbW33vanKsozVasXn8+FyudbselQTW6vRMoJPc79fE6PRyMDAAO3t7Z8pLv4zOaDNZqO7u5vNmzczPT3Nxx9/rGu9SrheheeBBx7gS1/6Eh0dHbzyyiu6hnFVMZlMDAwM4PV6sdls5PN5MpnMqlIOV0vVzCuVCpVKhWKxuGbxylarlZaWFrq7u/F6vcRiMU6dOqXr9VAUBY/Hw8DAALt27UKSJE6ePMnp06fX7L34ahX3u+WVUovFQmtrK9euXVtrKWuCzWbjxRdf5Hd+53fI5/McOnSIX/3qV6vykFWbaWdnJy+88AIPPPAA/f39GAwGXn75ZV5++WUtKqLehV6tViv9/f1s2bIFWZbp7+/nySef1OJ89Xxg2traeO6557RYY4PBQFNTE7FYTLcHx2g0apEpsixrSQCxWIxsNqubDqfTSX9/v5ba6vF4cLvdlEoljh49qkuHW01i2LZtG9/85jd5+umnURSFt956i7/6q7/i8uXLur3WKcsyDQ0N7N+/n4cffphQKMTx48e5cuUKS0tLK67oXgscDge9vb1s2bKFqampNTHTzs5Otm3bRqlU4uLFiywtLekaBa6qKo8//jgbNmzg2rVrxONx2tra+NrXvsabb77J1atXV1S0e0VmWp3St7S08MUvfpGenh4ymQzLy8t0dnbyyCOPMDU1xfj4uC4Vs6uRGEajkcXFRSKRCKqq0tnZqVUx1wOz2czjjz/Orl27OHr0qJa15HQ6sdvtujSQamCbzWbD4/FoyY/5fJ433niDq1ev3rI4c61QFIWNGzeyefNmKpUKpVKJZDJJPp/H4XDQ3NzM6Oho3XVUtRgMBsLhMMPDwzgcDrxeL3v27GFiYkKX66GqKvv27eORRx5hz5499PT0YDAY2LFjB6+88grHjh1jZmZG1xlEU1MTf/Inf8KePXtIJBL88pe/xGAw6FqBLRAI8NRTT9HS0oLRaKS/v5+5uTmOHj3K4uIi+Xy+7h3MwMAABw8e1KKHqoF6bW1tvPjii/zqV7/izJkzd+xltzRTp9Op/SBZlpEkCYfDwfPPP09XVxfhcBij0Ui5XGZiYgKr1YrRaNRtRFjVls1mSaVSmM1mvF4vi4uLNDU13bbKfK3w+/0cPHiQlpYWzGYziqJQLBYxmUy6JrZWp/eVSgWn08lDDz3Epk2bmJ+fZ3x8XBcNfr+fAwcO8MgjjzA5Ocn09LSWmrq0tITH49G1jSSTSU6ePMnU1BQejwer1UqhUMBisehipoFAgIcffphAIKDNWPx+P1arVQs81HvK/+yzz/JHf/RHDA0NMTw8jNPppKGhgWAwqJsGh8NBU1MTfr8fh8PB1q1bSSaTtLS0MDU1xfnz5+s+Wrbb7VgsFmRZZnl5GbfbjcFgoKGhAZ/Px+zsLJOTk3d8XW5ppp9sbFXjqoaC9fb2Isuylu9TjZF1u92YTCZdTKxYLBKPx4nH4/h8PjZv3ozD4aBYLBIMBnWbOhmNRjweD62trTQ3N5NIJEilUrrlw8M/RipX/4RCIV5//XWOHj3K5cuXdckYgusjZJvNpkUqG41GFhYWtA4lEonoshFVTV/IZrMEg0Gi0SgNDQ04nU5CoZBuI8FyuaxFYmSzWdLpNCaTiVAoRCQSIZfL6W6mlUqFyclJLl26xPj4ONlsVvdNqKph/tmf/RldXV3Mz8+Tz+eJxWIEg0Fd7s/c3ByFQoHm5mZtryMQCBAIBBgfH0dVVaxW6x1/3i3N9EbD/lwux4kTJ+jq6qKzs5NwOEwmk0FRFC5cuMDJkyd1M5BcLkc0GiUWi1EsFlEUhZ6eHqxWq3Zz9CCTyXDkyBFtnc7v95PJZLQUSr1YXl4mk8lgMpkIBoOagU1OTup2LRYXF3nppZfYtm0bW7Zswe12E4/HsVqtmEwmlpaWdBuV5vN54vE4ZrOZQqGA0WikWCySSqV0M7BYLMbZs2cxm82USiWy2SxGo5FwOMzs7OwdZR/VmlOnTvHcc89po+JYLPap/Ck9KBaL/OpXv2Lfvn3Mzc3xve99j+npaa2D0YNQKMTly5e1QZDb7cbtdmO1WhkaGmJ+fn5FG6arji3p6OjgmWeewel0ksvlMBgMnDlzhmPHjt3QhOv1KpjVaqW9vZ2Ojg7a2trw+/189NFHnDlz5oYGUg8dJpOJxsZGtm3bhtvtZnl5mUgkwtDQEHNzczccIdfrelQ3oaxWq1bVfWFh4aZmWi8dO3fu5Ctf+QpNTU3Mz89z9epVTpw4wejo6A2jnuulw+l00tHRgdPp1EYZi4uLjI2NkUwmddPR3NxMb28vmzZtorW1lcuXL/P+++8TCoVq3j5up8VkMvHFL36Rvr4+Tp06xccff8z8/PxNP6uer3E+8MADmEwmjhw5cttBWD1y5BobG9m0aRO9vb0EAgFt8/bq1au89957jI+P/4af1TwDymg00t3drYlSFIXx8fGbjsTqeUNkWcZoNGpnxNLp9E0X0+udcFilXC6vWaCeqqooiqIlLN7qHtdLhyRJWCwWWlpacLvdhEIhZmdnb3pN6nk9PB4PnZ2dGI1GUqkU0WiUhYWFG2qpdztVFAVVVbHb7UQikZtOZ+v9bn5Vx50sRdU7sbVSqdzRTKFeOmRZxmAwaD5is9kACIfDN7w/NTVTSZIwmUyUy2Vtyna7vO27vUiB0HFv6zCbzVr44q3Oeep1PQwGA+Vy+aYdnSh08tunY1XnTKtrUJ907bvlELJAcCNyuZxua3F3ggiCvPdYlZnmcjmRYyMQCASfYFXnIYSRCgQCwae5vyscCAQCQY0Q6aQCgUBQA8TIVCAQCGqAMFOBQCCoAcJMBQKBoAbUJJ20+ibFWrxps1KEDqHjXtdxN2m5n3TUZGQqDuzfmvs9vkQguB+oiZlKknTf58jcCrPZvNYSBILfwGKxrGl2271GTRzQYDBgsVhq8VH3HEajEbPZLDobwV1HY2Mj69atW2sZ9ww1ecKrVfgFn0aWZWw2m671M+9G7oaORFXVu6KNVisU3S3oHYB5L/OZxviyLGOxWHC73bqmTt5Ih9lsJpvNrumrrrIsax2LJEl4PB4ymYxuxbI/iclk0uJT1ioNU1EU/H4/drudxcVF4vG47hpkWaaxsZHGxkYKhQKTk5O6F0KuYjQa2bJlCwAXLlxYk3bxSS1+v59wOLxmGu5WJElalY+s2EyrwVsul4t169bR29tLuVzm6NGja1IAxWAw0NLSgsfjIRQKEQ6Hda/Io6oqra2tdHV10dTUhN1uJ5fLMTs7y8mTJ3XVoigK69ev54tf/CIdHR1cuHCBl19+mampKV11+P1+du7cSV9fH6VSidHRUY4dO6a7ke3du5cDBw4QiURIJBKsW7eO06dPMzs7q6sOr9fLk08+yXe+8x0A/vIv/5IjR47oqqGKwWBgy5YtHDx4UIt00TMV9G7DbrfT39+PLMuYTCYkSeLcuXMrbqsrNlOz2cyWLVt47rnn2L17Nw0NDQwNDWlFd/Usc2az2diyZQvr1q3D5XIBMDY2xoULF3SLN5Ykie7ubh5//HGampro6Ohg/fr1qKrKO++8w8jIiG7RJbIss3v3bv71v/7X7Nu3j1gsBsD777+vm5lKksTAwABf+tKX8Pv9DA0NsbCwgMFgwOFw6Gqm7e3t/NEf/REAv/jFL4hGo2zYsIE///M/59/8m3+j2xTXaDTy7LPP8tRTTzE9PY3P5+M73/kOiUSCwcFB3QcgLpeL/v5+vF4vdrudxx9/nLNnzxIKhe6qMoV6sXv3bv7gD/6Acrmsxcq88cYbvPLKKyvKolqVmb744os888wzFAoFAoEA2WyWjo4OrFZr3W9GNXrCYrHwzDPP0NfXx9jYGNFoFK/Xy9NPP8327dv56U9/ytjYWF21wPUHZf369ZTLZa5evUoymcRqtfLII4/w6KOPcujQIRYXF3XJPWpsbOTLX/4y7e3tfPTRR0xOThKJRLSYDD1CytxuN1/4whd48cUXOXnyJAsLCywuLlIoFPD5fCwsLOgyczAYDGzduhWr1cqPf/xjPvjgA5qbm9m1axf9/f34/X7dOpiGhga6u7s5ffo04XAYt9tNT08PX/jCF0in04yNjelqqAaDgWQySTgcpqWlhYGBAdrb2xkeHubixYt1H7Xb7XaamppwuVzYbDbcbjdNTU0sLS1x4cIFxsfHdcsJ8/l8vPDCC6xfv56TJ08yOztLa2srjz76KEePHl1RYuuKzdTn82EymRgfHyeVSnHp0iVyuRwWiwWn08nS0lJdG0a5XMZisWiZ1wDxeJxkMonRaKRUKqGqqi6bPpIk4ff7aWxsZG5ujlQqpaWStrS00N/fz8MPP8zo6Cizs7N17WgURWHz5s0Ui0Veeukl4vE45XIZq9WK2+3WbfPFbrfT09NDe3s7Z86coVwuUywWyefzGAwGLU6l3lQqFUKhEC+99BJHjhwhmUzywAMP8NWvflULbtOLSqVCOp0mGAySTCYpFAosLS3R3t7Oxo0bCYfDuq4nV3PbvF4vn//853nzzTeJRqM0NTVx9uzZun9/uVzG7XbT3NyMz+fj0Ucf5YEHHuCdd965YeZSvZAkiaamJhoaGrTU5ap/7dy5k/Xr16+o81+RmSqKgtPpJBqNoigK6XSaQqGAqqpaBni9qVZMv3TpEoODg3zzm99k27ZtnD59mmg0SrlcJhqN6jKFq1QqpFIpwuGwZhILCwtUKhVGRka0aIpqxEs9UVWVbDbLuXPnCAaDmM1mDAYDHR0dxGIx3TagqtHfExMTvxEhbDAYsNvtuiSllstlZmZmsNvt9PX1USwWaW9vJxKJcOjQIV03fxKJhDbaq1QqqKpKLpfj2rVrDA4O3jDYr560tbXR2NjIlStXeOONN5AkiUKhwPj4uLY0VE+y2SwLCwsEAgFMJhOVSoWZmRmGh4dZXFzUdbNUkiSmpqaYm5tjenqaxcVFwuEwkiSRTqfx+Xwkk8kbhkD+OnfsfgaDAZvNRi6XY2hoiGg0qo12FEVheXkZRVGQZVmXniUej/Pyyy+zdetWnnjiCdra2sjn8+TzeRYXF+/ox9eCZDJJKBRi3759VCoVotEopVKJq1evcvHiRQ4fPszo6Gjdpy3ZbJahoSH8fj8Wi4VkMonFYkFVVYLBoG69/dLSEu+88w52ux1VVfH7/eRyObLZLJlMBlVVb5sXViuqJ0waGhqIxWJcuHCBa9euMTk5qauZplIpLl++TGdnJwaDQQt+HBoaYmpqSlfzUFWVtrY2WltbmZ6e5uTJkzQ2NpLL5bhy5You16VSqTA7O4ssyySTSYLBICaTiatXrzI/P6/bkkelUiGTyRAIBEin08iyTKFQYHZ2llOnTjE7O7siLXdspqVSSVvfiUQidHZ20t3djaqqRCIRrl69Sjgc1vVc5eTkJP/9v/93VFVl69atABw6dIgTJ07osj4I10dA165dY8eOHaxfv55gMMj8/DyvvfaadrpAr8YRiUQIBoPs3buXVCqF1WrF4/HoMtqoUigUOHnyJOFwmA0bNuB0OjGbzSwtLTE6Oko0GtXteiwvLzM/P09fXx+Li4vMzs7i9/uJxWK6rlFWKhXGxsbw+/34/X6KxSLT09MMDw/r8pxIkoTNZsNkMmGz2RgeHv7U7CAYDHL06FEWFhbqrqVKqVRiamqKUCikJZRWl4P0ZHZ2lh//+MesX7+eRCJBLBZjamqKpaWlFX/WqtNJrVYrjY2N5PN5YrEYmUyGSqWiRcguLy9/Kn2xnjGtPT09PPbYYxgMBt5++21GR0frkvp4Mx2KorBu3Tq6urqYmZlhdHT0tsfE6nU9zGYzmzdvpr29HbfbTSaT4e23377pOeB6Rj1X43MBbe30ZtRLx/bt23G5XMzMzNDR0UFTUxMLCwtMTk4yMTHxG5rqWUyjvb2dQCBANBplfn7+lmvotSp04nA4cLlc5HI5bb22+v+3trbidDoJh8O6PzOroV46qmv55XKZUql02w6uplHPVYxG4w1z2auH1iuVSt3NtIrH48FoNN52zaVeOlRVRVXVO16r1aOBGo1GTCYThULhpg/uvf6gVDPQ0+m0tq5fLBYpl8uk0+nfaCv1zoiHO0smrZWZ3uo7qyayvLwsKr7VQMdnMtNaCLgTfht0VB/StdaxUoSOe0/H3aTlftKx9i9NCwQCwT2AMNMaodeGl0AguDsRZioQCAQ1QEQ9CwQCQQ0QI1OBQCCoAcJMBQKBoAbUJJ30TrjbjzUIHULHvaLjbtJyP+kQI1OBQCCoAcJMBQKBoAYIMxUIBIIaIMxUINCRalTI3ZCUKqgtn8lMq2mca4EkSbhcLlRVXZPvv1upPqSSJIkI7puwVtdEVVVaWlrYs2cPXq9X3Bvuvujrz8KqS+N7vV56enpwu90Eg0GmpqZ0rxju8/l44IEHiMfjZDIZpqam1ixyWpZlHA4HxWJRK0eoB9XKP5VKBY/Hg8vl0qJbDAYD6XSaWCxGPp/XNT3W5XLh8Xi0guHFYpHl5WUtYkYv7HY7LpcLs9mMxWLB6/USi8W4ePGirkWZDQYDra2tuN1uAoEAzc3NlEolLeZGT2RZxuVyaRX2M5mM7om+cD0vbPPmzbS0tGhlCa9du/ZbG+q3KjO12Wxs27aNhx56iIceegi3282rr77KD3/4QyYnJ3V5YCuVCl6vl29961vYbDYaGxsJBoP8j//xP3jnnXd0zyT3eDz8wR/8AT09Pbz33nu89957umSSl8tlZFmmubmZzZs343K5iMfj5PN5lpeXkWUZRVEIBoNcuXJFl6Ayi8XC888/T3t7O6FQiOXlZcxmM5Ikcfz4cS5evFh3DXA9YPBP//RP2bx5MzMzMwAMDAxw+fJlvvvd7+oab+zxeGhoaMDj8dDT00M8HieVSmGxWEin07pq8fv99PX10dDQgNvtJhqNcuTIEV1zsRobG3nyySd55JFHtHSISqXC//yf/5NXX31V1w7GYDDQ29vLpk2bcDgcTE1NMTg4uOJC5iueoxsMBrq7u2lqaiIejxMKhXC73XzjG99g69atuk37ZVnWilOPjo4yODjIwMAA//7f/3sOHDig+/JDX18fTzzxBA888ADf+MY3+NrXvkZDQ0Pdv7dSqZDNZolEIlQqFS0jS5IkTCYTRqORQCBAIBDQ5ZpUo54DgQDFYhGbzYbdbkdRFCwWi67tY8OGDezbtw+bzYYkSeTzeUKhEM3NzezYsUOXzLIqdrud9vZ2bTbX0tKC1+vFZrPpOipUFAW3243VasVqtbJjxw7+7b/9t3z5y1/GZDLposHj8bB37166u7sJh8Ncu3aN6elpnE4njzzyCG63Wxcd8I/t5MUXX+Rf/at/xV/8xV/wve99j6985Ssrbh8rbtlOp5O+vj6ampqQZZlgMMilS5fI5/N4PB7d1oEkScJoNDI3N8fc3BxXrlzh0KFDpNNpfvd3fxefz6eLjioej4epqSneeustrl27xqZNm3j88cd1W9NNJpOMj49rvakkSZjNZtxuNw6HA0mSdJnWKopCe3s70WiUhYUFLQeq2l5SqVTdNXxSx+nTpzl//jzLy8vk83mCwSDlcpkNGzbovt7e0dHBM888Q3d3t5ZqazabdR2FKYqC0WgkHo8zPz/P9PQ0hUKBPXv20NjYqIsGo9GI2WwmGAwyPj5OOBwmm81SLBZZv349AwMDuq2jejwetm/fTm9vL8VikUgkooVkrvR5WXHXXP2R1UiKWCympRrqOVWB62XvGhoaUBSFfD6vZes4nU66u7tZXFzUTUsymcRgMJDP57XY6eofPZYcyuUy4XCYQCCgrRO2trbS0tJCOp3mwoULuo2AyuUyBoMBs9lMa2srHR0deDweTp06pVsbKZVKTE9P09vbi6IoWK1WZFnG7XZrJlbvjr+6XlwNsdu5cyfbtm2jVCphMplIpVKMj4/raqb5fJ5KpYLZbKZQKHD16lV+9rOf3TZGpZbkcjlSqRSFQgG73U53dzcDAwN0dXWxtLSEz+fTJZhTkiQURSGVShEMBkkkEuTzea5du8aHH3644u9fsZnG43GuXr2Ky+XCYrGQzWZJJBIYjUYmJyd1W9QvlUoMDg7y0EMPsX37dm0TyuFwaDlUenL58mUuXrxIf38/mUyGyclJhoaGdF1Ml2WZpqYmenp66OnpYcOGDTgcDl599VXdInSLxSKzs7Ps3r0bn89HX18f27ZtI5VK8eqrr+pqpidOnKC1tZW9e/dit9vp7+/Hbrdz9uxZjh49WvPwNoPBgMViwWazaZ17Pp+nUCgwOTnJD3/4Q86cOcPnPvc5ZFkmEokwPT2t6zS/UqlQKpXw+XzaaPDChQta4rAepNNp0um0NmtyuVw0NTVhNps5fPgw165d06WDqVQqhEIhTp48iaqqdHV1sbi4yDvvvEMoFFrx563YTAuFAleuXCGTyTAwMEBDQwOSJDExMcHo6KiuO6QTExP8r//1v/jjP/5jNm/ejNfrZWJigp/97GcMDg7qpgOuxwr/+Mc/5sCBAySTScbGxnR/UEqlEplMBlmW8fl8BAIBZmZmOHr0KHNzc7ptDF69epW5uTl6e3tJp9McP36cS5cu8f777+u6MZjNZvnwww/xer24XC5mZ2c5fPgwP/nJT+piHDabDYfDQSqVIh6Pf+rfTU9PMzMzw5EjR3jrrbfo7e3lwoULpNPpmuu4HdVBj9frZXl5mdnZWcLhsG5ttVQqMTMzQ09PD42NjaiqysjICN///vf5v//3/+oa9wwQCoV45513tIj01Z42WXUGVHXNsqGhAYvFQiwWu2VUbD1TMK1WK01NTSiKQigUIpFI3NTU610sobpoXSqVdA8pqx7P6u7upru7m0AgwPj4OKdOnSIej99QT72uR39/Pw6Hg2w2y/LyMgsLC7eMAK/nfbFarQQCATKZDLFY7JaG/ll0WCyWislk+g0j/XUkScLpdFIul2/64Na70En1HDLcPuCvHvfG6XTS1dWF0WikXC6TSqWYmZm5ZSDl3V7oRATq3YM6qsscRqORXC53y+lsPdNa7yQ2t946Vspn0WE2myvlcvmORt/VLPt0Ol3zTu4fPv+uuCa36vglSVrRaPhubyPCTIUOoeMe03E3abmfdIh38wUCgaAGCDMVCASCGiDMVCAQCGqASCcVCASCGiBGpgKBQFADhJkKBAJBDRDppEKH0HGP6bibtNxPOsTIVCAQCGqAMFOBQCCoAcJMBQKBoAYIMxUIBIIasKrcBkVRKJfLWoGGtTqrWq0YpSgKiqIQi8XWJBjsRkiStGbXpZoaq3dQ292IwWDAaDRqRTWWl5fX7L5U9ciyrBWHXiuqz8xva3hdragWUs/n8yQSCQqFwqrbx4rNVJIk7HY7TqcTQKssv7y8rPvDa7Va8fv9OBwO7HY74XCYYDC4JjUiP4nFYqG5uZlkMqlrtX8Ak8nEnj17aGlp4cSJE8zMzKxJByPLMmazmXK5rFV31xur1cqDDz7IwYMHkWWZ6elpTp06xeDgINlsVlctqqrS3t7OunXrcDgcxGIxPvroozUxs/7+fg4cOEAgEODdd9/lwoULa2qqkiTh8XgAWFpa0q2tyLJMa2srXV1dmM1mlpeXmZyc5OrVq6uqu7viqlGqqhIIBGhvb9eiIKrV1aenp29a7q3WxxqqiZzVeGO/348kSczPz3PlyhVisVjNddhstkqlUqFSqWgpn5IkaXHLdrsdr9fLvn37eO655/i7v/s73njjjRs21Hoc8zAajbz44os8/vjjWgLC4cOHefvtt29qqPU6btLV1cXTTz+N0+lkenqa48ePMzExcdPPqrUOVVV59tlnefDBB3E6nSwuLlIsFvF6vZw5c4Zf/vKXN0zjrFftzoMHDzIwMIDD4cBmsxGNRnnttde4cOHCDcsU1utoVGNjI3/1V39FU1MTs7OzTE1NceXKFU6fPs3MzIyuNW/b29vZvXs3PT09tLa2Ui6XOX36NG+//bYu98Zms7F3714CgQDZbJZKpYLD4SAcDvPhhx+u2MtWPDKt5tqUSiWMRiPt7e3s2bOHcDjM//k//4dr167pVm3fYrHgdDpxOp1YrVbMZjMej4disciVK1dqPo369YtrMBhwuVxahfVq/MLAwIBWFNlkMunW62/fvp0/+ZM/YW5ujvHxcWw2G//kn/wTZmZmdItXrrJhwwaeeuopUqkUPT09bNq0iZ/85CdcunRJl5GH3W6npaWFK1eukM1mMZvNmM1mXC4XBw8eZHBwULdo45aWFp5//nnMZjPJZBKHw0FzczOjo6NcunRJt+fFZrPx7W9/m4aGBsbHx5mYmCAWi9HQ0MDTTz/NO++8o1tUe2dnJy+88ALbt2+nv7+fzs5OJEkiFovxzjvv1P37VVWlu7sbr9eLwWCgWCySy+XweDw88cQTZDIZTpw4saLZ9oo3oMrlMsVikWw2q0UKd3d388wzz7Bp0yZt+l9vKpUKxWIRl8tFS0sLjY2N+Hw+fD4fdrsdi8VS88C0Uqmk/SmXy5RKJYrFojYlqFYNHxoa4ic/+QnDw8O6TbFVVeXBBx+ku7tbCzdMJpP4/X6ee+45jEajLjo+qadQKGipoF1dXfze7/2ebjG+1eTcxcVF8vk8iqJgs9moVCr4fD76+/t1ScCUJImGhgba2tpobW3F5/PR29vLY489RktLi25pvgCbNm3ihRdeoFAoEIvFSKfT5HI5SqUSvb29DAwM6JKd1tDQwMGDB+no6MBoNBIKhTh27BivvPIKs7OzuiwXGo1Gmpqa8Hg8BAIB/H4/LpcLt9vNxo0beeKJJ1bcVlc8Ml1eXiabzZJOp7FYLITDYU6cOIGiKGQyGcxmM7Is1723rVQqJBIJXC4Xu3btorW1lXw+z9WrVykWixgMBq3HqRflcplsNoskSaRSKRRF0QLj0uk0yWRS1/XKTCZDsVjEZDJpozCHw8GOHTvw+/3Mzc3ppmVqaop0Oo3T6cThcGjTOL0ifCuVCna7XYs2bmtro6+vj/7+flRV1c3EZFnG4/GQSqWIRqNEo1HC4TDvvvsu7733nm77DA6HA4fDQaVSYf369YyMjGgbuK2traiqyvT0tLZ8VS+MRiN79+5l165d2O12FhcXsVgsDAwMEIvFyGQyt4wuqRXFYpFYLIbdbmfDhg2kUilCoRCBQEAL+lupjhWbaaVS+VRujcFgYHl5mXQ6zfz8vK7mEY/HCYVCtLS08OCDD3L+/Hk+/PBDksmkbg9LtfGpqqqdciiXy+RyOS06Vg8KhQJvvPEGzz77LOvWrSORSNDT00NXVxeZTAaLxaKLjipjY2OcPn2a3//936ejo4OFhQVee+01lpaWdPl+m81Gd3c3nZ2dmM1mWlpaaG1tpbm5mStXrhAMBnVpq5VKhdnZWc6fP4/NZiMQCBCJRBgcHNQ1zTeZTHLs2DH+4i/+gi9/+cs4HA7a2towmUzYbDbefPNNxsbG6q6jWCwSjUYpFou43W6mpqaYnJwkl8tpz44e5PN5BgcHyWQy2O129uzZw/79+3G73UQiEY4dO7bijuUzBeqpqorNZsNkMmkGksvlbiiiXovYjY2NPP/88/T29jI4OMjg4CDhcJhMJkMymfyN9Z966bDZbDidTkwmE4VCgXQ6TSqVuunIo146du/eze/8zu/g8XgwGo2kUik++OADjh49Sjgc1k0HgM/n44UXXmDnzp3aNO5mvX0tdRgMBtra2mhvb9eyhvx+Pw0NDRgMBpaWlvjggw+YmZmpq44qFouFjRs30tXVRX9/PyaTiTfeeIMTJ07c9LPq+W6+1+ulubmZtrY2uru7mZyc5IMPPtDl3sD10XpHRwcbNmzQ9hai0SiFQoFsNkswGNR1I8zv9/PQQw/xz//5P6enp4df/OIX/Mf/+B9vGhBatwwoWZYxGAy3DU+r14VQFAW3261N6QuFwk0NvZ46ZFnGZrNhs9mA61PudDqt+y56tZNTVVXLSC8Wi586F6yHjirV84yFQuGWI8F6PLCA1iaraZzVGcvN0mPr2T4MBgNOpxOPx3PbI3x6FDqpHl8rlUprErr4ySWfO5kl1LOtqqrKQw89xKOPPqp1dDfzRhGop4OOauM0m80Ui0VtDVNvHStB6Lj3dNxNWn6bdHg8Hvbt28fJkyeJRqMr1rGqN6AEN6ZcLmsGWh2tCwSC3w5SqRTz8/Or3oQTZloH6r0jKhAIak+hUCCVSq3q7ScQhU4EAoEAuH5sq3rudjUIMxUIBAKuzygTicSqz/6KdFKBQCCoAWJkKhAIBDVAmKlAIBDUAGGmAoFAUAOEmQoEAkENEGYqEAgENUCYqUAgENSA/x8Tz7hF7X6kLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.15, 0.15), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    # augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "    augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "                             stds=[0.229, 0.224, 0.225]),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=clmp'\n",
    "model.forward = model.forward_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.5587, loss_val: nan, pos_over_neg: 1.0463637113571167 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.0802, loss_val: nan, pos_over_neg: 3.766254186630249 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 6.8559, loss_val: nan, pos_over_neg: 3.8215863704681396 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.6793, loss_val: nan, pos_over_neg: 18.27652931213379 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.5719, loss_val: nan, pos_over_neg: 19.421201705932617 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.5198, loss_val: nan, pos_over_neg: 28.400211334228516 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.4645, loss_val: nan, pos_over_neg: 50.231056213378906 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.4335, loss_val: nan, pos_over_neg: 53.602088928222656 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.3797, loss_val: nan, pos_over_neg: 51.45674133300781 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.3531, loss_val: nan, pos_over_neg: 60.74815368652344 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.3504, loss_val: nan, pos_over_neg: 88.90898132324219 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.3222, loss_val: nan, pos_over_neg: 141.582763671875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.3064, loss_val: nan, pos_over_neg: 184.57456970214844 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.2865, loss_val: nan, pos_over_neg: 128.48211669921875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.2843, loss_val: nan, pos_over_neg: 148.0657958984375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.2782, loss_val: nan, pos_over_neg: 137.0606689453125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.2577, loss_val: nan, pos_over_neg: 167.84774780273438 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.243, loss_val: nan, pos_over_neg: 263.75634765625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.2362, loss_val: nan, pos_over_neg: 301.8110046386719 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.2352, loss_val: nan, pos_over_neg: 280.9101867675781 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.2299, loss_val: nan, pos_over_neg: 228.8472900390625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.2184, loss_val: nan, pos_over_neg: 232.0416259765625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.2033, loss_val: nan, pos_over_neg: 379.7417297363281 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 6.2043, loss_val: nan, pos_over_neg: 601.3388671875 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 6.1713, loss_val: nan, pos_over_neg: 718.37451171875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 6.1771, loss_val: nan, pos_over_neg: 567.7335815429688 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 6.1668, loss_val: nan, pos_over_neg: 240.3358154296875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 6.1658, loss_val: nan, pos_over_neg: 470.6559753417969 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 6.1599, loss_val: nan, pos_over_neg: 414.66558837890625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 6.1441, loss_val: nan, pos_over_neg: 590.4993286132812 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 6.1496, loss_val: nan, pos_over_neg: 830.8899536132812 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 6.1387, loss_val: nan, pos_over_neg: 703.2197875976562 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 6.1271, loss_val: nan, pos_over_neg: 2162.826416015625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 6.1213, loss_val: nan, pos_over_neg: 316.80987548828125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 6.1246, loss_val: nan, pos_over_neg: 468.9641418457031 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 6.1173, loss_val: nan, pos_over_neg: 450.40484619140625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 6.1252, loss_val: nan, pos_over_neg: 685.3872680664062 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 6.1123, loss_val: nan, pos_over_neg: 1902.573486328125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 6.1187, loss_val: nan, pos_over_neg: 507.97723388671875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 6.0922, loss_val: nan, pos_over_neg: 599.371826171875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 6.0907, loss_val: nan, pos_over_neg: 458.7165832519531 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 6.0915, loss_val: nan, pos_over_neg: 917.9236450195312 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 6.0764, loss_val: nan, pos_over_neg: 672.4711303710938 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 6.0793, loss_val: nan, pos_over_neg: 511.6710510253906 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 6.0734, loss_val: nan, pos_over_neg: 513.6574096679688 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 6.056, loss_val: nan, pos_over_neg: 319.19903564453125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 6.0516, loss_val: nan, pos_over_neg: 798.717529296875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 6.0505, loss_val: nan, pos_over_neg: 1529.83447265625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 6.0395, loss_val: nan, pos_over_neg: 654.0528564453125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 6.0372, loss_val: nan, pos_over_neg: 577.9224243164062 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 6.0421, loss_val: nan, pos_over_neg: 573.9695434570312 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 6.0436, loss_val: nan, pos_over_neg: 196.1876678466797 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 6.0382, loss_val: nan, pos_over_neg: 783.4732666015625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 6.0345, loss_val: nan, pos_over_neg: 132.97593688964844 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 6.0284, loss_val: nan, pos_over_neg: 388.3067321777344 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 6.0365, loss_val: nan, pos_over_neg: 155.18527221679688 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 6.0259, loss_val: nan, pos_over_neg: 442.8148498535156 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 6.0304, loss_val: nan, pos_over_neg: 146.77459716796875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 6.0308, loss_val: nan, pos_over_neg: 272.4349670410156 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 6.0216, loss_val: nan, pos_over_neg: 170.69888305664062 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 6.0134, loss_val: nan, pos_over_neg: 158.09056091308594 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 6.0248, loss_val: nan, pos_over_neg: 201.91346740722656 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 6.0267, loss_val: nan, pos_over_neg: 230.28097534179688 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.9978, loss_val: nan, pos_over_neg: 557.8272705078125 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 6.0223, loss_val: nan, pos_over_neg: 109.51348876953125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 6.0044, loss_val: nan, pos_over_neg: 284.98974609375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.9994, loss_val: nan, pos_over_neg: 244.60745239257812 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 6.011, loss_val: nan, pos_over_neg: 207.0958709716797 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9955, loss_val: nan, pos_over_neg: 474.7755126953125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.9992, loss_val: nan, pos_over_neg: 215.7072296142578 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 6.0019, loss_val: nan, pos_over_neg: 384.2242126464844 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 6.0065, loss_val: nan, pos_over_neg: 159.2694854736328 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 6.0076, loss_val: nan, pos_over_neg: 251.764404296875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.9919, loss_val: nan, pos_over_neg: 219.37060546875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.9988, loss_val: nan, pos_over_neg: 330.0223083496094 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.984, loss_val: nan, pos_over_neg: 328.7473449707031 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.9871, loss_val: nan, pos_over_neg: 204.400146484375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.9796, loss_val: nan, pos_over_neg: 185.1700897216797 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.9942, loss_val: nan, pos_over_neg: 336.32489013671875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 6.0015, loss_val: nan, pos_over_neg: 198.37008666992188 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.985, loss_val: nan, pos_over_neg: 414.7425537109375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.9817, loss_val: nan, pos_over_neg: 205.12574768066406 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.973, loss_val: nan, pos_over_neg: 309.9580078125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9667, loss_val: nan, pos_over_neg: 532.4124755859375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.9671, loss_val: nan, pos_over_neg: 411.0006103515625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.9741, loss_val: nan, pos_over_neg: 268.92431640625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.9792, loss_val: nan, pos_over_neg: 185.21609497070312 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.9668, loss_val: nan, pos_over_neg: 288.6422424316406 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.9633, loss_val: nan, pos_over_neg: 573.853271484375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.9603, loss_val: nan, pos_over_neg: 2062.26806640625 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.9658, loss_val: nan, pos_over_neg: 367.1512451171875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9516, loss_val: nan, pos_over_neg: 927.89208984375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.9595, loss_val: nan, pos_over_neg: 403.6012268066406 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.9702, loss_val: nan, pos_over_neg: 416.2385559082031 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.9635, loss_val: nan, pos_over_neg: 381.346435546875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.9541, loss_val: nan, pos_over_neg: 897.2767944335938 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.9608, loss_val: nan, pos_over_neg: 258.8701171875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.9418, loss_val: nan, pos_over_neg: 1136.50927734375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9609, loss_val: nan, pos_over_neg: 593.9765014648438 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.9528, loss_val: nan, pos_over_neg: 427.6163024902344 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9448, loss_val: nan, pos_over_neg: 628.40283203125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.9484, loss_val: nan, pos_over_neg: 592.9531860351562 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.9373, loss_val: nan, pos_over_neg: 580.338134765625 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.9401, loss_val: nan, pos_over_neg: 707.0685424804688 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.9521, loss_val: nan, pos_over_neg: 309.79248046875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.943, loss_val: nan, pos_over_neg: 520.0994262695312 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.9319, loss_val: nan, pos_over_neg: 1321.1307373046875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.9432, loss_val: nan, pos_over_neg: 359.4255065917969 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.9358, loss_val: nan, pos_over_neg: 771.293212890625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9373, loss_val: nan, pos_over_neg: 536.6649169921875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.9403, loss_val: nan, pos_over_neg: 554.0269775390625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.9417, loss_val: nan, pos_over_neg: 364.5650939941406 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.9373, loss_val: nan, pos_over_neg: 374.2427062988281 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.9393, loss_val: nan, pos_over_neg: 534.358154296875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.9222, loss_val: nan, pos_over_neg: 910.2036743164062 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.9299, loss_val: nan, pos_over_neg: 243.93710327148438 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.9312, loss_val: nan, pos_over_neg: 337.9479064941406 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.9377, loss_val: nan, pos_over_neg: 200.83497619628906 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.9301, loss_val: nan, pos_over_neg: 408.031982421875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.9247, loss_val: nan, pos_over_neg: 252.2806396484375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.919, loss_val: nan, pos_over_neg: 607.8696899414062 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.9248, loss_val: nan, pos_over_neg: 220.00033569335938 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.9244, loss_val: nan, pos_over_neg: 255.3684539794922 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.9252, loss_val: nan, pos_over_neg: 429.1139831542969 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.9178, loss_val: nan, pos_over_neg: 224.468017578125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.906, loss_val: nan, pos_over_neg: 529.5594482421875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.9295, loss_val: nan, pos_over_neg: 224.78851318359375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.9242, loss_val: nan, pos_over_neg: 301.001220703125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.9253, loss_val: nan, pos_over_neg: 520.7054443359375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.9231, loss_val: nan, pos_over_neg: 355.5070495605469 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.9187, loss_val: nan, pos_over_neg: 891.8355102539062 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.9172, loss_val: nan, pos_over_neg: 385.8611145019531 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.9115, loss_val: nan, pos_over_neg: 210.62547302246094 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.9144, loss_val: nan, pos_over_neg: 393.4499206542969 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.918, loss_val: nan, pos_over_neg: 387.8304138183594 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.9207, loss_val: nan, pos_over_neg: 900.2819213867188 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.905, loss_val: nan, pos_over_neg: 720.6959228515625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.9169, loss_val: nan, pos_over_neg: 299.4462890625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.9141, loss_val: nan, pos_over_neg: 439.13812255859375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.9182, loss_val: nan, pos_over_neg: 188.36679077148438 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.9197, loss_val: nan, pos_over_neg: 267.7032165527344 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.9202, loss_val: nan, pos_over_neg: 251.90908813476562 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 230.99342346191406 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.907, loss_val: nan, pos_over_neg: 318.05364990234375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.9139, loss_val: nan, pos_over_neg: 229.5149383544922 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.9122, loss_val: nan, pos_over_neg: 285.38763427734375 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.9049, loss_val: nan, pos_over_neg: 374.97613525390625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.9147, loss_val: nan, pos_over_neg: 188.9615936279297 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.906, loss_val: nan, pos_over_neg: 1106.4700927734375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.9022, loss_val: nan, pos_over_neg: 286.3263854980469 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.9081, loss_val: nan, pos_over_neg: 616.089599609375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.9029, loss_val: nan, pos_over_neg: 447.30133056640625 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.9037, loss_val: nan, pos_over_neg: 541.9341430664062 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.9013, loss_val: nan, pos_over_neg: 529.971923828125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.9106, loss_val: nan, pos_over_neg: 493.1505432128906 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.9019, loss_val: nan, pos_over_neg: 321.2541198730469 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.897, loss_val: nan, pos_over_neg: 460.03424072265625 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 266.0008239746094 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.9086, loss_val: nan, pos_over_neg: 510.66119384765625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.9102, loss_val: nan, pos_over_neg: 258.0645446777344 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.9032, loss_val: nan, pos_over_neg: 594.8255004882812 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8982, loss_val: nan, pos_over_neg: 695.0076293945312 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.9066, loss_val: nan, pos_over_neg: 365.0043640136719 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8923, loss_val: nan, pos_over_neg: 1427.3646240234375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.9047, loss_val: nan, pos_over_neg: 423.2065124511719 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.9126, loss_val: nan, pos_over_neg: 219.2989501953125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.9047, loss_val: nan, pos_over_neg: 981.21044921875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.9015, loss_val: nan, pos_over_neg: 380.7654724121094 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8919, loss_val: nan, pos_over_neg: 568.5880737304688 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.9055, loss_val: nan, pos_over_neg: 319.4693908691406 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.9059, loss_val: nan, pos_over_neg: 299.0747985839844 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.9041, loss_val: nan, pos_over_neg: 274.6278381347656 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8983, loss_val: nan, pos_over_neg: 275.566162109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 293.4501037597656 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.9009, loss_val: nan, pos_over_neg: 296.9486389160156 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8954, loss_val: nan, pos_over_neg: 1419.8712158203125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8941, loss_val: nan, pos_over_neg: 302.3809814453125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 320.62255859375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8898, loss_val: nan, pos_over_neg: 493.8181457519531 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8913, loss_val: nan, pos_over_neg: 227.92269897460938 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 507.92559814453125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8887, loss_val: nan, pos_over_neg: 325.7248229980469 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8906, loss_val: nan, pos_over_neg: 357.38287353515625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 681.069091796875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 371.794921875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8914, loss_val: nan, pos_over_neg: 960.6661376953125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8931, loss_val: nan, pos_over_neg: 330.8414306640625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 666.32763671875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8997, loss_val: nan, pos_over_neg: 475.0352478027344 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8908, loss_val: nan, pos_over_neg: 351.2890930175781 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 315.6412658691406 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8783, loss_val: nan, pos_over_neg: 793.1367797851562 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8855, loss_val: nan, pos_over_neg: 418.2935791015625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 434.1011657714844 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8815, loss_val: nan, pos_over_neg: 516.7066040039062 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 564.9000854492188 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8907, loss_val: nan, pos_over_neg: 302.2835693359375 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8799, loss_val: nan, pos_over_neg: 422.9893493652344 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8759, loss_val: nan, pos_over_neg: 351.2707824707031 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 202.97132873535156 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8838, loss_val: nan, pos_over_neg: 627.498046875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8855, loss_val: nan, pos_over_neg: 352.3435363769531 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8867, loss_val: nan, pos_over_neg: 407.2021179199219 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 426.79010009765625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8928, loss_val: nan, pos_over_neg: 180.3863525390625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 941.682861328125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8799, loss_val: nan, pos_over_neg: 345.8048095703125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8797, loss_val: nan, pos_over_neg: 545.1105346679688 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8791, loss_val: nan, pos_over_neg: 351.453857421875 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8781, loss_val: nan, pos_over_neg: 456.2667236328125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8848, loss_val: nan, pos_over_neg: 394.2069396972656 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8758, loss_val: nan, pos_over_neg: 497.9176025390625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8738, loss_val: nan, pos_over_neg: 315.7369079589844 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.873, loss_val: nan, pos_over_neg: 488.23968505859375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8749, loss_val: nan, pos_over_neg: 342.97027587890625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8767, loss_val: nan, pos_over_neg: 345.46905517578125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8844, loss_val: nan, pos_over_neg: 285.0691833496094 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8863, loss_val: nan, pos_over_neg: 363.2892150878906 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8748, loss_val: nan, pos_over_neg: 274.9122314453125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8816, loss_val: nan, pos_over_neg: 458.87890625 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8731, loss_val: nan, pos_over_neg: 420.79931640625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 453.5384826660156 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.8688, loss_val: nan, pos_over_neg: 330.1257019042969 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8772, loss_val: nan, pos_over_neg: 427.61505126953125 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.878, loss_val: nan, pos_over_neg: 415.0859680175781 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8821, loss_val: nan, pos_over_neg: 475.59393310546875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 624.3652954101562 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 429.2597961425781 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8755, loss_val: nan, pos_over_neg: 329.6488342285156 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8869, loss_val: nan, pos_over_neg: 238.2509307861328 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8739, loss_val: nan, pos_over_neg: 548.131591796875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 231.61514282226562 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8811, loss_val: nan, pos_over_neg: 295.8414306640625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8773, loss_val: nan, pos_over_neg: 279.816162109375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8825, loss_val: nan, pos_over_neg: 278.2301940917969 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8802, loss_val: nan, pos_over_neg: 289.8297119140625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8823, loss_val: nan, pos_over_neg: 396.01080322265625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8678, loss_val: nan, pos_over_neg: 495.1772155761719 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 204.40882873535156 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 490.0487060546875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 485.6562194824219 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8757, loss_val: nan, pos_over_neg: 314.8815002441406 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 450.3526916503906 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8706, loss_val: nan, pos_over_neg: 340.7039489746094 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8812, loss_val: nan, pos_over_neg: 192.91583251953125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8729, loss_val: nan, pos_over_neg: 296.31610107421875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8697, loss_val: nan, pos_over_neg: 367.8131408691406 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8646, loss_val: nan, pos_over_neg: 297.58990478515625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8753, loss_val: nan, pos_over_neg: 280.2462463378906 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8744, loss_val: nan, pos_over_neg: 285.903564453125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.871, loss_val: nan, pos_over_neg: 233.55728149414062 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 360.46087646484375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8691, loss_val: nan, pos_over_neg: 318.4286804199219 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8707, loss_val: nan, pos_over_neg: 257.1835021972656 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8708, loss_val: nan, pos_over_neg: 427.1397705078125 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 463.3018798828125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8611, loss_val: nan, pos_over_neg: 497.46649169921875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.874, loss_val: nan, pos_over_neg: 263.7445068359375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 323.6800842285156 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8682, loss_val: nan, pos_over_neg: 337.4404296875 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 319.6629333496094 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 335.96661376953125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8877, loss_val: nan, pos_over_neg: 231.92994689941406 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 270.4831848144531 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 352.75732421875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8728, loss_val: nan, pos_over_neg: 295.5950012207031 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8776, loss_val: nan, pos_over_neg: 170.36351013183594 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.8666, loss_val: nan, pos_over_neg: 535.2041015625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8644, loss_val: nan, pos_over_neg: 288.4883117675781 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 182.3743896484375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 642.6149291992188 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.868, loss_val: nan, pos_over_neg: 185.99501037597656 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 175.13070678710938 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8609, loss_val: nan, pos_over_neg: 428.4310302734375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8655, loss_val: nan, pos_over_neg: 319.0596923828125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 213.3763885498047 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8689, loss_val: nan, pos_over_neg: 260.0855407714844 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 245.4774627685547 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 265.6065979003906 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8645, loss_val: nan, pos_over_neg: 784.564453125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 324.1209411621094 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8553, loss_val: nan, pos_over_neg: 400.55889892578125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8634, loss_val: nan, pos_over_neg: 1762.755126953125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.862, loss_val: nan, pos_over_neg: 297.5491943359375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8627, loss_val: nan, pos_over_neg: 409.0596923828125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 686.1463623046875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 503.3856201171875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 311.5482482910156 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 527.108154296875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 330.3941345214844 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 410.7255554199219 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8615, loss_val: nan, pos_over_neg: 367.3937683105469 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.863, loss_val: nan, pos_over_neg: 570.0186157226562 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 503.461669921875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 355.94781494140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 354.681884765625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 595.1351318359375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.873, loss_val: nan, pos_over_neg: 199.05442810058594 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8637, loss_val: nan, pos_over_neg: 262.82855224609375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 725.8319091796875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 332.44091796875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8556, loss_val: nan, pos_over_neg: 379.22760009765625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 591.5203247070312 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 604.9830932617188 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8538, loss_val: nan, pos_over_neg: 1212.1837158203125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 362.3002014160156 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8568, loss_val: nan, pos_over_neg: 480.5890197753906 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.851, loss_val: nan, pos_over_neg: 414.1405334472656 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8649, loss_val: nan, pos_over_neg: 423.5791931152344 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8616, loss_val: nan, pos_over_neg: 454.2806091308594 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8495, loss_val: nan, pos_over_neg: 687.822998046875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8564, loss_val: nan, pos_over_neg: 400.9823913574219 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 460.0264892578125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 327.8464050292969 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8532, loss_val: nan, pos_over_neg: 400.49456787109375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 449.6253967285156 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 552.1898803710938 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 692.9371337890625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 1101.2042236328125 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 451.90814208984375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 399.3565368652344 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 440.57244873046875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 455.2120361328125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 586.0719604492188 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8509, loss_val: nan, pos_over_neg: 786.8392944335938 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8539, loss_val: nan, pos_over_neg: 408.2918701171875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 577.222412109375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8479, loss_val: nan, pos_over_neg: 484.48614501953125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 302.2103271484375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 432.61822509765625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 1146.10888671875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 377.51910400390625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8544, loss_val: nan, pos_over_neg: 560.0536499023438 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8383, loss_val: nan, pos_over_neg: 1393.7645263671875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 350.58868408203125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8589, loss_val: nan, pos_over_neg: 334.5410461425781 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 595.2517700195312 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 351.64117431640625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8456, loss_val: nan, pos_over_neg: 479.59332275390625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.847, loss_val: nan, pos_over_neg: 508.0940246582031 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 546.7769165039062 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8499, loss_val: nan, pos_over_neg: 685.9225463867188 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8439, loss_val: nan, pos_over_neg: 775.3059692382812 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8552, loss_val: nan, pos_over_neg: 369.6273498535156 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 1475.7508544921875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 452.9361267089844 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8475, loss_val: nan, pos_over_neg: 441.6918640136719 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 483.4727478027344 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8498, loss_val: nan, pos_over_neg: 375.044189453125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 578.0592651367188 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8471, loss_val: nan, pos_over_neg: 492.5455627441406 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8423, loss_val: nan, pos_over_neg: 386.68670654296875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8407, loss_val: nan, pos_over_neg: 779.8329467773438 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 860.7576293945312 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 995.6942749023438 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 519.6853637695312 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 917.5982666015625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8516, loss_val: nan, pos_over_neg: 354.70074462890625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 541.5726318359375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 572.2471923828125 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 1278.202392578125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8444, loss_val: nan, pos_over_neg: 354.9791564941406 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 749.1587524414062 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.842, loss_val: nan, pos_over_neg: 763.5342407226562 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 700.523681640625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 207.39999389648438 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 737.5433349609375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8529, loss_val: nan, pos_over_neg: 385.1487731933594 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8418, loss_val: nan, pos_over_neg: 468.4450988769531 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 545.5149536132812 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8483, loss_val: nan, pos_over_neg: 474.03466796875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8485, loss_val: nan, pos_over_neg: 258.57708740234375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 343.4541931152344 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8476, loss_val: nan, pos_over_neg: 433.6487121582031 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 409.09344482421875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8459, loss_val: nan, pos_over_neg: 376.6317443847656 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 412.5563659667969 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 462.0089416503906 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 245.95028686523438 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 668.6800537109375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 291.08905029296875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 411.1493835449219 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.836, loss_val: nan, pos_over_neg: 475.1204528808594 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 466.3460998535156 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 362.31878662109375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8372, loss_val: nan, pos_over_neg: 354.4947509765625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8435, loss_val: nan, pos_over_neg: 459.26580810546875 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 528.0426635742188 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 907.6571044921875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8288, loss_val: nan, pos_over_neg: 598.1431884765625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 581.715087890625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 612.9237060546875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8396, loss_val: nan, pos_over_neg: 478.8102111816406 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 589.9039306640625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 760.7168579101562 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 805.1981811523438 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8438, loss_val: nan, pos_over_neg: 669.6482543945312 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 557.2269897460938 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 466.0688781738281 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 1279.0684814453125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8477, loss_val: nan, pos_over_neg: 284.9652404785156 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 363.2684326171875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8378, loss_val: nan, pos_over_neg: 458.84619140625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 332.2691345214844 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 261.1371154785156 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 543.2796020507812 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8461, loss_val: nan, pos_over_neg: 560.46923828125 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8368, loss_val: nan, pos_over_neg: 410.9308166503906 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.8402, loss_val: nan, pos_over_neg: 439.9167175292969 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 429.1470642089844 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 726.2797241210938 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 554.9170532226562 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 527.9559936523438 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 590.66748046875 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 643.6299438476562 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 488.77703857421875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 270.50531005859375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.833, loss_val: nan, pos_over_neg: 519.5454711914062 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8473, loss_val: nan, pos_over_neg: 217.72714233398438 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 347.51275634765625 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 750.0604858398438 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 423.6301574707031 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 272.2481689453125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 965.3362426757812 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8433, loss_val: nan, pos_over_neg: 215.5577850341797 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8417, loss_val: nan, pos_over_neg: 271.2730407714844 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.837, loss_val: nan, pos_over_neg: 1289.0401611328125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 774.3412475585938 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 229.8717041015625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 479.3948974609375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8392, loss_val: nan, pos_over_neg: 414.2652587890625 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 824.3021850585938 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8387, loss_val: nan, pos_over_neg: 275.65771484375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8352, loss_val: nan, pos_over_neg: 464.0544128417969 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 685.6320190429688 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 364.7319641113281 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 412.0262145996094 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 606.3860473632812 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 741.123046875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 319.65484619140625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 378.00128173828125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8442, loss_val: nan, pos_over_neg: 356.5713195800781 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8331, loss_val: nan, pos_over_neg: 477.1324157714844 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 594.4136352539062 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8377, loss_val: nan, pos_over_neg: 335.91790771484375 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8273, loss_val: nan, pos_over_neg: 469.435302734375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8269, loss_val: nan, pos_over_neg: 526.4893188476562 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 386.5045166015625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 519.4515991210938 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8356, loss_val: nan, pos_over_neg: 260.17816162109375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 403.4833679199219 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 404.8020324707031 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 298.83050537109375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 218.27069091796875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 508.4967956542969 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8304, loss_val: nan, pos_over_neg: 442.03131103515625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.834, loss_val: nan, pos_over_neg: 318.2485656738281 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 641.5552368164062 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 403.9620056152344 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8234, loss_val: nan, pos_over_neg: 635.455078125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 306.8438720703125 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 463.8038635253906 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 582.7650756835938 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 412.0228576660156 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 791.0733032226562 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.831, loss_val: nan, pos_over_neg: 463.3399353027344 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 280.4111633300781 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 517.6639404296875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 441.952880859375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.84, loss_val: nan, pos_over_neg: 310.62396240234375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8364, loss_val: nan, pos_over_neg: 307.505126953125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 596.3780517578125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 315.4479675292969 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8323, loss_val: nan, pos_over_neg: 427.81170654296875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 721.0731811523438 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8211, loss_val: nan, pos_over_neg: 629.1632080078125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8345, loss_val: nan, pos_over_neg: 291.3645324707031 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8295, loss_val: nan, pos_over_neg: 397.23931884765625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8275, loss_val: nan, pos_over_neg: 581.0455322265625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 433.16998291015625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8234, loss_val: nan, pos_over_neg: 438.0317687988281 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8326, loss_val: nan, pos_over_neg: 502.1142883300781 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 788.3214111328125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 657.2462768554688 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.83, loss_val: nan, pos_over_neg: 588.4503173828125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8271, loss_val: nan, pos_over_neg: 670.8612060546875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 446.9910888671875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 830.8610229492188 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 1103.7906494140625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 1028.9052734375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 895.4664916992188 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 817.0609130859375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8264, loss_val: nan, pos_over_neg: 1012.0709838867188 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 752.0635986328125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 760.9461059570312 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 853.9740600585938 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 594.8385009765625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 686.7787475585938 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 445.7933654785156 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 1011.6453857421875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 2564.872802734375 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 689.3756713867188 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 677.391357421875 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8292, loss_val: nan, pos_over_neg: 1622.1322021484375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 763.5117797851562 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 326.59814453125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8221, loss_val: nan, pos_over_neg: 1557.121826171875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 1203.39794921875 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 527.8980102539062 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 486.19219970703125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8214, loss_val: nan, pos_over_neg: 566.1845703125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8262, loss_val: nan, pos_over_neg: 1307.1092529296875 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 400.8914489746094 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8188, loss_val: nan, pos_over_neg: 664.4779663085938 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 539.2205810546875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8222, loss_val: nan, pos_over_neg: 629.8131713867188 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.8248, loss_val: nan, pos_over_neg: 689.234619140625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 372.8727722167969 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.8306, loss_val: nan, pos_over_neg: 523.424560546875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8278, loss_val: nan, pos_over_neg: 379.9832763671875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8294, loss_val: nan, pos_over_neg: 610.31787109375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 389.7930908203125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8374, loss_val: nan, pos_over_neg: 423.3454284667969 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8359, loss_val: nan, pos_over_neg: 396.8931884765625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8277, loss_val: nan, pos_over_neg: 498.8281555175781 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 736.9615478515625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 864.4725341796875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 379.0234375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 662.6111450195312 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 408.01763916015625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 241.17196655273438 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 461.343505859375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 405.9095458984375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 567.2240600585938 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 374.5350646972656 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.8268, loss_val: nan, pos_over_neg: 724.7662353515625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 1000.7446899414062 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 428.331787109375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8266, loss_val: nan, pos_over_neg: 826.1251220703125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8256, loss_val: nan, pos_over_neg: 1435.029541015625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.82, loss_val: nan, pos_over_neg: 772.9208374023438 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 419.9820861816406 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 512.2479248046875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 685.5014038085938 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 405.7402038574219 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8325, loss_val: nan, pos_over_neg: 957.3154296875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 1564.1080322265625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8287, loss_val: nan, pos_over_neg: 522.9310913085938 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 512.7092895507812 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8197, loss_val: nan, pos_over_neg: 1323.224365234375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 783.0018310546875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8241, loss_val: nan, pos_over_neg: 656.4979858398438 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.821, loss_val: nan, pos_over_neg: 432.6850891113281 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 501.5152893066406 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 607.3228759765625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 609.7243041992188 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 553.445556640625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 1720.2119140625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 551.6347045898438 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 422.83453369140625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8194, loss_val: nan, pos_over_neg: 921.6117553710938 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 443.7527160644531 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 851.2319946289062 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8186, loss_val: nan, pos_over_neg: 355.140625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8258, loss_val: nan, pos_over_neg: 421.8660583496094 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 583.7886352539062 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8162, loss_val: nan, pos_over_neg: 514.9639892578125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 608.9036254882812 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 1518.79443359375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 550.4590454101562 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8217, loss_val: nan, pos_over_neg: 412.74066162109375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 766.8250122070312 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 544.5199584960938 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 294.1707763671875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.826, loss_val: nan, pos_over_neg: 769.6375732421875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 500.17877197265625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 360.9644775390625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 1083.346435546875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8159, loss_val: nan, pos_over_neg: 767.8530883789062 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8158, loss_val: nan, pos_over_neg: 795.8289794921875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8253, loss_val: nan, pos_over_neg: 329.6371765136719 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 653.72509765625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 457.7151184082031 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8205, loss_val: nan, pos_over_neg: 338.3625793457031 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 721.4608764648438 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8187, loss_val: nan, pos_over_neg: 445.2054748535156 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.8231, loss_val: nan, pos_over_neg: 299.68359375 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 403.680419921875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 428.34930419921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8252, loss_val: nan, pos_over_neg: 310.9274597167969 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8187, loss_val: nan, pos_over_neg: 393.5570983886719 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8204, loss_val: nan, pos_over_neg: 299.6945495605469 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 278.5340576171875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 413.827392578125 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8118, loss_val: nan, pos_over_neg: 426.9234313964844 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 749.1969604492188 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 246.59854125976562 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 507.73626708984375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8195, loss_val: nan, pos_over_neg: 1029.3585205078125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 462.5622253417969 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8213, loss_val: nan, pos_over_neg: 492.7926940917969 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 529.7352905273438 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 701.8826904296875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.816, loss_val: nan, pos_over_neg: 420.0191345214844 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 732.1431884765625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8168, loss_val: nan, pos_over_neg: 380.6136474609375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8162, loss_val: nan, pos_over_neg: 698.95703125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 593.4246215820312 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 654.4664916992188 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8193, loss_val: nan, pos_over_neg: 625.2017211914062 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 539.3986206054688 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 624.0978393554688 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8171, loss_val: nan, pos_over_neg: 554.0811157226562 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.8167, loss_val: nan, pos_over_neg: 529.7869262695312 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.819, loss_val: nan, pos_over_neg: 506.1485595703125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 556.2318115234375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8203, loss_val: nan, pos_over_neg: 488.1476135253906 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 594.5242919921875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 663.83642578125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 790.2598876953125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 458.42999267578125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 844.9437866210938 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.816, loss_val: nan, pos_over_neg: 668.62255859375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 561.488525390625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8168, loss_val: nan, pos_over_neg: 517.4143676757812 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8135, loss_val: nan, pos_over_neg: 656.6162109375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 1193.3607177734375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 926.0494995117188 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8197, loss_val: nan, pos_over_neg: 574.7750854492188 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8244, loss_val: nan, pos_over_neg: 570.8011474609375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8124, loss_val: nan, pos_over_neg: 1010.6051025390625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.8233, loss_val: nan, pos_over_neg: 1140.2890625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 561.174072265625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8127, loss_val: nan, pos_over_neg: 1320.9908447265625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 861.7894287109375 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 668.742919921875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8186, loss_val: nan, pos_over_neg: 1082.064697265625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 571.1317138671875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8179, loss_val: nan, pos_over_neg: 660.3724365234375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 412.2113952636719 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 628.3108520507812 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 481.5339660644531 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 447.5116271972656 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 710.0650024414062 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.8173, loss_val: nan, pos_over_neg: 738.68359375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8248, loss_val: nan, pos_over_neg: 530.9866943359375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 561.9724731445312 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8169, loss_val: nan, pos_over_neg: 1074.3192138671875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8169, loss_val: nan, pos_over_neg: 942.4482421875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 543.7356567382812 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 593.4419555664062 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8178, loss_val: nan, pos_over_neg: 607.5390014648438 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 791.7787475585938 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 463.0740966796875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 876.0960083007812 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 595.8547973632812 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 366.8993835449219 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8242, loss_val: nan, pos_over_neg: 516.6937255859375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 822.0288696289062 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 430.744140625 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8173, loss_val: nan, pos_over_neg: 590.7935180664062 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 419.6275634765625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 1561.085205078125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8152, loss_val: nan, pos_over_neg: 526.8374633789062 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8233, loss_val: nan, pos_over_neg: 329.1357727050781 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 769.378662109375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8263, loss_val: nan, pos_over_neg: 358.9131164550781 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 309.7991943359375 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8212, loss_val: nan, pos_over_neg: 496.2594909667969 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 588.8369750976562 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 581.5484619140625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 621.6235961914062 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 662.4765014648438 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 737.6992797851562 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8197, loss_val: nan, pos_over_neg: 364.9369812011719 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 737.138427734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 919.7787475585938 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 884.111328125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 1807.579833984375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8179, loss_val: nan, pos_over_neg: 824.24951171875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 1459.3251953125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 1588.5047607421875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 1165.0386962890625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 1156.145263671875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 717.0997314453125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8133, loss_val: nan, pos_over_neg: 1161.654052734375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.8109, loss_val: nan, pos_over_neg: 1346.2603759765625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8184, loss_val: nan, pos_over_neg: 616.0308837890625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 900.9297485351562 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 1017.314453125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8221, loss_val: nan, pos_over_neg: 521.3380737304688 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 555.2377319335938 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 838.7802734375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 942.4846801757812 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 1518.5374755859375 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [21:13<106119:04:49, 1273.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.8182, loss_val: nan, pos_over_neg: 609.788330078125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 509.2325439453125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8182, loss_val: nan, pos_over_neg: 571.3419799804688 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 713.7899780273438 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8198, loss_val: nan, pos_over_neg: 610.425537109375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 707.8052978515625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 1390.362548828125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 631.4072265625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8152, loss_val: nan, pos_over_neg: 747.34375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 819.7352294921875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8257, loss_val: nan, pos_over_neg: 604.325927734375 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 691.0167846679688 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 600.0771484375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.816, loss_val: nan, pos_over_neg: 653.1404418945312 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8103, loss_val: nan, pos_over_neg: 1014.4102172851562 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8125, loss_val: nan, pos_over_neg: 535.5944213867188 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8245, loss_val: nan, pos_over_neg: 745.2576293945312 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.8181, loss_val: nan, pos_over_neg: 1722.126220703125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 969.6682739257812 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8153, loss_val: nan, pos_over_neg: 463.71923828125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 742.2012329101562 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8165, loss_val: nan, pos_over_neg: 666.6190795898438 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8112, loss_val: nan, pos_over_neg: 481.2845153808594 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 644.1983032226562 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 511.98095703125 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 685.322265625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 576.4588623046875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 694.2780151367188 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 638.6641235351562 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 568.1671752929688 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8156, loss_val: nan, pos_over_neg: 1084.57080078125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 498.6284484863281 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 827.5286254882812 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 623.6656494140625 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 422.8110046386719 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 666.0903930664062 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8171, loss_val: nan, pos_over_neg: 562.9207153320312 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8187, loss_val: nan, pos_over_neg: 670.9736328125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 943.8040161132812 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.8162, loss_val: nan, pos_over_neg: 467.1346435546875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8214, loss_val: nan, pos_over_neg: 494.99200439453125 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 907.58837890625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 562.5975952148438 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 531.5568237304688 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 542.21142578125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 769.6659545898438 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8192, loss_val: nan, pos_over_neg: 432.8582763671875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 690.6578979492188 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 878.135009765625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 940.4818725585938 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8126, loss_val: nan, pos_over_neg: 774.1168212890625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 826.3255615234375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8148, loss_val: nan, pos_over_neg: 680.29150390625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 885.7904052734375 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 825.802001953125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8077, loss_val: nan, pos_over_neg: 708.6417236328125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 479.94775390625 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 1026.6038818359375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 990.5628051757812 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 1010.064697265625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8109, loss_val: nan, pos_over_neg: 576.6776733398438 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 851.3173217773438 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 1029.97216796875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 1971.18896484375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 863.3262329101562 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8016, loss_val: nan, pos_over_neg: 1443.4677734375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8145, loss_val: nan, pos_over_neg: 1957.4205322265625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 885.399658203125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8069, loss_val: nan, pos_over_neg: 1134.18994140625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.803, loss_val: nan, pos_over_neg: 1234.9578857421875 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 546.58935546875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 675.9906005859375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 762.2147827148438 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.8083, loss_val: nan, pos_over_neg: 1147.9114990234375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 907.6568603515625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 820.5736694335938 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 618.7177124023438 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 476.9209289550781 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 413.63153076171875 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 582.0996704101562 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 401.52685546875 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 584.7890625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8133, loss_val: nan, pos_over_neg: 423.71697998046875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 431.01409912109375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8146, loss_val: nan, pos_over_neg: 1144.64306640625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 506.0931396484375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8111, loss_val: nan, pos_over_neg: 439.46258544921875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 785.8652954101562 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 1242.9561767578125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 463.10003662109375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 454.2681579589844 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.8157, loss_val: nan, pos_over_neg: 940.432373046875 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 627.5760498046875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.815, loss_val: nan, pos_over_neg: 308.8321838378906 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 1195.6778564453125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 4581.9716796875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 596.410400390625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 584.9486694335938 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 707.2216186523438 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 661.6134643554688 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 820.24560546875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.8091, loss_val: nan, pos_over_neg: 434.7679443359375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 527.6776123046875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 485.6877136230469 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 747.509521484375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 728.3947143554688 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 509.7876281738281 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 735.481689453125 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 749.9902954101562 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 898.0697631835938 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 641.7564086914062 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.8033, loss_val: nan, pos_over_neg: 891.26123046875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 552.63330078125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 484.2884826660156 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8088, loss_val: nan, pos_over_neg: 809.3671875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8059, loss_val: nan, pos_over_neg: 573.3519287109375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 554.6560668945312 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8072, loss_val: nan, pos_over_neg: 321.7773742675781 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 702.1954956054688 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 785.2557983398438 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 496.39031982421875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.8075, loss_val: nan, pos_over_neg: 451.9810791015625 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 1602.530517578125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.8116, loss_val: nan, pos_over_neg: 729.9273681640625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 431.6014404296875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 513.8038330078125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 714.591796875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 771.0302734375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 759.6730346679688 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 2407.098876953125 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 446.28466796875 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 552.1209106445312 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 1319.862060546875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 597.5422973632812 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 966.4207153320312 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 514.8787841796875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8099, loss_val: nan, pos_over_neg: 854.1151123046875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 504.4775390625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 736.4938354492188 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 584.9454956054688 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 626.4812622070312 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 1488.58203125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.803, loss_val: nan, pos_over_neg: 572.2113647460938 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 744.0607299804688 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8049, loss_val: nan, pos_over_neg: 882.5347290039062 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 725.0050659179688 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8084, loss_val: nan, pos_over_neg: 377.5912170410156 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.8074, loss_val: nan, pos_over_neg: 1496.46337890625 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 1271.29931640625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 1908.870849609375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 398.51385498046875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 949.2787475585938 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 599.6538696289062 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 529.1272583007812 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 925.6937255859375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 706.4840698242188 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 915.3634643554688 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 931.9791870117188 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 1119.42236328125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 894.66259765625 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 661.1975708007812 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 1121.930908203125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 551.2096557617188 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 443.03887939453125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8025, loss_val: nan, pos_over_neg: 1088.3707275390625 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 661.6842651367188 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 411.745361328125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 746.3009033203125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 554.677734375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8104, loss_val: nan, pos_over_neg: 487.26507568359375 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 540.498779296875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 659.4892578125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8098, loss_val: nan, pos_over_neg: 488.52984619140625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8064, loss_val: nan, pos_over_neg: 688.9338989257812 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 723.1837768554688 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 481.41888427734375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 1123.5809326171875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8033, loss_val: nan, pos_over_neg: 629.9379272460938 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8035, loss_val: nan, pos_over_neg: 778.5667114257812 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 529.8375244140625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 572.974365234375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 511.6713562011719 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 806.3685302734375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 394.4627380371094 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 619.4620361328125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 642.3604736328125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 1745.692138671875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 657.024169921875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 467.34368896484375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 555.5103149414062 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 1220.5621337890625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8089, loss_val: nan, pos_over_neg: 495.8842468261719 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 1107.5015869140625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 511.59814453125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8054, loss_val: nan, pos_over_neg: 953.2023315429688 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 605.1292724609375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 453.5714111328125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 724.1434936523438 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 471.9178466796875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 810.8889770507812 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 475.1126403808594 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 1113.6470947265625 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 454.8326110839844 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 729.7368774414062 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 689.522705078125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 526.4653930664062 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 964.810302734375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 733.65478515625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 544.0858764648438 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 538.47900390625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 1028.1812744140625 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 528.2865600585938 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 500.15118408203125 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 1357.3035888671875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 1285.616455078125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 563.271728515625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 953.0883178710938 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 1706.328857421875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 555.3450317382812 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 482.1121826171875 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 662.2210083007812 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 1269.681640625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 834.6310424804688 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 583.8138427734375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 766.8526611328125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 1329.427734375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 379.1914978027344 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 407.4989929199219 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 775.1843872070312 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 564.5889892578125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 437.3827209472656 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 694.1936645507812 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 589.5076293945312 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.8082, loss_val: nan, pos_over_neg: 350.09210205078125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 650.8584594726562 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 809.1246337890625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 364.93157958984375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 476.8314208984375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 1191.5677490234375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 462.663330078125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 438.79052734375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 422.326171875 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 976.7871704101562 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 630.05419921875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 422.9144592285156 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 1107.265625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 685.553466796875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 2037.153564453125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 1369.7939453125 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8033, loss_val: nan, pos_over_neg: 441.77630615234375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 621.0774536132812 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 1027.6153564453125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 1377.176513671875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 716.849365234375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 709.7009887695312 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 991.427490234375 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 1140.4207763671875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 1030.417724609375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 708.7573852539062 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 388.0227966308594 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 536.25927734375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 1380.181396484375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 345.29119873046875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 589.754150390625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 1148.2320556640625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 1240.2593994140625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 1203.75 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 608.3988647460938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 464.4737548828125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 414.74261474609375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 539.1277465820312 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 633.2932739257812 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 517.162353515625 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 1399.8665771484375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 915.3469848632812 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 643.8460083007812 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 1072.1856689453125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 352.9810485839844 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 543.9840698242188 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 669.2637329101562 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 515.2654418945312 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 1003.751708984375 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 819.2607421875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 581.6222534179688 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 754.38916015625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 626.8073120117188 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 848.4281616210938 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 408.3953857421875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 459.1434631347656 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 353.16937255859375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 706.7361450195312 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 441.9649658203125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8109, loss_val: nan, pos_over_neg: 399.5171813964844 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 702.255859375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 428.00677490234375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 624.9161987304688 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 2035.51513671875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 858.6246337890625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 814.7723999023438 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 1299.0052490234375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 1411.606689453125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 791.1026000976562 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 1112.9937744140625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 964.1653442382812 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 983.2815551757812 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 1271.3326416015625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1232.736572265625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 2522.7373046875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 839.71484375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 1240.4862060546875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 850.1572265625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 3219.88427734375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 820.1143798828125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 663.8670654296875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 2460.914794921875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1438.55419921875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 797.7960815429688 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 1900.38720703125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7986, loss_val: nan, pos_over_neg: 847.8467407226562 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 1281.2822265625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 1304.142822265625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 586.3984985351562 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 525.8903198242188 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 5131.72265625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 725.3682861328125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 757.4830322265625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 406.6026916503906 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 692.778564453125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 752.1546630859375 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 831.1854858398438 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1360.3663330078125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1838.1871337890625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 827.9458618164062 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 600.8353271484375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 580.6343383789062 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 883.4246826171875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 552.4899291992188 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 586.94677734375 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 791.4200439453125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 1339.3870849609375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 453.0027160644531 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 7469.38818359375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 778.3904418945312 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 810.344970703125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 476.1302490234375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 589.365234375 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 1041.2965087890625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 754.71826171875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 571.1768798828125 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 682.581787109375 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 957.7449951171875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 552.4754028320312 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 494.1650390625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 653.9799194335938 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 1162.9896240234375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 684.8333129882812 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 936.2760620117188 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8081, loss_val: nan, pos_over_neg: 517.8302612304688 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 953.0446166992188 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 837.2146606445312 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 1688.33740234375 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 1053.4822998046875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 1392.42041015625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 1006.1851806640625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 1310.73486328125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8045, loss_val: nan, pos_over_neg: 1173.567138671875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 502.34979248046875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 918.6875610351562 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 702.9430541992188 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 507.5233154296875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 647.7637329101562 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 937.2047729492188 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 1223.985107421875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 461.7417297363281 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 537.5547485351562 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 2691.161376953125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 791.2208862304688 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 854.632568359375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 861.8467407226562 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 768.6116333007812 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 2291.241943359375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 908.302490234375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 965.912353515625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 946.7808227539062 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1576.6702880859375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 774.6422729492188 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 393.9298095703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 717.65576171875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 832.7353515625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 695.0101928710938 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1697.939453125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 449.69012451171875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 849.6024780273438 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 531.2716064453125 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8011, loss_val: nan, pos_over_neg: 513.5401611328125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 704.326171875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 835.9163818359375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 784.92724609375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 885.9083251953125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 1322.1885986328125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1303.4716796875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 562.3860473632812 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 350.2685241699219 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 2611.54638671875 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 836.3932495117188 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 675.9807739257812 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 1222.7318115234375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 576.6085815429688 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 789.4427490234375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 895.451416015625 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 432.7040710449219 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 565.373291015625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 628.244873046875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 482.5628662109375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 711.507080078125 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 1030.456298828125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 1761.7659912109375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 376.78656005859375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 419.1022033691406 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 496.47088623046875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 1935.79443359375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 650.1573486328125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 490.7609558105469 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7933, loss_val: nan, pos_over_neg: 975.90380859375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 763.24658203125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 780.9609375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 459.1907653808594 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 468.73114013671875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 1064.760986328125 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 647.1942749023438 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 591.1923217773438 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 751.3092651367188 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 974.28173828125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 688.9762573242188 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 751.4356079101562 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 711.6565551757812 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 844.9815673828125 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 600.30419921875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 2479.969970703125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7984, loss_val: nan, pos_over_neg: 1119.589111328125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 842.3906860351562 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 945.3848266601562 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 823.5054931640625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 439.2279052734375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 709.7883911132812 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 566.8765869140625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 364.74359130859375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 481.0936279296875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 781.9390869140625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 483.9427185058594 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 458.0205993652344 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 855.1494750976562 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 412.72564697265625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 588.1674194335938 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 508.3714294433594 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 915.8094482421875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7942, loss_val: nan, pos_over_neg: 450.5770568847656 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 485.8924255371094 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 565.0718383789062 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 1076.81982421875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 795.916259765625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 538.5718383789062 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 562.3417358398438 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 918.419677734375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 922.339599609375 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 663.3353881835938 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 567.4327392578125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 855.4146118164062 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 761.3186645507812 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 628.0177612304688 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 524.0032958984375 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 737.82861328125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 727.2979736328125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 514.7799682617188 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 616.5540771484375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 475.2095031738281 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 574.3087768554688 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 384.5555725097656 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 1054.5135498046875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 617.9312744140625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 1116.3341064453125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 908.8895263671875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 399.04876708984375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 575.3433227539062 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 547.5440673828125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 642.891357421875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 381.09844970703125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 534.5838012695312 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 641.5181884765625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 1046.93701171875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 659.5950317382812 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8124, loss_val: nan, pos_over_neg: 652.0220336914062 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 651.2857666015625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 736.7905883789062 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 556.5177001953125 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 525.8138427734375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 1615.0989990234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 355.8753356933594 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 799.5130615234375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 538.9649047851562 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 853.4640502929688 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 904.007080078125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 452.8295593261719 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 797.6915283203125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 715.9428100585938 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 950.9528198242188 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 542.99365234375 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 607.363525390625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 411.1937255859375 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 644.01611328125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1132.204833984375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 1238.2603759765625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 673.9238891601562 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 476.177978515625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 988.4356689453125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 714.416748046875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 545.6596069335938 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 233.50277709960938 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 919.6904296875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 721.7051391601562 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 1191.03125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 832.886474609375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 826.900146484375 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 747.0029296875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 1464.94921875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 916.5631713867188 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 769.144287109375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 2048.2392578125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 850.9757080078125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 472.21405029296875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 5045.017578125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 608.2400512695312 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1123.7274169921875 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 918.072998046875 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 952.9575805664062 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 755.6011352539062 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 867.091064453125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 1464.201904296875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 814.6896362304688 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1119.98974609375 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 498.4050598144531 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 918.123779296875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1824.794921875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7973, loss_val: nan, pos_over_neg: 419.4953308105469 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 468.1632080078125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 930.8477783203125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 554.0404052734375 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 1125.630859375 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 669.3864135742188 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 524.4058837890625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 981.7482299804688 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 1140.761962890625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 509.9118957519531 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 567.1012573242188 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 967.0340576171875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1221.97705078125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 1382.273681640625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 489.5352478027344 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 864.6249389648438 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 5173.6708984375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 1424.85400390625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1628.54736328125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 662.173095703125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 966.2130126953125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 568.497314453125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 4394.38427734375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 1579.305908203125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 979.0402221679688 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1042.0577392578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 634.2376098632812 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1314.979736328125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 680.8152465820312 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 687.4452514648438 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 636.9102172851562 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 591.02783203125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 2295.084228515625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1565.9630126953125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 633.1351318359375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 1795.688720703125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 2536.34521484375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 729.6556396484375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 485.41571044921875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1011.8912353515625 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 1977.854248046875 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 713.9539794921875 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 769.4133911132812 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 713.9878540039062 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 2963.69580078125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 2065.366943359375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 1191.22998046875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 1526.9940185546875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 2038.7755126953125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 2456.77294921875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 1023.7263793945312 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 783.47216796875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 787.4248046875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 828.8035278320312 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 446.13055419921875 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 1036.0113525390625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7979, loss_val: nan, pos_over_neg: 447.2882080078125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 464.4985046386719 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 399.6627197265625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 846.5247802734375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 1553.1514892578125 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1043.149658203125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 924.8990478515625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 801.9793701171875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 993.3822021484375 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 2790.947021484375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 1209.208251953125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 940.8840942382812 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1567.3616943359375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1248.099853515625 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 839.3660278320312 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 2580.269775390625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1370.547119140625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 1107.3336181640625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 1725.7354736328125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 758.4631958007812 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 522.9207153320312 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 541.68505859375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 607.6920166015625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 538.9068603515625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 474.7742004394531 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1287.1876220703125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 475.5709533691406 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1319.4661865234375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 821.7785034179688 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 1006.2268676757812 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 567.4542846679688 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 728.931640625 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1196.9398193359375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 683.0709838867188 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 468.2001953125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 544.9006958007812 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 1415.428466796875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1068.4754638671875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 577.3253173828125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 1298.4959716796875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 596.0494995117188 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 805.581787109375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 949.6702880859375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 489.67626953125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 633.4331665039062 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 655.5736694335938 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 794.2447509765625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 873.3569946289062 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 691.7037963867188 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 934.403564453125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 475.15869140625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 2724.187744140625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 1442.178955078125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 1197.5582275390625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1074.17138671875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 1508.63671875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 835.5635375976562 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 591.2799072265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 791.0457153320312 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 868.0714111328125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 949.0062866210938 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1208.9310302734375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 718.233154296875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 653.6909790039062 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 671.6427001953125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 780.1256713867188 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 668.460693359375 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 1510.4005126953125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 714.033203125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 1105.24462890625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 3927.43408203125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 746.927001953125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 937.7252807617188 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 1695.0382080078125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 1270.69287109375 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 569.8968505859375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 1372.7442626953125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 791.3941040039062 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1509.4503173828125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 829.218017578125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1506.9580078125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 1965.43115234375 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 1013.5216064453125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 1843.3212890625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1186.5989990234375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 863.2474365234375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 804.469482421875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1836.9237060546875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 582.4686279296875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 924.47900390625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 783.1080322265625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 794.6357421875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 1150.5272216796875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1365.043701171875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 1038.77783203125 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 934.3685302734375 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [42:09<105272:56:31, 1263.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 811.5289916992188 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 1319.1134033203125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1285.5338134765625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 1342.169677734375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 590.3429565429688 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 1870.6231689453125 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 2697.01806640625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 1080.3848876953125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 1383.94140625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 787.5067749023438 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 4712.591796875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1092.5882568359375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1211.0230712890625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 506.8359069824219 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1085.86474609375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1895.6241455078125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1662.430908203125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 866.0725708007812 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 941.968994140625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 1251.0587158203125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1523.4246826171875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1608.8037109375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 661.2158813476562 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 1006.6263427734375 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 701.7608642578125 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 432.5838317871094 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 470.2866516113281 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 1315.8472900390625 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 1175.60302734375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 619.05224609375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 1256.8115234375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1780.4666748046875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 647.605224609375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 617.0983276367188 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 563.6981811523438 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 689.55615234375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 809.8182373046875 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 493.247314453125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 1206.285888671875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 740.568115234375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1347.3675537109375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 1269.5350341796875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 654.7665405273438 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 645.41943359375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 1310.4649658203125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 552.1231689453125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 2775.614990234375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 469.70977783203125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 1230.452880859375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 1208.31982421875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 861.2926025390625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 544.105224609375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 560.1873779296875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1179.2291259765625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 580.5245971679688 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 2220.66552734375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 598.4481811523438 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1368.1766357421875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 1198.6201171875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 675.9517211914062 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 756.2680053710938 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 1129.9287109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 443.25250244140625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 551.9642333984375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 811.1227416992188 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7921, loss_val: nan, pos_over_neg: 431.22393798828125 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 521.6239624023438 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 508.14862060546875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1541.8717041015625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 1126.813720703125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 552.2098388671875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 534.930908203125 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 800.2608642578125 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 724.613037109375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 687.4182739257812 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 597.4465942382812 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 533.8441162109375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 794.6596069335938 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 598.93212890625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 542.1268310546875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1760.49169921875 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 1698.8759765625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1306.9205322265625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 647.3949584960938 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 639.3165893554688 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 654.6743774414062 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 2102.08349609375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 763.9010620117188 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 690.3474731445312 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 573.317138671875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 926.2449340820312 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 494.3186950683594 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1569.3162841796875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 662.79345703125 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 803.0112915039062 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 4352.79150390625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 1055.9896240234375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 613.782470703125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 514.775634765625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 994.7977294921875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 739.5504760742188 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 551.4151000976562 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 791.031005859375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 897.0352783203125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1129.2357177734375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1010.0 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 956.6363525390625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 564.5003662109375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 500.13134765625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 762.6665649414062 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7879, loss_val: nan, pos_over_neg: 682.622802734375 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 456.1044616699219 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 1079.652099609375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 551.5320434570312 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1189.60791015625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 22821.869140625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 816.8944702148438 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 1367.728271484375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 907.3109130859375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1143.4127197265625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 563.90087890625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 5240.79443359375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 680.2759399414062 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 939.8267822265625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 2534.4853515625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: -5357.8203125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1147.2578125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 857.8399047851562 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 817.7559204101562 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 966.7450561523438 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 646.5316772460938 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 655.0104370117188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 394.4474182128906 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 835.2550659179688 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 864.421142578125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 913.7135009765625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 4155.345703125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 951.167236328125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 704.9521484375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 892.8331298828125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 965.2677001953125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 657.1910400390625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1116.6806640625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1008.0513305664062 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 497.802978515625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 565.9790649414062 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 872.2449340820312 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 695.1626586914062 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 978.773193359375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 541.96728515625 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 801.1641845703125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 1255.69873046875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 1557.6248779296875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 523.3513793945312 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 516.354736328125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 738.3433837890625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 931.9771118164062 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1067.238037109375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 902.0706176757812 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 648.2310180664062 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 997.1251831054688 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1602.2322998046875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 683.5198364257812 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 1049.7509765625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 1004.8988037109375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 667.6837158203125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 509.6638488769531 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 904.2144775390625 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 1330.4989013671875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 586.113525390625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 973.5732421875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 481.71234130859375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 790.5338745117188 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1947.63671875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 774.9302978515625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 1182.5731201171875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 721.0890502929688 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 6367.490234375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 629.0234375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1038.5675048828125 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1060.2059326171875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1179.5362548828125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 497.626708984375 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 532.6080322265625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 538.45166015625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 613.1852416992188 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 493.6982421875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 847.0479736328125 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 900.7723999023438 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 720.294189453125 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 489.608154296875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 790.576416015625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 524.88427734375 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 676.9751586914062 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1295.5517578125 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 648.3065185546875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 926.8937377929688 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 720.6679077148438 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1132.1502685546875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1268.9202880859375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 507.5629577636719 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 751.5645751953125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 545.3063354492188 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 2016.0457763671875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 1493.79296875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 585.0651245117188 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 512.1046752929688 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 651.8179931640625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 1273.2501220703125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1870.615234375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 820.592529296875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 432.7087097167969 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 846.0430297851562 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 667.9352416992188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1230.3138427734375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 680.8118286132812 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 744.5721435546875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 727.456298828125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 1417.8201904296875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1259.663818359375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 676.3740234375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 626.810546875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1077.0343017578125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 509.69781494140625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 1514.5247802734375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 1092.2203369140625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 1002.02880859375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 1875.2606201171875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.788, loss_val: nan, pos_over_neg: 1116.17578125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 1277.6519775390625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 2420.080078125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1019.64990234375 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 730.1832275390625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1314.8836669921875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 962.7462158203125 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 819.47314453125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1133.552490234375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1043.2672119140625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 1055.765625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 834.51611328125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1148.5093994140625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 564.0223999023438 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 816.5730590820312 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 503.17913818359375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 603.5535278320312 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 557.4090576171875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 648.9515380859375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1795.637451171875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1173.027587890625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1344.8118896484375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 849.9795532226562 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 763.5664672851562 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 607.9702758789062 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 550.6439819335938 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 536.9638061523438 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 759.2957153320312 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 1145.3463134765625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1142.0255126953125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 675.8765869140625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 888.8177490234375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 808.103271484375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 911.0999145507812 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 852.4762573242188 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 663.416259765625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 404.98077392578125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 736.6746215820312 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1018.3807983398438 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1228.84423828125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 654.2127075195312 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 543.1530151367188 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 613.054931640625 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 904.3578491210938 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1010.4837036132812 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 849.9281005859375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1195.333251953125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1148.4874267578125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.79, loss_val: nan, pos_over_neg: 566.8056640625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1688.1646728515625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1375.2349853515625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 711.6692504882812 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 725.5162963867188 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 653.1211547851562 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 1195.8662109375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1203.5809326171875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 702.734375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 600.42236328125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1139.59033203125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 1017.1299438476562 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7932, loss_val: nan, pos_over_neg: 427.1745910644531 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 774.4566040039062 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 1036.779052734375 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 753.01416015625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 724.7022705078125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 523.6077880859375 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1283.5201416015625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 838.8558349609375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1265.079833984375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1581.742919921875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 1527.370361328125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 571.0125732421875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1795.186279296875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 786.2492065429688 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 721.20361328125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 562.314453125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1122.281982421875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1189.778076171875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 695.6051635742188 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 704.2625122070312 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 828.4472045898438 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 591.3353271484375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 829.8283081054688 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 1044.738037109375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 601.1853637695312 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 611.4470825195312 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 579.0167236328125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 1118.459716796875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 862.0068359375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 592.2293090820312 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 743.0355834960938 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 559.7942504882812 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 621.375244140625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 523.5669555664062 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 552.2941284179688 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 574.7185668945312 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 471.9261169433594 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 849.7578735351562 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 1013.2236938476562 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 918.5974731445312 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 518.5700073242188 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 572.5247192382812 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 1086.845703125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 914.308837890625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 531.730712890625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 677.0490112304688 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 821.7542724609375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 745.277099609375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 973.478271484375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 548.2317504882812 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 560.5201416015625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1767.767333984375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 583.4246826171875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 851.9226684570312 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 396.4991760253906 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 571.5182495117188 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 955.52490234375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 770.4091186523438 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 567.2261352539062 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 788.5796508789062 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 1355.216796875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 684.1162109375 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 936.6747436523438 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 721.0297241210938 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 805.4459838867188 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 611.3428955078125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 920.058837890625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 1330.7489013671875 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 687.191162109375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 784.1804809570312 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 902.1431274414062 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 379.2627258300781 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1839.4296875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1215.5367431640625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 459.1734619140625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 737.475830078125 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 553.65283203125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1194.33447265625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 776.1730346679688 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 755.6879272460938 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1672.404541015625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1548.4111328125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1308.909423828125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 893.255859375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 639.783447265625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1136.7210693359375 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 647.0089721679688 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 1340.2301025390625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 830.7685546875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 628.2515258789062 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1602.4356689453125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 3236.17529296875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 1092.962158203125 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 1107.7911376953125 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 652.4555053710938 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 726.0314331054688 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 1258.1976318359375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 667.7543334960938 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 552.2780151367188 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 774.8259887695312 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1208.0313720703125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 2315.0810546875 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 2360.331298828125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1576.2947998046875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 1005.912109375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1194.46240234375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 2299.115966796875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 1263.3189697265625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 721.798583984375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 764.9136352539062 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 1210.7235107421875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 866.011474609375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1081.819580078125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 841.126953125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1044.9757080078125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 2775.81005859375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 921.604248046875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 612.1952514648438 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 688.7406005859375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1098.52099609375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 519.8298950195312 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1670.468017578125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 809.538330078125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 1031.7698974609375 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 977.446044921875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 674.2670288085938 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 710.6322021484375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 505.0550231933594 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 705.3370361328125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1413.1495361328125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1326.931884765625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1085.4085693359375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1364.75 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 640.1588134765625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1593.16162109375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 773.4702758789062 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1067.29052734375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 700.2268676757812 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 906.9965209960938 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1133.5498046875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 933.9119262695312 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 503.75079345703125 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1064.2098388671875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1234.4068603515625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 1424.7979736328125 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 912.7285766601562 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 759.6300659179688 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 761.9395141601562 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 531.29931640625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 1714.6240234375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 833.0526123046875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 718.5899047851562 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 641.8343505859375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 618.098876953125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 612.6192626953125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 426.59033203125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 523.4669799804688 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1059.1622314453125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 754.8872680664062 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 507.3439636230469 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 487.99560546875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 986.7271118164062 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1748.6910400390625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 717.3541870117188 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 1320.48095703125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 771.6140747070312 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 874.2329711914062 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 528.41845703125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 821.9847412109375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 674.664306640625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 518.6862182617188 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1592.0367431640625 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1076.26318359375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 854.2095947265625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 453.3673400878906 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 935.71435546875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 956.6838989257812 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1148.08251953125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 965.1085815429688 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 1773.2020263671875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 833.417724609375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 834.1328735351562 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 2268.813232421875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 797.016845703125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 516.9354248046875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 506.3650817871094 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 640.7673950195312 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 842.2896728515625 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1020.0264282226562 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 633.130126953125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 566.1823120117188 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1074.1810302734375 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 849.501953125 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 797.0001831054688 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 752.3306274414062 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 400.04608154296875 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 556.3753051757812 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 418.1819763183594 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 781.6906127929688 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1463.6900634765625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 915.2453002929688 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 593.3728637695312 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 629.5087890625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1645.015380859375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 936.0004272460938 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 852.4406127929688 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 1075.6724853515625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 981.3570556640625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 2080.522216796875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1487.3594970703125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1223.5352783203125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 559.2947387695312 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1045.810791015625 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 630.7171630859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1089.697998046875 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1048.7440185546875 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 747.8216552734375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1030.7064208984375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1121.104736328125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 822.3804321289062 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1715.178466796875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 809.8180541992188 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 602.94384765625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 1009.0614013671875 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 469.3238830566406 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 687.3101806640625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 639.9110107421875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 961.9983520507812 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1268.5595703125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1334.0478515625 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 544.9404296875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1388.4168701171875 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 1118.3382568359375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 676.9843139648438 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 699.4033203125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 3247.06640625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 828.5148315429688 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 742.4534912109375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1242.222900390625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 5477.650390625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1342.670654296875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1045.5123291015625 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1339.521484375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 2962.775634765625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 792.907958984375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 546.786376953125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1502.67431640625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1404.0142822265625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1278.6580810546875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 599.16943359375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 828.7637939453125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1424.1268310546875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 1342.7376708984375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 2262.539794921875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1391.0948486328125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 954.5677490234375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: -8072.74365234375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 638.1166381835938 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 2837.23388671875 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1068.719482421875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2013.33447265625 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 1836.317138671875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1260.5770263671875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 690.76025390625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 2460.011474609375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 732.3938598632812 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1019.7047729492188 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1265.986083984375 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1550.46533203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1850.4532470703125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 892.1719360351562 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 677.2322387695312 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 2508.126708984375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1088.6805419921875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 752.0841064453125 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 1410.8577880859375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 723.06884765625 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1845.125244140625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 628.0984497070312 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 950.1923217773438 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1491.59033203125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1809.120849609375 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1333.300048828125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1305.474609375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 890.5625610351562 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 617.2571411132812 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1060.1488037109375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 507.1881408691406 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 815.1095581054688 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1869.413330078125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 712.7205200195312 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1068.90380859375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1313.4490966796875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1156.4083251953125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 919.6776123046875 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1251.3480224609375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1045.1947021484375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 910.010986328125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1939.5821533203125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1317.4232177734375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 876.8552856445312 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1699.3590087890625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1047.6307373046875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 2832.053955078125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 765.1513671875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 942.474853515625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 1190.5091552734375 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 678.5650634765625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 1099.3818359375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 803.06005859375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1999.197021484375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 787.9405517578125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 2039.007568359375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 830.5236206054688 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 668.3228759765625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 823.9531860351562 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 487.9786376953125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 608.4600830078125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 896.698486328125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 873.3352661132812 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 3748.11083984375 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 843.3680419921875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1746.7777099609375 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 5939.1396484375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 2373.116943359375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 597.5460815429688 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 476.99847412109375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 621.0660400390625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1259.8013916015625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 551.1543579101562 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 538.862060546875 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 872.1337280273438 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 965.5403442382812 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 546.5408935546875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 587.0694580078125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 1048.5621337890625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1458.0208740234375 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 913.6638793945312 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 773.7337036132812 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 2332.80126953125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 904.7278442382812 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 3901.305419921875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 801.1605224609375 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 441.4413757324219 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1221.2781982421875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 10553.66796875 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1433.5953369140625 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 763.8890991210938 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1862.6978759765625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 2847.5009765625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 2739.54931640625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 982.8090209960938 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 446.4375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 960.0236206054688 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1118.9669189453125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 870.3377685546875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 940.76171875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 851.2229614257812 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 1016.5455932617188 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1613.9071044921875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1207.5826416015625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 633.5304565429688 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 496.748046875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 913.1279907226562 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1657.9134521484375 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 781.427978515625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1333.699951171875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1407.5196533203125 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 904.0305786132812 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1488.3359375 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1182.527099609375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1028.4659423828125 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 733.3531494140625 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 2438.6552734375 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 981.9487915039062 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 743.1066284179688 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 1022.3301391601562 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 13400.541015625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 642.0006713867188 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 2206.434326171875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1756.2147216796875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1214.226806640625 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1213.5948486328125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 658.8509521484375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 762.5130615234375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1145.8924560546875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1441.4114990234375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1350.1402587890625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 863.8484497070312 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 761.3350219726562 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 1615.3057861328125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 559.0734252929688 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 1185.3199462890625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 552.7955322265625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 586.0205078125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1106.15380859375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 590.6190185546875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 752.07421875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 626.1209106445312 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1254.66259765625 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 730.9546508789062 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 624.0726318359375 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 889.3692626953125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 564.5620727539062 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 361.1278076171875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1083.3765869140625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 871.2781372070312 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:03:20<105580:15:23, 1266.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 875.8759765625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1111.1373291015625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 902.0773315429688 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 892.1907958984375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 769.300048828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 616.8064575195312 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 865.061279296875 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1197.7471923828125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 991.906494140625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 434.4156799316406 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 875.6856689453125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 864.9790649414062 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 554.1574096679688 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 684.4320678710938 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 897.5399169921875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1312.587646484375 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 709.6805419921875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 377.3351745605469 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 755.4008178710938 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 810.8510131835938 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1087.3525390625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 659.7057495117188 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 667.4532470703125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 1166.27783203125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1270.7291259765625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 801.8967895507812 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 907.20556640625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 955.8851928710938 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 1228.214111328125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 798.53125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 911.3174438476562 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1505.8055419921875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 909.4244384765625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1721.395751953125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1036.2125244140625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1824.3837890625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 901.4558715820312 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1318.9368896484375 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 960.0773315429688 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 692.4721069335938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 2976.954345703125 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1122.09912109375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1986.068359375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1412.865966796875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1313.912353515625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 606.4940185546875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1873.2701416015625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 861.7344970703125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1432.0985107421875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 734.3942260742188 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1293.200927734375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1251.0159912109375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1447.2105712890625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 846.3413696289062 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 958.4971923828125 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1256.224609375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1020.8329467773438 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1189.8330078125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 914.8994750976562 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 667.6170654296875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 948.0462036132812 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1373.2113037109375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 1136.6158447265625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1742.009765625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 4011.604248046875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1435.0985107421875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 926.1871948242188 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 802.0321655273438 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1086.2459716796875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 768.1984252929688 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 767.5415649414062 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 631.8369750976562 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 899.755859375 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 745.8598022460938 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 740.8951416015625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 680.1044311523438 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 751.8527221679688 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1005.7022705078125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 809.362548828125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 874.856201171875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 696.5739135742188 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 397.1595153808594 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1701.5198974609375 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1182.97900390625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 2361.085205078125 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1212.0567626953125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 831.6763305664062 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 901.0339965820312 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 857.4807739257812 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1399.5789794921875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 896.9077758789062 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 644.1498413085938 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 500.7955627441406 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1214.924072265625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 562.5505981445312 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 537.3587036132812 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 473.78173828125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 586.0119018554688 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 596.286865234375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 775.0023803710938 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 692.0517578125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 627.5361328125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 588.015869140625 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 529.9180908203125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1000.48681640625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 854.0386962890625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 669.1203002929688 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 679.3797607421875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1348.990966796875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1320.4873046875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1366.089111328125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 867.2508544921875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 856.6878051757812 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 9618.333984375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1365.3172607421875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 2443.1181640625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 798.0803833007812 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 835.9549560546875 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 844.3269653320312 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 851.9821166992188 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 5080.96728515625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 815.787109375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 812.9288940429688 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 822.966552734375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1294.2513427734375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 3032.39404296875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 622.8580932617188 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 859.1392211914062 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 990.0372924804688 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 2694.66650390625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1330.3453369140625 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1114.308349609375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 726.2156372070312 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 756.540771484375 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 673.79736328125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 843.95751953125 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1440.3240966796875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1708.418212890625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1278.8941650390625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 646.2225341796875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 709.296875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1393.926025390625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1230.9085693359375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 794.6607055664062 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 763.21630859375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 901.3426513671875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 617.2284545898438 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1223.3685302734375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 1041.7288818359375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 881.1823120117188 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1294.0916748046875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1435.3035888671875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 963.361572265625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 6248.8271484375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1458.654052734375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1383.6434326171875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 968.478271484375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1189.7332763671875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 885.1382446289062 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 713.5057983398438 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1022.7745971679688 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1528.282470703125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 602.4728393554688 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 979.4019775390625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1110.934326171875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 417.6190490722656 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 545.57275390625 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1504.67236328125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 533.4021606445312 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 472.5212097167969 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2104.514892578125 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1305.677490234375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 951.23681640625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1015.4517211914062 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 845.4816284179688 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 451.0108947753906 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1211.907958984375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 633.0623779296875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 618.7477416992188 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 932.0673217773438 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 877.218994140625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 972.064208984375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 578.2598266601562 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 882.402587890625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1005.7171630859375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 4701.8359375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 759.5706176757812 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 2206.488525390625 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1214.552978515625 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1930.7135009765625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1299.619140625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 973.5474853515625 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1775.1661376953125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1229.95947265625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1028.3814697265625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1082.8427734375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 814.0960083007812 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1289.3671875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 662.4937133789062 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 664.2606811523438 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 1081.567138671875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 3010.958984375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 885.1428833007812 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 863.6531982421875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1357.6407470703125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1070.0576171875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 957.294677734375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1269.957275390625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 2678.96240234375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1818.931640625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1062.1141357421875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1994.8873291015625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1206.48681640625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 557.8161010742188 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1533.9595947265625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 3443.65283203125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 825.5445556640625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1301.082275390625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1749.87548828125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 853.9752807617188 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1713.0245361328125 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1330.8880615234375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 573.3327026367188 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1191.6070556640625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1301.7176513671875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 724.5172729492188 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 796.7622680664062 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1423.8233642578125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1754.295166015625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1429.6580810546875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1098.3956298828125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1309.4697265625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 719.4903564453125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 983.0704345703125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1562.9864501953125 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 674.3723754882812 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 885.3108520507812 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1006.8851318359375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 732.40673828125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 955.3851928710938 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 921.116455078125 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 467.6567687988281 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 623.3914184570312 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1330.6007080078125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 727.173828125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 448.7243347167969 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 554.7251586914062 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 809.8515625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 808.654541015625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 789.9290161132812 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 851.7061767578125 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1281.722412109375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1063.0443115234375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 1161.73291015625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 988.8668212890625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 997.8893432617188 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 2203.22265625 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 520.710693359375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 914.189453125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 2349.18896484375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 2874.303955078125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1024.520751953125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1937.638916015625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1740.2716064453125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1530.8612060546875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1216.909912109375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 4350.650390625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1869.833251953125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 614.249267578125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 908.1127319335938 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 792.0078735351562 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2572.135009765625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 808.9523315429688 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 813.5228881835938 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 2518.474853515625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1555.8321533203125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 595.4767456054688 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 861.6939086914062 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1417.1715087890625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 991.9840087890625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 777.4060668945312 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 854.7581176757812 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 713.017578125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 921.3768310546875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1626.318359375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 835.770751953125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1035.0863037109375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1100.765625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 1269.166748046875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 762.7055053710938 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 937.3164672851562 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1073.9840087890625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1265.9228515625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 816.8826904296875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1696.093505859375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 894.8734741210938 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 588.4359130859375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 881.7174682617188 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1797.7366943359375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1055.7781982421875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1241.545654296875 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 977.299560546875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1200.7191162109375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 697.9472045898438 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1179.334228515625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3758.952880859375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1067.1575927734375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1602.175048828125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2232.82177734375 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 1579.6929931640625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1117.677734375 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 5148.494140625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 530.5411987304688 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1717.5947265625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1070.0438232421875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 465.0778503417969 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1273.3822021484375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1549.2589111328125 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1659.4261474609375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 3137.048583984375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 4007.960693359375 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1356.3662109375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 810.97509765625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1935.844482421875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 559.4116821289062 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1338.0694580078125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 442.9588317871094 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 475.6374206542969 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 633.2365112304688 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1026.38818359375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1545.1864013671875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1728.5787353515625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1076.9261474609375 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1288.862548828125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1194.4732666015625 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 681.0050048828125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1690.404296875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1492.7325439453125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1405.3426513671875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1171.676025390625 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1781.4427490234375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1554.867431640625 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1721.77392578125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1733.2823486328125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1317.2093505859375 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 2843.045166015625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 911.5860595703125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 907.613525390625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1857.1458740234375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1783.9686279296875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1199.5626220703125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1077.983154296875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 2015.5604248046875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 7685.70068359375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1645.591552734375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1055.2783203125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 2064.252685546875 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1823.064453125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1192.30029296875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 920.2473754882812 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 4808.46826171875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 612.0671997070312 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1124.22900390625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 893.90283203125 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 7118.23583984375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 5589.36328125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 2036.697265625 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 2251.45703125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1629.8074951171875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 877.4320068359375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1601.2222900390625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1985.2945556640625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 7590.55517578125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 520.1220092773438 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1515.7447509765625 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 730.49951171875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 673.7111206054688 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 626.8427734375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1023.0239868164062 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 525.7044677734375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 859.5079956054688 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1800.27099609375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2161.731201171875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 715.215576171875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 559.5409545898438 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 842.2689819335938 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 3723.687255859375 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1142.2794189453125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 851.28466796875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 940.32666015625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 624.4379272460938 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 825.4423217773438 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 900.0306396484375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1123.3563232421875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 901.0264892578125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 756.37353515625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 827.228759765625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1076.2535400390625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 966.0105590820312 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 687.8034057617188 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1045.355224609375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2380.58056640625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1009.742919921875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 690.7675170898438 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 901.0463256835938 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 2138.927734375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 950.5836791992188 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 914.9635009765625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 636.2492065429688 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1050.364501953125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 929.5498046875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1668.7130126953125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 562.9613037109375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1255.1573486328125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1562.7723388671875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 763.2340087890625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 754.70703125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1424.4796142578125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 970.7003173828125 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 837.1991577148438 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 990.8659057617188 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1038.1610107421875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 827.44677734375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1455.46337890625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1115.199951171875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 689.108154296875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 919.7216796875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1215.7347412109375 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 883.7864379882812 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1590.387451171875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 975.713623046875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 754.0386962890625 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 777.0106811523438 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1220.891357421875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1564.1385498046875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 768.8386840820312 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 431.454833984375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 626.4464111328125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1661.0010986328125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1750.6612548828125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 552.6290283203125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 343.2318115234375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1259.991455078125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 695.9993286132812 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1617.263671875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 721.25146484375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 928.2537231445312 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1258.494873046875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1685.7799072265625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1298.618408203125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1470.797119140625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1571.80859375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 694.5272827148438 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1554.283203125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1980.149169921875 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1140.45361328125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1428.3717041015625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 2150.208251953125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1085.177978515625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 2498.016845703125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1242.7850341796875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 3144.623291015625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 2289.38916015625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 828.5309448242188 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 902.0775756835938 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 2464.255126953125 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1095.5419921875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 783.1513671875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 844.5599365234375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1114.8262939453125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 6609.35791015625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 796.1605834960938 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 860.71630859375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1943.6036376953125 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1211.8448486328125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 774.0402221679688 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 2543.692626953125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 916.4344482421875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 741.546875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1197.876220703125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1312.33837890625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 905.5189819335938 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 881.3546752929688 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1005.7398681640625 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1301.5816650390625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 3483.591552734375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 1061.4825439453125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 899.2941284179688 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1013.0599365234375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1370.4110107421875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 3444.219970703125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1051.471923828125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1095.3389892578125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1427.8580322265625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 747.4966430664062 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1349.7808837890625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1591.20703125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1043.03173828125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1120.932373046875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1290.9281005859375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 635.8790893554688 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1159.1859130859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 430.00665283203125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1514.5518798828125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 816.35595703125 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 574.7169189453125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 2196.4619140625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 2778.7568359375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 951.1835327148438 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 805.09033203125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 911.15576171875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 907.81787109375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1691.2303466796875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1233.587890625 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1576.2449951171875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1553.950927734375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1280.9256591796875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 740.8853149414062 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 953.240966796875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1243.443359375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1276.9071044921875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1278.51953125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1369.4439697265625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 932.0330810546875 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1496.093505859375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 1218.72412109375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1679.8292236328125 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1989.92333984375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1828.785400390625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 986.4232177734375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 956.227783203125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1556.9244384765625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 959.5869140625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1313.398681640625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 769.08740234375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 535.19580078125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1032.0655517578125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 662.1483764648438 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1005.1268920898438 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1139.4881591796875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 648.7373657226562 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 1894.9237060546875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1256.396728515625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1549.24169921875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1475.5550537109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1448.227294921875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1712.5003662109375 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 972.8926391601562 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1856.673095703125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1054.7332763671875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 521.1294555664062 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1842.7606201171875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 2170.380126953125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 2549.54833984375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 912.0626220703125 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 985.9403076171875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1515.171142578125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 4202.8720703125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 925.779296875 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 932.7745361328125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2016.4093017578125 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 2415.704345703125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1210.8756103515625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1058.5595703125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 775.7683715820312 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1400.670654296875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1847.5479736328125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1566.4599609375 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1014.164794921875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1553.82275390625 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 2966.599853515625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1099.724853515625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 981.9800415039062 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1336.7078857421875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 822.0546264648438 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 929.2881469726562 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 2089.36474609375 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1283.435791015625 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 518.1825561523438 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 747.437255859375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 723.72900390625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 635.4810791015625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 906.3977661132812 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1093.9417724609375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 588.265380859375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 922.9605712890625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1384.38671875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 936.451171875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1778.0013427734375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1805.8707275390625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1380.218505859375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1227.9373779296875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1821.7044677734375 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1166.136474609375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1111.0631103515625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1362.67236328125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 616.346923828125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 2020.4036865234375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1597.522216796875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 910.1906127929688 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 983.8414916992188 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2192.689697265625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1025.2093505859375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: -8676.3056640625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1042.9779052734375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 528.7291259765625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1303.5509033203125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1744.4395751953125 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 745.1964111328125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 781.037353515625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1827.6307373046875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 2331.42578125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1530.1484375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1416.302978515625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 561.80126953125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 778.1784057617188 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1766.7274169921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1138.923828125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 711.3275756835938 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1198.428466796875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 784.0174560546875 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 819.2708129882812 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1290.7857666015625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 767.237060546875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 502.32733154296875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 664.6464233398438 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 793.7097778320312 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1193.614501953125 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 702.2447509765625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 815.159912109375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 441.1123046875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1136.4105224609375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 773.7708129882812 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 615.3951416015625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 670.9225463867188 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 663.3413696289062 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1723.8970947265625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 2636.470458984375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1007.6746215820312 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 639.674072265625 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 935.1238403320312 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1600.39404296875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 760.9802856445312 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1219.56982421875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 543.462890625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 700.5641479492188 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1526.3153076171875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 909.4017333984375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 735.857666015625 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 718.9783935546875 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1152.921875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1033.366455078125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1546.8560791015625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 687.9132690429688 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1117.4097900390625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1317.4271240234375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1155.2496337890625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 938.5608520507812 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 699.078857421875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 577.845458984375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 717.967529296875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1263.4620361328125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1177.8321533203125 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 818.8583374023438 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1148.181396484375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 952.5118408203125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 893.885498046875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 2244.386962890625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1042.37060546875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1427.74267578125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1241.659912109375 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 733.7024536132812 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1704.5234375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1124.8717041015625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1312.31494140625 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 632.4257202148438 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1650.470947265625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1505.228271484375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1253.889892578125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1599.795166015625 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 656.176025390625 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 659.6989135742188 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1395.5789794921875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 8321.5458984375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1070.4085693359375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 888.4688720703125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 759.6229858398438 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 554.8099365234375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 669.4611206054688 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 988.0426635742188 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 740.20263671875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1226.7237548828125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 411.89703369140625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 953.9907836914062 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 831.529541015625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:24:23<105419:26:41, 1265.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 739.2103271484375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 653.6482543945312 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 733.9569091796875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1222.999755859375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 432.6592102050781 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 455.9900817871094 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 669.7667846679688 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 984.7442016601562 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 581.0574340820312 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 576.3468627929688 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1042.283935546875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 786.6644287109375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1320.3170166015625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1723.017333984375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 784.761474609375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 811.0428466796875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1252.3028564453125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 896.1829833984375 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2758.9892578125 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1205.2742919921875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 689.637451171875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1554.3089599609375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 635.3490600585938 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1174.7509765625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1628.9847412109375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 2303.9462890625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 867.7361450195312 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 3368.2099609375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1400.375732421875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1008.9710693359375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1194.185791015625 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1874.4163818359375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1381.147216796875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 627.224609375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1114.4503173828125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1017.1575927734375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 867.6575927734375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 548.1049194335938 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1114.7030029296875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 789.1068725585938 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 846.96728515625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1197.50830078125 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 880.1564331054688 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1265.478515625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 846.9321899414062 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 913.6541748046875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 878.03662109375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1310.6572265625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1196.52001953125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1422.870361328125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 10616.1904296875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1952.5526123046875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1264.98291015625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 2815.353271484375 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1097.8704833984375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 808.993408203125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 698.3487548828125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1018.2943725585938 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1062.5806884765625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1313.48193359375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1606.23876953125 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 704.6647338867188 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 2199.84423828125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1106.68359375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 941.8491821289062 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 780.7640380859375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1171.479736328125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1645.19189453125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1183.266845703125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 943.1302490234375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 804.0697021484375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2876.525634765625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1920.850830078125 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 823.2750244140625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 706.7429809570312 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1043.6187744140625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 3482.614990234375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 891.8259887695312 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 575.9196166992188 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1444.9248046875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 746.1796875 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1139.045654296875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1418.8990478515625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 669.8822631835938 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 575.4752197265625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1259.111328125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1070.71337890625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1280.7899169921875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 736.8523559570312 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 865.42529296875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 2274.309814453125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1080.69140625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 675.1807250976562 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 914.5625610351562 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 1443.1878662109375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 6811.57861328125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1135.6810302734375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 732.6176147460938 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2058.4775390625 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 5334.38916015625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 845.1780395507812 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 914.893798828125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 790.604248046875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 779.0288696289062 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1228.158935546875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1447.19287109375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 861.0712890625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1129.6392822265625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1314.797607421875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 1210.2305908203125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 945.8917846679688 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1988.8515625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1028.991455078125 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 2703.793212890625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1396.2467041015625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1436.9306640625 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1832.05322265625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1301.548583984375 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 3490.174560546875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 6722.736328125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 6259.77685546875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1357.3834228515625 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1742.9097900390625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1436.1090087890625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 2306.300048828125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 731.7178955078125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1000.1068725585938 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1498.6375732421875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1189.1119384765625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1107.82568359375 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 749.536865234375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 2247.5693359375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 850.7742309570312 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1421.857666015625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 659.8025512695312 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 805.69921875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 919.9776611328125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 919.0015258789062 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 779.8140869140625 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1079.22607421875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 783.9048461914062 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 767.280517578125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1568.3094482421875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1151.6322021484375 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 610.5445556640625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 631.1323852539062 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1337.724365234375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 840.8463134765625 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1079.7125244140625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 657.0681762695312 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1127.2899169921875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1602.81201171875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1388.7435302734375 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 454.00665283203125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 859.6278076171875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1164.5848388671875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 931.2548828125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 928.0655517578125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 853.1580810546875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1051.3658447265625 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1578.426513671875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1546.0616455078125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1103.570556640625 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 973.1841430664062 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 759.6442260742188 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1073.7904052734375 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1194.73095703125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 819.7293090820312 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 873.3331298828125 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 793.0276489257812 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 701.0062255859375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 908.7509765625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1149.5699462890625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 759.2002563476562 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 891.234375 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 583.7171020507812 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1518.0404052734375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1220.7864990234375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 805.5827026367188 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 849.4434204101562 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1606.712890625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 996.7468872070312 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 907.15625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1131.9949951171875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 705.5772094726562 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 426.2516174316406 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 753.3343505859375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 864.2223510742188 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1802.305908203125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1305.5836181640625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 560.0990600585938 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 884.8578491210938 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1028.1070556640625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 988.4002685546875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 767.1783447265625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 803.7115478515625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1722.1256103515625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 716.485595703125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1820.809326171875 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 856.3565673828125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1207.708984375 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1077.1590576171875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 891.3316650390625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1414.480712890625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 927.1212158203125 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1452.702392578125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1284.62646484375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1498.038330078125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 916.2696533203125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1032.762939453125 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1307.286376953125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1607.620849609375 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 712.2434692382812 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 916.8198852539062 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1663.914306640625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1328.5823974609375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1343.9991455078125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2012.4219970703125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1265.752197265625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 950.4304809570312 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 2618.241943359375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 3761.025634765625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 903.8775634765625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1914.0413818359375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1478.46337890625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1238.59521484375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1119.7789306640625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1069.9739990234375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1188.5943603515625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 792.6185913085938 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1086.6641845703125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1189.6644287109375 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 758.0115966796875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 931.9368896484375 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 806.570068359375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1630.4412841796875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1453.4493408203125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1077.2850341796875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1008.5042724609375 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1552.2742919921875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 880.1238403320312 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1459.435791015625 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1000.39794921875 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1108.09765625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1099.6673583984375 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 675.4115600585938 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 956.3351440429688 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1364.142578125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1480.01171875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 891.85107421875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1166.543212890625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 974.474853515625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1567.70849609375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1518.217529296875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 724.0492553710938 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1820.5185546875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1244.7347412109375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1308.6385498046875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 979.8072509765625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1271.0980224609375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 535.5138549804688 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 608.6935424804688 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 2065.177734375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1270.8489990234375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 703.5148315429688 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1125.65283203125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 690.4059448242188 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 875.88916015625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1448.873291015625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 992.8057861328125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 728.6087036132812 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1819.6597900390625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 699.2628173828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1014.5679931640625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 498.8116455078125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1493.8392333984375 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 3360.6162109375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 968.9417724609375 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1121.07421875 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 890.239501953125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1145.5 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 2211.0439453125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 659.1508178710938 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1099.2066650390625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1472.8155517578125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1293.4576416015625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 921.982177734375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1072.10888671875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 938.2683715820312 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1096.239990234375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1313.0594482421875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 953.408447265625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 608.63818359375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 747.2216796875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 7371.9248046875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1125.8995361328125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 852.8277587890625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 650.8336791992188 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 708.89697265625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 707.4921264648438 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 791.5115356445312 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 714.2711791992188 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 871.9446411132812 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 941.3820190429688 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 988.1822509765625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1280.0845947265625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1584.9029541015625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 672.966796875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 917.1923828125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1049.6346435546875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 621.7926635742188 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 891.5676879882812 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1604.360595703125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 631.1134643554688 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 758.5957641601562 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 955.646728515625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 962.768798828125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1015.7821044921875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 829.9217529296875 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 860.1004638671875 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 853.983154296875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 946.4639282226562 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1197.370361328125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 745.060302734375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 586.83056640625 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 658.0252075195312 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1247.9381103515625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 608.5654907226562 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 860.0842895507812 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1058.7723388671875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1278.250244140625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 3815.579833984375 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 741.8178100585938 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 682.6390991210938 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 843.1524047851562 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1162.681884765625 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1136.188232421875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1386.6436767578125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 994.078369140625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 936.1908569335938 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1710.7276611328125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 3111.546630859375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 2003.6492919921875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2014.8935546875 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1477.1710205078125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1159.6065673828125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1540.131103515625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1918.408935546875 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 993.7976684570312 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1974.2149658203125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 741.557861328125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 2058.127685546875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2020.4188232421875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1313.7928466796875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1166.9840087890625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 843.3223266601562 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2012.9405517578125 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 614.0288696289062 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 2676.602294921875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1493.516357421875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1195.3377685546875 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 780.1767578125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 788.6640625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 3212.33056640625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 2802.32177734375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 955.9087524414062 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1505.3721923828125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1022.5676879882812 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 856.09814453125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1796.71240234375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 539.5779418945312 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 468.5759582519531 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 634.0430908203125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 650.7655029296875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 643.0665283203125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1656.3172607421875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 781.5767822265625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1541.2044677734375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 870.1532592773438 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 858.8665771484375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 717.2130126953125 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 531.5191650390625 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 978.4916381835938 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1708.71728515625 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1006.3705444335938 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1207.6478271484375 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1709.0313720703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1056.2755126953125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 942.15673828125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1365.05419921875 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 869.0162353515625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1437.714599609375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1387.0908203125 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 618.7041625976562 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 2623.593017578125 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1738.8253173828125 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1649.060546875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 901.07666015625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1045.639892578125 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1447.0679931640625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1300.626708984375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1892.1484375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 850.1821899414062 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1211.96826171875 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1561.3028564453125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1423.86669921875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 4989.26904296875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1183.73828125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2594.06298828125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1283.216064453125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 2933.91796875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 4950.6572265625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1682.080078125 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1011.6818237304688 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 2158.74853515625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1481.3638916015625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1942.9503173828125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1751.4718017578125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1527.96533203125 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 74049.2578125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: -30735.22265625 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1935.8797607421875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 2853.629638671875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1174.2603759765625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 3866.09423828125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 3026.928466796875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 945.5773315429688 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 653.4384155273438 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2379.09130859375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 2218.83349609375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1621.7152099609375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 919.9471435546875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1452.0875244140625 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: -23558.970703125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1727.4608154296875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1587.6995849609375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1353.3857421875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1914.8690185546875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1249.9488525390625 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1321.8477783203125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1104.56005859375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1608.606689453125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2420.327392578125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1545.8450927734375 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 922.305419921875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1853.689208984375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 825.6982421875 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2031.2635498046875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 765.3320922851562 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 739.3297119140625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1354.6636962890625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 715.3701171875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1170.7083740234375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1087.9832763671875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1514.37353515625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1345.09033203125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1684.185791015625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1129.62548828125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1251.9970703125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1747.7412109375 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 991.1546630859375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1262.3126220703125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1165.067138671875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 746.9939575195312 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1540.021728515625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1292.284912109375 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1268.33203125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 555.88623046875 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 897.8881225585938 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1414.303955078125 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1486.7799072265625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 748.7276000976562 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 912.1939697265625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 615.0098266601562 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 851.25634765625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 718.5049438476562 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1260.805419921875 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1096.4366455078125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1206.245849609375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 819.9215087890625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1155.5540771484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 754.5986938476562 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 630.2002563476562 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1129.080078125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1110.25 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1407.5032958984375 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 756.5089721679688 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 834.3546752929688 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1037.283935546875 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 698.0961303710938 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1962.5494384765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 755.3184204101562 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1355.8331298828125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1190.2303466796875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1415.8900146484375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 771.78271484375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1634.882080078125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1025.2724609375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 820.7655029296875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1281.8250732421875 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1514.9969482421875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 935.281005859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1187.2724609375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1079.10302734375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 3018.2265625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2093.834228515625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1056.4012451171875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1262.0657958984375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 864.482666015625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1328.653564453125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1568.9775390625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1535.8829345703125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 2717.487548828125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1204.8184814453125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 4554.56640625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1049.678466796875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 965.4154663085938 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1296.9412841796875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1091.2830810546875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1114.626953125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 777.1013793945312 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1393.0430908203125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1342.586181640625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 567.9963989257812 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 814.9647827148438 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 531.593017578125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 827.45458984375 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 656.803955078125 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 601.7432250976562 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 741.6565551757812 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 772.0709838867188 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 910.3421020507812 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 491.7245788574219 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 852.6278686523438 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 887.1227416992188 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 598.160888671875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 951.3737182617188 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 680.4718627929688 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 681.5557250976562 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 712.1205444335938 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 727.959228515625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1324.4674072265625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1071.1605224609375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 435.0902099609375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 426.70709228515625 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 871.0026245117188 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 722.1591796875 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 614.1203002929688 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 463.62713623046875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 535.6912231445312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 739.6409301757812 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1682.865966796875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1420.40869140625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1577.4278564453125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1882.407470703125 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 992.1644287109375 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1438.3798828125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2650.578857421875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 885.5425415039062 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 599.0596313476562 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 657.8471069335938 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 651.7818603515625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1964.2486572265625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 855.4102172851562 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1812.61865234375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1120.330322265625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1627.637451171875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1035.9246826171875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 5247.046875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 3526.2421875 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1281.372802734375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 753.3464965820312 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 5100.29345703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 3198.451416015625 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 781.0512084960938 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1674.2406005859375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 2324.29541015625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1463.1796875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1134.119384765625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 844.3712768554688 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 912.5237426757812 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1349.271728515625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1122.42041015625 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1020.7159423828125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 4249.2109375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1431.7969970703125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1416.1163330078125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 3429.809326171875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 581.9138793945312 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1839.2667236328125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 789.8084106445312 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 2633.849853515625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1646.54345703125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1099.0244140625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 907.4080810546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1689.110107421875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 2007.3577880859375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 940.6649780273438 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1127.1246337890625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1364.8353271484375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1218.6563720703125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 4358.4365234375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 2369.646240234375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1570.061279296875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1454.000732421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1067.974853515625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1521.958740234375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2195.04833984375 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1492.2413330078125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1214.0128173828125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 2900.89404296875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1484.3179931640625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 998.9642944335938 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1274.989501953125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1403.7457275390625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 2616.1279296875 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1198.981201171875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1523.01318359375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 800.0447387695312 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1140.11376953125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1869.3436279296875 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 891.6506958007812 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2136.30322265625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 2086.5439453125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1132.8448486328125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1142.482421875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 878.2811889648438 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1148.297119140625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 912.7667236328125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1556.3016357421875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 583.3359985351562 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 652.0126342773438 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 849.6691284179688 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 639.3930053710938 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1379.629638671875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 899.3931884765625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1079.63232421875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 811.8025512695312 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 971.4014282226562 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1372.4324951171875 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1881.8101806640625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1950.8272705078125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1515.1494140625 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1430.2515869140625 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1248.1253662109375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1901.7574462890625 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1121.403564453125 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 894.7743530273438 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 774.159912109375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 899.2329711914062 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 980.1412353515625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 846.2885131835938 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1430.4073486328125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1224.49755859375 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1017.5725708007812 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 855.8482055664062 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 10270.5341796875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 828.6943969726562 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1034.2344970703125 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 548.4096069335938 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1348.6351318359375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 2193.608642578125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1632.573974609375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 796.6903076171875 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 705.431884765625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 999.8800659179688 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1046.736328125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1246.8619384765625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 867.6129760742188 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 790.46142578125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1337.7952880859375 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1049.7054443359375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1450.9478759765625 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 817.31298828125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 670.2935180664062 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 925.9559326171875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1152.85791015625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1019.3055419921875 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 913.9572143554688 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 2299.677490234375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1281.1690673828125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 677.148193359375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1390.3702392578125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1993.959716796875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 721.916259765625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1511.3232421875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 716.2125854492188 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1376.6380615234375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 2532.205810546875 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1168.5555419921875 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1463.791748046875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 979.1475830078125 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2056.40771484375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 991.5755615234375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1154.7198486328125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:45:32<105558:54:24, 1266.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1431.099853515625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 765.1487426757812 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 3187.507568359375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 907.0603637695312 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 944.46142578125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1765.876953125 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2467.568359375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1053.24658203125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 806.7343139648438 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 792.5269165039062 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1122.659423828125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 3522.732177734375 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1847.4876708984375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 478.34844970703125 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 701.996337890625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1215.0362548828125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1103.294189453125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 868.8233642578125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1414.211669921875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1236.8541259765625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 886.9662475585938 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1230.3868408203125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1006.0126342773438 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1958.4591064453125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 912.8534545898438 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 850.9699096679688 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1257.1368408203125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 682.154296875 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2747.373291015625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 930.5517578125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1808.5731201171875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 2081.96875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1240.284423828125 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1554.430419921875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 766.888916015625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 653.0223999023438 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 709.73095703125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 989.4148559570312 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 888.6320190429688 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1295.22705078125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 531.7694091796875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 847.0502319335938 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 639.1192016601562 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1390.1256103515625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1241.4495849609375 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1567.1978759765625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 854.712890625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1154.994140625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1243.9111328125 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1554.0333251953125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 592.1624145507812 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 6100.73046875 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1749.614501953125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1247.5963134765625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1590.52880859375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1284.5599365234375 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 618.089111328125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1841.4659423828125 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 977.2457885742188 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2511.455810546875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1983.1141357421875 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1341.1717529296875 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 870.1400756835938 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1249.43896484375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1251.9033203125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 699.159912109375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 831.39697265625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1194.3720703125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 866.8963012695312 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1200.003173828125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 627.0542602539062 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1291.2821044921875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 949.9718627929688 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1424.46240234375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 4097.80126953125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 948.1602783203125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1247.0540771484375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 2164.97607421875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1525.2882080078125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1853.7923583984375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1004.551025390625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1376.271484375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 944.6898193359375 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1343.113037109375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 2082.805419921875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1522.2642822265625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1410.6336669921875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2768.43701171875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 2954.612060546875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1455.4259033203125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1471.346923828125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1040.084228515625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 681.3568725585938 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 992.626708984375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 3872.1455078125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1556.8232421875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1292.692626953125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1215.6026611328125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1443.3497314453125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1646.0599365234375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 2831.805419921875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1647.173828125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 729.3735961914062 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1563.41943359375 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 2246.575439453125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 3234.509765625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1722.4976806640625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 2290.24072265625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 3031.09326171875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1128.67578125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 918.8659057617188 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 947.411376953125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1440.597900390625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1054.0 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1063.569091796875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1864.896484375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 822.0985107421875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 947.472900390625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1041.0108642578125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1048.7010498046875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1751.2894287109375 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 800.5678100585938 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1071.943603515625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 856.8858032226562 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 757.875244140625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 575.1177368164062 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 757.2597045898438 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 798.05615234375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1047.1588134765625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 634.6265869140625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1009.4898071289062 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1105.81591796875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1005.1727905273438 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 500.24688720703125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 603.1914672851562 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 886.2742919921875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1093.11279296875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1194.0499267578125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1102.5794677734375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 756.6301879882812 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 718.56689453125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 864.982666015625 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1114.227783203125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1091.6715087890625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 898.3137817382812 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 868.2401123046875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1415.3756103515625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1287.972412109375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 964.529296875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 4564.06396484375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 917.7081298828125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 29401.1328125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 5525.685546875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1918.8465576171875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1413.8525390625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 823.626708984375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1479.4561767578125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1163.6893310546875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 933.7523193359375 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 3435.38671875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1466.93017578125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1787.4263916015625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1111.1741943359375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1490.935302734375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 772.623291015625 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2541.4794921875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 729.6707763671875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 890.4600830078125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1243.40234375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 988.8317260742188 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 711.93310546875 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1065.54052734375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1620.4298095703125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1799.8641357421875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1009.1035766601562 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 2607.866943359375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1795.7000732421875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1600.6827392578125 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 4632.0126953125 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1364.395263671875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 3188.705322265625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1104.1199951171875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1488.186767578125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 847.5072021484375 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 3744.999755859375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2086.077392578125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1175.8033447265625 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 666.831787109375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 652.781982421875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1587.8521728515625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 583.6616821289062 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 871.7614135742188 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 758.7548217773438 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1244.6209716796875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 716.7825927734375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 706.7671508789062 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 841.3895874023438 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 711.0267333984375 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1506.77490234375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1157.297119140625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 722.6903686523438 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1257.419677734375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1579.3665771484375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 949.6996459960938 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 2001.2464599609375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 561.608154296875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1258.936279296875 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 567.2807006835938 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 991.9616088867188 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1074.029296875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1140.7132568359375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 900.1754760742188 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 931.77783203125 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 980.6072998046875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1640.2589111328125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2700.02001953125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1406.403076171875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1110.4228515625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 943.4525146484375 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1483.60986328125 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1019.3118286132812 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1099.986328125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 2085.022705078125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 702.06103515625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1469.646728515625 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 2755.001220703125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1112.2911376953125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1578.2686767578125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1510.8001708984375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1253.9091796875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1488.9490966796875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1091.5625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1631.5728759765625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 791.4423828125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 907.1473388671875 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 948.5595092773438 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 685.4542846679688 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 991.7203979492188 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1313.9962158203125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 603.8212280273438 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 961.5651245117188 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1018.9124755859375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1715.5301513671875 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 579.1441040039062 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 833.940185546875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2468.11279296875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1904.436279296875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 876.5847778320312 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 2150.907958984375 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 899.334716796875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 4337.3779296875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 2621.16748046875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1585.50146484375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 940.616943359375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 919.2127685546875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 871.7415771484375 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1376.335693359375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 3288.96875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 664.3607788085938 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 441.3763427734375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 784.8989868164062 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 379.34716796875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1095.2789306640625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1100.2216796875 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 649.8869018554688 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 974.2296142578125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 469.6352844238281 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 765.5015258789062 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1490.7891845703125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1491.1927490234375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 710.3046875 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1361.9991455078125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 949.5472412109375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 795.8778076171875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 970.8223266601562 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1185.8477783203125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 885.7318725585938 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1391.8414306640625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1701.3299560546875 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 933.830322265625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1923.1612548828125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1289.2918701171875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 983.22314453125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2163.7158203125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 926.5184326171875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 943.460205078125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 323.6719665527344 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1156.56494140625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1590.1370849609375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1838.137939453125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1458.9464111328125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1049.0054931640625 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 2019.991943359375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1180.1822509765625 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1094.549072265625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 2217.189208984375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 681.77099609375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1996.3651123046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1576.2860107421875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 824.2678833007812 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1461.5509033203125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1975.0966796875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 920.1268920898438 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1737.2977294921875 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1385.9451904296875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 773.6060791015625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 877.1624145507812 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1500.883544921875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1428.268310546875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 859.9152221679688 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1605.3033447265625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1104.93359375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1216.981689453125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1277.0755615234375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1471.9791259765625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1351.615478515625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1288.958740234375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1884.60302734375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1004.9933471679688 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1434.67138671875 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1499.82421875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1214.16015625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1639.2608642578125 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1622.469482421875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 915.3995361328125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 793.849365234375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1117.2332763671875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 935.203857421875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 649.0477294921875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1227.1866455078125 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1140.367431640625 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1435.876708984375 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 689.88330078125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 904.2672729492188 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1040.5126953125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1037.1759033203125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 982.22216796875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1511.79638671875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 739.4881591796875 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 621.5208740234375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1695.6497802734375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1082.38671875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 955.0508422851562 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2226.813720703125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 986.51025390625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1202.6854248046875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1449.66015625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 937.7058715820312 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 639.0354614257812 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 992.1649780273438 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1046.792236328125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1275.640625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 833.9255981445312 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 715.9558715820312 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 637.0595092773438 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 860.480712890625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1069.0054931640625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1351.970703125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 2020.052734375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1164.0906982421875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1246.2193603515625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1090.1837158203125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 2221.34228515625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1689.79296875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 913.876220703125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1538.944580078125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1322.2081298828125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2543.686767578125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1367.1253662109375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1908.436279296875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1662.6846923828125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1176.4483642578125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2833.861572265625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1533.633544921875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 782.244873046875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1785.204833984375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1474.4915771484375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 2013.4783935546875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2819.70849609375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 926.1250610351562 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1124.79443359375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1160.5262451171875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 996.5917358398438 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 2927.098388671875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1250.7183837890625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1571.0185546875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 769.7867431640625 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 830.7095336914062 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1307.7535400390625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 850.01123046875 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 888.8060302734375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1212.949951171875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 997.2500610351562 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 2029.1510009765625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 2206.55029296875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 903.7720336914062 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 43649.78125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1087.356201171875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1131.5003662109375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 985.1676635742188 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2047.006103515625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 3016.5615234375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1025.4923095703125 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2338.64013671875 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1016.0208129882812 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2037.0450439453125 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1835.655029296875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1371.6951904296875 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1128.349853515625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1960.28076171875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 847.9480590820312 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 11063.9296875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1542.09228515625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3733.642822265625 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 815.8862915039062 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 695.2493286132812 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1420.1522216796875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1649.3529052734375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3832.251953125 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 161075.84375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1324.25537109375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1253.549072265625 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1596.6015625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 976.8724365234375 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1094.55224609375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2218.699951171875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 2111.575439453125 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 856.875732421875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1373.04052734375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1111.864990234375 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1520.9384765625 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 861.659912109375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 893.225341796875 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 3084.43017578125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1191.2198486328125 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.758, loss_val: nan, pos_over_neg: -16088.646484375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1284.332275390625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 3711.01416015625 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1040.8206787109375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1357.0677490234375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1417.52197265625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1284.1705322265625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 682.2977294921875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 570.9345092773438 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 940.895263671875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 3222.39404296875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 5081.81298828125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1302.0816650390625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 507.9853515625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 934.8577880859375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1017.9141235351562 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2021.0487060546875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 535.77587890625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 702.432861328125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1238.1597900390625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 957.2254028320312 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 2078.6748046875 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1146.58251953125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 4565.84765625 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1217.8321533203125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1471.8577880859375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 773.48974609375 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 6926.43408203125 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 899.3017578125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1377.65576171875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1008.6676635742188 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 841.0965576171875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 776.3513793945312 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 922.9591674804688 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 4326.74169921875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 849.6723022460938 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1117.1595458984375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 849.1199340820312 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 838.294921875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1181.7052001953125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 675.7449340820312 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1896.853759765625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1118.9635009765625 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 622.1959838867188 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 812.4579467773438 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1276.0263671875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 750.8877563476562 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 583.729248046875 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 848.7839965820312 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 803.9567260742188 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1035.560791015625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 946.8121948242188 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1078.0836181640625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1437.564208984375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 851.5879516601562 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1577.5054931640625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1182.0833740234375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1507.806640625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 869.0042724609375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1977.4090576171875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 970.1253662109375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 832.0559692382812 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 3884.84814453125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 4525.703125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1019.6663818359375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 562.3847045898438 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1133.1461181640625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 850.2865600585938 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 976.7584228515625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 863.1079711914062 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 987.8658447265625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 936.1034545898438 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1183.2978515625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 845.4620361328125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1185.162353515625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1107.951171875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 908.76318359375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1187.75537109375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 924.6522216796875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 675.590576171875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1588.077880859375 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 912.008056640625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1105.1044921875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 829.465576171875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1087.5081787109375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1196.5244140625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1156.86962890625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1065.439697265625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 919.6829223632812 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 839.7154541015625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1805.5706787109375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1318.5545654296875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2571.22802734375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1189.6207275390625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 3335.03076171875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1442.6761474609375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1284.60888671875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2381.3427734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 889.05859375 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 2312.14111328125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2639.904296875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2767.013916015625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1608.7822265625 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1538.6414794921875 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1065.4388427734375 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1177.50048828125 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1603.5528564453125 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1611.6590576171875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1230.2763671875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 952.0868530273438 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1748.4222412109375 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1451.3409423828125 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1359.6025390625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 923.283203125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1284.881103515625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1254.8692626953125 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1114.67822265625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1977.7054443359375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1435.1826171875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 645.4007568359375 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 992.3388061523438 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1462.769287109375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1324.8983154296875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 962.6423950195312 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1310.448486328125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1501.4730224609375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 980.4105224609375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 3171.62841796875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1547.1932373046875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 701.3136596679688 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 2787.397216796875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1201.9830322265625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1162.95166015625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1241.735107421875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 908.557861328125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1442.979736328125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1229.6202392578125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 867.5157470703125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1416.7789306640625 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1824.8670654296875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1416.5865478515625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 772.592529296875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1282.0433349609375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2495.26611328125 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1383.885986328125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1135.9647216796875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1420.4886474609375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 855.3645629882812 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 767.550537109375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1202.760009765625 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1379.359375 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1016.395263671875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1058.586181640625 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1036.1507568359375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1400.7147216796875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 814.455810546875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 3002.612060546875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1060.2740478515625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2820.98291015625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1241.1593017578125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 937.8500366210938 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 176364.453125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1064.083984375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1640.057861328125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 3370.0244140625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1108.399169921875 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 4705.68212890625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1118.0723876953125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 721.248779296875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1675.2398681640625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 541.1571044921875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 987.0861206054688 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1971.472900390625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1132.156494140625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 973.0776977539062 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1919.3380126953125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1477.465087890625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1165.581787109375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1056.0283203125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1588.428955078125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 712.0059204101562 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 939.1487426757812 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 3659.324951171875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 940.1064453125 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1058.6212158203125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 2450.515869140625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 3701.789306640625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1322.2874755859375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 988.3677368164062 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1196.955810546875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2181.706787109375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2321.43505859375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2299.170166015625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 4215.80126953125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1121.0606689453125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1517.717529296875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1426.843017578125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 756.25830078125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 940.0293579101562 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1141.0411376953125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 616.2516479492188 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 708.123291015625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 702.4962158203125 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1179.7169189453125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 576.292236328125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 484.5174560546875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 546.6392211914062 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 412.63067626953125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 860.1575927734375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1807.796630859375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1064.350341796875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1118.27294921875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 586.3687133789062 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 896.6860961914062 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1566.5157470703125 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1023.3674926757812 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 890.77294921875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 617.8565063476562 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 544.6550903320312 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 882.0662231445312 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1106.3863525390625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 828.445556640625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1050.81201171875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1241.8941650390625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 841.8419799804688 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 2083.548095703125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 995.701416015625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 895.822509765625 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1391.3238525390625 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1612.7906494140625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 846.8960571289062 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 584.65283203125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 717.2196655273438 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 967.7354125976562 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 983.9880981445312 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1027.9508056640625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 2537.8046875 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 689.322021484375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1741.9482421875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 615.5110473632812 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1132.884033203125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1635.046630859375 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 723.256591796875 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1704.0238037109375 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1387.30126953125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 919.5557250976562 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1899.76708984375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1217.0704345703125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 707.7980346679688 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1494.915283203125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 2441.123779296875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1300.2860107421875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1441.2845458984375 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 941.6084594726562 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1020.2988891601562 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1342.5234375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1848.482666015625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1145.753662109375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1736.1363525390625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1069.6026611328125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:06:33<105385:42:29, 1264.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2585.496337890625 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1069.0421142578125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 3873.705322265625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1273.3228759765625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2976.782958984375 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2552.41064453125 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1025.0238037109375 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1144.614501953125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 2395.68505859375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1902.3817138671875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2181.73388671875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1408.593994140625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 4371.87158203125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1689.47021484375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 693.5455322265625 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 2264.97216796875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1672.6748046875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1218.9613037109375 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1535.2431640625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1096.283447265625 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1653.425537109375 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 953.505126953125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1442.039306640625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1630.656494140625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2006.346435546875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 4546.533203125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2169.468505859375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1306.175048828125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3197.21728515625 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 2428.896728515625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 852.4268188476562 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1036.021240234375 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 931.712646484375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 2277.9609375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1498.9996337890625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1077.721435546875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 11262.0859375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 3147.7275390625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1340.1038818359375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1082.962158203125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1562.2265625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1511.603515625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 2057.065673828125 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 14380.22265625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2538.801025390625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2432.2333984375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 4226.787109375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1860.36865234375 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 950.7725219726562 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 668.6873168945312 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1022.76220703125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2146.384521484375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1797.201416015625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 3247.27197265625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 843.9199829101562 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1447.2467041015625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1530.3839111328125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1671.0498046875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1524.1719970703125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1303.5146484375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1068.6546630859375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1371.7689208984375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1141.3082275390625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 7278.1923828125 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1615.0050048828125 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 12803.0234375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2540.474609375 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1595.5260009765625 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 608.3079833984375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1172.6767578125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3912.472900390625 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1709.0506591796875 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1095.01171875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 893.02880859375 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 2306.783203125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1045.0069580078125 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1095.9769287109375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 939.376953125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1870.9283447265625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 848.3788452148438 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 606.4318237304688 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2941.5048828125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1349.4072265625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 4054.243408203125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2286.6123046875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1150.065673828125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1429.5439453125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1063.1524658203125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1566.634765625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 7096.8193359375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 948.2565307617188 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 4179.99072265625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1356.8607177734375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 846.83251953125 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1148.848388671875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 2440.779052734375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1112.37109375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 3153.60693359375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 812.2496948242188 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: -10285.158203125 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 2654.09130859375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1720.527587890625 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2683.528076171875 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 940.594970703125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1042.9415283203125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1083.9989013671875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 3182.634765625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1252.031982421875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 715.728271484375 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1003.620361328125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 2284.5029296875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1076.69482421875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 683.2523193359375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 661.4202880859375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 3816.35400390625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 895.0419921875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1206.6478271484375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1293.1451416015625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1244.9991455078125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1352.754638671875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 904.3787841796875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1145.3275146484375 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 824.4722900390625 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2276.150146484375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 5470.337890625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1264.12646484375 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1162.023193359375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1819.863525390625 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 8362.66015625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 676.6637573242188 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 889.0394897460938 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 796.1898193359375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1292.83935546875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 2124.710205078125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1549.443359375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1376.556640625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 2991.931640625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1457.8095703125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1649.1046142578125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 3207.212646484375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1883.68603515625 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 3603.18408203125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1461.7342529296875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 637.7913208007812 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 996.0093383789062 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1090.3157958984375 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 913.7430419921875 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1319.1826171875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1451.75390625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2349.705810546875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1497.74755859375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1354.7940673828125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1066.125244140625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1664.67724609375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2275.8505859375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 985.7883911132812 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1758.529052734375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1188.0511474609375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1506.916748046875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1236.1087646484375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1972.5479736328125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3569.33544921875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 3183.4267578125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 879.9063110351562 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 724.3157958984375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 4387.5888671875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1077.4830322265625 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 698.0292358398438 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1453.457275390625 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 873.4169311523438 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 835.6842041015625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 938.3556518554688 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 728.9712524414062 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1009.020263671875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 850.3628540039062 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 997.0931396484375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 707.2303466796875 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 543.3615112304688 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 657.8228149414062 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 730.6151123046875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1578.8184814453125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 624.825927734375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 405.051513671875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1003.1002807617188 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 940.716552734375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 591.2001953125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 653.8900146484375 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 2324.0537109375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1563.9925537109375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1148.136474609375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 553.9855346679688 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1591.295654296875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 2588.08642578125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1457.7060546875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 804.309326171875 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 4592.7373046875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 2194.408935546875 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1258.0963134765625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1003.1661987304688 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1576.5623779296875 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 718.00048828125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1818.046142578125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1283.1004638671875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2433.500732421875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 890.2391357421875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 3304.5263671875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1067.632568359375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1311.9344482421875 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1359.013427734375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 909.5530395507812 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1014.6167602539062 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 3927.873046875 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1271.8734130859375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1142.5284423828125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 803.1341552734375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 993.4262084960938 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2537.76611328125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1279.7662353515625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 822.5660400390625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1603.21044921875 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1306.74462890625 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 755.4737548828125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 965.1015625 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 907.4097290039062 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1036.4642333984375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 747.7901611328125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1291.7213134765625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 859.7237548828125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1468.254150390625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 3135.0546875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1191.8345947265625 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 626.7084350585938 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1248.45068359375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1551.336181640625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1653.9593505859375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1775.5330810546875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1217.919921875 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2201.521484375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 514.4207153320312 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1673.2501220703125 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 11764.908203125 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1305.401123046875 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1342.0089111328125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1352.3253173828125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: -104884.625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2187.641845703125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2696.658935546875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 3629.901611328125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 6944.6044921875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 2665.0439453125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1936.6162109375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 536.4564208984375 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1978.1168212890625 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1090.992919921875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1421.216064453125 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1926.196044921875 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 847.6610107421875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 1285.218505859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 3083.09033203125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1014.667724609375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 891.0624389648438 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 751.671630859375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1721.7664794921875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1114.4755859375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 727.3795776367188 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1254.9205322265625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1196.867919921875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1707.4185791015625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1544.256103515625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1328.632080078125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1207.784912109375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1381.234619140625 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 2805.9912109375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1578.65087890625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 856.39013671875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1315.4276123046875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 874.9989624023438 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 657.078125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3131.77197265625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2691.984619140625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1576.0758056640625 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1226.2266845703125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 896.4902954101562 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2491.501953125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1329.3197021484375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1731.5343017578125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1510.914794921875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 992.6923828125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 581.9490966796875 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1091.060546875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 5682.2529296875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1031.5638427734375 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1678.39111328125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 801.70361328125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1235.360595703125 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1731.196044921875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1428.38427734375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 2955.213134765625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 2703.459228515625 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2387.864501953125 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1873.730224609375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1014.0980834960938 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1278.100341796875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 903.3161010742188 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 2476.115234375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1618.74267578125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1171.9150390625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 874.3596801757812 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1496.3466796875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 969.8408203125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1493.10595703125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.753, loss_val: nan, pos_over_neg: -10761.21484375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1517.622314453125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1026.254638671875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 680.3370971679688 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1230.364501953125 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 2704.544921875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 992.5192260742188 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 763.915771484375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1417.380859375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1325.1260986328125 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2033.8421630859375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1664.343505859375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1374.8551025390625 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1258.237060546875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1101.1898193359375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1873.1240234375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 981.2356567382812 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1067.9949951171875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 855.6306762695312 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 966.96533203125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 806.169921875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1059.8931884765625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1176.8245849609375 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1823.954345703125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1193.141845703125 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1138.8551025390625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2288.436279296875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1512.635009765625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 982.0906982421875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 981.0663452148438 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1142.005615234375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1885.6973876953125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1384.443359375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1035.6075439453125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 573.6614379882812 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 913.1776123046875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1144.1793212890625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1613.1754150390625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 668.2745971679688 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 593.2440185546875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1624.6217041015625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 778.3511352539062 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 876.1387329101562 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1185.0318603515625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1144.6883544921875 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1778.2315673828125 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 876.1315307617188 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1043.5372314453125 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1306.6168212890625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2037.2210693359375 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1008.054443359375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1674.689697265625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 871.01904296875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 946.6915283203125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 955.0111694335938 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 587.6868896484375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1063.6656494140625 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 3018.470947265625 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1790.2054443359375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1516.7998046875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1818.944580078125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 4633.828125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 2070.072509765625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1124.10693359375 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1637.9569091796875 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1584.9010009765625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1853.940673828125 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 16028.1435546875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 931.41748046875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1417.3421630859375 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1646.0362548828125 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 2746.529296875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 8689.9794921875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1168.88037109375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 3039.861572265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 5630.90234375 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1043.707763671875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1075.6290283203125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 783.1508178710938 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1981.8201904296875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 3312.621337890625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1350.182373046875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1223.79931640625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1097.4525146484375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1103.4722900390625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1065.781494140625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 2646.47802734375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 881.8468627929688 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1290.592529296875 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 2304.728759765625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1157.1248779296875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1429.0299072265625 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1820.958740234375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 681.4248046875 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1029.9915771484375 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 2011.946044921875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1335.703125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1111.810791015625 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1483.74658203125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1526.7510986328125 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 3412.549072265625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: -4536113.5 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1357.7265625 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 965.1082763671875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1783.158935546875 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1242.750732421875 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1327.4339599609375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1732.247802734375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2202.3935546875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1359.18603515625 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1537.57763671875 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 600.2593994140625 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 892.4696655273438 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1899.0263671875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 4412.109375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 3084.132568359375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1042.357666015625 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1240.2567138671875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 781.7025756835938 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1310.7752685546875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 738.2425537109375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 808.9735717773438 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1230.01904296875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 932.0064086914062 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 850.4781494140625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 814.9833374023438 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1134.4925537109375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1063.3475341796875 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1068.4288330078125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 742.0169677734375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 684.4539184570312 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1614.9317626953125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1103.2222900390625 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1050.78369140625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 941.4404907226562 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 698.75244140625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1773.0208740234375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1142.1546630859375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1065.9708251953125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 963.43603515625 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 952.1370239257812 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 3025.38916015625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1948.67529296875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 858.7582397460938 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 571.5906982421875 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1276.71240234375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1012.7308349609375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 993.6289672851562 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 733.5995483398438 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1236.2677001953125 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1662.887939453125 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 2110.62548828125 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 2049.843017578125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 627.1026611328125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1315.103515625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 887.201416015625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 114717.703125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1129.694580078125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 813.767333984375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2799.429931640625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1277.6533203125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 915.006103515625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 804.91552734375 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1452.669921875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 3456.745849609375 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 860.556640625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 992.4623413085938 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 668.1467895507812 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1046.3297119140625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 2916.4326171875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 762.7451171875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1089.673095703125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1345.036865234375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1107.5543212890625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1375.21533203125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 635.5238037109375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1021.740478515625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1187.5787353515625 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1026.4871826171875 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 622.3198852539062 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 868.9507446289062 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 942.9065551757812 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 736.741455078125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 945.4344482421875 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1124.3262939453125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 26420.8984375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1183.912841796875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1125.3287353515625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1607.3099365234375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1571.5264892578125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1077.0140380859375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1837.537353515625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 2474.708984375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1684.791259765625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1801.9637451171875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 863.3595581054688 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1028.642822265625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2033.122314453125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 16160.19921875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 2384.787353515625 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1217.36328125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1096.298828125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 902.339111328125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 4549.01611328125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7398, loss_val: nan, pos_over_neg: 16130.6201171875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 6050.59033203125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1606.0865478515625 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 652.2363891601562 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1152.310791015625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1647.51708984375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1227.5980224609375 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 913.4843139648438 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2642.83642578125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 832.3350830078125 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1258.0113525390625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1188.956298828125 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1702.2894287109375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1340.0537109375 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 770.1312866210938 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1191.4454345703125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1688.7618408203125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1198.60009765625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 807.4884643554688 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1157.6295166015625 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1841.080078125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1060.3428955078125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1018.0818481445312 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 559.9519653320312 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 663.7196044921875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2072.576171875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1629.1776123046875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1483.9049072265625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1887.330810546875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 679.581787109375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1216.9578857421875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 968.3878784179688 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1694.293701171875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 916.7786865234375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 902.1306762695312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 745.0396118164062 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1181.9293212890625 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2073.4873046875 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 3419.384765625 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 982.1222534179688 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1008.7018432617188 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 2154.14892578125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1005.0509033203125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 720.1404418945312 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 939.4847412109375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1705.7188720703125 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 2096.353271484375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1560.0360107421875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 849.5489501953125 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 651.3394775390625 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 8719.89453125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 2452.658203125 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 994.8143310546875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1641.202392578125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 815.1903076171875 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 4714.490234375 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1191.69677734375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1351.77001953125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1333.985595703125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1346.1282958984375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1010.8556518554688 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1153.11767578125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1511.3387451171875 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1733.158935546875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1310.1981201171875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1992.013916015625 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1054.4207763671875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 3509.34033203125 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 3245.5166015625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1516.1055908203125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 874.6221313476562 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 840.3653564453125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1421.23583984375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1569.513427734375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 901.6498413085938 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 821.5924682617188 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1755.9610595703125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 798.3407592773438 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 920.3735961914062 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 921.6552124023438 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 911.341064453125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1051.31689453125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1392.5693359375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 931.4902954101562 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1017.3001098632812 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 860.480224609375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1159.525390625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1091.384033203125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 976.6549682617188 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 772.6597900390625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2499.554931640625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 719.1637573242188 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 738.049560546875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 796.7279663085938 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1178.3966064453125 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1427.4725341796875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1407.9359130859375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 790.206298828125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1402.9141845703125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 904.3031005859375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1222.393798828125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1296.7464599609375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1166.828125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 900.2122192382812 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1038.3756103515625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 2865.3720703125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1429.4178466796875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1152.9183349609375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1250.40673828125 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1549.8162841796875 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1235.96630859375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 658.937255859375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 796.2315063476562 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 963.498779296875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2347.598388671875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1798.853271484375 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 3360.9970703125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 965.1270141601562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 956.9140625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1468.0020751953125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1497.7264404296875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1930.772705078125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1419.2119140625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 889.6922607421875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1384.2261962890625 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1483.6658935546875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 866.9267578125 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1323.0418701171875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2915.326904296875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 795.1110229492188 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1381.96484375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1330.9853515625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1471.953125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1494.7315673828125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1265.827392578125 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 912.69287109375 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 981.1854858398438 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 862.8771362304688 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1110.5919189453125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1711.3995361328125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 907.50927734375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1072.157958984375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 704.9178466796875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1269.7607421875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 779.9134521484375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 1477.6153564453125 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1683.262451171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 555.4287719726562 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 741.7930908203125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 2204.427490234375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1103.9957275390625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 2855.40673828125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 903.722900390625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1342.108642578125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 987.1395263671875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1392.8763427734375 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1022.717529296875 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3274.975830078125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1388.319580078125 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1202.4031982421875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 2279.238037109375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1466.61962890625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1422.246337890625 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1066.0670166015625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1832.736328125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1053.311767578125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1032.3984375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 982.32080078125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1695.879638671875 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1498.1732177734375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 2400.11962890625 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1739.657470703125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1726.7481689453125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1049.1812744140625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1418.713134765625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1920.322265625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1887.6536865234375 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1196.1505126953125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 954.4096069335938 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1441.733154296875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:27:45<105590:34:26, 1267.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 967.9889526367188 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1657.6190185546875 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 2460.54638671875 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1486.33203125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1297.356201171875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1888.7569580078125 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 8103.541015625 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 741.6808471679688 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 714.9130249023438 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1597.3013916015625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1741.596923828125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 597.6911010742188 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 578.7215576171875 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 992.544677734375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 996.8966674804688 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1797.9044189453125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 877.791259765625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 698.4531860351562 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 959.2302856445312 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1496.1044921875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1114.1593017578125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 895.1055297851562 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1036.7261962890625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 889.4019165039062 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1071.5877685546875 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1044.6563720703125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2423.054443359375 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 3212.09814453125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1085.783203125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 1301.9322509765625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2026.42724609375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1759.5848388671875 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1720.6513671875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1374.453125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2308.307861328125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 785.135498046875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 496.57025146484375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 830.2232055664062 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1118.839599609375 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 937.1206665039062 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 989.2242431640625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1148.6109619140625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 961.9535522460938 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 973.5025634765625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1487.1416015625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 14256.0869140625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 4077.81103515625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 764.2704467773438 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1117.3570556640625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2633.64013671875 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1192.651611328125 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 2751.528564453125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1597.88232421875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1387.147216796875 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1166.2269287109375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 611.1776123046875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2462.16064453125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 734.7921752929688 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1737.58154296875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 2162.019287109375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1324.840087890625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 605.6820068359375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 851.0018310546875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 728.25146484375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1232.7884521484375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1208.4996337890625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 782.637451171875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 986.4630126953125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1465.9267578125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 5027.865234375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1177.079345703125 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1244.23828125 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 966.0055541992188 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2868.348876953125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1074.5875244140625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 991.4041137695312 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1204.3115234375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1323.915283203125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1555.374755859375 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 2335.8359375 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1727.47802734375 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1365.7041015625 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1881.700439453125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 11178.521484375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 846.7894287109375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 783.7461547851562 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1116.3209228515625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1600.0281982421875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1707.0509033203125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1835.5550537109375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1190.1951904296875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 3360.30908203125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1184.1510009765625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1652.6116943359375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1423.669677734375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 854.2640991210938 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 776.3240966796875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1043.4906005859375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 929.57958984375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1921.7916259765625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 910.9201049804688 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1531.663818359375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 1333.220458984375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1096.5279541015625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 2051.040771484375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1670.6636962890625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 679.1582641601562 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1062.1708984375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1436.3765869140625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 728.7296142578125 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1672.4022216796875 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1055.397705078125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1457.65234375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1802.1064453125 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1005.6231689453125 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1037.0941162109375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1270.4161376953125 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1051.6148681640625 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1972.1588134765625 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 734.998291015625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 886.8467407226562 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1414.8546142578125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1614.8602294921875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 4782.29638671875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1725.868896484375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 868.8917846679688 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 2213.05859375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1240.3470458984375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1911.99609375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 943.5665893554688 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2068.970458984375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1935.07177734375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 825.6193237304688 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1564.7012939453125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 3651.44677734375 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 2414.74072265625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 942.5271606445312 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 926.69970703125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 904.3182983398438 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1453.317626953125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1502.5872802734375 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1315.7462158203125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1252.116943359375 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1048.3892822265625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 936.5245971679688 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 939.2576293945312 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 2915.02685546875 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: -67266.7109375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1588.2352294921875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2467.793212890625 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1330.7752685546875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1805.156982421875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1397.772705078125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1143.6953125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1505.8150634765625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1075.040283203125 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1157.4267578125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 713.364501953125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 546.5512084960938 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1616.9197998046875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2812.645751953125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1262.8162841796875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 655.594482421875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 854.9681396484375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1296.0538330078125 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 796.8525390625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 898.5757446289062 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 922.0801391601562 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1557.5003662109375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1510.4569091796875 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1053.916015625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1517.861083984375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2052.807373046875 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1187.6551513671875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1230.58203125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2605.42626953125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 610.2487182617188 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1568.20458984375 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1326.1131591796875 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1218.453369140625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 956.3607177734375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1337.3682861328125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1402.7432861328125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1162.8414306640625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1334.132568359375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 817.7276000976562 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 3260.435546875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 10076.49609375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1350.6846923828125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2338.542724609375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1277.8720703125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1199.591552734375 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 636.9894409179688 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 894.1445922851562 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1035.6690673828125 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1120.63134765625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1459.68798828125 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 782.0480346679688 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 956.3076782226562 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 967.5388793945312 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 518.1884765625 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1571.5032958984375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1453.5098876953125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 933.7825317382812 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 944.2190551757812 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 971.9327392578125 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 825.734375 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 853.95068359375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 760.8399047851562 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1286.4296875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 2340.066650390625 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 865.058349609375 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 628.7074584960938 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1785.5865478515625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1515.0946044921875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 2909.591064453125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 746.1345825195312 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 702.987548828125 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1536.74267578125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 2312.95458984375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 2111.904296875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1572.1982421875 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 977.8093872070312 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1523.4759521484375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1061.7806396484375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 718.0179443359375 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 2244.201904296875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1178.401123046875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1142.658935546875 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 651.680419921875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 1152.1973876953125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1025.173095703125 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 3520.396728515625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1409.87841796875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1480.039306640625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1703.135986328125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1366.3729248046875 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1757.1439208984375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1704.6495361328125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1027.866943359375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 569.1434936523438 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1617.6534423828125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1090.8131103515625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1633.5390625 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1947.06982421875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1772.82568359375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 3059.31396484375 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 722.659423828125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 724.0801391601562 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1928.4127197265625 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1759.0855712890625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1169.125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1237.0657958984375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1667.124267578125 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 946.4391479492188 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 796.5834350585938 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 601.288818359375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 974.7509765625 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1192.988037109375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 924.8580322265625 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1142.51416015625 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1607.61767578125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1046.3072509765625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1723.177001953125 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 965.6718139648438 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1050.5396728515625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1365.4849853515625 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1189.0772705078125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 2212.72509765625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 5686.71435546875 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 971.3748168945312 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 798.262451171875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 930.3511352539062 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 924.2298583984375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 968.3650512695312 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 2189.837890625 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 4313.486328125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1804.6241455078125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 957.9290161132812 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 717.78076171875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 996.5848388671875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 987.473876953125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1533.4884033203125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1060.095947265625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1063.396484375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1676.629150390625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 665.8355102539062 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1054.7044677734375 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 2948.84375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 2940.359375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1094.8048095703125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 782.5986938476562 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2237.895263671875 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1376.3272705078125 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 892.661865234375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 979.207763671875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 999.526611328125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 789.6654052734375 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1737.8499755859375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 4112.96728515625 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1595.4805908203125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 810.6373291015625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1695.353515625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1193.13232421875 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1203.196044921875 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 763.661865234375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1951.55712890625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1563.5919189453125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 3010.715576171875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1565.719970703125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1396.99951171875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1071.3214111328125 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1602.843017578125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1215.7275390625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 871.1153564453125 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1128.1614990234375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1090.6319580078125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1896.4237060546875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1387.2584228515625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1350.72265625 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1366.660888671875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1042.1033935546875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 755.1279296875 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 982.0447387695312 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7419, loss_val: nan, pos_over_neg: 1671.5582275390625 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1319.0609130859375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 23932.693359375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1879.0540771484375 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 942.6226806640625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1036.207275390625 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1098.2103271484375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1528.7684326171875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1067.318603515625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1576.816650390625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1617.323974609375 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1305.5242919921875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1508.80712890625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1039.7332763671875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2217.180908203125 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1318.0740966796875 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 978.777099609375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1209.5936279296875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 5679.4677734375 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 4733.36962890625 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1405.0601806640625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1032.8258056640625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1284.90869140625 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1181.0543212890625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 2208.29296875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 877.397216796875 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 977.7403564453125 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 982.9894409179688 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2299.545166015625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 2278.509765625 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1379.498291015625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1673.4112548828125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2970.76171875 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2107.1328125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1925.1087646484375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 2574.254150390625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 2210.759033203125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1858.929443359375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1648.2120361328125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1672.095458984375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 2341.79052734375 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1111.463623046875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1423.5126953125 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1397.1336669921875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 3788.34521484375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1290.9573974609375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1062.309814453125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1249.5574951171875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1924.8289794921875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 765.71875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1064.512451171875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 733.65625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 3660.015625 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1707.462158203125 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 514.9143676757812 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2012.6705322265625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1548.2789306640625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 504.9223327636719 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1150.019287109375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 825.342529296875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2109.089599609375 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1097.529296875 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 433.7658996582031 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 931.588623046875 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1307.1163330078125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2444.578369140625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1190.1424560546875 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1435.936279296875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1869.4661865234375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1048.1156005859375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1405.1015625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1908.80859375 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1521.57666015625 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1839.5880126953125 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 963.7244873046875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1256.3424072265625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2467.31201171875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 10503.9140625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7434, loss_val: nan, pos_over_neg: 7949.44482421875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 957.4435424804688 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2102.126220703125 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 12921.025390625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1425.1102294921875 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 3185.957275390625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 2289.865966796875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1305.400390625 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1787.61279296875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1783.36279296875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 2449.099853515625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1206.3477783203125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1597.34326171875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1167.403564453125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1857.8851318359375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1761.4884033203125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 3281.494873046875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1158.1241455078125 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7377, loss_val: nan, pos_over_neg: 2107.805419921875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 2855.52099609375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1232.0177001953125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7409, loss_val: nan, pos_over_neg: 5290.86962890625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 948.934814453125 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1809.8367919921875 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1470.002685546875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1009.8067626953125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 992.1978759765625 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1160.1656494140625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 2424.80224609375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 22343.849609375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1712.6484375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 969.4779052734375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1093.1005859375 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1637.1328125 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1247.54541015625 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1080.5616455078125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 667.2026977539062 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1242.598388671875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1687.926025390625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1160.5616455078125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1241.7789306640625 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 2337.80908203125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1033.117431640625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1697.8192138671875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1142.848876953125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 957.0098266601562 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 10442.294921875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 4815.2802734375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1566.0919189453125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1788.0245361328125 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7412, loss_val: nan, pos_over_neg: 9963.0830078125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1157.8343505859375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 2377.981201171875 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 21773.728515625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 3996.17236328125 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 704.5606079101562 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1316.0052490234375 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1250.04345703125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1359.30224609375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1616.0413818359375 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 980.631103515625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 726.831787109375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 3216.251220703125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1161.1834716796875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 2000.7452392578125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1842.9300537109375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1292.2020263671875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 882.5769653320312 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1178.6680908203125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1214.600341796875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1217.2200927734375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 1936.9530029296875 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 6134.14404296875 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 1432.10986328125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 548.3812255859375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1669.178466796875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: -9499.94140625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1569.0439453125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 936.4603271484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 974.3214721679688 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1054.138916015625 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 2413.247314453125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1098.5740966796875 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 994.41455078125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1527.3671875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1182.543701171875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1904.2745361328125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1136.861572265625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1402.4376220703125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 935.0045776367188 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1107.814697265625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1285.494384765625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 3812.542724609375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1776.57470703125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1158.8255615234375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 843.29248046875 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1062.6153564453125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 803.4630126953125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1213.0906982421875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 3445.44970703125 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1274.71630859375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1630.46142578125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1311.6572265625 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1503.0892333984375 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 2011.5322265625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1178.6451416015625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1280.590576171875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1239.2841796875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 750.5223388671875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 964.1969604492188 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1370.39013671875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 954.51953125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1206.5791015625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1228.281982421875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 906.5855102539062 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 701.4729614257812 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 813.8690795898438 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1115.3843994140625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1269.2169189453125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1228.123291015625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1005.4605712890625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 903.7487182617188 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 767.4508666992188 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1370.70068359375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 852.248779296875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 766.9859008789062 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 644.9713134765625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1352.46826171875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1415.444091796875 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 2006.7720947265625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 849.7510986328125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 832.57861328125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1007.173095703125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1175.032470703125 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 937.1153564453125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1750.1253662109375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2240.600830078125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 3814.162841796875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1559.3944091796875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 828.7543334960938 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 656.4244384765625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1605.486328125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2536.178955078125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 7013.419921875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 988.2349243164062 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1042.5367431640625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 721.9896240234375 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 974.2037963867188 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1805.9937744140625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1681.1053466796875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 2282.3203125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 835.278564453125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1057.047119140625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 4815.31201171875 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 866.6065673828125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1022.1168823242188 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2031.032958984375 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2952.94189453125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1794.9244384765625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1922.2354736328125 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 2815.790771484375 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1583.504638671875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1432.6435546875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1955.52099609375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1985.14697265625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 7343.49072265625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1034.2073974609375 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 736.397705078125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1505.8624267578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 3082.027587890625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1001.3018188476562 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 612.6395263671875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 817.7188720703125 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 845.9335327148438 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1083.1693115234375 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 915.936767578125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1165.084228515625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 1192.8048095703125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1310.9534912109375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1115.7364501953125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1200.3236083984375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1062.249755859375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1670.335693359375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1128.2471923828125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 672.021484375 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1389.3765869140625 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1901.376220703125 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 739.84375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1218.6553955078125 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 865.142578125 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1743.59228515625 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 3419.69287109375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2822.12451171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 2049.764892578125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 2060.1044921875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 791.7069702148438 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 2043.8590087890625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 2247.971923828125 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 933.7190551757812 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1424.8944091796875 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1186.998779296875 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1030.3472900390625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 2019.0003662109375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 970.445068359375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1024.5665283203125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 2547.621337890625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1773.3006591796875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 22958.0546875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1009.2500610351562 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1491.259521484375 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1916.2664794921875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1929.8203125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1774.364990234375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1101.726806640625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1037.8118896484375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 921.4912719726562 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 4070.13134765625 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 847.2189331054688 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1354.7840576171875 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss  Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix  Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE  RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "#     augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "    \n",
    "    augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "                             stds=[0.229, 0.224, 0.225]),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:09<00:00,  5.42it/s]\n",
      "100%|| 50/50 [00:05<00:00,  8.84it/s]\n",
      "100%|| 50/50 [00:03<00:00, 15.45it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "c_lst = [1e-1, 1e-2, 1e-3]\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train  C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val  C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-2)).fit(features_train, y_labeled_train)\n",
    "\n",
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
