{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "source": [
    "# !source activate jupyter_launcher\n",
    "!pip3 install numba\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install sklearn\n",
    "!pip3 install pycuda\n",
    "!pip3 install tqdm\n",
    "!pip3 install seaborn\n",
    "!pip3 install h5py\n",
    "!pip3 install hdfdict\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josh/opt/anaconda3/bin/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import cuml\n",
    "\n",
    "# for creating validation set\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MZ9Hq6SVvves"
   },
   "outputs": [],
   "source": [
    "base_dir = '/n/data1/hms/neurobio/sabatini/josh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9w3t_mtdDB0j"
   },
   "outputs": [],
   "source": [
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh'\n",
    "base_dir = '/Users/josh/Documents/'\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(f'{base_dir}/github_repos')\n",
    "# sys.path.append(f'/media/rich/Home_Linux_partition/github_repos')\n",
    "dir_folders = f'{base_dir}/label_data'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import math_functions, classification, h5_handling, plotting_helpers, indexing, misc #, decomposition, torch_helpers\n",
    "from GCaMP_ROI_classifier.new_stuff import util, models, training_simCLR, augmentation, training_classHead, training_supervised\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import unlabeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_unlabeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_balanced.h5')\n",
    "data_unlabeled = h5_handling.simple_load(path=f'{base_dir}/label_data/masks_20211202_balanced.h5')\n",
    "\n",
    "masks_cat_raw = torch.as_tensor(np.concatenate((data_unlabeled['SYTmasks'], data_unlabeled['NPmasks'], data_unlabeled['RHmasks']), axis=0), dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labeled = h5_handling.simple_load(path=r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/masks_20211202_unbalanced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_SYT = data_labeled['SYTmasks']\n",
    "# labels_SYT = classification.squeeze_integers(data_labeled['SYTlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_lst = np.concatenate(np.where(np.isnan(masks_SYT).sum(axis=-1).sum(axis=-1)))\n",
    "# non_nan = [_ for _ in range(masks_SYT.shape[0]) if _ not in nan_lst]\n",
    "# labels_SYT = labels_SYT[non_nan]\n",
    "# masks_SYT = masks_SYT[non_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_labeled_train_SYT, X_labeled_val_SYT, y_labeled_train_SYT, y_labeled_val_SYT = train_test_split(masks_SYT, labels_SYT, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toss any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks: torch.Size([711808, 36, 36])\n",
      "Number of masks: torch.Size([711807, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of masks: {masks_cat_raw.shape}')\n",
    "\n",
    "ROIs_without_NaNs = torch.where(~torch.any(torch.any(torch.isnan(masks_cat_raw), dim=1), dim=1))[0]\n",
    "masks_cat = masks_cat_raw[ROIs_without_NaNs]\n",
    "\n",
    "print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "source": [
    "## Import labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8AO_lypDB0o",
    "outputId": "4edfd739-a0b7-4789-aea1-4a9f6c2665c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_folders = f'{base_dir}/label_data'\n",
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "# dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                            fileNames_statFiles=fileNames_statFiles,\n",
    "                                            out_height_width=[32,32],\n",
    "                                            max_footprint_width=241,\n",
    "                                            plot_pref=True)\n",
    "images_labeled_raw = np.concatenate(sf_all, axis=0)\n",
    "images_labeled_raw = (images_labeled_raw / np.max(images_labeled_raw, axis=(1,2), keepdims=True)) * 1\n",
    "print(f'concatenated images shape: {images_labeled_raw.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels_raw = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plotting_helpers.plot_image_grid(images=images_labeled_raw,\n",
    "                                labels=None,\n",
    "                                grid_shape=(10,10), cmap=plt.get_cmap('gray'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ip1UMYy6DB0p"
   },
   "outputs": [],
   "source": [
    "labels = classification.squeeze_integers(labels_raw)\n",
    "images_labeled = images_labeled_raw[labels != 2]\n",
    "labels = labels[labels != 2]\n",
    "labels = classification.squeeze_integers(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYh_wBqCDB0q"
   },
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn4Pu2cKDB0q",
    "outputId": "3afafb73-54a7-4e2d-8030-c0af6272cbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9714, 32, 32)\n",
      "(9714,)\n",
      "532\n",
      "(2128, 32, 32)\n",
      "(2128,)\n",
      "532\n",
      "532\n",
      "532\n",
      "0\n",
      "0\n",
      "(2128, 32, 32)\n",
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "balanced = True\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "if balanced:\n",
    "    numToGetTo = np.sum(labels_dup==0)\n",
    "    print(numToGetTo)\n",
    "    for ii in np.array([1,2,3]):\n",
    "  #     idxToDelete = np.cumsum(labels_dup==ii) <= (np.sum(labels_dup==ii) - numToGetTo)\n",
    "        if ii==3:\n",
    "            numToGetTo = np.sum(labels_dup==0)/1\n",
    "        else:\n",
    "            numToGetTo = np.sum(labels_dup==0)\n",
    "\n",
    "        idxToDelete = (np.cumsum(labels_dup==ii) * (labels_dup==ii)) > numToGetTo\n",
    "        images_dup = images_dup[idxToDelete==0,:,:]\n",
    "        labels_dup = labels_dup[idxToDelete==0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "NpMB08CYDB0q"
   },
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVA_Aa6rDB0q",
    "outputId": "15b9e55a-4881-40be-f06b-dec658fa55a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1702, 32, 32), (1702,)), ((426, 32, 32), (426,)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "\n",
    "###### REMOVE WITH ENOUGH RAM\n",
    "images = images_dup\n",
    "labels = labels_dup\n",
    "\n",
    "# X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.3)\n",
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val = train_test_split(images_dup, labels_dup, test_size = 0.2)\n",
    "# X_train, y_train = X_labeled_train, y_labeled_train\n",
    "\n",
    "# X_labeled_val, X_test, y_labeled_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_labeled_val, y_labeled_val, test_size = 0.5)\n",
    "\n",
    "(X_labeled_train.shape, y_labeled_train.shape), (X_labeled_val.shape, y_labeled_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mdJafJMMDB0r",
    "outputId": "2e8d00f6-32bf-4aeb-d02d-e10dcaaccfe3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNxaCTbcDB0r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tz9Q8wYuDB0s"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "def classification_step(X_train, y_train, X_test, model, model_device, temperature):\n",
    "    logreg = LogisticRegression()\n",
    "    features_train = model(torch.as_tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    logreg.fit(features_train, y_train)\n",
    "    # logreg.fit(features, y_train[y_train != 3])\n",
    "    \n",
    "    features_test = model(torch.as_tensor(X_test, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()    \n",
    "    y_hat = logreg.predict_proba(features_test)\n",
    "    y_hat = torch.as_tensor(y_hat, dtype=torch.float32, device='cpu')\n",
    "    \n",
    "#     print(y_hat)\n",
    "    print(f'accuracy: {logreg.score(features, y):.5}')\n",
    "\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train), y_hat, normalize='true')\n",
    "#     # cm = sklearn.metrics.confusion_matrix(idx_to_oneHot(y_train[y_train != 3]), y_hat, normalize='true')\n",
    "#     cm = rh_cm(y_hat, y)\n",
    "#     # cm = rh_cm(y_hat, y_train[y_train != 3])\n",
    "    \n",
    "    unc = util.loss_uncertainty(y_hat, temperature=temperature)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     return torch.tensor(unc, dtype=torch.float32, device=model_device)\n",
    "    return unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtkRZSMqDB0v",
    "outputId": "230c559f-f22c-4182-b3ab-024ba2080a50"
   },
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)\n",
    "# DEVICE = torch_helpers.set_device(use_GPU=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define New model = model + pre-head + latent layer OR classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gt4xpqbHBjyL"
   },
   "outputs": [],
   "source": [
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(self, base_model, un_modified_model, pre_head_fc_sizes=[100], post_head_fc_sizes=[100], classifier_fc_sizes=None):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "    \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 512\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "            non_linearity = torch.nn.ReLU()\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "            if i < len(post_head_fc_sizes) - 1:\n",
    "                non_linearity = torch.nn.ReLU()\n",
    "                self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "                self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MIix9BdUCkqf"
   },
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# # base_model = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# for param in base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# retrain = list(base_model.children())[-1:]\n",
    "# for layer in retrain:\n",
    "#     params = layer.parameters()\n",
    "#     for param in params:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with a pretrained resnet model, and chop off the final layer. This will be used as the base on which we add the pre-head layers (for expressivity), latent layers (for simCLR), or classification layers (for post-hoc logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aWnb7WWri9qK"
   },
   "outputs": [],
   "source": [
    "model_chopped = torch.nn.Sequential(*(list(base_model_frozen.children())[:-1] + [torch.nn.Flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "source": [
    "### Make combined model\n",
    "'model' has two forward methods. One for generating latents (for simCLR) and one for classifying labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6Qx-1NGJNY3",
    "outputId": "f7cb3ded-3b48-439e-bf57-a526fb48bac7"
   },
   "outputs": [],
   "source": [
    "model = ModelTackOn(model_chopped, base_model_frozen, pre_head_fc_sizes=[1024, 512], post_head_fc_sizes=[64], classifier_fc_sizes=[len(np.unique(y_labeled_train))])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(model_chopped.to(DEVICE), base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "# model = torch.nn.Sequential([model_chopped.to(DEVICE), torch.nn.Linear], pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "\n",
    "\n",
    "# model = ModelTackOn(base_model_frozen, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "# model = ModelTackOn(base_model, pre_head_fc_sizes=[len(np.unique(y_train))], post_head_fc_sizes=[])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.6.0.conv1.weight\n",
      "base_model.6.0.bn1.weight\n",
      "base_model.6.0.bn1.bias\n",
      "base_model.6.0.conv2.weight\n",
      "base_model.6.0.bn2.weight\n",
      "base_model.6.0.bn2.bias\n",
      "base_model.6.0.downsample.0.weight\n",
      "base_model.6.0.downsample.1.weight\n",
      "base_model.6.0.downsample.1.bias\n",
      "base_model.6.1.conv1.weight\n",
      "base_model.6.1.bn1.weight\n",
      "base_model.6.1.bn1.bias\n",
      "base_model.6.1.conv2.weight\n",
      "base_model.6.1.bn2.weight\n",
      "base_model.6.1.bn2.bias\n",
      "base_model.7.0.conv1.weight\n",
      "base_model.7.0.bn1.weight\n",
      "base_model.7.0.bn1.bias\n",
      "base_model.7.0.conv2.weight\n",
      "base_model.7.0.bn2.weight\n",
      "base_model.7.0.bn2.bias\n",
      "base_model.7.0.downsample.0.weight\n",
      "base_model.7.0.downsample.1.weight\n",
      "base_model.7.0.downsample.1.bias\n",
      "base_model.7.1.conv1.weight\n",
      "base_model.7.1.bn1.weight\n",
      "base_model.7.1.bn1.bias\n",
      "base_model.7.1.conv2.weight\n",
      "base_model.7.1.bn2.weight\n",
      "base_model.7.1.bn2.bias\n",
      "PreHead_0.weight\n",
      "PreHead_0.bias\n",
      "PreHead_1.weight\n",
      "PreHead_1.bias\n",
      "PostHead_0.weight\n",
      "PostHead_0.bias\n",
      "Classifier_0.weight\n",
      "Classifier_0.bias\n"
     ]
    }
   ],
   "source": [
    "# unfreeze particular blocks in ResNet model\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if name[:10] == 'base_model':\n",
    "        if int(name[11]) < 6:\n",
    "            param.requires_grad = False\n",
    "        elif int(name[11]) >= 6:\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, param in list(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.15, 0.15), #0, .3, .45 (DEFAULT)\n",
    "                                        scale=(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "                                        shear=(-15, 15, -15, 15),\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.5), 10**(6.)),\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.00015,\n",
    "                                    prob=1),\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224), \n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # To do or not to do (DEFAULT)\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225],\n",
    "                                     inplace=False),\n",
    "    \n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "tq77tWZeDB0s"
   },
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    \n",
    "#     torchvision.transforms.RandomAdjustSharpness(torch.rand(1)*5, p=0.5),\n",
    "#         torchvision.transforms.RandomPerspective(distortion_scale=0.7, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.1)),\n",
    "        \n",
    "\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        \n",
    "    torchvision.transforms.RandomAffine(\n",
    "                                        degrees=(-180,180),\n",
    "                                        translate=(0.2, 0.2), #0.15/.15\n",
    "                                        scale=(0.4, 1.3),  #.6, 1.2\n",
    "                                        shear=(-25, 25, -25, 25), # -15/+15 across board\n",
    "                                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "                                        fill=0, \n",
    "                                        fillcolor=None, \n",
    "                                        resample=None),\n",
    "    augmentation.AddPoissonNoise(   scaler_bounds=(10**(4.0), 10**(6.)), # 4.5, 6\n",
    "                                    prob=1,\n",
    "                                    base=1000,\n",
    "                                    scaling='log'),\n",
    "    augmentation.AddGaussianNoise(  mean=0, \n",
    "                                    std=0.0002, # 0.00015\n",
    "                                    prob=1),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # Do vs. don't do -- bounds between 0/1. Either do this OR do this followed by torchvision.transforms.Normalize\n",
    "    \n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), # Do vs. don't do\n",
    "    \n",
    "    # augmentation.AddPoissonNoise(   scaler_bounds=(10**(1.5), 10**(4.0)),\n",
    "    #                                 prob=1,\n",
    "    #                                 base=1000,\n",
    "    #                                 scaling='log'),\n",
    "    # augmentation.AddGaussianNoise(  mean=0, \n",
    "    #                                 std=0.1,\n",
    "    #                                 prob=1),\n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "    \n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.0, 0.0),\n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         # fillcolor=None, \n",
    "#                                         resample=None),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "# scripted_transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PmM4nnV1nCVd"
   },
   "outputs": [],
   "source": [
    "dataset_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=2,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=16,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAD8CAYAAABHPleGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABYPklEQVR4nO29Xcgt23rX+XvGqKo537XWPt/RPklHEyXSHfvGdFAbRQQRY2g63ihGkG4I5EZRwYucmAuvAtGLQEPjxQGDLWhiQKFzEQgaFBHUTlqi5oMkJ0ZN7NNJTs45e6+13nfOWTXG0xfjo54aVXO+c+2z915zm/XAfD/mrFk1atQzno//8zFEVXlDb+gacq97AG/ow0NvmOUNXU1vmOUNXU1vmOUNXU1vmOUNXU1vmOUNXU3vG7OIyLeIyM+LyOdE5DPv13Xe0AdH8n7gLCLigV8A/jjwq8BPAN+uqj/7nl/sDX1g9H5Jlt8PfE5V/4OqnoAfAr7tfbrWG/qAqHufzvs1wK+Y/38V+APnDh7cXu/cW/k/hSzsVBUBEEkvVZIkVAQBJ5COSL8WQlKb/zdI6o8Ln5fTmfOJzNd7N5JZmmteew5VMwRz38uBLu/bnru9bn1//uyd6QtfUNWv2jrs/WKWrVEtZkREvhP4ToC9e8b/9JEseGJmiBAgRnAOvEe8Q0NETyeIiniHDAN4v3GlOJ8nxvSeWwtRkcJwDUVN74sD79KEjxMaAjiH+DQmQkBDnMe5Ok++dvPAxPt53BrTObbIjj3GdD3VPG43n8veg71ve//lPOW65XM7Hif82Bc++5+2B/P+McuvAl9r/v9vgf/XHqCqnwU+C/DR7lNab7KQSL6B9BDKQxHvQWK9uavJPFCR5eRuTnZQRDQxXiHn5u/GC9IgNg+/fEc1SYcQFqtJNla8qi7Gq+XvRgqpKrK6nJwXqhuMraqIRoiXrZL3i1l+AvgGEfl64L8Afxb4c2ePVtKqNWRXTF29UJlIWomiMUkCSL9dhKB19dTzWmmSGUMisyQh1FWn5XpbTJalF7Cc/LJiC9mVbCRFkVKrMeVxLa7lJKldkaW0zH9rPufyOy5J5yKVLLX/52tCWL9v6H1hFlWdROQvAj8GeOAHVPVnrvhi+l31sZtXdvnM+/Xk1mMMw7TnPaevF8fF9DBa9dWuxswkuiXm6zFLSbZY6eWzc+rrHGWm0XKOcm/5f20ZJtt5j9LWdzfo/ZIsqOqPAj969ReaFaCqiJU27Y1UNZCPKcxTGCbq+ntlUuo8zw+9ivJGAhTJsjmRVoqUz8uKbq5ZPztHjTpcqOSg8wIRh4imc9rrZDtPr1kULRVV/whjvW/M8kokkgxYWBhmi6G3ItsacoUBLMO0ZFegOd/88cZEWQPynI0SkzRaqMVq18SZeYpHt3FP87mMxCrfL+NzLqki0n1KJDHGOelWpbNsqyJ7zJV0G8yCLvV/K2I3pMpKBeT3LUm2bxbeQTlneYDtA7vSjbVSaXE9mCXJY+fKzFQ9nPazx75vVVmZi/J/q3rtfb6K6jN0G8xSDFwrrrdWAmtD+CJlSSORWWwXSVAM5fKAC0M1DFRU1KbksQ9Zlqt+waTvhozUnCWVJsOdcskLXk85h5Vo5r4sc147zhthltmoLOJ8pZNhiR004rZ9mCLZu3EChFlsQ5JMbu2Gmi83w9s4rhX9zhlsJp9G49IYtfdbrrNl5Fq7KZ9/5bJXlXulobzyljYggA+LzQKsb7jo5C293DxQ2WIajcn+tRiOc0nzm3OsmOHcxG94IMvPlyt/U7Xa+zXnXXkj5Tut5CvSQs3xZbxb4yugppF8Z+l1eUOvTFtILCwZpvzfPExr9ErGIgqwtqBL7uGGGF6J6vRHVWWLY4rhrBuYTL722WuWc5bxtW61NfqL6lNF85ytbKVz9k6D5Szu6wo75jaYRVg+5EJbhhtnpAgsvZbWra0PIiPDUbeh9haAaz2hwijF1W2N2Txe3Zj8FfO1xrx1s8u47WchpjGLm2NmRv1JDgfYcV6SFdX+uwJjgVthFm0e/Ll4jvEegLVo3XJvN20CnRHYjWstzmvR4HycQLVLXsX9tF7PQhpYqXbOvsnXVZVZ+tixFkCxxNS2qAUTrVNxBd0Gs8AZCHpD/JbjitpqdHCrLhZUjs0rqqK1zQOsxxYDOTrA2AtmJV4Ess6hu2bM1VPbCjrWg2bbZCFR6nXm4Oslb9EySZGO9Xz946xwe2mV5QFaO4U2+BfXjBA3JFNLUevEtu7iVnzGkhQX1EadnSwkxVlRbq5VVdg52jqHVac5uHrxetFI3nJc9Z50MYZZbT2OL92GZBHW9oml4rlcEXFd2CrWvW7tARuYNOdaoMIhMOsbrtLtxfYyg1xKjYKN6HYcaXUPlrYCmhvXx0udM5t+IHHOh6kYVHP/l+g2mAWZASbjacByRZM/t+60Qn2IK5jcuthFn6eTbo5i4Z6GgHqfGMZJDeKl7294Y7DyyMpYqo1lx7UxlpUd0zIdlxmlzpNVld6nnBxx4II5dO12PyZbbkcNFc/CiNhNQ66Q1eObNodbMhls2wUFUGvPXaSRak6RaPCbNv7kZPnbnv8cbeFI7fetym0kblGnC/fXzoVrVKvYhKmsSl/BQL8RycK8Ik0W2SbOkT5YusLmHKu4iEV9y/8wi+nGULUBQTXSSFsgDNYPo4yhfp4khHTdkkEtE5uMwIUqOAPBX2VQ23OJJrVULl3CEO+CboRZjNrxNoFJZjc3bBikFsizK93762IyjbucsA+Z1cw0zZ5YPqea75UY0OYY6v3k8IVVg8VIzjZEerAJrV250oXagOGWxGzfL2NSAWK6N5WFbfIqjHMbzKJLDGKVwHQGD6m5KzbntlA7mTXn1XgWsMBokmveQPbOzbbGxXsw6QTXPIDG+0ipjYahzhn5i3OcH9cqdfSSRXJlsPM2mAVmuLsYkTauE8ISD/GGERrUspK1dc6FEiwZpHYrjfOs7XEuO69FclvgbUMdFIxkZXstxnkhpWLLditjhMvu8RXR/NtglgZTqVSkhXVnmxWzykmFapxKC9zZNM0tcpIYxXoqjwFwRRK1D6Iw97lUi9YmMd9XVwzUS5l1G6jv1qKw5z2HW6muPt+i22CW4n0ANXG4uKuRGjAj2xVtWmT+Z/47w9hnVdsVAFRLWxM5I6Is3XdbxmIDg+Vebd5OtWOsF9O4/JYxWjVqz9fACfV8sPp7q5LibMpGpttgFqg3V70SsqHpSQGyYrTG7bRIYIGSFoNxa7WdW0GLRCbdXpGr65WHXaLAZYxlDFW6LQ3XylgxSyWXXdpWopTapPp/TGq4uL52LNbmKQDgNUHCKwOJt4OzFNoS2xXDeHy4KzugfdA2Kt2EDRagnB3POQOwxTmuNBQXlKPG7cPatDvUhAzO0CKUsTD4N5ghj/eqXBduRbKIGXCts5ltga2SC4uxKNQVtYLb7bnq/xue1Ra1eI25fr7YUhoZdVA9qC28pEFLV/aDyW1RycnsekZNNfbaVi7voqLBGrKNNF/l/zR0G8xSqK0MDBureiMvRUQTaFZAsAsBtlWkueAddjU+xkx2TEbNVEZtVUlrZ7TM7P3MJNpUChTbY+s89vzFRjLnamNOC2ehVWFX0G0xS0utKF2tmo2VsJFllvJ5jaooXo530KUpqA8jBHSc5uvaB3Qp280GKs8Ba1v3YZFce06Rdb3RhoRanceQGgm3WTZClsSPjTfTbTBLAeVaZPEMo8zHNiK1MNdW0lTz0MU76Aek83OMRBUdR0RcKsDXXJdcvAXfntdEcYtxucEIC2MWtovZjTdYk8kbuODsQ7USy0ioNL703iK63MSPVkj0GboNZsm0mS13zbGWGk8mH7x86CLQdYlRdgPa+TlWdPQopMz8cUrfd24O9S/OH6jZ9WXMbdTXlqOU8RQVKgIhJntK3Vq6VMkyA4abC8hKHpPYVDGlACrmXHYccB1oyY0xy6La0LnLqGKTI1LpjM1RHrYMPdL3iUmGHvoOHTq096iAOw3IbkDGKaUnFLfVm5yaDNzpFBAfZvd2ARhul8qmzzQF+FDW6Z3LaPvCGL6mZiqHJ1K6zHVMcC3dDLPYWt6KrUCzwjag7taIMxMqZqWL99B3yN0duh9gNxCHDu0dcdcRB0fsBH+KuKcDMob0PGOEmNWCKjIGGCdkCsg4wTRljyWv5pLaWOyfDWNbQ9h+8DZt0tJWXm2JrttCOWOv1fM00rq41gIV37mIahu6DWaxc1PzZMv/lzPKqhG3yLTL8LVjrhHyPkmUoUef7Ij7njh44s4Tdo6wc8QO3ORxoyJB8+JPf7ugSFTkFHGHCXea4DQio0dGvwTPWhQXzku/et9uoVYsGrxqR7Ll7RW0u1xrKyHsMWn9CN0GsywM3KZzQqtmrPopK6gcW1fU2uIvdoJmtRPvOqa9J+wdYRDCIMQuTbgLigQSc2RtUcifFH/s8ceAv5+QhxE5npDTiJxGVCOiDm0ZezmgbQ+nudeKs2x5T42RWnvLWJi/MJAx7qWbH/k1qZSWboNZMpXCsDm3ZMP6v2TgFSqwe2voikDniYMn7DzhzjHeOcJOiD3EDlCQmCZZwpz7ETvAgRvBHx3d0dPvPF3v8C9TbCsxV2kQdAZJ3Rr7JdS65OpaRlpl9s3Ga33458pYMhMVDEvt+4/Q7TBLk+VVaSvJ55IdY8mgwkUFxX1H3HmmO8e0d0x3QtiRJEs/250S55cKaJfVWgA3Cv6ojHdC/8zTv+jpng90b3vk/jBLhGla1zq392OlTJtiYHux1FvaQKjPNjE6I2Hr55cR25Zuh1lgxj+AmseS36+/rXva0gYCK10HQw93e+KzPeHJwPi0S4yyE8IAYS9Me4gDlVG2coXEvqdSJVD30vPkCx1PBkf3ZY/cd8jDMWE2pxGdpu2x2nsr11ioFdLfYQPKL2AbZOkT5/sXqZHwel4TRlmnR8TNCsqWbodZClhUff7QmC9ngKlG52vuKineIyVINwzo3Y7wdMf0tGN6MkuUOKTf0xMl7lgwizpSqFWzRJmSOlIPsVe0Sy9/74g7h8SBO8A7hyMZ1xpLcz+dYYE2r6QN4NXuD2kaNlWEfeC2aM6eNzNOAQFr+KQ1eq+k22GWrUmrH834y4I2kNoUvk8TJEMPux26H4hPBsJdl9VPkiRhL4Q9THcQ7pR4p8lNnjJjdor6vKqDJAbqFYaI2wX6PjAME8dDz8vEJoRhx37v2TlwIrnktEi8FNC0AF01Mm2CFrCVtHSNXVGYcpUiMZ9sZpIWQHyEHmUWEfkB4H8Gfl1V/4f83ieAfwB8HfAfgT+jql/Kn3038B0kufCXVPXHHh2FgJTyyTY73lIRyRuroUqlvkseUddV8C3eDYR9lzyfXbZR9lKZZHqihKcRhghR0MwYeIVOER8Rp4hX+j5wtzvxZBh52p+460ZeTgP/2X2c5/s7xieeMPS4SekBp6k3npbcFxWIWS3ZZCU1KrjNKb4kAayqqWCcmQ/XMJ+NWlsmuaJN7DWS5e8A/wfwd817nwF+XFW/T9ImDp8BvktEvpHUxvT3Al8N/BMR+T2q+ohzb3S0yRfduhFr4K1Wg/eJSbyDPqOzu5647wn7jKdkNznsGkbZB/wuoEGIk0s2SRfxXaQfJnb9xJPdibeGI5/Y3fOx4YGn/sgzf+Q+DrzVH/hPTz7OF7uP4aaO4UWHhB39FBMaPKW4kU7THBku4J3NovOso+CwSFuox7YYTsZRLKNsSgwbH4Nt43iDHmUWVf3nIvJ1zdvfBvzR/Pf/Cfwz4Lvy+z+kqkfgl0Xkc6Q+/v/y0ZFcQhGNvocL4lgjxIA6SS6sS3VI2vuE0PaSVl5B28l2iT2dkNBYFNdFnI90XWA/jLw1HPn0k3f4HXdf5NP9l3nLH3jqjrwT9kQVDqHn+UfvOH3c8/K3pfCBOqF3zoB4E2Tkl2nayIRr1tVGrGsVKTZ/11CBDUBahmxxq62Y0Rl6tzbLb1fVz+eBfF5Eflt+/2uAf2WO+9X83mVSrRN2Nk80bEuaRYF3RllrsRmAF7QTYi8JKyGDblP2ZjTZKWSJIpLyY5KNmf8GehfZ+4lPDS/43btf47/bfZ6nMrGXwG/GHW+Hp3x+91GePjny5Y/tOBw6cB7N1/f3E/7QI4cpSZrCNOOYXiGsjN8FcLflNW31rSvhjSJdCpK8kfRE1FcKH73XBu4We24682J798vTGt6vGWIbEehz+aR2wtS55H2ki6CdI/oU94leUJnxE7LXI9lO0ZDUgPOKc0mqeB/pfGDXTTzrj3yqf8Hv6L/I7+pOPJGeXgaehAf+Y/9lPjG85GNPHnj5sYFjSAZvEl0d/eDo7j2+97ixS7Gnw4gc3bxHRZwWjLEAJx+jNu+mVEuqwNR4YDY/+RxGs0Hvlll+TUQ+naXKp4Ffz+8/2rO/kNre/f5T2uarVNrCA7bS/0wyk/QJV9HdkFRQL4mN86uqnnJJBaLA5MAFRJSuD4lRXOTpMPJWf+Bj/QPP/AEnkVGVUQJosuQHCTzzRz6+u+flWwNfjI5j2CGTR6IQu6QGu15wY4cbI37ocC9dHYqyXm2XvJS5uiBLjWKnlEL4+STrkMHKk3wcoHu3zPIjwP8KfF/+/X+Z9/++iHw/ycD9BuD/vuqM57LBWjrXdbsEC/d7dD+g+x161xN3WRWUfN3MLAtbJQoy5dXdC85H+i4wdIGhm3g2HPn48MAnhxc8dUcA7hWIgV4ixzzPT/yJT+7uOcUOJ8pvBOE07pDgkv3kFPXgJsWNjtg7elXcFGpUe9GVajE/S9VrDeC5IoK5d4xFgb3fFO+z236ddLnGdf5BkjH7KRH5VeCvk5jkh0XkO4D/DPzpfPGfEZEfBn4WmIC/8LgnlO5yoXpaI2y+u/S7iOo231Vk/t9LYpICoccSNEvvaZUq2RhehJwUJ4p3kd5FBhfY+Yle0q0cYs+XZeClRDzK8zhwiD0O5c6f+NjwQFTh5bOBFw8d42kWa+ocblT8KV3QjX1Ke1BFQszpCwBmuxg4v/IvVB6k39tI8fIcCf95jK7xhr79zEd/7Mzx3wt876NXXn9v/mcrA6w1/JpjKmI5jogT8A7p0stNDn9M3lHsDDAcwQUIXQLg6CM4JQbHGDydj0QVIsJD6Hl7umPn3qKXQMRxUs9Be+7jji9Oz7iPA1EdTpL6GroJ2QemJz5HsRPD+EPyxmIvyUu763OkO6Z4ko65dLepkWoN2XLvbWJVxnGuqbmuDPmh6fz0KvGsLSYpVBKmVBHnkN4jQ4c7RTTbc9OuVN6VyDIVgJMhgW9RhWlyTNkwnqLj5TTQyRN6CfQSGNXzPNzxdrjjeXadR/XErNscytAFumFivPNMwZdkE0BwE/hOCDuHhA6ZIjp2KZYVImCSxs+kW24lW9d4mt3IamPLHctI13ZSuA1mgc1koM0Ia/7MUtXZJR8mKvQ9chjxzqUVGzoQwe+UMEmSKOXUWUskl3luBxo1McoxdAwu8OB6vjw9IeD4knvKfRh4GXYcQ7JRACZ1nLKP7kRxLqHAulNCLPiOZPXnctxJcSeP9CkvWCaXqhvbXT9Ksledh43W703Ctu3NYuksRHGBboNZCpp5KVZxBvJeGHoiGTYHPZ6yeI343YCM6ZiwE6a9R6b04LR4twoaU3qk7wJdl1TAcezwLrLzE1GFd8Y9Xz7dVQliyaFM6pii4xQ9ITpizDElr8Q7GF0xsCU/bMEfHdq7lAfcd0iIqUzVoNmb2XIlXwWWCeF1QLKcszMNAs7uTdDQTTCLwnLFPEZNXdAiez+fT2RCHyIyjjBOuN0AQPeko7tzTBOg2dAVTX/H9H3vI94lZpmi4zR1hN4REQ5Tx/Nxz3Hq6H3grhvpJFbmiSpEFUJ0hJjCBunCEe1BO2H0Hu0ABHcSuoMQDg7XO+g8dB7pPKqlY1SuIsjAXQXSStvVrSZCW9l1MEe0yxZ3ugZDz9FNMMsWrTjdFpgXMoxi622SsRthmsW2AK7z+IeB7uDoHjxhD+GQ9H70sTKLCHgXs1cEd/3IrpsYXDIc+xCIXhKTqDCRVNUYPFHnSQ9RklrrywNRtBe0U8adI3qPqCDRgXa4oLjjBFNI6RVAacda7l3KAMtnlrbyfRbzlb2esPXdDwmzSMm5gFklzR9uGrOLUsxYNqn00Ml849kzqHmsfYc/THT3nn5whIEaL9Je0B1VEnin7LqJu37kaXfiWX/kWXdijNl9nvp0CYRT8DyMPfennhAdnQ94p6gK3kd0WCY/yS79Pg0DB3oKUuiPHf5lhz+M6YBScmL7xdhI8mKzz6X9chbpHk2XhXzO1L3hw5T8ZANmG2mIqyShYGJCpcNAWdVZJxd7RqbUNlWOHfIw0g0+x4p8SmTqhLiDGMTMoVY186Q7cedHBjfhUOhgcBOn2CU1FTxTdBxOPTEKoXNVjTmX0hrKLToX6X0C/J73gZcRjrHHjUL/4Ohf9rhTQA7HnJLBPC92dw9o0jnm+RHWx2wawNDUVV+WLrfDLLAtOrORWmD+xWTlVZFsFJtdtuzLpiEiTOjphLs/gINeyOBcguHDHsJTV1WRE2UMnneO+8QMpslxVMGL0kkEB4MPdC5Fp6fJE6OgOnc+AOi6QO8DfQ4h9D4wDSOHJz3T6DiePG50oAN3XtippiS9+8MyjWFjyz+g2UGW7Si+9aislLpCBcEtMctG1lslo5rUqCUgMUy3vI1V//qYkFGJCfF1qnQku1ZiTxiE8akgRyE+kRp5PgXP/ann0HWoCi4zSJ+bDzuJdCQps+smdvm4EBzTNK9Y5xQvyr6f2HcTnSR7aOw8d3cn7qMwhuRKp1zYHjfdMYx5zNOETtM6B7fMSwnARpZR5FaqlL9hxl4sgz0CzN0OsxiqYBNsw9k2LZANW2arfCTGlHh0PCVjN4cGeoHhqeN07/EHIZ7Sg56CZ8pIrqpw7DpOwaeotEa8LCfWidL5QBdclizlXpJK63zkSbZ/nJQHl3CcEBwPTzzjKXlH40theurpngy4cYLDcXajtygzjXqfjjP2R+so2HyXx9qytnQ7zNJ0DKj0SHh+keNyaecwMzmqmnJKHk50IvQvevoXjumJEPae412Pc3HxoL2LCWTLaEZQ4RQTAx1CP6smHwkqVQU5l2JMu25i5yeedCc6F/A5/nQMHfddAJkL2tRBGBxh3yGHAbcbUh5vMXhL2kJbzUDBWjYefM3vMftiWwb50MD9G1TQ25VhaxKE1ow1F1mtqgCscZhFuxyTUd2/2DG88ExPhemJcHrScewifR/o+4nOB3qX7JKC1EZNhu39NHAMRk35MKe7klzwzidm2fuROz+y87Mb/mLc0bkd4mYUWoVsR3n8zsPQ15iRTk2MbNE1wZTyNup6UWJim1G3u4NcoJtllkKL7PfGsCvMVLLkYJ6UxT4+phLPbqXClIA8f5joX/b0L5LtMj04ws6nh+3jwl5xEpmi5xQ9k/r6WZIMBYBb8rcTrWmXnUsAXtD0cpJiSK5L6QvpJUSvaJdR3c4nu6zUH22h2a2RauyZOleYxdIyyoemmQ8so8qrj3Rux9641yVwWBnIe0Q8teRikeRcVpzMnpcqcproHgL9vaO7l2S7HD1B4OQiY++IKvQuMEbPIXQcQsJZdt3EjoT0huiYsnrpXWTM74XoeBh7TsHzchzY+Ym9n7GXfTfRDxOHXZ9LaSUxjeSwQJfzUxbtWQ1cb73IAkFYr0c14S+hpAdeh9i2dDvMAmkCbK97m2RcPi9kJqa2sLDR1Rw3WdT+ZprVUYQgyBjwh0D/0tPfC+O9EPaOKErofDVyIQUK76eBw9Tnhz7SucgkjpN0SNQZ/p+SejoFxxQ6YpYku35i8MmV7iS50V0XUsAxF7GpSA5wSoGUl9JjK1e3qJ7SWmNMlQQV9bWRZguEnqvHbui2mAWTX7FFrR0CNWVQW8DK1N6051vEoVRT0C7ElJR0gP4FxM4xAtErBz/w6/KMY37gpwzrRxW8i+xJiGuyQzqOoauSJMQUJyqPIqowhpQYHvI5puA5PAzIyeFGkImc35JyXJhCepWdU/J91/Eb77B4kgtbr3g/G2DntRFnuEFmqQBc680U2ujkiGs2Y7DlnKXepqQPquQmO2mlSs5+l6DIFOkfIvFtlwA7L4yDZ3Tw9uh5/nKPcxHvla4L1V6JKjzpTuz9RFTHO1PHy+PAFK2BqdXgdZLc5sPkOY49x0PP9Lyne+nwh1R078b0kmNATmPeoWS9W6paADKHNKq9VhaQzfbPVPvlvgLdDrO0gFNL56oQC/Xd2rK3XRcW/XUBUkAt7VaWgo5+jHT3KVGqILuxc4RczhpFCYMy7gLdLhCCI0RhGhxOtNohp+B5OCbo3zk1r5htGADPaew4HTrifYd/4bO9BP6Y+sC4MaaUyykkjCgujXigpv1pTviqaQvez56RRWlzKGSxxd+HKp+lULtitrL8Ddq1ELdtboet9nMu/59yXYiO2ls8akphuD/m/wHtsv4HNwlhJ9VTCTsl7BzT3jMNHYdh4H4/8nDXcbxLkeeXx4Fp7IjB2klKSeHX4FLZyeiQk6Qo+L3QvYTuXunvle4h4g+5rx3MVYxqF1XGW7KqnWvCc6uORa9bXWMrdj4/VN4QzYpRB+NosJZtnbs8QZPbUQJmuatCyWmtDANASHm79+BCqPmsouAmR/9SmPa5NcdOiDvJ9dKSmwIpx73PMaHkNR2PHXF06OigFNSXIQZJDHJKFQVuSr/9AfqXSv8S+vuYukodx9zNUhDnUJcfvu2bJ1J7+S63L/a5KF/n+8bC+2EheStWc4Fuilku0hWcX8nJnCxkv28ZrMDiMfW+JSdLQ5oUmSLdg0tqaJ8b/+wz41SmSU2Awp0wjY63Tx6cokcPo6SqxyApWTt3kXIj+IPgTunvkgfsj0r/oPT3kf7FhH85Ig+nVCMdLGTQ/C7329IGfF+xlq0F9aFCcIsLXKK7BUyDpeVfaCF2czYZzGH64iFtVQ3Ua+ZJK5tgxZR0JCEiD33qP9enVmB9aVa4d3Pbjp0QB5juhOmlZ3rqUgJWZG4IJEAkG67QHRJjuBP4UXPfF8UfFX8IdA8B//KEvHhADqdaPK/TBCFuNgaqoKXGmjm32cp+Md1a5zN5UI8/otthFliijnBms6Vsl/ilSK27gBVRm49p0ckFQLdAMfNDCAEOqRuD67oEiHmP+pTyGPcD4WlPeNLlLpdJ2kx36bd21EI2HMR8C/0LGJ4ne8SfIu6Yf08xdcA8TdXzkeMJPRyXjFEK6M8khs2SIVTVuyicb6GFhj68aZWqs+Rgw7thKVLbsoZVB8Yt+2ZrX0VS7gvjlHRE15k9kZPd4HcD7rjHv+yJdx1h39HtXO16qZ5UU+1ITQ37BIANL5Td24H+RcCdIm4MiTnGMBfKh+z5nEYYTyYwmqXnGTjhUmacBSBtE+eLc3OGbpNZzIpZ1fMaSklP25O0PqWJTsMqzlRUWm1/kVMaJMxGt0oysmUK+KHHHQfcrsfvuxTHKcX3uVw25l4w6oX+RWR4PiZb5DRVl1gq4BZn6ZHd5BUTtG02mntexMXMYrs4z1se5xm6LWbZTDI2Yfni/kHdCGHVOO8cRnOhVpgYE05TukPCnCPSnmuaQA4J/Druk6Q59NWVT83k0t+684R9R+yE7n7Cvzgmo7W02yjMYduIbUm8aG2LZQ7PQs2WXNqyF4A9hwUo7TxvpDmco9thliYxexNhtPsIwgxvXwKV2kBiZby4vG42kheJ4Pn7wOxNlSSjkNSFQMJCRGZjXHIh/qHDPXSpvvk4Ig9HKN0rKw6ks6F9Ll3ASMPN+zVSWNr725hfO4fXbh8Dt8QsW+WoBl2UVurYLV2CLldRw0yL1EF7XqvuLAh4CUG24j0G9MScOlDGKcm+4TjOYxynZIuUY88kHj3WR658XtTOIktwi1Ga3JZWHbfNEC/R7TALG/ZHGXybwF2OrQxgYH0bL9pgFOsylvNYaXIxkGlXZ8ZoiNPiwWv5zJajWFe2YdJHadETNy5606ySwwK1hqp8t3Ss3O4tl1XWle38b4NZxDw0G6s4Z8M0JZnic6/8phBt9ozCEn9pVuN8LsdqSht11KYkLtqbVfQ5ztjNNfGXjTrvhfq8pp9eLAxv1FqJfamu77PMi6HHDOLbYJaawRVrwKw2pWnC7ZqPw+4GlhvWFNrqEGBdxoq/tFhEu+LPYRrl3EZaqPeLTDTrxS1CFvn3ZgzMPKyVVCwlp6WPikVctyCAwlyE2Wss49/a2uYKSXe9k/1BULsyWE9ae9Pt8asWY/m1qY9jUg9q1F2qjnTV9rhqzKu3lozS9qBd5ZpYhPqSZ9LaXheOka0QQFtec+Eetug2JEvxfPKDAresa4FVrGOzFLPQxqpZ7Amw8HaswRoXwTjBn+9pL8vI7qpDUwult2qsbMKlKQ+lSroyH9OU58NDQaVbQ7j12MrxkvKGxbOUaF8h3QazwBIrgCWjNEGzkoJgczwWny8MUWmM4XDRhlgkiDtBxC8MVHVuVjdO0t8G/1ncS3ZLVzvBWwM4cUxyeUVmacSMq0iJ+dTzG6DSJKXXv0sqZZ2Ttae56V5/aEC5LS9hKxJ6RXS0kj3fmSKqiwbjubJOG7jcOt6diXgXZguBSw1oL0qDx4rBHksSM+9VjKUguY/YLY/aLCLytSLyT0Xk50TkZ0TkL+f3PyEi/1hEfjH//rj5zneLyOdE5OdF5E88do1KhtsLKLcy3Mx74nO3JO/mVwOPz4aksU/cbDzb6rxiJNdrRJ3tokK5FLZ9zdcsRvdyFVdJOCZQrgJz+VXdd+dS16qhR4YhlYAUqZgRX2tjYVVoec3PYSVNFvNX1FY5zyOq6hoDdwL+qqr+98AfBP6CpB79pX//NwA/nv9Hlv37vwX4WyJyuY9zKxKbG980WssD7rrUp98+/DQQFnmnRWzHOE+iyPLYosKKUWxUQpot89DyAy8P3R4nWxKyMMU01WqEBbMZRLluTl4CmdlVr6qjUdl1Di+Biu38gVG1hmku0KPMoqqfV9V/k/9+DvwcqcX6t5H69pN//6n897eR+/er6i8DpX//+WusRmUeehNptp+txOuVYnshscqD3fI0jGRqV+l8yQsAm8VJyrm3vBnD4EBmrggx1JLVpd1m5sd+9xWM2OUiMEDnBXolm0XShg+/D/jXvMf9+0t5xmIjpUImYLhwOx+xX4qxupiYNmemMEQxOksySpZA60o/Nz+80rPt0iSXBKzsoVDusY2FmaDeZv5xOXar6+QrxHc2bUK3cZ9bX73uCiAiz4B/CPwVVX3n0qEb762eqoh8p4j8pIj85KiH8uaME6xE+ZWTUa94JihXznUBW7goLQpZl7swnGnpVc9RmCnbRJZRzkmrytBlA4hVvEfW0uAKUO2iMX8FXSVZRKQnMcrfU9V/lN/+ivr3q+3d7z6pK53phK2NqGxdc6X24W+t9jYXZBWHaiD65lorw7ms9mJAtwFPmLEd77ZR1jYOdS5loB3rxrkW37827vSKdI03JMDfBn5OVb/ffPQjpL79sO7f/2dFZCciX881/ftLpHaBh2yshGKk1i1X4nJybdrB5t3Ono89Z/JWGjQX5muN49LYbaB7S7OnUoA3X1+SN87a8lBW82GlkkvhjEXqxobnU+9xY+7a6zyaGLVB10iWPwT8eeDfi8hP5ff+Gu9l/35pQLhM7WotcaFki5gV9Fi0GFYP6KyKO/Pw5cwDFStZ7Jgs8CaSluU14n7D/thcNOmiM+iXj9uSOKuxbdF7kd2vqv+CbTsE3rP+/Y2BVRBT2wLLO0oKei282lpZaQDpAW0ld2+kZ55djRVu59Xh8oK6OlnGvJrocTVmq/uaa5mL5HRuzQAWTKteUbKZNlHaEswsEs4ylWW8R+h2AoniWCUoNbm31Wg09s0mDlJUk/2srPTqSc2pBSV4WD9vg3xbBu+FgJ+2zLGVLrkVHsjjPCtJeER9uDOMYluktnhWNqZX4OLW6S9++kGR0EyewVMuiM6zmV3nvtOKWhuNbkL+i3O10ehzZFTIgmFehUy1wiIXxhb7m3GV94rNtfre6vwbm4BfSbcTGypk2oMv2mhs6NRzOjp/mH5nMS5bq0Y1Ga8lbyYHBdtzViTYCZTNydsIdQ5uprHmh1aSjNyGZFhIGSMlS9Miy3Sm1Xyb9VZ705R7LZ+tQDc/o9MtFe/uEbo9ZrEpgSVKYEX4JePPurPnvJTFtWLukUuWChvXcEY9Nd7au6XVNWx8px1nScuUnMW3qGcmp1JGSjluUqdLI9k27Vkw3wKqePy+bkMNnaMrm/leRY2rufn5Y3QtoxR76V0Cia/0Pc3M1AQ7L9KrRO4NyWMZ3R8EichvAC+BL7zusbwCfYr/Osf7O1X1q7Y+uAlmARCRn1TVb37d47iWfiuO97bV0Bu6KXrDLG/oarolZvns6x7AK9JvufHejM3yhm6fbkmyvKEbpzfM8oauptfOLCLyLbkK4HMi8pnXPR4AEfkBEfl1Eflp8957X83w3o33g6nAsOUBH/SLVDzzS8DvAgbg3wLf+DrHlMf1R4BvAn7avPc3gc/kvz8D/I389zfmce+Ar8/34z/g8X4a+Kb891vAL+Rxvadjft2S5fcDn1PV/6CqJ+CHSNUBr5VU9Z8DX2ze/jbeo2qG95r0A6jAgNevhr4G+BXz/1WVAK+JFtUMgK1muJl7uFSBwVc45tfNLFdVAtw43cw9vNcVGC29bma5qhLgRujXchUD76aa4f2mSxUY+fOveMyvm1l+AvgGEfl6ERlIZa8/8prHdI7eu2qG95g+kAoMeL3eULbMv5Vkvf8S8D2vezx5TD8IfB4YSavwO4BPkmq6fzH//oQ5/nvy+H8e+JOvYbx/mKRG/h3wU/n1re/1mN/A/W/oanrf1NAtgm1v6Cuj90WySEqe/QXgj5PE+E8A366qP/ueX+wNfWD0fkmWmwTb3tBXRu9Xdv8W6PMH7AEi8p3AdwJ4uv/xqf8oqY7VHKT5RxF+wvIY87nW+pz1biLpaxeSvzfPa64t+bPSTkt1jUrUxkA0n20ca6957rhLuernrm3OoWWc+Tpix7d5jvTrnfCbX9AzObjvF7M8Cvqo7aLgP6V/8On/Mve+Fcm7dy1LQEr55aI/S+mmNKY25/Uc+TuquuyHYsstbL3yVjOfWvbpchcmn2p0TuO6CbHtMlVvsqlCNF0c5kL2uay23Ofi862J1LnozJa91muV6sIQ5vIQ21N44xzlsx97+wf+07nrvl/M8uqgTyz7+J0hWyymsqrxmdtb+EXdzKqHSmmYbChNnAJNA59cPAbkDkwbBfSlpVjpKgkLBrE9WGybVNW23YYsW4lY5j3T539RiGbPJc1e120jpNLtsumqebaNa6b3i1kq2Ab8FxLY9ucufqOsCNvlyLToKpOvqqn/rV2trlk5pbi8MJPIgglKu9KtrWRSp2y/YBhg2XLUm+pFc536GEtNcSMJC+OVay7apBqqrUds+9PF7iFxLhgrLcVc00PPtjfdYgLVuZV8OeZ1tDZV1UlE/iLwY6Q0hB9Q1Z+58IX5oRfxuNUHt2l0U1enFcWZRGSj3ZRb/u3iYleMsxR10e2g7m62tUOCeZBSwCzTN3clGUTSDMWZadN3I5VJHqPSscE3UvRV6RHP+H0rX1XVHwV+9KqD21JKMavE9py1dkhhkFU7sSyB8upOD4u5BLXZNaO2NDXtMBa7nW3177d7E22RXdVG4izVjqlvnqb1QgCkqbteNOzR3KPGC9A0/rGqtNxHOU9RdSJI3833dQXdTq1z3ncZMGoltRZHY1I9VvT6DYnSqJXFwyyMBabV+TDviaxVR8z1xdl4Loxr++Sm6210mtoyIscx2VxN6/aVCqwPNCDFhjBzsuoX0zJIHYNRY2WxtX1Y2gL7K/C21x1IXJJpb3GxznnrM6vjzQqtZLdYOUeGUTYbCdreLkUt2de1/WfzPcwdFWZGsYy06sPLxkO18/VYbXgZ48K4vV5d3Y5kwVjr1gsok1OM3o3JqzaBOGB+IIvVFlKrjOo5uOYaWT0tHsZGz92CX6w2gTKuefUqWuYpKs3uZRiM7ZUlhd0fyL6/Oueq6U+2d0qbj7LHs5GElSl1PnYh4S7QTTFLsSHqJLSSoH0IxtuhTyJ3Zdhm/b6Ji2hMbvjWnskwb623wF/WHamIefPv+v/5jlCV2cv+Qe31REyfl6xubZfwct8wz1PTRar2hbGwT8sIed7UfvY6vKF3QyvrvWGU6j7bFbBoQmhca3i030hdgYTZE1kOyJw3LB9I0/FytfqtSirSqfwfky0k7e5kW+O1au+M+1sXix1bmYdiOJf7sU17iue5uN7rwVlejVq1aW2HljZsgwrW1fPJciKsFwF18hdi2B5Xji1iW6RiLyIyG5pbDzkzQ2UEe10z1pX0axbLoqvVpg1mDN+8lUwBABcoLsxjFUn7HDSel+3Rd4luy8AFFg377P+wwDAWtsXWe+fcQbPCYUMSueUWeivPysnc9bHvUm/b3N82nzD9apnX3F/1koph3Ho01tAvtGFPbNoaZrMKHael1Ky98RqvjiXSfI5uQ7KUMW+KfAPtQ7rh8lmx6p1b9uMvZAN/sN2z317LfF9k3nC7Hms3IS+2TPn+qDNyC4mRClZkjXOZGVu21EvpT2fR2A3pNe8JsJZu1Yg94+lUJouKoshW+9QNug1moXEJw3ILWm1FJsxMstX+qzYulplhrK62hqGVIlLEfoHBM1pbqAXt3Hz+4upubgaax11VWtk3yFG30p3Pl5FlvPGSGhzpEkIbjaRsmc0AhMmrM1L2CmDudtRQ6//D0gtpkcym0eBCDbUNBDdojr/4+eUdK9zhXB+5rfftg7oG/2j2U9zGeNbfre8XQHKr/y2XVUu9fzHq88PlOp8B5Ky6aamx8hc5LPl8Wgy8LbGduzwmXd9ldNeZvrOTsSVk+b3ogPKA48qFrSu7xJFMCGIhNS1i2xrZWcqupGtFaJv0hnTS5Tla1Qu5a/llV7mlm2KWzbySM4hrtSmKCF24p8k2KCtP0i7js1iHlV0kxcVVhbLhQzFuIcd7lobqxU20i10iucX6pNlTMhFiqG1JFQzTysIOW2AhFCCSzARGmrZeU9O61M5vHWmbc3OBbodZqp1hYfW8AtXNUmGLrrhR4IyEyG4m2QDd6MK9GahsvLF6D6391O6capmhXv/CoDfu7dHEqHKMjeSfS4kw0ffH6DaYRc7o5yxmV/sn2wQes5qq5PCzpClTfVaVBNKEqSYPJBt+FQneMA7L//N5NkDCBtQTEbTv06My3xWLWNf73vB+rI3Weoua96A2WxerW0u6Oh4Xl4vCzRLnEt0Gs9AMdrHtbZ6MyPxesQHKijmHRBY8I6us1Yqs4jeuo7blPC1iXGhLstTbWRre6S2Z3e02QGgj7i019sci/FDBxBxnAuPhuLRoWqmX0z4WKZzIUqKfoRthlkzFE3CyLZqrCpgWntMqT8TC7vb0FeKf/1+Bc7Jx7RakK7m5LTJcvr8Y84ZRis8bey9TQ+uY7TlsgFGa1d+Cl2asC1VnHIQFWFgWGyCey+qQm2GWOcUPWG9rV2jLiCvUWP31ePtdmFVL84C2tk+x+/PMIyXvwBFMoHGDaS5RZpjkIem2YWoZpubStt5Yw2wiaevidg4sHrWwv2ZAUx8JIsKtMEtFcDdcv1bvGo+iHrK1m2kGrxbnLdSu5PL/AqJ3c9TWPqRySEl7NGkMK3rsAZSUiq3j2jDAhpe4gvsLlG+ClNVjPAdgXsEkhW6DWaAB4wzqag27qmOLCskTQkiTVKRHi9c0KOwqbmOg83rejM7OCUomY987cEPat7Dr6sNZbbFrqObV5hwTC7xp31+ej3z9apec2SGlXMduAmqTuGtM6grQcotuh1lgOXC7d08Rw+amZRxRDWjUFBEWw1jFkBNnkqszTdOSETNVpij1NkViNOAZkMZTjM0i9k/j2nC15y6vkrubDW/xHhkaZilqoYyz3Hc4I4WsjWZrgYqUyZJXpmk7OX0jvrRFt8MsGw9wRSWIh6ChMEFja5zDXGwtkA0SsnTbBb+dYD0fPHslhSHVGMn1YZUg5BKKr/hHudetfYzKTm5bNoY1xOu9WUAyslCNJaQBiclL+cq7oNtglsegaostlEn1PkdtG5CrntLmuBgbpy3FqPjK7FovUxQMumkN3bKpVf0/p2VGTdFeOy5re5T7qvaU5rofnZnGyWw4L4xaxyqbr9xHGV/fL2NH5xi+XVSPLVRuhFkU47qO0zzRbeTW7vnsHUo/Z35t3HwLk1tgbpF7mo9TKzVgad/kPJc2DCBFsliPyu5433hTZezzOLM00vJwmZnGGtgx4UELsjjQSuI10sqWupg5quex/5+hm2CWND92+1idC6Yw+Iibg34V2bXxIcswNocF5hhLDs7ZRCpgmSpgrlvHmFdrLUqrdkKsaLIYVbeV/TZf68x7ktDeRwvLrCRtYYCo6TwO5iL4WJHphZQs93sOjmjoJpjFRo7VSsKtYF5XHoLJOKuSxzBMa/GX1We8gUUcZSP+U8ewEOtavbGaEFWuUQCxrltko7VA2IIV8rVLzuxm/c+ZFNMFRFCYP19jIb3KPdkQiZF4Ok0fskBisdhbQ9dA+stYR1waivazlhlMQG2xW+ljEPcmjA8Wga3XkdlGqd0eNM6gWzuu7J5bl78yUl08zNL0DNmUg5J3KyJo9BupzUuPro7RMv0Fug1mEWYPpaiDkotSHkRZQaV849LNbUV/F9fL4F3ZqfSMulhQMURhGz2FpRqzNkKReHlc6V6NS916My1ia1RdHiA1ilzUI1JR2FpyYjP7zPdrSqfdYL2VRBt0G8ySybq0JWAmsDbOLJ7RMobR5Vt7FS8elClJhTNMUj7LgNu50lOrhlpgDGsYlziPGWu9b2NMVxW0lW9iEedhmJk0LO93y0aqn03TjCdlLwqAh7NTcCvMYnCOyDxRNWNektG2ZdFnWqkpOOsKbpakMk/q2SqBNk1hwzCsRWLF1ikJWNYw3oqAXxjzFlpry0Qkn3dRYFeMfucWxy6Rb617RX+4JIsBt5I3xNKjafIvUsWdZ2GXFGor+CytckWWzLd4MI0bvfjcSjaoTLXwNtzyu/baKylmPboYF31qVuO2tp1RJ6tKxnNAZ1mYBp64hm6DWYTqDhc4vHZ4wsDcNp/DAxrnsgmYRXz5f6vrwTlJUVa7YYQ6mfUhbhSItekLZRyZtu0fw2x1DoxHV3NqNbXFaG0YY8sBtUWaXVQ19bJcr2GIRUT9yuL422CWc2SNyGrFF5ylmWyLO9T3jGqDZYuw1t6Ij7TJKp6QJrS3Mm+ebJtisUhpMNeo9k69v8bWsozcxMYWUefShMiCcnGZCL5IqzTnfayQ7BLdHrMUFWNJazvwGXSyGe2N8WfBtza8LxqXuTP5OyWvo1JevZIRZUsJJW1Wqo03WeO0zc0pOcXFuDynKlc1P7p0o4sd5NyKGcuclftYqEp7zRBSKS4NM56h22AWxbiZDhuKX+RgFLylIJHjOBu2DS5TDMyapFxjQxn5LZdubR67EstqtUapjbkU5i1FaTYsUbL9FvaN5FCAyfct1EiBRdOeeozOc5PPVxmmXD9jJ5sR6ia3pczdud52Ld0Gs8DSuKXR9cUNtqtsCzBLX8zHzJOS4iRZRFskVBpQzFyvnsOeExIj1LhLTKqpje2VvBVbo10xFcOUdoyNAbsgqyKtS764fWvTmFCI/Sya8EhLV+TgPmoGywe5uWQO3FUMwEZTy2qOcZFktLDoF1HqWZ9X1DYXileI3LmUvNT3y++X8xrxPV9HapxlFvVpomtVZDRq0jCadVvbiHS9z/ng5au0G8svnabaGWqFbBtJJ95B39U+vosAp/cpSt112RZs+vg2dI3P9HeAb2ne+wzw46r6DaStST6TB/eNpDamvzd/529J6uN/FRU4Wm3T39ZFtQ+gYiVzu4nWoCvnqZNri9e9mzGGtt/K/M+Mx7T1RpaMFFmM3x4fl5UIi/Fu2RtFBddzxnwfcZ2VV1HaBrkt+Sx+Ls9dMoybVetXKln0A9lcUhc6tj74eRDn3U2Db2yVhGwx0GqSZbmy7bmkrMZztc1bQb5GorQSpJxfN5h+MdYtfMRWLcLMgKtmRvOxydAOCeFdocE6/34kPvRubZbFRo0iYjdq/FfmuLMbNYrp3b+Xp8sAVzpx+m3jGY3oXkHvhaxebkX9IgYzP4wF+lki2RZ2Bxb1TIXOxYm273ke70b7j1UIo4knAdBvCOpLbn9UqrPe1kSTjOOaJPaIW30ddHc9bV1tk11V9bOq+s2q+s09u0WS0UqV5JWzlhxGNWyt5pZRynEVm2hEdgtciVmdtWrPvNqVvmV7lP+3HmZmhpqhZ7+3EeBcqCxp7tt6jbA0WLNkWUANi+8VO+sys79byfJrIvLpLFW+4o0ahctg0SL4Z12/csClFW2ljLEbJNsBAjOQ1XWzSqlMMrcHWxjPTtLkqlaDXHJ/3fNjydeJzIne5f22OsAiuoXRbA7KliSzWIutJFhP6NrwbnNpNujdMsuPkDZo/D7WGzX+fRH5fuCruXajxuJpbL1f3L/yns1h2cw3md3FhSRqMu8LyJcYxhiA0s0PtTBI8cRySoN2+dhsZ8nUwfGUmLepadq0AzwG9ym2xlS7ZtpmQDZEsUgsN/jKmmmysVt8+pIT3H7HelqcUQGGHmUWEflB4I8CnxKRXwX+OolJflhEvgP4z8CfTjesPyMiPwz8LDABf0FVHymKPEN2ouwNtpKipXxMBZzUGH62zZeVUlA9Auk66ExwTQQtKso7tPfo0KFOkKjIGFL3784jB7+UDFu2VPmsXL908VaHRr++pxYrMQHXRaYcS2aq9wwLRHy1iF6BHmUWVf32Mx/9sTPHfy/wva88EhMYawOBlbYCgy0I1/y9MFzLuRdJSvPDFedgN6D7Ae1nBDX1d0tME3cd4c4TO8GdIv4QcKeAjD2y39U+tyqSE4zyGDuPdm4BAcgYkMMJOZ6SWuojEsPcl7eJP62nrAHojLSyaqrev4EYFvkz52yqhm4DwS03Zh9iG6soHZqgJkQlsW/Au1YcF+wgYAxZVzc4mB9IvlbXobue+HRH2JkyCgfqErOEvWN86gk9dEdHd+/wR48ERWwKJSBBcVO6Rtx1hH2HdlKP9YcJ5xxOFUoaZFT0dEIeDms3eDFlOi+KRuLUudiya+qcLJ2BD08+y2OcXTdhiKtJq9895yqTsBL2eYUOPZIRWykT2vfQd+h+IDzbMT0bCHuXGKTLUkJTPCfshPFOiAOEnTDtBDf5lJhfpIoTkMwsASQq0QuxS++7SXGj0g2OziWpJZmpmEK6Vq6cXHf4Zg53rEC5xDAFObaJ4tYwlsiCiRZe3wW6DWaBFWhVk5WhMRJDPWZBmUkWydLFJSz9avsehh7tuwXGokNHHDxx1zE98YQ7x7RzhEGIHenBR0Ah9qT3B+AOSs5NPZdPr9il70gAF4CY/neT4o+CPyqxSwzk912SMscJ9zBCiAn7sF5LbVY4M0OVxm01o02KajfAsPk4VppfkdNyG8wizAVcmSrD0Ngom9/Pto73cxykIJYakWGAuz16tyMOHXHfoXkLGs0rPu4cITPItJslR9glfnBTevDqEsPEPjNFD9pp4hnJ7w2K9pqMhQgyCe4kiUkOgj9C95CYLuwEn9VZ/yI9dAeI5v60NVeWyyirCNaf0RBzdWSkdns4N4cmqeoS3QazqNHBhTFa4/acMVukSWYS6fvkzRjvR589YfrInulpx/TMMz7JUsODduQVPjNAlQ69VgnhJkFGKkOoV8IAcZcZQ0BLcVcfka5wuhCjEEchTA45Ce4o+BP4B6E7CP5B6Q6O7iOe/r6nfz7Rvd3jXh6Q0wjjhJ5GUj8X1g+8VDwYm0X6bgkWFim1FeUuOUKPOM+3wSywNshEEgPA0hgrsZBcH0NmFBmGpGKGZH8UL0Z7z/TRHceP9xw/4jh+TBg/AtOTxAhxUPARdXoWz5YgyJhfRRs4Je4V3Qekj5SdfkUU8Ypz0eBqiqrkYLUjTI5pcsiDx79wdC8T87hR8AfH/ouOJ17oHbgHjzwcE4g4bkiFisOY/QJMsVuhhXReOBJmo9JH6HaYpYnKbgrEJmoLZG/AJ5d3N6C7LtkgfbL6w85z/HjH4WOO4yeE4yeV8ZMT3dOR/X5k14/0PuJdKnQPKkzBMwXHGDzT5JjGjnBycHJ5BecB7gLdLtD1IeNbgojifcQ5TX9LYhzvFO8iTpQQHSE6Xh4GHp7sCC863EmQKakoxOHHDgk7OhFciMkYn8L63lmr7LqIvKt2Sq3t3nIkLBp+gW6HWYq4LByupnWYUUFtqal4h3Qe7Ty664hPBsJdRxgc2gnT3nF65pieCGEP07PI7qMHPv7WPc+GEx8dHnjSnfhId2TnRh7iwEPoeTkNvHPacz8OvDgOvHzYMfquMoo4xTnFdyEPUYjB41yk6yJDN60aN7hc+tq5SOci7JPUOe56wqGDo0NfOsZnwvEthz90yc0eAzJOuRmAmS9Dq0VUOnHarLk2+NrM7WN0G8wizNFVm7nWqqatwKD3NbFHh45w1zE+7Qh7qcbq9EQIdzDdKfp04pMfecnXPHubj/YHPjG85Lf37/DV/Zf4mL/ny+EJvxme8aXpKV8Yn/HF0xN+/eEtfkOUF+wB6LqA9zGrFmGaHGHyxJNHe5C9ctenjPtT8JCPC9HhXcRLkjK9DzwdToxPHe887Ll/sSNoz/REGJ8Jp4PDTR3+0KHduhtDtT8alNh6k3XTrXKMrWOysahHIuZwK8zCGmkFtjnemXIQJ8mg7bskVXYd094zPXFM++TJhJ0w7SFkD8YPkWf9iY8P93yyf8mn+hf8zuEL/O7+N/iUH3kev8RvxCf8f9NHeeI+iScyRc8YZz3f+4iIcpo8p6lDi2rKqkh1rURFklqab03ofaB3oaqm47Ejup7YQdiR7mGfVKkrXl5J+DbzsfWga1VkSZ5Ss4sajSS6glHgVpileEM2KgyzqDWZ7jXI1nUzPH+3I+57wt4T9o5pJ4QBQp+8HM0vnKIKD1PPQ+gZO08vgb078cRNvOU8ngDcE73ji+4ZTpSdn/jk/iV33ZjsGHUcp4wCZ8ZwXmEXEKfEKLw8DpVBUhwv2y+iBBVOwXMMnn030bnIafKE0SOTICHjOkIC83aeuO/w9wVTiUt10kaqYRE/OxsLsvkzj7jNcCvMAosVUKlJClowikFd411PvOsIe5ewkSFhGMktTgtRvabfUThMHffTwDgkJvQoPcoTGfBuxEvgqA/s3QhAJ5FP7V7idi94Z9rx5dMTQm6xHmPycpyP+C6NMwTHfRjoukDnI0MXqtrRzCgPpx6XvaTELB1x9LiTJDe9aIdOCDuH33VJuniHFMnSVj+0cEOL4Iqc/55zazXX0O0wC8wQPCT8pB18wQNiCjpq59HeE3tP7ByxlyRNDF4yN7QRZII4Oh5OPW+f7vhof+B5v+c3wzN+xR0ZeYlPvS854egl8MSfiCq4/PSOsaOYmVXlqCDZsE3OhyNGIQSHc0qIwmnqKoONIZ0hqCRVhmccPYvGThkxrppLJEW2u85E0CN1XwOTkgosWsmvNsEqqszGsT5UkgWWeS0L0CgnGWVgKQUSh2TMeY/6hMSqk8QkXf6dQU2J4Mb0CkfH4WHg7WHPb3ZPeas/MKrn18aP8swfeOqOvOVSK4Ggwqe6F+xk4kXY8SLsOMakhmJmlBiFqJK3C7DxllnynLSorGKfJ29IVRiDJwRHCC4Be32SgKIFNTYBShHYDamZ0DTBlNt3lHkrQUWom1tZXGWxYXqZ70ybjQUaui1msXkZmVZQv0llwDvoXE0fUJfheD/bgFIg95BAL3dyhJPn/pgY5gvHZ7w93qXLo3xieMlvG97ho/6BQSY+0b3ASeQ+DhxjxyH0TDExS8xAWyFvjNgCmKoKIQgxOGIucBt2I72fXe7x1BGnjJn4LE405cu4yiykEEXfISEuUyA35s02D9iihUNh8JpLdFvM0pLtlnDO6hcMo6Tf5DhN+Tx6iDsIO0WzXRGz7fLF45OEeZCYZVTHqJ77bsdb/sAzf+AYe46x4+W04xB6xpjan3Y+sNsl6eKcJnVFQQKKa02+nlbmidFVw1gk2TthchASM0tMcHAJNGrnsvTMtT5bO66dmb9Hmx5xnQqCW2cWmEVoufGQN9w0SdNaAoLWRinkIA4JYwlPIrqLuC49yOPY8Y7s6X1yXzuJuAyFTtFz7DoOseeoHe9Me+6nnlPwhCxZ9v3Evp+I2fYYg2eKrno+SGIgkayupJgXwhQdXpTeB0SUMHnCJLhDsq1SQBLCSfCZYejcfO8wJzlZaisQSn5vUTNxw075UHZRaFIiKxUvqI1fVJfRQA/ZRrEqKfZK2Cu6i0ifoHhVKkbS+UjnA72LRIRJPafYcYwdx67jGHuej3sOoecYOqZsqA4+8LRPBvDbxz1TSBLHidJ3JZVCCDEzS4iZeZIXRA4FDC5ykAFRSekMmseeg5wl2KllH6XHJIFlGMMc2w2PSgDrw5L8ZKkkD0viAPFQe8ilSFw6LkYYJ9xhwvUed3L4XoknSXqfnF5QUmwnCJMkhDUH+Yph6X3EO0/nQ4oNRccUHYep522/J6pU9VPIi3LXjXykP+CyBCkxn6Gb6F2RUI6ggnfKyacYTIkXlecUouB8ZBoi012KEekx58MUw94VA16S+5xtjtZOqbQldZjtklWq5lYVQEO3wywlLlRAuWwhlpgdsMjn0GlK4fu+wx09fnDEISUVqWSVtM9gHCCj4Lwj7pJkcS4yjp6Yo8DOR0KXjNDQT4zB4zKIBlTDVbMb7UTZ+5FPDPd0LjCpY4xJRe38RO8DUYUxJvW084GnQ7mNZByXoKVqsnnc3ZRu8STwQmrCVUp/YE4cNyp4XaoqcyXDuY3Ia3pH/n1mz4GWbodZMtWCsgTrzkiuNDcTApxGxHtc7/G9T63nAkiUhLvsBNnlFZo9IoIQpiQhYnRoEGJeYbl/UrIhbLAyM0f5HVWq5HAS8UQGN7HzE0Ecd93IvhtTXIjEHJ2kyHb5P2iKakOWLC7ifSR2ulCpYBglu8ltMHVF7dY0C4zFJIC30uQR2P92mGVroDEZIBX+tzenisaInEbk3uGD4k49YexwU5dXXprk6U7SQxBgEqaHjtA7xOXcE9H0dzZAk00S6XLqQsJDHFN+uN5Fgo+8HHd84fiMOz9yPw0Jb3GRwU/c+YT+HkJPVGEiAXVeEsayl4nJO/yUkNyCt3ByiamlAIuScm2sqWEz94tECJpUdjRVDY3bXHGWra334NEM/9thlksU48wo1nCbppQ6GAJyGtFjj5x2yGlAZSB6nzPgihEHMjqIgo4O9gG/mzKjzGomhDRpnY/0LjLGxCjHU5quFHEOvBwHvIscfMcpps86Fxlc4M6P1cYJ0aGiRElpDZ1E9t24QIafi6JBkFOKDcFspCfJmm+hxIJ0VsmLhDE3z1MF5soxthFR6fJQQLsPTSkIVJullKqu8AFr4dtC9TihMaSs+CmF3L0q/ZDUUBh8zpktbiIoQtwpkax63GyXpF49KU+leDIlvaDYFunSyeYY42zbDD4wuAknkdEgveXcnVuqoimmgORx6pgmj44OP0oCD8dklPuT4k8Rd4y4MaTclhDZykdJEngNzM3H6rILaFPW++GQLKXwqUUgWzi6IJLWsCtJPuOEaqybebuHHr/39L2gPkFl7iQ18z5O5ByUvGo1O129Qh8JfcqQO8iQgoQ+0vchpUtCzXpLQ03G7uACTlJKwymmYKUW1eQCvQ90ktzzF+OOY+h4eRq4P/Wcjj1MDgmZUY7Q3Sv9y0j/PNDdj7j7ExxPtSlRJStZSvrGRg1RTZ8Ut86aaw3iDboNZoFFcEtaw6wtQsv2SGnlWbtfQ0I5neAOPd3LFDcCkODwx7mMI+TVG09FSgGS8kjiXVJTQZKtIENE9yN3+7FKhqK2iuToJPK0OxLVcQg9L8YdY/T188QwyYQ+TAOHqU+Mcuw5HnvCg68qyI3QHZT+QelfBPrnp8oochzzbmxZrdTEQl3hkSvK6ZM1r2arxPYC3QazlBTKLesdqttXmg/aHm51hZTvFi/p4YSvjQI7RGHKqzaMIJOQKkUzM+UEeQkJf9E+G8QO4iSMMcH0PksZ7zPT5HFEFU7RM0XP83HHIee7lByWY+iSaoouM8nA6eSZTh169Mi9p3sp9M+F/oXSPSj+IZXHysOYGGWckp2WY0MaZolRqUSjF02mrWfX1DpfWboKN8IspfPk1ehk0/Gv7femU6ohduTwvO6APoF8IZV1uKBMNvm68GkOOGqXPagOZPToyREOjtArsgt0w1TjO1N03I/9nPE2JpS3c5FdPzH4wHHsa2bd8dAzHTv0lOJBckoZ/sM7wvC2MjxX+vtI9xBwhxExEkVjhLjRdy9NZFXXJeIstg1aPKNqKuz/YbBZcpswgaVl3orHSx2Oagv2bPQeEqPIFOhyYTt0uEmIvaRgHWRxwoxpjEntpzBBLl/1OZLtPWGvxCBMWdJMk8vhgwTpayyBQuj6BMyFznEYO47HLjHJwSNHh88Z/W6C/oWw+5Kye1vpX0S6+4C/H3EPY64dGrP0NV7MVrUDM6NUKh022bBz4MMlWQSZt3OxdC5lYetGFwZd8px0Sp0RkkoSZNKaegkuG9Ra95FIaQAQveAc6CmbURnviB78SZhGIRwdses4FgwkJjBw3o0TTn1k3He4TlMpyTHZJd3B4U6k6sQT+AP0z5XdO5Hh7YnufsLfJ1Uqx2Sr6DhWyWDbickZhlmUiYTAxXZmV2b43wSzpIKyfr6JrVYT5zpWZ2mzKHWNeQs6kdTR6HDExZjdzgGJ822LSi18h8Qo0mkyoG1Q0qdgXtin0IE/QrFYJAqllrmWsHol9o6498ROU/lqrkZ0J/CnVMLavVSGl0r/PDC8M+KfH5DDiDwcawtTcob+YreRknIaQjJ4M4C52uFeswMwbbjHxsD98MD9tmfIQmqsI6KLtueGVklSOfCouSuBFBymSV2UkNPSsu0SS96uZPtlSpInSRYl7IRul3EbLaEErUnWqRY6qbpSLx275OGkqsP8OindA+yeB/p3At2LE/7FEXn5AKcRPZ0yHFAQWhM3a5HZgk21qZOQFlfp95LjRpvhgg/NTmaQEUcxxpYxdBujrN29dCFaW4mkEZ1ikjAh4EoR/RRxB48OubVGnvCUaJSi3m5SZIqJl0zaZuxyNygKopqYigg4CEPKB572qQwlDoIbtQJtpRVHdzAYymHMG4nHWXp4n3YhadROmZOKS/m8KXkbSa5zO+fb2paoZ+f0DN0Os0CSIAVpLf1lbWO+jQbHiC4mdOEZQe2koCEzDOBU0VOHqz3i8svn3/m7boqpb0qr+jCpA/lvYkSCJqYacg3TnWd65gmDqz1ZSoqkKPhjwD9MuBfJNpFx2mjx2ly/lb41e65Jn7ywkRewUDuPBiYz3QizPCICt0SmMxKowV1WWIzV+XkrPRlLsDF1YVDvai+5CuRNKWcmAYU6G4ElNmPd/CwRxDu073BDjzsO+LFPRWJjRMaYzlNua4zIw4gcjolRTiNa6pltu/da/G7moy0c28pHMR2e2qSnR9uobtA1DQi/Fvi7wH9DErSfVdX/XUQ+AfwD4OuA/wj8GVX9Uv7OdwPfQXpkf0lVf+ziRZTcpRHArKjaFcBA2AVnUVnYMpSy17jcBaw2GixR2tMpHT9NNf9j0cq9VjxKKkTP2IZCZdJag2NjMmWyQ0q0JsTU/ksVOXVzXGeKs0QKIeEnp3EG26prvN0xHFipkCR5lwuqqKQaRtlqtXElvlLoGskyAX9VVf+NiLwF/D8i8o+B/43Uv//7ROQzpP7939X07/9q4J+IyO95tGtlWT2LEk/TEcD5NJFxqpMjMkuYmq2erf/yPc36utbaWKng5oyzRSFbaVVhJVIh5+YyUpgz+wpaLOmhyOQQVVyIqThsSpFxYpxzdLJq1Cnke9NZZZbtccp5bVG7M2ERi1wXatVSSSxrGeWKwjJL13Sr/DxQWq8/F5GfI7VY/zZSy1NI/fv/GfBdmP79wC+LSOnf/y8vXqjcSEnIjmZjqcUNzqH3Ws/bUPUWzq0YW9rZ3i8gJQ1qMyE6MdBiu+AS2HQASQVqVIRTUhNTqGEIjbFKJi3nsmUdJXEpXz8VPbkZIigP10iLlf1RFkyW0jW3xeIpxWXenqFNeiWbRUS+Dvh9wL/mK+zf3/buX8QsNnYgqzq569KqKu5gC19vrJiSXaYt77TgVBHV5drFQ/OuMkZl0jGsV2ZlGEADOmXjtzBGxkNK1lvNSSkLpGyEHuaanq0A4QJmqOmoulxYmpsYZqdAxNeeu0VSrtpvPEJXM4uIPAP+IfBXVPWdC+Jr64PVaFT1s8BnAT7afdX8ebEtXLMD2XIw87EtmuvcouNRMhQ3otkbQJTkyPYiL6Qwawl4t9vDbDUANBttacnVNNvtbRXRtXko1t3dyjVZ9LKt1/Tz8Vg1nnNzdcnYC7n6XiVsi0hPYpS/p6r/KL/9HvbvX0dIZzxAa4Cw/m8eWJ2Q0q2yZWK7zZzpQ4fLG4y3TGPEs9jMs/qx8Yrqm0ZtWGq7bZqFsKCiDkKcUVmWTLXCn7KaVkmhku02H2YOiy1YEN42rTI+buQ+eoSkK/5t4OdU9fvNRz9C6tsP6/79f1ZEdiLy9VzTv1/nVSD2gRusBUg3eDql1zQtb7Z6M2ZSF3+7CnTh3Jxe2HZDMg2EtKZOaN4QqpFk9hbCvClVUVXlOxVyL1QkYmOg6ulEPB6XUsu55QISV724Ss4t5828X++rMKDPTaP7vu6lVFX+e9AH9w8Bfx749yLyU/m9v8b72b9/o0CqloE0+RsLl7e1HwydCxNUholNqqKxCRYIsUFTV9dqQw6WWsZuKcbZG/J+Vkpb7q0NCrYusb22uY9kuM9eUitt5cwisHSNN/Qv2LZD4L3q3y+NsbVl4BYqYrRMvsgya93sEdh+d2FEt5HWopbyOct7zY1ddjnLe1sGY5vY1Uo0SCmh5QFvjEFVs5G8YZiXa5i/tbHTKmBpv3dlxBluBsGV2f20DWaKuC3qqI0fFVp0ZsS4tHFmGJu3ayfowsOBDQYrzGq6eNvYTbVLmkY6lSHsOWp7jOU9tWkElanafRfNuBeSsxxTjFiXN52QjSrGV6AbYZYLtBXfaHWr7RBt94U2VQCbquTcCuXMhBb7oej36Giz9q6icg4r+awhvbVxeKOC2/Gtou72u/NB28d+uGJDa1qJzLi80bMdAJxQXcj8vZK2ufCc4DqYu5RT2ADe4iHLMpcm09lYTFE/fjnGZTjjDFkj1krDc1n5Bt3etGmMKn9PYkMfDKlRHVaUx8WkW+mwQDOj5rRJNm46eza5IK2E821s5+zKMt6URLYL0WOWZPYhX1qp1Raz5+GMBN2wjRr3f5EwtrrUGdsLlrDDlT3lrosgfdDUGnUtXTLIimtpbZX6vcct/mvH9a6PWcRnXnH6W0YpdGUpR6WN+bvGjpFrod73k0TkN4CXwBde91hegT7Ff53j/Z2q+lVbH9wEswCIyE+q6je/7nFcS78Vx3ubaugN3SS9YZY3dDXdErN89nUP4BXpt9x4b8ZmeUO3T7ckWd7QjdNrZxYR+RYR+XkR+VzO5X3tJCI/ICK/LiI/bd77hIj8YxH5xfz74+az787j/3kR+ROvYbxfKyL/VER+TkR+RkT+8vsy5pp78RpeJFz+l4DfBQzAvwW+8XWOKY/rjwDfBPy0ee9vAp/Jf38G+Bv572/M494BX5/vx3/A4/008E3577eAX8jjek/H/Loly+8HPqeq/0FVT8APkRK+Xyup6j8Hvti8/W2kxHTy7z9l3v8hVT2q6i8DJUH9AyNV/byq/pv893PAJtW/Z2N+3czyNcCvmP83k7tvhBYJ6oBNUL+Ze7iUVM9XOObXzSxbAYkPm3t2M/fQJtVfOnTjvUfH/LqZ5V0kd782+rWcmM5XnqD+3tOlpPr8+Vc85tfNLD8BfIOIfL2IDKRKxh95zWM6R+9dgvp7TB9IUj28Xm8oW+bfSrLefwn4ntc9njymHyRVYY6kVfgdwCeBHwd+Mf/+hDn+e/L4fx74k69hvH+YpEb+HfBT+fWt7/WY3yC4b+hqet1q6A19iOgNs7yhq+kNs7yhq+kNs7yhq+kNs7yhq+kNs7yhq+kNs7yhq+kNs7yhq+n/B9HOLQyp8ewdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "for ii in idx_rand:\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].imshow(dataset_train[ii][0][0][0])\n",
    "    axs[1].imshow(dataset_train[ii][0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nstWf2PhVwfV",
    "outputId": "968f73ab-75d7-4735-ea1e-49e7fb3821cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_helpers.delete_all_cuda_tensors(globals())\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "model.prep_contrast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yDqu-bi8mnJB"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=64)\n",
    "\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-3.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_EOD_transfmod=norm'\n",
    "model.forward = model.forward_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/695, loss_train: 7.561, loss_val: nan, pos_over_neg: 1.0406272411346436 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 7.1437, loss_val: nan, pos_over_neg: 2.7838664054870605 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 6.895, loss_val: nan, pos_over_neg: 2.958254337310791 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 6.6375, loss_val: nan, pos_over_neg: 16.179611206054688 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 6.5539, loss_val: nan, pos_over_neg: 17.238676071166992 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 6.4695, loss_val: nan, pos_over_neg: 20.072927474975586 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 6.4008, loss_val: nan, pos_over_neg: 36.53895568847656 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 6.3493, loss_val: nan, pos_over_neg: 51.54439926147461 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 6.3351, loss_val: nan, pos_over_neg: 57.25225830078125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 6.2888, loss_val: nan, pos_over_neg: 73.40570068359375 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 6.2712, loss_val: nan, pos_over_neg: 89.42797088623047 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 6.2624, loss_val: nan, pos_over_neg: 102.28662872314453 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 6.2387, loss_val: nan, pos_over_neg: 108.83406066894531 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 6.2314, loss_val: nan, pos_over_neg: 122.15565490722656 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 6.2159, loss_val: nan, pos_over_neg: 138.1888427734375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 6.2031, loss_val: nan, pos_over_neg: 288.6463623046875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 6.1917, loss_val: nan, pos_over_neg: 290.41534423828125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 6.1747, loss_val: nan, pos_over_neg: 242.0494384765625 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 6.1801, loss_val: nan, pos_over_neg: 229.5741729736328 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 6.1568, loss_val: nan, pos_over_neg: 174.9648895263672 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 6.1423, loss_val: nan, pos_over_neg: 267.6479797363281 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 6.1402, loss_val: nan, pos_over_neg: 281.8436584472656 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 6.1298, loss_val: nan, pos_over_neg: 553.6534423828125 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 6.1186, loss_val: nan, pos_over_neg: 594.5422973632812 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 6.1328, loss_val: nan, pos_over_neg: 482.88531494140625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 6.111, loss_val: nan, pos_over_neg: 405.0965576171875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 6.1086, loss_val: nan, pos_over_neg: 401.2702331542969 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 6.0988, loss_val: nan, pos_over_neg: 581.5630493164062 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 6.0823, loss_val: nan, pos_over_neg: 1654.7904052734375 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 6.0914, loss_val: nan, pos_over_neg: 4858.28173828125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 6.0872, loss_val: nan, pos_over_neg: 714.7122802734375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 6.0778, loss_val: nan, pos_over_neg: 1275.96728515625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 6.0677, loss_val: nan, pos_over_neg: 455.51361083984375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 6.0575, loss_val: nan, pos_over_neg: 576.1466674804688 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 6.0515, loss_val: nan, pos_over_neg: 658.7351684570312 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 6.0421, loss_val: nan, pos_over_neg: 1438.4547119140625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 6.0495, loss_val: nan, pos_over_neg: 415.7337951660156 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 6.0488, loss_val: nan, pos_over_neg: 311.3133239746094 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 6.0504, loss_val: nan, pos_over_neg: 462.8885192871094 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 6.0265, loss_val: nan, pos_over_neg: 512.9998168945312 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 6.033, loss_val: nan, pos_over_neg: 283.20068359375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 6.0357, loss_val: nan, pos_over_neg: 431.7403869628906 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 6.0191, loss_val: nan, pos_over_neg: 474.0910949707031 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 6.0199, loss_val: nan, pos_over_neg: 826.376220703125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 6.0127, loss_val: nan, pos_over_neg: 1117.655029296875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 6.0118, loss_val: nan, pos_over_neg: 589.2134399414062 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 6.0083, loss_val: nan, pos_over_neg: 967.7493896484375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 6.0239, loss_val: nan, pos_over_neg: 676.8668212890625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.998, loss_val: nan, pos_over_neg: 697.9849243164062 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.9994, loss_val: nan, pos_over_neg: 589.5675659179688 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.9985, loss_val: nan, pos_over_neg: 343.64117431640625 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.9921, loss_val: nan, pos_over_neg: 561.0369262695312 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.9916, loss_val: nan, pos_over_neg: 858.2838134765625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.9917, loss_val: nan, pos_over_neg: 587.3544311523438 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.985, loss_val: nan, pos_over_neg: 640.604248046875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.9882, loss_val: nan, pos_over_neg: 805.6868286132812 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.9857, loss_val: nan, pos_over_neg: 1245.908203125 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.9871, loss_val: nan, pos_over_neg: 780.0598754882812 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.9761, loss_val: nan, pos_over_neg: 452.32275390625 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.9711, loss_val: nan, pos_over_neg: 883.5457153320312 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.9698, loss_val: nan, pos_over_neg: 1065.2318115234375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.9639, loss_val: nan, pos_over_neg: 835.459228515625 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.9672, loss_val: nan, pos_over_neg: 599.2987060546875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.9612, loss_val: nan, pos_over_neg: 1152.0286865234375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.9598, loss_val: nan, pos_over_neg: 494.8822021484375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.9597, loss_val: nan, pos_over_neg: 752.4922485351562 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.9629, loss_val: nan, pos_over_neg: 353.690673828125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.9613, loss_val: nan, pos_over_neg: 281.2787170410156 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.9554, loss_val: nan, pos_over_neg: 480.4079895019531 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.9517, loss_val: nan, pos_over_neg: 432.58380126953125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.9516, loss_val: nan, pos_over_neg: 516.8991088867188 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.9524, loss_val: nan, pos_over_neg: 363.9932556152344 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.9439, loss_val: nan, pos_over_neg: 695.94482421875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.9538, loss_val: nan, pos_over_neg: 240.46153259277344 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.9464, loss_val: nan, pos_over_neg: 469.71844482421875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.9498, loss_val: nan, pos_over_neg: 384.4450378417969 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.9446, loss_val: nan, pos_over_neg: 219.31138610839844 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.9463, loss_val: nan, pos_over_neg: 265.6125183105469 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.9438, loss_val: nan, pos_over_neg: 212.2339324951172 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.9437, loss_val: nan, pos_over_neg: 275.24542236328125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.9469, loss_val: nan, pos_over_neg: 204.02203369140625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.9359, loss_val: nan, pos_over_neg: 169.3885040283203 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.9376, loss_val: nan, pos_over_neg: 225.54306030273438 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.9369, loss_val: nan, pos_over_neg: 267.5456237792969 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.9411, loss_val: nan, pos_over_neg: 200.01193237304688 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.9352, loss_val: nan, pos_over_neg: 314.9439697265625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.9326, loss_val: nan, pos_over_neg: 195.321533203125 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.9302, loss_val: nan, pos_over_neg: 292.6367492675781 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.9298, loss_val: nan, pos_over_neg: 161.81204223632812 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.93, loss_val: nan, pos_over_neg: 166.3397216796875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.9391, loss_val: nan, pos_over_neg: 166.070556640625 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.9312, loss_val: nan, pos_over_neg: 264.6392517089844 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.9334, loss_val: nan, pos_over_neg: 212.5203857421875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.9152, loss_val: nan, pos_over_neg: 378.0916748046875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.9129, loss_val: nan, pos_over_neg: 226.96575927734375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.9255, loss_val: nan, pos_over_neg: 206.55650329589844 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.926, loss_val: nan, pos_over_neg: 219.1084442138672 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.9226, loss_val: nan, pos_over_neg: 408.9872131347656 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.9348, loss_val: nan, pos_over_neg: 171.7003631591797 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.9296, loss_val: nan, pos_over_neg: 429.77557373046875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.9217, loss_val: nan, pos_over_neg: 140.95254516601562 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.922, loss_val: nan, pos_over_neg: 326.42584228515625 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.9198, loss_val: nan, pos_over_neg: 187.3746337890625 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.9218, loss_val: nan, pos_over_neg: 204.83778381347656 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.9242, loss_val: nan, pos_over_neg: 422.80303955078125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.919, loss_val: nan, pos_over_neg: 376.8047180175781 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.9161, loss_val: nan, pos_over_neg: 346.8846435546875 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.9124, loss_val: nan, pos_over_neg: 306.9805603027344 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.9081, loss_val: nan, pos_over_neg: 446.6350402832031 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.9081, loss_val: nan, pos_over_neg: 236.72947692871094 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.9088, loss_val: nan, pos_over_neg: 575.9143676757812 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.9229, loss_val: nan, pos_over_neg: 271.65972900390625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.9123, loss_val: nan, pos_over_neg: 427.26873779296875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.8996, loss_val: nan, pos_over_neg: 558.9450073242188 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.9165, loss_val: nan, pos_over_neg: 355.63092041015625 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.917, loss_val: nan, pos_over_neg: 422.7732238769531 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.9025, loss_val: nan, pos_over_neg: 1470.525390625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.9031, loss_val: nan, pos_over_neg: 1026.944580078125 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.9006, loss_val: nan, pos_over_neg: 469.07196044921875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8981, loss_val: nan, pos_over_neg: 845.41845703125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.908, loss_val: nan, pos_over_neg: 438.24420166015625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.9033, loss_val: nan, pos_over_neg: 279.9639892578125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.9048, loss_val: nan, pos_over_neg: 406.466552734375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.9007, loss_val: nan, pos_over_neg: 498.6605529785156 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.9069, loss_val: nan, pos_over_neg: 602.8720092773438 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.9003, loss_val: nan, pos_over_neg: 512.4273071289062 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.9009, loss_val: nan, pos_over_neg: 383.2997741699219 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8957, loss_val: nan, pos_over_neg: 784.532470703125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.9008, loss_val: nan, pos_over_neg: 492.3697204589844 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.8983, loss_val: nan, pos_over_neg: 522.5752563476562 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.8925, loss_val: nan, pos_over_neg: 998.9774169921875 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.9045, loss_val: nan, pos_over_neg: 286.24560546875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 861.4822998046875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8893, loss_val: nan, pos_over_neg: 719.625244140625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8891, loss_val: nan, pos_over_neg: 552.5120239257812 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.8962, loss_val: nan, pos_over_neg: 629.3596801757812 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.9041, loss_val: nan, pos_over_neg: 295.4257507324219 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8991, loss_val: nan, pos_over_neg: 375.0988464355469 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.8934, loss_val: nan, pos_over_neg: 447.3165283203125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.9029, loss_val: nan, pos_over_neg: 643.9840087890625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.9001, loss_val: nan, pos_over_neg: 304.4423828125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.9043, loss_val: nan, pos_over_neg: 320.6342468261719 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.8918, loss_val: nan, pos_over_neg: 559.8406982421875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.895, loss_val: nan, pos_over_neg: 228.02149963378906 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.8932, loss_val: nan, pos_over_neg: 499.7993469238281 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.8984, loss_val: nan, pos_over_neg: 299.4985046386719 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.8915, loss_val: nan, pos_over_neg: 437.75445556640625 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.8923, loss_val: nan, pos_over_neg: 393.3487548828125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.8857, loss_val: nan, pos_over_neg: 308.4505615234375 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8877, loss_val: nan, pos_over_neg: 192.4589080810547 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8993, loss_val: nan, pos_over_neg: 423.0740966796875 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 400.94610595703125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.8954, loss_val: nan, pos_over_neg: 248.07977294921875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.8858, loss_val: nan, pos_over_neg: 307.95745849609375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.8824, loss_val: nan, pos_over_neg: 315.98663330078125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.8961, loss_val: nan, pos_over_neg: 167.09388732910156 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.8833, loss_val: nan, pos_over_neg: 411.69512939453125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.8782, loss_val: nan, pos_over_neg: 264.308349609375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.8929, loss_val: nan, pos_over_neg: 280.62652587890625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8818, loss_val: nan, pos_over_neg: 346.1852111816406 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.8865, loss_val: nan, pos_over_neg: 322.11328125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.8888, loss_val: nan, pos_over_neg: 244.31822204589844 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.8948, loss_val: nan, pos_over_neg: 264.3986511230469 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.8942, loss_val: nan, pos_over_neg: 288.2492370605469 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.8804, loss_val: nan, pos_over_neg: 327.0099792480469 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.8862, loss_val: nan, pos_over_neg: 294.8103332519531 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.889, loss_val: nan, pos_over_neg: 320.892333984375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 206.89479064941406 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8849, loss_val: nan, pos_over_neg: 392.11627197265625 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8837, loss_val: nan, pos_over_neg: 609.7481079101562 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.8902, loss_val: nan, pos_over_neg: 280.57818603515625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.8953, loss_val: nan, pos_over_neg: 309.51580810546875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 538.66845703125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8879, loss_val: nan, pos_over_neg: 493.6439208984375 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.881, loss_val: nan, pos_over_neg: 1251.6148681640625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8834, loss_val: nan, pos_over_neg: 340.30340576171875 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8784, loss_val: nan, pos_over_neg: 338.56787109375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8796, loss_val: nan, pos_over_neg: 232.83863830566406 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.8889, loss_val: nan, pos_over_neg: 352.8668518066406 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.876, loss_val: nan, pos_over_neg: 378.9056701660156 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8786, loss_val: nan, pos_over_neg: 243.36172485351562 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.8793, loss_val: nan, pos_over_neg: 320.53411865234375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.8783, loss_val: nan, pos_over_neg: 266.1648864746094 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.8789, loss_val: nan, pos_over_neg: 286.6021423339844 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.8801, loss_val: nan, pos_over_neg: 243.3916778564453 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8692, loss_val: nan, pos_over_neg: 388.0435791015625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8774, loss_val: nan, pos_over_neg: 282.40106201171875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8807, loss_val: nan, pos_over_neg: 552.4700927734375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.8743, loss_val: nan, pos_over_neg: 350.5192565917969 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8733, loss_val: nan, pos_over_neg: 339.1234436035156 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.8831, loss_val: nan, pos_over_neg: 216.7344970703125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.8829, loss_val: nan, pos_over_neg: 297.3126525878906 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8842, loss_val: nan, pos_over_neg: 339.361328125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.8704, loss_val: nan, pos_over_neg: 466.44921875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8746, loss_val: nan, pos_over_neg: 528.0011596679688 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8674, loss_val: nan, pos_over_neg: 414.3583679199219 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.868, loss_val: nan, pos_over_neg: 401.9936828613281 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.8622, loss_val: nan, pos_over_neg: 501.553955078125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.8705, loss_val: nan, pos_over_neg: 277.1014099121094 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.8723, loss_val: nan, pos_over_neg: 307.5799865722656 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 262.11669921875 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.8768, loss_val: nan, pos_over_neg: 267.3433532714844 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.8675, loss_val: nan, pos_over_neg: 290.78131103515625 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 834.3775024414062 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.8724, loss_val: nan, pos_over_neg: 333.5639343261719 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.8713, loss_val: nan, pos_over_neg: 437.6472473144531 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.8795, loss_val: nan, pos_over_neg: 315.6172180175781 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8696, loss_val: nan, pos_over_neg: 338.26300048828125 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.8685, loss_val: nan, pos_over_neg: 315.3893737792969 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8777, loss_val: nan, pos_over_neg: 474.364013671875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.8694, loss_val: nan, pos_over_neg: 374.4551696777344 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.8693, loss_val: nan, pos_over_neg: 545.8118896484375 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.8618, loss_val: nan, pos_over_neg: 605.3755493164062 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8752, loss_val: nan, pos_over_neg: 487.1444091796875 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.8751, loss_val: nan, pos_over_neg: 675.61767578125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8701, loss_val: nan, pos_over_neg: 984.7408447265625 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.8756, loss_val: nan, pos_over_neg: 497.2686767578125 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8667, loss_val: nan, pos_over_neg: 1054.962646484375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.8626, loss_val: nan, pos_over_neg: 744.9117431640625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.8686, loss_val: nan, pos_over_neg: 638.9451904296875 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 991.3621826171875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 419.9337158203125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 386.2287902832031 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.8737, loss_val: nan, pos_over_neg: 860.4512329101562 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.8596, loss_val: nan, pos_over_neg: 362.415283203125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.8633, loss_val: nan, pos_over_neg: 327.218017578125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 1233.129638671875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.8606, loss_val: nan, pos_over_neg: 392.8208312988281 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8601, loss_val: nan, pos_over_neg: 399.7010803222656 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.8608, loss_val: nan, pos_over_neg: 1115.1905517578125 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8575, loss_val: nan, pos_over_neg: 435.1968078613281 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.868, loss_val: nan, pos_over_neg: 229.2433319091797 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 481.14764404296875 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.867, loss_val: nan, pos_over_neg: 268.7359619140625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.8615, loss_val: nan, pos_over_neg: 281.1131896972656 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.8642, loss_val: nan, pos_over_neg: 540.1484985351562 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.8581, loss_val: nan, pos_over_neg: 371.12744140625 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.8555, loss_val: nan, pos_over_neg: 287.71148681640625 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 267.9091491699219 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8648, loss_val: nan, pos_over_neg: 330.2658996582031 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.861, loss_val: nan, pos_over_neg: 282.7842102050781 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.8668, loss_val: nan, pos_over_neg: 260.5259094238281 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 408.23345947265625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.8718, loss_val: nan, pos_over_neg: 165.9580841064453 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 262.2378234863281 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.856, loss_val: nan, pos_over_neg: 292.0878601074219 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.8654, loss_val: nan, pos_over_neg: 255.77223205566406 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 281.4734191894531 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.8542, loss_val: nan, pos_over_neg: 223.33876037597656 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.8656, loss_val: nan, pos_over_neg: 235.99365234375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 180.2228240966797 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.8621, loss_val: nan, pos_over_neg: 130.5395050048828 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.8645, loss_val: nan, pos_over_neg: 237.50289916992188 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.8734, loss_val: nan, pos_over_neg: 210.38226318359375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.8663, loss_val: nan, pos_over_neg: 215.42343139648438 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.8639, loss_val: nan, pos_over_neg: 291.7784729003906 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.8625, loss_val: nan, pos_over_neg: 475.14044189453125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.8635, loss_val: nan, pos_over_neg: 235.4254608154297 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 278.3420104980469 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.8548, loss_val: nan, pos_over_neg: 363.1103210449219 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 365.60577392578125 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.8533, loss_val: nan, pos_over_neg: 309.80084228515625 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.8578, loss_val: nan, pos_over_neg: 325.69659423828125 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.8547, loss_val: nan, pos_over_neg: 342.4680480957031 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 488.03271484375 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.8631, loss_val: nan, pos_over_neg: 289.1060791015625 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.8652, loss_val: nan, pos_over_neg: 200.2051544189453 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.855, loss_val: nan, pos_over_neg: 637.1259765625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.8515, loss_val: nan, pos_over_neg: 403.2501220703125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.8698, loss_val: nan, pos_over_neg: 269.5799255371094 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.8537, loss_val: nan, pos_over_neg: 575.3956298828125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.8561, loss_val: nan, pos_over_neg: 624.0142211914062 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.8531, loss_val: nan, pos_over_neg: 783.2334594726562 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.8482, loss_val: nan, pos_over_neg: 478.2590026855469 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.8497, loss_val: nan, pos_over_neg: 933.1692504882812 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.8468, loss_val: nan, pos_over_neg: 445.59619140625 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.8443, loss_val: nan, pos_over_neg: 391.0372619628906 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 528.6085815429688 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 499.8476867675781 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8531, loss_val: nan, pos_over_neg: 469.7001953125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.8486, loss_val: nan, pos_over_neg: 1452.3665771484375 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.8466, loss_val: nan, pos_over_neg: 522.7847900390625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.8636, loss_val: nan, pos_over_neg: 710.61962890625 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.8569, loss_val: nan, pos_over_neg: 428.4845275878906 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8513, loss_val: nan, pos_over_neg: 534.1168823242188 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.8518, loss_val: nan, pos_over_neg: 507.5722961425781 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.843, loss_val: nan, pos_over_neg: 483.0872497558594 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 730.9231567382812 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 658.0223999023438 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 796.097900390625 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.8597, loss_val: nan, pos_over_neg: 342.75048828125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.8493, loss_val: nan, pos_over_neg: 477.692626953125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.8406, loss_val: nan, pos_over_neg: 910.8497314453125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.8586, loss_val: nan, pos_over_neg: 311.4239807128906 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 737.5087890625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8512, loss_val: nan, pos_over_neg: 251.1446990966797 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.8491, loss_val: nan, pos_over_neg: 323.2689208984375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.8464, loss_val: nan, pos_over_neg: 1113.2369384765625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.8451, loss_val: nan, pos_over_neg: 470.1921081542969 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.8546, loss_val: nan, pos_over_neg: 291.21112060546875 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.8484, loss_val: nan, pos_over_neg: 1100.474365234375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.8508, loss_val: nan, pos_over_neg: 304.08343505859375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 400.7959899902344 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.8428, loss_val: nan, pos_over_neg: 402.2886962890625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8472, loss_val: nan, pos_over_neg: 491.84869384765625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 344.42822265625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.8496, loss_val: nan, pos_over_neg: 390.1330871582031 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.8525, loss_val: nan, pos_over_neg: 532.982177734375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 1485.2762451171875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8517, loss_val: nan, pos_over_neg: 302.8625793457031 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.8573, loss_val: nan, pos_over_neg: 690.6773681640625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.8614, loss_val: nan, pos_over_neg: 236.8928985595703 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 438.095703125 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.8426, loss_val: nan, pos_over_neg: 885.794921875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.8494, loss_val: nan, pos_over_neg: 410.04693603515625 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.8411, loss_val: nan, pos_over_neg: 515.7009887695312 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.8441, loss_val: nan, pos_over_neg: 925.9277954101562 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 318.9963073730469 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 397.5552673339844 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.8413, loss_val: nan, pos_over_neg: 453.3985595703125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 490.0007019042969 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.8481, loss_val: nan, pos_over_neg: 355.4294128417969 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 631.9004516601562 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 513.765380859375 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.8445, loss_val: nan, pos_over_neg: 556.7110595703125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.8514, loss_val: nan, pos_over_neg: 495.3802490234375 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.8458, loss_val: nan, pos_over_neg: 325.4133605957031 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 417.92919921875 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 370.0782775878906 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.8447, loss_val: nan, pos_over_neg: 336.356201171875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.8462, loss_val: nan, pos_over_neg: 462.3110656738281 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.848, loss_val: nan, pos_over_neg: 534.3580322265625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.8403, loss_val: nan, pos_over_neg: 582.9722290039062 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.8489, loss_val: nan, pos_over_neg: 462.7986145019531 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.8376, loss_val: nan, pos_over_neg: 396.55157470703125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.8446, loss_val: nan, pos_over_neg: 449.54833984375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 253.9103546142578 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.8501, loss_val: nan, pos_over_neg: 484.8041687011719 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 326.8728332519531 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 229.04112243652344 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.846, loss_val: nan, pos_over_neg: 448.9242248535156 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.8465, loss_val: nan, pos_over_neg: 346.060302734375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.8463, loss_val: nan, pos_over_neg: 303.9241638183594 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.8357, loss_val: nan, pos_over_neg: 405.29681396484375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 865.3277587890625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.8431, loss_val: nan, pos_over_neg: 301.094482421875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.8467, loss_val: nan, pos_over_neg: 371.636474609375 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.8404, loss_val: nan, pos_over_neg: 548.7706298828125 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 314.8899841308594 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.8388, loss_val: nan, pos_over_neg: 443.3572082519531 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.8298, loss_val: nan, pos_over_neg: 739.8182373046875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.838, loss_val: nan, pos_over_neg: 611.8123779296875 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.8355, loss_val: nan, pos_over_neg: 665.4151000976562 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 459.4111633300781 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 561.8016357421875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 1247.267578125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.8488, loss_val: nan, pos_over_neg: 462.523193359375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.8382, loss_val: nan, pos_over_neg: 469.3202209472656 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.8363, loss_val: nan, pos_over_neg: 582.9827880859375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.8422, loss_val: nan, pos_over_neg: 404.0508117675781 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 24253.458984375 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.8414, loss_val: nan, pos_over_neg: 757.4710693359375 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.8449, loss_val: nan, pos_over_neg: 788.7235107421875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.8386, loss_val: nan, pos_over_neg: 1082.4471435546875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.85, loss_val: nan, pos_over_neg: 441.6356506347656 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 526.005615234375 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.8419, loss_val: nan, pos_over_neg: 582.7532348632812 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 404.91192626953125 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 592.9266357421875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.8371, loss_val: nan, pos_over_neg: 416.617431640625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.8427, loss_val: nan, pos_over_neg: 377.7923583984375 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.8416, loss_val: nan, pos_over_neg: 371.81005859375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 335.4534606933594 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.8366, loss_val: nan, pos_over_neg: 392.9441223144531 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.8487, loss_val: nan, pos_over_neg: 424.55694580078125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.8408, loss_val: nan, pos_over_neg: 441.8601379394531 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.8395, loss_val: nan, pos_over_neg: 653.4637451171875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.8391, loss_val: nan, pos_over_neg: 2062.734130859375 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 1094.6788330078125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 561.4603271484375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 894.576416015625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.8232, loss_val: nan, pos_over_neg: 1058.4271240234375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 403.68341064453125 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.8312, loss_val: nan, pos_over_neg: 1202.648193359375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.8434, loss_val: nan, pos_over_neg: 508.2920837402344 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.8319, loss_val: nan, pos_over_neg: 590.0029907226562 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.8346, loss_val: nan, pos_over_neg: 502.0337219238281 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 656.1820678710938 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.8478, loss_val: nan, pos_over_neg: 240.60960388183594 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.8255, loss_val: nan, pos_over_neg: 1541.0582275390625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.841, loss_val: nan, pos_over_neg: 609.4596557617188 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.8452, loss_val: nan, pos_over_neg: 336.8987121582031 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.8347, loss_val: nan, pos_over_neg: 682.138671875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 403.2839660644531 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 1056.2738037109375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 988.6829223632812 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 448.8362121582031 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.8393, loss_val: nan, pos_over_neg: 488.8137512207031 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.8302, loss_val: nan, pos_over_neg: 1326.185791015625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.8362, loss_val: nan, pos_over_neg: 461.16845703125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.8274, loss_val: nan, pos_over_neg: 612.3759765625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.8327, loss_val: nan, pos_over_neg: 607.6264038085938 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 473.9265441894531 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.8296, loss_val: nan, pos_over_neg: 757.5050048828125 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 428.7920227050781 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 851.7434692382812 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.8301, loss_val: nan, pos_over_neg: 755.2245483398438 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.8263, loss_val: nan, pos_over_neg: 456.1540832519531 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 212.89202880859375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.8369, loss_val: nan, pos_over_neg: 362.0408935546875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 536.1411743164062 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.8361, loss_val: nan, pos_over_neg: 324.4808349609375 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.835, loss_val: nan, pos_over_neg: 463.3096008300781 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.8283, loss_val: nan, pos_over_neg: 673.5831298828125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.8351, loss_val: nan, pos_over_neg: 584.4996948242188 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.8436, loss_val: nan, pos_over_neg: 521.4400024414062 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.8299, loss_val: nan, pos_over_neg: 524.4166870117188 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.8322, loss_val: nan, pos_over_neg: 1106.46337890625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.8339, loss_val: nan, pos_over_neg: 505.1425476074219 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 331.0378723144531 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 397.5867614746094 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.8354, loss_val: nan, pos_over_neg: 410.8880615234375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 460.75018310546875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.8437, loss_val: nan, pos_over_neg: 374.7461242675781 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.8314, loss_val: nan, pos_over_neg: 377.9346008300781 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.8249, loss_val: nan, pos_over_neg: 899.4092407226562 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.8399, loss_val: nan, pos_over_neg: 366.8294982910156 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.8365, loss_val: nan, pos_over_neg: 324.20428466796875 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 305.2547912597656 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.8324, loss_val: nan, pos_over_neg: 327.5373840332031 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.8337, loss_val: nan, pos_over_neg: 377.54901123046875 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.827, loss_val: nan, pos_over_neg: 227.3107452392578 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 428.8118591308594 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.8397, loss_val: nan, pos_over_neg: 271.6235046386719 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.8321, loss_val: nan, pos_over_neg: 427.5341796875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 604.8531494140625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.8313, loss_val: nan, pos_over_neg: 634.5294799804688 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.8271, loss_val: nan, pos_over_neg: 507.052001953125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.8401, loss_val: nan, pos_over_neg: 427.12445068359375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 1498.0072021484375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.8286, loss_val: nan, pos_over_neg: 708.2941284179688 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 368.7894287109375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 953.913330078125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.8375, loss_val: nan, pos_over_neg: 1707.705322265625 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.8424, loss_val: nan, pos_over_neg: 605.7098999023438 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 1474.2969970703125 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.8329, loss_val: nan, pos_over_neg: 1107.9892578125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.8306, loss_val: nan, pos_over_neg: 721.0105590820312 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.8455, loss_val: nan, pos_over_neg: 501.4684143066406 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.8309, loss_val: nan, pos_over_neg: 555.0899047851562 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 569.4574584960938 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 553.6539306640625 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 420.6556396484375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.8205, loss_val: nan, pos_over_neg: 1905.7747802734375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.8315, loss_val: nan, pos_over_neg: 805.2633666992188 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.8316, loss_val: nan, pos_over_neg: 769.9915771484375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.8271, loss_val: nan, pos_over_neg: 635.6024780273438 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.8291, loss_val: nan, pos_over_neg: 489.603271484375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.8344, loss_val: nan, pos_over_neg: 460.08935546875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.8332, loss_val: nan, pos_over_neg: 933.4190673828125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 683.637451171875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.8293, loss_val: nan, pos_over_neg: 929.3563232421875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.8343, loss_val: nan, pos_over_neg: 2004.572265625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 705.263427734375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.8342, loss_val: nan, pos_over_neg: 724.5135498046875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.8285, loss_val: nan, pos_over_neg: 905.7218627929688 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 549.8933715820312 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.832, loss_val: nan, pos_over_neg: 977.36181640625 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.828, loss_val: nan, pos_over_neg: 1079.8863525390625 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.8333, loss_val: nan, pos_over_neg: 393.5815734863281 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 691.3600463867188 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.8281, loss_val: nan, pos_over_neg: 585.5517578125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.8267, loss_val: nan, pos_over_neg: 585.46044921875 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 492.4238586425781 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.8206, loss_val: nan, pos_over_neg: 358.7685241699219 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 549.2636108398438 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 404.30889892578125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.8289, loss_val: nan, pos_over_neg: 278.0289611816406 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.8236, loss_val: nan, pos_over_neg: 532.10888671875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.8217, loss_val: nan, pos_over_neg: 399.9735412597656 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 469.8783264160156 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.8214, loss_val: nan, pos_over_neg: 851.5350341796875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 506.2495422363281 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 430.37384033203125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.8246, loss_val: nan, pos_over_neg: 288.73492431640625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 261.22528076171875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.8235, loss_val: nan, pos_over_neg: 532.5771484375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.8311, loss_val: nan, pos_over_neg: 545.8233642578125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.8305, loss_val: nan, pos_over_neg: 266.9793395996094 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 603.203369140625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 1398.166015625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 296.1729431152344 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.8308, loss_val: nan, pos_over_neg: 220.26632690429688 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.8279, loss_val: nan, pos_over_neg: 373.2925109863281 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 247.08978271484375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.8328, loss_val: nan, pos_over_neg: 358.1337585449219 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.8335, loss_val: nan, pos_over_neg: 653.3931884765625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 368.8937072753906 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.8272, loss_val: nan, pos_over_neg: 757.2488403320312 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 518.1210327148438 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.8238, loss_val: nan, pos_over_neg: 541.4395751953125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.8264, loss_val: nan, pos_over_neg: 578.38525390625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.8261, loss_val: nan, pos_over_neg: 369.8306579589844 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 417.7370300292969 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.8272, loss_val: nan, pos_over_neg: 533.0194091796875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 704.5704345703125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 430.9649353027344 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.8228, loss_val: nan, pos_over_neg: 776.2390747070312 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.825, loss_val: nan, pos_over_neg: 500.5988464355469 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.8259, loss_val: nan, pos_over_neg: 615.875244140625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.8297, loss_val: nan, pos_over_neg: 272.8201599121094 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.8271, loss_val: nan, pos_over_neg: 436.0481872558594 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.8215, loss_val: nan, pos_over_neg: 968.8899536132812 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 533.0858764648438 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.8284, loss_val: nan, pos_over_neg: 271.9205322265625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.8219, loss_val: nan, pos_over_neg: 677.6376342773438 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.82, loss_val: nan, pos_over_neg: 664.41943359375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 522.358154296875 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.82, loss_val: nan, pos_over_neg: 443.0562438964844 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 565.8646850585938 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 374.2767639160156 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.818, loss_val: nan, pos_over_neg: 511.3064270019531 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 885.1849975585938 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.8201, loss_val: nan, pos_over_neg: 532.5111694335938 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.8282, loss_val: nan, pos_over_neg: 791.8751831054688 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.8167, loss_val: nan, pos_over_neg: 671.7706909179688 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.8229, loss_val: nan, pos_over_neg: 387.8023681640625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 396.030029296875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.8251, loss_val: nan, pos_over_neg: 428.6699523925781 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.8243, loss_val: nan, pos_over_neg: 474.2444152832031 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 500.81634521484375 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 296.7005310058594 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.8176, loss_val: nan, pos_over_neg: 542.2988891601562 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 737.6129150390625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.823, loss_val: nan, pos_over_neg: 395.46502685546875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.822, loss_val: nan, pos_over_neg: 612.5830688476562 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 929.9400634765625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 3156.257080078125 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.8158, loss_val: nan, pos_over_neg: 551.0802612304688 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.8184, loss_val: nan, pos_over_neg: 334.4405212402344 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 1329.7021484375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 1734.467041015625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 742.895751953125 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.8183, loss_val: nan, pos_over_neg: 773.7490234375 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.8226, loss_val: nan, pos_over_neg: 695.05908203125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.8208, loss_val: nan, pos_over_neg: 438.8953857421875 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.8171, loss_val: nan, pos_over_neg: 804.5739135742188 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 1345.6414794921875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.8127, loss_val: nan, pos_over_neg: 708.7081298828125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 517.9635009765625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.8202, loss_val: nan, pos_over_neg: 2074.002197265625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.8077, loss_val: nan, pos_over_neg: 1011.5122680664062 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.8144, loss_val: nan, pos_over_neg: 796.4813842773438 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.8187, loss_val: nan, pos_over_neg: 697.0620727539062 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 805.4195556640625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 596.5200805664062 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.8199, loss_val: nan, pos_over_neg: 917.5835571289062 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.8203, loss_val: nan, pos_over_neg: 918.7103881835938 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 632.4913330078125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.8146, loss_val: nan, pos_over_neg: 2109.052978515625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.8184, loss_val: nan, pos_over_neg: 517.6177368164062 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.8154, loss_val: nan, pos_over_neg: 858.7730712890625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 1378.643310546875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.8075, loss_val: nan, pos_over_neg: 1307.0643310546875 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.8185, loss_val: nan, pos_over_neg: 562.8764038085938 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 664.9507446289062 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.8157, loss_val: nan, pos_over_neg: 871.3294067382812 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 1090.21044921875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 647.6016845703125 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 596.237548828125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.8247, loss_val: nan, pos_over_neg: 461.1412658691406 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.8172, loss_val: nan, pos_over_neg: 507.3037109375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 876.1061401367188 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.8196, loss_val: nan, pos_over_neg: 526.4063110351562 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.8146, loss_val: nan, pos_over_neg: 491.1146545410156 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.8194, loss_val: nan, pos_over_neg: 325.65838623046875 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.8191, loss_val: nan, pos_over_neg: 452.0570068359375 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 497.76947021484375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.8132, loss_val: nan, pos_over_neg: 575.5966796875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.8318, loss_val: nan, pos_over_neg: 304.4831848144531 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.8156, loss_val: nan, pos_over_neg: 447.8306579589844 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 589.876220703125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 395.2566833496094 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 446.8480224609375 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.811, loss_val: nan, pos_over_neg: 546.42333984375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.8232, loss_val: nan, pos_over_neg: 216.3643035888672 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.82, loss_val: nan, pos_over_neg: 324.7570495605469 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 444.7350769042969 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 346.58544921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 274.80804443359375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.8182, loss_val: nan, pos_over_neg: 472.2458801269531 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 345.70086669921875 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 540.1668090820312 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.8239, loss_val: nan, pos_over_neg: 369.057373046875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.8212, loss_val: nan, pos_over_neg: 325.8246765136719 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.8164, loss_val: nan, pos_over_neg: 457.1015625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 498.19561767578125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.8085, loss_val: nan, pos_over_neg: 630.5281372070312 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 556.6649169921875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.8165, loss_val: nan, pos_over_neg: 539.3636474609375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.8119, loss_val: nan, pos_over_neg: 787.2900390625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 834.4735717773438 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.8237, loss_val: nan, pos_over_neg: 319.1437683105469 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.8139, loss_val: nan, pos_over_neg: 490.6275634765625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.8225, loss_val: nan, pos_over_neg: 783.4057006835938 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 413.47320556640625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.8227, loss_val: nan, pos_over_neg: 310.4715881347656 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.823, loss_val: nan, pos_over_neg: 448.96331787109375 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.8109, loss_val: nan, pos_over_neg: 554.5848388671875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 621.8999633789062 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.8169, loss_val: nan, pos_over_neg: 724.2010498046875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.8161, loss_val: nan, pos_over_neg: 522.0313720703125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 329.88250732421875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 1402.2760009765625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 732.6361083984375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.8113, loss_val: nan, pos_over_neg: 401.0792236328125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.8216, loss_val: nan, pos_over_neg: 1310.8868408203125 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.8146, loss_val: nan, pos_over_neg: 732.2576904296875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 696.5208740234375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.8187, loss_val: nan, pos_over_neg: 516.8157348632812 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 904.5936279296875 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 2028.158203125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 822.6516723632812 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.8123, loss_val: nan, pos_over_neg: 483.8235168457031 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.8254, loss_val: nan, pos_over_neg: 516.9620971679688 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 626.4306640625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.8038, loss_val: nan, pos_over_neg: 1085.09619140625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.8122, loss_val: nan, pos_over_neg: 651.0115356445312 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.8151, loss_val: nan, pos_over_neg: 1519.575439453125 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 876.9779052734375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 1254.2998046875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.814, loss_val: nan, pos_over_neg: 591.240966796875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.8137, loss_val: nan, pos_over_neg: 945.0021362304688 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 831.6617431640625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 772.8836669921875 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.8076, loss_val: nan, pos_over_neg: 2275.15478515625 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 561.7546997070312 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.8146, loss_val: nan, pos_over_neg: 393.9616394042969 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.8155, loss_val: nan, pos_over_neg: 465.0767822265625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 610.8115234375 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 764.437744140625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 733.19482421875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 536.2705078125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.8147, loss_val: nan, pos_over_neg: 939.5437622070312 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 2365.692626953125 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.8218, loss_val: nan, pos_over_neg: 488.6971435546875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 1675.0833740234375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 1118.17333984375 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.8114, loss_val: nan, pos_over_neg: 419.1265563964844 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 585.2516479492188 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.8174, loss_val: nan, pos_over_neg: 596.4060668945312 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.8163, loss_val: nan, pos_over_neg: 562.629638671875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 501.3486328125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 613.9730834960938 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 3063.007568359375 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.8131, loss_val: nan, pos_over_neg: 573.69189453125 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 432.7169494628906 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.8106, loss_val: nan, pos_over_neg: 683.4788208007812 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 812.3922119140625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.8126, loss_val: nan, pos_over_neg: 745.3037109375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.8096, loss_val: nan, pos_over_neg: 1010.173583984375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.8044, loss_val: nan, pos_over_neg: 1949.3153076171875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.8133, loss_val: nan, pos_over_neg: 1881.47998046875 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.8156, loss_val: nan, pos_over_neg: 461.79876708984375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.8009, loss_val: nan, pos_over_neg: 1690.588134765625 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 597.4830322265625 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 960.5799560546875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.8167, loss_val: nan, pos_over_neg: 552.2374267578125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.8149, loss_val: nan, pos_over_neg: 535.4627685546875 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.8136, loss_val: nan, pos_over_neg: 475.09368896484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.8121, loss_val: nan, pos_over_neg: 1254.201416015625 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.8107, loss_val: nan, pos_over_neg: 721.427001953125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 626.8548583984375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.8068, loss_val: nan, pos_over_neg: 779.476806640625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 509.0385437011719 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.8105, loss_val: nan, pos_over_neg: 336.7978820800781 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7994, loss_val: nan, pos_over_neg: 1040.5977783203125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 841.3007202148438 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 546.6625366210938 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.8049, loss_val: nan, pos_over_neg: 1620.1614990234375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.8116, loss_val: nan, pos_over_neg: 1017.53466796875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 407.9725341796875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 790.0106201171875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.8143, loss_val: nan, pos_over_neg: 701.2212524414062 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 744.3230590820312 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 423.28472900390625 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.812, loss_val: nan, pos_over_neg: 563.2438354492188 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.8152, loss_val: nan, pos_over_neg: 650.8733520507812 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 488.2717590332031 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.8075, loss_val: nan, pos_over_neg: 2292.03515625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.8086, loss_val: nan, pos_over_neg: 905.5582275390625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.817, loss_val: nan, pos_over_neg: 293.05731201171875 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.8077, loss_val: nan, pos_over_neg: 615.2809448242188 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.8127, loss_val: nan, pos_over_neg: 809.2991943359375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.8058, loss_val: nan, pos_over_neg: 470.21795654296875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300000 [21:09<105761:08:49, 1269.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Iter: 0/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 411.4357604980469 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 441.9308166503906 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 548.5442504882812 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 625.7948608398438 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 340.034423828125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.807, loss_val: nan, pos_over_neg: 663.1629638671875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 764.852783203125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 511.5382995605469 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.8128, loss_val: nan, pos_over_neg: 309.436279296875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 593.6736450195312 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.8101, loss_val: nan, pos_over_neg: 381.29327392578125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.8071, loss_val: nan, pos_over_neg: 706.7661743164062 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 367.1083984375 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.8138, loss_val: nan, pos_over_neg: 384.9373474121094 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.8035, loss_val: nan, pos_over_neg: 703.977294921875 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.8043, loss_val: nan, pos_over_neg: 773.3689575195312 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 671.6004028320312 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.81, loss_val: nan, pos_over_neg: 339.748046875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.8055, loss_val: nan, pos_over_neg: 365.0990905761719 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.8186, loss_val: nan, pos_over_neg: 281.101318359375 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 786.2470703125 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.8134, loss_val: nan, pos_over_neg: 408.451904296875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.8109, loss_val: nan, pos_over_neg: 375.31463623046875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 425.71258544921875 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.8141, loss_val: nan, pos_over_neg: 408.52777099609375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 768.962646484375 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 896.811767578125 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.8133, loss_val: nan, pos_over_neg: 448.00909423828125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 501.8985595703125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 1447.458251953125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.8189, loss_val: nan, pos_over_neg: 505.5872802734375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.809, loss_val: nan, pos_over_neg: 544.8988647460938 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.8207, loss_val: nan, pos_over_neg: 265.9494934082031 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 887.1777954101562 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 1056.9332275390625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.8097, loss_val: nan, pos_over_neg: 477.3116455078125 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.8001, loss_val: nan, pos_over_neg: 1014.866455078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 414.42010498046875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 700.8162231445312 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 543.0391845703125 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 395.6590881347656 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.8129, loss_val: nan, pos_over_neg: 203.7183380126953 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.8048, loss_val: nan, pos_over_neg: 399.16351318359375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.8127, loss_val: nan, pos_over_neg: 559.1076049804688 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 638.3746337890625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 663.7412109375 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.8066, loss_val: nan, pos_over_neg: 427.0718688964844 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 588.2395629882812 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 644.7877807617188 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 451.3780212402344 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 428.34539794921875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 460.0118713378906 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 739.40185546875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 666.3450317382812 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.8079, loss_val: nan, pos_over_neg: 557.2849731445312 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 481.4781188964844 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 671.2811279296875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 720.655029296875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 427.92230224609375 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 364.3743591308594 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.8033, loss_val: nan, pos_over_neg: 610.6373901367188 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 418.2248840332031 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.806, loss_val: nan, pos_over_neg: 869.4940185546875 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.8007, loss_val: nan, pos_over_neg: 1907.8232421875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 674.16552734375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 1103.6864013671875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.8087, loss_val: nan, pos_over_neg: 463.0487976074219 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 1429.8311767578125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 700.3576049804688 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 523.439208984375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 768.0654296875 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 1217.8212890625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 620.1249389648438 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 953.2798461914062 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.8011, loss_val: nan, pos_over_neg: 823.2791748046875 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 811.1448974609375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 987.6314697265625 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.8018, loss_val: nan, pos_over_neg: 691.8639526367188 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 1006.3565673828125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 1028.9649658203125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 816.75732421875 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.8065, loss_val: nan, pos_over_neg: 891.281982421875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 941.4754028320312 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.8067, loss_val: nan, pos_over_neg: 599.7623901367188 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.8102, loss_val: nan, pos_over_neg: 640.1271362304688 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.8059, loss_val: nan, pos_over_neg: 1395.428955078125 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.8021, loss_val: nan, pos_over_neg: 372.4421081542969 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.8115, loss_val: nan, pos_over_neg: 347.2255859375 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 547.4993896484375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 743.50048828125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.8117, loss_val: nan, pos_over_neg: 594.1508178710938 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.808, loss_val: nan, pos_over_neg: 826.5723876953125 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 562.8524780273438 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.8073, loss_val: nan, pos_over_neg: 631.1559448242188 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.8078, loss_val: nan, pos_over_neg: 450.5823669433594 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 597.289306640625 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.8049, loss_val: nan, pos_over_neg: 401.495849609375 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.8046, loss_val: nan, pos_over_neg: 319.6968078613281 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.8005, loss_val: nan, pos_over_neg: 845.2449340820312 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.8035, loss_val: nan, pos_over_neg: 711.4481201171875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 443.2649230957031 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 752.2896118164062 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7982, loss_val: nan, pos_over_neg: 569.2706298828125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 560.9719848632812 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.8108, loss_val: nan, pos_over_neg: 411.9532470703125 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 462.7806701660156 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 864.1448974609375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.8047, loss_val: nan, pos_over_neg: 696.330322265625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.8059, loss_val: nan, pos_over_neg: 439.0582275390625 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 1075.685791015625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7996, loss_val: nan, pos_over_neg: 1061.8033447265625 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 1487.5787353515625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 1075.694091796875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 607.0352783203125 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.8063, loss_val: nan, pos_over_neg: 803.557373046875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 541.4727172851562 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 445.7922668457031 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 496.3188781738281 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.8037, loss_val: nan, pos_over_neg: 578.7356567382812 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 410.3091735839844 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.8035, loss_val: nan, pos_over_neg: 794.308349609375 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 694.1817016601562 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 811.2012329101562 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 1541.6904296875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.8042, loss_val: nan, pos_over_neg: 557.7388916015625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.8036, loss_val: nan, pos_over_neg: 374.6335754394531 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.8061, loss_val: nan, pos_over_neg: 412.169189453125 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.8006, loss_val: nan, pos_over_neg: 1147.0399169921875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.8031, loss_val: nan, pos_over_neg: 1188.5146484375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 786.389404296875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 1037.315673828125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 1229.5748291015625 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.8092, loss_val: nan, pos_over_neg: 450.6485900878906 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 530.33056640625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.8015, loss_val: nan, pos_over_neg: 576.43408203125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 641.2955932617188 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.8057, loss_val: nan, pos_over_neg: 726.4240112304688 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.8056, loss_val: nan, pos_over_neg: 1019.0338134765625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 1401.904052734375 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 1358.570068359375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 481.35394287109375 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 937.9093627929688 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 800.2337036132812 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.8142, loss_val: nan, pos_over_neg: 312.966064453125 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 721.405029296875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7992, loss_val: nan, pos_over_neg: 625.7799682617188 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 965.4033203125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.8016, loss_val: nan, pos_over_neg: 869.92626953125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 671.7395629882812 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.8013, loss_val: nan, pos_over_neg: 1056.3465576171875 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.8033, loss_val: nan, pos_over_neg: 748.2986450195312 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.8052, loss_val: nan, pos_over_neg: 1630.6663818359375 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 860.010009765625 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 484.28173828125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7987, loss_val: nan, pos_over_neg: 666.71533203125 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7991, loss_val: nan, pos_over_neg: 672.9400634765625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 489.60003662109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 879.7110595703125 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 1415.5699462890625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.8093, loss_val: nan, pos_over_neg: 894.7138671875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 915.9667358398438 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 3785.327880859375 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 893.8786010742188 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 507.90576171875 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.804, loss_val: nan, pos_over_neg: 617.6884155273438 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 831.45947265625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 674.5081176757812 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 669.5361938476562 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 430.28082275390625 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.8041, loss_val: nan, pos_over_neg: 634.4034423828125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 648.7440795898438 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 1268.88037109375 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 436.267578125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 362.3338317871094 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 658.9067993164062 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.8019, loss_val: nan, pos_over_neg: 562.7015991210938 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.8, loss_val: nan, pos_over_neg: 479.8179016113281 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.8051, loss_val: nan, pos_over_neg: 335.1031494140625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 579.8041381835938 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.8004, loss_val: nan, pos_over_neg: 619.4749755859375 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.8023, loss_val: nan, pos_over_neg: 356.9808654785156 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7932, loss_val: nan, pos_over_neg: 624.9392700195312 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 424.6992492675781 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 411.9871520996094 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 271.72528076171875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.8011, loss_val: nan, pos_over_neg: 550.7449951171875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.8002, loss_val: nan, pos_over_neg: 338.4610900878906 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.8039, loss_val: nan, pos_over_neg: 368.0489807128906 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 490.55303955078125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.8012, loss_val: nan, pos_over_neg: 407.5688171386719 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.799, loss_val: nan, pos_over_neg: 706.4464721679688 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7974, loss_val: nan, pos_over_neg: 369.5985107421875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 492.7365417480469 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.798, loss_val: nan, pos_over_neg: 678.2855224609375 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.8034, loss_val: nan, pos_over_neg: 754.4158325195312 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.8038, loss_val: nan, pos_over_neg: 516.2196044921875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 706.940185546875 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7977, loss_val: nan, pos_over_neg: 416.33251953125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 521.9970703125 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 387.09271240234375 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.813, loss_val: nan, pos_over_neg: 279.6359558105469 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 558.2520751953125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 1104.439453125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.8016, loss_val: nan, pos_over_neg: 602.2987670898438 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 518.1812133789062 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 628.2603759765625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.805, loss_val: nan, pos_over_neg: 399.0069580078125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 551.6101684570312 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7988, loss_val: nan, pos_over_neg: 480.9111633300781 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.8024, loss_val: nan, pos_over_neg: 688.3733520507812 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 783.44921875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.796, loss_val: nan, pos_over_neg: 462.93951416015625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 583.5615234375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.8014, loss_val: nan, pos_over_neg: 842.5060424804688 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 556.6525268554688 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.8095, loss_val: nan, pos_over_neg: 455.1469421386719 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.802, loss_val: nan, pos_over_neg: 715.7119750976562 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.8026, loss_val: nan, pos_over_neg: 436.4982604980469 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7941, loss_val: nan, pos_over_neg: 620.0426025390625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 733.8350830078125 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 357.4748229980469 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 1101.0689697265625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7999, loss_val: nan, pos_over_neg: 655.8244018554688 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 1126.700927734375 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 817.8324584960938 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 452.711181640625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 1148.373046875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 1529.51611328125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.8059, loss_val: nan, pos_over_neg: 386.1565856933594 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7968, loss_val: nan, pos_over_neg: 545.2349853515625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 315.6604919433594 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 505.5344543457031 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 503.04241943359375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 701.0741577148438 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 349.341552734375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 1057.72900390625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 805.3333740234375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 432.4193420410156 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.8025, loss_val: nan, pos_over_neg: 338.25994873046875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.8053, loss_val: nan, pos_over_neg: 393.77337646484375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7963, loss_val: nan, pos_over_neg: 549.7742309570312 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 707.6109619140625 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7976, loss_val: nan, pos_over_neg: 464.1556091308594 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 687.8579711914062 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 520.0086669921875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 630.7752685546875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 554.4949340820312 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 546.1420288085938 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 441.7290954589844 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 594.1826171875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 605.7225952148438 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 536.5400390625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 590.5443725585938 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 933.422119140625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 938.42236328125 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 745.5758666992188 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 645.7759399414062 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 677.1992797851562 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 611.257568359375 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 878.2985229492188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 501.1336975097656 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 886.8729248046875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 1841.5875244140625 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 1283.7265625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 571.7619018554688 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 975.8978881835938 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1755.2166748046875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7989, loss_val: nan, pos_over_neg: 540.961181640625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 608.7926635742188 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 562.1647338867188 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 668.7490844726562 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7962, loss_val: nan, pos_over_neg: 1761.56201171875 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 665.1770629882812 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 337.3029479980469 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.791, loss_val: nan, pos_over_neg: 855.9215698242188 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7926, loss_val: nan, pos_over_neg: 1164.3917236328125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 863.8309936523438 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 385.635009765625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 498.27923583984375 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.8062, loss_val: nan, pos_over_neg: 638.104248046875 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 1049.1619873046875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 613.5525512695312 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.801, loss_val: nan, pos_over_neg: 686.3516845703125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 2760.2548828125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.8029, loss_val: nan, pos_over_neg: 691.2598876953125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 573.3783569335938 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 753.1553344726562 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 836.7385864257812 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 695.408447265625 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.8017, loss_val: nan, pos_over_neg: 383.9664611816406 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7964, loss_val: nan, pos_over_neg: 568.8944702148438 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 765.2030029296875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 704.6050415039062 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 580.3472900390625 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7966, loss_val: nan, pos_over_neg: 814.1325073242188 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.8027, loss_val: nan, pos_over_neg: 728.8803100585938 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7965, loss_val: nan, pos_over_neg: 1077.5179443359375 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 762.7635498046875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7983, loss_val: nan, pos_over_neg: 542.4561767578125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7993, loss_val: nan, pos_over_neg: 633.1295776367188 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 739.1494750976562 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 354.3547058105469 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 846.861572265625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 950.0494384765625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.8003, loss_val: nan, pos_over_neg: 788.0696411132812 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.8008, loss_val: nan, pos_over_neg: 439.32843017578125 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 560.1195678710938 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7981, loss_val: nan, pos_over_neg: 659.2874145507812 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 424.21026611328125 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.8022, loss_val: nan, pos_over_neg: 1021.182861328125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7998, loss_val: nan, pos_over_neg: 639.768310546875 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7969, loss_val: nan, pos_over_neg: 371.921630859375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 396.38470458984375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 1495.7532958984375 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 686.0239868164062 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 329.73931884765625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 460.942138671875 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1062.5281982421875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 351.15869140625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 604.7850952148438 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 778.3364868164062 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 657.3436279296875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 659.6640625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 456.1341857910156 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 802.912841796875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 741.12158203125 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1174.0303955078125 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 947.0949096679688 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 464.5418701171875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7932, loss_val: nan, pos_over_neg: 768.1688842773438 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 1137.453857421875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 598.140380859375 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 723.7034301757812 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7956, loss_val: nan, pos_over_neg: 729.7212524414062 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 1799.326416015625 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 1253.301513671875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 517.4629516601562 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7925, loss_val: nan, pos_over_neg: 844.023681640625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7953, loss_val: nan, pos_over_neg: 721.1162109375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.797, loss_val: nan, pos_over_neg: 1131.6614990234375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 635.8103637695312 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 832.3656005859375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 1202.460205078125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7995, loss_val: nan, pos_over_neg: 793.0881958007812 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 1150.149658203125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 590.8857421875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 628.1993408203125 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 761.9524536132812 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7955, loss_val: nan, pos_over_neg: 473.0592956542969 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 816.8649291992188 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 430.3982849121094 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 359.0216064453125 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 921.2319946289062 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 839.8099365234375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 1163.1763916015625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 694.1792602539062 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 887.6126098632812 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 788.69140625 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 1360.975830078125 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 671.7020263671875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.787, loss_val: nan, pos_over_neg: 1028.9141845703125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 1379.0106201171875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 722.29052734375 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 697.289306640625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1959.9478759765625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7975, loss_val: nan, pos_over_neg: 1460.9547119140625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7946, loss_val: nan, pos_over_neg: 646.5511474609375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 472.9409484863281 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 953.18408203125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 780.8448486328125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 610.7235717773438 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 1082.8096923828125 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 884.990234375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 626.3887329101562 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 1442.5306396484375 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7957, loss_val: nan, pos_over_neg: 606.3357543945312 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 471.4305419921875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1143.57666015625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 4688.484375 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 492.96435546875 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7997, loss_val: nan, pos_over_neg: 538.7582397460938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 1274.5643310546875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 2670.81884765625 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 884.4400024414062 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 875.39892578125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 953.7317504882812 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 1118.04443359375 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7948, loss_val: nan, pos_over_neg: 422.9687805175781 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 664.23291015625 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 1090.7724609375 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 731.7713012695312 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 455.94354248046875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 899.861083984375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.795, loss_val: nan, pos_over_neg: 605.1776123046875 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 629.721435546875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 610.8857421875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7952, loss_val: nan, pos_over_neg: 408.2197570800781 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 596.691162109375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 558.0272216796875 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 458.27777099609375 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 395.55743408203125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 434.07135009765625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 981.229248046875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7924, loss_val: nan, pos_over_neg: 439.40863037109375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7958, loss_val: nan, pos_over_neg: 324.195556640625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7936, loss_val: nan, pos_over_neg: 562.2156982421875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 643.3550415039062 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 711.0613403320312 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 459.6934814453125 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7971, loss_val: nan, pos_over_neg: 368.2478942871094 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7967, loss_val: nan, pos_over_neg: 485.5893249511719 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.792, loss_val: nan, pos_over_neg: 1298.300537109375 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 599.9948120117188 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 783.2188110351562 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7896, loss_val: nan, pos_over_neg: 485.078857421875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 608.584228515625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7912, loss_val: nan, pos_over_neg: 997.5014038085938 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 540.668701171875 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 508.66253662109375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 828.391357421875 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7944, loss_val: nan, pos_over_neg: 476.02239990234375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 704.1290893554688 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 766.017333984375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 619.7603759765625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 820.62451171875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 711.1371459960938 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7856, loss_val: nan, pos_over_neg: 560.5843505859375 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 561.8804321289062 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 356.19793701171875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7913, loss_val: nan, pos_over_neg: 501.8939514160156 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 609.9070434570312 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7945, loss_val: nan, pos_over_neg: 622.46533203125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.793, loss_val: nan, pos_over_neg: 345.7736511230469 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 1020.43798828125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 781.633056640625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 1110.899169921875 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 999.2767333984375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 598.5380249023438 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 1072.1661376953125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 380.9016418457031 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 813.9073486328125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7892, loss_val: nan, pos_over_neg: 851.9843139648438 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7934, loss_val: nan, pos_over_neg: 519.0782470703125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 1729.147705078125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7915, loss_val: nan, pos_over_neg: 952.2814331054688 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 674.308837890625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 596.247314453125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 1854.599365234375 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 942.933349609375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7985, loss_val: nan, pos_over_neg: 302.4424133300781 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 658.8050537109375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 481.8876647949219 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 1597.7711181640625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 486.5631408691406 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 812.916748046875 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7904, loss_val: nan, pos_over_neg: 662.204345703125 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 1094.7298583984375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7852, loss_val: nan, pos_over_neg: 1197.3543701171875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 928.8523559570312 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 1369.905029296875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 1563.7550048828125 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 1040.4912109375 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7929, loss_val: nan, pos_over_neg: 784.9609985351562 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 565.0635375976562 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 561.0894165039062 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 745.6925659179688 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 485.599853515625 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 1788.485595703125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7895, loss_val: nan, pos_over_neg: 755.9600219726562 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1365.66162109375 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 422.2992858886719 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 3245.2080078125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 2350.158203125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 430.1709899902344 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 878.5853881835938 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7972, loss_val: nan, pos_over_neg: 799.8499145507812 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 1169.0628662109375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7908, loss_val: nan, pos_over_neg: 571.76904296875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 1837.039794921875 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 700.9682006835938 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 623.2105102539062 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 815.6268310546875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7954, loss_val: nan, pos_over_neg: 816.8721923828125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1181.7259521484375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 684.6925659179688 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7927, loss_val: nan, pos_over_neg: 597.6754760742188 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7978, loss_val: nan, pos_over_neg: 536.0631713867188 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 746.7327270507812 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7938, loss_val: nan, pos_over_neg: 972.8255004882812 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7937, loss_val: nan, pos_over_neg: 668.8121337890625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 876.2958374023438 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1183.347412109375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7903, loss_val: nan, pos_over_neg: 558.29345703125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7901, loss_val: nan, pos_over_neg: 2237.501220703125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7907, loss_val: nan, pos_over_neg: 1225.1861572265625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 585.3165283203125 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 981.6746826171875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 1438.9010009765625 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 1016.4746704101562 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7949, loss_val: nan, pos_over_neg: 467.094970703125 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 1211.8282470703125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 582.775634765625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7891, loss_val: nan, pos_over_neg: 902.523193359375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 765.0098266601562 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 550.9370727539062 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7909, loss_val: nan, pos_over_neg: 852.9620971679688 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 732.8117065429688 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 989.2486572265625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 569.1103515625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 695.4290771484375 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7947, loss_val: nan, pos_over_neg: 332.46112060546875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 682.3330688476562 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 766.1167602539062 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 762.3014526367188 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 555.5827026367188 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7917, loss_val: nan, pos_over_neg: 586.1013793945312 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 405.8687744140625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 897.8941650390625 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 707.8665161132812 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 497.68682861328125 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7951, loss_val: nan, pos_over_neg: 403.8254089355469 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 998.2440795898438 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7961, loss_val: nan, pos_over_neg: 1519.308349609375 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 556.0709228515625 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 405.29937744140625 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7939, loss_val: nan, pos_over_neg: 631.00927734375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 635.3531494140625 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 523.96484375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 682.20947265625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 417.38323974609375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7881, loss_val: nan, pos_over_neg: 409.09844970703125 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7834, loss_val: nan, pos_over_neg: 423.8073425292969 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 549.324462890625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 472.8113098144531 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 310.85125732421875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7889, loss_val: nan, pos_over_neg: 536.7109375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 812.138916015625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 934.3421020507812 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 400.3092041015625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 1023.5828247070312 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 1476.4605712890625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 423.90057373046875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 426.7050476074219 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 921.9664916992188 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 691.6124267578125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 814.6439819335938 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7959, loss_val: nan, pos_over_neg: 489.8974914550781 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 482.08563232421875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1019.5154418945312 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1005.4547729492188 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1037.6041259765625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 968.3027954101562 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 430.2437438964844 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 724.5416870117188 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 718.9248657226562 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 749.8214111328125 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 791.3407592773438 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 559.1336669921875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1099.3985595703125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1341.0880126953125 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 643.9382934570312 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 490.984130859375 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 651.6869506835938 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 868.0152587890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 603.7095336914062 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 610.5396118164062 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 414.4884948730469 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7898, loss_val: nan, pos_over_neg: 536.7345581054688 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 561.6036987304688 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 693.6701049804688 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 550.4547119140625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 351.3260498046875 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7931, loss_val: nan, pos_over_neg: 540.4237670898438 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 673.8900146484375 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 695.419677734375 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 547.140625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 892.271240234375 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7918, loss_val: nan, pos_over_neg: 608.030517578125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 440.4887390136719 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 982.73486328125 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 1034.5360107421875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7841, loss_val: nan, pos_over_neg: 673.3018798828125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 363.2403564453125 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 483.2425842285156 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 1580.7904052734375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7887, loss_val: nan, pos_over_neg: 655.9921264648438 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 1133.9246826171875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 740.9113159179688 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7916, loss_val: nan, pos_over_neg: 477.82366943359375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1417.9285888671875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7911, loss_val: nan, pos_over_neg: 1818.4052734375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7857, loss_val: nan, pos_over_neg: 807.1002197265625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.794, loss_val: nan, pos_over_neg: 530.2977905273438 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 715.9771728515625 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7886, loss_val: nan, pos_over_neg: 572.022705078125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 733.6203002929688 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 1607.7490234375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 914.9843139648438 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7922, loss_val: nan, pos_over_neg: 1400.05810546875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 1185.3670654296875 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7899, loss_val: nan, pos_over_neg: 1073.050048828125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1732.5999755859375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 499.5026550292969 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 910.0120849609375 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 793.5068359375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1281.3463134765625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7906, loss_val: nan, pos_over_neg: 1546.1044921875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 791.1187744140625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 3124.387939453125 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1547.53857421875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 1289.54931640625 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 937.7408447265625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 6449.88818359375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 900.1801147460938 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 710.8009643554688 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7923, loss_val: nan, pos_over_neg: 503.6309509277344 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 650.0076904296875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 2298.555419921875 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 1609.8861083984375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 877.7861328125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 774.8558959960938 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7843, loss_val: nan, pos_over_neg: 1481.766845703125 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 981.8223876953125 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 1224.684326171875 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 761.7861938476562 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 772.3460693359375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 788.501708984375 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 859.5729370117188 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7888, loss_val: nan, pos_over_neg: 1391.0797119140625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 749.7675170898438 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 763.4199829101562 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 640.1917724609375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7868, loss_val: nan, pos_over_neg: 3778.9306640625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 641.86865234375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 835.2682495117188 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 656.8838500976562 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 537.3087768554688 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 1220.033447265625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7832, loss_val: nan, pos_over_neg: 573.56689453125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 743.0751953125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 910.08837890625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 972.7346801757812 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7861, loss_val: nan, pos_over_neg: 628.2967529296875 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 846.2655639648438 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 566.3248901367188 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 350.58428955078125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 759.9192504882812 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7914, loss_val: nan, pos_over_neg: 609.195556640625 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 867.2511596679688 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 539.4342651367188 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 1631.3135986328125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1205.90625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 849.10498046875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7849, loss_val: nan, pos_over_neg: 1066.3935546875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 904.180419921875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 744.3596801757812 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1034.2596435546875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7905, loss_val: nan, pos_over_neg: 3021.983642578125 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 466.5281982421875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7935, loss_val: nan, pos_over_neg: 519.6638793945312 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7871, loss_val: nan, pos_over_neg: 1228.3021240234375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1439.1285400390625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 894.82958984375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 540.2778930664062 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 2376.779296875 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 479.2532653808594 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7862, loss_val: nan, pos_over_neg: 709.5068359375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 1590.3875732421875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7835, loss_val: nan, pos_over_neg: 1145.288330078125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 810.2061767578125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1277.596435546875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 813.5945434570312 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 605.9818725585938 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 565.6001586914062 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 541.4803466796875 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 1100.4603271484375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 777.9249877929688 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1960.45703125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 953.185791015625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 837.6643676757812 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7826, loss_val: nan, pos_over_neg: 959.2085571289062 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 2617.9248046875 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 706.0177612304688 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 597.6246948242188 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 922.2098388671875 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 1009.18798828125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7894, loss_val: nan, pos_over_neg: 534.6734008789062 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 938.3145751953125 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1791.490478515625 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 1166.6749267578125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 882.2510986328125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 545.8314208984375 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1352.137939453125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7873, loss_val: nan, pos_over_neg: 1369.751708984375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 778.572509765625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/300000 [42:02<104990:30:49, 1259.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Iter: 0/695, loss_train: 5.7885, loss_val: nan, pos_over_neg: 317.5196838378906 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 765.0432739257812 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 1412.412353515625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 959.1016845703125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 970.4857788085938 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 1206.8153076171875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7928, loss_val: nan, pos_over_neg: 954.6618041992188 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 1044.353515625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 755.0987548828125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.789, loss_val: nan, pos_over_neg: 520.8925170898438 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 1051.038330078125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 527.1644897460938 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 825.2650756835938 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7863, loss_val: nan, pos_over_neg: 572.5674438476562 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 1019.407470703125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7872, loss_val: nan, pos_over_neg: 671.3934326171875 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 819.9957275390625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 1505.298095703125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 502.23779296875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1234.3388671875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 951.2353515625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1403.6361083984375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 1158.245849609375 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 1122.8720703125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 2611.7431640625 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 947.1796875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 1032.5701904296875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 779.4474487304688 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 432.9601745605469 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1000.0007934570312 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 898.793701171875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 553.8202514648438 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 972.6700439453125 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7823, loss_val: nan, pos_over_neg: 1091.2362060546875 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 774.2949829101562 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 760.8050537109375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 894.5283203125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7824, loss_val: nan, pos_over_neg: 797.3535766601562 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 2992.117431640625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 823.7444458007812 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 783.069091796875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 937.6146850585938 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 653.6614379882812 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1304.0501708984375 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7844, loss_val: nan, pos_over_neg: 883.072998046875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 536.8834838867188 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 685.4006958007812 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 2515.667236328125 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 736.8858032226562 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1223.4251708984375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 926.1856079101562 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 996.9074096679688 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 604.4052734375 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7877, loss_val: nan, pos_over_neg: 391.2821350097656 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 956.4369506835938 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 766.918212890625 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.779, loss_val: nan, pos_over_neg: 413.90484619140625 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 1018.8450927734375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 856.9133911132812 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7884, loss_val: nan, pos_over_neg: 584.3442993164062 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7855, loss_val: nan, pos_over_neg: 413.46728515625 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 527.521240234375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 460.65869140625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 714.05078125 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7846, loss_val: nan, pos_over_neg: 755.84228515625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 742.6920166015625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 734.9965209960938 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 577.8946533203125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1283.32958984375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 498.93212890625 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7859, loss_val: nan, pos_over_neg: 639.3104858398438 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 403.89495849609375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7866, loss_val: nan, pos_over_neg: 486.6859436035156 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 1270.58544921875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1250.63427734375 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.783, loss_val: nan, pos_over_neg: 631.1104125976562 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 761.9981689453125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 826.8389892578125 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 812.8717041015625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 814.7399291992188 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 568.1881103515625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1114.023193359375 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 1314.84716796875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 519.3499755859375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 614.562255859375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 728.1384887695312 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 1281.9749755859375 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 1041.0711669921875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 729.150146484375 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1595.3563232421875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7897, loss_val: nan, pos_over_neg: 874.0986328125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 854.2259521484375 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 1521.395263671875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1126.4176025390625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7839, loss_val: nan, pos_over_neg: 2223.96826171875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7817, loss_val: nan, pos_over_neg: 611.0685424804688 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7833, loss_val: nan, pos_over_neg: 919.7163696289062 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 548.17041015625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7878, loss_val: nan, pos_over_neg: 618.9705200195312 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 784.9833374023438 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 692.8358764648438 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 1517.9217529296875 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 800.9600219726562 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7812, loss_val: nan, pos_over_neg: 602.968505859375 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 2001.8603515625 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7815, loss_val: nan, pos_over_neg: 685.4325561523438 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 1013.0791015625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 584.6558837890625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 1063.0511474609375 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7882, loss_val: nan, pos_over_neg: 587.6151733398438 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 838.5177612304688 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 921.9139404296875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 467.1585388183594 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 817.677734375 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7789, loss_val: nan, pos_over_neg: 1205.7335205078125 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 625.432861328125 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 497.23992919921875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 777.9880981445312 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7874, loss_val: nan, pos_over_neg: 526.3262329101562 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 531.1695556640625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7853, loss_val: nan, pos_over_neg: 573.1082153320312 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 834.4144897460938 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 984.0156860351562 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 891.805419921875 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 709.1934814453125 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 578.9955444335938 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1167.8785400390625 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 738.6358642578125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7775, loss_val: nan, pos_over_neg: 975.0689697265625 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 621.4689331054688 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1559.3057861328125 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 1499.5498046875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 1460.8358154296875 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7838, loss_val: nan, pos_over_neg: 657.2974853515625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1392.1177978515625 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 950.0413208007812 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 1482.5223388671875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2854.38623046875 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1312.8302001953125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 580.86083984375 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1055.2828369140625 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 731.5421142578125 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 890.7760009765625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 813.4744873046875 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 690.066162109375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1285.415283203125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 712.58349609375 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7825, loss_val: nan, pos_over_neg: 845.22705078125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1390.5714111328125 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 3904.607177734375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 2203.361328125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 954.1452026367188 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 726.9613647460938 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.785, loss_val: nan, pos_over_neg: 653.0349731445312 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1543.5054931640625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 931.8441162109375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 811.2511596679688 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 724.0559692382812 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 1816.87890625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 608.4755249023438 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 2164.451904296875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1312.195556640625 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1180.8975830078125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 1027.2886962890625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1749.1434326171875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1641.3134765625 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1259.30615234375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1921.2137451171875 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 385.0941467285156 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 535.2994384765625 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1059.5240478515625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 1154.694091796875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1845.8695068359375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 490.3055114746094 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 427.7525634765625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 598.8974609375 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 777.9888305664062 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7893, loss_val: nan, pos_over_neg: 344.0201416015625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 586.4719848632812 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 439.8569030761719 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 658.5538940429688 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 595.4745483398438 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7869, loss_val: nan, pos_over_neg: 894.0109252929688 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 679.2775268554688 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7867, loss_val: nan, pos_over_neg: 543.89794921875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7854, loss_val: nan, pos_over_neg: 991.522705078125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 734.1981201171875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 507.5479431152344 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 714.7899169921875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 825.7786865234375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 1057.0679931640625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 535.5145874023438 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7919, loss_val: nan, pos_over_neg: 350.8124084472656 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 711.00390625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 908.3502807617188 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7842, loss_val: nan, pos_over_neg: 655.5643310546875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7858, loss_val: nan, pos_over_neg: 512.3942260742188 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 661.95703125 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 556.8114624023438 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1047.7213134765625 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 1085.6376953125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.78, loss_val: nan, pos_over_neg: 598.9246826171875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7827, loss_val: nan, pos_over_neg: 688.9345703125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 430.1196594238281 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 638.5618896484375 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 1243.7427978515625 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 1154.0625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 482.9713439941406 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7847, loss_val: nan, pos_over_neg: 610.28271484375 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 874.7562255859375 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 668.2162475585938 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 681.30322265625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 557.1087646484375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 544.69677734375 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 472.98187255859375 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 768.9339599609375 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 823.5184326171875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1920.3795166015625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 901.5087890625 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 693.005859375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 622.977294921875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 975.77197265625 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 991.1339111328125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 783.004638671875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 522.197998046875 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 784.1846923828125 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 1021.092041015625 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1011.5189208984375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7811, loss_val: nan, pos_over_neg: 476.663818359375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 643.9967041015625 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 886.1261596679688 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 751.215576171875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 946.5968017578125 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 693.5673217773438 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1569.3402099609375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1042.5936279296875 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 1460.99169921875 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 799.0787963867188 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 1951.9425048828125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 949.5840454101562 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 1089.5146484375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 924.1845703125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 1426.18896484375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1017.0874633789062 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 630.1486206054688 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 659.4320068359375 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 1249.0740966796875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 508.7702331542969 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 539.5145263671875 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7813, loss_val: nan, pos_over_neg: 585.8065185546875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 2247.79052734375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7766, loss_val: nan, pos_over_neg: 551.0025024414062 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 499.5011291503906 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.786, loss_val: nan, pos_over_neg: 857.0736083984375 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1076.4979248046875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 572.0009765625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 862.7725219726562 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7845, loss_val: nan, pos_over_neg: 521.1781616210938 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 2318.60205078125 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 666.8963623046875 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 789.7034301757812 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 883.3385009765625 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7876, loss_val: nan, pos_over_neg: 770.142333984375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 627.93359375 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 928.54052734375 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7864, loss_val: nan, pos_over_neg: 743.3428955078125 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 2077.0107421875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1635.5478515625 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7837, loss_val: nan, pos_over_neg: 926.5509033203125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 2543.234130859375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 745.3468017578125 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7848, loss_val: nan, pos_over_neg: 680.18017578125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1669.7288818359375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7816, loss_val: nan, pos_over_neg: 1056.5706787109375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 1352.0155029296875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7818, loss_val: nan, pos_over_neg: 568.8365478515625 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7831, loss_val: nan, pos_over_neg: 956.4927368164062 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 904.2987060546875 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7902, loss_val: nan, pos_over_neg: 976.96142578125 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 836.4287719726562 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7943, loss_val: nan, pos_over_neg: 512.5209350585938 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 920.3434448242188 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7875, loss_val: nan, pos_over_neg: 787.2871704101562 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7828, loss_val: nan, pos_over_neg: 699.9488525390625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 773.06103515625 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7883, loss_val: nan, pos_over_neg: 567.485595703125 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7794, loss_val: nan, pos_over_neg: 729.2116088867188 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 892.3340454101562 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7797, loss_val: nan, pos_over_neg: 629.5668334960938 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 691.0551147460938 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 556.2852172851562 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 916.906982421875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7819, loss_val: nan, pos_over_neg: 523.9746704101562 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 711.936279296875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7793, loss_val: nan, pos_over_neg: 815.7359619140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 507.42755126953125 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 965.2133178710938 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1923.4610595703125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1190.46923828125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 397.4098205566406 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 593.5804443359375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 906.5828857421875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 993.342529296875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 569.4363403320312 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1316.3770751953125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1637.8162841796875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 2975.996337890625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 675.5499267578125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7772, loss_val: nan, pos_over_neg: 994.0668334960938 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 774.572021484375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1471.6622314453125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 881.2963256835938 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1230.487060546875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 652.2512817382812 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 432.6997375488281 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 736.3615112304688 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 904.3054809570312 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7785, loss_val: nan, pos_over_neg: 884.8058471679688 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 1643.6876220703125 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 916.4152221679688 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 791.5105590820312 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 2028.68408203125 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 842.6627807617188 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 761.9918823242188 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 603.4447631835938 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7829, loss_val: nan, pos_over_neg: 438.68707275390625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1346.2833251953125 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 834.6602172851562 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 893.82373046875 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 2431.05859375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 776.6923828125 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7787, loss_val: nan, pos_over_neg: 827.5567016601562 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7786, loss_val: nan, pos_over_neg: 679.6133422851562 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1526.163330078125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 671.621826171875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 453.7218933105469 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1175.900390625 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 1085.2030029296875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 787.043212890625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 982.0264282226562 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1141.48388671875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 1126.3262939453125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 885.2564697265625 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1035.930908203125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 1289.03125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 815.1806640625 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 594.5098266601562 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 1222.5267333984375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 636.43115234375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1711.841064453125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 2199.419921875 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 872.6474609375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 981.7276611328125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 727.569580078125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 2249.639892578125 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 911.9644775390625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 719.2597045898438 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7799, loss_val: nan, pos_over_neg: 539.6719970703125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7763, loss_val: nan, pos_over_neg: 564.2831420898438 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 805.155517578125 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 2036.24462890625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.784, loss_val: nan, pos_over_neg: 619.1696166992188 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 609.0817260742188 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7851, loss_val: nan, pos_over_neg: 671.2537841796875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1407.1812744140625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 816.556884765625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7865, loss_val: nan, pos_over_neg: 345.5896301269531 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1011.7644653320312 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1048.20654296875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 632.4913940429688 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1263.8956298828125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 588.179443359375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 826.85888671875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1315.73681640625 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 766.4071044921875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 667.1337280273438 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 821.8479614257812 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 719.7462768554688 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 743.167236328125 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7784, loss_val: nan, pos_over_neg: 876.478271484375 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 476.41363525390625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 753.9680786132812 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 706.4592895507812 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1014.3822021484375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 2331.549072265625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 687.3941650390625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 522.3562622070312 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 889.5570678710938 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1758.27099609375 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1973.8994140625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 757.0771484375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 638.8193359375 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 813.8541259765625 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7791, loss_val: nan, pos_over_neg: 582.4292602539062 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 730.839599609375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1225.649169921875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7836, loss_val: nan, pos_over_neg: 772.583251953125 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 945.9657592773438 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 689.5503540039062 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7788, loss_val: nan, pos_over_neg: 649.0597534179688 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 735.1433715820312 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7807, loss_val: nan, pos_over_neg: 1341.884765625 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 579.3843383789062 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7769, loss_val: nan, pos_over_neg: 559.7332763671875 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 904.71240234375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 328.8608093261719 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 565.9751586914062 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 882.9318237304688 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 816.2816772460938 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1018.192138671875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 467.0560607910156 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7806, loss_val: nan, pos_over_neg: 513.1451416015625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 823.3535766601562 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 756.0221557617188 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 496.3812255859375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7795, loss_val: nan, pos_over_neg: 388.77032470703125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 639.2117309570312 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 787.1857299804688 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1419.189208984375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 430.2574157714844 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7796, loss_val: nan, pos_over_neg: 529.9310302734375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 787.1436767578125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 1521.33251953125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 732.1348266601562 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 550.2127685546875 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 1018.9744262695312 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 710.0099487304688 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 976.533203125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1105.1566162109375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 561.2450561523438 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.778, loss_val: nan, pos_over_neg: 942.1699829101562 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 735.6634521484375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 1090.9959716796875 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 831.02734375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1056.535400390625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1553.7467041015625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 1801.53466796875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 2693.091796875 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 954.0372314453125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 499.71319580078125 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1755.6507568359375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1178.7486572265625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 852.263427734375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 905.2890625 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1404.154296875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 908.3554077148438 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1426.49365234375 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7821, loss_val: nan, pos_over_neg: 833.1561889648438 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1632.8448486328125 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1077.349609375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1599.4300537109375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 912.2205810546875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1348.38671875 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1165.61962890625 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 1052.887939453125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 905.7593994140625 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 1296.5849609375 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 1056.0972900390625 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.782, loss_val: nan, pos_over_neg: 673.4979858398438 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 1351.5235595703125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 2031.765869140625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 958.2192993164062 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 725.603759765625 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 630.6297607421875 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 887.6143798828125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 781.860107421875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 884.414794921875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1197.730712890625 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 547.7852172851562 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1184.7869873046875 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 647.1817626953125 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 693.4445190429688 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 620.6521606445312 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 1269.2965087890625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 707.8642578125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 575.3477172851562 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1303.9552001953125 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 426.5964050292969 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 773.5585327148438 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 505.5827331542969 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 686.0084228515625 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1000.4929809570312 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 1436.1483154296875 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1121.6839599609375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 661.9635620117188 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 661.4717407226562 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 8119.11669921875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 884.68701171875 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 671.5823974609375 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 667.82958984375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 607.5787963867188 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1070.5911865234375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 1806.31396484375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1398.2496337890625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 772.406005859375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 908.9298706054688 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1957.6533203125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 956.6282958984375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 663.17724609375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 837.2005615234375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7805, loss_val: nan, pos_over_neg: 483.270263671875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 529.8792114257812 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 557.3530883789062 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7814, loss_val: nan, pos_over_neg: 470.5025329589844 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 543.2766723632812 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7801, loss_val: nan, pos_over_neg: 1774.2672119140625 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 1033.0914306640625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 755.06689453125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 1022.9923706054688 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7808, loss_val: nan, pos_over_neg: 691.6776123046875 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1245.0814208984375 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 1100.1392822265625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 771.9168701171875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1249.9539794921875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1811.823974609375 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7777, loss_val: nan, pos_over_neg: 978.7547607421875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 889.9755859375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 827.8721923828125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 891.819580078125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7803, loss_val: nan, pos_over_neg: 673.4271850585938 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 1139.205810546875 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 672.8888549804688 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 653.8877563476562 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1439.47412109375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 1270.4197998046875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 802.443115234375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 692.5633544921875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 812.858154296875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7752, loss_val: nan, pos_over_neg: 1187.53759765625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1346.9886474609375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 885.5117797851562 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 724.54931640625 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 577.9712524414062 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 697.0294189453125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 899.9943237304688 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 700.5113525390625 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 862.4441528320312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 558.8685302734375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7778, loss_val: nan, pos_over_neg: 590.4115600585938 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 680.850341796875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 767.1428833007812 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1344.756591796875 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 790.181884765625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 622.84765625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1279.724365234375 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1487.1552734375 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 835.1206665039062 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7792, loss_val: nan, pos_over_neg: 516.22265625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 711.9949951171875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 737.8572387695312 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 902.6316528320312 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 899.5292358398438 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 867.4300537109375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 677.102783203125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 555.109375 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 788.300537109375 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1748.5196533203125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7781, loss_val: nan, pos_over_neg: 1072.6142578125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7747, loss_val: nan, pos_over_neg: 886.927978515625 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 890.2034912109375 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 845.1917724609375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7746, loss_val: nan, pos_over_neg: 943.1088256835938 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1281.742431640625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1095.136962890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1115.2412109375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 2897.21923828125 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7758, loss_val: nan, pos_over_neg: 1070.5718994140625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 635.4409790039062 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 624.1686401367188 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 923.6461791992188 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1109.39306640625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 912.2523193359375 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 476.7066650390625 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 491.7234802246094 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 923.1942138671875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 799.463134765625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7809, loss_val: nan, pos_over_neg: 488.96636962890625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 829.0205688476562 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 619.679931640625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7753, loss_val: nan, pos_over_neg: 882.499755859375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 791.2030029296875 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 859.6832275390625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 648.5775146484375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 895.484619140625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 847.4746704101562 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 950.4017944335938 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7804, loss_val: nan, pos_over_neg: 649.2870483398438 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 501.7254943847656 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 754.1195068359375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 851.9185180664062 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 2242.984375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 1182.609130859375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 800.2380981445312 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 873.2980346679688 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7774, loss_val: nan, pos_over_neg: 755.2626953125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 1563.0888671875 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1854.11474609375 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7748, loss_val: nan, pos_over_neg: 733.9044189453125 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1177.777099609375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 866.2806396484375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1289.7008056640625 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 1296.961181640625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 921.202392578125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1470.8756103515625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 2344.763427734375 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 2624.023681640625 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 2706.385498046875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1424.4224853515625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1519.5748291015625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 996.072509765625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 1299.121826171875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 475.15655517578125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 805.8367919921875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 717.8346557617188 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7743, loss_val: nan, pos_over_neg: 723.8619384765625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 1463.26220703125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1083.2298583984375 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 1731.80322265625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 889.4901733398438 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1074.6982421875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7755, loss_val: nan, pos_over_neg: 677.2921752929688 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7783, loss_val: nan, pos_over_neg: 1020.9435424804688 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 884.3079223632812 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 734.7608032226562 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 899.3764038085938 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1255.3819580078125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 1002.4563598632812 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 716.1954956054688 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1133.3238525390625 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 1362.323974609375 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1034.100341796875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 847.9386596679688 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 528.2449951171875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7761, loss_val: nan, pos_over_neg: 715.5308227539062 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 850.1622924804688 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 895.48486328125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7742, loss_val: nan, pos_over_neg: 627.6074829101562 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 543.021484375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1314.5899658203125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 706.0731811523438 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 1594.578857421875 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1602.791015625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 2029.6407470703125 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 942.3311157226562 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 881.9305419921875 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1733.8857421875 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 568.9697265625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 607.5945434570312 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 441.60986328125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 654.8695678710938 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 915.0538330078125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 803.973388671875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 428.6796875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 800.2479248046875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 853.10791015625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 542.927734375 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7773, loss_val: nan, pos_over_neg: 1279.6861572265625 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1378.6622314453125 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1154.1126708984375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.781, loss_val: nan, pos_over_neg: 484.90191650390625 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 901.49560546875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 2528.420654296875 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 898.9057006835938 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 964.4124755859375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 674.4990234375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 861.3703002929688 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 437.95166015625 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 685.8624267578125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 651.2570190429688 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 835.1185913085938 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1048.0958251953125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7802, loss_val: nan, pos_over_neg: 571.8429565429688 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 576.8700561523438 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 626.1192016601562 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1137.9609375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1126.8875732421875 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 638.9449462890625 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 737.6900024414062 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 717.5396118164062 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1035.14501953125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 868.8671264648438 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 809.7537231445312 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 771.58935546875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 775.2291259765625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1499.0794677734375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7782, loss_val: nan, pos_over_neg: 820.9620361328125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 755.5009765625 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 775.4320678710938 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 794.3646240234375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 920.3684692382812 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7735, loss_val: nan, pos_over_neg: 473.35260009765625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.775, loss_val: nan, pos_over_neg: 618.0338745117188 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7718, loss_val: nan, pos_over_neg: 718.2493896484375 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1615.8607177734375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1293.5025634765625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/300000 [1:02:47<104415:01:58, 1252.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Iter: 0/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 752.6302490234375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1854.033447265625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 676.272705078125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 830.5025634765625 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 632.4591064453125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 637.07763671875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 473.3608703613281 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 796.97900390625 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7739, loss_val: nan, pos_over_neg: 1206.25 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 815.3682861328125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 718.0364379882812 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 711.584716796875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 886.0274658203125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7767, loss_val: nan, pos_over_neg: 1141.36669921875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 686.4074096679688 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 516.3157348632812 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 767.301513671875 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 546.2442626953125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 726.9853515625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 484.7882080078125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 932.7803344726562 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 697.8864135742188 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 686.029296875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 817.4807739257812 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1582.4268798828125 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1771.531494140625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 608.9551391601562 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.777, loss_val: nan, pos_over_neg: 351.9706726074219 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7768, loss_val: nan, pos_over_neg: 840.9676513671875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7764, loss_val: nan, pos_over_neg: 1631.060791015625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 743.319091796875 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 430.2059020996094 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 795.6112670898438 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 801.0863647460938 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1038.62744140625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 604.0894775390625 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 667.8538818359375 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.776, loss_val: nan, pos_over_neg: 484.13385009765625 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 2192.46875 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1903.9989013671875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 473.5129089355469 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 633.017333984375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7701, loss_val: nan, pos_over_neg: 1242.0322265625 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7776, loss_val: nan, pos_over_neg: 4101.7822265625 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1001.1124877929688 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 828.8983764648438 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 1428.86669921875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1460.8377685546875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1054.14404296875 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 2447.614990234375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1476.22021484375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1027.3157958984375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 919.9747924804688 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 545.7027587890625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1162.7322998046875 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7704, loss_val: nan, pos_over_neg: 1100.969482421875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 649.3986206054688 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 1215.9910888671875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 962.0673217773438 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 591.2293090820312 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1571.279052734375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 542.0701293945312 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7729, loss_val: nan, pos_over_neg: 720.5740356445312 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 724.8817749023438 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.774, loss_val: nan, pos_over_neg: 532.2508544921875 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 880.3099365234375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 1807.2769775390625 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 2798.1396484375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1623.036865234375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 834.9408569335938 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1362.919189453125 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 944.2123413085938 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1163.4891357421875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 997.5790405273438 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7733, loss_val: nan, pos_over_neg: 520.1543579101562 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 750.3590087890625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 689.4610595703125 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1314.81201171875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 910.0624389648438 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 633.1007080078125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7726, loss_val: nan, pos_over_neg: 1724.185791015625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 598.9776000976562 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 491.85211181640625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1010.0963134765625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1240.0189208984375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 472.5697326660156 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 665.381103515625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 451.4809265136719 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 2034.736328125 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1159.648193359375 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 1060.2850341796875 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 789.6033325195312 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 914.1262817382812 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 557.4773559570312 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 507.3248291015625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 588.1160888671875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1170.670166015625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 683.6580200195312 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7744, loss_val: nan, pos_over_neg: 858.3048095703125 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 703.116943359375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1331.114501953125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 663.2982788085938 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 859.5159912109375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1287.68896484375 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1437.178466796875 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7754, loss_val: nan, pos_over_neg: 445.9004211425781 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 738.4046630859375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1084.301513671875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 836.5344848632812 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 912.154296875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 656.328125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 363.8453674316406 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 786.0750732421875 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 567.248291015625 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 749.0780639648438 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 3318.830810546875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1693.4381103515625 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 795.9981079101562 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1040.4658203125 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7757, loss_val: nan, pos_over_neg: 1114.85791015625 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 1409.3494873046875 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 978.5269165039062 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1204.75732421875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1206.0560302734375 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 487.776123046875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1418.6497802734375 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1108.736083984375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 631.7078857421875 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2398.003662109375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 597.019775390625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 969.7259521484375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 911.5182495117188 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 1515.8984375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 850.8447265625 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7711, loss_val: nan, pos_over_neg: 693.719970703125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1103.62744140625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7779, loss_val: nan, pos_over_neg: 567.2476806640625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 1134.2589111328125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1056.4168701171875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 980.419921875 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1311.492919921875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 946.7494506835938 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7771, loss_val: nan, pos_over_neg: 863.7369384765625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1021.580322265625 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1702.9344482421875 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 692.5447998046875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 777.82861328125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1539.5596923828125 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7732, loss_val: nan, pos_over_neg: 882.7793579101562 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 826.9776611328125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 597.8704223632812 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 897.4530029296875 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7798, loss_val: nan, pos_over_neg: 566.4630126953125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 978.1953125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 782.9306640625 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 607.8667602539062 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 934.906005859375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1422.193359375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 651.6165161132812 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7738, loss_val: nan, pos_over_neg: 753.0838623046875 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1013.1224975585938 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1425.785888671875 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 2028.7421875 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1473.1484375 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1490.9862060546875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.771, loss_val: nan, pos_over_neg: 1477.04736328125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 1074.7515869140625 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7822, loss_val: nan, pos_over_neg: 659.2498168945312 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 732.6100463867188 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 2751.54345703125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 866.5230102539062 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 786.0323486328125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 2681.206787109375 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 906.100830078125 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 565.170166015625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1474.36572265625 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 1446.3941650390625 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 831.9812622070312 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 1818.736083984375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1289.712890625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 590.94384765625 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 960.9463500976562 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 620.3491821289062 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 1017.0099487304688 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 775.8660888671875 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 361.3968505859375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 574.4774169921875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 967.466796875 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 663.1326904296875 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1526.8677978515625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 839.8634033203125 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 694.0169067382812 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 483.6210632324219 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 3186.66455078125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 570.78662109375 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1130.42822265625 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 678.4588012695312 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 1024.7420654296875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 956.7122192382812 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 554.9157104492188 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 810.8012084960938 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 858.368408203125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 712.8370361328125 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 910.338134765625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1036.5848388671875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 849.1522827148438 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1083.28759765625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1221.9429931640625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 863.2880249023438 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1514.701904296875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 552.961669921875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 481.1908874511719 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2115.140625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 724.4871215820312 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 535.0050659179688 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 3358.5361328125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1449.6724853515625 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 846.2418823242188 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 731.8829956054688 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7751, loss_val: nan, pos_over_neg: 734.2454833984375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 2611.296875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1040.6456298828125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 920.082763671875 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1758.8072509765625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 662.7799682617188 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 662.4098510742188 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 647.6442260742188 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 732.4305419921875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1581.0970458984375 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 818.7759399414062 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 1046.384033203125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 503.0062255859375 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 745.9645385742188 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 873.72314453125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 902.2605590820312 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7756, loss_val: nan, pos_over_neg: 679.8785400390625 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 621.0835571289062 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 1392.759521484375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 956.23486328125 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 908.4443359375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 638.895751953125 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 484.9748840332031 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 984.4732055664062 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1043.4842529296875 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7762, loss_val: nan, pos_over_neg: 701.3189697265625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 658.6640014648438 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 644.8764038085938 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1960.1376953125 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 885.9971313476562 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1188.077392578125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 854.8844604492188 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7709, loss_val: nan, pos_over_neg: 458.3414611816406 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 840.0487670898438 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 827.3888549804688 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1643.5511474609375 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 549.8980712890625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 827.7335205078125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 683.0062255859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 822.6077270507812 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 665.1373901367188 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1018.3329467773438 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 679.04443359375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1111.612060546875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 570.2957153320312 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 548.338134765625 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 413.67572021484375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 889.2481689453125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 432.7895202636719 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 748.9539184570312 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 855.8731689453125 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 623.7417602539062 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1077.2845458984375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 7551.744140625 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7694, loss_val: nan, pos_over_neg: 495.7235107421875 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 2565.458740234375 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7716, loss_val: nan, pos_over_neg: 784.4547119140625 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7745, loss_val: nan, pos_over_neg: 698.492919921875 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7699, loss_val: nan, pos_over_neg: 1200.4432373046875 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 529.982666015625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 857.0781860351562 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7713, loss_val: nan, pos_over_neg: 749.2090454101562 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1213.9169921875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 847.058349609375 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 920.0631103515625 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 3575.134521484375 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 755.03369140625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 769.880126953125 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1012.893798828125 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1045.43359375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 996.4842529296875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 821.200439453125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 1049.9317626953125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 2002.9749755859375 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1297.143310546875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 938.0015869140625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 691.7063598632812 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1587.459228515625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 2310.10595703125 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1243.605224609375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1594.1663818359375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2430.51806640625 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1384.645263671875 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 999.99755859375 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1245.0596923828125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1654.025146484375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1461.8883056640625 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1479.0494384765625 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1512.3553466796875 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1485.1513671875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1155.3143310546875 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1399.9361572265625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1711.2613525390625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 4525.9833984375 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1068.3209228515625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1551.7054443359375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1020.5931396484375 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 5758.27880859375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 930.7359008789062 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 6257841.0 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 1933.9036865234375 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1771.6021728515625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1245.7188720703125 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1442.799072265625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 1495.292236328125 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7697, loss_val: nan, pos_over_neg: 1156.62451171875 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 783.8126831054688 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 668.0992431640625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 1249.196533203125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 2153.32666015625 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 763.8530883789062 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1152.23583984375 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 690.207275390625 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2843.366455078125 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 4012.118408203125 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 958.6683959960938 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1154.042724609375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 7200.33251953125 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7724, loss_val: nan, pos_over_neg: 1523.114501953125 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7731, loss_val: nan, pos_over_neg: 1082.66015625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 759.7896118164062 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 1383.026611328125 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1227.654296875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7714, loss_val: nan, pos_over_neg: 934.591796875 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 685.0221557617188 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1566.4188232421875 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 542.1039428710938 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1519.123779296875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 641.0933837890625 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 607.0935668945312 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 3727.3837890625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 822.6994018554688 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1946.2427978515625 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1950.6456298828125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1093.583740234375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1115.0360107421875 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1555.3902587890625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1590.54296875 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 557.4959716796875 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 594.9761962890625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 5910.4287109375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2693.591064453125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1488.4180908203125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 886.1740112304688 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 1080.861572265625 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1068.4830322265625 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 679.9800415039062 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 529.6212768554688 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1018.0817260742188 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 513.2288208007812 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1662.7833251953125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1238.072265625 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1266.0966796875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 481.5189514160156 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 836.9315185546875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 902.038818359375 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7715, loss_val: nan, pos_over_neg: 861.6201782226562 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1541.341796875 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 1329.4266357421875 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 9253.0107421875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1013.174072265625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 563.4149169921875 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 781.0018920898438 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1255.1248779296875 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1626.062255859375 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1038.002197265625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 418.2406311035156 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1005.5177001953125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1422.0377197265625 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 673.4801635742188 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 896.1392211914062 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2158.802490234375 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 871.519775390625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 444.7428894042969 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7727, loss_val: nan, pos_over_neg: 587.9107055664062 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1707.4163818359375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 816.8713989257812 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7749, loss_val: nan, pos_over_neg: 687.82421875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 533.9451904296875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1803.0931396484375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1031.5914306640625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 1065.2900390625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7734, loss_val: nan, pos_over_neg: 640.47216796875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 1499.966552734375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 988.0282592773438 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 1172.927734375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1025.94921875 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 779.6097412109375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 878.0726928710938 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 679.6130981445312 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1256.9024658203125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 968.8993530273438 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 665.538818359375 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 493.05364990234375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7696, loss_val: nan, pos_over_neg: 940.7200927734375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 527.4146728515625 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 482.0544128417969 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 732.8845825195312 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 763.3590698242188 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 532.7415161132812 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 757.29052734375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 527.3627319335938 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1721.6923828125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1015.6331787109375 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 937.8826904296875 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.773, loss_val: nan, pos_over_neg: 967.5370483398438 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1364.5928955078125 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1890.2447509765625 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1003.5274658203125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 646.1605224609375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 611.9567260742188 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1408.2666015625 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 704.14208984375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7719, loss_val: nan, pos_over_neg: 552.2146606445312 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 947.963623046875 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 725.1715087890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 791.3745727539062 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1111.483642578125 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 757.8718872070312 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1152.0042724609375 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 853.7694091796875 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 406.67059326171875 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 525.5833129882812 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 547.8624267578125 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1602.457763671875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 683.8076171875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 517.96484375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 966.2818603515625 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 2308.549560546875 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 868.0465698242188 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1201.080810546875 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 510.6693115234375 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 653.3547973632812 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 705.7061767578125 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7712, loss_val: nan, pos_over_neg: 1049.2689208984375 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 957.0310668945312 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7693, loss_val: nan, pos_over_neg: 592.4335327148438 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 631.1317749023438 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7725, loss_val: nan, pos_over_neg: 1127.2958984375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 2456.801513671875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 1587.6436767578125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 860.347900390625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 794.5639038085938 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 1019.7584838867188 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1333.2572021484375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7668, loss_val: nan, pos_over_neg: 1490.291748046875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 1087.791748046875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 449.785888671875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1461.6593017578125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7736, loss_val: nan, pos_over_neg: 3217.64501953125 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 3473.32666015625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1329.4716796875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 3045.007080078125 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 1056.939697265625 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7686, loss_val: nan, pos_over_neg: 638.58837890625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 1371.29345703125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1839.762939453125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 952.658447265625 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7723, loss_val: nan, pos_over_neg: 553.767578125 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 898.4788208007812 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7691, loss_val: nan, pos_over_neg: 708.5914306640625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1125.3623046875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 837.6692504882812 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1662.943359375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1199.312255859375 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1069.4215087890625 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1329.615966796875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 935.6962280273438 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 896.85595703125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 774.5982055664062 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 760.0567016601562 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1299.1470947265625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 629.648193359375 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 649.9920654296875 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1365.3050537109375 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1042.13134765625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 833.8573608398438 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1063.3184814453125 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 944.4312133789062 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1346.231201171875 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 2187.96337890625 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1276.1151123046875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 976.7811889648438 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1440.6351318359375 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 836.8564453125 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1128.07080078125 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1282.6357421875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 1193.6822509765625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1528.5433349609375 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1575.7825927734375 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 1719.267822265625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 1583.6072998046875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1210.18798828125 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 2187.6689453125 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 2548.958251953125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1176.4298095703125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 517.0341796875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 690.673095703125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 743.776611328125 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1849.4708251953125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 2020.865234375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 548.0266723632812 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1071.6424560546875 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 4111.92431640625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7667, loss_val: nan, pos_over_neg: 792.7728271484375 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 745.0397338867188 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 947.3028564453125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 668.16796875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7687, loss_val: nan, pos_over_neg: 2306.2275390625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1175.16357421875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 560.0952758789062 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 2895.81103515625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 687.8598022460938 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7741, loss_val: nan, pos_over_neg: 533.1341552734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 751.3395385742188 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 787.2071533203125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1414.3729248046875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 1465.049072265625 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1244.56982421875 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 1514.60400390625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 2323.88916015625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 9129.8486328125 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2009.2955322265625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 785.16748046875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 946.902587890625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7706, loss_val: nan, pos_over_neg: 1007.0406494140625 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 675.0151977539062 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 630.3981323242188 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 2245.1279296875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 919.45947265625 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 2915.57421875 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1147.739013671875 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7722, loss_val: nan, pos_over_neg: 909.6846313476562 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7684, loss_val: nan, pos_over_neg: 761.091064453125 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1096.541748046875 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7759, loss_val: nan, pos_over_neg: 1122.6395263671875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 2679.12890625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 2411.91015625 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 661.5535278320312 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 885.0274047851562 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 4902.2265625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1983.8922119140625 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1822.4937744140625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 2595.245849609375 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 637.0679931640625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7676, loss_val: nan, pos_over_neg: 850.8917236328125 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1522.9617919921875 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7728, loss_val: nan, pos_over_neg: 840.0327758789062 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2111.72216796875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7737, loss_val: nan, pos_over_neg: 615.3065795898438 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 800.8495483398438 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1318.0889892578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 921.3604736328125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7692, loss_val: nan, pos_over_neg: 800.10009765625 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 881.9541625976562 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 965.1041259765625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1225.45556640625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1044.258056640625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1028.0528564453125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 739.2972412109375 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 681.6310424804688 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 980.8894653320312 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 742.4735717773438 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 417.59075927734375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1212.198486328125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 457.0159606933594 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 656.4566650390625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 610.8565063476562 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 1257.686279296875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2346.686279296875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1022.455078125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 467.28424072265625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 851.8810424804688 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1046.805419921875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1582.977294921875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7681, loss_val: nan, pos_over_neg: 1307.0816650390625 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1330.965087890625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1188.3748779296875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1864.532958984375 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1081.5242919921875 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 3795.9990234375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 818.94580078125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1001.8418579101562 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 1116.93994140625 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7677, loss_val: nan, pos_over_neg: 674.68310546875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1023.797607421875 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1429.10498046875 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7652, loss_val: nan, pos_over_neg: 1051.893798828125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1584.6256103515625 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 1016.453369140625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 641.0611572265625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1409.3563232421875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1464.867431640625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 5332.97021484375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7708, loss_val: nan, pos_over_neg: 3044.176025390625 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1431.845703125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1329.18798828125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 623.65576171875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 729.703369140625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 736.87646484375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1832.21826171875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7717, loss_val: nan, pos_over_neg: 846.3067016601562 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 2228.271484375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7674, loss_val: nan, pos_over_neg: 1284.3656005859375 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.77, loss_val: nan, pos_over_neg: 1750.9478759765625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7671, loss_val: nan, pos_over_neg: 525.0588989257812 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1263.262451171875 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 2063.8173828125 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 2659.21728515625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 757.3685302734375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 512.3563232421875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 887.310546875 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 560.267333984375 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1975.244873046875 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7658, loss_val: nan, pos_over_neg: 854.7683715820312 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 998.169189453125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1483.290771484375 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2296.993408203125 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7679, loss_val: nan, pos_over_neg: 1264.7952880859375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1277.5439453125 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 848.29150390625 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 739.556884765625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 835.4185180664062 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1187.130859375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 812.3251953125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1624.98291015625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1387.9512939453125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 1013.2819213867188 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1971.9005126953125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 3476.921630859375 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 931.2136840820312 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 1232.5997314453125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1372.5494384765625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 2057.2919921875 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7721, loss_val: nan, pos_over_neg: 842.2469482421875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 860.8494873046875 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7673, loss_val: nan, pos_over_neg: 1027.219970703125 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 1801.6339111328125 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1618.732666015625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2310.85546875 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1535.797119140625 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1201.7763671875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 1566.3262939453125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 873.6555786132812 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1920.848876953125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 1273.2454833984375 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 710.8993530273438 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 770.4006958007812 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1452.9578857421875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 1174.1651611328125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1345.11083984375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1622.2967529296875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 959.14990234375 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 1341.1397705078125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 892.1445922851562 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1352.827880859375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 533.7803344726562 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 927.2144165039062 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.764, loss_val: nan, pos_over_neg: 1301.4686279296875 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 715.6748046875 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 698.9829711914062 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7698, loss_val: nan, pos_over_neg: 575.3885498046875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1360.7301025390625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 781.3133544921875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1003.4856567382812 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7705, loss_val: nan, pos_over_neg: 760.96484375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1128.6837158203125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 759.82421875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 540.1314086914062 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 460.3612976074219 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1083.019775390625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1061.5367431640625 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 1061.06103515625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 755.7830810546875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 503.4947509765625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1265.6322021484375 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/300000 [1:23:33<104182:25:27, 1250.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Iter: 0/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1584.7200927734375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 2522.063720703125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 783.1817016601562 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1825.206787109375 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1010.2967529296875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1604.8709716796875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 771.7916870117188 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 860.9619750976562 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 803.2359619140625 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 1176.213134765625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 975.2572631835938 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1031.744140625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 527.2427368164062 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1207.408935546875 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 929.5577392578125 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 539.5501098632812 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 829.91650390625 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1248.2078857421875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 2327.460693359375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 2123.90283203125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1383.4783935546875 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1066.2979736328125 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 1161.9910888671875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 1391.2325439453125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 733.9522094726562 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7661, loss_val: nan, pos_over_neg: 1699.6217041015625 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 748.254150390625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 543.7529907226562 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 962.3690185546875 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1640.9290771484375 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1227.267333984375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 870.9204711914062 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 694.8004150390625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7765, loss_val: nan, pos_over_neg: 603.9124755859375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1061.6978759765625 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 776.8067016601562 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 893.63916015625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1804.1346435546875 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 942.750244140625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 977.5189208984375 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7707, loss_val: nan, pos_over_neg: 873.0130615234375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1520.846435546875 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1015.1547241210938 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 681.7649536132812 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1071.1519775390625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1817.87548828125 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 1261.338134765625 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 813.5053100585938 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 7428.54541015625 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1447.020751953125 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1265.09521484375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1595.0130615234375 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1310.4267578125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 969.7203979492188 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1216.6103515625 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 2775.18408203125 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 758.4135131835938 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1573.0115966796875 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 2521.747314453125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1100.0152587890625 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1022.7073364257812 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 946.753173828125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7641, loss_val: nan, pos_over_neg: 1559.1998291015625 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 2885.540771484375 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1270.880615234375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7665, loss_val: nan, pos_over_neg: 504.85491943359375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1842.45361328125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 988.71875 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1116.8275146484375 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 656.904052734375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1539.28271484375 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7632, loss_val: nan, pos_over_neg: 498.19610595703125 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 2693.589111328125 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 1493.9989013671875 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1985.125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 851.5733032226562 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 653.4430541992188 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1044.5267333984375 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1207.5244140625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1015.6820678710938 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 846.3663330078125 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1166.40283203125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 1169.080810546875 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1273.0458984375 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1217.1444091796875 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 902.968994140625 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 601.2560424804688 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 667.97900390625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 977.5143432617188 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 857.49951171875 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7643, loss_val: nan, pos_over_neg: 965.5616455078125 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1541.13134765625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1449.6728515625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7675, loss_val: nan, pos_over_neg: 599.2990112304688 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1059.3656005859375 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1153.451904296875 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7689, loss_val: nan, pos_over_neg: 1027.526123046875 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 946.6946411132812 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 2521.154296875 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1948.09521484375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1046.6072998046875 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 7129.06396484375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 709.6723022460938 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 1908.02783203125 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 2497.61474609375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2404.927978515625 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 890.3314208984375 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7688, loss_val: nan, pos_over_neg: 720.342041015625 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1034.3499755859375 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 934.140869140625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 725.7160034179688 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1214.9061279296875 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 4928.9541015625 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 571.637939453125 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 809.9182739257812 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1208.475341796875 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7666, loss_val: nan, pos_over_neg: 1523.5213623046875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1971.3839111328125 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7636, loss_val: nan, pos_over_neg: 613.354248046875 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 830.3164672851562 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1440.173095703125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 933.21923828125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1691.1019287109375 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 808.6168823242188 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1693.9515380859375 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 2874.408203125 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2950.615966796875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1843.427734375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 861.874755859375 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1952.9957275390625 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 538.4989624023438 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2228.681396484375 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 985.5089721679688 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1153.9669189453125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 945.6641845703125 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1179.7220458984375 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1843.804931640625 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1174.173828125 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.768, loss_val: nan, pos_over_neg: 883.67626953125 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 799.1065673828125 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1492.385498046875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 2065.237060546875 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7678, loss_val: nan, pos_over_neg: 970.1724853515625 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 600.7402954101562 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 2357.679443359375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1070.5555419921875 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 6638.04248046875 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1351.23388671875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 846.5435180664062 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1048.5914306640625 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1133.9642333984375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 3989.85986328125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7702, loss_val: nan, pos_over_neg: 827.5047607421875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 928.5962524414062 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7682, loss_val: nan, pos_over_neg: 600.3515014648438 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1779.047119140625 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 2411.290283203125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1192.2515869140625 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 640.1885986328125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 881.1749267578125 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1674.1258544921875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1146.9600830078125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1380.6700439453125 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 890.5250854492188 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1111.1815185546875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1132.6258544921875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1903.8253173828125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 983.5913696289062 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 925.9964599609375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 893.3265991210938 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 524.44384765625 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 2735.89453125 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1341.6959228515625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 760.837890625 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 585.1689453125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 689.1036376953125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 826.8919067382812 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 596.2318725585938 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 2282.56396484375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 836.66796875 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 836.2520751953125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1134.10205078125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 3385.679931640625 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1788.809326171875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 886.1516723632812 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1496.8204345703125 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7654, loss_val: nan, pos_over_neg: 445.17645263671875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1868.0069580078125 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1581.000244140625 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1344.910400390625 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1690.061279296875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1165.82763671875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1596.61767578125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 2312.496337890625 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 3623.76416015625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1226.3367919921875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1018.9065551757812 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2346.38134765625 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7683, loss_val: nan, pos_over_neg: 778.5728149414062 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 765.6546020507812 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 768.7073364257812 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 865.3034057617188 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 888.1141357421875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1361.4022216796875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 862.1702270507812 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1971.549560546875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 978.7467041015625 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1337.3287353515625 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2351.843017578125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1246.4898681640625 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 2098.007080078125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1043.692626953125 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1542.473388671875 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.769, loss_val: nan, pos_over_neg: 393.4815368652344 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 665.98486328125 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 843.8029174804688 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1288.3909912109375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7649, loss_val: nan, pos_over_neg: 956.327880859375 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1625.176513671875 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 606.3300170898438 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 1218.7357177734375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1869.2103271484375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 2171.41748046875 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1083.4351806640625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 893.766845703125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 758.9449462890625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 947.0878295898438 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 871.9526977539062 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1632.0594482421875 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 590.8011474609375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 974.1805419921875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1176.895263671875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 1096.8011474609375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1164.7183837890625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 844.8687744140625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 643.9083251953125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 689.318359375 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 2809.149169921875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1189.023681640625 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 612.5004272460938 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 967.982177734375 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1696.113037109375 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1346.4503173828125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 3931.60986328125 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 956.9602661132812 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1202.4256591796875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 888.379150390625 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 2316.525634765625 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 933.6183471679688 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1764.5645751953125 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1742.901123046875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 2050.807373046875 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 3455.321044921875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 2864.46875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 1235.9931640625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1203.7491455078125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1249.5477294921875 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1636.0140380859375 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1123.3055419921875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 558.64599609375 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1448.039794921875 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 2236.565185546875 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 703.378662109375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1398.3424072265625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 950.6317138671875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 770.7864990234375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 882.7366943359375 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1411.754638671875 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1270.4903564453125 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 809.1133422851562 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 857.4282836914062 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 3027.007080078125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1000.3558349609375 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 670.2030639648438 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7669, loss_val: nan, pos_over_neg: 847.6633911132812 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2602.140869140625 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.766, loss_val: nan, pos_over_neg: 1110.260986328125 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 650.6322631835938 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 1078.15185546875 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1043.6309814453125 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1065.6064453125 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 970.888916015625 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 937.8013305664062 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1697.3409423828125 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7672, loss_val: nan, pos_over_neg: 1050.789794921875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 850.3291015625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.762, loss_val: nan, pos_over_neg: 1899.08154296875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1037.474853515625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1075.8431396484375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7653, loss_val: nan, pos_over_neg: 1110.641845703125 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1005.7223510742188 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 4303.17138671875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1183.0400390625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 976.0846557617188 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1150.851318359375 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 5541.26171875 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1541.0936279296875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1401.291259765625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 598.12060546875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 3585.359375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1258.403564453125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1088.787109375 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1577.6875 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1308.45654296875 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 957.1454467773438 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1047.422607421875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 31551.919921875 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 2794.0283203125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1744.34716796875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 924.2145385742188 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1720.2452392578125 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 3225.13427734375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1466.0682373046875 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1401.1510009765625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 999.5131225585938 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 925.4232788085938 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 2322.253662109375 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1553.8433837890625 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1629.2484130859375 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1127.132080078125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1754.555419921875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 4481.08740234375 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 2300.44287109375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1334.0692138671875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1549.5230712890625 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1996.595947265625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1118.5274658203125 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 998.8025512695312 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1503.214111328125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 3513.916748046875 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 712.8074340820312 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1509.8748779296875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 861.1102294921875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1464.1707763671875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1180.44091796875 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 687.306884765625 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 698.5330200195312 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 3212.2890625 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 957.0125122070312 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 703.8308715820312 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 989.61669921875 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 902.2254028320312 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 734.4569702148438 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 581.3987426757812 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 888.288330078125 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 929.21826171875 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 731.419921875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 669.5099487304688 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 701.625732421875 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1598.6220703125 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 622.64990234375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 611.6812133789062 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 924.1514892578125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1421.2254638671875 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1090.9056396484375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1204.6895751953125 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1337.115234375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 1957.327880859375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1465.2437744140625 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 848.9862060546875 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 807.8248291015625 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 914.1660766601562 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1915.1522216796875 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 2226.654052734375 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 808.632080078125 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 863.3804931640625 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1036.12646484375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 2445.4619140625 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 2015.2308349609375 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1258.7806396484375 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 722.3617553710938 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1147.0804443359375 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1463.3612060546875 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 579.2542114257812 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1104.190673828125 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 937.7050170898438 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7645, loss_val: nan, pos_over_neg: 853.0517578125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 928.9243774414062 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1071.8531494140625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 899.471923828125 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 882.1117553710938 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 1047.1419677734375 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 901.4927368164062 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 688.4920043945312 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 788.1695556640625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 721.2926635742188 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 1833.9141845703125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1291.0499267578125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7648, loss_val: nan, pos_over_neg: 646.5770874023438 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1052.901123046875 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 2426.8994140625 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1483.3162841796875 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 825.252685546875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 761.8389282226562 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1310.9744873046875 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2370.696044921875 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1463.0594482421875 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 898.16162109375 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 586.6929931640625 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1359.5318603515625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1181.8419189453125 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1028.122802734375 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1102.54296875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 787.6887817382812 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1655.4072265625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 772.4896850585938 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1571.376708984375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 975.047119140625 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 601.1258544921875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1318.5931396484375 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1467.0037841796875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7625, loss_val: nan, pos_over_neg: 1314.151123046875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 855.625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1572.35205078125 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 783.4077758789062 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1482.44189453125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 793.8539428710938 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1220.2847900390625 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 882.3593139648438 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.765, loss_val: nan, pos_over_neg: 1201.6038818359375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1120.3731689453125 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7655, loss_val: nan, pos_over_neg: 759.5671997070312 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 763.8788452148438 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 669.3632202148438 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 705.4119262695312 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1588.212890625 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7615, loss_val: nan, pos_over_neg: 965.9791259765625 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7633, loss_val: nan, pos_over_neg: 767.9126586914062 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 891.6498413085938 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 829.654541015625 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1658.8218994140625 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 807.5745849609375 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 627.4996337890625 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1269.7442626953125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 611.8668212890625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7627, loss_val: nan, pos_over_neg: 649.1166381835938 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1344.17138671875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 619.5704345703125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 670.733642578125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 1412.4456787109375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 2956.485595703125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2168.599853515625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1135.172607421875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 884.4180297851562 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 700.2810668945312 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 681.853271484375 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7662, loss_val: nan, pos_over_neg: 465.0174255371094 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 961.191650390625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 828.9849853515625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1351.885009765625 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2393.57080078125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1655.3822021484375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1437.2752685546875 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1213.0048828125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 872.676513671875 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 990.0921630859375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 821.576416015625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 688.5897216796875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 627.2753295898438 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1445.4237060546875 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1725.80322265625 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1544.8660888671875 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1139.2547607421875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 1356.793212890625 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 7269.14697265625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 681.1259765625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 1424.934326171875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 2017.212158203125 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1175.62841796875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 934.5777587890625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 2005.9306640625 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1191.90234375 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1148.8282470703125 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 882.0452270507812 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 705.1607666015625 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1308.8992919921875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 854.6876831054688 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1448.6990966796875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 891.9042358398438 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 942.4061889648438 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 920.7347412109375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1796.672119140625 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 915.594970703125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 794.9534301757812 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7656, loss_val: nan, pos_over_neg: 688.311279296875 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2200.2158203125 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 2129.443359375 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 737.6328125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7685, loss_val: nan, pos_over_neg: 758.3342895507812 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 641.1708984375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 1994.603759765625 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1147.2266845703125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1045.6060791015625 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1040.14794921875 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 714.707275390625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 1007.7368774414062 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1181.1585693359375 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 997.3995971679688 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 779.208251953125 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 963.1482543945312 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.772, loss_val: nan, pos_over_neg: 679.2528076171875 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 777.1640625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 856.554931640625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 810.5385131835938 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1375.0545654296875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 861.1743774414062 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7637, loss_val: nan, pos_over_neg: 448.061279296875 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1501.6588134765625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2394.40087890625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 1750.6104736328125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 731.7855834960938 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 976.607177734375 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1420.7099609375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1822.21630859375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 723.6099853515625 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1134.48486328125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1174.6312255859375 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 838.8399047851562 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7626, loss_val: nan, pos_over_neg: 727.6786499023438 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2360.9287109375 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 773.0401611328125 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 748.2798461914062 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 782.4791259765625 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1519.889892578125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1230.7821044921875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1020.6005859375 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 717.9065551757812 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 2691.472900390625 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1189.966064453125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 829.5652465820312 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 761.4827270507812 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1810.0491943359375 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 646.971923828125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 2066.854736328125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 810.2385864257812 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 915.2288208007812 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2458.17138671875 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1013.3037109375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1430.776611328125 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 966.1958618164062 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1393.1326904296875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1372.1470947265625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 1011.6531982421875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 649.0753173828125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1397.6622314453125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1138.1041259765625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1054.53759765625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1174.027587890625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 1102.9639892578125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1104.50146484375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2831.953125 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 1100.076171875 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1518.8511962890625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1073.9737548828125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1118.5538330078125 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1615.0465087890625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 897.7220458984375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7621, loss_val: nan, pos_over_neg: 1071.8839111328125 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 929.1012573242188 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1519.3150634765625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1539.9647216796875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 611.9158935546875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 992.4979858398438 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1659.2152099609375 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1908.83935546875 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 2340.540771484375 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1281.4755859375 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1365.38720703125 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 2121.18701171875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7651, loss_val: nan, pos_over_neg: 463.6986999511719 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1046.6514892578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 1013.4507446289062 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1103.632080078125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 780.7938232421875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 2350.7822265625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 992.2197265625 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1359.7882080078125 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 919.7520141601562 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1513.1568603515625 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 850.4583740234375 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 2206.68359375 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 999.9443359375 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1000.3018188476562 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 930.5833129882812 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 2955.703125 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2549.080322265625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 1086.2222900390625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 2685.04443359375 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1912.0946044921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1500.67041015625 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1509.1033935546875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1923.7056884765625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 3943.385986328125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7634, loss_val: nan, pos_over_neg: 892.3356323242188 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 950.4168701171875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1384.7091064453125 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1011.9259033203125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 855.7854614257812 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1038.1700439453125 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 826.0151977539062 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 3243.169189453125 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7703, loss_val: nan, pos_over_neg: 1940.8536376953125 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1229.8018798828125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 2522.6171875 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7647, loss_val: nan, pos_over_neg: 5326.10791015625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1118.75537109375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7644, loss_val: nan, pos_over_neg: 1076.194091796875 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1807.064453125 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1041.9908447265625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 807.5970458984375 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7631, loss_val: nan, pos_over_neg: 758.1817016601562 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7624, loss_val: nan, pos_over_neg: 1759.2144775390625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 865.2874145507812 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1709.22705078125 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1888.89599609375 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 845.0960693359375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1339.61962890625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1768.9151611328125 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1216.506103515625 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1324.0994873046875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2082.950439453125 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1615.9613037109375 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7619, loss_val: nan, pos_over_neg: 724.8759765625 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 700.0806274414062 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1993.0521240234375 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1005.7318115234375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 2309.27587890625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 2238.010498046875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1060.41943359375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1215.270263671875 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7638, loss_val: nan, pos_over_neg: 807.4981689453125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 3550.173095703125 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1012.4375610351562 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1129.0411376953125 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 1260.4132080078125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1660.5076904296875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 825.5433349609375 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 830.8043823242188 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1355.5531005859375 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 2115.149658203125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1303.35009765625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1500.709716796875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1154.81005859375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1608.6376953125 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 851.8482666015625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 991.4935302734375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 968.9657592773438 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1269.6903076171875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 1105.6671142578125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1317.436279296875 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 662.9321899414062 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1064.185546875 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1195.0616455078125 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1980.1861572265625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1027.3819580078125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.761, loss_val: nan, pos_over_neg: 899.6862182617188 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1333.532958984375 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 1470.1141357421875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 2267.165771484375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 589.4225463867188 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7605, loss_val: nan, pos_over_neg: 1095.0406494140625 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 1614.9932861328125 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 1511.28662109375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 902.6524658203125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7587, loss_val: nan, pos_over_neg: 903.6901245117188 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2050.006591796875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 958.5694580078125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 3565.9169921875 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 2136.287353515625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7622, loss_val: nan, pos_over_neg: 3602.953857421875 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1034.9530029296875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2273.76171875 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1786.73193359375 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7609, loss_val: nan, pos_over_neg: 752.3960571289062 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 828.1586303710938 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1464.3529052734375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 1204.4259033203125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 2297.064453125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1781.53125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 3976.5576171875 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 970.51904296875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1735.7347412109375 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7663, loss_val: nan, pos_over_neg: 1038.092041015625 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 4474.619140625 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 2512.485595703125 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 739.74365234375 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2740.51904296875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 2091.660888671875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1058.4027099609375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7608, loss_val: nan, pos_over_neg: 1482.371337890625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 4059.833740234375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1133.12744140625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3519.493408203125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 2213.3583984375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1512.4361572265625 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/300000 [1:44:33<104480:26:54, 1253.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Iter: 0/695, loss_train: 5.7635, loss_val: nan, pos_over_neg: 3069.833740234375 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 986.4855346679688 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1511.8751220703125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 581.5512084960938 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 658.9463500976562 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 841.07763671875 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.763, loss_val: nan, pos_over_neg: 872.7089233398438 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1217.7423095703125 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 981.8101196289062 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 1541.69775390625 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7607, loss_val: nan, pos_over_neg: 1063.6180419921875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1141.69775390625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1659.769775390625 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 2128.571533203125 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 992.7410278320312 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 676.1179809570312 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 778.4612426757812 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 840.3602294921875 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1216.20654296875 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 1019.2770385742188 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1014.5979614257812 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1050.937255859375 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 2137.65625 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.767, loss_val: nan, pos_over_neg: 1499.766357421875 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 3524.005615234375 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1267.432373046875 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 3504.056884765625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1517.89599609375 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1383.6475830078125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 3222.42431640625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1068.497314453125 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 958.97900390625 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1669.850341796875 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1072.94189453125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 2831.8955078125 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1955.43359375 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1056.070556640625 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1504.995361328125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1344.78173828125 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7614, loss_val: nan, pos_over_neg: 1240.04931640625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7695, loss_val: nan, pos_over_neg: 591.41357421875 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 983.7432250976562 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 1372.9560546875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 2723.050048828125 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1203.2236328125 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1641.4898681640625 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 2069.058349609375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1129.689697265625 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1572.79443359375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1550.888916015625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 744.279296875 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7606, loss_val: nan, pos_over_neg: 664.9472045898438 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1023.7056884765625 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1012.625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1029.099365234375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 933.8231811523438 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 995.3403930664062 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2151.224853515625 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1112.8807373046875 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 669.0955200195312 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 841.5715942382812 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1899.3790283203125 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2060.58642578125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2045.017822265625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 977.6285400390625 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 982.2420654296875 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 2609.06201171875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 5393.78125 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1493.4014892578125 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1740.7113037109375 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 663.5794067382812 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1369.92041015625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1410.950439453125 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 5447.509765625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1020.6549072265625 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 700.167724609375 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 901.9656982421875 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1459.0465087890625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1404.626220703125 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1246.1990966796875 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 815.6856079101562 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1688.7305908203125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 647.6046752929688 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1392.2342529296875 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1367.1409912109375 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7657, loss_val: nan, pos_over_neg: 688.8440551757812 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 2167.66357421875 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1238.9884033203125 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1310.166748046875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 2192.31298828125 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7586, loss_val: nan, pos_over_neg: 1596.1058349609375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 928.037841796875 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 855.5074462890625 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1891.892822265625 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1361.95556640625 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1532.6829833984375 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1190.2071533203125 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 895.655517578125 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 897.3193359375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1380.2330322265625 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1052.818359375 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1252.4669189453125 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 821.292724609375 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 853.7139282226562 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 633.5595092773438 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7664, loss_val: nan, pos_over_neg: 1198.457763671875 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1116.721923828125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.7642, loss_val: nan, pos_over_neg: 1613.770263671875 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1146.3516845703125 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1653.6910400390625 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1249.8917236328125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2584.137939453125 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 782.0192260742188 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 711.6060180664062 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 858.8560180664062 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 957.1721801757812 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1458.6536865234375 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 884.8864135742188 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 595.9680786132812 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 3078.17236328125 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1701.03759765625 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1161.0400390625 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 545.41357421875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1937.638916015625 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 1574.0555419921875 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 883.2238159179688 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1022.9749755859375 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 4025.56787109375 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 995.9054565429688 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 612.4468383789062 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 623.9320678710938 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 575.400390625 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1045.523193359375 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1630.2236328125 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 951.7683715820312 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 792.10888671875 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7603, loss_val: nan, pos_over_neg: 1038.7257080078125 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 894.0101928710938 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1191.424560546875 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1030.5982666015625 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 768.1102294921875 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 646.8504028320312 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 568.2908935546875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 503.3907165527344 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 1275.635009765625 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 662.4821166992188 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 964.33642578125 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 945.2653198242188 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1345.701904296875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1746.80908203125 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1260.219970703125 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1199.069580078125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 957.567626953125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 3663.71240234375 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1949.87109375 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1665.3421630859375 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1701.831787109375 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1245.7017822265625 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1592.62890625 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1257.0693359375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 5075.8896484375 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 796.0205688476562 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2930.89599609375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 868.4003295898438 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 652.66015625 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 954.6854248046875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1609.377685546875 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 990.6064453125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1253.4178466796875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1085.314453125 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1035.7445068359375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 498.2243957519531 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 710.5499267578125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 789.3501586914062 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1039.455322265625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1071.0167236328125 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1394.81396484375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1215.281982421875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1281.5045166015625 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1099.7369384765625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1462.0389404296875 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1455.8939208984375 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7611, loss_val: nan, pos_over_neg: 694.1082153320312 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1140.7098388671875 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 864.521484375 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1034.6688232421875 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1233.280029296875 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 2595.415771484375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1136.005859375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1315.8822021484375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1107.199951171875 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1041.8466796875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1130.535400390625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1235.2401123046875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7629, loss_val: nan, pos_over_neg: 696.0608520507812 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7659, loss_val: nan, pos_over_neg: 453.93646240234375 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 744.5962524414062 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7604, loss_val: nan, pos_over_neg: 1049.077880859375 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 3031.30859375 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 929.772705078125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 1036.83642578125 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 2122.515380859375 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 871.4343872070312 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1824.648681640625 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 910.6201171875 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1874.451171875 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 815.4550170898438 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 1159.93359375 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1210.1729736328125 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 829.6990356445312 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1399.7939453125 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1172.6553955078125 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 4116.900390625 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 952.1651611328125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 823.5408935546875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 878.7156372070312 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 784.9095458984375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 809.8585815429688 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1412.827392578125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1079.9906005859375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 711.0538330078125 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 1024.9320068359375 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7602, loss_val: nan, pos_over_neg: 699.5089111328125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 2378.487060546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1474.5391845703125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1116.2020263671875 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1847.8148193359375 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 3548.7958984375 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3052.322265625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1438.9119873046875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 3328.061767578125 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1152.68212890625 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1493.461181640625 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2321.182861328125 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1908.4287109375 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1362.2181396484375 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 896.3215942382812 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2141.567138671875 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1043.096435546875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 3061.935302734375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1042.265625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 599.990478515625 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 983.3089599609375 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 577.0659790039062 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1819.468994140625 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 876.0057373046875 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.759, loss_val: nan, pos_over_neg: 715.99169921875 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1303.1336669921875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1290.3814697265625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1554.6630859375 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1219.08154296875 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1671.0279541015625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1453.74365234375 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 1139.311279296875 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1405.2684326171875 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1355.3848876953125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1175.7347412109375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1035.6334228515625 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1389.1444091796875 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 2694.969970703125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1019.6591796875 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1086.3125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 883.3861083984375 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 454.3593444824219 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 583.70361328125 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 723.5941162109375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 871.8128051757812 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 937.9981689453125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1125.355712890625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 852.3876342773438 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 938.7114868164062 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1009.5423583984375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 562.1534423828125 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1328.4517822265625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1174.563232421875 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 2038.97607421875 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1284.0677490234375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1885.329345703125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 642.1168212890625 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1283.9554443359375 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 731.1715087890625 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1307.053955078125 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1024.8006591796875 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 1045.9969482421875 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1194.6981201171875 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1589.869140625 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 37275.21875 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 2050.90380859375 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 827.91943359375 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1200.3568115234375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 1901.768310546875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 7119.0810546875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 1201.42578125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 653.29931640625 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 715.4605712890625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1304.6578369140625 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1156.3463134765625 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1631.13525390625 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 940.138427734375 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1068.255859375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1058.6478271484375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 600.6016845703125 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1025.130126953125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1563.3240966796875 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1576.8505859375 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1460.27294921875 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1176.503662109375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1169.6224365234375 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1225.799560546875 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1118.97900390625 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 758.5171508789062 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 1953.6868896484375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1324.670166015625 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1512.148681640625 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1406.5184326171875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1574.5858154296875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1199.6700439453125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1542.1898193359375 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 921.398681640625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2069.62158203125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1422.516357421875 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 487.67498779296875 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1523.6510009765625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 934.3790893554688 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1278.44384765625 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 4318.76123046875 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 911.81982421875 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1092.4776611328125 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 4017.358642578125 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 762.8836059570312 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 929.5321044921875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 898.857421875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1950.19873046875 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7589, loss_val: nan, pos_over_neg: 523.1935424804688 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1022.7012939453125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7597, loss_val: nan, pos_over_neg: 793.9417724609375 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 800.5081787109375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 814.2659301757812 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 790.3522338867188 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 924.538818359375 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 704.2457275390625 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1398.367919921875 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1186.0048828125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 710.0820922851562 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 714.261962890625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 834.1001586914062 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 679.4585571289062 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 829.8972778320312 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 804.2353515625 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 971.2357177734375 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 942.0325317382812 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 739.0188598632812 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 639.2225341796875 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1476.087890625 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 649.0316772460938 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 725.5220947265625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1041.7777099609375 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 783.1079711914062 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 797.7412719726562 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 604.8470458984375 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 510.7853698730469 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2124.066650390625 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 2430.882080078125 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 994.1760864257812 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 753.2942504882812 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 964.0527954101562 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2949.37060546875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 5835.46435546875 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1618.600830078125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 593.8553466796875 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 537.9887084960938 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1036.9793701171875 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1592.0338134765625 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 970.4735107421875 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1176.155029296875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 970.71337890625 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 2961.69580078125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 768.2310791015625 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 819.7341918945312 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.7646, loss_val: nan, pos_over_neg: 505.5947570800781 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 807.4635620117188 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1230.2655029296875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 922.0537719726562 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 901.5565185546875 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1236.82275390625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1381.6767578125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 3701.10205078125 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 3035.35693359375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 895.7798461914062 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 955.4979858398438 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1157.4298095703125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 794.7677001953125 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 861.2474975585938 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 3518.421142578125 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 517.5601196289062 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 791.8385620117188 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 705.8136596679688 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1411.8328857421875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 614.029052734375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 754.1129150390625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1157.773193359375 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 740.17919921875 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1020.031982421875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 909.0256958007812 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 696.9793090820312 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1035.69775390625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 913.8090209960938 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 896.4554443359375 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1266.9979248046875 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 943.8406982421875 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1070.4130859375 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1442.992919921875 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 2078.56640625 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 10250.8115234375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1202.474609375 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 2105.38720703125 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1075.830078125 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7617, loss_val: nan, pos_over_neg: 824.8428955078125 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1273.43603515625 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1293.7767333984375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1034.9495849609375 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 866.1497192382812 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1052.3328857421875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 915.2048950195312 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 3736.386962890625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1082.2852783203125 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 976.4584350585938 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7628, loss_val: nan, pos_over_neg: 1071.3223876953125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1732.762451171875 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1210.9617919921875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1074.710693359375 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 4451.498046875 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2773.480224609375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1034.0218505859375 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1112.6875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1086.1943359375 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1254.1849365234375 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2721.3330078125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 833.09033203125 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 955.7181396484375 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2879.05712890625 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1372.2904052734375 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1036.4495849609375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 2035.01904296875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 848.15625 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 880.9561157226562 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7599, loss_val: nan, pos_over_neg: 884.9105834960938 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7595, loss_val: nan, pos_over_neg: 1075.711181640625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 996.0806884765625 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 2643.859130859375 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7639, loss_val: nan, pos_over_neg: 765.325439453125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 1157.809326171875 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1338.72021484375 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 4118.12548828125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1885.247314453125 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1055.316162109375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1249.9439697265625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 2518.440185546875 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1008.3065185546875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7598, loss_val: nan, pos_over_neg: 2003.7022705078125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2017.3734130859375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7623, loss_val: nan, pos_over_neg: 1290.7613525390625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1086.2279052734375 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1548.1273193359375 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2347.472900390625 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 79596.546875 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1526.84326171875 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2474.353271484375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 2299.412109375 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1832.900634765625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 956.6063842773438 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2146.088623046875 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1855.4632568359375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 3787.297119140625 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1859.710693359375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1667.65673828125 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1461.0667724609375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 1984.787109375 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1256.70703125 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 3038.938720703125 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 1857.665771484375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1635.3934326171875 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1388.2210693359375 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 970.5587768554688 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 689.3915405273438 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 20249.34765625 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 7428.49853515625 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1183.1661376953125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 727.0314331054688 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1434.4622802734375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1418.07373046875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1226.22314453125 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1074.466064453125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 890.5250854492188 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1744.023681640625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1327.545654296875 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 777.8035888671875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1187.0361328125 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 713.4138793945312 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1005.2424926757812 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1697.4658203125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1171.458984375 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1220.9107666015625 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7601, loss_val: nan, pos_over_neg: 542.4144287109375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 743.42333984375 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 672.59033203125 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1622.282470703125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 828.95751953125 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1464.3516845703125 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7581, loss_val: nan, pos_over_neg: 3511.077880859375 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7613, loss_val: nan, pos_over_neg: 894.630126953125 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 898.0928344726562 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 570.227294921875 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2122.190185546875 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1255.938232421875 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 2092.628173828125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 646.294921875 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1079.1614990234375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 596.47607421875 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1543.443603515625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 984.0050659179688 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 746.536376953125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 796.1641845703125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 961.8411254882812 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1238.2884521484375 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1178.1085205078125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1180.7296142578125 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 926.9739990234375 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7616, loss_val: nan, pos_over_neg: 791.127685546875 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1321.5404052734375 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1029.849853515625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1945.100341796875 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1866.4542236328125 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2598.385009765625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.758, loss_val: nan, pos_over_neg: 1021.23974609375 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1235.2528076171875 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2864.364990234375 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 834.4163818359375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 2466.656494140625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1461.0103759765625 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1731.2781982421875 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1361.0045166015625 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1415.7802734375 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 98098.578125 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 1678.4737548828125 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1445.42578125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1978.7076416015625 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 3901.18701171875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7596, loss_val: nan, pos_over_neg: 1013.7471923828125 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1402.3453369140625 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 958.7936401367188 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 828.6106567382812 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 738.3519897460938 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 911.8396606445312 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1515.013427734375 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 972.1373291015625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 453.70245361328125 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 883.558837890625 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1018.3958740234375 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1047.2730712890625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 780.9832153320312 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1818.5477294921875 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1054.804931640625 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1850.21728515625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 792.0269165039062 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1096.48291015625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 926.8504638671875 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1213.4283447265625 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 795.7630004882812 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 1328.455810546875 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1087.030517578125 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 888.7462158203125 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1637.0831298828125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 956.6893310546875 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 621.3638305664062 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 942.9007568359375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1801.3046875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 713.6348266601562 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7591, loss_val: nan, pos_over_neg: 697.9544067382812 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 625.6970825195312 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7584, loss_val: nan, pos_over_neg: 998.028564453125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 743.9781494140625 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1063.9215087890625 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 494.9631042480469 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 700.9376831054688 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 862.06298828125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.76, loss_val: nan, pos_over_neg: 610.7010498046875 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 981.1697998046875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 1504.017333984375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1114.4163818359375 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 618.0828857421875 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 976.1187744140625 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 791.9912109375 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1920.3973388671875 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1491.9158935546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 796.5288696289062 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 749.24951171875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 432.2076110839844 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 902.7377319335938 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 819.72509765625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 689.1937866210938 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 991.0494995117188 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1458.7532958984375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 685.5252075195312 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7569, loss_val: nan, pos_over_neg: 737.228759765625 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 737.2921752929688 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1211.7952880859375 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 3018.66064453125 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1208.062744140625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 961.908447265625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1032.9776611328125 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1264.6568603515625 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1036.0235595703125 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1186.0789794921875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1010.5968017578125 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1430.4437255859375 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 723.3914794921875 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 570.68115234375 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 743.7426147460938 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1895.083251953125 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 2363.140625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 995.5715942382812 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 671.7284545898438 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1052.6195068359375 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 996.9547729492188 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1598.287109375 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 700.832275390625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 705.7233276367188 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 803.0849609375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 737.7392578125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1675.5950927734375 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7593, loss_val: nan, pos_over_neg: 1045.11962890625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1190.8343505859375 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1850.40771484375 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1278.634521484375 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 2598.47216796875 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 827.5897216796875 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 964.881103515625 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1148.72607421875 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1152.2315673828125 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1078.6253662109375 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 855.099853515625 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1809.5140380859375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1122.5052490234375 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1784.587646484375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 2060.6240234375 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 3008.1787109375 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1044.380126953125 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1593.9305419921875 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 9539.177734375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1399.53466796875 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 657.5552978515625 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7583, loss_val: nan, pos_over_neg: 780.1533813476562 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 844.35009765625 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1270.6988525390625 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1435.9822998046875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7557, loss_val: nan, pos_over_neg: 1726.6182861328125 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 889.1416625976562 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: -5325.67333984375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 911.6483764648438 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 11712.34375 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 765.0488891601562 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 35412.84375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1814.0830078125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 2472.986328125 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 798.7938842773438 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 614.0294189453125 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 977.4511108398438 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1244.531494140625 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 911.722412109375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1073.1982421875 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 1117.151611328125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 627.1998291015625 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1259.787353515625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 821.9151000976562 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1421.82666015625 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 1532.4600830078125 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 1031.7904052734375 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2435.48486328125 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 717.652099609375 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 560.794921875 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 647.5032348632812 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 2619.189453125 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1037.9593505859375 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1573.736572265625 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7612, loss_val: nan, pos_over_neg: 765.139892578125 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 696.9185180664062 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1038.13232421875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1209.5096435546875 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2730.58203125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1008.5255126953125 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1079.72900390625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 638.1651611328125 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1890.47998046875 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 3624.2333984375 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/300000 [2:05:35<104708:52:56, 1256.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Iter: 0/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1352.6531982421875 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 814.0870971679688 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1039.388916015625 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1678.6942138671875 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1529.18408203125 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1030.980712890625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 898.2947998046875 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 857.4622192382812 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 937.5931396484375 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 805.1488647460938 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1438.6220703125 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1528.9136962890625 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 765.0289916992188 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 660.3489990234375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 891.1591186523438 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7554, loss_val: nan, pos_over_neg: 1017.521728515625 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 903.9287109375 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1731.854736328125 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 826.795166015625 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1472.6427001953125 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 951.0283813476562 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1575.060546875 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 787.2499389648438 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 909.4263916015625 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7575, loss_val: nan, pos_over_neg: 625.3065795898438 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7564, loss_val: nan, pos_over_neg: 679.7838745117188 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 885.6015625 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 880.8698120117188 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1831.71533203125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1438.2783203125 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 734.2785034179688 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1532.501220703125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 948.122802734375 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1029.8509521484375 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1115.9525146484375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1984.19873046875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 767.2022705078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 2966.618408203125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1481.1578369140625 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1973.6112060546875 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 2692.541259765625 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2969.007568359375 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1519.187255859375 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1599.135498046875 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 918.80029296875 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1315.86669921875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1154.78271484375 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1922.31201171875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 3160.53662109375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1107.7978515625 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 585.8803100585938 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1180.8941650390625 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1841.017578125 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1740.2340087890625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 774.09375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 649.4603881835938 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1235.70458984375 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 966.6477661132812 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1387.7637939453125 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1190.5565185546875 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 810.1123657226562 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 744.3491821289062 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1168.3302001953125 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 1443.4822998046875 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 1019.5783081054688 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1558.922119140625 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1084.631591796875 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 733.0227661132812 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 946.302978515625 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 3199.335205078125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1376.8331298828125 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1888.3277587890625 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1442.156982421875 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 5473.9462890625 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1018.5196533203125 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7566, loss_val: nan, pos_over_neg: 1349.4986572265625 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1089.52880859375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1371.5565185546875 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1837.614990234375 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 925.2999267578125 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 625.2672729492188 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1388.86328125 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1872.134765625 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1132.7275390625 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 600.6470336914062 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 810.4141235351562 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 624.308837890625 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1927.2205810546875 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2990.05322265625 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 898.9406127929688 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7579, loss_val: nan, pos_over_neg: 689.6250610351562 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 715.8523559570312 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 884.9759521484375 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1146.35888671875 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 1891.2459716796875 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 621.0264892578125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 655.347900390625 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 523.3939208984375 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 701.3890991210938 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1414.380615234375 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1159.8330078125 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 699.5629272460938 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 778.4874877929688 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1046.447509765625 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 2130.42333984375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 1004.235595703125 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 1108.32861328125 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1007.02099609375 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 732.5521850585938 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 517.4886474609375 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 532.6355590820312 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 955.2907104492188 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 649.0530395507812 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 693.576904296875 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1221.2342529296875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 801.4838256835938 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 621.2518310546875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 796.9249267578125 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 1585.716552734375 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1495.193359375 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 671.3770751953125 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 555.7725219726562 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 943.09033203125 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 663.2698364257812 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7565, loss_val: nan, pos_over_neg: 814.2056884765625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7416, loss_val: nan, pos_over_neg: 3221.627685546875 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 4574.67138671875 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 921.0407104492188 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 908.5798950195312 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 989.8049926757812 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1252.1468505859375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1316.965576171875 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 769.4356689453125 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 812.6336669921875 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 756.0709838867188 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1347.603759765625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1286.3553466796875 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1008.7338256835938 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 645.5806274414062 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 715.4946899414062 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1738.778564453125 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.7588, loss_val: nan, pos_over_neg: 601.9530639648438 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 816.6593017578125 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 796.4246215820312 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1065.9417724609375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 744.8297729492188 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 881.8012084960938 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 652.1240234375 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 801.7645263671875 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 1092.5452880859375 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 925.1517333984375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 839.118408203125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1266.982421875 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 945.9071044921875 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1899.7840576171875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1232.1883544921875 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 2234.317626953125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 723.355224609375 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1510.5107421875 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 2128.710693359375 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1046.4189453125 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1265.5361328125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 961.6945190429688 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 968.094970703125 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1188.24169921875 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 720.3468017578125 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 776.46240234375 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1011.1119995117188 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1733.5888671875 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 904.191162109375 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1080.4609375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 1271.7666015625 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2577.645751953125 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2060.477294921875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 1161.5548095703125 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 715.7708129882812 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 933.8890380859375 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1617.463623046875 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1450.7413330078125 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1804.4605712890625 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1067.477783203125 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 1495.2911376953125 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1159.582763671875 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1364.767822265625 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1967.970703125 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1880.187744140625 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 2044.085205078125 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1354.2281494140625 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.7618, loss_val: nan, pos_over_neg: 543.598876953125 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1094.34130859375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 2537.724365234375 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2719.387939453125 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1109.0015869140625 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 656.1044921875 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1917.6680908203125 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1311.5457763671875 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1272.2642822265625 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 857.2018432617188 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1059.6871337890625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 1240.604736328125 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7577, loss_val: nan, pos_over_neg: 719.5844116210938 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 739.998779296875 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 723.7073974609375 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1417.953857421875 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 986.3058471679688 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 721.0171508789062 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 982.71533203125 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 2016.6201171875 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7576, loss_val: nan, pos_over_neg: 924.9891967773438 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1035.385498046875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 1658.654052734375 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 2278.650390625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 810.8988037109375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 587.755126953125 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1092.805419921875 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1003.99560546875 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1097.925537109375 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 1072.3671875 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 623.0415649414062 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 761.9325561523438 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 985.6917724609375 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1509.0118408203125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 3986.30908203125 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1198.285400390625 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 885.9495849609375 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 910.7539672851562 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1214.41455078125 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 1108.39404296875 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1378.2314453125 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 1232.7216796875 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1359.193359375 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1431.982421875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 881.1954956054688 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1426.152587890625 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1030.506103515625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1648.321533203125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 821.239501953125 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1262.4232177734375 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 952.2459716796875 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 3753.487060546875 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 988.463134765625 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 7137.78173828125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1016.1837158203125 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 4199.568359375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 2090.32080078125 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1442.484619140625 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7592, loss_val: nan, pos_over_neg: 1441.8876953125 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1170.5234375 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 922.4154663085938 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1852.3179931640625 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1368.0404052734375 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7553, loss_val: nan, pos_over_neg: 1733.2198486328125 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1085.1826171875 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1218.5093994140625 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1111.67041015625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1096.7354736328125 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1262.267578125 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2061.10205078125 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1370.1197509765625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 2666.032470703125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1146.99609375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1242.3585205078125 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2038.426513671875 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1560.7301025390625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 707.8578491210938 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 1206.261474609375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 866.721923828125 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 809.177001953125 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 3561.926025390625 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1076.6820068359375 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1286.7034912109375 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1156.8226318359375 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1015.785888671875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1446.1363525390625 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 856.6065673828125 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1415.856689453125 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1136.5833740234375 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1078.8087158203125 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 809.9495239257812 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 608.6032104492188 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 900.2069702148438 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 848.2586669921875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1386.2589111328125 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1942.984375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.757, loss_val: nan, pos_over_neg: 3503.641845703125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 873.7086791992188 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1693.830322265625 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 5334.837890625 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1576.358642578125 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 2964.799560546875 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 971.5635986328125 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1264.4581298828125 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1368.323486328125 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 920.8076171875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 950.7762451171875 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1358.5697021484375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2204.595703125 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1761.9129638671875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1646.2052001953125 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7573, loss_val: nan, pos_over_neg: 966.9017333984375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 3433.458740234375 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1100.2379150390625 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1537.62744140625 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2854.634765625 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1733.0362548828125 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 1352.8812255859375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1314.12646484375 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 1707.98876953125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7582, loss_val: nan, pos_over_neg: 860.7528686523438 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2453.82470703125 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1190.83447265625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1067.435302734375 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 881.8399047851562 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 2600.322998046875 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1037.0115966796875 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1209.69140625 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1040.962158203125 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 965.9701538085938 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1183.9010009765625 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 2472.64453125 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 2670.564697265625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 790.1727905273438 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1132.0833740234375 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 831.1131591796875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 2155.6474609375 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1285.615478515625 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 1563.369140625 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 668.1363525390625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 719.6752319335938 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 961.4992065429688 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1102.791748046875 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 911.1807250976562 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1390.5640869140625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1506.7840576171875 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 980.0867309570312 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 849.4387817382812 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1422.7464599609375 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 908.4302368164062 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1384.2454833984375 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 813.1572875976562 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1591.859130859375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2386.67578125 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1780.048095703125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1429.673095703125 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 958.9070434570312 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1594.21923828125 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1155.7752685546875 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1102.5723876953125 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 910.5999755859375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1119.8717041015625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 5898.74365234375 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1454.8148193359375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 3573.0634765625 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1092.8878173828125 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1045.3297119140625 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1181.63134765625 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 971.652587890625 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1438.7708740234375 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 907.0438232421875 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1092.127197265625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1755.0908203125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1937.6121826171875 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1414.9820556640625 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1013.1980590820312 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7572, loss_val: nan, pos_over_neg: 636.8154907226562 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 4427.76220703125 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 2031.9246826171875 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2679.39599609375 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1976.4190673828125 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 3441.612548828125 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 3127.033203125 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 78311.765625 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 3645.89501953125 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1494.4385986328125 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7594, loss_val: nan, pos_over_neg: 1586.74169921875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 3365.25537109375 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1123.0843505859375 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 861.3684692382812 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1087.8111572265625 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 6655.9775390625 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2470.029541015625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1397.8280029296875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 766.572021484375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1823.3604736328125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1888.9063720703125 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 2560.298095703125 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 658.3461303710938 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2310.52392578125 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 3028.75048828125 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 1160.5074462890625 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 670.3888549804688 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1247.4727783203125 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2477.130859375 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 787.8599853515625 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 1982.6685791015625 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1181.1900634765625 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 951.9498901367188 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1344.4400634765625 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1482.398193359375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1149.7506103515625 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1427.1678466796875 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 1353.4688720703125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1280.696044921875 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 1006.24365234375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1093.8023681640625 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1768.2730712890625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1585.4263916015625 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 2115.540283203125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1723.0843505859375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1225.481689453125 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1448.154296875 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 2106.349853515625 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1449.093505859375 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1613.18359375 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1610.75341796875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 784.427978515625 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 1054.9876708984375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7537, loss_val: nan, pos_over_neg: 940.2445068359375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 3877.610107421875 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 877.3434448242188 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 868.7289428710938 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1061.839599609375 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 4049.01123046875 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1448.7705078125 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 4434.02099609375 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1638.1077880859375 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 675.35498046875 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1274.7344970703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.756, loss_val: nan, pos_over_neg: 723.1429443359375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1191.0848388671875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1534.1099853515625 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 911.52001953125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 2183.09912109375 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1052.0751953125 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1802.7674560546875 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 1155.2340087890625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 4148.3466796875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1320.5694580078125 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 971.4535522460938 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 892.5523681640625 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1505.5062255859375 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1491.4127197265625 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1102.4139404296875 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 3826.421875 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 2358.07080078125 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1171.5396728515625 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1768.9962158203125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 639.0535278320312 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1584.4007568359375 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 669.8151245117188 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 935.212158203125 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 707.8997802734375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7538, loss_val: nan, pos_over_neg: 2528.515869140625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1357.6435546875 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1254.6636962890625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7561, loss_val: nan, pos_over_neg: 500.85296630859375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1330.1806640625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1014.5557861328125 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1165.8162841796875 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1820.0528564453125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 3712.34375 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 919.6561889648438 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2077.197998046875 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 825.8566284179688 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 5110.55029296875 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1447.9049072265625 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.7571, loss_val: nan, pos_over_neg: 1297.2178955078125 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 966.7622680664062 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1001.8501586914062 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 888.8226928710938 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1581.388671875 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 678.7180786132812 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 602.2090454101562 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1039.9954833984375 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1051.1732177734375 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 893.346435546875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 14003.2099609375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1579.665771484375 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1887.5911865234375 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7549, loss_val: nan, pos_over_neg: 1140.5750732421875 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1109.9378662109375 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2976.187255859375 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 3692.9296875 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 2781.27392578125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1361.2757568359375 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 4289.4296875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1513.0399169921875 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 796.54931640625 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1018.038330078125 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1051.505615234375 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2369.967529296875 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 2155.420654296875 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 772.2933349609375 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1268.2506103515625 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1615.8961181640625 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 955.415771484375 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 3464.838134765625 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1517.6351318359375 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1481.2718505859375 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 842.3043823242188 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 849.531494140625 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1105.49072265625 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1234.466064453125 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1508.34130859375 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 790.0000610351562 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 741.9198608398438 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 1702.6846923828125 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 978.6160278320312 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.754, loss_val: nan, pos_over_neg: 582.229248046875 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 791.0322265625 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1224.934326171875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1088.5103759765625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1667.1995849609375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1309.71484375 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1394.100830078125 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1329.6844482421875 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 2250.546142578125 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2765.6181640625 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1790.5126953125 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7524, loss_val: nan, pos_over_neg: 944.4745483398438 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1404.4937744140625 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 965.774658203125 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7428, loss_val: nan, pos_over_neg: 1980.7674560546875 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1048.063720703125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1339.7850341796875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1508.4698486328125 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1152.34423828125 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 676.3026123046875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1920.70166015625 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 2324.399169921875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 966.4392700195312 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 870.7655639648438 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 4725.91650390625 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 1993.241455078125 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 3449.92626953125 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1411.9837646484375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 685.782470703125 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1579.7901611328125 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1213.867431640625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 5567.6533203125 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2006.1507568359375 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 2380.5771484375 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1206.275390625 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1419.365478515625 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 2058.8369140625 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1977.4228515625 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7542, loss_val: nan, pos_over_neg: 803.1829223632812 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 989.172119140625 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 3501.3291015625 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 3061.527099609375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 2501.541259765625 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 2969.148193359375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1033.4420166015625 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 3429.46240234375 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 2121.3681640625 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2181.853271484375 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 956.3701171875 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1424.8623046875 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 793.4212036132812 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1342.3084716796875 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1312.8367919921875 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1393.3834228515625 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 713.7401123046875 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1803.1099853515625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2341.36083984375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1260.418212890625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1549.4915771484375 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1486.5654296875 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 7785.34716796875 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 3706.199951171875 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 5182.4326171875 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 3782.386962890625 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 2248.75439453125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 2386.544189453125 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1850.012451171875 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1309.814453125 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: 5810.7529296875 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1086.4912109375 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1361.0906982421875 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 994.7180786132812 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 2854.28125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1483.46142578125 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 4245.142578125 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 5936.64306640625 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1179.7845458984375 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 2516.7822265625 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 2467.604736328125 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 5328.8330078125 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1504.39794921875 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 677.385986328125 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 799.7884521484375 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 4058.9677734375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1132.6651611328125 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2421.056396484375 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 3367.604736328125 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1105.605224609375 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 730.17626953125 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1921.791259765625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1850.873291015625 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1578.0712890625 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1786.3890380859375 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1453.0833740234375 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7541, loss_val: nan, pos_over_neg: 1019.2738037109375 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 761.088134765625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 844.7018432617188 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 2705.634521484375 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1013.0745239257812 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7574, loss_val: nan, pos_over_neg: 931.951904296875 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2923.888671875 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1857.7789306640625 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7527, loss_val: nan, pos_over_neg: 800.966796875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 1072.278564453125 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2947.79296875 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 3556.296630859375 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1342.593994140625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2482.049072265625 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2500.990478515625 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 17951.869140625 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1294.642822265625 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2230.82666015625 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 5481.8837890625 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 1398.6959228515625 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 2123.92919921875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1353.6341552734375 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2077.116455078125 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1061.0206298828125 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1301.795654296875 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1279.8277587890625 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 1541.7073974609375 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1302.7891845703125 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1011.2559814453125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7533, loss_val: nan, pos_over_neg: 1091.4586181640625 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 1028.8424072265625 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 146467.765625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1011.3136596679688 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 930.4120483398438 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7407, loss_val: nan, pos_over_neg: 27886.62890625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1388.3206787109375 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1040.701416015625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1166.2906494140625 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 3296.396728515625 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1666.9754638671875 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 3820.08740234375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 882.8739013671875 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 1233.4150390625 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1813.0577392578125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7407, loss_val: nan, pos_over_neg: 1178.91015625 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1408.5604248046875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 853.8032836914062 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 924.9339599609375 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.753, loss_val: nan, pos_over_neg: 894.8341064453125 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 896.5061645507812 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 929.1566772460938 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 890.080078125 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7556, loss_val: nan, pos_over_neg: 1100.028564453125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 729.0162353515625 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 772.2166137695312 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1234.86279296875 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1475.0474853515625 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1303.2489013671875 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 2147.6796875 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 821.6740112304688 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1497.0072021484375 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2059.70703125 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 2333.2080078125 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 2519.7314453125 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1426.73974609375 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 2062.0625 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1729.59912109375 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1708.9971923828125 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 1139.286376953125 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1405.286376953125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 2873.141845703125 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 2675.262451171875 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1600.268798828125 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1059.235595703125 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 608.7599487304688 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 2059.8232421875 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 873.5914306640625 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 738.7235717773438 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1086.770751953125 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1055.413330078125 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7567, loss_val: nan, pos_over_neg: 700.192138671875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 2412.376953125 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 4724.39208984375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.755, loss_val: nan, pos_over_neg: 1256.924560546875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1370.7100830078125 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1821.7928466796875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 95745.7109375 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 19547.67578125 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1060.05224609375 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2036.5699462890625 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1078.541259765625 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1089.9107666015625 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1229.614013671875 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/300000 [2:26:30<104662:47:09, 1255.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Iter: 0/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 2178.368408203125 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1977.6885986328125 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1649.319580078125 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1141.8828125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 3062.919921875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7545, loss_val: nan, pos_over_neg: 1321.56787109375 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1183.137939453125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 858.1251831054688 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1055.830810546875 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7406, loss_val: nan, pos_over_neg: 2262.04248046875 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 1065.662841796875 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 2055.615966796875 lr: 0.00031623\n",
      "Iter: 12/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1104.3614501953125 lr: 0.00031623\n",
      "Iter: 13/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1882.5989990234375 lr: 0.00031623\n",
      "Iter: 14/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1871.2366943359375 lr: 0.00031623\n",
      "Iter: 15/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 1499.6329345703125 lr: 0.00031623\n",
      "Iter: 16/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 1364.96142578125 lr: 0.00031623\n",
      "Iter: 17/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1165.484375 lr: 0.00031623\n",
      "Iter: 18/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1611.923583984375 lr: 0.00031623\n",
      "Iter: 19/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 804.4178466796875 lr: 0.00031623\n",
      "Iter: 20/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 1424.1337890625 lr: 0.00031623\n",
      "Iter: 21/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 709.275634765625 lr: 0.00031623\n",
      "Iter: 22/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1208.0233154296875 lr: 0.00031623\n",
      "Iter: 23/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1708.5283203125 lr: 0.00031623\n",
      "Iter: 24/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1092.700439453125 lr: 0.00031623\n",
      "Iter: 25/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 926.923828125 lr: 0.00031623\n",
      "Iter: 26/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 960.944091796875 lr: 0.00031623\n",
      "Iter: 27/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 891.8330078125 lr: 0.00031623\n",
      "Iter: 28/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 2222.063720703125 lr: 0.00031623\n",
      "Iter: 29/695, loss_train: 5.7428, loss_val: nan, pos_over_neg: 2542.90869140625 lr: 0.00031623\n",
      "Iter: 30/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 2446.1865234375 lr: 0.00031623\n",
      "Iter: 31/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1184.6602783203125 lr: 0.00031623\n",
      "Iter: 32/695, loss_train: 5.7434, loss_val: nan, pos_over_neg: 1688.13916015625 lr: 0.00031623\n",
      "Iter: 33/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 13872.3251953125 lr: 0.00031623\n",
      "Iter: 34/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1984.42724609375 lr: 0.00031623\n",
      "Iter: 35/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 1838.606201171875 lr: 0.00031623\n",
      "Iter: 36/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 1162.44580078125 lr: 0.00031623\n",
      "Iter: 37/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 2140.499267578125 lr: 0.00031623\n",
      "Iter: 38/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 919.4498901367188 lr: 0.00031623\n",
      "Iter: 39/695, loss_train: 5.7504, loss_val: nan, pos_over_neg: 951.3759765625 lr: 0.00031623\n",
      "Iter: 40/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1082.9915771484375 lr: 0.00031623\n",
      "Iter: 41/695, loss_train: 5.7416, loss_val: nan, pos_over_neg: 2526.7197265625 lr: 0.00031623\n",
      "Iter: 42/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 1474.0692138671875 lr: 0.00031623\n",
      "Iter: 43/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 892.2796020507812 lr: 0.00031623\n",
      "Iter: 44/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 2065.135009765625 lr: 0.00031623\n",
      "Iter: 45/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1389.4959716796875 lr: 0.00031623\n",
      "Iter: 46/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 6660.49951171875 lr: 0.00031623\n",
      "Iter: 47/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1379.508544921875 lr: 0.00031623\n",
      "Iter: 48/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 4180.8037109375 lr: 0.00031623\n",
      "Iter: 49/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 3673.370849609375 lr: 0.00031623\n",
      "Iter: 50/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1702.8685302734375 lr: 0.00031623\n",
      "Iter: 51/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 1593.75439453125 lr: 0.00031623\n",
      "Iter: 52/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1207.1248779296875 lr: 0.00031623\n",
      "Iter: 53/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 2466.2900390625 lr: 0.00031623\n",
      "Iter: 54/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: -19650.537109375 lr: 0.00031623\n",
      "Iter: 55/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1446.862060546875 lr: 0.00031623\n",
      "Iter: 56/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 1301.4364013671875 lr: 0.00031623\n",
      "Iter: 57/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 2659.618896484375 lr: 0.00031623\n",
      "Iter: 58/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1012.0228881835938 lr: 0.00031623\n",
      "Iter: 59/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1847.562255859375 lr: 0.00031623\n",
      "Iter: 60/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1337.208740234375 lr: 0.00031623\n",
      "Iter: 61/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 3852.3583984375 lr: 0.00031623\n",
      "Iter: 62/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1404.85302734375 lr: 0.00031623\n",
      "Iter: 63/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1044.0240478515625 lr: 0.00031623\n",
      "Iter: 64/695, loss_train: 5.7377, loss_val: nan, pos_over_neg: 1147.06396484375 lr: 0.00031623\n",
      "Iter: 65/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1670.519287109375 lr: 0.00031623\n",
      "Iter: 66/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2127.9189453125 lr: 0.00031623\n",
      "Iter: 67/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1120.394287109375 lr: 0.00031623\n",
      "Iter: 68/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1303.3612060546875 lr: 0.00031623\n",
      "Iter: 69/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 1218.294189453125 lr: 0.00031623\n",
      "Iter: 70/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 875.25 lr: 0.00031623\n",
      "Iter: 71/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1140.9564208984375 lr: 0.00031623\n",
      "Iter: 72/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1845.6539306640625 lr: 0.00031623\n",
      "Iter: 73/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1428.1427001953125 lr: 0.00031623\n",
      "Iter: 74/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 610.5512084960938 lr: 0.00031623\n",
      "Iter: 75/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 814.1182250976562 lr: 0.00031623\n",
      "Iter: 76/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 928.85302734375 lr: 0.00031623\n",
      "Iter: 77/695, loss_train: 5.7419, loss_val: nan, pos_over_neg: 2275.326416015625 lr: 0.00031623\n",
      "Iter: 78/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1166.4918212890625 lr: 0.00031623\n",
      "Iter: 79/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 665.1099243164062 lr: 0.00031623\n",
      "Iter: 80/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1544.5172119140625 lr: 0.00031623\n",
      "Iter: 81/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 1893.2615966796875 lr: 0.00031623\n",
      "Iter: 82/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1941.87548828125 lr: 0.00031623\n",
      "Iter: 83/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 7755.71533203125 lr: 0.00031623\n",
      "Iter: 84/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 2997.254150390625 lr: 0.00031623\n",
      "Iter: 85/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1188.4912109375 lr: 0.00031623\n",
      "Iter: 86/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 942.3095092773438 lr: 0.00031623\n",
      "Iter: 87/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1689.2447509765625 lr: 0.00031623\n",
      "Iter: 88/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 598.83154296875 lr: 0.00031623\n",
      "Iter: 89/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1014.6917114257812 lr: 0.00031623\n",
      "Iter: 90/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1875.6048583984375 lr: 0.00031623\n",
      "Iter: 91/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 2026.0250244140625 lr: 0.00031623\n",
      "Iter: 92/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 659.453857421875 lr: 0.00031623\n",
      "Iter: 93/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 2060.378662109375 lr: 0.00031623\n",
      "Iter: 94/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1719.843017578125 lr: 0.00031623\n",
      "Iter: 95/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 584.73876953125 lr: 0.00031623\n",
      "Iter: 96/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 805.9550170898438 lr: 0.00031623\n",
      "Iter: 97/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1126.6383056640625 lr: 0.00031623\n",
      "Iter: 98/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1043.50537109375 lr: 0.00031623\n",
      "Iter: 99/695, loss_train: 5.7531, loss_val: nan, pos_over_neg: 1230.7928466796875 lr: 0.00031623\n",
      "Iter: 100/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1409.4927978515625 lr: 0.00031623\n",
      "Iter: 101/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 2580.7802734375 lr: 0.00031623\n",
      "Iter: 102/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 2057.923095703125 lr: 0.00031623\n",
      "Iter: 103/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1000.2311401367188 lr: 0.00031623\n",
      "Iter: 104/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 1128.435302734375 lr: 0.00031623\n",
      "Iter: 105/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 1819.144287109375 lr: 0.00031623\n",
      "Iter: 106/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 6265.400390625 lr: 0.00031623\n",
      "Iter: 107/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 988.9352416992188 lr: 0.00031623\n",
      "Iter: 108/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1186.10498046875 lr: 0.00031623\n",
      "Iter: 109/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 559.246826171875 lr: 0.00031623\n",
      "Iter: 110/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 2469.298095703125 lr: 0.00031623\n",
      "Iter: 111/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 2101.342041015625 lr: 0.00031623\n",
      "Iter: 112/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 511.15277099609375 lr: 0.00031623\n",
      "Iter: 113/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 641.7147827148438 lr: 0.00031623\n",
      "Iter: 114/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 1001.3436279296875 lr: 0.00031623\n",
      "Iter: 115/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1660.8568115234375 lr: 0.00031623\n",
      "Iter: 116/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1146.752685546875 lr: 0.00031623\n",
      "Iter: 117/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1079.03173828125 lr: 0.00031623\n",
      "Iter: 118/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 839.7098999023438 lr: 0.00031623\n",
      "Iter: 119/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 1418.2762451171875 lr: 0.00031623\n",
      "Iter: 120/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1172.154052734375 lr: 0.00031623\n",
      "Iter: 121/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1229.1153564453125 lr: 0.00031623\n",
      "Iter: 122/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1259.2371826171875 lr: 0.00031623\n",
      "Iter: 123/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1046.44189453125 lr: 0.00031623\n",
      "Iter: 124/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1176.342041015625 lr: 0.00031623\n",
      "Iter: 125/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 859.1194458007812 lr: 0.00031623\n",
      "Iter: 126/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1010.8826293945312 lr: 0.00031623\n",
      "Iter: 127/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 647.27392578125 lr: 0.00031623\n",
      "Iter: 128/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 610.801513671875 lr: 0.00031623\n",
      "Iter: 129/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 837.4481201171875 lr: 0.00031623\n",
      "Iter: 130/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 930.6107177734375 lr: 0.00031623\n",
      "Iter: 131/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 725.1723022460938 lr: 0.00031623\n",
      "Iter: 132/695, loss_train: 5.7548, loss_val: nan, pos_over_neg: 890.2251586914062 lr: 0.00031623\n",
      "Iter: 133/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 550.9617309570312 lr: 0.00031623\n",
      "Iter: 134/695, loss_train: 5.752, loss_val: nan, pos_over_neg: 792.3152465820312 lr: 0.00031623\n",
      "Iter: 135/695, loss_train: 5.7559, loss_val: nan, pos_over_neg: 574.1099853515625 lr: 0.00031623\n",
      "Iter: 136/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 969.6693725585938 lr: 0.00031623\n",
      "Iter: 137/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1151.75390625 lr: 0.00031623\n",
      "Iter: 138/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 702.9744262695312 lr: 0.00031623\n",
      "Iter: 139/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 654.8008422851562 lr: 0.00031623\n",
      "Iter: 140/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 795.0962524414062 lr: 0.00031623\n",
      "Iter: 141/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 994.4910278320312 lr: 0.00031623\n",
      "Iter: 142/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1067.529296875 lr: 0.00031623\n",
      "Iter: 143/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1747.6199951171875 lr: 0.00031623\n",
      "Iter: 144/695, loss_train: 5.7543, loss_val: nan, pos_over_neg: 1308.9154052734375 lr: 0.00031623\n",
      "Iter: 145/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 919.4649658203125 lr: 0.00031623\n",
      "Iter: 146/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 677.5281372070312 lr: 0.00031623\n",
      "Iter: 147/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1563.6258544921875 lr: 0.00031623\n",
      "Iter: 148/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1813.0758056640625 lr: 0.00031623\n",
      "Iter: 149/695, loss_train: 5.7558, loss_val: nan, pos_over_neg: 880.3777465820312 lr: 0.00031623\n",
      "Iter: 150/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1093.859375 lr: 0.00031623\n",
      "Iter: 151/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1183.4884033203125 lr: 0.00031623\n",
      "Iter: 152/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1440.2100830078125 lr: 0.00031623\n",
      "Iter: 153/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1360.3311767578125 lr: 0.00031623\n",
      "Iter: 154/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 643.670654296875 lr: 0.00031623\n",
      "Iter: 155/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 981.0443725585938 lr: 0.00031623\n",
      "Iter: 156/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1029.24658203125 lr: 0.00031623\n",
      "Iter: 157/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1210.1591796875 lr: 0.00031623\n",
      "Iter: 158/695, loss_train: 5.7513, loss_val: nan, pos_over_neg: 1258.803955078125 lr: 0.00031623\n",
      "Iter: 159/695, loss_train: 5.7529, loss_val: nan, pos_over_neg: 967.8684692382812 lr: 0.00031623\n",
      "Iter: 160/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1188.004638671875 lr: 0.00031623\n",
      "Iter: 161/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1693.9444580078125 lr: 0.00031623\n",
      "Iter: 162/695, loss_train: 5.7518, loss_val: nan, pos_over_neg: 1039.8704833984375 lr: 0.00031623\n",
      "Iter: 163/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1090.7056884765625 lr: 0.00031623\n",
      "Iter: 164/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 708.3568115234375 lr: 0.00031623\n",
      "Iter: 165/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1860.313232421875 lr: 0.00031623\n",
      "Iter: 166/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1910.4874267578125 lr: 0.00031623\n",
      "Iter: 167/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1018.167236328125 lr: 0.00031623\n",
      "Iter: 168/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1136.5736083984375 lr: 0.00031623\n",
      "Iter: 169/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 816.4346313476562 lr: 0.00031623\n",
      "Iter: 170/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1242.531005859375 lr: 0.00031623\n",
      "Iter: 171/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 2530.041748046875 lr: 0.00031623\n",
      "Iter: 172/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 3381.978759765625 lr: 0.00031623\n",
      "Iter: 173/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 2446.279296875 lr: 0.00031623\n",
      "Iter: 174/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 1311.453369140625 lr: 0.00031623\n",
      "Iter: 175/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 817.5034790039062 lr: 0.00031623\n",
      "Iter: 176/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1857.239501953125 lr: 0.00031623\n",
      "Iter: 177/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 2416.140625 lr: 0.00031623\n",
      "Iter: 178/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 3569.79833984375 lr: 0.00031623\n",
      "Iter: 179/695, loss_train: 5.7535, loss_val: nan, pos_over_neg: 690.5856323242188 lr: 0.00031623\n",
      "Iter: 180/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 1198.0804443359375 lr: 0.00031623\n",
      "Iter: 181/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 1231.8543701171875 lr: 0.00031623\n",
      "Iter: 182/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1802.7158203125 lr: 0.00031623\n",
      "Iter: 183/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 652.3994750976562 lr: 0.00031623\n",
      "Iter: 184/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 2926.40478515625 lr: 0.00031623\n",
      "Iter: 185/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 2655.958984375 lr: 0.00031623\n",
      "Iter: 186/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1725.454345703125 lr: 0.00031623\n",
      "Iter: 187/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1687.0921630859375 lr: 0.00031623\n",
      "Iter: 188/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1133.28662109375 lr: 0.00031623\n",
      "Iter: 189/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1910.5267333984375 lr: 0.00031623\n",
      "Iter: 190/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 2098.416015625 lr: 0.00031623\n",
      "Iter: 191/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1664.010498046875 lr: 0.00031623\n",
      "Iter: 192/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1273.614501953125 lr: 0.00031623\n",
      "Iter: 193/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1622.5206298828125 lr: 0.00031623\n",
      "Iter: 194/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1255.9898681640625 lr: 0.00031623\n",
      "Iter: 195/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 909.9005737304688 lr: 0.00031623\n",
      "Iter: 196/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 1132.660888671875 lr: 0.00031623\n",
      "Iter: 197/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1074.591796875 lr: 0.00031623\n",
      "Iter: 198/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1125.691650390625 lr: 0.00031623\n",
      "Iter: 199/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1054.3905029296875 lr: 0.00031623\n",
      "Iter: 200/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 788.1627197265625 lr: 0.00031623\n",
      "Iter: 201/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 855.8720703125 lr: 0.00031623\n",
      "Iter: 202/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 529.47216796875 lr: 0.00031623\n",
      "Iter: 203/695, loss_train: 5.7546, loss_val: nan, pos_over_neg: 1827.8206787109375 lr: 0.00031623\n",
      "Iter: 204/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1091.588134765625 lr: 0.00031623\n",
      "Iter: 205/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1355.0775146484375 lr: 0.00031623\n",
      "Iter: 206/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 965.9808959960938 lr: 0.00031623\n",
      "Iter: 207/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: 1503.344482421875 lr: 0.00031623\n",
      "Iter: 208/695, loss_train: 5.7547, loss_val: nan, pos_over_neg: 1987.19384765625 lr: 0.00031623\n",
      "Iter: 209/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 1387.4324951171875 lr: 0.00031623\n",
      "Iter: 210/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1288.1785888671875 lr: 0.00031623\n",
      "Iter: 211/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1033.494384765625 lr: 0.00031623\n",
      "Iter: 212/695, loss_train: 5.7392, loss_val: nan, pos_over_neg: 1291.154052734375 lr: 0.00031623\n",
      "Iter: 213/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1206.392822265625 lr: 0.00031623\n",
      "Iter: 214/695, loss_train: 5.7536, loss_val: nan, pos_over_neg: 1123.28515625 lr: 0.00031623\n",
      "Iter: 215/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1096.368408203125 lr: 0.00031623\n",
      "Iter: 216/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 718.5955810546875 lr: 0.00031623\n",
      "Iter: 217/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 680.220947265625 lr: 0.00031623\n",
      "Iter: 218/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1365.9434814453125 lr: 0.00031623\n",
      "Iter: 219/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 1383.3704833984375 lr: 0.00031623\n",
      "Iter: 220/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1108.9774169921875 lr: 0.00031623\n",
      "Iter: 221/695, loss_train: 5.7578, loss_val: nan, pos_over_neg: 1678.895751953125 lr: 0.00031623\n",
      "Iter: 222/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 1033.607421875 lr: 0.00031623\n",
      "Iter: 223/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 3230.1435546875 lr: 0.00031623\n",
      "Iter: 224/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 2117.78125 lr: 0.00031623\n",
      "Iter: 225/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1175.6103515625 lr: 0.00031623\n",
      "Iter: 226/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 678.1357421875 lr: 0.00031623\n",
      "Iter: 227/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 3268.280517578125 lr: 0.00031623\n",
      "Iter: 228/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1223.6334228515625 lr: 0.00031623\n",
      "Iter: 229/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 1291.7864990234375 lr: 0.00031623\n",
      "Iter: 230/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1764.8572998046875 lr: 0.00031623\n",
      "Iter: 231/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2212.676513671875 lr: 0.00031623\n",
      "Iter: 232/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1760.18896484375 lr: 0.00031623\n",
      "Iter: 233/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1576.77294921875 lr: 0.00031623\n",
      "Iter: 234/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1403.4908447265625 lr: 0.00031623\n",
      "Iter: 235/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1778.8897705078125 lr: 0.00031623\n",
      "Iter: 236/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 721.4906616210938 lr: 0.00031623\n",
      "Iter: 237/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 2319.78955078125 lr: 0.00031623\n",
      "Iter: 238/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 985.6204223632812 lr: 0.00031623\n",
      "Iter: 239/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 1071.0579833984375 lr: 0.00031623\n",
      "Iter: 240/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 987.6754760742188 lr: 0.00031623\n",
      "Iter: 241/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 752.1749267578125 lr: 0.00031623\n",
      "Iter: 242/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 993.0816650390625 lr: 0.00031623\n",
      "Iter: 243/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1250.056396484375 lr: 0.00031623\n",
      "Iter: 244/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1425.8221435546875 lr: 0.00031623\n",
      "Iter: 245/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 1574.7413330078125 lr: 0.00031623\n",
      "Iter: 246/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1741.2462158203125 lr: 0.00031623\n",
      "Iter: 247/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1199.3494873046875 lr: 0.00031623\n",
      "Iter: 248/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 1158.5087890625 lr: 0.00031623\n",
      "Iter: 249/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 3876.121826171875 lr: 0.00031623\n",
      "Iter: 250/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 685.01806640625 lr: 0.00031623\n",
      "Iter: 251/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1399.1851806640625 lr: 0.00031623\n",
      "Iter: 252/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 761.878173828125 lr: 0.00031623\n",
      "Iter: 253/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 881.7431030273438 lr: 0.00031623\n",
      "Iter: 254/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1291.5455322265625 lr: 0.00031623\n",
      "Iter: 255/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1300.5845947265625 lr: 0.00031623\n",
      "Iter: 256/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1282.3978271484375 lr: 0.00031623\n",
      "Iter: 257/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1180.1160888671875 lr: 0.00031623\n",
      "Iter: 258/695, loss_train: 5.7563, loss_val: nan, pos_over_neg: 522.1754150390625 lr: 0.00031623\n",
      "Iter: 259/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 4196.96142578125 lr: 0.00031623\n",
      "Iter: 260/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1238.261474609375 lr: 0.00031623\n",
      "Iter: 261/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1033.1409912109375 lr: 0.00031623\n",
      "Iter: 262/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1000.2443237304688 lr: 0.00031623\n",
      "Iter: 263/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1696.7515869140625 lr: 0.00031623\n",
      "Iter: 264/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1861.95654296875 lr: 0.00031623\n",
      "Iter: 265/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 924.6527099609375 lr: 0.00031623\n",
      "Iter: 266/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 1399.309326171875 lr: 0.00031623\n",
      "Iter: 267/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 776.5697631835938 lr: 0.00031623\n",
      "Iter: 268/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 2321.448974609375 lr: 0.00031623\n",
      "Iter: 269/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 689.24462890625 lr: 0.00031623\n",
      "Iter: 270/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1125.7879638671875 lr: 0.00031623\n",
      "Iter: 271/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 1366.620361328125 lr: 0.00031623\n",
      "Iter: 272/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1820.5750732421875 lr: 0.00031623\n",
      "Iter: 273/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 3429.855224609375 lr: 0.00031623\n",
      "Iter: 274/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 837.70166015625 lr: 0.00031623\n",
      "Iter: 275/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 498.9585876464844 lr: 0.00031623\n",
      "Iter: 276/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1025.916259765625 lr: 0.00031623\n",
      "Iter: 277/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 928.28759765625 lr: 0.00031623\n",
      "Iter: 278/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 777.9574584960938 lr: 0.00031623\n",
      "Iter: 279/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 922.88916015625 lr: 0.00031623\n",
      "Iter: 280/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 760.551513671875 lr: 0.00031623\n",
      "Iter: 281/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1009.9031982421875 lr: 0.00031623\n",
      "Iter: 282/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1168.7525634765625 lr: 0.00031623\n",
      "Iter: 283/695, loss_train: 5.7412, loss_val: nan, pos_over_neg: 1509.0380859375 lr: 0.00031623\n",
      "Iter: 284/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1142.1456298828125 lr: 0.00031623\n",
      "Iter: 285/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1143.7451171875 lr: 0.00031623\n",
      "Iter: 286/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1313.9261474609375 lr: 0.00031623\n",
      "Iter: 287/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1173.4061279296875 lr: 0.00031623\n",
      "Iter: 288/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1005.0529174804688 lr: 0.00031623\n",
      "Iter: 289/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1305.9427490234375 lr: 0.00031623\n",
      "Iter: 290/695, loss_train: 5.7394, loss_val: nan, pos_over_neg: 1870.9940185546875 lr: 0.00031623\n",
      "Iter: 291/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 2172.596435546875 lr: 0.00031623\n",
      "Iter: 292/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 1962.4312744140625 lr: 0.00031623\n",
      "Iter: 293/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1550.4197998046875 lr: 0.00031623\n",
      "Iter: 294/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1207.8560791015625 lr: 0.00031623\n",
      "Iter: 295/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 3413.81787109375 lr: 0.00031623\n",
      "Iter: 296/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 2154.78076171875 lr: 0.00031623\n",
      "Iter: 297/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1677.0145263671875 lr: 0.00031623\n",
      "Iter: 298/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1530.1912841796875 lr: 0.00031623\n",
      "Iter: 299/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1135.5980224609375 lr: 0.00031623\n",
      "Iter: 300/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1319.221923828125 lr: 0.00031623\n",
      "Iter: 301/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 981.7310180664062 lr: 0.00031623\n",
      "Iter: 302/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1687.0010986328125 lr: 0.00031623\n",
      "Iter: 303/695, loss_train: 5.7532, loss_val: nan, pos_over_neg: 1376.3028564453125 lr: 0.00031623\n",
      "Iter: 304/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1134.3824462890625 lr: 0.00031623\n",
      "Iter: 305/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 3328.665771484375 lr: 0.00031623\n",
      "Iter: 306/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1286.95751953125 lr: 0.00031623\n",
      "Iter: 307/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 3651.3095703125 lr: 0.00031623\n",
      "Iter: 308/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1210.2515869140625 lr: 0.00031623\n",
      "Iter: 309/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1997.81005859375 lr: 0.00031623\n",
      "Iter: 310/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 926.1343994140625 lr: 0.00031623\n",
      "Iter: 311/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 1136.414306640625 lr: 0.00031623\n",
      "Iter: 312/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 995.5890502929688 lr: 0.00031623\n",
      "Iter: 313/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 3033.210205078125 lr: 0.00031623\n",
      "Iter: 314/695, loss_train: 5.7428, loss_val: nan, pos_over_neg: 2376.716552734375 lr: 0.00031623\n",
      "Iter: 315/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1297.7322998046875 lr: 0.00031623\n",
      "Iter: 316/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 2122.843994140625 lr: 0.00031623\n",
      "Iter: 317/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1136.803466796875 lr: 0.00031623\n",
      "Iter: 318/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 1431.272705078125 lr: 0.00031623\n",
      "Iter: 319/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 1733.5263671875 lr: 0.00031623\n",
      "Iter: 320/695, loss_train: 5.7534, loss_val: nan, pos_over_neg: 573.38134765625 lr: 0.00031623\n",
      "Iter: 321/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 2213.728759765625 lr: 0.00031623\n",
      "Iter: 322/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1133.8990478515625 lr: 0.00031623\n",
      "Iter: 323/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1034.6912841796875 lr: 0.00031623\n",
      "Iter: 324/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 845.4024658203125 lr: 0.00031623\n",
      "Iter: 325/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 835.2683715820312 lr: 0.00031623\n",
      "Iter: 326/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1317.917724609375 lr: 0.00031623\n",
      "Iter: 327/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1031.63525390625 lr: 0.00031623\n",
      "Iter: 328/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 971.9782104492188 lr: 0.00031623\n",
      "Iter: 329/695, loss_train: 5.7562, loss_val: nan, pos_over_neg: 632.5833740234375 lr: 0.00031623\n",
      "Iter: 330/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 710.6508178710938 lr: 0.00031623\n",
      "Iter: 331/695, loss_train: 5.7585, loss_val: nan, pos_over_neg: 733.7684326171875 lr: 0.00031623\n",
      "Iter: 332/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1204.3463134765625 lr: 0.00031623\n",
      "Iter: 333/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 913.5250244140625 lr: 0.00031623\n",
      "Iter: 334/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 956.595703125 lr: 0.00031623\n",
      "Iter: 335/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1203.530029296875 lr: 0.00031623\n",
      "Iter: 336/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1464.4520263671875 lr: 0.00031623\n",
      "Iter: 337/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1109.2244873046875 lr: 0.00031623\n",
      "Iter: 338/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1430.478515625 lr: 0.00031623\n",
      "Iter: 339/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 591.9285278320312 lr: 0.00031623\n",
      "Iter: 340/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1290.609130859375 lr: 0.00031623\n",
      "Iter: 341/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1330.9232177734375 lr: 0.00031623\n",
      "Iter: 342/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1287.4600830078125 lr: 0.00031623\n",
      "Iter: 343/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1118.40380859375 lr: 0.00031623\n",
      "Iter: 344/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 1999.8502197265625 lr: 0.00031623\n",
      "Iter: 345/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 3446.823974609375 lr: 0.00031623\n",
      "Iter: 346/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 1199.9554443359375 lr: 0.00031623\n",
      "Iter: 347/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 1159.249755859375 lr: 0.00031623\n",
      "Iter: 348/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1093.2054443359375 lr: 0.00031623\n",
      "Iter: 349/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 4357.49462890625 lr: 0.00031623\n",
      "Iter: 350/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 3108.586181640625 lr: 0.00031623\n",
      "Iter: 351/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 2307.6083984375 lr: 0.00031623\n",
      "Iter: 352/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 954.2706298828125 lr: 0.00031623\n",
      "Iter: 353/695, loss_train: 5.7509, loss_val: nan, pos_over_neg: 1261.3714599609375 lr: 0.00031623\n",
      "Iter: 354/695, loss_train: 5.7514, loss_val: nan, pos_over_neg: 3598.26708984375 lr: 0.00031623\n",
      "Iter: 355/695, loss_train: 5.743, loss_val: nan, pos_over_neg: 2719.943359375 lr: 0.00031623\n",
      "Iter: 356/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 2456.0751953125 lr: 0.00031623\n",
      "Iter: 357/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 2904.4111328125 lr: 0.00031623\n",
      "Iter: 358/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 3022.9833984375 lr: 0.00031623\n",
      "Iter: 359/695, loss_train: 5.7522, loss_val: nan, pos_over_neg: 1752.6373291015625 lr: 0.00031623\n",
      "Iter: 360/695, loss_train: 5.7568, loss_val: nan, pos_over_neg: 2347.84033203125 lr: 0.00031623\n",
      "Iter: 361/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1777.4698486328125 lr: 0.00031623\n",
      "Iter: 362/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 2887.07177734375 lr: 0.00031623\n",
      "Iter: 363/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1158.088623046875 lr: 0.00031623\n",
      "Iter: 364/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: 1653.2060546875 lr: 0.00031623\n",
      "Iter: 365/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1051.6297607421875 lr: 0.00031623\n",
      "Iter: 366/695, loss_train: 5.7517, loss_val: nan, pos_over_neg: 627.9974365234375 lr: 0.00031623\n",
      "Iter: 367/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 878.9954223632812 lr: 0.00031623\n",
      "Iter: 368/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 6769.888671875 lr: 0.00031623\n",
      "Iter: 369/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 1590.0240478515625 lr: 0.00031623\n",
      "Iter: 370/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1979.4793701171875 lr: 0.00031623\n",
      "Iter: 371/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 897.8546752929688 lr: 0.00031623\n",
      "Iter: 372/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 1973.1136474609375 lr: 0.00031623\n",
      "Iter: 373/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 826.2766723632812 lr: 0.00031623\n",
      "Iter: 374/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 1817.3192138671875 lr: 0.00031623\n",
      "Iter: 375/695, loss_train: 5.7496, loss_val: nan, pos_over_neg: 1321.0703125 lr: 0.00031623\n",
      "Iter: 376/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 3201.348876953125 lr: 0.00031623\n",
      "Iter: 377/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 745.7026977539062 lr: 0.00031623\n",
      "Iter: 378/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 2124.51171875 lr: 0.00031623\n",
      "Iter: 379/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 933.6627807617188 lr: 0.00031623\n",
      "Iter: 380/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 1130.922119140625 lr: 0.00031623\n",
      "Iter: 381/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 2835.873779296875 lr: 0.00031623\n",
      "Iter: 382/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1185.8607177734375 lr: 0.00031623\n",
      "Iter: 383/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 2284.4267578125 lr: 0.00031623\n",
      "Iter: 384/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1593.4508056640625 lr: 0.00031623\n",
      "Iter: 385/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 5185.27197265625 lr: 0.00031623\n",
      "Iter: 386/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1802.8572998046875 lr: 0.00031623\n",
      "Iter: 387/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1363.144287109375 lr: 0.00031623\n",
      "Iter: 388/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 1727.2772216796875 lr: 0.00031623\n",
      "Iter: 389/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 3541.171875 lr: 0.00031623\n",
      "Iter: 390/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1373.7470703125 lr: 0.00031623\n",
      "Iter: 391/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 1271.699462890625 lr: 0.00031623\n",
      "Iter: 392/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1378.879638671875 lr: 0.00031623\n",
      "Iter: 393/695, loss_train: 5.7383, loss_val: nan, pos_over_neg: 3081.9287109375 lr: 0.00031623\n",
      "Iter: 394/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 3301.829833984375 lr: 0.00031623\n",
      "Iter: 395/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1070.0792236328125 lr: 0.00031623\n",
      "Iter: 396/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1978.8662109375 lr: 0.00031623\n",
      "Iter: 397/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 1197.26904296875 lr: 0.00031623\n",
      "Iter: 398/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 1164.1552734375 lr: 0.00031623\n",
      "Iter: 399/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 2020.9102783203125 lr: 0.00031623\n",
      "Iter: 400/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2328.543212890625 lr: 0.00031623\n",
      "Iter: 401/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 2652.0830078125 lr: 0.00031623\n",
      "Iter: 402/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 2501.284912109375 lr: 0.00031623\n",
      "Iter: 403/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1236.5003662109375 lr: 0.00031623\n",
      "Iter: 404/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 1267.4173583984375 lr: 0.00031623\n",
      "Iter: 405/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 23123.572265625 lr: 0.00031623\n",
      "Iter: 406/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 10397.1474609375 lr: 0.00031623\n",
      "Iter: 407/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 2762.13720703125 lr: 0.00031623\n",
      "Iter: 408/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1747.3636474609375 lr: 0.00031623\n",
      "Iter: 409/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 570.3499145507812 lr: 0.00031623\n",
      "Iter: 410/695, loss_train: 5.7505, loss_val: nan, pos_over_neg: 1318.691650390625 lr: 0.00031623\n",
      "Iter: 411/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 4149.30517578125 lr: 0.00031623\n",
      "Iter: 412/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1509.805419921875 lr: 0.00031623\n",
      "Iter: 413/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1093.367431640625 lr: 0.00031623\n",
      "Iter: 414/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 3277.897216796875 lr: 0.00031623\n",
      "Iter: 415/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 2594.083984375 lr: 0.00031623\n",
      "Iter: 416/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1147.607177734375 lr: 0.00031623\n",
      "Iter: 417/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 1339.988037109375 lr: 0.00031623\n",
      "Iter: 418/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 1332.7415771484375 lr: 0.00031623\n",
      "Iter: 419/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1193.538818359375 lr: 0.00031623\n",
      "Iter: 420/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1236.002685546875 lr: 0.00031623\n",
      "Iter: 421/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 525.57861328125 lr: 0.00031623\n",
      "Iter: 422/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1241.3790283203125 lr: 0.00031623\n",
      "Iter: 423/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 2049.269775390625 lr: 0.00031623\n",
      "Iter: 424/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 13122.5625 lr: 0.00031623\n",
      "Iter: 425/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1991.8585205078125 lr: 0.00031623\n",
      "Iter: 426/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 640.5835571289062 lr: 0.00031623\n",
      "Iter: 427/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 2419.876220703125 lr: 0.00031623\n",
      "Iter: 428/695, loss_train: 5.7506, loss_val: nan, pos_over_neg: 2059.882568359375 lr: 0.00031623\n",
      "Iter: 429/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 1719.21435546875 lr: 0.00031623\n",
      "Iter: 430/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1280.0469970703125 lr: 0.00031623\n",
      "Iter: 431/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 2248.47314453125 lr: 0.00031623\n",
      "Iter: 432/695, loss_train: 5.7555, loss_val: nan, pos_over_neg: 999.8804931640625 lr: 0.00031623\n",
      "Iter: 433/695, loss_train: 5.7396, loss_val: nan, pos_over_neg: 867.9155883789062 lr: 0.00031623\n",
      "Iter: 434/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1184.097900390625 lr: 0.00031623\n",
      "Iter: 435/695, loss_train: 5.7442, loss_val: nan, pos_over_neg: 1816.1724853515625 lr: 0.00031623\n",
      "Iter: 436/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 3982.051513671875 lr: 0.00031623\n",
      "Iter: 437/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 2501.347412109375 lr: 0.00031623\n",
      "Iter: 438/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 1726.2242431640625 lr: 0.00031623\n",
      "Iter: 439/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 835.2611694335938 lr: 0.00031623\n",
      "Iter: 440/695, loss_train: 5.7511, loss_val: nan, pos_over_neg: 962.2510986328125 lr: 0.00031623\n",
      "Iter: 441/695, loss_train: 5.744, loss_val: nan, pos_over_neg: -28985.533203125 lr: 0.00031623\n",
      "Iter: 442/695, loss_train: 5.7456, loss_val: nan, pos_over_neg: 3072.548583984375 lr: 0.00031623\n",
      "Iter: 443/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 1241.9239501953125 lr: 0.00031623\n",
      "Iter: 444/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1104.9920654296875 lr: 0.00031623\n",
      "Iter: 445/695, loss_train: 5.7499, loss_val: nan, pos_over_neg: 953.46875 lr: 0.00031623\n",
      "Iter: 446/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 5451.51220703125 lr: 0.00031623\n",
      "Iter: 447/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 2260.523681640625 lr: 0.00031623\n",
      "Iter: 448/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 1168.4169921875 lr: 0.00031623\n",
      "Iter: 449/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1371.0303955078125 lr: 0.00031623\n",
      "Iter: 450/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 937.0829467773438 lr: 0.00031623\n",
      "Iter: 451/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: 2116.191162109375 lr: 0.00031623\n",
      "Iter: 452/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1090.736572265625 lr: 0.00031623\n",
      "Iter: 453/695, loss_train: 5.7428, loss_val: nan, pos_over_neg: 4149.68408203125 lr: 0.00031623\n",
      "Iter: 454/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 2041.236572265625 lr: 0.00031623\n",
      "Iter: 455/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 2450.353271484375 lr: 0.00031623\n",
      "Iter: 456/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 647.88525390625 lr: 0.00031623\n",
      "Iter: 457/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1029.5111083984375 lr: 0.00031623\n",
      "Iter: 458/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1300.950439453125 lr: 0.00031623\n",
      "Iter: 459/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 2169.366455078125 lr: 0.00031623\n",
      "Iter: 460/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1694.9852294921875 lr: 0.00031623\n",
      "Iter: 461/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 3301.650390625 lr: 0.00031623\n",
      "Iter: 462/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 855.1409301757812 lr: 0.00031623\n",
      "Iter: 463/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1299.0128173828125 lr: 0.00031623\n",
      "Iter: 464/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1240.9249267578125 lr: 0.00031623\n",
      "Iter: 465/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 1005.9697875976562 lr: 0.00031623\n",
      "Iter: 466/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 976.4590454101562 lr: 0.00031623\n",
      "Iter: 467/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1212.7718505859375 lr: 0.00031623\n",
      "Iter: 468/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1147.69091796875 lr: 0.00031623\n",
      "Iter: 469/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 983.9713134765625 lr: 0.00031623\n",
      "Iter: 470/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 691.5484008789062 lr: 0.00031623\n",
      "Iter: 471/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 819.4492797851562 lr: 0.00031623\n",
      "Iter: 472/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 2883.126708984375 lr: 0.00031623\n",
      "Iter: 473/695, loss_train: 5.7521, loss_val: nan, pos_over_neg: 1004.6107788085938 lr: 0.00031623\n",
      "Iter: 474/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 976.526611328125 lr: 0.00031623\n",
      "Iter: 475/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 1334.65576171875 lr: 0.00031623\n",
      "Iter: 476/695, loss_train: 5.7393, loss_val: nan, pos_over_neg: 1320.9710693359375 lr: 0.00031623\n",
      "Iter: 477/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1778.78076171875 lr: 0.00031623\n",
      "Iter: 478/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 1636.535400390625 lr: 0.00031623\n",
      "Iter: 479/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1179.2197265625 lr: 0.00031623\n",
      "Iter: 480/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 1138.1748046875 lr: 0.00031623\n",
      "Iter: 481/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1884.4405517578125 lr: 0.00031623\n",
      "Iter: 482/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 5739.78955078125 lr: 0.00031623\n",
      "Iter: 483/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 2734.96142578125 lr: 0.00031623\n",
      "Iter: 484/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 1103.448486328125 lr: 0.00031623\n",
      "Iter: 485/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 1295.0419921875 lr: 0.00031623\n",
      "Iter: 486/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 1330.4884033203125 lr: 0.00031623\n",
      "Iter: 487/695, loss_train: 5.741, loss_val: nan, pos_over_neg: 1746.82470703125 lr: 0.00031623\n",
      "Iter: 488/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 757.4761352539062 lr: 0.00031623\n",
      "Iter: 489/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 839.43212890625 lr: 0.00031623\n",
      "Iter: 490/695, loss_train: 5.7397, loss_val: nan, pos_over_neg: 2893.10986328125 lr: 0.00031623\n",
      "Iter: 491/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 2128.091796875 lr: 0.00031623\n",
      "Iter: 492/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1150.4658203125 lr: 0.00031623\n",
      "Iter: 493/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 1452.9736328125 lr: 0.00031623\n",
      "Iter: 494/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 979.97021484375 lr: 0.00031623\n",
      "Iter: 495/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 2182.652587890625 lr: 0.00031623\n",
      "Iter: 496/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1321.5858154296875 lr: 0.00031623\n",
      "Iter: 497/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1002.6881713867188 lr: 0.00031623\n",
      "Iter: 498/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 1694.27587890625 lr: 0.00031623\n",
      "Iter: 499/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1119.5335693359375 lr: 0.00031623\n",
      "Iter: 500/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1346.3876953125 lr: 0.00031623\n",
      "Iter: 501/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 922.9098510742188 lr: 0.00031623\n",
      "Iter: 502/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 2772.256591796875 lr: 0.00031623\n",
      "Iter: 503/695, loss_train: 5.7433, loss_val: nan, pos_over_neg: 1598.8228759765625 lr: 0.00031623\n",
      "Iter: 504/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1467.8709716796875 lr: 0.00031623\n",
      "Iter: 505/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 1063.5008544921875 lr: 0.00031623\n",
      "Iter: 506/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 5444.09228515625 lr: 0.00031623\n",
      "Iter: 507/695, loss_train: 5.7479, loss_val: nan, pos_over_neg: -3030.15625 lr: 0.00031623\n",
      "Iter: 508/695, loss_train: 5.7552, loss_val: nan, pos_over_neg: 2375.455322265625 lr: 0.00031623\n",
      "Iter: 509/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1411.583251953125 lr: 0.00031623\n",
      "Iter: 510/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 677.4754638671875 lr: 0.00031623\n",
      "Iter: 511/695, loss_train: 5.7438, loss_val: nan, pos_over_neg: 2853.152587890625 lr: 0.00031623\n",
      "Iter: 512/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 747.1361083984375 lr: 0.00031623\n",
      "Iter: 513/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1238.72705078125 lr: 0.00031623\n",
      "Iter: 514/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 934.8794555664062 lr: 0.00031623\n",
      "Iter: 515/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1406.2413330078125 lr: 0.00031623\n",
      "Iter: 516/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 841.789306640625 lr: 0.00031623\n",
      "Iter: 517/695, loss_train: 5.7395, loss_val: nan, pos_over_neg: 1556.4833984375 lr: 0.00031623\n",
      "Iter: 518/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1320.10009765625 lr: 0.00031623\n",
      "Iter: 519/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 3194.166015625 lr: 0.00031623\n",
      "Iter: 520/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1939.068115234375 lr: 0.00031623\n",
      "Iter: 521/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 2307.256103515625 lr: 0.00031623\n",
      "Iter: 522/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 2460.00439453125 lr: 0.00031623\n",
      "Iter: 523/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 926.578125 lr: 0.00031623\n",
      "Iter: 524/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1210.0213623046875 lr: 0.00031623\n",
      "Iter: 525/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1455.906494140625 lr: 0.00031623\n",
      "Iter: 526/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 2154.030029296875 lr: 0.00031623\n",
      "Iter: 527/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1776.940185546875 lr: 0.00031623\n",
      "Iter: 528/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1131.6153564453125 lr: 0.00031623\n",
      "Iter: 529/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 1832.647216796875 lr: 0.00031623\n",
      "Iter: 530/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 1140.342041015625 lr: 0.00031623\n",
      "Iter: 531/695, loss_train: 5.7525, loss_val: nan, pos_over_neg: 2119.565673828125 lr: 0.00031623\n",
      "Iter: 532/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 1254.8841552734375 lr: 0.00031623\n",
      "Iter: 533/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1722.4351806640625 lr: 0.00031623\n",
      "Iter: 534/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1727.9735107421875 lr: 0.00031623\n",
      "Iter: 535/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 1373.0146484375 lr: 0.00031623\n",
      "Iter: 536/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 809.1121215820312 lr: 0.00031623\n",
      "Iter: 537/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1210.4056396484375 lr: 0.00031623\n",
      "Iter: 538/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 6385.49853515625 lr: 0.00031623\n",
      "Iter: 539/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 1387.5330810546875 lr: 0.00031623\n",
      "Iter: 540/695, loss_train: 5.7489, loss_val: nan, pos_over_neg: 1523.7056884765625 lr: 0.00031623\n",
      "Iter: 541/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1240.9208984375 lr: 0.00031623\n",
      "Iter: 542/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1722.690185546875 lr: 0.00031623\n",
      "Iter: 543/695, loss_train: 5.7488, loss_val: nan, pos_over_neg: 1931.1737060546875 lr: 0.00031623\n",
      "Iter: 544/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 1639.5166015625 lr: 0.00031623\n",
      "Iter: 545/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 1234.52392578125 lr: 0.00031623\n",
      "Iter: 546/695, loss_train: 5.7429, loss_val: nan, pos_over_neg: 1149.5343017578125 lr: 0.00031623\n",
      "Iter: 547/695, loss_train: 5.748, loss_val: nan, pos_over_neg: 1187.096435546875 lr: 0.00031623\n",
      "Iter: 548/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 3270.598388671875 lr: 0.00031623\n",
      "Iter: 549/695, loss_train: 5.7392, loss_val: nan, pos_over_neg: 1972.300537109375 lr: 0.00031623\n",
      "Iter: 550/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 563.2391967773438 lr: 0.00031623\n",
      "Iter: 551/695, loss_train: 5.7451, loss_val: nan, pos_over_neg: 778.1829833984375 lr: 0.00031623\n",
      "Iter: 552/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 998.2021484375 lr: 0.00031623\n",
      "Iter: 553/695, loss_train: 5.7443, loss_val: nan, pos_over_neg: 1945.10595703125 lr: 0.00031623\n",
      "Iter: 554/695, loss_train: 5.7399, loss_val: nan, pos_over_neg: 2736.73046875 lr: 0.00031623\n",
      "Iter: 555/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1199.402587890625 lr: 0.00031623\n",
      "Iter: 556/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1362.618896484375 lr: 0.00031623\n",
      "Iter: 557/695, loss_train: 5.7484, loss_val: nan, pos_over_neg: 1153.3529052734375 lr: 0.00031623\n",
      "Iter: 558/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1029.5343017578125 lr: 0.00031623\n",
      "Iter: 559/695, loss_train: 5.7523, loss_val: nan, pos_over_neg: 695.9781494140625 lr: 0.00031623\n",
      "Iter: 560/695, loss_train: 5.7406, loss_val: nan, pos_over_neg: 1674.6605224609375 lr: 0.00031623\n",
      "Iter: 561/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 700.1084594726562 lr: 0.00031623\n",
      "Iter: 562/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 622.8894653320312 lr: 0.00031623\n",
      "Iter: 563/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1141.2105712890625 lr: 0.00031623\n",
      "Iter: 564/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1211.6009521484375 lr: 0.00031623\n",
      "Iter: 565/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 894.713134765625 lr: 0.00031623\n",
      "Iter: 566/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 1710.000244140625 lr: 0.00031623\n",
      "Iter: 567/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 1821.2305908203125 lr: 0.00031623\n",
      "Iter: 568/695, loss_train: 5.745, loss_val: nan, pos_over_neg: 1644.1640625 lr: 0.00031623\n",
      "Iter: 569/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 2318.348876953125 lr: 0.00031623\n",
      "Iter: 570/695, loss_train: 5.7417, loss_val: nan, pos_over_neg: 1410.2496337890625 lr: 0.00031623\n",
      "Iter: 571/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 992.8497924804688 lr: 0.00031623\n",
      "Iter: 572/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1800.3565673828125 lr: 0.00031623\n",
      "Iter: 573/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 895.6157836914062 lr: 0.00031623\n",
      "Iter: 574/695, loss_train: 5.7415, loss_val: nan, pos_over_neg: 971.09228515625 lr: 0.00031623\n",
      "Iter: 575/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 824.61474609375 lr: 0.00031623\n",
      "Iter: 576/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1766.3043212890625 lr: 0.00031623\n",
      "Iter: 577/695, loss_train: 5.7453, loss_val: nan, pos_over_neg: 1477.8800048828125 lr: 0.00031623\n",
      "Iter: 578/695, loss_train: 5.7469, loss_val: nan, pos_over_neg: 969.9872436523438 lr: 0.00031623\n",
      "Iter: 579/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 871.5906982421875 lr: 0.00031623\n",
      "Iter: 580/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 3262.6376953125 lr: 0.00031623\n",
      "Iter: 581/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 2008.6932373046875 lr: 0.00031623\n",
      "Iter: 582/695, loss_train: 5.7482, loss_val: nan, pos_over_neg: 1282.037109375 lr: 0.00031623\n",
      "Iter: 583/695, loss_train: 5.7424, loss_val: nan, pos_over_neg: 1266.5870361328125 lr: 0.00031623\n",
      "Iter: 584/695, loss_train: 5.7472, loss_val: nan, pos_over_neg: 1011.0668334960938 lr: 0.00031623\n",
      "Iter: 585/695, loss_train: 5.7551, loss_val: nan, pos_over_neg: 1714.8643798828125 lr: 0.00031623\n",
      "Iter: 586/695, loss_train: 5.7519, loss_val: nan, pos_over_neg: 2684.052978515625 lr: 0.00031623\n",
      "Iter: 587/695, loss_train: 5.7471, loss_val: nan, pos_over_neg: 3195.732421875 lr: 0.00031623\n",
      "Iter: 588/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 829.2083740234375 lr: 0.00031623\n",
      "Iter: 589/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 1157.39794921875 lr: 0.00031623\n",
      "Iter: 590/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1608.9732666015625 lr: 0.00031623\n",
      "Iter: 591/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1681.706787109375 lr: 0.00031623\n",
      "Iter: 592/695, loss_train: 5.7502, loss_val: nan, pos_over_neg: 1190.617919921875 lr: 0.00031623\n",
      "Iter: 593/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 1154.493408203125 lr: 0.00031623\n",
      "Iter: 594/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1307.99560546875 lr: 0.00031623\n",
      "Iter: 595/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1609.5289306640625 lr: 0.00031623\n",
      "Iter: 596/695, loss_train: 5.7413, loss_val: nan, pos_over_neg: 1762.4295654296875 lr: 0.00031623\n",
      "Iter: 597/695, loss_train: 5.7508, loss_val: nan, pos_over_neg: 1606.0806884765625 lr: 0.00031623\n",
      "Iter: 598/695, loss_train: 5.7473, loss_val: nan, pos_over_neg: 2105.529052734375 lr: 0.00031623\n",
      "Iter: 599/695, loss_train: 5.7414, loss_val: nan, pos_over_neg: 1194.073974609375 lr: 0.00031623\n",
      "Iter: 600/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 920.8764038085938 lr: 0.00031623\n",
      "Iter: 601/695, loss_train: 5.7467, loss_val: nan, pos_over_neg: 1095.599853515625 lr: 0.00031623\n",
      "Iter: 602/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 1470.1231689453125 lr: 0.00031623\n",
      "Iter: 603/695, loss_train: 5.742, loss_val: nan, pos_over_neg: 1244.658447265625 lr: 0.00031623\n",
      "Iter: 604/695, loss_train: 5.7544, loss_val: nan, pos_over_neg: 1147.2001953125 lr: 0.00031623\n",
      "Iter: 605/695, loss_train: 5.7452, loss_val: nan, pos_over_neg: 1590.514892578125 lr: 0.00031623\n",
      "Iter: 606/695, loss_train: 5.7419, loss_val: nan, pos_over_neg: 1295.6241455078125 lr: 0.00031623\n",
      "Iter: 607/695, loss_train: 5.7455, loss_val: nan, pos_over_neg: 895.3523559570312 lr: 0.00031623\n",
      "Iter: 608/695, loss_train: 5.7487, loss_val: nan, pos_over_neg: 2641.19384765625 lr: 0.00031623\n",
      "Iter: 609/695, loss_train: 5.7468, loss_val: nan, pos_over_neg: 2406.086669921875 lr: 0.00031623\n",
      "Iter: 610/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1698.0877685546875 lr: 0.00031623\n",
      "Iter: 611/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 642.0647583007812 lr: 0.00031623\n",
      "Iter: 612/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 725.9525146484375 lr: 0.00031623\n",
      "Iter: 613/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1057.0203857421875 lr: 0.00031623\n",
      "Iter: 614/695, loss_train: 5.7515, loss_val: nan, pos_over_neg: 738.1802978515625 lr: 0.00031623\n",
      "Iter: 615/695, loss_train: 5.7528, loss_val: nan, pos_over_neg: 1203.7325439453125 lr: 0.00031623\n",
      "Iter: 616/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 1004.5504760742188 lr: 0.00031623\n",
      "Iter: 617/695, loss_train: 5.7478, loss_val: nan, pos_over_neg: 1020.3235473632812 lr: 0.00031623\n",
      "Iter: 618/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1769.1741943359375 lr: 0.00031623\n",
      "Iter: 619/695, loss_train: 5.7486, loss_val: nan, pos_over_neg: 766.3446044921875 lr: 0.00031623\n",
      "Iter: 620/695, loss_train: 5.7483, loss_val: nan, pos_over_neg: 902.9290771484375 lr: 0.00031623\n",
      "Iter: 621/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 648.4940185546875 lr: 0.00031623\n",
      "Iter: 622/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1348.5574951171875 lr: 0.00031623\n",
      "Iter: 623/695, loss_train: 5.7439, loss_val: nan, pos_over_neg: 1700.587890625 lr: 0.00031623\n",
      "Iter: 624/695, loss_train: 5.7491, loss_val: nan, pos_over_neg: 2287.97265625 lr: 0.00031623\n",
      "Iter: 625/695, loss_train: 5.7428, loss_val: nan, pos_over_neg: 1398.5963134765625 lr: 0.00031623\n",
      "Iter: 626/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 990.3759765625 lr: 0.00031623\n",
      "Iter: 627/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1210.7537841796875 lr: 0.00031623\n",
      "Iter: 628/695, loss_train: 5.7447, loss_val: nan, pos_over_neg: 1419.05810546875 lr: 0.00031623\n",
      "Iter: 629/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1519.8951416015625 lr: 0.00031623\n",
      "Iter: 630/695, loss_train: 5.7458, loss_val: nan, pos_over_neg: 1285.64111328125 lr: 0.00031623\n",
      "Iter: 631/695, loss_train: 5.7441, loss_val: nan, pos_over_neg: 2649.61669921875 lr: 0.00031623\n",
      "Iter: 632/695, loss_train: 5.744, loss_val: nan, pos_over_neg: 2680.155517578125 lr: 0.00031623\n",
      "Iter: 633/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 1201.30712890625 lr: 0.00031623\n",
      "Iter: 634/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 2403.39453125 lr: 0.00031623\n",
      "Iter: 635/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 1253.155517578125 lr: 0.00031623\n",
      "Iter: 636/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1140.134765625 lr: 0.00031623\n",
      "Iter: 637/695, loss_train: 5.7378, loss_val: nan, pos_over_neg: 2355.73388671875 lr: 0.00031623\n",
      "Iter: 638/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 1094.7340087890625 lr: 0.00031623\n",
      "Iter: 639/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 649.4490356445312 lr: 0.00031623\n",
      "Iter: 640/695, loss_train: 5.7414, loss_val: nan, pos_over_neg: 9904.0703125 lr: 0.00031623\n",
      "Iter: 641/695, loss_train: 5.7422, loss_val: nan, pos_over_neg: -52419.0234375 lr: 0.00031623\n",
      "Iter: 642/695, loss_train: 5.7526, loss_val: nan, pos_over_neg: 1671.4661865234375 lr: 0.00031623\n",
      "Iter: 643/695, loss_train: 5.7498, loss_val: nan, pos_over_neg: 865.8978881835938 lr: 0.00031623\n",
      "Iter: 644/695, loss_train: 5.7434, loss_val: nan, pos_over_neg: 1744.6614990234375 lr: 0.00031623\n",
      "Iter: 645/695, loss_train: 5.7464, loss_val: nan, pos_over_neg: 1053.4493408203125 lr: 0.00031623\n",
      "Iter: 646/695, loss_train: 5.7397, loss_val: nan, pos_over_neg: 1694.340576171875 lr: 0.00031623\n",
      "Iter: 647/695, loss_train: 5.7382, loss_val: nan, pos_over_neg: 1696.0594482421875 lr: 0.00031623\n",
      "Iter: 648/695, loss_train: 5.7512, loss_val: nan, pos_over_neg: 1976.9571533203125 lr: 0.00031623\n",
      "Iter: 649/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 1341.470947265625 lr: 0.00031623\n",
      "Iter: 650/695, loss_train: 5.7423, loss_val: nan, pos_over_neg: 1957.2900390625 lr: 0.00031623\n",
      "Iter: 651/695, loss_train: 5.7462, loss_val: nan, pos_over_neg: 1038.1671142578125 lr: 0.00031623\n",
      "Iter: 652/695, loss_train: 5.7495, loss_val: nan, pos_over_neg: 2248.049072265625 lr: 0.00031623\n",
      "Iter: 653/695, loss_train: 5.749, loss_val: nan, pos_over_neg: 1025.621826171875 lr: 0.00031623\n",
      "Iter: 654/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 1144.458251953125 lr: 0.00031623\n",
      "Iter: 655/695, loss_train: 5.7411, loss_val: nan, pos_over_neg: 1264.5428466796875 lr: 0.00031623\n",
      "Iter: 656/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1084.72216796875 lr: 0.00031623\n",
      "Iter: 657/695, loss_train: 5.7431, loss_val: nan, pos_over_neg: 1124.40087890625 lr: 0.00031623\n",
      "Iter: 658/695, loss_train: 5.7481, loss_val: nan, pos_over_neg: 1983.8427734375 lr: 0.00031623\n",
      "Iter: 659/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1105.4827880859375 lr: 0.00031623\n",
      "Iter: 660/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 2164.06884765625 lr: 0.00031623\n",
      "Iter: 661/695, loss_train: 5.7475, loss_val: nan, pos_over_neg: 1000.6470947265625 lr: 0.00031623\n",
      "Iter: 662/695, loss_train: 5.7448, loss_val: nan, pos_over_neg: 1597.6588134765625 lr: 0.00031623\n",
      "Iter: 663/695, loss_train: 5.7516, loss_val: nan, pos_over_neg: 931.3909912109375 lr: 0.00031623\n",
      "Iter: 664/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 895.5348510742188 lr: 0.00031623\n",
      "Iter: 665/695, loss_train: 5.7494, loss_val: nan, pos_over_neg: 1099.7313232421875 lr: 0.00031623\n",
      "Iter: 666/695, loss_train: 5.7437, loss_val: nan, pos_over_neg: 1678.924560546875 lr: 0.00031623\n",
      "Iter: 667/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 1544.1573486328125 lr: 0.00031623\n",
      "Iter: 668/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 894.81298828125 lr: 0.00031623\n",
      "Iter: 669/695, loss_train: 5.7445, loss_val: nan, pos_over_neg: 1442.7493896484375 lr: 0.00031623\n",
      "Iter: 670/695, loss_train: 5.7465, loss_val: nan, pos_over_neg: 918.4843139648438 lr: 0.00031623\n",
      "Iter: 671/695, loss_train: 5.7485, loss_val: nan, pos_over_neg: 1557.7872314453125 lr: 0.00031623\n",
      "Iter: 672/695, loss_train: 5.7436, loss_val: nan, pos_over_neg: 856.8936157226562 lr: 0.00031623\n",
      "Iter: 673/695, loss_train: 5.7454, loss_val: nan, pos_over_neg: 1862.7822265625 lr: 0.00031623\n",
      "Iter: 674/695, loss_train: 5.7449, loss_val: nan, pos_over_neg: 3131.031005859375 lr: 0.00031623\n",
      "Iter: 675/695, loss_train: 5.7461, loss_val: nan, pos_over_neg: 2271.04443359375 lr: 0.00031623\n",
      "Iter: 676/695, loss_train: 5.7477, loss_val: nan, pos_over_neg: 1743.1201171875 lr: 0.00031623\n",
      "Iter: 677/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 1585.405517578125 lr: 0.00031623\n",
      "Iter: 678/695, loss_train: 5.751, loss_val: nan, pos_over_neg: 725.3623657226562 lr: 0.00031623\n",
      "Iter: 679/695, loss_train: 5.7444, loss_val: nan, pos_over_neg: 2147.596923828125 lr: 0.00031623\n",
      "Iter: 680/695, loss_train: 5.7435, loss_val: nan, pos_over_neg: 2264.532958984375 lr: 0.00031623\n",
      "Iter: 681/695, loss_train: 5.75, loss_val: nan, pos_over_neg: 769.1226806640625 lr: 0.00031623\n",
      "Iter: 682/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1242.0125732421875 lr: 0.00031623\n",
      "Iter: 683/695, loss_train: 5.7466, loss_val: nan, pos_over_neg: 646.2234497070312 lr: 0.00031623\n",
      "Iter: 684/695, loss_train: 5.747, loss_val: nan, pos_over_neg: 823.882568359375 lr: 0.00031623\n",
      "Iter: 685/695, loss_train: 5.7418, loss_val: nan, pos_over_neg: 1985.6435546875 lr: 0.00031623\n",
      "Iter: 686/695, loss_train: 5.7459, loss_val: nan, pos_over_neg: 584.166748046875 lr: 0.00031623\n",
      "Iter: 687/695, loss_train: 5.7492, loss_val: nan, pos_over_neg: 1241.336669921875 lr: 0.00031623\n",
      "Iter: 688/695, loss_train: 5.746, loss_val: nan, pos_over_neg: 1146.6007080078125 lr: 0.00031623\n",
      "Iter: 689/695, loss_train: 5.7425, loss_val: nan, pos_over_neg: 1679.972900390625 lr: 0.00031623\n",
      "Iter: 690/695, loss_train: 5.7421, loss_val: nan, pos_over_neg: 972.313232421875 lr: 0.00031623\n",
      "Iter: 691/695, loss_train: 5.7501, loss_val: nan, pos_over_neg: 728.3534545898438 lr: 0.00031623\n",
      "Iter: 692/695, loss_train: 5.7463, loss_val: nan, pos_over_neg: 1672.9315185546875 lr: 0.00031623\n",
      "Iter: 693/695, loss_train: 5.7427, loss_val: nan, pos_over_neg: 1166.73583984375 lr: 0.00031623\n",
      "Iter: 694/695, loss_train: 5.7457, loss_val: nan, pos_over_neg: 1027.376953125 lr: 0.00031623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/300000 [2:47:38<104983:34:14, 1259.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Iter: 0/695, loss_train: 5.7432, loss_val: nan, pos_over_neg: 1765.8162841796875 lr: 0.00031623\n",
      "Iter: 1/695, loss_train: 5.7446, loss_val: nan, pos_over_neg: 1129.736572265625 lr: 0.00031623\n",
      "Iter: 2/695, loss_train: 5.7474, loss_val: nan, pos_over_neg: 1375.6771240234375 lr: 0.00031623\n",
      "Iter: 3/695, loss_train: 5.7539, loss_val: nan, pos_over_neg: 1396.7520751953125 lr: 0.00031623\n",
      "Iter: 4/695, loss_train: 5.7426, loss_val: nan, pos_over_neg: 3747.571044921875 lr: 0.00031623\n",
      "Iter: 5/695, loss_train: 5.7507, loss_val: nan, pos_over_neg: 2211.263916015625 lr: 0.00031623\n",
      "Iter: 6/695, loss_train: 5.7476, loss_val: nan, pos_over_neg: 1993.2218017578125 lr: 0.00031623\n",
      "Iter: 7/695, loss_train: 5.7497, loss_val: nan, pos_over_neg: 733.7907104492188 lr: 0.00031623\n",
      "Iter: 8/695, loss_train: 5.7503, loss_val: nan, pos_over_neg: 760.5606689453125 lr: 0.00031623\n",
      "Iter: 9/695, loss_train: 5.7385, loss_val: nan, pos_over_neg: 1921.343017578125 lr: 0.00031623\n",
      "Iter: 10/695, loss_train: 5.7493, loss_val: nan, pos_over_neg: 1330.6051025390625 lr: 0.00031623\n",
      "Iter: 11/695, loss_train: 5.7378, loss_val: nan, pos_over_neg: 5837.18701171875 lr: 0.00031623\n"
     ]
    }
   ],
   "source": [
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion,\n",
    "                                    scheduler=scheduler,\n",
    "                                    temperature=0.5,\n",
    "                                    # l2_alpha,\n",
    "                                    mode='semi-supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    device=DEVICE, \n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')\n",
    "\n",
    "    losses_train_npy = np.array(losses_train)\n",
    "    losses_val_npy = np.array(losses_val)\n",
    "    val_accs_npy = np.array(val_accs)\n",
    "    acc_npy = np.array(acc)\n",
    "\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "    np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "af10GlccgaV4",
    "outputId": "2ec75ade-6308-4a67-89e4-4bf3f996f746"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style='white', palette='bright', context='poster')\n",
    "plt.rcdefaults()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses_train, label='Training Loss')\n",
    "plt.plot(losses_val, label='Validation Loss')\n",
    "plt.title(f'Loss  Balanced Transfer Learning, No Data Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch Step')\n",
    "plt.ylabel('Loss')\n",
    "# plt.savefig('./Training-Loss.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "Cl4TSsfc2MDy",
    "outputId": "ccc80bf3-a191-49ec-e635-dce022144cbe"
   },
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,12))\n",
    "# val_transfer_cm = get_cm(features_val, y_val)\n",
    "# plt.imshow(val_transfer_cm)\n",
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "plt.imshow(test_transfer_cm)\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(test_transfer_cm.shape[0]):\n",
    "    for j in range(test_transfer_cm.shape[1]):\n",
    "        plt.annotate(np.round(test_transfer_cm[i,j], 3), (j,i), ha='center')\n",
    "plt.title(f'Test Confusion Matrix  Balanced Transfer Learning, No Augmentation, L2 Lambda = {l2_alpha}')\n",
    "plt.xlabel('True Class')\n",
    "plt.ylabel('Predicted Class')\n",
    "# plt.savefig('./Confusion-Matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'ResNet18_simCLR_model_202112078_temp=1.0'\n",
    "\n",
    "# torch.save(model.state_dict(), '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_3.pth')\n",
    "torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/new_stuff/models/ResNet18_simCLR_model_20211205_2.pth'))\n",
    "model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/{model_file_name}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train_npy = np.array(losses_train)\n",
    "losses_val_npy = np.array(losses_val)\n",
    "val_accs_npy = np.array(val_accs)\n",
    "acc_npy = np.array(acc)\n",
    "\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_train.npy', losses_train_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_losses_val.npy', losses_val_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_val_accs.npy', val_accs_npy)\n",
    "np.save(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/model_performance/{model_file_name}_tr_accs.npy', acc_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEqA0gLPl3-6"
   },
   "source": [
    "## Train classifier using classifier layers of model (or do supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "fmMkNykeVHbn"
   },
   "source": [
    "test_transfer_cm = get_cm(features_test, y_test)\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.npy',\n",
    "        test_transfer_cm)\n",
    "torch.save(model.state_dict(), f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-TransferL2Lambda={l2_alpha}.pth')\n",
    "\n",
    "np.save(f'/content/drive/MyDrive/00 - ROI/GCaMP_ROI_classifier/new_stuff/npy-figures/TestingCM-{\"Un\" if not balanced else \"\"}Balanced-SKLearn-Solver={solver}C={C_reg}.npy',\n",
    "        logistic_pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "zo42G3CeWozY"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_cm(pred_cm, y_cm, plot=False):\n",
    "  ### NOTE  RETURNS A MATRIX WITH PREDICTION NUM ASSOCIATED WITH ROW NUM\n",
    "  ### AND COLUMN NUM ASSOCIATED WITH TRUE VALUE. (TRANSPOSE OF SKLEARN OUTPUT.)\n",
    "\n",
    "  cm = confusion_matrix(y_cm, np.argmax(pred_cm, -1))\n",
    "  cm = cm / np.where(cm.sum(1, keepdims=True)==0, np.ones_like(cm.sum(1, keepdims=True)), cm.sum(1, keepdims=True))\n",
    "  \n",
    "  # cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "  # print(cm)\n",
    "  \n",
    "  if plot:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "  \n",
    "  return cm.T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWk_NgpNd2Ia",
    "outputId": "2959f230-bd91-46cd-e898-d270aade7e54"
   },
   "source": [
    "num_tr_ex = X_val.shape[0]\n",
    "\n",
    "\n",
    "# solver = 'lbfgs'\n",
    "solver = 'liblinear'\n",
    "# solver = 'newton-cg'\n",
    "C_reg = 0.01\n",
    "# C_reg = 0.0001\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', )\n",
    "# logreg = LogisticRegression(solver=solver, penalty='none', max_iter=4000)\n",
    "# logreg = LogisticRegression(solver=solver)\n",
    "logreg = LogisticRegression(solver=solver, C=C_reg)\n",
    "# logreg = LogisticRegression(solver='lbfgs', penalty='none', max_iter=4000)\n",
    "\n",
    "# base_features_train = base_model_frozen(x_feed_through_tr).detach().cpu()\n",
    "base_features_train = cpu_tr.cpu().detach().numpy()\n",
    "logreg.fit(base_features_train, y_train)\n",
    "\n",
    "# base_features_val = base_model_frozen(x_feed_through_val).detach().cpu()\n",
    "base_features_val = cpu_val.cpu().detach().numpy()\n",
    "\n",
    "base_features_te = cpu_te.cpu().detach().numpy()\n",
    "\n",
    "# base_model_frozen.to('cpu')\n",
    "# X_labeled_train.to('cpu')\n",
    "\n",
    "logistic_pred_train = get_cm(logreg.predict_proba(base_features_train), y_train)\n",
    "logistic_pred_val = get_cm(logreg.predict_proba(base_features_val), y_val)\n",
    "logistic_pred_test = get_cm(logreg.predict_proba(base_features_te), y_test)\n",
    "\n",
    "\n",
    "x_feed_through_tr.to(DEVICE)\n",
    "x_feed_through_val.to(DEVICE)\n",
    "x_feed_through_te.to(DEVICE)\n",
    "\n",
    "print(x_feed_through_tr.shape, x_feed_through_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLH9o3jLl4G_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNJk6Qwl4O3"
   },
   "source": [
    "Freeze pre-head layers, unfreeze classification layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq4toNxdl4jb"
   },
   "source": [
    "Define labeled dataset to use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MGvBSux9l4pn"
   },
   "source": [
    "X_labeled_train, X_labeled_val, y_labeled_train, y_labeled_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS_mTd7cl4vI"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "# criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "# optimizer = Adam(model.parameters(), lr=2e-2)\n",
    "optimizer = Adam(model.parameters(), lr=10**(-4.5))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0000,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "criterion = [_.to(DEVICE) for _ in criterion]\n",
    "losses_train, losses_val, val_accs, acc = [], [np.nan], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_null(var):\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reinit_classifier()\n",
    "model.train()\n",
    "model.prep_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validation = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_validation = torch.utils.data.DataLoader( dataset_validation,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4WvU5xxl41A"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "# model.to(DEVICE)\n",
    "\n",
    "l2_alpha = 0.000\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    loss_rolling_train = training_simCLR.epoch_step(dataloader_validation, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    L2_alpha=0.04,\n",
    "                                    mode='supervised',\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=1,\n",
    "                                   \n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcpUsTJl46l"
   },
   "source": [
    "Evalculate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling_train)\n",
    "\n",
    "data_in = torch.as_tensor(X_labeled_val, dtype=torch.float32, device=DEVICE)\n",
    "# data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_val)\n",
    "# cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHaYL5XjaBfP"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "data_in = torch.as_tensor(X_labeled_train, dtype=torch.float32, device=DEVICE)\n",
    "data_in = util.tile_channels(data_in[:,None,...], dim=1)\n",
    "proba = torch.nn.functional.softmax(model.forward_classifier(data_in), dim=1)\n",
    "cm = classification.confusion_matrix(proba.detach().cpu().numpy(), y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNlRDjrVaCD-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_validation = torch.nn.Sequential(\n",
    "    torchvision.transforms.Resize(size=(224,224),\n",
    "                                  interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    "#     augmentation.Normalize(  means=[0.485, 0.456, 0.406],\n",
    "#                              stds=[0.229, 0.224, 0.225]),\n",
    "#     torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225],\n",
    "#                                      inplace=False),\n",
    "    \n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)), # just clamping, both this and clamping = normalizing (DEFAULT)\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225],\n",
    "                                     inplace=False),\n",
    ")\n",
    "scripted_transforms_validation = torch.jit.script(transforms_validation)\n",
    "# scripted_transforms = transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_train = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_train, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_train_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_train.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_train_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataset_labeled_val = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(X_labeled_val, device='cpu', dtype=torch.float32), \n",
    "                                    # torch.as_tensor(X_labeled_val_SYT, device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(X_labeled_val.shape[0]), device='cpu', dtype=torch.float32),\n",
    "                                    # torch.as_tensor(torch.zeros(X_labeled_val_SYT.shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_labeled_train = torch.utils.data.DataLoader( dataset_labeled_train,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n",
    "dataloader_labeled_val = torch.utils.data.DataLoader( dataset_labeled_val,\n",
    "    #                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False,\n",
    "                                                    drop_last=False,\n",
    "#                                                     pin_memory=True,\n",
    "#                                                     num_workers=32,\n",
    "#                                                     persistent_workers=True,\n",
    "                                                    # prefetch_factor=0\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_train], dim=0)\n",
    "features_val   = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_val], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_train, acc_val = [], []\n",
    "# C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "for C in C_toUse:\n",
    "#     print(f'C = {C}')\n",
    "    logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "#     tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "#     print(f'time: {time.time() - tic}')\n",
    "    acc = logreg.score(features_train, y_labeled_train)\n",
    "    acc_train.append(acc)\n",
    "#     print(f'acc_train: {acc}')\n",
    "    acc = logreg.score(features_val, y_labeled_val)\n",
    "    acc_val.append(acc)\n",
    "#     print(f'acc_val: {acc}')\n",
    "#     print('')\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train, acc_val = [], []\n",
    "# # C_toUse = np.array([1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# # C_toUse = np.array([10,1,0.1,0.01,0.001,0.0001,0.00001])\n",
    "# C_toUse = np.array([10000])\n",
    "# for C in tqdm(C_toUse):\n",
    "# #     print(f'C = {C}')\n",
    "#     logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=C)\n",
    "# #     tic = time.time()\n",
    "#     logreg.fit(features_train, y_labeled_train_SYT)\n",
    "# #     print(f'time: {time.time() - tic}')\n",
    "#     acc = logreg.score(features_train, y_labeled_train_SYT)\n",
    "#     acc_train.append(acc)\n",
    "# #     print(f'acc_train: {acc}')\n",
    "#     acc = logreg.score(features_val, y_labeled_val_SYT)\n",
    "#     acc_val.append(acc)\n",
    "# #     print(f'acc_val: {acc}')\n",
    "# #     print('')\n",
    "    \n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(C_toUse, acc_train)\n",
    "# plt.plot(C_toUse, acc_val)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('acc')\n",
    "# plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:05<00:00,  9.46it/s]\n",
      "100%|| 50/50 [00:03<00:00, 15.28it/s]\n",
      "100%|| 50/50 [00:02<00:00, 24.73it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=50)\n",
    "all_split_inx = list(splitter.split(features_train))\n",
    "\n",
    "train_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "train_y = [y_labeled_train[_[0]] for _ in all_split_inx]\n",
    "test_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "test_y = [y_labeled_train[_[1]] for _ in all_split_inx]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10,10))\n",
    "plt.suptitle(f'{model_file_name}')\n",
    "\n",
    "c_lst = [1e-1, 1e-2, 1e-3]\n",
    "for ic, c in enumerate(c_lst):\n",
    "    train_cms = []\n",
    "    test_cms = []\n",
    "    for inx_split in trange(len(train_X)):\n",
    "        tmp_train_X = train_X[inx_split]\n",
    "        tmp_train_y = train_y[inx_split]\n",
    "        \n",
    "        tmp_test_X = test_X[inx_split]\n",
    "        tmp_test_y = test_y[inx_split]\n",
    "        \n",
    "        logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=c).fit(tmp_train_X, tmp_train_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_train_X)\n",
    "\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_train_y)\n",
    "        train_cms.append(cm)\n",
    "\n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('train');\n",
    "        \n",
    "        proba = logreg.predict_proba(tmp_test_X)\n",
    "        preds = np.argmax(proba, axis=1)\n",
    "        cm = classification.confusion_matrix(preds, tmp_test_y)\n",
    "        test_cms.append(cm)\n",
    "        \n",
    "#         plt.figure()\n",
    "#         sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "#         plt.title('val');\n",
    "\n",
    "    sns.heatmap(np.mean(train_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 0])\n",
    "    ax[ic, 0].set_title(f'train  C:{c}');\n",
    "\n",
    "    sns.heatmap(np.mean(test_cms,axis=0), annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'), ax=ax[ic, 1])\n",
    "    ax[ic, 1].set_title(f'val  C:{c}');\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(solver='liblinear', max_iter=800, C=10**(-3)).fit(features_train, y_labeled_train)\n",
    "\n",
    "%matplotlib inline\n",
    "proba = logreg.predict_proba(features_train)\n",
    "\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_train)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "cm = classification.confusion_matrix(preds, y_labeled_val)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# proba = logreg.predict_proba(features_train)\n",
    "\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_train_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('train');\n",
    "\n",
    "# proba = logreg.predict_proba(features_val)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "# cm = classification.confusion_matrix(preds, y_labeled_val_SYT)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "# plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CchY4kGDB00"
   },
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcrdLrYtDB00"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_cat[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_cat[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unlabeled_noAug = util.dataset_simCLR(\n",
    "                                    torch.as_tensor(masks_SYT[:], device='cpu', dtype=torch.float32), \n",
    "                                    torch.as_tensor(torch.zeros(masks_SYT[:].shape[0]), device='cpu', dtype=torch.float32),\n",
    "\n",
    "                                    n_transforms=1,\n",
    "                                    class_weights=np.array([1]),\n",
    "                                    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "                                    transform=scripted_transforms_validation,\n",
    "                                    # DEVICE='cpu',\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64,\n",
    "                                    \n",
    "                                    temp_uncertainty=16\n",
    "                                    )\n",
    "dataloader_unlabeled_noAug = torch.utils.data.DataLoader( dataset_unlabeled_noAug,\n",
    "#                                                 batch_size=int(pct_batch_size*X_train.shape[0]),\n",
    "                                                batch_size=1024,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=False,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=32,\n",
    "                                                persistent_workers=True,\n",
    "                                                # prefetch_factor=0\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: run unlabeled data through model\n",
    "features_train = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_unlabeled_noAug], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPyKFRdq28d3"
   },
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fpQXf0o28d3"
   },
   "outputs": [],
   "source": [
    "# model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gwucuZXDB00"
   },
   "outputs": [],
   "source": [
    "_, features_embedded, _, evr = decomposition.torch_pca(features_train, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = cuml.TSNE( n_components=2,\n",
    "                  perplexity=50.0,\n",
    "                  early_exaggeration=12.0,\n",
    "#                   late_exaggeration=1.0,\n",
    "                  learning_rate=200.0,\n",
    "                  n_iter=1000,\n",
    "                  n_iter_without_progress=300,\n",
    "                  min_grad_norm=1e-07,\n",
    "                  metric='euclidean',\n",
    "                  init='random',\n",
    "                  verbose=False,\n",
    "#                   random_state=None,\n",
    "#                   method='barnes_hut',\n",
    "#                   angle=0.5,\n",
    "#                   learning_rate_method='adaptive',\n",
    "# #                   n_neighbors=90,\n",
    "#                   perplexity_max_iter=100,\n",
    "#                   exaggeration_iter=250,\n",
    "#                   pre_momentum=0.5,\n",
    "#                   post_momentum=0.8,\n",
    "# #                   square_distances=True,\n",
    "#                   handle=None,\n",
    "#                   output_type=None\n",
    "                )\n",
    "features_embedded = tsne.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = cuml.UMAP(n_neighbors=100,\n",
    "                n_components=2,\n",
    "                n_epochs=None,\n",
    "                learning_rate=1.0,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0,\n",
    "                set_op_mix_ratio=1.0, \n",
    "                local_connectivity=1.0,\n",
    "                repulsion_strength=1.0, \n",
    "                negative_sample_rate=5, \n",
    "                transform_queue_size=4.0, \n",
    "                init='spectral', \n",
    "                verbose=False,\n",
    "                a=None, \n",
    "                b=None, \n",
    "                target_n_neighbors=- 1, \n",
    "#                 target_weight=0.5, \n",
    "                target_metric='categorical', \n",
    "                handle=None,                \n",
    "                hash_input=False, \n",
    "                random_state=None, \n",
    "                callback=None, \n",
    "                output_type=None\n",
    "                )\n",
    "features_embedded = umap.fit_transform(features_train.to(DEVICE)).get()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.delete_all_cuda_tensors(globals())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch_helpers.tensor_sizeOnDisk(features_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2imvF8ZoDB00"
   },
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=120.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features_train.cpu())\n",
    "# features_embedded = tsne.fit_transform(features_embedded[:,:5].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=10, c=labels_SYT, cmap=plt.get_cmap('tab10'))\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.001)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgxJ8VXwDB00"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], s=30, c=y_labeled_train, cmap=plt.get_cmap('tab10'))\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], s=0.2)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels[labels!=3])\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwFf2BsVDB00"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_train.cpu().detach(), aspect='auto', interpolation='antialiased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARf-u1K28d4"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evr)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHXPapkDB00"
   },
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aBVd9FTDB00"
   },
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_-Xu9EDB01"
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['base_model.4.0.conv1.weight'].cpu()\n",
    "layer_3 = model.state_dict()['base_model.7.0.conv1.weight'].cpu()\n",
    "layer_4 = model.state_dict()['base_model.7.1.conv2.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:], clim=(-.1,.1))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiz2fHFDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwJQBUhpDB01"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1grXld0IDB01"
   },
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quqNFL1jDB01"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvDiVxDICXEn",
    "outputId": "2c29e3cf-4515-4aae-f0b1-22e30d51fa5f"
   },
   "outputs": [],
   "source": [
    "data_unlabeled = torch.as_tensor(masks_cat, dtype=torch.float32, device='cpu')\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# penalized_params = list(model.modules())[-1].parameters()\n",
    "# penalized_params = torch.cat([_.view(-1) for _ in penalized_params], -1)\n",
    "\n",
    "early_stopping = 50\n",
    "prv_best_val = np.inf\n",
    "early_stopping_cnt = 0\n",
    "\n",
    "l2_alpha = 0.1\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "#     loss_rolling_train, loss_rolling_val = training_supervised.epoch_step(dataloader_train, \n",
    "#                                     model, \n",
    "#                                     optimizer, \n",
    "#                                     criterion, \n",
    "\n",
    "#                                     penalized_params, l2_alpha,\n",
    "\n",
    "#                                     scheduler=scheduler,\n",
    "#                                     loss_rolling_train=losses_train, \n",
    "#                                     device=DEVICE, \n",
    "#                                     loss_rolling_val=losses_val,\n",
    "#                                     verbose=2,\n",
    "#                                     verbose_update_period=100,\n",
    "                                   \n",
    "#                                     do_validation=True,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "#                                    )\n",
    "    \n",
    "    loss_rolling_train, loss_rolling_val = training_simCLR.epoch_step(dataloader_train, \n",
    "                                    model, \n",
    "                                    optimizer, \n",
    "                                    criterion, \n",
    "\n",
    "                                    # penalized_params, l2_alpha,\n",
    "\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_rolling_train=losses_train, \n",
    "                                    device=DEVICE, \n",
    "                                    loss_rolling_val=losses_val,\n",
    "                                    verbose=2,\n",
    "                                    verbose_update_period=100,\n",
    "                                   \n",
    "                                    do_validation=True,\n",
    "                                    X_val=x_feed_through_val,\n",
    "                                    y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    if early_stopping:\n",
    "      if len(loss_rolling_val) > 0:\n",
    "        if loss_rolling_val[-1] < prv_best_val:\n",
    "          early_stopping_cnt = 0\n",
    "          prv_best_val = loss_rolling_val[-1]\n",
    "          torch.save(model.state_dict(), f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth')\n",
    "        else:\n",
    "          early_stopping_cnt += 1\n",
    "    \n",
    "      if early_stopping_cnt >= early_stopping:\n",
    "        model.load_state_dict(torch.load(f'{base_dir}/github_repos/GCaMP_ROI_classifier/new_stuff/models/checkpoints/checkpoint.pth'))\n",
    "        break\n",
    "    \n",
    "    # torch_helpers.show_all_tensors(globals())\n",
    "    \n",
    "    features_train = model(x_feed_through_tr)\n",
    "    features_train = features_train.cpu().detach().numpy()\n",
    "    features_val = model(x_feed_through_val)\n",
    "    features_val = features_val.cpu().detach().numpy()\n",
    "    # y_hat = scipy.special.softmax(features_val, axis=-1) # logreg.predict_proba(features_val)\n",
    "    \n",
    "    print('Training Confusion Matrix')\n",
    "    print(get_cm(features_train, y_train))\n",
    "    print()\n",
    "    print(logistic_pred_train)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print('Val Confusion Matrix')\n",
    "    print(get_cm(features_val, y_val))\n",
    "    print()\n",
    "    print(logistic_pred_val)\n",
    "\n",
    "    # model.to(DEVICE)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "E5EeUhzUDB0v"
   },
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=30)\n",
    "# logreg_predict_head = LogisticRegression(solver='liblinear')\n",
    "dataset_train.classification_model = None\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "#                                                    gamma=1-0.001,\n",
    "# #                                                    gamma=1,\n",
    "#                                                   )\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "\n",
    "    model.prep_contrast()\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion,\n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=100,\n",
    "                               )\n",
    "    \n",
    "\n",
    "    model.prep_classifier()\n",
    "\n",
    "    # print(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1).shape)\n",
    "\n",
    "    features_train = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "    # features_train = model(util.tile_channels(torch.as_tensor(X_labeled_train[:,None,...], device=DEVICE, dtype=torch.float32), dim=1)).detach().cpu()\n",
    "    # features_train = model(torch.as_tensor(X_labeled_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    # features = model(torch.tensor(X_train[y_train != 3], device=DEVICE, dtype=torch.float32)[:,None,...]).detach().cpu()\n",
    "    \n",
    "    tic = time.time()\n",
    "    logreg.fit(features_train, y_labeled_train)\n",
    "    print(time.time() - tic)\n",
    "    acc.append(logreg.score(features_train, y_labeled_train))\n",
    "    print(f'acc: {acc[-1]}')\n",
    "    \n",
    "    dataset_train.net_model = copy.deepcopy(model).to('cpu')\n",
    "    dataset_train.classification_model = logreg\n",
    "    \n",
    "\n",
    "#     sample_id_num = np.arange(X_labeled_val.shape[0])\n",
    "#     epoch_val = epoch\n",
    "#     batch_val = -1\n",
    "#     p_tmp = logreg.predict_proba(model(torch.as_tensor(util.tile_channels(X_labeled_val), device=DEVICE, dtype=torch.float32)).detach().cpu())\n",
    "#     logits = p_tmp\n",
    "#     # logits = np.log(1/(1/p_tmp - 1))\n",
    "\n",
    "#     col_vals = [sample_id_num, epoch_val, batch_val, y_labeled_val]\n",
    "#     setup = np.empty((len(sample_id_num), len(col_vals)))\n",
    "#     for icv, col_val in enumerate(col_vals):\n",
    "#       setup[:, icv] = col_val\n",
    "#     tmp_tracking_np = np.concatenate([setup, logits], axis=1)\n",
    "\n",
    "#     tmp_tracking_df = pd.DataFrame(tmp_tracking_np, index=sample_id_num, columns=tracking_df_cols + [f'logits_{i}' for i in range(logits.shape[1])])\n",
    "#     tracking_df = tracking_df.append(tmp_tracking_df, ignore_index=True)\n",
    "#     display(tracking_df)\n",
    "\n",
    "\n",
    "    \n",
    "    features_val = model.get_head(model.base_model(util.tile_channels(torch.as_tensor(X_labeled_val[:,None,...], device=DEVICE, dtype=torch.float32), dim=1))).detach().cpu()\n",
    "\n",
    "\n",
    "    # logreg_predict_head.fit(features_train, y_labeled_train)\n",
    "    # y_hat = logreg_predict_head.predict_proba(features_val)\n",
    "\n",
    "    y_hat = logreg.predict_proba(features_val)\n",
    "    \n",
    "    cm = classification.confusion_matrix(y_hat, y_labeled_val)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # tracking_df = tracking_df.append(pd.DataFrame([np.array([100, 0, 0, 0])], index=tracking_df_cols), ignore_index=True)\n",
    "    \n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train, solver='liblinear')\n",
    "    \n",
    "#     proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "#     class_weights = proba.sum(axis=0)\n",
    "#     total_num = class_weights.sum()\n",
    "    \n",
    "#     eps = 1e-4\n",
    "    \n",
    "#     class_weights[class_weights <= 3] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "#     final_weights = np.array([1/proba.shape[1] for _ in range(proba.shape[1])])\n",
    "    \n",
    "#     print(class_weights)\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
