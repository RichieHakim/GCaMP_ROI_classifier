{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90714895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall umap --yes\n",
    "# !pip uninstall umap-learn --yes\n",
    "# !pip3 install umap-learn\n",
    "# !conda uninstall umap-learn\n",
    "# !pip freeze\n",
    "# !conda install -y -c conda-forge umap-learn --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b687e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from kymatio import Scattering2D\n",
    "import json\n",
    "%matplotlib notebook\n",
    "\n",
    "# base_dir = '/n/data1/hms/neurobio/sabatini/josh/analysis/ROI_net_training/20220510_testingSimCLRscript/jobNum_*/'\n",
    "base_dir = '/n/data1/hms/neurobio/sabatini/josh/analysis/ROI_net_training/simCLR_paramsweep_temp'\n",
    "jns = sorted(glob.glob(str(Path(base_dir) / 'jobNum_*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9087786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/data1/hms/neurobio/sabatini/josh/analysis/ROI_net_training/simCLR_paramsweep_temp/jobNum_0\n"
     ]
    }
   ],
   "source": [
    "pth_fn_lst = []\n",
    "log_fn_lst = []\n",
    "loss_fn_lst = []\n",
    "params_fn_lst = []\n",
    "run_outputs_fn_lst = []\n",
    "sbatch_config_fn_lst = []\n",
    "base_py_fn_lst = []\n",
    "\n",
    "for jn in jns:\n",
    "    print(jn)\n",
    "    \n",
    "    pth_fn = glob.glob(str(Path(jn) / '*.pth'))\n",
    "    log_fn = glob.glob(str(Path(jn) / 'log.txt'))\n",
    "    loss_fn = glob.glob(str(Path(jn) / 'loss.npy'))\n",
    "    params_fn = glob.glob(str(Path(jn) / 'params.json'))\n",
    "    run_outputs_fn = glob.glob(str(Path(jn) / 'run_outputs.json'))\n",
    "    sbatch_config_fn = glob.glob(str(Path(jn) / 'sbatch_config.sh'))\n",
    "    base_py_fn = glob.glob(str(Path(jn) / '*.py'))\n",
    "    \n",
    "    assert len(pth_fn) == 1\n",
    "    assert len(log_fn) == 1\n",
    "    assert len(loss_fn) == 1\n",
    "    assert len(params_fn) == 1\n",
    "    assert len(run_outputs_fn) == 1\n",
    "    assert len(sbatch_config_fn) == 1\n",
    "    assert len(base_py_fn) == 1\n",
    "    \n",
    "    pth_fn_lst += pth_fn\n",
    "    log_fn_lst += log_fn\n",
    "    loss_fn_lst += loss_fn\n",
    "    params_fn_lst += params_fn\n",
    "    run_outputs_fn_lst += run_outputs_fn\n",
    "    sbatch_config_fn_lst += sbatch_config_fn\n",
    "    base_py_fn_lst += base_py_fn\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "with open(params_fn[0], 'rb') as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8e7395",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'convnext_tiny'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_244844/3433400099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_model_frozen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_chopped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_chopped_pooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_out_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmodel_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref_log_all_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_244844/3433400099.py\u001b[0m in \u001b[0;36mmodel_from_params\u001b[0;34m(params, pref_log_all_steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpref_log_all_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbase_model_frozen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'torchvision_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model_frozen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'convnext_tiny'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "def model_from_params(params, pref_log_all_steps=False):\n",
    "    base_model_frozen = torchvision.models.__dict__[params['torchvision_model']](pretrained=True)\n",
    "    for param in base_model_frozen.parameters():\n",
    "        param.requires_grad = False\n",
    "    if pref_log_all_steps:\n",
    "        write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}  imported pretrained model')\n",
    "\n",
    "    ### Make combined model\n",
    "\n",
    "    ## Tacking on the latent layers needs to be done in a few steps.\n",
    "\n",
    "    ## 0. Chop the base model\n",
    "    ## 1. Tack on a pooling layer to reduce the size of the convlutional parameters\n",
    "    ## 2. Determine the size of the output (internally done in ModelTackOn)\n",
    "    ## 3. Tack on a linear layer of the correct size  (internally done in ModelTackOn)\n",
    "\n",
    "    if pref_log_all_steps:\n",
    "        write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}  making combined model...')\n",
    "\n",
    "    model_chopped = torch.nn.Sequential(list(base_model_frozen.children())[0][:params['n_block_toInclude']])  ## 0.\n",
    "    model_chopped_pooled = torch.nn.Sequential(model_chopped, torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten())  ## 1.\n",
    "\n",
    "    image_out_size = list(dataset_train[0][0][0].shape)\n",
    "    data_dim = tuple([1] + list(image_out_size))\n",
    "    \n",
    "    model = ModelTackOn(\n",
    "    #     model_chopped.to('cpu'),\n",
    "        model_chopped_pooled.to('cpu'),\n",
    "        base_model_frozen.to('cpu'),\n",
    "        data_dim=data_dim,\n",
    "        pre_head_fc_sizes=params['pre_head_fc_sizes'], \n",
    "        post_head_fc_sizes=params['post_head_fc_sizes'], \n",
    "        classifier_fc_sizes=None,\n",
    "        nonlinearity=params['head_nonlinearity'],\n",
    "        kwargs_nonlinearity={},\n",
    "    )\n",
    "    return base_model_frozen, model_chopped, model_chopped_pooled, image_out_size, data_dim, model\n",
    "\n",
    "model_from_params(params, pref_log_all_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b84698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'torchvision.models',\n",
       " '__doc__': None,\n",
       " '__package__': 'torchvision.models',\n",
       " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7f9a57cc62e0>,\n",
       " '__spec__': ModuleSpec(name='torchvision.models', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f9a57cc62e0>, origin='/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/__init__.py', submodule_search_locations=['/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models']),\n",
       " '__path__': ['/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models'],\n",
       " '__file__': '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/__init__.py',\n",
       " '__cached__': '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/__pycache__/__init__.cpython-38.pyc',\n",
       " '__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f9b6398cb50>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'Exception': Exception,\n",
       "  'TypeError': TypeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'SystemExit': SystemExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'ImportError': ImportError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'OSError': OSError,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'EOFError': EOFError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'NameError': NameError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'TabError': TabError,\n",
       "  'LookupError': LookupError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ValueError': ValueError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'SystemError': SystemError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'BufferError': BufferError,\n",
       "  'Warning': Warning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2021 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': Type license() to see the full license text,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_imps._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1013__': <capsule object NULL at 0x7f9a64c08c30>,\n",
       "  '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1011__': <capsule object NULL at 0x7f99f94056f0>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9b6398cbe0>>},\n",
       " 'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       " 'AlexNet': torchvision.models.alexnet.AlexNet,\n",
       " 'resnet': <module 'torchvision.models.resnet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/resnet.py'>,\n",
       " 'ResNet': torchvision.models.resnet.ResNet,\n",
       " 'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnext50_32x4d': <function torchvision.models.resnet.resnext50_32x4d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnext101_32x8d': <function torchvision.models.resnet.resnext101_32x8d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'wide_resnet50_2': <function torchvision.models.resnet.wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'wide_resnet101_2': <function torchvision.models.resnet.wide_resnet101_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'vgg': <module 'torchvision.models.vgg' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/vgg.py'>,\n",
       " 'VGG': torchvision.models.vgg.VGG,\n",
       " 'vgg11': <function torchvision.models.vgg.vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg13': <function torchvision.models.vgg.vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg16': <function torchvision.models.vgg.vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg19': <function torchvision.models.vgg.vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'squeezenet': <module 'torchvision.models.squeezenet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/squeezenet.py'>,\n",
       " 'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       " 'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'inception': <module 'torchvision.models.inception' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/inception.py'>,\n",
       " 'Inception3': torchvision.models.inception.Inception3,\n",
       " 'inception_v3': <function torchvision.models.inception.inception_v3(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> 'Inception3'>,\n",
       " 'InceptionOutputs': torchvision.models.inception.InceptionOutputs,\n",
       " '_InceptionOutputs': torchvision.models.inception.InceptionOutputs,\n",
       " 'densenet': <module 'torchvision.models.densenet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/densenet.py'>,\n",
       " 'DenseNet': torchvision.models.densenet.DenseNet,\n",
       " 'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'googlenet': <function torchvision.models.googlenet.googlenet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> 'GoogLeNet'>,\n",
       " 'GoogLeNet': torchvision.models.googlenet.GoogLeNet,\n",
       " 'GoogLeNetOutputs': torchvision.models.googlenet.GoogLeNetOutputs,\n",
       " '_GoogLeNetOutputs': torchvision.models.googlenet.GoogLeNetOutputs,\n",
       " '_utils': <module 'torchvision.models._utils' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/_utils.py'>,\n",
       " 'mobilenetv2': <module 'torchvision.models.mobilenetv2' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/mobilenetv2.py'>,\n",
       " 'mobilenetv3': <module 'torchvision.models.mobilenetv3' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py'>,\n",
       " 'mobilenet': <module 'torchvision.models.mobilenet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/mobilenet.py'>,\n",
       " 'MobileNetV2': torchvision.models.mobilenetv2.MobileNetV2,\n",
       " 'mobilenet_v2': <function torchvision.models.mobilenetv2.mobilenet_v2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mobilenetv2.MobileNetV2>,\n",
       " 'MobileNetV3': torchvision.models.mobilenetv3.MobileNetV3,\n",
       " 'mobilenet_v3_large': <function torchvision.models.mobilenetv3.mobilenet_v3_large(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mobilenetv3.MobileNetV3>,\n",
       " 'mobilenet_v3_small': <function torchvision.models.mobilenetv3.mobilenet_v3_small(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mobilenetv3.MobileNetV3>,\n",
       " 'mnasnet': <module 'torchvision.models.mnasnet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/mnasnet.py'>,\n",
       " 'MNASNet': torchvision.models.mnasnet.MNASNet,\n",
       " 'mnasnet0_5': <function torchvision.models.mnasnet.mnasnet0_5(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mnasnet.MNASNet>,\n",
       " 'mnasnet0_75': <function torchvision.models.mnasnet.mnasnet0_75(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mnasnet.MNASNet>,\n",
       " 'mnasnet1_0': <function torchvision.models.mnasnet.mnasnet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mnasnet.MNASNet>,\n",
       " 'mnasnet1_3': <function torchvision.models.mnasnet.mnasnet1_3(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.mnasnet.MNASNet>,\n",
       " 'shufflenetv2': <module 'torchvision.models.shufflenetv2' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/shufflenetv2.py'>,\n",
       " 'ShuffleNetV2': torchvision.models.shufflenetv2.ShuffleNetV2,\n",
       " 'shufflenet_v2_x0_5': <function torchvision.models.shufflenetv2.shufflenet_v2_x0_5(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.shufflenetv2.ShuffleNetV2>,\n",
       " 'shufflenet_v2_x1_0': <function torchvision.models.shufflenetv2.shufflenet_v2_x1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.shufflenetv2.ShuffleNetV2>,\n",
       " 'shufflenet_v2_x1_5': <function torchvision.models.shufflenetv2.shufflenet_v2_x1_5(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.shufflenetv2.ShuffleNetV2>,\n",
       " 'shufflenet_v2_x2_0': <function torchvision.models.shufflenetv2.shufflenet_v2_x2_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.shufflenetv2.ShuffleNetV2>,\n",
       " 'efficientnet': <module 'torchvision.models.efficientnet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/efficientnet.py'>,\n",
       " 'EfficientNet': torchvision.models.efficientnet.EfficientNet,\n",
       " 'efficientnet_b0': <function torchvision.models.efficientnet.efficientnet_b0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b1': <function torchvision.models.efficientnet.efficientnet_b1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b2': <function torchvision.models.efficientnet.efficientnet_b2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b3': <function torchvision.models.efficientnet.efficientnet_b3(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b4': <function torchvision.models.efficientnet.efficientnet_b4(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b5': <function torchvision.models.efficientnet.efficientnet_b5(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b6': <function torchvision.models.efficientnet.efficientnet_b6(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'efficientnet_b7': <function torchvision.models.efficientnet.efficientnet_b7(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.efficientnet.EfficientNet>,\n",
       " 'regnet': <module 'torchvision.models.regnet' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/regnet.py'>,\n",
       " 'RegNet': torchvision.models.regnet.RegNet,\n",
       " 'regnet_y_400mf': <function torchvision.models.regnet.regnet_y_400mf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_800mf': <function torchvision.models.regnet.regnet_y_800mf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_1_6gf': <function torchvision.models.regnet.regnet_y_1_6gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_3_2gf': <function torchvision.models.regnet.regnet_y_3_2gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_8gf': <function torchvision.models.regnet.regnet_y_8gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_16gf': <function torchvision.models.regnet.regnet_y_16gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_y_32gf': <function torchvision.models.regnet.regnet_y_32gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_400mf': <function torchvision.models.regnet.regnet_x_400mf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_800mf': <function torchvision.models.regnet.regnet_x_800mf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_1_6gf': <function torchvision.models.regnet.regnet_x_1_6gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_3_2gf': <function torchvision.models.regnet.regnet_x_3_2gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_8gf': <function torchvision.models.regnet.regnet_x_8gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_16gf': <function torchvision.models.regnet.regnet_x_16gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'regnet_x_32gf': <function torchvision.models.regnet.regnet_x_32gf(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.regnet.RegNet>,\n",
       " 'segmentation': <module 'torchvision.models.segmentation' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/segmentation/__init__.py'>,\n",
       " 'detection': <module 'torchvision.models.detection' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/detection/__init__.py'>,\n",
       " 'video': <module 'torchvision.models.video' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/video/__init__.py'>,\n",
       " 'quantization': <module 'torchvision.models.quantization' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/quantization/__init__.py'>,\n",
       " 'feature_extraction': <module 'torchvision.models.feature_extraction' from '/home/joz608/.conda/envs/jupyter_launcher/lib/python3.8/site-packages/torchvision/models/feature_extraction.py'>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd136183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - ^C\r\n",
      "\b\bfailed\r\n",
      "\r\n",
      "CondaError: KeyboardInterrupt\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge torchvision==0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183505d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f14c5fc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/n/data1/hms/neurobio/sabatini/josh/analysis/ROI_net_training/simCLR_paramsweep_temp/jobNum_0/train_ROInet_simCLR_20220508.py']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_code = ''\n",
    "\n",
    "# trgrd = False\n",
    "# with open(base_py[0], 'r') as f:\n",
    "# #     display(f.readlines())\n",
    "#     for line in f.readlines():\n",
    "#         if 'Import pretrained model' in line and 'break':\n",
    "#             break\n",
    "#         if 'class ModelTackOn' in line:\n",
    "#             trgrd = True\n",
    "#         if trgrd:\n",
    "#             final_code += line\n",
    "# #             print(line, end='')\n",
    "base_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a66817bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_210073/947108948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbase_model_frozen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'torchvision_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model_frozen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "base_model_frozen = torchvision.models.__dict__[params['torchvision_model']](pretrained=True)\n",
    "\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if pref_log_all_steps:\n",
    "    write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}  imported pretrained model')\n",
    "\n",
    "\n",
    "\n",
    "### Make combined model\n",
    "\n",
    "## Tacking on the latent layers needs to be done in a few steps.\n",
    "\n",
    "## 0. Chop the base model\n",
    "## 1. Tack on a pooling layer to reduce the size of the convlutional parameters\n",
    "## 2. Determine the size of the output (internally done in ModelTackOn)\n",
    "## 3. Tack on a linear layer of the correct size  (internally done in ModelTackOn)\n",
    "\n",
    "if pref_log_all_steps:\n",
    "    write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}  making combined model...')\n",
    "\n",
    "model_chopped = torch.nn.Sequential(list(base_model_frozen.children())[0][:params['n_block_toInclude']])  ## 0.\n",
    "model_chopped_pooled = torch.nn.Sequential(model_chopped, torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten())  ## 1.\n",
    "\n",
    "image_out_size = list(dataset_train[0][0][0].shape)\n",
    "data_dim = tuple([1] + list(image_out_size))\n",
    "\n",
    "## 2. , 3.\n",
    "model = ModelTackOn(\n",
    "#     model_chopped.to('cpu'),\n",
    "    model_chopped_pooled.to('cpu'),\n",
    "    base_model_frozen.to('cpu'),\n",
    "    data_dim=data_dim,\n",
    "    pre_head_fc_sizes=params['pre_head_fc_sizes'], \n",
    "    post_head_fc_sizes=params['post_head_fc_sizes'], \n",
    "    classifier_fc_sizes=None,\n",
    "    nonlinearity=params['head_nonlinearity'],\n",
    "    kwargs_nonlinearity={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1da93862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=12, releaselevel='final', serial=0)\n",
      "jupyter_launcher\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'base_model' and 'un_modified_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_210073/2442705803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelTackOn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'base_model' and 'un_modified_model'"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(base_py[0].split('/')[-1][:-3], base_py[0])\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "module.ModelTackOn()\n",
    "\n",
    "model = module.ModelTackOn(\n",
    "    #     model_chopped.to('cpu'),\n",
    "        model_chopped_pooled.to('cpu'),\n",
    "        base_model_frozen.to('cpu'),\n",
    "        data_dim=data_dim,\n",
    "        pre_head_fc_sizes=params['pre_head_fc_sizes'], \n",
    "        post_head_fc_sizes=params['post_head_fc_sizes'], \n",
    "        classifier_fc_sizes=None,\n",
    "        nonlinearity=params['head_nonlinearity'],\n",
    "        kwargs_nonlinearity={},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c311779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4f836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sesh1 = np.load(r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh1.npy')\n",
    "labels_sesh2 = np.load(r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c0beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16c940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a56d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_make_dataset(X):\n",
    "    out = dataset.dataset_simCLR(\n",
    "        X=torch.as_tensor(X, device='cpu', dtype=torch.float32),\n",
    "        y=torch.as_tensor(torch.zeros(X.shape[0]), device='cpu', dtype=torch.float32),\n",
    "        n_transforms=1,\n",
    "        class_weights=np.array([1]),\n",
    "        transform=scripted_transforms_classifier,\n",
    "        DEVICE='cpu',\n",
    "        dtype_X=torch.float32,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def helper_make_dataloader(ds):\n",
    "    out = torch.utils.data.DataLoader( \n",
    "        ds,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "#         pin_memory=True,\n",
    "#         num_workers=36,\n",
    "#         persistent_workers=True,\n",
    "#         prefetch_factor=2\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_clean = helper_make_dataset(images_labeled_clean)\n",
    "dataloader_labeled_clean = helper_make_dataloader(dataset_labeled_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model.base_model(data[0][0].to(DEVICE)).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_sample_weights(labels):\n",
    "    labels = np.int64(labels.copy())\n",
    "    counts, vals = np.histogram(labels, bins=np.concatenate((np.unique(labels), [labels.max()+1])))\n",
    "    vals = vals[:-1]\n",
    "\n",
    "    n_labels = len(labels)\n",
    "    weights = n_labels / counts\n",
    "    \n",
    "    sample_weights = np.array([weights[l] for l in labels])\n",
    "    \n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents_swt(sfs, swt, device_model):\n",
    "    sfs = torch.as_tensor(np.ascontiguousarray(sfs[None,...]), device=device_model, dtype=torch.float32)\n",
    "    latents_swt = swt(sfs[None,...]).squeeze()\n",
    "    latents_swt = latents_swt.reshape(latents_swt.shape[0], -1)\n",
    "    return latents_swt\n",
    "\n",
    "\n",
    "device_model = torch_helpers.set_device(use_GPU=True)\n",
    "\n",
    "scattering = Scattering2D(J=2, L=8, shape=images_labeled_clean[0].shape[-2:])\n",
    "if device_model != 'cpu':\n",
    "    scattering = scattering.cuda()\n",
    "\n",
    "latents_swt = get_latents_swt(images_labeled_clean, scattering.cuda(), device_model).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.corrcoef(features_nn.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(features_nn, aspect='auto',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac609ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(scipy.stats.zscore(features_nn, axis=0), aspect='auto', vmin=-0.8, vmax=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8095c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn_z = scipy.stats.zscore(features_nn.numpy(), axis=0)\n",
    "features_nn_z = features_nn_z[:, ~np.isnan(features_nn_z[0,:])]\n",
    "features_nn_z = torch.as_tensor(features_nn_z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn_z, rank=40, zscore=True)\n",
    "comp, scores_swt, SVs, EVR_swt = decomposition.torch_pca(latents_swt, rank=20)\n",
    "comp, scores_image, SVs, EVR_image = decomposition.torch_pca(images_labeled_clean.reshape(images_labeled_clean.shape[0], -1), rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e951e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(EVR_nn)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df365f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(torch.corrcoef(features_nn.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54535ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_nn, scores_swt]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_val, labels_train, labels_val = sklearn.model_selection.train_test_split(features_norm, labels_clean, test_size=0.3)\n",
    "print(f'train / test shapes: images_labeled_train, images_labeled_val, labels_train, labels_val: {features_train.shape, features_val.shape, labels_train.shape, labels_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train, acc_val = [], []\n",
    "C_toUse = np.array([1000, 100, 10,1,0.1,0.01,0.001])\n",
    "# C_toUse = np.array([10**-4, 10**-5, 10**-6, 10**-7])\n",
    "# C_toUse = np.array([10**2, 10**3, 10**4, 10**5])\n",
    "for C in C_toUse:\n",
    "    logreg = sklearn.linear_model.LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "#         solve='sag'\n",
    "#         solve='saga'\n",
    "#         solver='newton-cg',\n",
    "#         solver='liblinear',\n",
    "        max_iter=6000, \n",
    "        C=C,\n",
    "        fit_intercept=True, \n",
    "        class_weight='balanced',\n",
    "    #     n_jobs=-1\n",
    "    )\n",
    "    logreg.fit(features_train, labels_train)\n",
    "\n",
    "    acc = logreg.score(features_train, labels_train, sample_weight=get_balanced_sample_weights(labels_train))\n",
    "    acc_train.append(acc)\n",
    "\n",
    "    acc = logreg.score(features_val, labels_val, sample_weight=get_balanced_sample_weights(labels_val))\n",
    "    acc_val.append(acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a622ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);\n",
    "\n",
    "print(f'best val score: {max(acc_val)}')\n",
    "print(f'best C value: {C_toUse[np.argmax(acc_val)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "#         solver='sag',\n",
    "#         solver='saga',\n",
    "#         solver='newton-cg',\n",
    "#         solver='liblinear',\n",
    "    max_iter=8000, \n",
    "    C=10**(0),\n",
    "    fit_intercept=True, \n",
    "    class_weight='balanced',\n",
    "#     n_jobs=-1\n",
    ").fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = sklearn.svm.SVC(\n",
    "    C=10**(1), \n",
    "    kernel='rbf',\n",
    "    degree=3, \n",
    "    gamma='scale',\n",
    "    coef0=0.0, \n",
    "    shrinking=True,\n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200,\n",
    "    class_weight='balanced',\n",
    "    verbose=False, \n",
    "    max_iter=- 1, \n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=None\n",
    ")\n",
    "svm.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = logreg.predict_proba(features_train)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "\n",
    "# preds = svm.predict(features_train_norm).astype(np.int32)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_train.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_val.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee16a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sesh12cat = np.concatenate((labels_sesh1, labels_sesh2), axis=0)\n",
    "labels_sesh21cat = np.concatenate((labels_sesh2, labels_sesh1), axis=0)\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    classification.confusion_matrix(labels_sesh12cat.astype(np.int32), labels_sesh21cat.astype(np.int32)),\n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 16}, \n",
    "    vmax=1., \n",
    "    cmap=plt.get_cmap('gray')\n",
    ")\n",
    "plt.title('relabeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba003ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(name, params.shape) for name, params in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d55010",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['base_model.0.0.0.weight'].cpu()\n",
    "# layer_2 = model.state_dict()['base_model.0.6.3.block.1.0.weight'].cpu()\n",
    "# layer_3 = model.state_dict()['base_model.0.7.0.block.1.0.weight'].cpu()\n",
    "# layer_4 = model.state_dict()['base_model.0.7.0.block.1.0.weight'].cpu()\n",
    "\n",
    "\n",
    "plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_1], dim=0), grid_shape=(15,15), kwargs_imshow={'vmax': 0.2});\n",
    "# plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_2], dim=0), grid_shape=(6,6), kwargs_imshow={'vmax': 0.2});\n",
    "# plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_3], dim=0), grid_shape=(4,6), kwargs_imshow={'vmax': 0.2});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(\n",
    "    n_neighbors=30,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    metric_kwds=None,\n",
    "    output_metric='euclidean',\n",
    "    output_metric_kwds=None,\n",
    "    n_epochs=None,\n",
    "    learning_rate=1.0,\n",
    "    init='spectral',\n",
    "    min_dist=0.1,\n",
    "    spread=1.0,\n",
    "    low_memory=True,\n",
    "    n_jobs=-1,\n",
    "    set_op_mix_ratio=1.0,\n",
    "    local_connectivity=1.0,\n",
    "    repulsion_strength=1.0,\n",
    "    negative_sample_rate=5,\n",
    "    transform_queue_size=4.0,\n",
    "    a=None,\n",
    "    b=None,\n",
    "    random_state=None,\n",
    "    angular_rp_forest=False,\n",
    "    target_n_neighbors=-1,\n",
    "    target_metric='categorical',\n",
    "    target_metric_kwds=None,\n",
    "    target_weight=0.5,\n",
    "    transform_seed=42,\n",
    "    transform_mode='embedding',\n",
    "    force_approximation_algorithm=False,\n",
    "    verbose=False,\n",
    "    tqdm_kwds=None,\n",
    "    unique=False,\n",
    "    densmap=False,\n",
    "    dens_lambda=2.0,\n",
    "    dens_frac=0.3,\n",
    "    dens_var_shift=0.1,\n",
    "    output_dens=False,\n",
    "    disconnection_distance=None,\n",
    "    precomputed_knn=(None, None, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ccd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = umap.fit_transform(features_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82913e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], s=5, c=labels_clean, cmap='gist_rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08307b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(scores_nn[:,1], scores_nn[:,0], c=labels_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
