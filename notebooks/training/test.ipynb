{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCaMP_ROI_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a19cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping GCaMP_ROI_classifier as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip uninstall GCaMP_ROI_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "## Import general libraries\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "### Import personal libraries\n",
    "dir_github = '/media/rich/Home_Linux_partition/github_repos'\n",
    "import sys\n",
    "sys.path.append(dir_github)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from basic_neural_processing_modules import indexing, server\n",
    "\n",
    "\n",
    "## set paths\n",
    "dir_save = '/media/rich/bigSSD/'\n",
    "\n",
    "path_script = '/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/scripts/20220508_simCLR/train_ROInet_simCLR_20220508.py'\n",
    "\n",
    "\n",
    "\n",
    "## define params\n",
    "params_template = {\n",
    "    'paths': {\n",
    "        'dir_github':'/media/rich/Home_Linux_partition/github_repos',\n",
    "        'fileName_save_model':'EfficientNet_b0_7unfrozen_simCLR',\n",
    "        'path_data_training':'/media/rich/bigSSD/analysis_data/ROIs_for_training/sf_sparse_36x36_20220503.npz',\n",
    "    },\n",
    "    \n",
    "    'prefs': {\n",
    "        'saveModelIteratively':True,\n",
    "        'saveLogs':True,\n",
    "    },\n",
    "    \n",
    "    'useGPU_training': True,\n",
    "    'useGPU_dataloader': False,\n",
    "    'dataloader_kwargs':{\n",
    "        'batch_size': 1024,\n",
    "        'shuffle': True,\n",
    "        'drop_last': True,\n",
    "        'pin_memory': True,\n",
    "        'num_workers': 36,\n",
    "        'persistent_workers': True,\n",
    "        'prefetch_factor': 2,\n",
    "    },\n",
    "\n",
    "    'pre_head_fc_sizes': [128, 128],\n",
    "    'post_head_fc_sizes': [128],\n",
    "    'block_to_unfreeze': '1.2',\n",
    "    'n_block_toInclude': 4,\n",
    "    \n",
    "    'lr': 1*10**-4,\n",
    "    'gamma': 1-0.0000,\n",
    "    'n_epochs': 9999999,\n",
    "    'temperature': 0.5,\n",
    "    \n",
    "    'augmentation': {\n",
    "        'Scale_image_sum': {'sum_val':1, 'epsilon':1e-9, 'min_sub':True},\n",
    "        'AddPoissonNoise': {'scaler_bounds':(10**(4), 10**(5)), 'prob':0.5, 'base':1000, 'scaling':'log'},\n",
    "        'Horizontal_stripe_scale': {'alpha_min_max':(0.5, 1), 'im_size':(36,36), 'prob':0.5},\n",
    "        'Horizontal_stripe_shift': {'alpha_min_max':(1  , 3), 'im_size':(36,36), 'prob':0.5},\n",
    "        'RandomHorizontalFlip': {'p':0.5},\n",
    "        'RandomAffine': {\n",
    "            'degrees':(-180,180),\n",
    "            'translate':(0.1, 0.1), #0, .3, .45 (DEFAULT)\n",
    "            'scale':(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "            'shear':(-15, 15, -15, 15),\n",
    "#             'interpolation':torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "            'interpolation':'bilinear', \n",
    "            'fill':0, \n",
    "            'fillcolor':None, \n",
    "            'resample':None,\n",
    "        },\n",
    "        'AddGaussianNoise': {'mean':0, 'std':0.0010, 'prob':0.5},\n",
    "        'ScaleDynamicRange': {'scaler_bounds':(0,1), 'epsilon':1e-9},\n",
    "        'WarpPoints': {\n",
    "            'r':[0.3, 0.6],\n",
    "            'cx':[-0.3, 0.3],\n",
    "            'cy':[-0.3, 0.3], \n",
    "            'dx':[-0.24, 0.24], \n",
    "            'dy':[-0.24, 0.24], \n",
    "            'n_warps':2,\n",
    "            'prob':0.5,\n",
    "            'img_size_in':[36, 36],\n",
    "            'img_size_out':[72,72],\n",
    "        },\n",
    "        'TileChannels': {'dim':0, 'n_channels':3},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## make params dicts with grid swept values\n",
    "params = copy.deepcopy(params_template)\n",
    "params = [indexing.deep_update_dict(params, ['dataloader_kwargs', 'prefetch_factor'], val) for ii,val in enumerate([4,5,6])]\n",
    "params = [indexing.deep_update_dict(params[ii], ['block_to_unfreeze'], val) for ii,val in enumerate(['1.0', '1.0', '1.0'])]\n",
    "params = indexing.flatten_list([[indexing.deep_update_dict(params[ii], ['lr'], val) for jj,val in enumerate([0.00001, 0.0001, 0.001])] for ii in range(3)])\n",
    "\n",
    "params_unchanging, params_changing = indexing.find_differences_across_dictionaries(params)\n",
    "\n",
    "\n",
    "\n",
    "## copy script .py file to dir_save\n",
    "import shutil\n",
    "shutil.copy2(path_script, str(Path(dir_save) / Path(path_script).name));\n",
    "\n",
    "\n",
    "\n",
    "## save parameters to file\n",
    "parameters_batch = {\n",
    "    'params': params,\n",
    "    'params_unchanging': params_unchanging,\n",
    "    'params_changing': params_changing\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(str(Path(dir_save) / 'parameters_batch.json'), 'w') as f:\n",
    "    json.dump(parameters_batch, f)\n",
    "\n",
    "# with open(str(Path(dir_save) / 'parameters_batch.json')) as f:\n",
    "#     test = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "## define slurm SBATCH parameters\n",
    "sbatch_config_default = \\\n",
    "\"\"\"#!/usr/bin/bash\n",
    "#SBATCH --job-name=python_test\n",
    "#SBATCH --output=/home/rh183/script_logs/python_01_%j.log\n",
    "#SBATCH --partition=priority\n",
    "#SBATCH -c 1\n",
    "#SBATCH -n 1\n",
    "#SBATCH --mem=1GB\n",
    "#SBATCH --time=0-00:00:10\n",
    "\n",
    "python \"$@\"\n",
    "\"\"\"\n",
    "\n",
    "## run batch_run function\n",
    "paths_scripts = [path_script]\n",
    "params_list = params\n",
    "sbatch_config_list = [sbatch_config_default]\n",
    "max_n_jobs=3\n",
    "dir_save='/n/data1/hms/neurobio/sabatini/rich/analysis/test_dispatcher_ROInet'\n",
    "name_save='jobNum_'\n",
    "\n",
    "server.batch_run(paths_scripts=paths_scripts,\n",
    "                    params_list=params_list,\n",
    "                    sbatch_config_list=sbatch_config_list,\n",
    "                    max_n_jobs=2,\n",
    "                    dir_save=dir_save,\n",
    "                    name_save='jobNum_',\n",
    "                    verbose=True,\n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
