{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "S3q3I42jDB0f",
    "outputId": "3ad88a07-0e8b-474f-b0d8-9fb6c2a99f0c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139469/1226147920.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PUUWS0VmwD7-"
   },
   "outputs": [],
   "source": [
    "# # !source activate jupyter_launcher\n",
    "# !pip3 install numba\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install scipy\n",
    "# !pip3 install torch\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install sklearn\n",
    "# !pip3 install pycuda\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install h5py\n",
    "# !pip3 install hdfdict\n",
    "# !pip3 install ipywidgets\n",
    "# !pip3 install numpy==1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eTIgCGQsDB0i"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse arguments\n",
    "\n",
    "# import sys\n",
    "# path_script, path_params, dir_save = sys.argv\n",
    "                \n",
    "# import json\n",
    "# with open(path_params, 'r') as f:\n",
    "#     params = json.load(f)\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy2(path_script, str(Path(dir_save) / Path(path_script).name));\n",
    "\n",
    "\n",
    "# dir_save = '/media/rich/bigSSD/analysis_data/ROI_net_training/testing_dispatcher_20220504'\n",
    "dir_save = Path(r'/media/rich/bigSSD/')\n",
    "\n",
    "# params_template = {\n",
    "params = {\n",
    "    'pref_log_all_steps': True,\n",
    "    'paths': {\n",
    "        'dir_github': '/media/rich/Home_Linux_partition/github_repos',\n",
    "#         'dir_github': dir_github,\n",
    "        'fileName_save_model': 'ConvNext_tiny__1_0_unfrozen__simCLR',\n",
    "        'path_data_training': '/media/rich/bigSSD/analysis_data/ROIs_for_training/sf_sparse_36x36_20220503.npz',\n",
    "#         'path_data_training': '/n/data1/hms/neurobio/sabatini/rich/data/ROI_network_data/sf_sparse_36x36_20220503.npz',\n",
    "    },\n",
    "    \n",
    "    'prefs': {\n",
    "        'saveModelIteratively':True,\n",
    "        'saveLogs':True,\n",
    "    },\n",
    "    \n",
    "    'useGPU_training': True,\n",
    "    'useGPU_dataloader': False,\n",
    "    'dataloader_kwargs':{\n",
    "        'batch_size': 1024,\n",
    "        'shuffle': True,\n",
    "        'drop_last': True,\n",
    "        'pin_memory': True,\n",
    "        # 'num_workers': 18,\n",
    "        # 'persistent_workers': True,\n",
    "        # 'prefetch_factor': 2,\n",
    "        'num_workers': 4,\n",
    "        'persistent_workers': True,\n",
    "        'prefetch_factor': 1,\n",
    "    },\n",
    "    'inner_batch_size': 256,\n",
    "\n",
    "    'torchvision_model': 'convnext_tiny',\n",
    "\n",
    "    'head_pool_method': 'AdaptiveAvgPool2d',\n",
    "    'head_pool_method_kwargs': {'output_size': 1},\n",
    "    'pre_head_fc_sizes': [256, 128],\n",
    "    'post_head_fc_sizes': [128],\n",
    "    'block_to_unfreeze': '6.0',\n",
    "    'n_block_toInclude': 9,\n",
    "    'head_nonlinearity': 'GELU',\n",
    "    'head_nonlinearity_kwargs': {},\n",
    "\n",
    "    'lr': 1*10**-2.5,\n",
    "    'penalty_orthogonality':0.00,\n",
    "    'weight_decay': 0.0000,\n",
    "    'gamma': 1-0.0000,\n",
    "    'n_epochs': 9999999,\n",
    "    'temperature': 0.1,\n",
    "    'l2_alpha': 0.0000,\n",
    "    \n",
    "    'augmentation': {\n",
    "        'Scale_image_sum': {'sum_val':1, 'epsilon':1e-9, 'min_sub':True},\n",
    "        'AddPoissonNoise': {'scaler_bounds':(1.0*10**(3.5), 1.0*10**(4)), 'prob':0.7, 'base':1000, 'scaling':'log'},\n",
    "        'Horizontal_stripe_scale': {'alpha_min_max':(0.5, 1), 'im_size':(36,36), 'prob':0.3},\n",
    "        'Horizontal_stripe_shift': {'alpha_min_max':(1  , 2), 'im_size':(36,36), 'prob':0.3},\n",
    "        'RandomHorizontalFlip': {'p':0.5},\n",
    "        'RandomAffine': {\n",
    "            'degrees':(-180,180),\n",
    "            'translate':(0.1, 0.1), #0, .3, .45 (DEFAULT)\n",
    "            'scale':(0.6, 1.2), # no scale (1,1), (0.4, 1.5)\n",
    "            'shear':(-8, 8, -8, 8),\n",
    "#             'interpolation':torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "            'interpolation':'bilinear', \n",
    "            'fill':0, \n",
    "            'fillcolor':None, \n",
    "            'resample':None,\n",
    "        },\n",
    "        'AddGaussianNoise': {'mean':0, 'std':0.0010, 'prob':0.5},\n",
    "        'ScaleDynamicRange': {'scaler_bounds':(0,1), 'epsilon':1e-9},\n",
    "        'WarpPoints': {\n",
    "            'r':[0.3, 0.6],\n",
    "            'cx':[-0.3, 0.3],\n",
    "            'cy':[-0.3, 0.3], \n",
    "            'dx':[-0.24, 0.24], \n",
    "            'dy':[-0.24, 0.24], \n",
    "            'n_warps':2,\n",
    "            'prob':0.5,\n",
    "            'img_size_in':[36, 36],\n",
    "#             'img_size_out':[72,72],\n",
    "            'img_size_out':[224,224],\n",
    "        },\n",
    "        'TileChannels': {'dim':0, 'n_channels':3},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GExNkvATEBtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import personal libraries\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(params['paths']['dir_github'])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import torch_helpers, math_functions, classification, h5_handling, plotting_helpers, indexing, misc, decomposition, path_helpers\n",
    "from GCaMP_ROI_classifier import util, models, training, augmentation, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_log(path_log, text, mode='a', start_on_new_line=True):\n",
    "    with open(path_log, mode=mode) as log:\n",
    "        if start_on_new_line==True:\n",
    "            log.write('\\n')\n",
    "        log.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare paths\n",
    "\n",
    "path_saveModel = str((dir_save / params['paths']['fileName_save_model']).with_suffix('.pth'))\n",
    "path_saveLog = str(dir_save / 'log.txt')\n",
    "path_saveLoss = (dir_save / 'loss.npy')\n",
    "\n",
    "device_train = torch_helpers.set_device(use_GPU=params['useGPU_training'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_log(path_log=path_saveLog, text=f'sys.version: {sys.version_info}')\n",
    "write_to_log(path_log=path_saveLog, text=f\"sys.version: {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hTqZzmpJDB0j"
   },
   "outputs": [],
   "source": [
    "### Import unlabeled training data\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "sf_sparse = scipy.sparse.load_npz(params['paths']['path_data_training'])\n",
    "\n",
    "sf_dense = torch.as_tensor(sf_sparse.toarray().reshape(sf_sparse.shape[0], 36,36), dtype=torch.float32)\n",
    "\n",
    "##toss any NaNs\n",
    "\n",
    "# print(f'Number of masks: {sf_dense.shape}')\n",
    "ROIs_without_NaNs = ~torch.any(torch.any(torch.isnan(sf_dense), dim=1), dim=1)\n",
    "ROIs_nonAllZero = (torch.max(torch.max(sf_dense, dim=1)[0], dim=1)[0] > 0)\n",
    "ROIs_toKeep = torch.where(ROIs_without_NaNs * ROIs_nonAllZero)[0]\n",
    "masks_cat = sf_dense[ROIs_toKeep]\n",
    "\n",
    "n_masks_removed = np.sum(sf_dense.shape[0] - ROIs_toKeep.shape[0])\n",
    "# print(f'Number of masks: {masks_cat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T2ARByXvDB0s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: 'cpu'\n"
     ]
    }
   ],
   "source": [
    "### Define augmentation pipeline\n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    *[augmentation.__dict__[key](**params) for key,params in params['augmentation'].items()]\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "\n",
    "device_dataloader = torch_helpers.set_device(use_GPU=params['useGPU_dataloader'])\n",
    "\n",
    "dataset_train = dataset.dataset_simCLR(\n",
    "    torch.as_tensor(masks_cat, device=device_dataloader, dtype=torch.float32), \n",
    "    torch.as_tensor(torch.zeros(masks_cat.shape[0]), device=device_dataloader, dtype=torch.float32),\n",
    "    n_transforms=2,\n",
    "    class_weights=np.array([1]),\n",
    "    # class_weights=np.array([1]*4)[np.random.randint(0,4, X_train.shape[0])],\n",
    "    transform=scripted_transforms,\n",
    "    # DEVICE='cpu',\n",
    "    DEVICE=device_dataloader,\n",
    "    dtype_X=torch.float32,\n",
    "    dtype_y=torch.int64,\n",
    "    # temp_uncertainty=1\n",
    ")\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    **params['dataloader_kwargs']\n",
    "\n",
    "#     batch_size=1024,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=36,\n",
    "#     persistent_workers=True,\n",
    "#     prefetch_factor=3,\n",
    "    \n",
    "#     batch_size=1024,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=False,\n",
    "#     num_workers=36,\n",
    "#     persistent_workers=True,\n",
    "#     prefetch_factor=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib notebook\n",
    "\n",
    "# idx_rand = np.random.randint(0,masks_cat.shape[0], 10)\n",
    "# for ii in idx_rand:\n",
    "#     fig, axs = plt.subplots(1,2)\n",
    "#     # print(dataset_train[ii][0][0][0].shape)\n",
    "#     axs[0].imshow(dataset_train[ii][0][0][0].cpu())\n",
    "#     axs[1].imshow(dataset_train[ii][0][1][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3aA1-hY4DB0v"
   },
   "outputs": [],
   "source": [
    "### Define ModelTackOn\n",
    "\n",
    "class ModelTackOn(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        base_model, \n",
    "        un_modified_model,\n",
    "        data_dim=(1,3,36,36), \n",
    "        pre_head_fc_sizes=[100], \n",
    "        post_head_fc_sizes=[100], \n",
    "        classifier_fc_sizes=None, \n",
    "        nonlinearity='relu', \n",
    "        kwargs_nonlinearity={},\n",
    "    ):\n",
    "            super(ModelTackOn, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            final_base_layer = list(un_modified_model.children())[-1]\n",
    "            # final_base_layer = list(list(model.children())[-1].children())[-1]\n",
    "            # print(final_base_layer)\n",
    "            \n",
    "            self.data_dim = data_dim\n",
    "\n",
    "            self.pre_head_fc_lst = []\n",
    "            self.post_head_fc_lst = []\n",
    "            self.classifier_fc_lst = []\n",
    "                \n",
    "            self.nonlinearity = nonlinearity\n",
    "            self.kwargs_nonlinearity = kwargs_nonlinearity\n",
    "\n",
    "            self.init_prehead(final_base_layer, pre_head_fc_sizes)\n",
    "            self.init_posthead(pre_head_fc_sizes[-1], post_head_fc_sizes)\n",
    "            if classifier_fc_sizes is not None:\n",
    "                self.init_classifier(pre_head_fc_sizes[-1], classifier_fc_sizes)\n",
    "            \n",
    "    def init_prehead(self, prv_layer, pre_head_fc_sizes):\n",
    "        for i, pre_head_fc in enumerate(pre_head_fc_sizes):\n",
    "            if i == 0:\n",
    "#                 in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 1280\n",
    "#                 in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 960\n",
    "#                 in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 768\n",
    "#                 in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 1536\n",
    "#                 in_features = prv_layer.in_features if hasattr(prv_layer,'in_features') else 1024\n",
    "                in_features = self.base_model(torch.rand(*(self.data_dim))).data.squeeze().shape[0]  ## RH EDIT\n",
    "            else:\n",
    "                in_features = pre_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=pre_head_fc)\n",
    "            self.add_module(f'PreHead_{i}', fc_layer)\n",
    "            self.pre_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#             if i < len(pre_head_fc_sizes) - 1:\n",
    "#             non_linearity = torch.nn.ReLU()\n",
    "#             non_linearity = torch.nn.GELU()\n",
    "            non_linearity = torch.nn.__dict__[self.nonlinearity](**self.kwargs_nonlinearity)\n",
    "            self.add_module(f'PreHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "\n",
    "    def init_posthead(self, prv_size, post_head_fc_sizes):\n",
    "        for i, post_head_fc in enumerate(post_head_fc_sizes):\n",
    "            if i == 0:\n",
    "                in_features = prv_size\n",
    "            else:\n",
    "                in_features = post_head_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=post_head_fc)\n",
    "            self.add_module(f'PostHead_{i}', fc_layer)\n",
    "            self.post_head_fc_lst.append(fc_layer)\n",
    "\n",
    "#                 non_linearity = torch.nn.ReLU()\n",
    "#                 non_linearity = torch.nn.GELU()\n",
    "            non_linearity = torch.nn.__dict__[self.nonlinearity](**self.kwargs_nonlinearity)    \n",
    "            self.add_module(f'PostHead_{i}_NonLinearity', non_linearity)\n",
    "            self.pre_head_fc_lst.append(non_linearity)\n",
    "    \n",
    "    def init_classifier(self, prv_size, classifier_fc_sizes):\n",
    "            for i, classifier_fc in enumerate(classifier_fc_sizes):\n",
    "                if i == 0:\n",
    "                    in_features = prv_size\n",
    "                else:\n",
    "                    in_features = classifier_fc_sizes[i - 1]\n",
    "            fc_layer = torch.nn.Linear(in_features=in_features, out_features=classifier_fc)\n",
    "            self.add_module(f'Classifier_{i}', fc_layer)\n",
    "            self.classifier_fc_lst.append(fc_layer)\n",
    "\n",
    "    def reinit_classifier(self):\n",
    "        for i_layer, layer in enumerate(self.classifier_fc_lst):\n",
    "            layer.reset_parameters()\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         interim = self.base_model(X)\n",
    "#         interim = self.get_head(interim)\n",
    "#         interim = self.get_latent(interim)\n",
    "#         return interim\n",
    "\n",
    "    def forward_classifier(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.classify(interim)\n",
    "        return interim\n",
    "\n",
    "    def forward_latent(self, X):\n",
    "        interim = self.base_model(X)\n",
    "        interim = self.get_head(interim)\n",
    "        interim = self.get_latent(interim)\n",
    "        return interim\n",
    "\n",
    "\n",
    "    def get_head(self, base_out):\n",
    "        # print('base_out', base_out.shape)\n",
    "        head = base_out\n",
    "        for pre_head_layer in self.pre_head_fc_lst:\n",
    "          # print('pre_head_layer', pre_head_layer.in_features)\n",
    "          head = pre_head_layer(head)\n",
    "          # print('head', head.shape)\n",
    "        return head\n",
    "\n",
    "    def get_latent(self, head):\n",
    "        latent = head\n",
    "        for post_head_layer in self.post_head_fc_lst:\n",
    "            latent = post_head_layer(latent)\n",
    "        return latent\n",
    "\n",
    "    def classify(self, head):\n",
    "        logit = head\n",
    "        for classifier_layer in self.classifier_fc_lst:\n",
    "            logit = classifier_layer(logit)\n",
    "        return logit\n",
    "\n",
    "    def set_pre_head_grad(self, requires_grad=True):\n",
    "        for layer in self.pre_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "                \n",
    "    def set_post_head_grad(self, requires_grad=True):\n",
    "        for layer in self.post_head_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def set_classifier_grad(self, requires_grad=True):\n",
    "        for layer in self.classifier_fc_lst:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def prep_contrast(self):\n",
    "        self.set_pre_head_grad(requires_grad=True)\n",
    "        self.set_post_head_grad(requires_grad=True)\n",
    "        self.set_classifier_grad(requires_grad=False)\n",
    "\n",
    "    def prep_classifier(self):\n",
    "        self.set_pre_head_grad(requires_grad=False)\n",
    "        self.set_post_head_grad(requires_grad=False)\n",
    "        self.set_classifier_grad(requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oyjLftj_cEGW"
   },
   "outputs": [],
   "source": [
    "### Import pretrained model\n",
    "\n",
    "import torchvision.models\n",
    "\n",
    "# base_model_frozen = torchvision.models.resnet101(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet18(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# base_model_frozen = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# base_model_frozen = torchvision.models.convnext_tiny(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.convnext_small(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.convnext_base(pretrained=True)\n",
    "# base_model_frozen = torchvision.models.convnext_large(pretrained=True)\n",
    "\n",
    "\n",
    "# base_model_frozen = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "base_model_frozen = torchvision.models.__dict__[params['torchvision_model']](pretrained=True)\n",
    "\n",
    "for param in base_model_frozen.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_frozen2 = torchvision.models.__dict__[params['torchvision_model']](pretrained=True)\n",
    "# model_chopped2 = torch.nn.Sequential(list(base_model_frozen2.children())[0][:params['n_block_toInclude']])  ## 0.\n",
    "# model_chopped_pooled2 = torch.nn.Sequential(model_chopped2, torch.nn.AdaptiveAvgPool2d(output_size=1), torch.nn.Flatten())  ## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_E18ZEzpClNd"
   },
   "outputs": [],
   "source": [
    "### Make combined model\n",
    "\n",
    "## Tacking on the latent layers needs to be done in a few steps.\n",
    "\n",
    "## 0. Chop the base model\n",
    "## 1. Tack on a pooling layer to reduce the size of the convlutional parameters\n",
    "## 2. Determine the size of the output (internally done in ModelTackOn)\n",
    "## 3. Tack on a linear layer of the correct size  (internally done in ModelTackOn)\n",
    "\n",
    "\n",
    "model_chopped = torch.nn.Sequential(list(base_model_frozen.children())[0][:params['n_block_toInclude']])  ## 0.\n",
    "model_chopped_pooled = torch.nn.Sequential(model_chopped, torch.nn.__dict__[params['head_pool_method']](**params['head_pool_method_kwargs']), torch.nn.Flatten())  ## 1.\n",
    "\n",
    "image_out_size = list(dataset_train[0][0][0].shape)\n",
    "data_dim = tuple([1] + list(image_out_size))\n",
    "\n",
    "## 2. , 3.\n",
    "model = ModelTackOn(\n",
    "#     model_chopped.to('cpu'),\n",
    "    model_chopped_pooled.to('cpu'),\n",
    "    base_model_frozen.to('cpu'),\n",
    "    data_dim=data_dim,\n",
    "    pre_head_fc_sizes=params['pre_head_fc_sizes'], \n",
    "    post_head_fc_sizes=params['post_head_fc_sizes'], \n",
    "    classifier_fc_sizes=None,\n",
    "    nonlinearity=params['head_nonlinearity'],\n",
    "    kwargs_nonlinearity=params['head_nonlinearity_kwargs'],\n",
    ")\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### unfreeze particular blocks in model\n",
    "\n",
    "mnp = [name for name, param in model.named_parameters()]  ## 'model named parameters'\n",
    "mnp_blockNums = [name[name.find('.'):name.find('.')+8] for name in mnp]  ## pulls out the numbers just after the model name\n",
    "mnp_nums = [path_helpers.get_nums_from_string(name) for name in mnp_blockNums]  ## converts them to numbers\n",
    "block_to_freeze_nums = path_helpers.get_nums_from_string(params['block_to_unfreeze'])  ## converts the input parameter specifying the block to freeze into a number for comparison\n",
    "\n",
    "m_baseName = mnp[0][:mnp[0].find('.')]\n",
    "\n",
    "for ii, (name, param) in enumerate(model.named_parameters()):\n",
    "    if m_baseName in name:\n",
    "#         print(name)\n",
    "        if mnp_nums[ii] < block_to_freeze_nums:\n",
    "            param.requires_grad = False\n",
    "        elif mnp_nums[ii] >= block_to_freeze_nums:\n",
    "            param.requires_grad = True\n",
    "\n",
    "names_layers_requiresGrad = [( param.requires_grad , name ) for name,param in list(model.named_parameters())]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[name for name,val in base_model_frozen.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, 'base_model.0.0.0.0.weight'),\n",
       " (False, 'base_model.0.0.0.0.bias'),\n",
       " (False, 'base_model.0.0.0.1.weight'),\n",
       " (False, 'base_model.0.0.0.1.bias'),\n",
       " (False, 'base_model.0.0.1.0.layer_scale'),\n",
       " (False, 'base_model.0.0.1.0.block.0.weight'),\n",
       " (False, 'base_model.0.0.1.0.block.0.bias'),\n",
       " (False, 'base_model.0.0.1.0.block.2.weight'),\n",
       " (False, 'base_model.0.0.1.0.block.2.bias'),\n",
       " (False, 'base_model.0.0.1.0.block.3.weight'),\n",
       " (False, 'base_model.0.0.1.0.block.3.bias'),\n",
       " (False, 'base_model.0.0.1.0.block.5.weight'),\n",
       " (False, 'base_model.0.0.1.0.block.5.bias'),\n",
       " (False, 'base_model.0.0.1.1.layer_scale'),\n",
       " (False, 'base_model.0.0.1.1.block.0.weight'),\n",
       " (False, 'base_model.0.0.1.1.block.0.bias'),\n",
       " (False, 'base_model.0.0.1.1.block.2.weight'),\n",
       " (False, 'base_model.0.0.1.1.block.2.bias'),\n",
       " (False, 'base_model.0.0.1.1.block.3.weight'),\n",
       " (False, 'base_model.0.0.1.1.block.3.bias'),\n",
       " (False, 'base_model.0.0.1.1.block.5.weight'),\n",
       " (False, 'base_model.0.0.1.1.block.5.bias'),\n",
       " (False, 'base_model.0.0.1.2.layer_scale'),\n",
       " (False, 'base_model.0.0.1.2.block.0.weight'),\n",
       " (False, 'base_model.0.0.1.2.block.0.bias'),\n",
       " (False, 'base_model.0.0.1.2.block.2.weight'),\n",
       " (False, 'base_model.0.0.1.2.block.2.bias'),\n",
       " (False, 'base_model.0.0.1.2.block.3.weight'),\n",
       " (False, 'base_model.0.0.1.2.block.3.bias'),\n",
       " (False, 'base_model.0.0.1.2.block.5.weight'),\n",
       " (False, 'base_model.0.0.1.2.block.5.bias'),\n",
       " (False, 'base_model.0.0.2.0.weight'),\n",
       " (False, 'base_model.0.0.2.0.bias'),\n",
       " (False, 'base_model.0.0.2.1.weight'),\n",
       " (False, 'base_model.0.0.2.1.bias'),\n",
       " (False, 'base_model.0.0.3.0.layer_scale'),\n",
       " (False, 'base_model.0.0.3.0.block.0.weight'),\n",
       " (False, 'base_model.0.0.3.0.block.0.bias'),\n",
       " (False, 'base_model.0.0.3.0.block.2.weight'),\n",
       " (False, 'base_model.0.0.3.0.block.2.bias'),\n",
       " (False, 'base_model.0.0.3.0.block.3.weight'),\n",
       " (False, 'base_model.0.0.3.0.block.3.bias'),\n",
       " (False, 'base_model.0.0.3.0.block.5.weight'),\n",
       " (False, 'base_model.0.0.3.0.block.5.bias'),\n",
       " (False, 'base_model.0.0.3.1.layer_scale'),\n",
       " (False, 'base_model.0.0.3.1.block.0.weight'),\n",
       " (False, 'base_model.0.0.3.1.block.0.bias'),\n",
       " (False, 'base_model.0.0.3.1.block.2.weight'),\n",
       " (False, 'base_model.0.0.3.1.block.2.bias'),\n",
       " (False, 'base_model.0.0.3.1.block.3.weight'),\n",
       " (False, 'base_model.0.0.3.1.block.3.bias'),\n",
       " (False, 'base_model.0.0.3.1.block.5.weight'),\n",
       " (False, 'base_model.0.0.3.1.block.5.bias'),\n",
       " (False, 'base_model.0.0.3.2.layer_scale'),\n",
       " (False, 'base_model.0.0.3.2.block.0.weight'),\n",
       " (False, 'base_model.0.0.3.2.block.0.bias'),\n",
       " (False, 'base_model.0.0.3.2.block.2.weight'),\n",
       " (False, 'base_model.0.0.3.2.block.2.bias'),\n",
       " (False, 'base_model.0.0.3.2.block.3.weight'),\n",
       " (False, 'base_model.0.0.3.2.block.3.bias'),\n",
       " (False, 'base_model.0.0.3.2.block.5.weight'),\n",
       " (False, 'base_model.0.0.3.2.block.5.bias'),\n",
       " (False, 'base_model.0.0.4.0.weight'),\n",
       " (False, 'base_model.0.0.4.0.bias'),\n",
       " (False, 'base_model.0.0.4.1.weight'),\n",
       " (False, 'base_model.0.0.4.1.bias'),\n",
       " (False, 'base_model.0.0.5.0.layer_scale'),\n",
       " (False, 'base_model.0.0.5.0.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.0.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.0.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.0.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.0.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.0.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.0.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.0.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.1.layer_scale'),\n",
       " (False, 'base_model.0.0.5.1.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.1.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.1.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.1.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.1.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.1.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.1.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.1.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.2.layer_scale'),\n",
       " (False, 'base_model.0.0.5.2.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.2.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.2.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.2.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.2.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.2.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.2.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.2.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.3.layer_scale'),\n",
       " (False, 'base_model.0.0.5.3.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.3.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.3.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.3.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.3.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.3.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.3.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.3.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.4.layer_scale'),\n",
       " (False, 'base_model.0.0.5.4.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.4.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.4.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.4.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.4.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.4.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.4.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.4.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.5.layer_scale'),\n",
       " (False, 'base_model.0.0.5.5.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.5.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.5.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.5.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.5.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.5.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.5.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.5.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.6.layer_scale'),\n",
       " (False, 'base_model.0.0.5.6.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.6.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.6.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.6.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.6.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.6.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.6.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.6.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.7.layer_scale'),\n",
       " (False, 'base_model.0.0.5.7.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.7.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.7.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.7.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.7.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.7.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.7.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.7.block.5.bias'),\n",
       " (False, 'base_model.0.0.5.8.layer_scale'),\n",
       " (False, 'base_model.0.0.5.8.block.0.weight'),\n",
       " (False, 'base_model.0.0.5.8.block.0.bias'),\n",
       " (False, 'base_model.0.0.5.8.block.2.weight'),\n",
       " (False, 'base_model.0.0.5.8.block.2.bias'),\n",
       " (False, 'base_model.0.0.5.8.block.3.weight'),\n",
       " (False, 'base_model.0.0.5.8.block.3.bias'),\n",
       " (False, 'base_model.0.0.5.8.block.5.weight'),\n",
       " (False, 'base_model.0.0.5.8.block.5.bias'),\n",
       " (True, 'base_model.0.0.6.0.weight'),\n",
       " (True, 'base_model.0.0.6.0.bias'),\n",
       " (True, 'base_model.0.0.6.1.weight'),\n",
       " (True, 'base_model.0.0.6.1.bias'),\n",
       " (True, 'base_model.0.0.7.0.layer_scale'),\n",
       " (True, 'base_model.0.0.7.0.block.0.weight'),\n",
       " (True, 'base_model.0.0.7.0.block.0.bias'),\n",
       " (True, 'base_model.0.0.7.0.block.2.weight'),\n",
       " (True, 'base_model.0.0.7.0.block.2.bias'),\n",
       " (True, 'base_model.0.0.7.0.block.3.weight'),\n",
       " (True, 'base_model.0.0.7.0.block.3.bias'),\n",
       " (True, 'base_model.0.0.7.0.block.5.weight'),\n",
       " (True, 'base_model.0.0.7.0.block.5.bias'),\n",
       " (True, 'base_model.0.0.7.1.layer_scale'),\n",
       " (True, 'base_model.0.0.7.1.block.0.weight'),\n",
       " (True, 'base_model.0.0.7.1.block.0.bias'),\n",
       " (True, 'base_model.0.0.7.1.block.2.weight'),\n",
       " (True, 'base_model.0.0.7.1.block.2.bias'),\n",
       " (True, 'base_model.0.0.7.1.block.3.weight'),\n",
       " (True, 'base_model.0.0.7.1.block.3.bias'),\n",
       " (True, 'base_model.0.0.7.1.block.5.weight'),\n",
       " (True, 'base_model.0.0.7.1.block.5.bias'),\n",
       " (True, 'base_model.0.0.7.2.layer_scale'),\n",
       " (True, 'base_model.0.0.7.2.block.0.weight'),\n",
       " (True, 'base_model.0.0.7.2.block.0.bias'),\n",
       " (True, 'base_model.0.0.7.2.block.2.weight'),\n",
       " (True, 'base_model.0.0.7.2.block.2.bias'),\n",
       " (True, 'base_model.0.0.7.2.block.3.weight'),\n",
       " (True, 'base_model.0.0.7.2.block.3.bias'),\n",
       " (True, 'base_model.0.0.7.2.block.5.weight'),\n",
       " (True, 'base_model.0.0.7.2.block.5.bias'),\n",
       " (True, 'PreHead_0.weight'),\n",
       " (True, 'PreHead_0.bias'),\n",
       " (True, 'PreHead_1.weight'),\n",
       " (True, 'PreHead_1.bias'),\n",
       " (True, 'PostHead_0.weight'),\n",
       " (True, 'PostHead_0.bias')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_layers_requiresGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save run outputs\n",
    "\n",
    "## The training step is written so that it can run until a job ends, so this needs to be saved before\n",
    "\n",
    "run_outputs = {\n",
    "    'dir_save': str(dir_save),    \n",
    "    'path_save_runOutputs': str(dir_save / 'run_outputs.json'),    \n",
    "    'path_saveModel': str(path_saveModel),\n",
    "    'path_saveLog': str(path_saveLog),\n",
    "    'path_saveLoss': str(path_saveLoss),\n",
    "    'device_train': device_train,\n",
    "    'masks_training_shape': list(masks_cat.shape),\n",
    "    'n_masks_removed': int(n_masks_removed),\n",
    "    'image_resized_shape': list(dataset_train[0][0][0].shape),\n",
    "    'names_layers_requiresGrad': names_layers_requiresGrad,\n",
    "}\n",
    "run_outputs;\n",
    "\n",
    "import json\n",
    "with open(run_outputs['path_save_runOutputs'], 'w') as f:\n",
    "    json.dump(run_outputs, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "outputs": [],
   "source": [
    "### Training\n",
    "\n",
    "model.to(device_train)\n",
    "model.prep_contrast()\n",
    "model.forward = model.forward_latent\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = [CrossEntropyLoss()]\n",
    "optimizer = Adam(\n",
    "    model.parameters(), \n",
    "    lr=params['lr'],\n",
    "#     lr=1*10**-2,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=params['gamma'],\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "\n",
    "criterion = [_.to(device_train) for _ in criterion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/bigSSD/ConvNext_tiny_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OQ27o1ny9Xfi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                               | 0/9999999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "before dataloader\n",
      "after dataloader\n",
      "Iter: 0/3021, loss_train: 7.6211, loss_val: nan, pos_over_neg: 1.0012803077697754 lr: 0.0031623\n",
      "after dataloader\n",
      "Iter: 1/3021, loss_train: 8.4018, loss_val: nan, pos_over_neg: 1.0257292985916138 lr: 0.0031623\n",
      "after dataloader\n",
      "Iter: 2/3021, loss_train: 7.6913, loss_val: nan, pos_over_neg: 1.0163170099258423 lr: 0.0031623\n",
      "after dataloader\n",
      "Iter: 3/3021, loss_train: 7.3838, loss_val: nan, pos_over_neg: 1.054558515548706 lr: 0.0031623\n",
      "after dataloader\n",
      "Iter: 4/3021, loss_train: 8.4119, loss_val: nan, pos_over_neg: 1.8694628477096558 lr: 0.0031623\n",
      "after dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                               | 0/9999999 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     losses_train \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# l2_alpha,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty_orthogonality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpenalty_orthogonality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msemi-supervised\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_rolling_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_rolling_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner_batch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_update_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;43;03m#                                     do_validation=False,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;43;03m#                                     X_val=x_feed_through_val,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;43;03m#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m## save loss stuff\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaveLogs\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/GCaMP_ROI_classifier/training.py:232\u001b[0m, in \u001b[0;36mepoch_step\u001b[0;34m(dataloader, model, optimizer, criterion, scheduler, temperature, L2_alpha, penalty_orthogonality, mode, loss_rolling_train, loss_rolling_val, device, inner_batch_size, do_validation, validation_Object, verbose, verbose_update_period, X_val, y_val)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Get batch weights\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemi-supervised\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 232\u001b[0m     loss, pos_over_neg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step_simCLR\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty_orthogonality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty_orthogonality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Needs to take in weights\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupervised\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    245\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_step_classifier(X_batch, y_batch, model, optimizer, criterion, scheduler, L2_alpha\u001b[38;5;241m=\u001b[39mL2_alpha)\n",
      "File \u001b[0;32m/media/rich/Home_Linux_partition/github_repos/GCaMP_ROI_classifier/GCaMP_ROI_classifier/training.py:74\u001b[0m, in \u001b[0;36mtrain_step_simCLR\u001b[0;34m(X_train_batch, y_train_batch, model, optimizer, criterion, scheduler, temperature, sample_weights, penalty_orthogonality, inner_batch_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([model\u001b[38;5;241m.\u001b[39mforward(sub_batch) \u001b[38;5;28;01mfor\u001b[39;00m sub_batch \u001b[38;5;129;01min\u001b[39;00m make_batches(X_train_batch, batch_size\u001b[38;5;241m=\u001b[39minner_batch_size)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# logits, labels = info_nce_loss(features, batch_size=X_train_batch.shape[0]/2, n_views=2, temperature=temperature, DEVICE=X_train_batch.device)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m richs_contrastive_matrix(features, batch_size\u001b[38;5;241m=\u001b[39mX_train_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, n_views\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, temperature\u001b[38;5;241m=\u001b[39mtemperature, DEVICE\u001b[38;5;241m=\u001b[39mX_train_batch\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rapids-21.12/lib/python3.8/site-packages/torch/cuda/memory.py:114\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses_train, losses_val = [], [np.nan]\n",
    "for epoch in tqdm(range(params['n_epochs'])):\n",
    "    print(f'epoch: {epoch}')\n",
    "    \n",
    "    losses_train = training.epoch_step(\n",
    "        dataloader_train, \n",
    "        model, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        scheduler=scheduler,\n",
    "        temperature=params['temperature'],\n",
    "        # l2_alpha,\n",
    "        penalty_orthogonality=params['penalty_orthogonality'],\n",
    "        mode='semi-supervised',\n",
    "        loss_rolling_train=losses_train, \n",
    "        loss_rolling_val=losses_val,\n",
    "        device=device_train, \n",
    "        inner_batch_size=params['inner_batch_size'],\n",
    "        verbose=2,\n",
    "        verbose_update_period=1,\n",
    "\n",
    "#                                     do_validation=False,\n",
    "#                                     X_val=x_feed_through_val,\n",
    "#                                     y_val=torch.as_tensor(y_val, device=DEVICE)\n",
    ")\n",
    "    \n",
    "    ## save loss stuff\n",
    "    if params['prefs']['saveLogs']:\n",
    "        write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}, completed epoch: {epoch}, loss: {losses_train[-1]}, lr: {scheduler.get_last_lr()[0]}')\n",
    "        np.save(path_saveLoss, losses_train)\n",
    "    \n",
    "    ## if loss becomes NaNs, don't save the network and stop training\n",
    "    if torch.isnan(torch.as_tensor(losses_train[-1])):\n",
    "        write_to_log(path_log=path_saveLog, text=f'time:{time.ctime()}, EXITED DUE TO loss==NaN')\n",
    "        break\n",
    "        \n",
    "    ## save model\n",
    "    if params['prefs']['saveModelIteratively']:\n",
    "        torch.save(model.state_dict(), path_saveModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(losses_train)\n",
    "# plt.yscale('log')\n",
    "plt.ylim([0, None]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/media/rich/bigSSD/EfficientNet_b0_7unfrozen_simCLR.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sklearn to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stat = r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/stat.npy'\n",
    "path_labels = [r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh1.npy', '/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh1.npy']\n",
    "\n",
    "# path_stat = r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse6_28 _ day20200815/stat.npy'\n",
    "# path_labels = r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse6_28 _ day20200815/labels_posthoc_all.npy'\n",
    "\n",
    "\n",
    "images_labeled = np.concatenate(\n",
    "    util.import_multiple_stat_files(   \n",
    "        paths_statFiles=[path_stat],\n",
    "        out_height_width=[36,36],\n",
    "        max_footprint_width=241,\n",
    "        plot_pref=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# labels = classification.squeeze_integers(np.concatenate([np.load(path_labels)]))\n",
    "\n",
    "labels = classification.squeeze_integers(np.concatenate([np.load(path) for path in path_labels]))\n",
    "images_labeled = np.concatenate((images_labeled, images_labeled), axis=0)\n",
    "\n",
    "assert images_labeled.shape[0] == labels.shape[0] , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_toKeep = np.where(np.logical_not(labels == 4))[0]\n",
    "\n",
    "images_labeled_clean = images_labeled[idx_toKeep]\n",
    "labels_clean = labels[idx_toKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rU8l0eP02TQR"
   },
   "outputs": [],
   "source": [
    "transforms_classifier = torch.nn.Sequential(\n",
    "    augmentation.ScaleDynamicRange(scaler_bounds=(0,1)),\n",
    "    \n",
    "    torchvision.transforms.Resize(\n",
    "        size=(224, 224),\n",
    "#         size=(180, 180),\n",
    "#         size=(72, 72),        \n",
    "        interpolation=torchvision.transforms.InterpolationMode.BILINEAR), \n",
    "    \n",
    "    augmentation.TileChannels(dim=0, n_channels=3),\n",
    ")\n",
    "\n",
    "scripted_transforms_classifier = torch.jit.script(transforms_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_make_dataset(X):\n",
    "    out = dataset.dataset_simCLR(\n",
    "        X=torch.as_tensor(X, device='cpu', dtype=torch.float32),\n",
    "        y=torch.as_tensor(torch.zeros(X.shape[0]), device='cpu', dtype=torch.float32),\n",
    "        n_transforms=1,\n",
    "        class_weights=np.array([1]),\n",
    "        transform=scripted_transforms_classifier,\n",
    "        DEVICE='cpu',\n",
    "        dtype_X=torch.float32,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def helper_make_dataloader(ds):\n",
    "    out = torch.utils.data.DataLoader( \n",
    "        ds,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "#         pin_memory=True,\n",
    "#         num_workers=36,\n",
    "#         persistent_workers=True,\n",
    "#         prefetch_factor=2\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labeled_clean = helper_make_dataset(images_labeled_clean)\n",
    "    \n",
    "dataloader_labeled_clean = helper_make_dataloader(dataset_labeled_clean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_labeled_clean = helper_make_dataset(masks_cat[:])\n",
    "    \n",
    "dataloader_labeled_clean = helper_make_dataloader(dataset_labeled_clean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_trainingData = helper_make_dataset(masks_cat[torch.randint(low=0, high=masks_cat.shape[0], size=(100000,1)).squeeze()])\n",
    "    \n",
    "dataloader_trainingData = helper_make_dataloader(dataset_trainingData)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features_trainingData = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_trainingData], dim=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pc_tform, _, _, _ = decomposition.torch_pca(features_trainingData, rank=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model.get_head(model.base_model(data[0][0].to(DEVICE))).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model.base_model(data[0][0].to(DEVICE)).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model_chopped_pooled2.to(DEVICE)(data[0][0].to(DEVICE)).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model(data[0][0].to(DEVICE)).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "features_nn = torch.cat([model_chopped.to(DEVICE)(data[0][0].to(DEVICE)).detach().cpu() for data in dataloader_labeled_clean], dim=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pc_tform.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features_tformed = features_nn @ pc_tform[:,:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sweep of logistic regressions over C (1/L2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_sample_weights(labels):\n",
    "    labels = np.int64(labels.copy())\n",
    "    counts, vals = np.histogram(labels, bins=np.concatenate((np.unique(labels), [labels.max()+1])))\n",
    "    vals = vals[:-1]\n",
    "\n",
    "    n_labels = len(labels)\n",
    "    weights = n_labels / counts\n",
    "    \n",
    "    sample_weights = np.array([weights[l] for l in labels])\n",
    "    \n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio import Scattering2D\n",
    "\n",
    "def get_latents_swt(sfs, swt, device_model):\n",
    "    sfs = torch.as_tensor(np.ascontiguousarray(sfs[None,...]), device=device_model, dtype=torch.float32)\n",
    "    latents_swt = swt(sfs[None,...]).squeeze()\n",
    "    latents_swt = latents_swt.reshape(latents_swt.shape[0], -1)\n",
    "    return latents_swt\n",
    "\n",
    "\n",
    "device_model = torch_helpers.set_device(use_GPU=True)\n",
    "\n",
    "scattering = Scattering2D(J=2, L=8, shape=images_labeled_clean[0].shape[-2:])\n",
    "if device_model != 'cpu':\n",
    "    scattering = scattering.cuda()\n",
    "\n",
    "latents_swt = get_latents_swt(images_labeled_clean, scattering.cuda(), device_model).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.corrcoef(features_nn.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.imshow(features_nn, aspect='auto',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.imshow(scipy.stats.zscore(features_nn, axis=0), aspect='auto', vmin=-0.8, vmax=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn_z = scipy.stats.zscore(features_nn.numpy(), axis=0)\n",
    "features_nn_z = features_nn_z[:, ~np.isnan(features_nn_z[0,:])]\n",
    "features_nn_z = torch.as_tensor(features_nn_z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn_z, rank=40, zscore=True)\n",
    "# comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn, rank=60, zscore=True)\n",
    "comp, scores_swt, SVs, EVR_swt = decomposition.torch_pca(latents_swt, rank=20)\n",
    "comp, scores_image, SVs, EVR_image = decomposition.torch_pca(images_labeled_clean.reshape(images_labeled_clean.shape[0], -1), rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(EVR_nn)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(torch.corrcoef(features_nn.T))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "meanSub = sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=False)\n",
    "\n",
    "features_norm = meanSub.fit_transform(features_nn)\n",
    "\n",
    "# features_norm = meanSub.fit_transform(latents_swt)\n",
    "\n",
    "# features_norm = meanSub.fit_transform(images_labeled_clean.reshape(images_labeled_clean.shape[0], -1))\n",
    "\n",
    "# features_norm = meanSub.fit_transform(scores)\n",
    "\n",
    "# features_norm = meanSub.fit_transform(np.concatenate((scores_nn, scores_swt, scores_image), axis=1))\n",
    "# features_all = np.concatenate([meanSub.fit_transform(scores) / torch.var(scores).mean() for scores in [features_nn, latents_swt, torch.as_tensor(images_labeled_clean.reshape(images_labeled_clean.shape[0], -1))]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp, features_norm, SVs, EVR = decomposition.torch_pca(features_norm, rank=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp, features_norm, SVs, EVR = decomposition.torch_pca(features_all, rank=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_norm = torch.cat([val / torch.std(val) for val in [scores_nn, scores_swt]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_nn]], dim=1)\n",
    "# features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_swt]], dim=1)\n",
    "# features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_image]], dim=1)\n",
    "features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_nn, scores_swt]], dim=1)\n",
    "# features_norm = torch.cat([val / torch.std(val, dim=0).mean() for val in [scores_nn, scores_swt, scores_image]], dim=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features_norm = features_nn\n",
    "# features_norm = features_nn_z\n",
    "\n",
    "# features_norm = scores_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "features_train, features_val, labels_train, labels_val = sklearn.model_selection.train_test_split(features_norm, labels_clean, test_size=0.3)\n",
    "print(f'train / test shapes: images_labeled_train, images_labeled_val, labels_train, labels_val: {features_train.shape, features_val.shape, labels_train.shape, labels_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train, acc_val = [], []\n",
    "C_toUse = np.array([1000, 100, 10,1,0.1,0.01,0.001])\n",
    "# C_toUse = np.array([10**-4, 10**-5, 10**-6, 10**-7])\n",
    "# C_toUse = np.array([10**2, 10**3, 10**4, 10**5])\n",
    "for C in C_toUse:\n",
    "    logreg = sklearn.linear_model.LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "#         solve='sag'\n",
    "#         solve='saga'\n",
    "#         solver='newton-cg',\n",
    "#         solver='liblinear',\n",
    "        max_iter=6000, \n",
    "        C=C,\n",
    "        fit_intercept=True, \n",
    "        class_weight='balanced',\n",
    "    #     n_jobs=-1\n",
    "    )\n",
    "    logreg.fit(features_train, labels_train)\n",
    "\n",
    "    acc = logreg.score(features_train, labels_train, sample_weight=get_balanced_sample_weights(labels_train))\n",
    "    acc_train.append(acc)\n",
    "\n",
    "    acc = logreg.score(features_val, labels_val, sample_weight=get_balanced_sample_weights(labels_val))\n",
    "    acc_val.append(acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);\n",
    "\n",
    "print(f'best val score: {max(acc_val)}')\n",
    "print(f'best C value: {C_toUse[np.argmax(acc_val)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_train, acc_val = [], []\n",
    "C_toUse = np.array([1000, 100, 10,1,0.1,0.01,0.001])\n",
    "for C in C_toUse:\n",
    "    svm = sklearn.svm.SVC(\n",
    "        C=C, \n",
    "        kernel='rbf',\n",
    "        degree=3, \n",
    "        gamma='scale',\n",
    "        coef0=0.0, \n",
    "        shrinking=True,\n",
    "        probability=False, \n",
    "        tol=0.001, \n",
    "        cache_size=200,\n",
    "        class_weight='balanced',\n",
    "        verbose=False, \n",
    "        max_iter=- 1, \n",
    "        decision_function_shape='ovr',\n",
    "        break_ties=False,\n",
    "        random_state=None\n",
    "    )\n",
    "    svm.fit(features_train, labels_train)\n",
    "\n",
    "    acc = svm.score(features_train, labels_train, sample_weight=get_balanced_sample_weights(labels_train))\n",
    "    acc_train.append(acc)\n",
    "\n",
    "    acc = svm.score(features_val, labels_val, sample_weight=get_balanced_sample_weights(labels_val))\n",
    "    acc_val.append(acc)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(C_toUse, acc_train)\n",
    "plt.plot(C_toUse, acc_val)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train', 'test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run a sinlg logistic regression with desired parameters and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "#         solver='sag',\n",
    "#         solver='saga',\n",
    "#         solver='newton-cg',\n",
    "#         solver='liblinear',\n",
    "    max_iter=8000, \n",
    "    C=10**(0),\n",
    "    fit_intercept=True, \n",
    "    class_weight='balanced',\n",
    "#     n_jobs=-1\n",
    ").fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm = sklearn.svm.SVC(\n",
    "    C=10**(1), \n",
    "    kernel='rbf',\n",
    "    degree=3, \n",
    "    gamma='scale',\n",
    "    coef0=0.0, \n",
    "    shrinking=True,\n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200,\n",
    "    class_weight='balanced',\n",
    "    verbose=False, \n",
    "    max_iter=- 1, \n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=None\n",
    ")\n",
    "svm.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "proba = logreg.predict_proba(features_train)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "\n",
    "# preds = svm.predict(features_train_norm).astype(np.int32)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_train.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "\n",
    "\n",
    "proba = logreg.predict_proba(features_val)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "\n",
    "# preds = svm.predict(features_val_norm).astype(np.int32)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_val.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "# proba = logreg.predict_proba(features_train_norm)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "\n",
    "preds = svm.predict(features_train).astype(np.int32)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_train.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('train');\n",
    "\n",
    "\n",
    "\n",
    "# proba = logreg.predict_proba(features_val_norm)\n",
    "# preds = np.argmax(proba, axis=1)\n",
    "\n",
    "preds = svm.predict(features_val).astype(np.int32)\n",
    "\n",
    "cm = classification.confusion_matrix(preds, labels_val.astype(np.int32))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, vmax=1., cmap=plt.get_cmap('gray'))\n",
    "plt.title('val');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sesh1 = np.load(r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh1.npy')\n",
    "labels_sesh2 = np.load(r'/media/rich/bigSSD/for_Josh/SimCLR-Label-Data/mouse2_6__20210409/labels_round2_sesh2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sesh12cat = np.concatenate((labels_sesh1, labels_sesh2), axis=0)\n",
    "labels_sesh21cat = np.concatenate((labels_sesh2, labels_sesh1), axis=0)\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    classification.confusion_matrix(labels_sesh12cat.astype(np.int32), labels_sesh21cat.astype(np.int32)),\n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 16}, \n",
    "    vmax=1., \n",
    "    cmap=plt.get_cmap('gray')\n",
    ")\n",
    "plt.title('relabeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(name, params.shape) for name, params in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "layer_1 = model.state_dict()['base_model.0.0.0.weight'].cpu()\n",
    "# layer_2 = model.state_dict()['base_model.0.6.3.block.1.0.weight'].cpu()\n",
    "# layer_3 = model.state_dict()['base_model.0.7.0.block.1.0.weight'].cpu()\n",
    "# layer_4 = model.state_dict()['base_model.0.7.0.block.1.0.weight'].cpu()\n",
    "\n",
    "\n",
    "plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_1], dim=0), grid_shape=(15,15), kwargs_imshow={'vmax': 0.2});\n",
    "# plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_2], dim=0), grid_shape=(6,6), kwargs_imshow={'vmax': 0.2});\n",
    "# plotting_helpers.plot_image_grid(torch.cat([arr for arr in layer_3], dim=0), grid_shape=(4,6), kwargs_imshow={'vmax': 0.2});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(\n",
    "    n_neighbors=30,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    metric_kwds=None,\n",
    "    output_metric='euclidean',\n",
    "    output_metric_kwds=None,\n",
    "    n_epochs=None,\n",
    "    learning_rate=1.0,\n",
    "    init='spectral',\n",
    "    min_dist=0.1,\n",
    "    spread=1.0,\n",
    "    low_memory=True,\n",
    "    n_jobs=-1,\n",
    "    set_op_mix_ratio=1.0,\n",
    "    local_connectivity=1.0,\n",
    "    repulsion_strength=1.0,\n",
    "    negative_sample_rate=5,\n",
    "    transform_queue_size=4.0,\n",
    "    a=None,\n",
    "    b=None,\n",
    "    random_state=None,\n",
    "    angular_rp_forest=False,\n",
    "    target_n_neighbors=-1,\n",
    "    target_metric='categorical',\n",
    "    target_metric_kwds=None,\n",
    "    target_weight=0.5,\n",
    "    transform_seed=42,\n",
    "    transform_mode='embedding',\n",
    "    force_approximation_algorithm=False,\n",
    "    verbose=False,\n",
    "    tqdm_kwds=None,\n",
    "    unique=False,\n",
    "    densmap=False,\n",
    "    dens_lambda=2.0,\n",
    "    dens_frac=0.3,\n",
    "    dens_var_shift=0.1,\n",
    "    output_dens=False,\n",
    "    disconnection_distance=None,\n",
    "    precomputed_knn=(None, None, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = umap.fit_transform(features_nn)\n",
    "# embeddings = umap.fit_transform(scores_nn)\n",
    "# embeddings = umap.fit_transform(latents_swt)\n",
    "# embeddings = umap.fit_transform(features_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], s=5, c=labels_clean, cmap='gist_rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(scores_nn[:,1], scores_nn[:,0], c=labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ROIClassifier_TRAIN_20211201_JZ_supervised-comparison5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 920.76378,
   "position": {
    "height": "40px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "500.99px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
