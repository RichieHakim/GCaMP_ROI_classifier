{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/Users/Josh/Documents/github_repos/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import torch_helpers, decomposition\n",
    "from GCaMP_ROI_classifier.old_stuff import util, models, training_simCLR, augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/Josh/Documents/Harvard/label_data/all_stat_files_20211022.pkl', 'rb') as file:\n",
    "    statFiles_scraped = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keys_toDelete = [\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\for Loic\\\\16x_analysis20200514\\\\Suite2p and MC for denoised movie\\\\suite2p\\\\plane0\\\\stat.npy',\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\round 4 experiments\\\\mouse 6.28\\\\20201102\\\\suite2p_accidentally_run_on_everything\\\\plane0\\\\stat.npy',\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\for Loic\\\\20x\\\\mouse 2.5\\\\20200306\\\\suite2p attemp 2 _tau 1_5\\\\plane0\\\\stat.npy',\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\for Loic\\\\20x\\\\mouse 2.5\\\\20200306\\\\suite2p attempt 1 _tau 2\\\\plane0\\\\stat.npy',\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\for Loic\\\\20x\\\\mouse 2.5\\\\20200306\\\\suite2p attempt 3 _tau 1\\\\plane0\\\\stat.npy',\n",
    "    '\\\\\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Rich\\\\data\\\\res2p\\\\scanimage data\\\\for Loic\\\\AAV\\\\oldBMIrampExp_20191112_mouse1013A\\\\ROI extraction\\\\suite2p\\\\plane0\\\\stat.npy',\n",
    "]\n",
    "for key in keys_toDelete:\n",
    "    del statFiles_scraped[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217802, 36, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_list = util.convert_multiple_stat_files(statFiles_dict=statFiles_scraped, out_height_width=[36,36], max_footprint_width=901, plot_pref=False)\n",
    "\n",
    "images_all = np.concatenate(sf_list, axis=0)\n",
    "\n",
    "images_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_all_norm = (images_all / np.sum(images_all, axis=(1,2), keepdims=True)) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((185131, 36, 36), (185131,)), ((32671, 36, 36), (32671,)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_all_norm, np.arange(images_all.shape[0]), test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640.0000169542105\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640.0000169542105\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated images shape: (9715, 36, 36)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640.0000169542105\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640.0000169542105\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dir_folders = r'/media/rich/bigSSD/for_Josh/GCAMP_ROI_Classifier_data/label_data'\n",
    "dir_folders = r'/users/Josh/Documents/Harvard/label_data'\n",
    "folders = [r'mouse 6_28 _ day 20200903/',\n",
    "             r'mouse6_28 _ day20200815/']\n",
    "fileNames_statFiles = [r'stat.npy']*len(folders)\n",
    "paths_statFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_statFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "statFile_import_kwargs = {'out_height_width': [36,36],\n",
    "                          'max_footprint_width': 241,\n",
    "                          'plot_pref':True}\n",
    "\n",
    "sf_all = util.import_multiple_stat_files(   paths_statFiles=paths_statFiles,\n",
    "                                        fileNames_statFiles=fileNames_statFiles,\n",
    "                                        out_height_width=[36,36],\n",
    "                                        max_footprint_width=241,\n",
    "                                        plot_pref=True)\n",
    "images_labeled = np.concatenate(sf_all, axis=0) *255\n",
    "print(f'concatenated images shape: {images_labeled.shape}')\n",
    "\n",
    "fileNames_labelFiles = ['labels_posthoc_filledIn_allCells.npy',\n",
    "             'labels_posthoc_all.npy']\n",
    "paths_labelFiles = [pathlib.Path(dir_folders) / folders[ii] / fileNames_labelFiles[ii] for ii in range(len(folders))]\n",
    "\n",
    "labels_all = util.import_multiple_label_files(paths_labelFiles=paths_labelFiles,\n",
    "                                       plot_pref=True)\n",
    "labels = np.concatenate(labels_all)\n",
    "\n",
    "assert np.alltrue([sf_all[ii].shape[0] == labels_all[ii].shape[0] for ii in range(len(sf_all))]) , 'num images in stat files does not correspond to num labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance classes of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9715, 36, 36)\n",
      "(9715,)\n",
      "532\n",
      "532\n",
      "620\n",
      "681\n",
      "7881\n",
      "(9715, 36, 36)\n",
      "(9715,)\n"
     ]
    }
   ],
   "source": [
    "duplicates = 1\n",
    "\n",
    "images_dup = np.tile(images_labeled , (duplicates , 1 , 1))\n",
    "labels_dup = np.tile(labels , (duplicates))\n",
    "\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)\n",
    "\n",
    "numToGetTo = np.sum(labels_dup==0)\n",
    "print(numToGetTo)\n",
    "\n",
    "print(np.sum(labels_dup==0))\n",
    "print(np.sum(labels_dup==1))\n",
    "print(np.sum(labels_dup==4))\n",
    "print(np.sum(labels_dup==5))\n",
    "print(images_dup.shape)\n",
    "print(labels_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((8257, 36, 36), (8257,)), ((1458, 36, 36), (1458,)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(images[:], labels[:], test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_dup[:], labels_dup[:], test_size = 0.15)\n",
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640.0000169542105\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(labels_dup, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms    \n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    \n",
    "#     torchvision.transforms.GaussianBlur(kernel_size=5,\n",
    "#                                         sigma=(0.0001, 0.5)),\n",
    "    \n",
    "#     torchvision.transforms.RandomPerspective(distortion_scale=0.4, \n",
    "#                                              p=0.5, \n",
    "#                                              interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                              fill=0),\n",
    "#     torchvision.transforms.RandomAffine(\n",
    "#                                         degrees=(-180,180),\n",
    "#                                         translate=(0.3, 0.3),\n",
    "#                                         scale=(0.7, 1.7), \n",
    "#                                         shear=(-30, 30, -30, 30), \n",
    "#                                         interpolation=torchvision.transforms.InterpolationMode.BILINEAR, \n",
    "#                                         fill=0, \n",
    "#                                         fillcolor=None, \n",
    "#                                         resample=None),\n",
    "    \n",
    "#     augmentation.AddPoissonNoise(   level_bounds=(0,0.7),\n",
    "#                                     prob=1),\n",
    "\n",
    "#     augmentation.AddGaussianNoise(  mean=0, \n",
    "#                                     std=0.4,\n",
    "#                                     prob=1),\n",
    ")\n",
    "# scripted_transforms = torch.jit.script(transforms)\n",
    "scripted_transforms = transforms\n",
    "\n",
    "\n",
    "\n",
    "dataset_train = util.dataset_simCLR(torch.tensor(X_train), \n",
    "                                    y_train, \n",
    "                                    n_transforms=2, \n",
    "                                    transform=scripted_transforms,\n",
    "                                    DEVICE='cpu',\n",
    "                                    dtype_X=torch.float32,\n",
    "                                    dtype_y=torch.int64 )\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                batch_size=1024,\n",
    "            #                                     sampler=sampler,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True,\n",
    "                                                pin_memory=False,\n",
    "#                                                 num_workers=32,\n",
    "                                                num_workers=0,\n",
    "#                                                 num_workers=16,\n",
    "#                                                 prefetch_factor=3,\n",
    "#                                                 persistent_workers=True,\n",
    "                                                )\n",
    "\n",
    "# dataset_val = util.dataset_simCLR(torch.tensor(X_val), \n",
    "#                                     y_val, \n",
    "#                                     n_transforms=2, \n",
    "#                                     transform=scripted_transforms,\n",
    "#                                     DEVICE='cpu',\n",
    "#                                     dtype_X=torch.float32,\n",
    "#                                     dtype_y=torch.int64 )\n",
    "\n",
    "# dataloader_val = torch.utils.data.DataLoader(   dataset_val,\n",
    "#                                                 batch_size=128,\n",
    "#             #                                     sampler=sampler,\n",
    "#                                                 shuffle=True,\n",
    "#                                                 drop_last=True,\n",
    "#                                                 pin_memory=True,\n",
    "#                                                 num_workers=0,\n",
    "#                                                 )         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ii, im in enumerate(images_all_norm):\n",
    "    plt.figure()\n",
    "    plt.imshow(im)\n",
    "    if ii > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018596649169921875\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"574.4444596620258\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0386350154876709\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"574.4444596620258\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03654766082763672\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"574.4444596620258\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03518795967102051\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"574.4444596620258\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "%matplotlib notebook\n",
    "tic=time.time()\n",
    "for ii, im in enumerate(dataset_train):\n",
    "#     for jj in range(im[0])\n",
    "    print(time.time() - tic)\n",
    "    tic = time.time()\n",
    "#     print((im[0][0]).shape)\n",
    "    fig, axs = plt.subplots(len(im[0]))\n",
    "    for jj, ax in enumerate(axs):\n",
    "        ax.imshow(im[0][jj].cpu().squeeze())\n",
    "    if ii > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch_helpers.set_device(use_GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = models.LeNet1(dropout_prob=0.3, momentum_val=0, n_output_features=128)\n",
    "model.train()\n",
    "# criterion = CrossEntropyLoss()\n",
    "criterion = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                   gamma=1-0.0005,\n",
    "#                                                    gamma=1,\n",
    "                                                  )\n",
    "val_obj = training_simCLR.validation_Obj(   X_val,\n",
    "                                            y_val,\n",
    "                                            model,\n",
    "                                            criterion,\n",
    "                                            DEVICE=DEVICE,\n",
    "                                            dtype_X=torch.float32,\n",
    "                                            dtype_y=torch.int64) # Needs to take in weights\n",
    "\n",
    "model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "\n",
    "losses_train, losses_val, val_accs = [], [np.nan], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Iter: 0/8, loss_train: 1.249e+04, loss_val: nan, lr: 0.0009536\n",
      "[ 445.74  535.1  8257.    581.69 6693.42]\n",
      "dataset_train.final_weights [0.36766535 0.30626641 0.01984778 0.28173624 0.02448422]\n",
      "epoch: 1\n",
      "Iter: 0/8, loss_train: 971.69, loss_val: nan, lr: 0.00094979\n",
      "[ 447.82  538.77 8257.    578.92 6690.7 ]\n",
      "dataset_train.final_weights [0.36685127 0.30492295 0.01989625 0.28377554 0.02455398]\n",
      "epoch: 2\n",
      "Iter: 0/8, loss_train: 1036.0, loss_val: nan, lr: 0.000946\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from training_classHead import HeadModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# classHead = HeadModel(model, RandomForestClassifier)\n",
    "classHead = HeadModel(model, LogisticRegression)\n",
    "dataset_train.headmodel = classHead\n",
    "\n",
    "n_epochs=300000\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    training_simCLR.epoch_step( dataloader_train, \n",
    "                                model, \n",
    "                                optimizer, \n",
    "                                criterion, \n",
    "                                scheduler=scheduler, \n",
    "                                temperature=0.5,\n",
    "                                loss_rolling_train=losses_train, \n",
    "                                device=DEVICE, \n",
    "                                do_validation=False,\n",
    "                                validation_Object=val_obj,\n",
    "                                loss_rolling_val=losses_val,\n",
    "                                verbose=2,\n",
    "                                verbose_update_period=10,\n",
    "                               )\n",
    "    # model predict\n",
    "    # Update model in DS\n",
    "    # get item calls model for each sample\n",
    "    # output\n",
    "    # X sample weights predictions\n",
    "    \n",
    "    classHead.fit(X_train[:, None, :, :], y_train)\n",
    "    \n",
    "    proba = classHead.predict_proba(X_train[:, None, :, :])\n",
    "    class_weights = proba.sum(axis=0)\n",
    "    total_num = class_weights.sum()\n",
    "    \n",
    "    eps = 1e-4\n",
    "    \n",
    "    class_weights[class_weights <= 3] = total_num\n",
    "    weightings = class_weights.sum()/class_weights\n",
    "    final_weights = weightings / weightings.sum()\n",
    "    \n",
    "    print(class_weights)\n",
    "\n",
    "    dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "    print('dataset_train.final_weights', dataset_train.class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [A, B, C]\n",
    "# [a, b, b]\n",
    "# [100, 50, 50]\n",
    "# x = 100\n",
    "# [x, x/2, x/2]\n",
    "# [1, 2, 2]\n",
    "\n",
    "# [1/5, 2/5, 2/5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])], tensor([5, 5, 5,  ..., 5, 0, 5]), tensor([1547, 4349, 3394,  ..., 5939, 1897, 1245]), tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0891728e-02 2.9298335e-01 2.0808190e-01 ... 4.7482211e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.5459572e-04 7.1132928e-02 2.8490696e-02 ... 1.2237633e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [8.6434120e-01 2.3477215e-01 1.6362664e+00 ... 7.4931586e-01\n",
      "  8.9495152e-01 6.9169378e-01]\n",
      " ...\n",
      " [5.3231776e-01 0.0000000e+00 5.8383352e-01 ... 9.6204078e-01\n",
      "  1.1975595e+00 0.0000000e+00]\n",
      " [9.8908961e-02 3.7857163e-01 2.5451156e-01 ... 7.7752456e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [4.5258913e-02 7.8043565e-02 2.8905728e-01 ... 1.8210934e-03\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "dataset_train.final_weights [0.31409498 0.31049847 0.01970464 0.01970464 0.31168812 0.02430916]\n",
      "[[3.0891728e-02 2.9298335e-01 2.0808190e-01 ... 4.7482211e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.5459572e-04 7.1132928e-02 2.8490696e-02 ... 1.2237633e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [8.6434120e-01 2.3477215e-01 1.6362664e+00 ... 7.4931586e-01\n",
      "  8.9495152e-01 6.9169378e-01]\n",
      " ...\n",
      " [6.8048441e-01 6.0925514e-01 5.6816703e-01 ... 2.7706984e-01\n",
      "  1.0042894e+00 1.6298890e-01]\n",
      " [8.9212835e-01 4.1740513e-01 1.4700600e+00 ... 6.3622260e-01\n",
      "  6.6693282e-01 2.5283301e-01]\n",
      " [8.0472463e-01 0.0000000e+00 1.4987009e+00 ... 1.1096411e+00\n",
      "  9.9810576e-01 7.8612834e-01]]\n",
      "[0 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[[0.31409498 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.31049847 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]]\n",
      "tensor([[0.3141, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3105, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243]], dtype=torch.float64)\n",
      "tensor([0.3141, 0.3105, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243,\n",
      "        0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243],\n",
      "       dtype=torch.float64)\n",
      "<GCaMP_ROI_classifier.old_stuff.util.dataset_simCLR object at 0x7fa820882070>\n",
      "Hi!\n",
      "[[0.31710166 0.         0.         0.413206   0.         0.5927775\n",
      "  1.8410573  1.9200089  0.3133525  0.         0.1935492  0.\n",
      "  0.23632179 0.39688054 0.         0.42841214 0.         0.6059195\n",
      "  0.         0.         0.33914357 0.22231688 0.         0.\n",
      "  0.10741333 0.         0.         0.73296046 0.         0.\n",
      "  1.3109076  0.45895696 0.17927736 0.         0.88167757 0.\n",
      "  0.02031151 1.27447    0.         0.26553705 0.32636592 0.\n",
      "  0.         0.754137   1.0635818  1.3156521  0.         0.\n",
      "  0.         0.97603077 0.30210048 0.613329   0.8224531  0.39778906\n",
      "  0.         0.         0.35582757 0.         0.         0.\n",
      "  0.         0.7916262  1.1123072  0.        ]]\n",
      "Hi!\n",
      "[[0.8391072  0.5930142  0.73891544 0.19961426 0.         0.9670569\n",
      "  0.3415193  0.7978321  0.01726668 0.         0.40849203 0.\n",
      "  1.1688116  0.4505822  0.         0.0972106  0.         0.45140207\n",
      "  0.16431321 0.79727685 0.5617722  0.         0.         0.17961104\n",
      "  0.         0.         0.         0.5755186  0.         0.\n",
      "  1.0985126  1.1182559  0.         0.         0.40173283 0.\n",
      "  0.2552709  0.66174334 0.5866576  0.33681756 0.         0.\n",
      "  0.         0.32206517 1.3604909  1.0218046  0.         0.84000844\n",
      "  0.39930436 0.69233996 0.23661001 0.6692592  0.8308171  1.3577939\n",
      "  0.         0.60761356 0.47029015 0.         0.         0.\n",
      "  0.         0.13435061 1.2207091  0.        ]]\n",
      "Hi!\n",
      "[[0.3872387  0.38032737 0.5172628  0.         0.         0.7727175\n",
      "  0.22180076 0.5350681  0.         0.14650716 0.25189388 0.\n",
      "  0.         0.19171233 0.         0.         0.         0.29216808\n",
      "  0.         0.76800513 0.30925694 0.         0.         0.03709899\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3736157  0.4840817  0.14334555 0.         0.         0.\n",
      "  0.         0.08203558 0.02768814 0.3646359  0.         0.\n",
      "  0.         0.         0.6138941  0.942941   0.         0.2206773\n",
      "  0.5296104  0.8028652  0.         0.51817507 0.6762055  0.69428307\n",
      "  0.         0.8263152  0.         0.         0.0244134  0.\n",
      "  0.29011717 0.33788162 0.0545742  0.        ]]\n",
      "Hi!\n",
      "[[0.62627274 0.         1.1325649  0.         0.         0.67849743\n",
      "  1.0730687  1.0331525  1.236365   0.         0.52424043 0.\n",
      "  0.04995542 0.         0.         0.7693077  0.35214147 0.8870161\n",
      "  0.         0.         1.0788683  0.3420418  0.         0.4261851\n",
      "  0.04738441 0.         0.         0.         0.         0.\n",
      "  0.2362091  0.12526007 0.         0.         0.3283195  0.\n",
      "  0.16923885 1.2470486  0.         0.71124554 0.20815778 0.\n",
      "  0.         1.3438468  0.         0.3264019  0.         0.43360746\n",
      "  0.         0.7410105  0.695673   0.15930533 0.2498569  0.05289815\n",
      "  0.         0.05162831 0.         0.4214475  0.         0.\n",
      "  0.         1.1648355  1.2178822  0.5388743 ]]\n",
      "Hi!\n",
      "[[0.41222382 0.51595825 1.0127113  0.         0.         0.7125923\n",
      "  0.2753504  0.6666741  0.8566499  0.         0.5589565  0.\n",
      "  1.1061248  0.         0.         0.60920274 0.         0.6714448\n",
      "  0.48351103 0.20534684 0.9295769  0.         0.         0.\n",
      "  0.04406267 0.         0.         0.31980017 0.         0.\n",
      "  0.7550697  0.57946855 0.         0.         0.34274548 0.\n",
      "  0.30359364 0.9712319  0.         0.525387   0.03286283 0.\n",
      "  0.         0.36245525 0.5797082  0.40036827 0.         0.7453317\n",
      "  0.         0.703151   0.64674383 0.35921338 0.5097116  0.5837999\n",
      "  0.         0.         0.23375326 0.         0.         0.\n",
      "  0.         0.6159502  1.2256378  0.48710483]]\n",
      "Hi!\n",
      "[[0.59863347 0.20567685 1.502424   0.         0.         0.7594054\n",
      "  0.38050908 0.43137825 1.4529881  0.         0.7157006  0.\n",
      "  0.69360566 0.         0.         0.88367045 0.44170997 0.9391269\n",
      "  0.5241321  0.         1.3371198  0.37016314 0.         0.50864077\n",
      "  0.10520946 0.         0.         0.         0.         0.\n",
      "  0.16632795 0.20038289 0.         0.         0.12022967 0.\n",
      "  0.33010766 1.1218835  0.         0.8693335  0.19689412 0.\n",
      "  0.         1.0641216  0.         0.         0.         0.8324964\n",
      "  0.         0.84822416 0.858266   0.08057294 0.2310817  0.12949888\n",
      "  0.         0.         0.         0.6755147  0.         0.\n",
      "  0.         0.9906705  1.3162006  1.0264776 ]]\n",
      "Hi!\n",
      "[[0.3667145  0.         0.09895448 0.32235393 0.         0.55090815\n",
      "  1.9141247  2.204806   1.078543   0.         0.29962048 0.\n",
      "  1.2471191  0.53310555 0.         1.0449853  0.         0.7780952\n",
      "  0.92164344 0.         0.64868903 0.49220666 0.         0.\n",
      "  0.4580184  0.         0.         1.1221741  0.         0.\n",
      "  1.6409693  0.5062623  0.         0.         1.2065649  0.\n",
      "  0.7086594  1.805205   0.         0.07758937 0.46058312 0.\n",
      "  0.         1.1037612  1.1702825  1.0566928  0.         0.5050246\n",
      "  0.         0.70442504 1.0774505  0.5774584  0.60536337 0.514315\n",
      "  0.         0.         0.67539597 0.         0.         0.\n",
      "  0.         0.69214886 1.833401   0.01730066]]\n",
      "Hi!\n",
      "[[0.88362443 0.5965988  1.6315846  0.         0.         1.2178047\n",
      "  0.         0.         0.29315668 0.02049066 0.54754364 0.\n",
      "  0.21032374 0.         0.         0.         0.45682365 0.2597426\n",
      "  0.         0.95594186 0.84545404 0.         0.         0.3193444\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.53534514 0.11212493 0.         0.         0.\n",
      "  0.         0.06532269 0.         0.71682954 0.         0.\n",
      "  0.         0.09280339 0.25458825 0.36949387 0.         0.63859814\n",
      "  0.7945204  0.72634816 0.00378918 0.53577566 0.8040815  0.8382273\n",
      "  0.         1.3590628  0.         0.         0.17001739 0.\n",
      "  0.41138753 0.19422336 0.634643   0.31606984]]\n",
      "Hi!\n",
      "[[0.49227032 0.41388723 0.33224925 0.         0.         0.5621818\n",
      "  0.8494354  1.2176633  0.9193591  0.         0.36137843 0.\n",
      "  1.6421537  0.42286956 0.         0.8300501  0.         0.74598485\n",
      "  1.0939825  0.         0.638598   0.1765219  0.         0.\n",
      "  0.50072724 0.         0.         0.6873915  0.         0.\n",
      "  1.2047424  0.6928438  0.         0.         0.79633725 0.\n",
      "  0.83880645 1.4501985  0.         0.3003767  0.12727721 0.\n",
      "  0.         0.49378437 1.0428519  0.61028    0.         1.0766456\n",
      "  0.         0.7459074  1.0441589  0.48073503 0.32159477 0.9777491\n",
      "  0.         0.         0.5673621  0.         0.         0.\n",
      "  0.         0.46863046 1.3051596  0.4145537 ]]\n",
      "Hi!\n",
      "[[0.47479016 0.7673408  1.571852   0.         0.         0.79070675\n",
      "  0.         0.         0.9979629  0.         0.66760695 0.\n",
      "  0.90668494 0.         0.         0.6699045  0.5110943  0.8775851\n",
      "  0.30222002 0.6061412  1.2653373  0.23406743 0.         0.10583086\n",
      "  0.1392616  0.         0.         0.         0.         0.\n",
      "  0.         0.2161554  0.         0.         0.         0.\n",
      "  0.24258183 0.72969896 0.         0.934314   0.         0.\n",
      "  0.         0.3481357  0.03520635 0.         0.         1.0945259\n",
      "  0.12060434 0.94271713 0.64204735 0.2070784  0.17457749 0.51131624\n",
      "  0.         0.14591727 0.         0.4969416  0.15449096 0.\n",
      "  0.02626206 0.6742684  0.89088744 1.0036267 ]]\n",
      "Hi!\n",
      "[[0.19044757 0.8164705  0.62615705 0.         0.         0.597475\n",
      "  0.1246863  0.54187787 0.35818    0.         0.4001663  0.\n",
      "  0.99449116 0.2924438  0.         0.18441668 0.         0.423073\n",
      "  0.         0.63146335 0.5610882  0.         0.         0.14179058\n",
      "  0.         0.         0.         0.17286195 0.         0.\n",
      "  0.7773777  0.531897   0.         0.         0.10033385 0.\n",
      "  0.         0.3394037  0.16518912 0.32952657 0.         0.\n",
      "  0.         0.         0.5208991  0.701001   0.         0.39864847\n",
      "  0.21770723 0.84953845 0.34315878 0.4044164  0.7839861  0.6674766\n",
      "  0.         0.01102822 0.06489319 0.         0.         0.\n",
      "  0.         0.43771523 0.4080426  0.17923108]]\n",
      "Hi!\n",
      "[[0.33606336 0.16240163 0.5327884  0.         0.         0.6226508\n",
      "  0.6452048  0.8793725  0.41553393 0.         0.36098355 0.\n",
      "  0.7026836  0.09514218 0.         0.4006055  0.         0.5092799\n",
      "  0.03757183 0.17086592 0.54860497 0.         0.         0.\n",
      "  0.01377921 0.         0.         0.30879852 0.         0.\n",
      "  0.77719194 0.5080109  0.         0.         0.4112043  0.\n",
      "  0.15966679 0.8661016  0.         0.30503887 0.         0.\n",
      "  0.         0.3031921  0.6193843  0.6983836  0.         0.40808564\n",
      "  0.         0.6352307  0.3907024  0.4245892  0.5062076  0.5442571\n",
      "  0.         0.         0.21979971 0.         0.         0.\n",
      "  0.         0.46842968 0.89272666 0.09155312]]\n",
      "Hi!\n",
      "[[0.05260482 0.2649268  0.34021965 0.         0.         0.33925566\n",
      "  0.02122304 0.16833952 0.04473197 0.11811712 0.24544743 0.\n",
      "  0.         0.03695989 0.         0.02319129 0.         0.15368272\n",
      "  0.         0.39395335 0.1904238  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08752106 0.05035331 0.         0.         0.\n",
      "  0.         0.00809665 0.05448833 0.2330404  0.         0.\n",
      "  0.         0.         0.08345667 0.40248463 0.         0.10363588\n",
      "  0.28315327 0.33074465 0.         0.25275064 0.26349035 0.3777787\n",
      "  0.         0.32049945 0.         0.         0.02325348 0.\n",
      "  0.15766034 0.26544863 0.         0.        ]]\n",
      "Hi!\n",
      "[[2.1504351e-01 7.8948271e-01 6.9069237e-01 0.0000000e+00 0.0000000e+00\n",
      "  3.0390641e-01 0.0000000e+00 0.0000000e+00 3.8053057e-01 0.0000000e+00\n",
      "  3.3573234e-01 0.0000000e+00 8.1080836e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.7528228e-01 8.0779558e-03 3.6056891e-01 6.1704306e-04 5.4766631e-01\n",
      "  3.4296331e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.5559753e-02 3.1619024e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.4435990e-01 0.0000000e+00 2.3854436e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.8425299e-02\n",
      "  4.5113564e-02 0.0000000e+00 5.8125538e-01 1.9492890e-01 3.7277889e-01\n",
      "  2.4921900e-01 1.6594437e-01 3.1056184e-02 5.6318015e-01 0.0000000e+00\n",
      "  0.0000000e+00 1.1088966e-02 0.0000000e+00 1.2470048e-01 0.0000000e+00\n",
      "  9.7930185e-02 3.1317255e-01 3.2246682e-01 3.3488521e-01]]\n",
      "Hi!\n",
      "[[1.1376928  0.35507447 1.9691086  0.         0.         1.3036554\n",
      "  0.         0.11590746 0.83529055 0.04561318 0.6664458  0.\n",
      "  0.         0.         0.         0.21663934 0.9150078  0.74389154\n",
      "  0.         0.63196826 1.2170461  0.14595725 0.         0.49626583\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20950907 0.0602978  0.         0.         0.\n",
      "  0.         0.28897634 0.         1.0867261  0.         0.\n",
      "  0.         0.87154824 0.         0.2893815  0.         0.74302083\n",
      "  0.5162701  0.93422747 0.34263787 0.1723271  0.4983325  0.40053093\n",
      "  0.         1.3171842  0.         0.42637813 0.10778204 0.\n",
      "  0.5667156  0.72304606 0.685469   0.67747515]]\n",
      "Hi!\n",
      "[[0.13172866 0.29460904 0.38251773 0.         0.         0.2866424\n",
      "  0.         0.         0.24375784 0.         0.16400297 0.\n",
      "  0.41067645 0.         0.         0.18373203 0.         0.00339493\n",
      "  0.         0.38126796 0.20887023 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06780986 0.18429787 0.         0.         0.         0.\n",
      "  0.         0.         0.05351239 0.03951116 0.         0.\n",
      "  0.         0.02630514 0.07929797 0.         0.         0.27241045\n",
      "  0.         0.163098   0.03696118 0.14453687 0.03847833 0.43712506\n",
      "  0.         0.         0.09741131 0.         0.01299559 0.\n",
      "  0.1271111  0.09746381 0.00980832 0.09155533]]\n",
      "Hi!\n",
      "[[3.6139745e-01 3.7506565e-01 0.0000000e+00 2.1674122e-01 0.0000000e+00\n",
      "  2.4937437e-01 1.2320470e+00 1.4708835e+00 1.6478246e-01 0.0000000e+00\n",
      "  1.4914563e-01 0.0000000e+00 1.0621967e+00 9.4773746e-01 0.0000000e+00\n",
      "  4.2228329e-01 0.0000000e+00 5.0204527e-01 3.0522436e-02 1.5409963e-01\n",
      "  1.3749969e-01 2.3078837e-01 0.0000000e+00 5.5389543e-04 2.6485741e-01\n",
      "  0.0000000e+00 0.0000000e+00 7.3601192e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.4080296e+00 6.2951159e-01 1.9855459e-01 0.0000000e+00 7.8796875e-01\n",
      "  0.0000000e+00 2.0637095e-01 1.1088374e+00 8.1613243e-02 2.0726083e-01\n",
      "  1.5995333e-01 0.0000000e+00 0.0000000e+00 3.8570580e-01 1.2313813e+00\n",
      "  1.1858937e+00 0.0000000e+00 2.9989651e-01 0.0000000e+00 9.2771608e-01\n",
      "  6.3761079e-01 4.6062484e-01 7.1699792e-01 9.1489393e-01 0.0000000e+00\n",
      "  0.0000000e+00 4.5234212e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 5.5249029e-01 5.0958520e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.0939934  0.2808279  0.         0.         0.         0.05155924\n",
      "  0.16059884 0.29055446 0.03717487 0.         0.05267341 0.\n",
      "  0.5275224  0.34955513 0.         0.09843981 0.         0.02853424\n",
      "  0.         0.08135651 0.04826323 0.         0.         0.\n",
      "  0.         0.         0.         0.1599574  0.         0.\n",
      "  0.26988617 0.25576895 0.08951563 0.         0.05850452 0.\n",
      "  0.08178888 0.04056511 0.23886567 0.07204653 0.         0.\n",
      "  0.         0.         0.3265174  0.34217688 0.         0.11221842\n",
      "  0.         0.16527171 0.03146883 0.08856363 0.10491399 0.50584507\n",
      "  0.         0.         0.25269726 0.         0.         0.\n",
      "  0.01408821 0.21218245 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6970024  0.3487211  0.08452572 0.33386165 0.         0.5206979\n",
      "  0.94324523 1.4405928  0.29930964 0.         0.30409896 0.\n",
      "  1.348807   0.89174235 0.         0.5247484  0.         0.61150944\n",
      "  0.49756032 0.21159422 0.37821004 0.26249373 0.         0.08684519\n",
      "  0.22529292 0.         0.         0.8857303  0.         0.\n",
      "  1.478741   0.9073319  0.04190665 0.         0.9034393  0.\n",
      "  0.53379405 1.1739632  0.37657687 0.14468597 0.20269503 0.\n",
      "  0.         0.5112037  1.5026863  1.1291788  0.         0.6832625\n",
      "  0.         0.7568267  0.63646394 0.5851605  0.6944148  1.1165199\n",
      "  0.         0.         0.6583436  0.         0.         0.\n",
      "  0.         0.31154966 1.1047026  0.        ]]\n",
      "Hi!\n",
      "[[0.02865759 0.15935923 0.2645514  0.         0.         0.1239043\n",
      "  0.         0.         0.134139   0.09326266 0.1700248  0.\n",
      "  0.08404528 0.         0.         0.11015367 0.         0.04664694\n",
      "  0.         0.18349361 0.159503   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05153114 0.03195782 0.         0.         0.\n",
      "  0.         0.         0.0066249  0.11404033 0.         0.\n",
      "  0.         0.         0.         0.16112195 0.         0.11328904\n",
      "  0.12893844 0.09081227 0.         0.15272933 0.04185336 0.22478943\n",
      "  0.         0.02873387 0.         0.         0.05366322 0.\n",
      "  0.10177879 0.14810735 0.         0.049197  ]]\n",
      "Hi!\n",
      "[[0.37222072 0.1239666  0.9813801  0.         0.         0.717989\n",
      "  0.8244222  1.0543139  1.3183362  0.         0.5746682  0.\n",
      "  1.2581747  0.         0.         0.95112056 0.         0.84892446\n",
      "  1.1204927  0.         1.0043811  0.09547004 0.         0.\n",
      "  0.37554947 0.         0.         0.5793894  0.         0.\n",
      "  0.90675044 0.5058473  0.         0.         0.6602498  0.\n",
      "  0.8076     1.4541231  0.         0.48040217 0.2523799  0.\n",
      "  0.         0.80671406 0.5695365  0.4028961  0.         0.99712914\n",
      "  0.         0.7402268  1.0482559  0.38593757 0.3490094  0.55116105\n",
      "  0.         0.         0.47224015 0.23664413 0.         0.\n",
      "  0.         0.69437385 1.7355059  0.7693676 ]]\n",
      "Hi!\n",
      "[[1.1525232  0.22211285 1.6801796  0.1215893  0.         1.4382237\n",
      "  0.21545917 0.7172716  0.40151381 0.06386022 0.53157085 0.\n",
      "  0.         0.         0.         0.02325191 0.51921064 0.47605538\n",
      "  0.         0.60081166 1.0653129  0.         0.         0.54057336\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5892402  0.16492356 0.         0.         0.\n",
      "  0.         0.2842359  0.         0.8516831  0.         0.\n",
      "  0.         0.5923349  0.16579632 0.67205113 0.         0.25380355\n",
      "  0.48591453 1.1707947  0.         0.5511845  1.2179627  0.47272196\n",
      "  0.         1.7819608  0.         0.         0.04295085 0.\n",
      "  0.3484642  0.5670144  0.94714445 0.05383654]]\n",
      "Hi!\n",
      "[[0.6279072  0.         0.9767318  0.16301289 0.         0.69682425\n",
      "  1.2877058  1.3510587  1.0505102  0.         0.44409457 0.\n",
      "  0.         0.         0.         0.646481   0.2853882  0.80879986\n",
      "  0.         0.         0.9700764  0.2398868  0.         0.54477185\n",
      "  0.         0.         0.         0.01315451 0.         0.\n",
      "  0.30134207 0.12053267 0.16738968 0.         0.3064496  0.\n",
      "  0.         1.116789   0.         0.7417726  0.09305965 0.\n",
      "  0.         1.3804983  0.         0.53991807 0.         0.\n",
      "  0.         0.94487697 0.48362243 0.22801512 0.61069244 0.\n",
      "  0.         0.32911688 0.         0.15725994 0.         0.\n",
      "  0.         1.207961   1.1841246  0.15880924]]\n",
      "Hi!\n",
      "[[0.01522223 0.10434702 0.06634759 0.         0.         0.\n",
      "  0.03501394 0.18457897 0.02125372 0.0623201  0.0165932  0.\n",
      "  0.08036017 0.16359387 0.         0.05070993 0.         0.04638048\n",
      "  0.         0.00767663 0.10283136 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02197755 0.17332697 0.208421   0.         0.         0.\n",
      "  0.         0.         0.17634605 0.03288488 0.         0.\n",
      "  0.         0.         0.23655532 0.2591947  0.         0.\n",
      "  0.11808527 0.07292362 0.         0.1690025  0.03966663 0.30702356\n",
      "  0.         0.085288   0.04940593 0.         0.         0.\n",
      "  0.06305068 0.14511788 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.49651167 0.579885   0.         0.15705252 0.         0.26548854\n",
      "  0.93031996 1.42446    0.40154374 0.         0.27110997 0.\n",
      "  1.5283731  1.126203   0.         0.61167026 0.         0.61847764\n",
      "  0.46934974 0.17647472 0.32565305 0.3312322  0.         0.17944567\n",
      "  0.24999641 0.         0.         0.9727259  0.         0.\n",
      "  1.5271213  0.7988624  0.03106695 0.         0.8442823  0.\n",
      "  0.47007883 1.1319598  0.29268843 0.10647536 0.08322497 0.\n",
      "  0.         0.49650803 1.3867224  1.1252208  0.         0.48968646\n",
      "  0.         0.9428893  0.81651336 0.41233364 0.734386   1.0739714\n",
      "  0.         0.         0.57681614 0.         0.         0.\n",
      "  0.         0.53993934 0.7745795  0.        ]]\n",
      "Hi!\n",
      "[[4.5674017e-01 9.4728768e-03 8.7297404e-01 6.8747951e-04 0.0000000e+00\n",
      "  8.0508798e-01 8.4469742e-01 9.8122960e-01 6.8868685e-01 0.0000000e+00\n",
      "  4.2987093e-01 0.0000000e+00 3.2637185e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.1349265e-01 0.0000000e+00 6.8262780e-01 0.0000000e+00 0.0000000e+00\n",
      "  8.1417584e-01 0.0000000e+00 0.0000000e+00 1.8644677e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 9.4994865e-02 0.0000000e+00 0.0000000e+00\n",
      "  5.2858436e-01 4.0036288e-01 0.0000000e+00 0.0000000e+00 3.0771613e-01\n",
      "  0.0000000e+00 0.0000000e+00 9.3015730e-01 0.0000000e+00 5.1966816e-01\n",
      "  2.6301119e-02 0.0000000e+00 0.0000000e+00 6.2970823e-01 3.2435259e-01\n",
      "  6.7762274e-01 0.0000000e+00 3.1772447e-01 0.0000000e+00 8.2398063e-01\n",
      "  4.0354764e-01 3.9006624e-01 6.7153263e-01 2.5424781e-01 0.0000000e+00\n",
      "  2.9275283e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.7657443e-01 1.0121188e+00 2.0797332e-01]]\n",
      "Hi!\n",
      "[[0.01467624 0.0782136  0.04466075 0.         0.         0.03115569\n",
      "  0.04830517 0.1804122  0.04331016 0.10508135 0.12101747 0.\n",
      "  0.         0.03570186 0.         0.07326579 0.         0.00454774\n",
      "  0.         0.12092417 0.12001281 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14718477 0.         0.         0.\n",
      "  0.         0.         0.05596261 0.10751722 0.         0.\n",
      "  0.         0.         0.09854653 0.31756634 0.         0.02442859\n",
      "  0.06605127 0.03961776 0.         0.18365192 0.00444389 0.25780246\n",
      "  0.         0.08110251 0.02343445 0.         0.         0.\n",
      "  0.0049301  0.15622136 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.7321981  0.         0.91994315 0.31918624 0.         1.090665\n",
      "  1.0406638  1.2907366  0.31960413 0.05292924 0.3374022  0.\n",
      "  0.         0.         0.         0.13005178 0.08146185 0.5336319\n",
      "  0.         0.12174518 0.71369886 0.         0.         0.3839346\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34725663 0.4719289  0.22094855 0.         0.10168386 0.\n",
      "  0.         0.5798099  0.         0.70252323 0.05885128 0.\n",
      "  0.         0.7661541  0.25785217 0.91946626 0.         0.\n",
      "  0.11665489 1.1332542  0.         0.5244529  1.088288   0.1366529\n",
      "  0.         1.1577846  0.         0.         0.         0.\n",
      "  0.         0.7695027  0.891391   0.        ]]\n",
      "Hi!\n",
      "[[0.25002503 0.30631623 0.23308024 0.01619026 0.         0.\n",
      "  0.         0.19457431 0.10880187 0.         0.         0.\n",
      "  0.44389218 0.23090582 0.         0.         0.         0.09451281\n",
      "  0.         0.06335691 0.02818813 0.         0.         0.\n",
      "  0.         0.         0.         0.14328596 0.         0.\n",
      "  0.19375637 0.33784628 0.08782962 0.         0.         0.\n",
      "  0.         0.         0.4551685  0.03272134 0.         0.\n",
      "  0.         0.09314193 0.36911282 0.18200876 0.         0.07422402\n",
      "  0.11509378 0.20116718 0.01057454 0.30476362 0.04646191 0.64450896\n",
      "  0.         0.         0.11210683 0.         0.         0.\n",
      "  0.05482383 0.10198908 0.03965704 0.        ]]\n",
      "Hi!\n",
      "[[0.31857732 0.01601309 0.3083946  0.03995742 0.         0.58288443\n",
      "  0.48495883 0.6003751  0.04094004 0.19607091 0.17643602 0.\n",
      "  0.         0.         0.         0.19963644 0.         0.40469253\n",
      "  0.         0.34235325 0.20539792 0.         0.         0.01071506\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02373564 0.05290804 0.17529397 0.         0.         0.\n",
      "  0.         0.19769104 0.         0.5062598  0.         0.\n",
      "  0.         0.3257628  0.0926726  0.6998785  0.         0.\n",
      "  0.2588171  0.7729934  0.         0.27987126 0.23451918 0.19152719\n",
      "  0.         0.53159755 0.         0.         0.         0.\n",
      "  0.26024818 0.60801    0.         0.        ]]\n",
      "Hi!\n",
      "[[0.73039824 0.34176323 0.         0.50635827 0.         0.58145577\n",
      "  1.1586528  1.621827   0.         0.         0.08320345 0.\n",
      "  1.2092447  1.0796374  0.         0.26503152 0.         0.37697607\n",
      "  0.19537582 0.31749126 0.16702916 0.27813172 0.         0.05011704\n",
      "  0.1871614  0.         0.         0.99217564 0.         0.\n",
      "  1.6007887  1.048922   0.43021193 0.         0.79690284 0.\n",
      "  0.45348263 1.1554751  0.49617592 0.16032846 0.19297673 0.\n",
      "  0.         0.60611266 1.7080373  1.4244763  0.         0.7430631\n",
      "  0.00427919 0.8155912  0.43491003 0.65074337 0.7061675  1.4619021\n",
      "  0.         0.01604407 0.6718784  0.         0.         0.\n",
      "  0.         0.17872928 0.81262016 0.        ]]\n",
      "Hi!\n",
      "[[1.0493822  0.07246274 2.3937082  0.         0.         0.9530209\n",
      "  0.22451203 0.21099076 1.796099   0.         0.92828256 0.\n",
      "  0.26942536 0.         0.         1.1240203  1.1895984  1.1275986\n",
      "  0.36749694 0.         1.8177068  0.6417939  0.         0.7311744\n",
      "  0.15135735 0.         0.         0.         0.         0.\n",
      "  0.         0.01660952 0.         0.         0.         0.\n",
      "  0.47808257 1.181309   0.         1.2571741  0.19211078 0.\n",
      "  0.         1.6738898  0.         0.         0.         1.0637306\n",
      "  0.         1.1210345  0.9220737  0.         0.27185747 0.\n",
      "  0.         0.34644806 0.         1.3734868  0.06085169 0.\n",
      "  0.         1.2500328  1.4569262  1.3530116 ]]\n",
      "Hi!\n",
      "[[0.9022917  0.29118305 1.4991233  0.         0.         1.1393784\n",
      "  0.33556017 0.38848156 0.85171115 0.12406321 0.60599303 0.\n",
      "  0.02706206 0.         0.         0.1717574  0.4996696  0.689895\n",
      "  0.         0.35124892 1.1401125  0.1251144  0.         0.61085415\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15072757 0.13924491 0.         0.         0.\n",
      "  0.         0.44647306 0.         0.7989841  0.         0.\n",
      "  0.         0.7101709  0.         0.36959314 0.         0.5017308\n",
      "  0.24297507 1.0402197  0.39795798 0.26355892 0.6281523  0.15591972\n",
      "  0.         0.846941   0.         0.33159837 0.05330179 0.\n",
      "  0.1610613  0.77044636 0.68289614 0.75543094]]\n",
      "Hi!\n",
      "[[0.29318306 0.7749962  1.0894887  0.         0.         0.7442561\n",
      "  0.0121514  0.         0.6705828  0.         0.5368781  0.\n",
      "  0.9898199  0.         0.         0.33229285 0.05314745 0.6317325\n",
      "  0.16654016 0.5756295  0.8604139  0.         0.         0.06651101\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26154518 0.4272653  0.         0.         0.         0.\n",
      "  0.03047432 0.51162046 0.         0.66080934 0.         0.\n",
      "  0.         0.01806666 0.23428376 0.1682029  0.         0.82987857\n",
      "  0.18718007 0.6641147  0.4825694  0.3154152  0.40285614 0.57385415\n",
      "  0.         0.09486715 0.         0.         0.11860936 0.\n",
      "  0.         0.5221155  0.68791336 0.7089283 ]]\n",
      "Hi!\n",
      "[[0.7161723  1.3896883  0.5461766  0.         0.         0.3400141\n",
      "  0.         0.41949427 0.5807714  0.         0.50114024 0.\n",
      "  2.3548381  0.72405285 0.         0.67413217 0.         0.6522935\n",
      "  0.98586094 0.69571644 0.5296823  0.05182971 0.         0.28682235\n",
      "  0.17659117 0.         0.         0.6384567  0.         0.\n",
      "  1.2638887  1.0492518  0.         0.         0.5324964  0.\n",
      "  0.641537   0.7865777  0.72302526 0.3536844  0.         0.\n",
      "  0.         0.46458322 1.2148869  0.471283   0.         1.1830407\n",
      "  0.         0.78069854 0.9186881  0.42832524 0.6675866  1.4025728\n",
      "  0.         0.         0.5347767  0.         0.         0.\n",
      "  0.         0.1778634  0.9577709  0.40308625]]\n",
      "Hi!\n",
      "[[0.02931843 0.16468027 0.08608977 0.         0.         0.12862639\n",
      "  0.01349431 0.1431071  0.02144942 0.01558259 0.09617469 0.\n",
      "  0.15845138 0.1818191  0.         0.03307629 0.         0.01428237\n",
      "  0.         0.20068808 0.07212573 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05192614 0.15442148 0.16276307 0.         0.         0.\n",
      "  0.         0.         0.18059568 0.05993981 0.         0.\n",
      "  0.         0.05662184 0.1641917  0.29200557 0.         0.0831779\n",
      "  0.14633232 0.10021912 0.         0.24961068 0.         0.4554101\n",
      "  0.         0.05708034 0.09114646 0.         0.         0.\n",
      "  0.06638228 0.06951176 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.30197915 0.5890512  1.2314103  0.         0.         0.4268689\n",
      "  0.         0.         0.3852357  0.         0.24344908 0.\n",
      "  0.5391536  0.         0.         0.15378441 0.34316137 0.27483186\n",
      "  0.         0.5401101  0.59385806 0.         0.         0.08834295\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24209157 0.20494749 0.         0.         0.\n",
      "  0.         0.         0.06063836 0.5021603  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.5705751\n",
      "  0.43944502 0.6132057  0.39017096 0.26268062 0.28872555 0.67365736\n",
      "  0.         0.28732863 0.         0.11782675 0.16543198 0.\n",
      "  0.27966136 0.17741625 0.42354098 0.48416618]]\n",
      "Hi!\n",
      "[[0.04227825 0.23318502 0.26121458 0.         0.         0.2079349\n",
      "  0.         0.00576001 0.         0.02125902 0.12541294 0.\n",
      "  0.1611299  0.12745745 0.         0.         0.         0.00834229\n",
      "  0.         0.24623944 0.11521302 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01710286 0.21426162 0.06569323 0.         0.         0.\n",
      "  0.         0.         0.20702542 0.12176105 0.         0.\n",
      "  0.         0.         0.20241667 0.20381881 0.         0.16278769\n",
      "  0.25227985 0.12373777 0.         0.2501089  0.12271069 0.35532615\n",
      "  0.         0.16562667 0.01575789 0.         0.03025969 0.\n",
      "  0.10238809 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.2669287  0.21909912 0.29374248 0.0190605  0.         0.5511182\n",
      "  0.11782962 0.40774173 0.         0.13495994 0.18845923 0.\n",
      "  0.         0.14172101 0.         0.         0.         0.15547173\n",
      "  0.         0.5134685  0.15242201 0.         0.         0.0031028\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05389624 0.22724687 0.14409478 0.         0.         0.\n",
      "  0.         0.03008858 0.         0.36110023 0.         0.\n",
      "  0.         0.         0.30123228 0.751498   0.         0.0236534\n",
      "  0.39918378 0.57088226 0.         0.4065385  0.43424696 0.4647991\n",
      "  0.         0.6037883  0.         0.         0.         0.\n",
      "  0.2948891  0.30014354 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.19001202 0.26015458 0.24483734 0.         0.         0.4928405\n",
      "  0.2003634  0.33102095 0.         0.05937999 0.14357002 0.\n",
      "  0.         0.23433176 0.         0.         0.         0.10128325\n",
      "  0.         0.51916134 0.09775441 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19587785 0.32986647 0.20332399 0.         0.         0.\n",
      "  0.         0.05140334 0.11671499 0.20913194 0.         0.\n",
      "  0.         0.         0.45172253 0.7572939  0.         0.20408152\n",
      "  0.43016657 0.4558017  0.         0.41950208 0.31539723 0.682778\n",
      "  0.         0.5950112  0.03130697 0.         0.         0.\n",
      "  0.17395186 0.07373523 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.51069134 0.08292717 0.178564   0.24614486 0.         0.5967342\n",
      "  1.170295   1.5248625  0.4869509  0.         0.28766116 0.\n",
      "  1.0670696  0.5322018  0.         0.53911555 0.         0.60046184\n",
      "  0.37695426 0.         0.4441973  0.17656113 0.         0.\n",
      "  0.23213123 0.         0.         0.72727525 0.         0.\n",
      "  1.2968483  0.67841524 0.         0.         0.77967227 0.\n",
      "  0.41853657 1.3044378  0.         0.17493923 0.20059901 0.\n",
      "  0.         0.41502696 1.1418368  1.042933   0.         0.49379268\n",
      "  0.         0.7176477  0.6061206  0.56023246 0.60844886 0.77963996\n",
      "  0.         0.         0.5093986  0.         0.         0.\n",
      "  0.         0.44552144 1.2199817  0.        ]]\n",
      "Hi!\n",
      "[[0.19325924 0.24835213 0.0912887  0.10261697 0.         0.21584997\n",
      "  0.1299415  0.42427704 0.         0.         0.05088064 0.\n",
      "  0.1507545  0.44189498 0.         0.         0.         0.12471931\n",
      "  0.         0.20676178 0.         0.         0.         0.02087131\n",
      "  0.         0.         0.         0.08964767 0.         0.\n",
      "  0.25749263 0.3239701  0.26300725 0.         0.         0.\n",
      "  0.         0.0051922  0.47871482 0.14242475 0.         0.\n",
      "  0.         0.         0.530108   0.5413575  0.         0.\n",
      "  0.22718088 0.25804374 0.         0.2922846  0.30614385 0.632567\n",
      "  0.         0.26681823 0.12420511 0.         0.         0.\n",
      "  0.07165993 0.16282248 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.0538232  0.04605956 0.         0.         0.07104164\n",
      "  0.12723687 0.26237446 0.         0.16420366 0.0994252  0.\n",
      "  0.         0.08699385 0.         0.06370746 0.         0.08513276\n",
      "  0.         0.14503488 0.06390842 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00403225 0.17950217 0.         0.         0.\n",
      "  0.         0.         0.03553804 0.15488362 0.         0.\n",
      "  0.         0.         0.10258246 0.41600177 0.         0.\n",
      "  0.1362307  0.16810937 0.         0.17159928 0.07086383 0.17950785\n",
      "  0.         0.15167488 0.         0.         0.         0.\n",
      "  0.08891144 0.20927283 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6040376  0.         1.3460436  0.         0.         0.79527736\n",
      "  0.9394288  1.1056716  1.4064087  0.         0.59518784 0.\n",
      "  0.3488194  0.         0.         0.8537206  0.33927172 0.8434624\n",
      "  0.32883078 0.         1.227645   0.25495943 0.         0.5651905\n",
      "  0.00468683 0.         0.         0.18920006 0.         0.\n",
      "  0.36487842 0.31075573 0.03521544 0.         0.28477094 0.\n",
      "  0.22040938 1.2803222  0.         0.6997612  0.29281047 0.\n",
      "  0.         1.3662323  0.         0.33704713 0.         0.4932865\n",
      "  0.         0.7381081  0.76963425 0.2469199  0.48574045 0.\n",
      "  0.         0.14551647 0.04252531 0.4491253  0.         0.\n",
      "  0.         1.0678141  1.570136   0.6472014 ]]\n",
      "Hi!\n",
      "[[0.42893904 0.         0.7129442  0.13077757 0.         0.72360027\n",
      "  1.2264773  1.3338611  0.6614919  0.         0.3884994  0.\n",
      "  0.10260186 0.         0.         0.48408687 0.         0.65895665\n",
      "  0.         0.         0.7710386  0.03718928 0.         0.12929074\n",
      "  0.         0.         0.         0.22576107 0.         0.\n",
      "  0.6446895  0.36730564 0.08185333 0.         0.47960943 0.\n",
      "  0.         1.0579655  0.         0.47031593 0.11419984 0.\n",
      "  0.         0.8511881  0.36764154 0.7319506  0.         0.09801128\n",
      "  0.         0.85243237 0.35925606 0.4053276  0.7527076  0.08763451\n",
      "  0.         0.23152891 0.         0.         0.         0.\n",
      "  0.         0.89904    1.1031204  0.        ]]\n",
      "Hi!\n",
      "[[0.9439231  0.16308582 1.6913552  0.         0.         1.1078802\n",
      "  0.26170024 0.4832496  0.9469532  0.         0.63403696 0.\n",
      "  0.13254075 0.         0.         0.41317815 0.56835955 0.738607\n",
      "  0.         0.18022177 1.2790482  0.05915838 0.         0.6178545\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3267429  0.07245921 0.         0.         0.\n",
      "  0.         0.6619825  0.         0.85909534 0.         0.\n",
      "  0.         0.8783516  0.         0.30832088 0.         0.53857905\n",
      "  0.17559111 0.87619215 0.4347614  0.3168415  0.635355   0.2479261\n",
      "  0.         0.9290261  0.         0.3552426  0.03540551 0.\n",
      "  0.         0.7848933  1.0329498  0.6319505 ]]\n",
      "Hi!\n",
      "[[0.3046278  0.         0.22033113 0.17461357 0.         0.5277159\n",
      "  1.5386804  1.5180804  0.5111428  0.         0.29559454 0.\n",
      "  0.39943823 0.20402186 0.         0.55633444 0.         0.76092803\n",
      "  0.         0.         0.46149293 0.21463376 0.         0.\n",
      "  0.24959667 0.         0.         0.5336223  0.         0.\n",
      "  1.1036733  0.38198236 0.         0.         0.8475934  0.\n",
      "  0.18803298 1.2828275  0.         0.24435876 0.23296517 0.\n",
      "  0.         0.7030249  0.85056096 1.074661   0.         0.19725251\n",
      "  0.         0.8479772  0.509165   0.42687565 0.6054113  0.38201982\n",
      "  0.         0.         0.32028645 0.         0.         0.\n",
      "  0.         0.83769214 1.0461049  0.        ]]\n",
      "Hi!\n",
      "[[0.16690086 0.4099177  0.21176098 0.         0.         0.48275366\n",
      "  0.15959522 0.3858508  0.         0.05040865 0.17634404 0.\n",
      "  0.09978647 0.29952562 0.         0.         0.         0.10424619\n",
      "  0.         0.6149695  0.13718401 0.         0.         0.04895698\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27585793 0.3121526  0.17204615 0.         0.         0.\n",
      "  0.         0.027569   0.13173164 0.2026565  0.         0.\n",
      "  0.         0.         0.47798464 0.7693357  0.         0.23593059\n",
      "  0.410297   0.54128414 0.         0.41706082 0.41821507 0.63145304\n",
      "  0.         0.4610025  0.00785554 0.         0.00293431 0.\n",
      "  0.13750023 0.23343167 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.73974866 0.8043806  0.08771486 0.33462003 0.         0.49614534\n",
      "  0.5757161  1.3293011  0.2754432  0.         0.28278342 0.\n",
      "  1.8931992  1.1939719  0.         0.45378754 0.         0.5043687\n",
      "  0.6935175  0.43323597 0.3552448  0.26616147 0.         0.1287816\n",
      "  0.15637128 0.         0.         0.98610765 0.         0.\n",
      "  1.6351568  1.1026112  0.12453258 0.         0.8246602  0.\n",
      "  0.506218   1.0393538  0.6806043  0.1332082  0.19147092 0.\n",
      "  0.         0.45938167 1.6910851  1.1109172  0.         0.8750107\n",
      "  0.         0.77378064 0.72072685 0.5697489  0.79870903 1.425571\n",
      "  0.         0.         0.6421667  0.         0.         0.\n",
      "  0.         0.18863833 1.0064954  0.        ]]\n",
      "Hi!\n",
      "[[0.5204708  0.7684626  0.7472636  0.         0.         0.4816218\n",
      "  0.26137432 0.597172   1.0541084  0.         0.5292417  0.\n",
      "  1.7558488  0.1977342  0.         0.81361866 0.         0.7151941\n",
      "  1.087282   0.24062003 0.867328   0.         0.         0.01596288\n",
      "  0.36259595 0.         0.         0.41351423 0.         0.\n",
      "  0.95187336 0.66516626 0.         0.         0.51471704 0.\n",
      "  0.685063   1.1102167  0.         0.48983258 0.00753307 0.\n",
      "  0.         0.30905858 0.73915434 0.23287012 0.         1.1766522\n",
      "  0.         0.82100844 0.99925834 0.32470274 0.36804196 0.8243776\n",
      "  0.         0.         0.38702703 0.         0.         0.\n",
      "  0.         0.4453842  1.1984607  0.6976651 ]]\n",
      "Hi!\n",
      "[[0.6684998  0.5360396  1.2665902  0.         0.         1.0267385\n",
      "  0.         0.03436529 0.20429675 0.15470384 0.4552982  0.\n",
      "  0.04220221 0.         0.         0.         0.24003822 0.24152505\n",
      "  0.         0.8788873  0.64499515 0.         0.         0.26283574\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.42705894 0.11464362 0.         0.         0.\n",
      "  0.         0.05071589 0.         0.66571635 0.         0.\n",
      "  0.         0.         0.2069269  0.4882943  0.         0.60261506\n",
      "  0.64235085 0.6403501  0.         0.48743853 0.6456502  0.6845376\n",
      "  0.         1.2066308  0.         0.         0.21712059 0.\n",
      "  0.36491662 0.1742997  0.39325252 0.29306397]]\n",
      "Hi!\n",
      "[[0.49016982 0.85439754 0.44348603 0.         0.         0.39016217\n",
      "  0.08500834 0.49146464 0.4289933  0.         0.4043977  0.\n",
      "  1.4946908  0.569219   0.         0.45027927 0.         0.53047115\n",
      "  0.49191624 0.55024487 0.45002308 0.         0.         0.12342466\n",
      "  0.09693268 0.         0.         0.35397002 0.         0.\n",
      "  0.93872875 0.74087286 0.         0.         0.37287742 0.\n",
      "  0.3600316  0.6863464  0.25515932 0.33186632 0.         0.\n",
      "  0.         0.17517434 0.8688204  0.52950984 0.         0.82048017\n",
      "  0.00482461 0.62123007 0.58045757 0.3116947  0.4514388  0.9296041\n",
      "  0.         0.         0.33513355 0.         0.00533081 0.\n",
      "  0.         0.3335211  0.6274369  0.26199168]]\n",
      "Hi!\n",
      "[[0.51961046 0.         1.1048104  0.         0.         0.71828765\n",
      "  0.96354365 1.0408728  1.1550053  0.         0.5583315  0.\n",
      "  0.3318523  0.         0.         0.7705404  0.12839204 0.83698905\n",
      "  0.16062272 0.         1.0583651  0.09243892 0.         0.34861818\n",
      "  0.03965846 0.         0.         0.20087005 0.         0.\n",
      "  0.4866503  0.30468184 0.         0.         0.3682895  0.\n",
      "  0.19034798 1.2393287  0.         0.63442314 0.22672594 0.\n",
      "  0.         1.1019804  0.1323535  0.47796622 0.         0.45422396\n",
      "  0.         0.7928807  0.66977847 0.25734532 0.41194984 0.12437699\n",
      "  0.         0.         0.1098735  0.23907275 0.         0.\n",
      "  0.         1.0321184  1.3683578  0.48177284]]\n",
      "Hi!\n",
      "[[0.15964703 0.45553797 0.35330552 0.         0.         0.28349906\n",
      "  0.         0.01534431 0.         0.         0.24448939 0.\n",
      "  0.36485067 0.26560047 0.         0.         0.         0.05605901\n",
      "  0.         0.4209439  0.16236259 0.         0.         0.03148222\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1590745  0.36235285 0.09106467 0.         0.         0.\n",
      "  0.         0.         0.41460258 0.12488797 0.         0.\n",
      "  0.         0.         0.32692444 0.2629088  0.         0.21470112\n",
      "  0.4004583  0.17785312 0.         0.3248452  0.22918522 0.64306873\n",
      "  0.         0.20193593 0.11812808 0.         0.03971286 0.\n",
      "  0.1788733  0.01087497 0.02221362 0.        ]]\n",
      "Hi!\n",
      "[[0.02151388 0.18366054 0.06906843 0.         0.         0.18616396\n",
      "  0.1072747  0.17468473 0.         0.04337776 0.12068418 0.\n",
      "  0.11479266 0.16841231 0.         0.         0.         0.04050822\n",
      "  0.         0.19855565 0.07101522 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08019255 0.17480665 0.15099472 0.         0.         0.\n",
      "  0.         0.         0.17849305 0.04780883 0.         0.\n",
      "  0.         0.         0.20668001 0.40545726 0.         0.09952515\n",
      "  0.19986048 0.20845187 0.         0.24445063 0.04775907 0.4326036\n",
      "  0.         0.1238548  0.083518   0.         0.         0.\n",
      "  0.0449715  0.10435647 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.16029054 0.         0.66131026 0.         0.         0.52569383\n",
      "  1.2048095  1.3224844  1.2256788  0.         0.4575142  0.\n",
      "  0.6650905  0.         0.         0.9194547  0.         0.79996943\n",
      "  0.42239976 0.         0.8761769  0.06698278 0.         0.08355685\n",
      "  0.17800419 0.         0.         0.39518026 0.         0.\n",
      "  0.82233715 0.18762901 0.         0.         0.6254252  0.\n",
      "  0.30105847 1.3989973  0.         0.4178632  0.23093636 0.\n",
      "  0.         1.1411339  0.25034705 0.52139485 0.         0.4210815\n",
      "  0.         0.7006915  0.8524765  0.31938434 0.44929603 0.00827473\n",
      "  0.         0.         0.19953975 0.16561171 0.         0.\n",
      "  0.         0.9605607  1.3616383  0.43542895]]\n",
      "Hi!\n",
      "[[0.8443734  0.         0.997213   0.4403136  0.         1.33459\n",
      "  1.1670787  1.3437388  0.13550963 0.11988933 0.2998958  0.\n",
      "  0.         0.         0.         0.13248503 0.12733649 0.5219788\n",
      "  0.         0.30579767 0.68046695 0.         0.         0.30813557\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27762392 0.51042265 0.2041932  0.         0.         0.\n",
      "  0.         0.5137894  0.         0.834958   0.03378918 0.\n",
      "  0.         0.7107134  0.4103919  1.1165498  0.         0.03062821\n",
      "  0.2911921  1.1422772  0.         0.6747248  1.1229602  0.44474807\n",
      "  0.         1.5003747  0.         0.         0.         0.\n",
      "  0.2509752  0.6864436  0.92805445 0.        ]]\n",
      "Hi!\n",
      "[[0.81046504 0.3993335  1.690979   0.         0.         0.94671065\n",
      "  0.12776795 0.00812581 1.0220897  0.00556627 0.70728207 0.\n",
      "  0.39375395 0.         0.         0.53565764 0.5990273  0.86051196\n",
      "  0.         0.28709885 1.3102206  0.19455582 0.         0.4922535\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24609229 0.02490301 0.         0.         0.\n",
      "  0.02666456 0.6010757  0.         1.0003109  0.         0.\n",
      "  0.         0.736291   0.         0.08888125 0.         0.7201741\n",
      "  0.16731507 0.8287174  0.5529064  0.15423954 0.3765523  0.22199687\n",
      "  0.         0.5327279  0.         0.5065346  0.13267429 0.\n",
      "  0.         0.8005155  0.82807744 0.9259843 ]]\n",
      "Hi!\n",
      "[[0.00212695 0.17279758 0.07207277 0.         0.         0.08144081\n",
      "  0.         0.1537868  0.         0.05041815 0.11541849 0.\n",
      "  0.0259435  0.13678882 0.         0.04944919 0.         0.0796504\n",
      "  0.         0.18357614 0.06964479 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04197306 0.13150215 0.15574357 0.         0.         0.\n",
      "  0.         0.         0.12786953 0.07118412 0.         0.\n",
      "  0.         0.         0.17755012 0.31858408 0.         0.01952682\n",
      "  0.18535824 0.15692605 0.         0.16441329 0.00891901 0.3440422\n",
      "  0.         0.14405163 0.03991416 0.         0.         0.\n",
      "  0.09340142 0.14328536 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.10696951 0.3526563  0.22951946 0.         0.         0.13974065\n",
      "  0.         0.1000547  0.         0.         0.12722398 0.\n",
      "  0.31158504 0.30103096 0.         0.         0.         0.11822712\n",
      "  0.         0.24123132 0.08326913 0.         0.         0.\n",
      "  0.         0.         0.         0.0021657  0.         0.\n",
      "  0.16481832 0.37873507 0.15269104 0.         0.         0.\n",
      "  0.         0.         0.3964276  0.06808461 0.         0.\n",
      "  0.         0.         0.39012572 0.272269   0.         0.0882035\n",
      "  0.30074686 0.151733   0.         0.27289823 0.19657885 0.6374747\n",
      "  0.         0.18676834 0.11326738 0.         0.         0.\n",
      "  0.1080214  0.10198398 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.05013274 0.28521362 0.50158614 0.         0.         0.40377152\n",
      "  0.         0.         0.2062652  0.07378948 0.2782572  0.\n",
      "  0.15323779 0.         0.         0.073525   0.         0.02409652\n",
      "  0.         0.49167734 0.2792129  0.         0.         0.03995667\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09010417 0.07137968 0.         0.         0.\n",
      "  0.         0.         0.01142471 0.26450834 0.         0.\n",
      "  0.         0.         0.         0.22666097 0.         0.3580596\n",
      "  0.31499708 0.13204086 0.02190499 0.30672303 0.1396132  0.36620393\n",
      "  0.         0.2382035  0.         0.         0.15885738 0.\n",
      "  0.12912883 0.03870326 0.06495989 0.1643661 ]]\n",
      "Hi!\n",
      "[[0.3506611  0.61908746 0.28968686 0.02391013 0.         0.4686975\n",
      "  0.04375891 0.3435462  0.         0.         0.21323487 0.\n",
      "  0.5016793  0.4862737  0.         0.         0.         0.18921289\n",
      "  0.         0.69608474 0.16643241 0.         0.         0.1770587\n",
      "  0.         0.         0.         0.11188032 0.         0.\n",
      "  0.5628399  0.5907762  0.16630158 0.         0.00685848 0.\n",
      "  0.         0.03413071 0.4838754  0.12976336 0.         0.\n",
      "  0.         0.         0.75226736 0.78546053 0.         0.31113127\n",
      "  0.49992892 0.5081827  0.         0.45599014 0.52985907 0.8809187\n",
      "  0.         0.43764788 0.19834137 0.         0.01172551 0.\n",
      "  0.03875707 0.1416838  0.10401283 0.        ]]\n",
      "Hi!\n",
      "[[0.5931034  1.0002877  1.2901175  0.         0.         0.6784347\n",
      "  0.         0.18715732 0.8623717  0.         0.6584998  0.\n",
      "  1.5829811  0.         0.         0.6508709  0.         0.7627394\n",
      "  0.74256897 0.5481485  0.9819266  0.         0.         0.07272107\n",
      "  0.13954721 0.         0.         0.27681583 0.         0.\n",
      "  0.73320854 0.74297374 0.         0.         0.26753244 0.\n",
      "  0.5017761  0.84353834 0.1948118  0.6602716  0.         0.\n",
      "  0.         0.20943028 0.70714295 0.11070377 0.         1.1009262\n",
      "  0.         0.7912933  0.7877817  0.3966567  0.3508331  0.9256304\n",
      "  0.         0.         0.20786352 0.         0.10877743 0.\n",
      "  0.         0.5063868  1.2129892  0.78223926]]\n",
      "Hi!\n",
      "[[2.86602169e-01 3.57502192e-01 5.30600667e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.58585703e-01 1.19135268e-01 1.67716861e-01\n",
      "  6.77067414e-02 1.48511693e-01 2.74583906e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.07619095e-02\n",
      "  0.00000000e+00 4.13735151e-01 0.00000000e+00 5.89107931e-01\n",
      "  3.31680089e-01 0.00000000e+00 0.00000000e+00 5.26214577e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.28357455e-02 2.11259112e-01\n",
      "  1.36354165e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.53657198e-01 0.00000000e+00 3.80118519e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.80418994e-02\n",
      "  1.79264933e-01 5.64484358e-01 0.00000000e+00 2.33722627e-01\n",
      "  2.94055432e-01 5.92176259e-01 8.08618218e-03 2.49532759e-01\n",
      "  2.64326364e-01 3.59566629e-01 0.00000000e+00 4.42904770e-01\n",
      "  0.00000000e+00 0.00000000e+00 3.90295945e-02 0.00000000e+00\n",
      "  2.66595483e-01 4.36752468e-01 3.51153489e-04 5.64165451e-02]]\n",
      "Hi!\n",
      "[[0.01438641 0.20035161 0.17859219 0.         0.         0.25163448\n",
      "  0.         0.12673613 0.         0.05869238 0.14436193 0.\n",
      "  0.06197945 0.17070197 0.         0.         0.         0.02193907\n",
      "  0.         0.28247103 0.06244228 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03634987 0.15761994 0.10912705 0.         0.         0.\n",
      "  0.         0.         0.16975373 0.1179084  0.         0.\n",
      "  0.         0.         0.21628799 0.36741912 0.         0.07942499\n",
      "  0.27648    0.1883758  0.         0.25387904 0.18778612 0.38339633\n",
      "  0.         0.24116156 0.0055522  0.         0.         0.\n",
      "  0.0829463  0.06494989 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.51864433 0.41817573 1.0080229  0.06465235 0.         1.0098132\n",
      "  0.29612535 0.86643094 0.22084385 0.         0.41255698 0.\n",
      "  0.73712254 0.00391571 0.         0.06503502 0.         0.35730734\n",
      "  0.         0.6197602  0.73664826 0.         0.         0.01101143\n",
      "  0.         0.         0.         0.25825533 0.         0.\n",
      "  0.7954162  0.8578855  0.007187   0.         0.17562845 0.\n",
      "  0.         0.5314265  0.08842348 0.36759365 0.         0.\n",
      "  0.         0.06426238 0.804678   0.827771   0.         0.41249004\n",
      "  0.36892137 0.88755    0.11978184 0.6818147  1.0225015  0.84053576\n",
      "  0.         0.8103146  0.10583501 0.         0.04233408 0.\n",
      "  0.         0.22395773 1.0848678  0.        ]]\n",
      "Hi!\n",
      "[[0.04188368 0.1028197  0.06555282 0.         0.         0.10193918\n",
      "  0.         0.12778744 0.05640948 0.09239046 0.14746918 0.\n",
      "  0.         0.07319964 0.         0.00783247 0.         0.03745567\n",
      "  0.         0.16202472 0.0866557  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03939071 0.11000175 0.         0.         0.\n",
      "  0.         0.         0.06185003 0.08484381 0.         0.\n",
      "  0.         0.         0.0809267  0.2932789  0.         0.03293565\n",
      "  0.10786247 0.04994411 0.         0.15724073 0.         0.2592128\n",
      "  0.         0.14509913 0.00595182 0.         0.02233966 0.\n",
      "  0.06542289 0.08762248 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.47880822 0.680944   0.2486156  0.01738889 0.         0.38761836\n",
      "  0.47989804 1.0121324  0.38251716 0.         0.3505647  0.\n",
      "  1.3574004  0.7810543  0.         0.4773128  0.         0.5193429\n",
      "  0.23220961 0.4315582  0.4332241  0.00237235 0.         0.18638407\n",
      "  0.01503617 0.         0.         0.63822514 0.         0.\n",
      "  1.2644434  0.72221845 0.         0.         0.57670635 0.\n",
      "  0.20161039 0.85898286 0.24956223 0.23259473 0.         0.\n",
      "  0.         0.27663407 1.0776381  0.85690254 0.         0.43764925\n",
      "  0.         0.8562651  0.56906664 0.4709119  0.7288258  0.8133255\n",
      "  0.         0.         0.33209556 0.         0.         0.\n",
      "  0.         0.386735   0.7963348  0.        ]]\n",
      "Hi!\n",
      "[[0.456396   0.5802715  0.53111506 0.         0.         0.530334\n",
      "  0.41100848 0.92750925 0.48944986 0.         0.40691534 0.\n",
      "  1.1422206  0.37200162 0.         0.4046126  0.         0.5428695\n",
      "  0.14564383 0.33313823 0.5756107  0.         0.         0.14244963\n",
      "  0.         0.         0.         0.47650287 0.         0.\n",
      "  1.0962455  0.68059367 0.         0.         0.46615896 0.\n",
      "  0.04299661 0.8164928  0.12418096 0.30284673 0.         0.\n",
      "  0.         0.17196561 0.8192482  0.75727874 0.         0.36700732\n",
      "  0.         0.8619631  0.506014   0.4692492  0.7953826  0.67846566\n",
      "  0.         0.         0.20961219 0.         0.         0.\n",
      "  0.         0.46204653 0.92734206 0.06631249]]\n",
      "Hi!\n",
      "[[0.53745997 0.3239369  0.36534452 0.19396187 0.         0.7789884\n",
      "  0.80652016 1.3722361  0.22568145 0.         0.25630474 0.\n",
      "  1.1005388  0.5250246  0.         0.16900752 0.         0.425266\n",
      "  0.08984356 0.30180565 0.47364014 0.09365278 0.         0.\n",
      "  0.02523327 0.         0.         0.55877906 0.         0.\n",
      "  1.2457544  0.88179207 0.0271867  0.         0.57622564 0.\n",
      "  0.         0.9427267  0.14497797 0.17825828 0.14533626 0.\n",
      "  0.         0.26078206 1.1828401  1.0900296  0.         0.52438945\n",
      "  0.07178286 0.8680154  0.42027968 0.7409606  0.94301885 1.0740291\n",
      "  0.         0.2586443  0.36386597 0.         0.         0.\n",
      "  0.         0.2856919  1.1192814  0.        ]]\n",
      "Hi!\n",
      "[[0.43968633 0.5578788  0.9638842  0.         0.         0.8964814\n",
      "  0.         0.19679777 0.1980407  0.02370576 0.43365157 0.\n",
      "  0.51818067 0.         0.         0.00801624 0.         0.45706248\n",
      "  0.         0.81136984 0.61026376 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2945334  0.5266787  0.         0.         0.         0.\n",
      "  0.         0.31978437 0.         0.48157516 0.         0.\n",
      "  0.         0.         0.53908    0.5472231  0.         0.69188184\n",
      "  0.4782383  0.66524523 0.14118019 0.50039864 0.5942478  0.774707\n",
      "  0.         0.6913191  0.         0.         0.08786066 0.\n",
      "  0.06333514 0.24031645 0.55960935 0.2089499 ]]\n",
      "Hi!\n",
      "[[0.6872902  0.98748815 0.3584896  0.         0.         0.38551307\n",
      "  0.26630864 1.0171772  0.73031056 0.         0.42409843 0.\n",
      "  2.2338324  0.9146761  0.         0.74872124 0.         0.6169138\n",
      "  1.1663488  0.33389592 0.55529845 0.19434269 0.         0.12961222\n",
      "  0.33643097 0.         0.         0.8406987  0.         0.\n",
      "  1.4205168  1.0152619  0.         0.         0.71408707 0.\n",
      "  0.7272513  1.1273463  0.4972415  0.2734719  0.04831826 0.\n",
      "  0.         0.47443736 1.3636125  0.6779777  0.         1.1120657\n",
      "  0.         0.7775079  1.0407015  0.45027432 0.63781047 1.3171782\n",
      "  0.         0.         0.57516265 0.         0.         0.\n",
      "  0.         0.3253417  1.1459558  0.31227905]]\n",
      "Hi!\n",
      "[[0.48983353 0.08328345 0.7307058  0.16291445 0.         0.8489508\n",
      "  0.7597075  1.1154516  0.30912322 0.         0.3661295  0.\n",
      "  0.6206235  0.04955116 0.         0.24758428 0.         0.43399394\n",
      "  0.         0.28646252 0.64848286 0.         0.         0.\n",
      "  0.         0.         0.         0.42799267 0.         0.\n",
      "  0.9075847  0.7860803  0.02631033 0.         0.39586422 0.\n",
      "  0.06517945 0.90314364 0.         0.29613298 0.06830864 0.\n",
      "  0.         0.29158092 0.863168   0.9027164  0.         0.41224808\n",
      "  0.08902896 0.7477407  0.22228746 0.5821521  0.7612892  0.7314801\n",
      "  0.         0.40574977 0.2919284  0.         0.         0.\n",
      "  0.         0.3894781  1.2087094  0.        ]]\n",
      "Hi!\n",
      "[[0.43931758 0.45990375 0.51162785 0.         0.         0.51252574\n",
      "  0.6430294  1.1078146  0.87699884 0.         0.43174565 0.\n",
      "  1.5223571  0.32969007 0.         0.6832825  0.         0.6541144\n",
      "  0.6952488  0.01188979 0.6753758  0.04488419 0.         0.\n",
      "  0.21717903 0.         0.         0.6050097  0.         0.\n",
      "  1.2109239  0.6612484  0.         0.         0.6483212  0.\n",
      "  0.32108665 1.1785133  0.         0.27220693 0.09812935 0.\n",
      "  0.         0.30909005 0.822926   0.60830146 0.         0.62441975\n",
      "  0.         0.74155426 0.89145803 0.4544422  0.72319204 0.6370956\n",
      "  0.         0.         0.35943693 0.         0.         0.\n",
      "  0.         0.50294536 1.3019813  0.33848011]]\n",
      "Hi!\n",
      "[[0.16176647 0.6262344  0.53445697 0.         0.         0.10056674\n",
      "  0.         0.         0.634613   0.         0.36692318 0.\n",
      "  0.6734709  0.         0.         0.3738296  0.08053572 0.21427123\n",
      "  0.         0.34383184 0.5111012  0.         0.         0.00387315\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1320722  0.22905882 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18555531 0.         0.\n",
      "  0.         0.04356638 0.         0.         0.         0.31798762\n",
      "  0.         0.20498705 0.3988467  0.         0.05796143 0.30593634\n",
      "  0.         0.         0.1003243  0.         0.10037057 0.\n",
      "  0.13392773 0.4367015  0.18928535 0.36951423]]\n",
      "Hi!\n",
      "[[0.42629585 0.8196494  0.31348425 0.04274411 0.         0.40398824\n",
      "  0.         0.3187985  0.         0.         0.22010177 0.\n",
      "  0.80474776 0.61144245 0.         0.         0.         0.22301883\n",
      "  0.         0.780733   0.14383224 0.         0.         0.20989819\n",
      "  0.         0.         0.         0.22539157 0.         0.\n",
      "  0.7140695  0.70755416 0.19200845 0.         0.11871939 0.\n",
      "  0.         0.09124367 0.5746083  0.14274484 0.         0.\n",
      "  0.         0.         0.85975367 0.7183834  0.         0.44399604\n",
      "  0.4860824  0.51143396 0.         0.43415755 0.553881   0.98955494\n",
      "  0.         0.3512097  0.3275548  0.         0.00389697 0.\n",
      "  0.01238746 0.14783397 0.17115088 0.        ]]\n",
      "Hi!\n",
      "[[0.04285309 0.16470988 0.11848523 0.         0.         0.0678592\n",
      "  0.         0.05891779 0.06186048 0.07531498 0.17216136 0.\n",
      "  0.0752882  0.12708545 0.         0.         0.         0.06812761\n",
      "  0.         0.19058326 0.12247881 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0233846  0.09441678 0.12212621 0.         0.         0.\n",
      "  0.         0.         0.16424593 0.09819787 0.         0.\n",
      "  0.         0.         0.15149048 0.21112975 0.         0.0674313\n",
      "  0.15204175 0.02047034 0.         0.15681045 0.06882164 0.29553762\n",
      "  0.         0.06583451 0.05038599 0.         0.02245485 0.\n",
      "  0.05270798 0.02747056 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.2729421  0.18670852 0.38555056 0.         0.         0.3888633\n",
      "  1.0313601  1.2327819  1.0871298  0.         0.39638343 0.\n",
      "  1.1667993  0.16472891 0.         0.92455584 0.         0.750091\n",
      "  0.67691934 0.         0.68517095 0.08165181 0.         0.\n",
      "  0.33715826 0.         0.         0.5185498  0.         0.\n",
      "  1.0823925  0.323808   0.         0.         0.7529028  0.\n",
      "  0.5009296  1.3867897  0.         0.3358654  0.1728596  0.\n",
      "  0.         0.7499477  0.61623347 0.5570163  0.         0.63207424\n",
      "  0.         0.7025927  0.9523166  0.34526327 0.38758883 0.3413838\n",
      "  0.         0.         0.36927924 0.         0.         0.\n",
      "  0.         0.73995423 1.1707656  0.40300387]]\n",
      "Hi!\n",
      "[[0.33507442 0.8673568  0.6327955  0.         0.         0.5419321\n",
      "  0.         0.15009125 0.21691579 0.         0.42189282 0.\n",
      "  0.8117638  0.34653136 0.         0.05014933 0.         0.3469427\n",
      "  0.         0.81553507 0.40408695 0.         0.         0.15455668\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.372746   0.48425564 0.         0.         0.         0.\n",
      "  0.         0.09935064 0.32197133 0.27086675 0.         0.\n",
      "  0.         0.         0.51744443 0.6165919  0.         0.5577673\n",
      "  0.39584547 0.4959067  0.13541506 0.4147414  0.5498623  0.8026723\n",
      "  0.         0.21790557 0.08863121 0.         0.09439969 0.\n",
      "  0.         0.19433765 0.2584546  0.10465648]]\n",
      "Hi!\n",
      "[[0.3538605  0.08365818 0.5595267  0.11418927 0.         0.7450782\n",
      "  0.9017691  1.108952   0.41864142 0.         0.32339138 0.\n",
      "  0.4937009  0.         0.         0.33450106 0.         0.5561581\n",
      "  0.         0.1541266  0.60617685 0.         0.         0.\n",
      "  0.         0.         0.         0.25198126 0.         0.\n",
      "  0.7827257  0.52881527 0.         0.         0.4184772  0.\n",
      "  0.         0.9620365  0.         0.3402437  0.04113805 0.\n",
      "  0.         0.37852424 0.6821098  0.82696015 0.         0.35507578\n",
      "  0.         0.8033808  0.3340813  0.4842794  0.6291961  0.5120148\n",
      "  0.         0.15765062 0.18563494 0.         0.         0.\n",
      "  0.         0.6012612  0.99947476 0.        ]]\n",
      "Hi!\n",
      "[[0.4145483  0.         0.         0.5846859  0.         0.7162313\n",
      "  2.1589324  2.111849   0.04449696 0.         0.08626768 0.\n",
      "  0.08796525 0.44981387 0.         0.303091   0.         0.5641271\n",
      "  0.         0.         0.22270763 0.4349522  0.         0.\n",
      "  0.19869776 0.         0.         0.7212893  0.         0.\n",
      "  1.283804   0.5498431  0.37843457 0.         0.9356029  0.\n",
      "  0.11971214 1.3255324  0.03246129 0.33013105 0.38687873 0.\n",
      "  0.         0.7325971  1.2894675  1.5159403  0.         0.06685317\n",
      "  0.         1.0139065  0.27053463 0.7337805  0.7787063  0.7363417\n",
      "  0.         0.16567773 0.4471126  0.         0.         0.\n",
      "  0.         0.7443886  1.0530037  0.        ]]\n",
      "Hi!\n",
      "[[0.29651034 0.         0.         0.30433476 0.         0.4540079\n",
      "  1.6151212  1.8369539  0.50253046 0.         0.17438588 0.\n",
      "  0.8011322  0.6671922  0.         0.6217994  0.         0.60911304\n",
      "  0.09161851 0.         0.3922072  0.2588413  0.         0.\n",
      "  0.26356965 0.         0.         0.7968015  0.         0.\n",
      "  1.4155183  0.46234256 0.07973131 0.         0.9106268  0.\n",
      "  0.19859155 1.3587569  0.         0.22885603 0.29225248 0.\n",
      "  0.         0.6522351  1.0555974  1.1883364  0.         0.15934785\n",
      "  0.         0.95465785 0.62399435 0.54025656 0.8140312  0.5237339\n",
      "  0.         0.         0.36832243 0.         0.         0.\n",
      "  0.         0.72329867 1.1172596  0.        ]]\n",
      "Hi!\n",
      "[[2.7614039e-01 0.0000000e+00 0.0000000e+00 3.9986208e-01 0.0000000e+00\n",
      "  2.5492662e-01 1.9016192e+00 1.7600636e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.7381310e-01 5.2450597e-01 0.0000000e+00\n",
      "  4.5455420e-01 0.0000000e+00 5.1615477e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 3.2617295e-01 0.0000000e+00 0.0000000e+00 3.1508800e-01\n",
      "  0.0000000e+00 0.0000000e+00 6.0422558e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.1218903e+00 3.4404734e-01 5.0079519e-01 0.0000000e+00 7.6775932e-01\n",
      "  0.0000000e+00 3.8137853e-01 1.2207037e+00 8.3317643e-04 2.9843268e-01\n",
      "  2.3694201e-01 0.0000000e+00 0.0000000e+00 5.5976129e-01 1.0857054e+00\n",
      "  1.2615083e+00 0.0000000e+00 6.9124684e-02 0.0000000e+00 8.5445827e-01\n",
      "  3.2742265e-01 4.5302865e-01 3.4260970e-01 7.8179693e-01 0.0000000e+00\n",
      "  4.4938460e-02 4.6458873e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 6.3773859e-01 4.2080671e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.41246575 0.6118026  0.9983119  0.         0.         0.8311542\n",
      "  0.06976843 0.2669044  0.5020155  0.         0.4935918  0.\n",
      "  0.7018831  0.         0.         0.22478619 0.         0.6543906\n",
      "  0.         0.579523   0.796312   0.         0.         0.00810257\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32915866 0.43957123 0.         0.         0.04449476 0.\n",
      "  0.         0.54694295 0.         0.5631621  0.         0.\n",
      "  0.         0.04590739 0.40840963 0.41121393 0.         0.70178884\n",
      "  0.20524095 0.7221292  0.38112423 0.40218055 0.5534451  0.5965643\n",
      "  0.         0.37205964 0.         0.         0.0460237  0.\n",
      "  0.         0.5266213  0.72047764 0.4359685 ]]\n",
      "Hi!\n",
      "[[0.4421182  0.50716275 0.70232016 0.         0.         0.5562218\n",
      "  0.39562687 0.66718644 0.72532094 0.         0.4660757  0.\n",
      "  1.177514   0.06920934 0.         0.57362056 0.         0.6538421\n",
      "  0.4739437  0.26150993 0.71799934 0.         0.         0.\n",
      "  0.2043459  0.         0.         0.27337965 0.         0.\n",
      "  0.80673534 0.57119244 0.         0.         0.4280797  0.\n",
      "  0.36061406 1.0087205  0.         0.4261186  0.         0.\n",
      "  0.         0.21094367 0.6658369  0.4465558  0.         0.7764991\n",
      "  0.         0.6387426  0.72690105 0.3897172  0.4862379  0.68449414\n",
      "  0.         0.         0.24027228 0.         0.         0.\n",
      "  0.         0.52386683 1.0096834  0.40899572]]\n",
      "Hi!\n",
      "[[1.1032097  0.         1.7971982  0.         0.         0.91595435\n",
      "  0.6806473  0.7922396  1.35159    0.         0.7022343  0.\n",
      "  0.         0.         0.         0.7566522  0.9717719  0.8864856\n",
      "  0.         0.         1.4531986  0.54893774 0.         0.79513407\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03557132 0.12496308 0.         0.         0.\n",
      "  0.         1.0067017  0.         0.98833096 0.10257677 0.\n",
      "  0.         1.6613513  0.         0.09567718 0.         0.2962147\n",
      "  0.         0.9196306  0.61252916 0.         0.47193712 0.\n",
      "  0.         0.6843037  0.         0.73787093 0.         0.\n",
      "  0.         1.2359251  1.2220931  0.6481501 ]]\n",
      "Hi!\n",
      "[[0.19772494 0.22845276 0.01701794 0.11929347 0.         0.13559434\n",
      "  0.14912717 0.36053833 0.         0.         0.         0.\n",
      "  0.3525397  0.49775934 0.         0.         0.         0.13683987\n",
      "  0.         0.13652386 0.         0.         0.         0.07326607\n",
      "  0.         0.         0.         0.15402725 0.         0.\n",
      "  0.37923703 0.38857752 0.3144311  0.         0.         0.\n",
      "  0.         0.         0.4682673  0.02421546 0.         0.\n",
      "  0.         0.02325395 0.5683298  0.4345958  0.         0.06463588\n",
      "  0.25431746 0.33324373 0.         0.26254606 0.2380294  0.7491726\n",
      "  0.         0.19485293 0.25536478 0.         0.         0.\n",
      "  0.2377705  0.28916264 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6727879  0.22508256 1.6146398  0.         0.         0.81433827\n",
      "  0.1677716  0.15104346 1.1183677  0.         0.69436985 0.\n",
      "  0.36829874 0.         0.         0.701287   0.54019326 0.94502896\n",
      "  0.21615577 0.20302632 1.2574631  0.25393084 0.         0.26964048\n",
      "  0.12163337 0.         0.         0.         0.         0.\n",
      "  0.         0.179323   0.         0.         0.         0.\n",
      "  0.33321565 0.9482838  0.         0.85428125 0.02683835 0.\n",
      "  0.         0.82127404 0.         0.04431433 0.         0.8849349\n",
      "  0.         0.76184744 0.62839955 0.09532413 0.19755994 0.21613777\n",
      "  0.         0.1208652  0.         0.62645733 0.09664311 0.\n",
      "  0.         0.9126007  1.1589737  0.87110615]]\n",
      "Hi!\n",
      "[[0.31838384 0.24630238 0.41361716 0.         0.         0.56109685\n",
      "  0.28489763 0.34141743 0.         0.12607549 0.21869798 0.\n",
      "  0.         0.         0.         0.10502005 0.         0.32598832\n",
      "  0.         0.58353543 0.27048054 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.177247   0.25754234 0.03904486 0.         0.         0.\n",
      "  0.         0.15337448 0.         0.31642568 0.         0.\n",
      "  0.         0.         0.29608414 0.679079   0.         0.19877754\n",
      "  0.36197352 0.62444586 0.         0.3567323  0.31374463 0.49620023\n",
      "  0.         0.5766256  0.         0.         0.         0.\n",
      "  0.25167003 0.34573668 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.13725683 0.20393533 0.00670813 0.13984267 0.         0.\n",
      "  0.10765528 0.27848896 0.         0.         0.02522478 0.\n",
      "  0.33687994 0.3654327  0.         0.07100339 0.         0.10391594\n",
      "  0.         0.06453523 0.04295342 0.         0.         0.\n",
      "  0.         0.         0.         0.22983302 0.         0.\n",
      "  0.24908426 0.29382116 0.3101057  0.         0.         0.\n",
      "  0.         0.         0.47565618 0.         0.         0.\n",
      "  0.         0.02974519 0.4219375  0.34117976 0.         0.\n",
      "  0.14680672 0.232583   0.         0.22553448 0.19096489 0.65643567\n",
      "  0.         0.02307048 0.26396465 0.         0.         0.\n",
      "  0.15434694 0.20597543 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.26538557 0.2894129  0.02825556 0.         0.         0.23056497\n",
      "  0.8856875  0.79988945 0.09810429 0.         0.11697211 0.\n",
      "  0.42049876 0.26848847 0.         0.2969771  0.         0.49174052\n",
      "  0.         0.25866497 0.12243757 0.         0.         0.\n",
      "  0.13209559 0.         0.         0.19222061 0.         0.\n",
      "  0.7393257  0.2771126  0.09618417 0.         0.39640874 0.\n",
      "  0.1449264  0.801343   0.         0.23345979 0.         0.\n",
      "  0.         0.21077196 0.6429734  0.7694832  0.         0.320886\n",
      "  0.         0.61511296 0.36308074 0.29056698 0.15944971 0.625349\n",
      "  0.         0.         0.27960482 0.         0.         0.\n",
      "  0.         0.46064594 0.28074586 0.        ]]\n",
      "Hi!\n",
      "[[0.438441   0.96213263 0.68139374 0.         0.         0.44540226\n",
      "  0.10403485 0.49291748 0.5789399  0.         0.49694633 0.\n",
      "  1.3452591  0.2908506  0.         0.50467825 0.         0.66400105\n",
      "  0.22097416 0.5607384  0.5962684  0.         0.         0.15220958\n",
      "  0.03563794 0.         0.         0.2815735  0.         0.\n",
      "  0.9093134  0.673664   0.         0.         0.3729155  0.\n",
      "  0.15025459 0.7036931  0.19318198 0.4378904  0.         0.\n",
      "  0.         0.19845511 0.75029325 0.43172804 0.         0.59932524\n",
      "  0.         0.76841784 0.6107831  0.3545644  0.5983875  0.7681647\n",
      "  0.         0.         0.17857456 0.         0.         0.\n",
      "  0.         0.5202432  0.70711786 0.34522882]]\n",
      "Hi!\n",
      "[[0.66595507 0.         0.92219764 0.15938191 0.         0.9326217\n",
      "  1.0080702  1.0228286  0.483109   0.03664616 0.38213512 0.\n",
      "  0.         0.         0.         0.19456814 0.12274501 0.6605108\n",
      "  0.         0.0986281  0.78603727 0.         0.         0.28059763\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23425353 0.3157557  0.13665982 0.         0.18191561 0.\n",
      "  0.         0.73605996 0.         0.6641227  0.00523569 0.\n",
      "  0.         0.7860124  0.1864634  0.69942904 0.         0.12644394\n",
      "  0.03593179 0.8985014  0.16308185 0.39137772 0.6221804  0.20959926\n",
      "  0.         0.69317377 0.         0.         0.         0.\n",
      "  0.         0.8336042  0.8193233  0.00590972]]\n",
      "Hi!\n",
      "[[0.04413489 0.25361958 0.32872912 0.         0.         0.17350157\n",
      "  0.         0.         0.14404128 0.05890529 0.21480657 0.\n",
      "  0.20441353 0.         0.         0.06519653 0.         0.03208927\n",
      "  0.         0.2834534  0.17165671 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12351533 0.01369107 0.         0.         0.\n",
      "  0.         0.         0.03308488 0.17779747 0.         0.\n",
      "  0.         0.         0.0147749  0.14450611 0.         0.20202863\n",
      "  0.21434982 0.14246309 0.00596015 0.21961501 0.06277384 0.32951316\n",
      "  0.         0.03901659 0.         0.         0.10039061 0.\n",
      "  0.09654279 0.06767352 0.         0.08837403]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64198476 0.6472582  1.2857828  0.         0.         1.0226717\n",
      "  0.         0.         0.20461206 0.1464017  0.5005701  0.\n",
      "  0.17470622 0.         0.         0.         0.19716448 0.35334772\n",
      "  0.         1.0326984  0.6590242  0.         0.         0.1914581\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4344396  0.05948615 0.         0.         0.\n",
      "  0.         0.0424469  0.         0.6916271  0.         0.\n",
      "  0.         0.         0.2864893  0.48699173 0.         0.6466909\n",
      "  0.72695094 0.68163675 0.01325562 0.47957978 0.6739688  0.7180444\n",
      "  0.         1.1191373  0.         0.         0.2630097  0.\n",
      "  0.4081245  0.25704658 0.36656764 0.351418  ]]\n",
      "Hi!\n",
      "[[0.01097647 0.07686096 0.08663327 0.         0.         0.12399292\n",
      "  0.         0.18039027 0.         0.08981388 0.12512136 0.\n",
      "  0.         0.13141231 0.         0.         0.         0.03403927\n",
      "  0.         0.16892076 0.04156648 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06975917 0.17457217 0.         0.         0.\n",
      "  0.         0.         0.11741386 0.12161326 0.         0.\n",
      "  0.         0.         0.18710807 0.36587447 0.         0.00074852\n",
      "  0.18841948 0.07579652 0.         0.21117726 0.05726956 0.29639572\n",
      "  0.         0.223254   0.         0.         0.         0.\n",
      "  0.04000814 0.01702381 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.530477   0.         0.05293957 0.4728473  0.         0.64119524\n",
      "  1.3899573  1.7616761  0.14181231 0.         0.19791606 0.\n",
      "  0.64675283 0.66136897 0.         0.315464   0.         0.47758868\n",
      "  0.         0.10531429 0.3068045  0.1489712  0.         0.01835071\n",
      "  0.03432812 0.         0.         0.7879626  0.         0.\n",
      "  1.4017197  0.6971402  0.18217172 0.         0.8003364  0.\n",
      "  0.07100561 1.1211824  0.1248398  0.16543639 0.2749056  0.\n",
      "  0.         0.34667352 1.2858135  1.3905181  0.         0.14310974\n",
      "  0.         0.9016226  0.24488589 0.6819568  0.8967372  0.7230839\n",
      "  0.         0.08088361 0.41619074 0.         0.         0.\n",
      "  0.         0.47706002 1.0631335  0.        ]]\n",
      "Hi!\n",
      "[[0.35495833 0.1895508  1.0547758  0.         0.         0.53910196\n",
      "  0.5786066  0.6348857  1.280892   0.         0.5791225  0.\n",
      "  0.5162359  0.         0.         0.7389769  0.2356112  0.8405829\n",
      "  0.14870799 0.         1.042146   0.25829878 0.         0.3463795\n",
      "  0.04007713 0.         0.         0.         0.         0.\n",
      "  0.3054242  0.12178343 0.         0.         0.20610528 0.\n",
      "  0.04789776 0.9512871  0.         0.7134202  0.10621491 0.\n",
      "  0.         1.0202281  0.         0.12128287 0.         0.3861531\n",
      "  0.         0.80317575 0.80315673 0.14618692 0.41675365 0.\n",
      "  0.         0.         0.         0.33004707 0.         0.\n",
      "  0.         1.0293002  0.8858242  0.7203726 ]]\n",
      "Hi!\n",
      "[[0.46646386 0.         0.8947261  0.         0.         0.40294576\n",
      "  1.0293093  0.93928784 1.0329416  0.         0.46794385 0.\n",
      "  0.         0.         0.         0.6101844  0.4102916  0.8596885\n",
      "  0.         0.         0.9094311  0.38419673 0.         0.2513978\n",
      "  0.02314016 0.         0.         0.         0.         0.\n",
      "  0.02447125 0.         0.08052818 0.         0.29858947 0.\n",
      "  0.         0.99300325 0.         0.54164994 0.04890732 0.\n",
      "  0.         1.2615983  0.         0.19935156 0.         0.07752631\n",
      "  0.         0.6865645  0.52566236 0.00810883 0.26699153 0.\n",
      "  0.         0.         0.         0.28536072 0.         0.\n",
      "  0.         1.225741   0.72215074 0.33355775]]\n",
      "Hi!\n",
      "[[0.         0.1009267  0.08239882 0.         0.         0.12844339\n",
      "  0.04998633 0.23501216 0.         0.09304063 0.05815757 0.\n",
      "  0.         0.14080268 0.         0.01393289 0.         0.04071789\n",
      "  0.         0.15852022 0.04517754 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02426172 0.13407859 0.18652685 0.         0.         0.\n",
      "  0.         0.         0.12573993 0.10993166 0.         0.\n",
      "  0.         0.         0.19186775 0.4081047  0.         0.02705842\n",
      "  0.16427344 0.19337855 0.         0.20350192 0.07887075 0.31513774\n",
      "  0.         0.17018531 0.         0.         0.         0.\n",
      "  0.10621193 0.17197278 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.61575013 0.         0.7773228  0.30533952 0.         0.81334716\n",
      "  1.3383794  1.375451   0.60244733 0.         0.35183546 0.\n",
      "  0.         0.         0.         0.36896583 0.07488906 0.67597926\n",
      "  0.         0.         0.75379395 0.         0.         0.3196776\n",
      "  0.         0.         0.         0.03591157 0.         0.\n",
      "  0.4224047  0.27387714 0.17135373 0.         0.30158484 0.\n",
      "  0.         0.9669395  0.         0.6816288  0.12153217 0.\n",
      "  0.         1.0235541  0.19204053 0.82034034 0.         0.\n",
      "  0.         1.0423408  0.26582345 0.39171046 0.77944523 0.02006821\n",
      "  0.         0.5578749  0.         0.         0.         0.\n",
      "  0.         1.0133368  1.0549412  0.        ]]\n",
      "Hi!\n",
      "[[0.09629336 0.25383398 0.08123752 0.01465013 0.         0.13017617\n",
      "  0.         0.16296056 0.         0.         0.08404382 0.\n",
      "  0.29858625 0.34159237 0.         0.         0.         0.06792689\n",
      "  0.         0.16744122 0.02938338 0.         0.         0.01321431\n",
      "  0.         0.         0.         0.05067305 0.         0.\n",
      "  0.21320638 0.30060828 0.20267963 0.         0.         0.\n",
      "  0.         0.         0.29103795 0.02237164 0.         0.\n",
      "  0.         0.         0.35871884 0.28862226 0.         0.1248313\n",
      "  0.21666358 0.20148878 0.         0.2259305  0.06453086 0.55202496\n",
      "  0.         0.09649698 0.20128028 0.         0.         0.\n",
      "  0.16625729 0.11222329 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.74181986 0.8866919  1.6840527  0.         0.         1.2337829\n",
      "  0.         0.         0.6953781  0.07719899 0.6889614  0.\n",
      "  0.76034236 0.         0.         0.16618069 0.33938923 0.5161571\n",
      "  0.         0.8434799  1.161736   0.         0.         0.5119413\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06595387 0.44594097 0.02539786 0.         0.         0.\n",
      "  0.         0.13722861 0.         0.80454123 0.         0.\n",
      "  0.         0.08233802 0.07571433 0.22366211 0.         0.8464236\n",
      "  0.6071602  0.8881997  0.35884988 0.5024287  0.70141965 0.6761131\n",
      "  0.         0.896112   0.         0.08147423 0.17852268 0.\n",
      "  0.19070305 0.38744456 0.6395338  0.8993352 ]]\n",
      "Hi!\n",
      "[[0.6883729  0.3066433  1.213219   0.         0.         0.8011565\n",
      "  0.11565924 0.03597986 0.65089774 0.13026617 0.4995439  0.\n",
      "  0.         0.         0.         0.15429302 0.45969707 0.63914156\n",
      "  0.         0.44724223 0.8713603  0.03661415 0.         0.29401636\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06097224 0.05352458 0.         0.         0.\n",
      "  0.         0.29246357 0.         0.6426302  0.         0.\n",
      "  0.         0.49578148 0.         0.19444856 0.         0.43776703\n",
      "  0.24112546 0.74807465 0.2968123  0.15309286 0.31616935 0.14740573\n",
      "  0.         0.6047467  0.         0.22404897 0.11944366 0.\n",
      "  0.27775943 0.6972394  0.3830659  0.4938939 ]]\n",
      "Hi!\n",
      "[[0.6484884  0.         0.99737614 0.2789731  0.         0.8044433\n",
      "  1.9448537  1.9533564  1.2544178  0.         0.43804243 0.\n",
      "  0.         0.         0.         0.83267397 0.31865144 0.85365367\n",
      "  0.         0.         1.0319895  0.3775183  0.         0.41874868\n",
      "  0.01625737 0.         0.         0.24433649 0.         0.\n",
      "  0.4913663  0.1186519  0.16866255 0.         0.58710825 0.\n",
      "  0.03668424 1.491324   0.         0.7256402  0.38573697 0.\n",
      "  0.         1.916395   0.         0.602466   0.         0.02595706\n",
      "  0.         0.8442098  0.6081022  0.32539704 0.63381195 0.\n",
      "  0.         0.26210725 0.02603683 0.29003182 0.         0.\n",
      "  0.         1.360494   1.612621   0.1121347 ]]\n",
      "Hi!\n",
      "[[0.7960987  0.16286115 1.6033263  0.         0.         0.8843596\n",
      "  0.21278216 0.28230828 1.0539047  0.         0.67843586 0.\n",
      "  0.25851467 0.         0.         0.6397554  0.5161749  0.8812685\n",
      "  0.         0.15505064 1.2669079  0.18587354 0.         0.4261328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23736946 0.00723193 0.         0.         0.\n",
      "  0.09277678 0.81489086 0.         0.901716   0.04733817 0.\n",
      "  0.         0.902376   0.         0.13036779 0.         0.7043116\n",
      "  0.04350101 0.776452   0.57754225 0.16830269 0.3169778  0.26279798\n",
      "  0.         0.40884042 0.         0.5204063  0.03818    0.\n",
      "  0.         0.8904103  1.0024766  0.7660356 ]]\n",
      "Hi!\n",
      "[[0.5444048  0.         0.7823874  0.20274282 0.         0.67712146\n",
      "  1.1383821  1.2119817  0.8134467  0.0122008  0.41144204 0.\n",
      "  0.         0.         0.         0.43703312 0.16533355 0.80911565\n",
      "  0.         0.         0.7643417  0.15706965 0.         0.45233366\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.36183968 0.05342827 0.22272089 0.         0.25725392 0.\n",
      "  0.         0.8587193  0.         0.80306315 0.01736201 0.\n",
      "  0.         1.2437773  0.         0.6938223  0.         0.\n",
      "  0.         1.1830779  0.38670388 0.23265354 0.767494   0.\n",
      "  0.         0.34616658 0.         0.         0.         0.\n",
      "  0.         1.1638964  0.65921366 0.02693634]]\n",
      "Hi!\n",
      "[[0.5453959  0.2816413  0.7055752  0.20621082 0.         0.80148673\n",
      "  0.56770134 0.8725906  0.01439507 0.         0.354443   0.\n",
      "  0.5471638  0.2528027  0.         0.08538503 0.         0.45428076\n",
      "  0.         0.5514559  0.49855772 0.         0.         0.09303492\n",
      "  0.         0.         0.         0.31530383 0.         0.\n",
      "  0.8563902  0.86926115 0.02568813 0.         0.33928254 0.\n",
      "  0.         0.6101348  0.19271958 0.2871619  0.         0.\n",
      "  0.         0.16473007 0.996947   0.95848596 0.         0.38689095\n",
      "  0.33593744 0.77542365 0.02138024 0.58544976 0.7592418  0.8411911\n",
      "  0.         0.55898786 0.29084376 0.         0.         0.\n",
      "  0.         0.29776147 0.875222   0.        ]]\n",
      "Hi!\n",
      "[[0.24947487 0.         0.17348629 0.27331823 0.         0.6313422\n",
      "  1.8967942  1.9407437  0.73734176 0.         0.2546394  0.\n",
      "  0.5480131  0.19676553 0.         0.73254895 0.         0.7870389\n",
      "  0.08451849 0.         0.574151   0.27471507 0.         0.\n",
      "  0.28235227 0.         0.         0.7251149  0.         0.\n",
      "  1.2949209  0.35756868 0.         0.         0.9268898  0.\n",
      "  0.2921438  1.524807   0.         0.23389669 0.3350021  0.\n",
      "  0.         1.0473506  0.8873875  1.0695537  0.         0.20214334\n",
      "  0.         0.89231527 0.64561856 0.5729027  0.5401814  0.30169147\n",
      "  0.         0.         0.41839927 0.         0.         0.\n",
      "  0.         0.90801084 1.3917545  0.        ]]\n",
      "Hi!\n",
      "[[0.04861298 0.26622304 0.07768299 0.         0.         0.11783062\n",
      "  0.         0.1626825  0.         0.03534788 0.03777651 0.\n",
      "  0.20558676 0.27573028 0.         0.         0.         0.06206029\n",
      "  0.         0.16396688 0.01102196 0.         0.         0.\n",
      "  0.         0.         0.         0.00610596 0.         0.\n",
      "  0.14382274 0.23632741 0.14789742 0.         0.         0.\n",
      "  0.         0.         0.27369487 0.026044   0.         0.\n",
      "  0.         0.         0.33347648 0.28358614 0.         0.07707521\n",
      "  0.19643739 0.15291478 0.         0.20464922 0.12792929 0.47869274\n",
      "  0.         0.08131577 0.10753436 0.         0.         0.\n",
      "  0.11968675 0.05955974 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.8647008  0.19927938 1.4632349  0.         0.         0.98727626\n",
      "  0.23674183 0.39202982 0.6373272  0.05092518 0.56953937 0.\n",
      "  0.         0.         0.         0.20846957 0.41474965 0.7000504\n",
      "  0.         0.35491952 1.0421078  0.         0.         0.45121354\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2902773  0.10367478 0.         0.         0.\n",
      "  0.         0.4734104  0.         0.8168836  0.         0.\n",
      "  0.         0.6921947  0.         0.38750455 0.         0.29967514\n",
      "  0.26681867 0.90182173 0.25139886 0.28652206 0.6309732  0.21166712\n",
      "  0.         0.8853541  0.         0.0913538  0.07004513 0.\n",
      "  0.1855843  0.723935   0.66429216 0.3837406 ]]\n",
      "Hi!\n",
      "[[0.47807065 0.68573785 1.0549849  0.         0.         0.85480917\n",
      "  0.         0.13086562 0.25352418 0.03763811 0.4695992  0.\n",
      "  0.5438974  0.         0.         0.05249976 0.02323485 0.463981\n",
      "  0.         0.83064395 0.7176735  0.         0.         0.1137481\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20141615 0.50565434 0.         0.         0.         0.\n",
      "  0.         0.18281499 0.         0.5543799  0.         0.\n",
      "  0.         0.         0.33417696 0.3918411  0.         0.47420415\n",
      "  0.50141597 0.7422057  0.15432075 0.40236628 0.5781308  0.6498889\n",
      "  0.         0.6174546  0.         0.         0.11103542 0.\n",
      "  0.17922017 0.35564685 0.39470232 0.2822358 ]]\n",
      "Hi!\n",
      "[[0.1468323  0.32839707 0.35216245 0.         0.         0.48683846\n",
      "  0.         0.24118027 0.         0.12192121 0.21757767 0.\n",
      "  0.         0.11764766 0.         0.         0.         0.1633062\n",
      "  0.         0.53750384 0.20033598 0.         0.         0.03182612\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07145521 0.23044513 0.08530103 0.         0.         0.\n",
      "  0.         0.         0.03231221 0.26126328 0.         0.\n",
      "  0.         0.         0.23904623 0.5768677  0.         0.11604869\n",
      "  0.41049352 0.46945006 0.         0.35070604 0.36326328 0.45338598\n",
      "  0.         0.50524986 0.         0.         0.075753   0.\n",
      "  0.2606693  0.20858493 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.10727943 0.04127947 0.         0.         0.05120864\n",
      "  0.04301384 0.1835905  0.00687919 0.0889875  0.09660476 0.\n",
      "  0.03489008 0.12680846 0.         0.04634177 0.         0.02170585\n",
      "  0.         0.07682691 0.105745   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01407888 0.08165482 0.17069085 0.         0.         0.\n",
      "  0.         0.         0.11630297 0.08479001 0.         0.\n",
      "  0.         0.         0.17393117 0.29381007 0.         0.\n",
      "  0.09748175 0.1035599  0.         0.15529528 0.06732702 0.2265698\n",
      "  0.         0.08982383 0.04359056 0.         0.         0.\n",
      "  0.06895415 0.12953034 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.47253782 0.4312276  0.72109914 0.04908609 0.         0.8982047\n",
      "  0.18422131 0.3312997  0.         0.02616038 0.30136797 0.\n",
      "  0.19530766 0.00144049 0.         0.         0.         0.00695336\n",
      "  0.         0.85112065 0.28602692 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20731866 0.61369425 0.10823929 0.         0.         0.\n",
      "  0.         0.16785742 0.2758019  0.3021714  0.         0.\n",
      "  0.         0.1003243  0.6826512  0.799211   0.         0.55844605\n",
      "  0.680369   0.56529766 0.         0.65317965 0.53705484 1.0691584\n",
      "  0.         1.025381   0.01158001 0.         0.06805442 0.\n",
      "  0.1046211  0.         0.4462712  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.27586567 0.28341153 0.         0.         0.31793535\n",
      "  0.         0.06046014 0.13574074 0.06950366 0.1937776  0.\n",
      "  0.1633371  0.08545163 0.         0.02241706 0.         0.07156365\n",
      "  0.         0.30135262 0.1561092  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04255416 0.10120782 0.         0.         0.         0.\n",
      "  0.         0.         0.01263935 0.12138767 0.         0.\n",
      "  0.         0.         0.17627846 0.3126289  0.         0.23750181\n",
      "  0.10984316 0.16296679 0.05130833 0.16838348 0.11077087 0.3565781\n",
      "  0.         0.09263736 0.05614653 0.         0.03868739 0.\n",
      "  0.0661915  0.11055264 0.         0.00784985]]\n",
      "Hi!\n",
      "[[0.60914654 0.         0.8673118  0.38956782 0.         0.82589954\n",
      "  1.6563325  1.7597269  0.9260016  0.         0.3648467  0.\n",
      "  0.         0.         0.         0.6020335  0.15937242 0.7690167\n",
      "  0.         0.         0.90532106 0.14760028 0.         0.44853118\n",
      "  0.         0.         0.         0.1969261  0.         0.\n",
      "  0.5227588  0.26635745 0.23667929 0.         0.43837443 0.\n",
      "  0.         1.2636182  0.         0.6951867  0.26355532 0.\n",
      "  0.         1.411802   0.09112604 0.7441393  0.         0.\n",
      "  0.         0.9536769  0.34726676 0.38522545 0.81235796 0.\n",
      "  0.         0.49482575 0.         0.         0.         0.\n",
      "  0.         1.1622422  1.4667872  0.        ]]\n",
      "Hi!\n",
      "[[0.37485087 0.363168   0.8407056  0.         0.         0.6217961\n",
      "  0.5755428  0.990362   1.2897655  0.         0.5147397  0.\n",
      "  1.5406433  0.         0.         0.8161545  0.         0.68411756\n",
      "  1.1202323  0.         0.9322707  0.01704673 0.         0.\n",
      "  0.31382397 0.         0.         0.50381714 0.         0.\n",
      "  0.96749073 0.5408442  0.         0.         0.58638215 0.\n",
      "  0.63515776 1.2731798  0.         0.3300931  0.20628913 0.\n",
      "  0.         0.5716367  0.5658745  0.3800882  0.         0.96898186\n",
      "  0.         0.8039369  1.0908375  0.45798415 0.5154287  0.57233435\n",
      "  0.         0.         0.38537708 0.04824532 0.         0.\n",
      "  0.         0.5164471  1.5665067  0.74601996]]\n",
      "Hi!\n",
      "[[0.24981888 0.         0.21499    0.20545803 0.         0.3988906\n",
      "  1.5465231  1.4056475  0.5432774  0.         0.2685162  0.\n",
      "  0.         0.         0.         0.48134002 0.         0.68124366\n",
      "  0.         0.         0.48415402 0.10509228 0.         0.03272903\n",
      "  0.01022972 0.         0.         0.10329084 0.         0.\n",
      "  0.5686296  0.05261559 0.14992593 0.         0.51691306 0.\n",
      "  0.         1.0194933  0.         0.58515024 0.1593482  0.\n",
      "  0.         1.060847   0.22331086 0.7362592  0.         0.\n",
      "  0.         0.91552323 0.38020664 0.24714595 0.4398615  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.0469106  0.549582   0.        ]]\n",
      "Hi!\n",
      "[[0.3024117  0.29517138 0.         0.11584852 0.         0.41810837\n",
      "  0.8228856  1.0272975  0.         0.         0.18205616 0.\n",
      "  0.39384168 0.49147046 0.         0.11550111 0.         0.39567667\n",
      "  0.         0.39505175 0.12180153 0.         0.         0.\n",
      "  0.         0.         0.         0.22833076 0.         0.\n",
      "  0.8646041  0.5049501  0.19875447 0.         0.4207385  0.\n",
      "  0.         0.6739396  0.00988902 0.3279033  0.         0.\n",
      "  0.         0.14103553 0.86515194 0.9931752  0.         0.15720598\n",
      "  0.057031   0.80785084 0.15649417 0.44736108 0.5262115  0.6485732\n",
      "  0.         0.05634698 0.25963777 0.         0.         0.\n",
      "  0.         0.43257457 0.26359072 0.        ]]\n",
      "Hi!\n",
      "[[0.27953494 0.8234114  0.7019798  0.         0.         0.5277918\n",
      "  0.         0.         0.01773798 0.         0.36175072 0.\n",
      "  0.7228869  0.18390326 0.         0.         0.         0.34033787\n",
      "  0.         0.84731454 0.32170567 0.         0.         0.06883742\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3139979  0.5092864  0.         0.         0.         0.\n",
      "  0.         0.         0.3271673  0.29783162 0.         0.\n",
      "  0.         0.         0.47235006 0.41580653 0.         0.47732508\n",
      "  0.51635367 0.4326906  0.01785184 0.4112654  0.43369886 0.8003664\n",
      "  0.         0.36130655 0.10455323 0.         0.1214147  0.\n",
      "  0.10589482 0.12427096 0.21855564 0.10992205]]\n",
      "Hi!\n",
      "[[1.10290945e-01 3.09868902e-01 1.60659626e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.60627598e-01 0.00000000e+00 1.48469299e-01\n",
      "  7.38721137e-05 0.00000000e+00 1.90843776e-01 0.00000000e+00\n",
      "  1.05562247e-01 2.38468543e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.67922869e-02 0.00000000e+00 3.53410274e-01\n",
      "  1.13491401e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 8.56626034e-02 2.33141109e-01\n",
      "  1.64523125e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.12723726e-01 1.21628083e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.93025643e-01 4.03648317e-01 0.00000000e+00 6.51400015e-02\n",
      "  2.98899978e-01 1.93190277e-01 0.00000000e+00 3.01063567e-01\n",
      "  1.51251674e-01 4.49705124e-01 0.00000000e+00 2.60678262e-01\n",
      "  1.03512265e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.01730600e-01 7.57976621e-02 0.00000000e+00 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.05495756 0.16508302 0.         0.         0.         0.1540573\n",
      "  0.1582886  0.26470464 0.         0.03585957 0.08924591 0.\n",
      "  0.08995164 0.21899615 0.         0.         0.         0.03384087\n",
      "  0.         0.1907161  0.05076037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15234938 0.17051503 0.23521993 0.         0.         0.\n",
      "  0.         0.         0.24792579 0.06547272 0.         0.\n",
      "  0.         0.00154993 0.2716872  0.47107902 0.         0.0686527\n",
      "  0.16432177 0.22720397 0.         0.22650428 0.07409938 0.49243674\n",
      "  0.         0.09439372 0.10090405 0.         0.         0.\n",
      "  0.04940252 0.15848999 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6089689  1.0615488  0.6829739  0.         0.         0.4022032\n",
      "  0.14082573 0.62851024 1.0876864  0.         0.54564196 0.\n",
      "  2.2487235  0.53053826 0.         0.93122554 0.         0.74915737\n",
      "  1.4116948  0.32438624 0.82308066 0.07083227 0.         0.14556488\n",
      "  0.4376554  0.         0.         0.6227975  0.         0.\n",
      "  1.1745656  0.8625243  0.         0.         0.6222008  0.\n",
      "  0.8366891  1.150101   0.24942325 0.4984663  0.04090599 0.\n",
      "  0.         0.456641   1.0324782  0.26678583 0.         1.3391757\n",
      "  0.         0.88294834 1.1776509  0.3526879  0.43978226 1.1192396\n",
      "  0.         0.         0.51229453 0.         0.0109725  0.\n",
      "  0.         0.4312671  1.2199458  0.72570574]]\n",
      "Hi!\n",
      "[[0.43944347 0.         0.31649852 0.30110914 0.         0.56132036\n",
      "  1.7490911  1.463561   0.37715784 0.         0.24743131 0.\n",
      "  0.         0.         0.         0.3581802  0.         0.7285871\n",
      "  0.         0.         0.4443408  0.10736218 0.         0.0291776\n",
      "  0.         0.         0.         0.06569861 0.         0.\n",
      "  0.51336515 0.0854473  0.19524094 0.         0.5226621  0.\n",
      "  0.         1.0349685  0.         0.6606318  0.16678838 0.\n",
      "  0.         1.0812106  0.31705672 0.87463385 0.         0.\n",
      "  0.         1.0157073  0.2303902  0.27223912 0.45651028 0.02810002\n",
      "  0.         0.10648388 0.         0.         0.         0.\n",
      "  0.         1.148025   0.55247194 0.        ]]\n",
      "Hi!\n",
      "[[0.596668   0.05780377 1.333523   0.         0.         0.80763775\n",
      "  0.5247279  0.6212814  1.2642723  0.         0.6256123  0.\n",
      "  0.3811097  0.         0.         0.6883629  0.335688   0.86999935\n",
      "  0.07648619 0.         1.1698003  0.21181647 0.         0.4979378\n",
      "  0.04710802 0.         0.         0.         0.         0.\n",
      "  0.10867272 0.19415338 0.01481365 0.         0.14092952 0.\n",
      "  0.09079181 0.9590203  0.         0.7643663  0.09963687 0.\n",
      "  0.         1.0626179  0.         0.21294993 0.         0.5584026\n",
      "  0.         0.7270929  0.68173814 0.22199261 0.451526   0.\n",
      "  0.         0.1806873  0.         0.40718827 0.         0.\n",
      "  0.         1.0213995  1.1136336  0.7673066 ]]\n",
      "Hi!\n",
      "[[0.364244   0.26934943 0.         0.2680845  0.         0.37039596\n",
      "  0.6457375  0.7171727  0.         0.00222778 0.         0.\n",
      "  0.21791086 0.6212505  0.         0.01273082 0.         0.08096811\n",
      "  0.         0.4203786  0.         0.         0.         0.06664696\n",
      "  0.         0.         0.         0.37101883 0.         0.\n",
      "  0.7128391  0.5323385  0.49166644 0.         0.07630897 0.\n",
      "  0.         0.20465426 0.4888791  0.0988332  0.         0.\n",
      "  0.         0.14866598 0.8982655  0.92365706 0.         0.090469\n",
      "  0.3445142  0.57246953 0.         0.51524436 0.3973994  0.908417\n",
      "  0.         0.4625598  0.2901013  0.         0.         0.\n",
      "  0.01462773 0.2936567  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5928874  0.5739663  0.32455412 0.02828426 0.         0.58212376\n",
      "  0.4948627  0.85597336 0.13233675 0.         0.27062792 0.\n",
      "  1.0606935  0.5065139  0.         0.26855287 0.         0.47878945\n",
      "  0.08186366 0.49060178 0.34150168 0.         0.         0.04783575\n",
      "  0.11638592 0.         0.         0.4069365  0.         0.\n",
      "  1.015313   0.7901575  0.02476213 0.         0.44287395 0.\n",
      "  0.2887487  0.8642102  0.20856366 0.25483647 0.         0.\n",
      "  0.         0.255028   1.1295797  0.8529488  0.         0.7265904\n",
      "  0.10111597 0.65147376 0.40749002 0.5141661  0.43109438 1.1222014\n",
      "  0.         0.08318831 0.43106332 0.         0.         0.\n",
      "  0.         0.24102445 0.73222667 0.        ]]\n",
      "Hi!\n",
      "[[0.6603427  0.7259901  0.26339307 0.07020751 0.         0.4552299\n",
      "  0.3775443  0.8631332  0.20182589 0.         0.289766   0.\n",
      "  1.3354596  0.771079   0.         0.34030452 0.         0.48977003\n",
      "  0.28813988 0.537136   0.3177306  0.         0.         0.19166583\n",
      "  0.08546888 0.         0.         0.5560663  0.         0.\n",
      "  1.1695839  0.87034094 0.00730718 0.         0.50520486 0.\n",
      "  0.43849593 0.8448205  0.37103212 0.21019635 0.         0.\n",
      "  0.         0.2848356  1.2462654  0.85901314 0.         0.7579365\n",
      "  0.02067648 0.68410724 0.48482195 0.46038842 0.51536286 1.1215125\n",
      "  0.         0.         0.48462015 0.         0.         0.\n",
      "  0.         0.21704479 0.6924022  0.        ]]\n",
      "Hi!\n",
      "[[0.77173674 0.         0.87634325 0.319597   0.         1.1661454\n",
      "  1.3401031  1.4279715  0.2894285  0.05430733 0.32507533 0.\n",
      "  0.         0.         0.         0.10111631 0.07323843 0.51651233\n",
      "  0.         0.15305158 0.69497645 0.01424297 0.         0.22974962\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38629982 0.49024442 0.16403584 0.         0.190558   0.\n",
      "  0.         0.76770204 0.         0.6251439  0.09649692 0.\n",
      "  0.         0.80089736 0.41751194 0.9776833  0.         0.09506344\n",
      "  0.1322321  1.0159743  0.01041637 0.6299122  0.893586   0.3983136\n",
      "  0.         1.1100838  0.         0.         0.         0.\n",
      "  0.         0.75008875 1.0444702  0.        ]]\n",
      "Hi!\n",
      "[[0.7673151  0.16853787 1.5405287  0.         0.         0.99861217\n",
      "  0.23158099 0.31832826 0.8650091  0.         0.636397   0.\n",
      "  0.33532754 0.         0.         0.48544234 0.4073424  0.8296905\n",
      "  0.         0.22047599 1.1823674  0.09242535 0.         0.35332265\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.36565983 0.         0.         0.         0.\n",
      "  0.08261196 0.7639031  0.         0.83122295 0.         0.\n",
      "  0.         0.7169556  0.         0.24803941 0.         0.76917845\n",
      "  0.14300935 0.6893183  0.5002925  0.26229382 0.37635034 0.39904708\n",
      "  0.         0.5762784  0.         0.41556188 0.03924902 0.\n",
      "  0.         0.77114075 1.0168785  0.6857311 ]]\n",
      "Hi!\n",
      "[[0.07157627 0.33089355 0.43308842 0.         0.         0.23987316\n",
      "  0.         0.         0.17277753 0.0269463  0.24036512 0.\n",
      "  0.256367   0.         0.         0.10674226 0.         0.05260588\n",
      "  0.         0.36078677 0.2621797  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09742374 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.19123042 0.         0.\n",
      "  0.         0.         0.         0.08537219 0.         0.2575553\n",
      "  0.19144675 0.18858293 0.05077308 0.2003612  0.10459916 0.3310028\n",
      "  0.         0.         0.         0.         0.13561839 0.\n",
      "  0.13996403 0.09956721 0.         0.15998498]]\n",
      "Hi!\n",
      "[[0.41219324 0.94051    0.4855863  0.01046241 0.         0.31895468\n",
      "  0.         0.15596801 0.         0.         0.27257484 0.\n",
      "  0.8742294  0.59691983 0.         0.         0.         0.21616443\n",
      "  0.         0.738332   0.18372887 0.         0.         0.24110594\n",
      "  0.         0.         0.         0.24542567 0.         0.\n",
      "  0.5761623  0.69256836 0.10077182 0.         0.08425166 0.\n",
      "  0.         0.         0.7325743  0.09016825 0.         0.\n",
      "  0.         0.         0.7370399  0.4715271  0.         0.34563097\n",
      "  0.48678347 0.38526776 0.03871847 0.456125   0.6123267  0.9273946\n",
      "  0.         0.24953073 0.31471932 0.         0.03841013 0.\n",
      "  0.13478571 0.15700519 0.33266285 0.        ]]\n",
      "Hi!\n",
      "[[0.0640555  0.26293674 0.1903674  0.         0.         0.26994577\n",
      "  0.         0.12232886 0.         0.06379166 0.15279458 0.\n",
      "  0.11583947 0.20515288 0.         0.         0.         0.09258656\n",
      "  0.         0.32987064 0.08211659 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09083537 0.19004403 0.09313656 0.         0.         0.\n",
      "  0.         0.         0.09867453 0.10499645 0.         0.\n",
      "  0.         0.         0.25313118 0.39959514 0.         0.12881485\n",
      "  0.27646682 0.2894565  0.         0.22164878 0.1732922  0.46518603\n",
      "  0.         0.19174603 0.01762847 0.         0.01005369 0.\n",
      "  0.13119015 0.112864   0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3419977  0.         0.7409187  0.02602596 0.         0.61378974\n",
      "  1.3184295  1.3700365  1.0800295  0.         0.45256197 0.\n",
      "  0.27201724 0.         0.         0.80634505 0.         0.8147786\n",
      "  0.07108494 0.         0.8850682  0.0823214  0.         0.19552022\n",
      "  0.10123722 0.         0.         0.25983256 0.         0.\n",
      "  0.63936657 0.1777986  0.00137221 0.         0.58130354 0.\n",
      "  0.1379492  1.3590778  0.         0.5198554  0.19355339 0.\n",
      "  0.         1.1938764  0.18655698 0.58081    0.         0.27272528\n",
      "  0.         0.75858426 0.6715335  0.31792146 0.49965018 0.\n",
      "  0.         0.         0.12142412 0.11915316 0.         0.\n",
      "  0.         1.0772988  1.3554535  0.27754533]]\n",
      "Hi!\n",
      "[[0.7311839  0.10750081 0.28267547 0.5818567  0.         0.9457494\n",
      "  1.1631298  1.5040003  0.         0.         0.12641805 0.\n",
      "  0.23082314 0.5831749  0.         0.         0.         0.25290853\n",
      "  0.         0.6740128  0.20797953 0.         0.         0.11624082\n",
      "  0.         0.         0.         0.5510226  0.         0.\n",
      "  1.21706    0.8736352  0.5051978  0.         0.5122733  0.\n",
      "  0.         0.54408866 0.4403002  0.24282935 0.18056154 0.\n",
      "  0.         0.23456877 1.3666096  1.5365295  0.         0.06424695\n",
      "  0.5313203  0.98534566 0.         0.92831844 1.1766682  0.91399175\n",
      "  0.         0.98385775 0.36515212 0.         0.         0.\n",
      "  0.         0.22804236 0.84828293 0.        ]]\n",
      "Hi!\n",
      "[[0.39721265 0.28724787 0.6921946  0.         0.         0.6652425\n",
      "  0.6219181  0.5745466  0.31402555 0.         0.23942015 0.\n",
      "  0.42018837 0.         0.         0.2216699  0.         0.5805938\n",
      "  0.         0.32423714 0.5555868  0.         0.         0.\n",
      "  0.05440605 0.         0.         0.03685044 0.         0.\n",
      "  0.47762352 0.39379674 0.         0.         0.24843924 0.\n",
      "  0.10554466 0.7712041  0.         0.4197549  0.         0.\n",
      "  0.         0.25851774 0.5396194  0.5490984  0.         0.6607332\n",
      "  0.10899002 0.6077442  0.2247343  0.35478148 0.18960781 0.62474066\n",
      "  0.         0.34457427 0.15240698 0.         0.         0.\n",
      "  0.         0.5368931  0.68004596 0.16213088]]\n",
      "Hi!\n",
      "[[0.00810239 0.22052369 0.1948102  0.         0.         0.2295778\n",
      "  0.         0.17754802 0.         0.1085391  0.1092355  0.\n",
      "  0.         0.16885594 0.         0.00238584 0.         0.07006405\n",
      "  0.         0.32932734 0.08358685 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15015092 0.13464394 0.         0.         0.\n",
      "  0.         0.         0.08245081 0.14418326 0.         0.\n",
      "  0.         0.         0.19113357 0.47415367 0.         0.06752629\n",
      "  0.257586   0.2982685  0.         0.27303255 0.1980695  0.41735655\n",
      "  0.         0.23290747 0.         0.         0.         0.\n",
      "  0.10889889 0.18166754 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.2764482  0.2502279  2.3780212  0.         0.         1.1207026\n",
      "  0.16638607 0.11794901 1.4236344  0.         0.88302    0.\n",
      "  0.         0.         0.         0.7655325  1.2512761  0.9332223\n",
      "  0.         0.11612516 1.7171012  0.5305506  0.         0.87465364\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09163243 0.07804669 0.         0.         0.\n",
      "  0.08031687 0.67650205 0.         1.2484039  0.0442115  0.\n",
      "  0.         1.4861507  0.         0.12378959 0.         0.6772583\n",
      "  0.12835497 1.0651029  0.77284145 0.         0.4553006  0.04534956\n",
      "  0.         0.9767612  0.         1.0376574  0.10928684 0.\n",
      "  0.06627607 0.97632706 0.99370044 1.1120595 ]]\n",
      "Hi!\n",
      "[[1.0621845  0.         1.5997447  0.06038886 0.         1.2462127\n",
      "  0.77230144 0.8030923  0.7707305  0.         0.5439377  0.\n",
      "  0.         0.         0.         0.3221091  0.6598191  0.69037414\n",
      "  0.         0.13774942 1.1626654  0.18267137 0.         0.57625914\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3666776  0.14113647 0.         0.         0.\n",
      "  0.         0.64400387 0.         0.8570912  0.         0.\n",
      "  0.         1.1746944  0.         0.4186771  0.         0.32258195\n",
      "  0.16259533 0.95642245 0.27698806 0.30700698 0.68498695 0.23803803\n",
      "  0.         1.2665317  0.         0.26214772 0.         0.\n",
      "  0.19966768 0.8953617  1.050652   0.19052598]]\n",
      "Hi!\n",
      "[[0.67916924 0.         0.929902   0.22119746 0.         1.0009279\n",
      "  1.2343926  1.3342069  0.5174757  0.         0.3847255  0.\n",
      "  0.         0.         0.         0.30574545 0.06689044 0.61515385\n",
      "  0.         0.02925299 0.8292318  0.01724699 0.         0.22488838\n",
      "  0.         0.         0.         0.04337027 0.         0.\n",
      "  0.47819287 0.43862078 0.12228361 0.         0.32322383 0.\n",
      "  0.         0.92160136 0.         0.6336626  0.1190558  0.\n",
      "  0.         0.88132983 0.35923493 0.84662473 0.         0.09377959\n",
      "  0.         0.99080133 0.21346734 0.54251444 0.8501809  0.2811453\n",
      "  0.         0.7327086  0.         0.         0.         0.\n",
      "  0.         0.82035387 1.1274306  0.        ]]\n",
      "Hi!\n",
      "[[0.12521774 0.2699937  0.45827812 0.         0.         0.20921779\n",
      "  0.         0.         0.2082091  0.06451127 0.24752598 0.\n",
      "  0.16466276 0.         0.         0.13412683 0.         0.06214796\n",
      "  0.         0.32071733 0.2469728  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08445563 0.07229882 0.         0.         0.\n",
      "  0.         0.         0.04986734 0.24009779 0.         0.\n",
      "  0.         0.         0.0045994  0.1075947  0.         0.22446074\n",
      "  0.228414   0.18956967 0.08325191 0.23510735 0.14218031 0.3137087\n",
      "  0.         0.095012   0.         0.         0.13051926 0.\n",
      "  0.10821646 0.12309148 0.         0.17600273]]\n",
      "Hi!\n",
      "[[8.8210851e-02 2.0803490e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.5208328e-01 7.0626147e-02 3.1725627e-01 0.0000000e+00 1.0163392e-01\n",
      "  1.4410901e-01 0.0000000e+00 1.1277173e-01 2.9327661e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.7539381e-02 0.0000000e+00 2.1124527e-01\n",
      "  3.6892850e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.2495062e-05 0.0000000e+00 0.0000000e+00\n",
      "  1.3446727e-01 9.6633866e-02 2.1840362e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7565277e-01 1.6121939e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7936548e-01\n",
      "  4.3254635e-01 0.0000000e+00 0.0000000e+00 1.8500015e-01 2.5136822e-01\n",
      "  0.0000000e+00 2.3136963e-01 2.1504062e-01 4.7284186e-01 0.0000000e+00\n",
      "  1.6657323e-01 7.9857081e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.2004523e-01 1.7336972e-01 0.0000000e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.44005334 0.43476793 0.55800796 0.121912   0.         0.7744838\n",
      "  0.11958221 0.4558761  0.         0.04203396 0.20152028 0.\n",
      "  0.10895183 0.31024018 0.         0.         0.         0.16787744\n",
      "  0.         0.85769296 0.18963711 0.         0.         0.05536611\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.47554657 0.6685475  0.1811245  0.         0.         0.\n",
      "  0.         0.05899493 0.2947785  0.27412677 0.         0.\n",
      "  0.         0.         0.803865   0.9011512  0.         0.22742215\n",
      "  0.67947876 0.6705339  0.         0.56475794 0.66724557 0.9212915\n",
      "  0.         0.93162733 0.04057985 0.         0.         0.\n",
      "  0.22782311 0.1232411  0.22491069 0.        ]]\n",
      "Hi!\n",
      "[[0.05325004 0.24528484 0.         0.         0.         0.23806983\n",
      "  0.9518535  1.0244423  0.12494178 0.         0.17194642 0.\n",
      "  0.45064116 0.40950903 0.         0.3055007  0.         0.43300965\n",
      "  0.         0.1622468  0.10241304 0.         0.         0.\n",
      "  0.07985843 0.         0.         0.19696805 0.         0.\n",
      "  0.7163564  0.23834692 0.09500555 0.         0.4327268  0.\n",
      "  0.         0.73802656 0.         0.27376822 0.00199231 0.\n",
      "  0.         0.27214527 0.5955062  0.8607005  0.         0.05584863\n",
      "  0.         0.7220331  0.3519288  0.2705963  0.3365375  0.4233772\n",
      "  0.         0.         0.20341688 0.         0.         0.\n",
      "  0.         0.6134041  0.14161476 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.30595627 0.26863414 0.00225799 0.         0.28722543\n",
      "  0.34777075 0.58443195 0.         0.09145105 0.19100957 0.\n",
      "  0.         0.05763793 0.         0.02693737 0.         0.31088677\n",
      "  0.         0.42311993 0.19339606 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13021281 0.19001086 0.         0.         0.\n",
      "  0.         0.07708906 0.0928821  0.37051567 0.         0.\n",
      "  0.         0.17104064 0.17369722 0.6941811  0.         0.\n",
      "  0.26399353 0.64489096 0.         0.23724441 0.3799516  0.2514593\n",
      "  0.         0.2041189  0.         0.         0.         0.\n",
      "  0.22072266 0.6334169  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.11994067 0.10325389 0.         0.         0.07814036\n",
      "  0.16425712 0.24662837 0.         0.15717427 0.06490963 0.\n",
      "  0.         0.1276284  0.         0.03951788 0.         0.14475003\n",
      "  0.         0.19746017 0.058479   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00098501 0.09160311 0.14879447 0.         0.         0.\n",
      "  0.         0.02540816 0.07488263 0.10374885 0.         0.\n",
      "  0.         0.         0.20547338 0.3868949  0.         0.\n",
      "  0.16344373 0.24853805 0.         0.14281788 0.11194167 0.31836185\n",
      "  0.         0.15298712 0.         0.         0.         0.\n",
      "  0.12194039 0.2866039  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.34998724 0.21002923 0.13199498 0.13091707 0.         0.46995753\n",
      "  0.8318888  0.9029362  0.         0.         0.18463492 0.\n",
      "  0.25229254 0.4527793  0.         0.08724313 0.         0.3806626\n",
      "  0.         0.45994365 0.14129645 0.         0.         0.06926026\n",
      "  0.         0.         0.         0.281889   0.         0.\n",
      "  0.8164422  0.5305758  0.17555264 0.         0.42251447 0.\n",
      "  0.         0.5634608  0.10226624 0.2746169  0.         0.\n",
      "  0.         0.15596013 0.8579846  0.9890439  0.         0.09525628\n",
      "  0.17390165 0.7717378  0.07543859 0.5181957  0.5057914  0.7466623\n",
      "  0.         0.26912746 0.33511257 0.         0.         0.\n",
      "  0.         0.35613722 0.3340149  0.        ]]\n",
      "Hi!\n",
      "[[0.82984346 0.         1.1487602  0.17747946 0.         1.1597868\n",
      "  0.67215633 0.98055995 0.4314052  0.10627854 0.40222502 0.\n",
      "  0.         0.         0.         0.07592602 0.25892493 0.47748858\n",
      "  0.         0.24672824 0.84426767 0.         0.         0.4715346\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11493026 0.38780108 0.17114793 0.         0.         0.\n",
      "  0.         0.5316831  0.         0.7106277  0.         0.\n",
      "  0.         0.66043013 0.14017993 0.76170224 0.         0.09267034\n",
      "  0.22766057 1.057739   0.05895737 0.50150794 0.923691   0.27796233\n",
      "  0.         1.2426541  0.         0.         0.         0.\n",
      "  0.11481227 0.69407576 0.87851834 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.43218932 0.31483492 0.         0.         0.36749193\n",
      "  0.40588132 0.5562843  0.27586672 0.04168756 0.23434278 0.\n",
      "  0.19200003 0.0740464  0.         0.1942979  0.         0.36581403\n",
      "  0.         0.3598167  0.40394112 0.         0.         0.\n",
      "  0.         0.         0.         0.0775456  0.         0.\n",
      "  0.19385457 0.1772952  0.         0.         0.         0.\n",
      "  0.         0.14928865 0.         0.44173127 0.         0.\n",
      "  0.         0.19408488 0.20684041 0.59471345 0.         0.\n",
      "  0.06986854 0.6888685  0.20869318 0.20036095 0.42390865 0.2358472\n",
      "  0.         0.         0.         0.         0.01277445 0.\n",
      "  0.         0.54912716 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.08810639 0.40747207 0.3164757  0.         0.         0.21065252\n",
      "  0.         0.18951291 0.01380194 0.         0.2219246  0.\n",
      "  0.22570023 0.17430858 0.         0.         0.         0.25531563\n",
      "  0.         0.4350823  0.15960456 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16302198 0.29869464 0.04546975 0.         0.         0.\n",
      "  0.         0.03031465 0.1569726  0.17508776 0.         0.\n",
      "  0.         0.         0.28942227 0.37336758 0.         0.08652984\n",
      "  0.29320642 0.3565658  0.         0.26556256 0.16488546 0.46107778\n",
      "  0.         0.15503483 0.0161435  0.         0.         0.\n",
      "  0.15853682 0.28868887 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.40568435 0.         0.6504915  0.         0.         0.44422492\n",
      "  0.72336906 0.7045856  0.6137517  0.10662855 0.33965534 0.\n",
      "  0.         0.         0.         0.28369823 0.3140661  0.6805126\n",
      "  0.         0.         0.6038469  0.39852834 0.         0.09445114\n",
      "  0.08216763 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22351846 0.         0.         0.\n",
      "  0.         0.4447583  0.         0.7813754  0.06566059 0.\n",
      "  0.         1.0964649  0.         0.3167658  0.         0.\n",
      "  0.         0.94832397 0.28262073 0.         0.09862805 0.\n",
      "  0.         0.2041381  0.         0.02273105 0.         0.\n",
      "  0.0635029  1.0343505  0.         0.15492077]]\n",
      "Hi!\n",
      "[[0.34485498 0.8337028  0.727485   0.         0.         0.5957402\n",
      "  0.         0.02862543 0.07059197 0.         0.4036567  0.\n",
      "  0.6698201  0.29918358 0.         0.         0.         0.24997519\n",
      "  0.         0.80945456 0.36738807 0.         0.         0.10854404\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27964225 0.5276376  0.         0.         0.         0.\n",
      "  0.         0.         0.3906203  0.23242341 0.         0.\n",
      "  0.         0.         0.49271122 0.39534727 0.         0.44460055\n",
      "  0.5668014  0.3820983  0.0046492  0.4878058  0.44773766 0.8080467\n",
      "  0.         0.35930285 0.085304   0.         0.05498034 0.\n",
      "  0.12765025 0.07713754 0.17426413 0.13504319]]\n",
      "Hi!\n",
      "[[0.20910212 0.6408517  0.38695458 0.         0.         0.25029448\n",
      "  0.         0.         0.25908592 0.         0.29706705 0.\n",
      "  0.68144715 0.075696   0.         0.11308724 0.         0.11322488\n",
      "  0.         0.45007852 0.3273619  0.         0.         0.06661927\n",
      "  0.         0.         0.         0.06834532 0.         0.\n",
      "  0.3889322  0.34700093 0.         0.         0.         0.\n",
      "  0.         0.         0.16667415 0.11735392 0.         0.\n",
      "  0.         0.         0.07212339 0.0028226  0.         0.3656073\n",
      "  0.14944573 0.33350202 0.22270791 0.14655462 0.24667515 0.52492714\n",
      "  0.00153579 0.         0.17128412 0.         0.16842604 0.\n",
      "  0.04482163 0.05352667 0.04940325 0.17423722]]\n",
      "Hi!\n",
      "[[0.50696164 0.49941248 0.21179922 0.0752585  0.         0.48966143\n",
      "  0.291878   0.5512167  0.         0.         0.09986727 0.\n",
      "  0.63374925 0.5731803  0.         0.04514394 0.         0.24782956\n",
      "  0.         0.6453237  0.03642507 0.         0.         0.14253408\n",
      "  0.         0.         0.         0.34369692 0.         0.\n",
      "  0.81011194 0.73475575 0.256204   0.         0.20164466 0.\n",
      "  0.1377511  0.40351653 0.3615581  0.14329131 0.         0.\n",
      "  0.         0.18186025 0.9138569  0.89689827 0.         0.5101962\n",
      "  0.3738525  0.5543993  0.         0.45118743 0.3831185  1.0231535\n",
      "  0.         0.40888566 0.3376024  0.         0.         0.\n",
      "  0.         0.07512137 0.29646775 0.        ]]\n",
      "Hi!\n",
      "[[3.73035759e-01 0.00000000e+00 6.82168543e-01 8.70486200e-02\n",
      "  0.00000000e+00 5.57728946e-01 1.35241449e+00 1.23595905e+00\n",
      "  8.40220392e-01 0.00000000e+00 3.94455403e-01 0.00000000e+00\n",
      "  8.44590217e-02 0.00000000e+00 0.00000000e+00 6.22630477e-01\n",
      "  0.00000000e+00 8.35508585e-01 0.00000000e+00 0.00000000e+00\n",
      "  7.81687319e-01 6.56530261e-02 0.00000000e+00 1.14305794e-01\n",
      "  1.01588085e-01 0.00000000e+00 0.00000000e+00 1.12209551e-01\n",
      "  0.00000000e+00 0.00000000e+00 5.56290507e-01 1.24438234e-01\n",
      "  3.10047437e-02 0.00000000e+00 5.52431703e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.23943400e+00 0.00000000e+00 5.32184839e-01\n",
      "  1.26864910e-01 0.00000000e+00 0.00000000e+00 1.04046309e+00\n",
      "  2.38067701e-01 6.08389437e-01 0.00000000e+00 2.18227699e-01\n",
      "  0.00000000e+00 7.55757928e-01 4.94303614e-01 2.46473402e-01\n",
      "  3.87221038e-01 9.46042186e-04 0.00000000e+00 0.00000000e+00\n",
      "  8.80645737e-02 1.38380425e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.06841993e+00 1.09062850e+00 1.56835780e-01]]\n",
      "Hi!\n",
      "[[0.17041577 0.18366925 0.3289696  0.02668931 0.         0.48728892\n",
      "  0.03448452 0.16630705 0.         0.03056095 0.16586098 0.\n",
      "  0.06316005 0.16307318 0.         0.         0.         0.05617684\n",
      "  0.         0.423317   0.11499792 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09135412 0.39275953 0.13225755 0.         0.         0.\n",
      "  0.         0.00947901 0.15391172 0.1671786  0.         0.\n",
      "  0.         0.         0.33832067 0.5957616  0.         0.26787847\n",
      "  0.39967528 0.28995758 0.         0.39251682 0.18255527 0.6193591\n",
      "  0.         0.52773386 0.08305112 0.         0.         0.\n",
      "  0.10268037 0.         0.04784026 0.        ]]\n",
      "Hi!\n",
      "[[0.29447538 0.54091257 0.47999927 0.         0.         0.46997377\n",
      "  0.40523311 0.859538   0.40984982 0.         0.39045763 0.\n",
      "  0.8993799  0.29845825 0.         0.3383622  0.         0.48942074\n",
      "  0.         0.34941652 0.50705135 0.         0.         0.13073267\n",
      "  0.         0.         0.         0.40186474 0.         0.\n",
      "  1.007171   0.5770914  0.         0.         0.40843794 0.\n",
      "  0.         0.60391444 0.10487831 0.26878917 0.         0.\n",
      "  0.         0.1542727  0.6217301  0.6866231  0.         0.14306343\n",
      "  0.         0.9055973  0.38964376 0.40066043 0.80049914 0.4688711\n",
      "  0.         0.         0.10942081 0.         0.         0.\n",
      "  0.         0.4901318  0.6729651  0.03137333]]\n",
      "Hi!\n",
      "[[0.50351286 0.98845935 0.959726   0.         0.         0.5749801\n",
      "  0.         0.         0.4009804  0.         0.50284487 0.\n",
      "  1.1818738  0.         0.         0.36085314 0.         0.6416491\n",
      "  0.13128878 0.7767163  0.6269492  0.         0.         0.05462902\n",
      "  0.         0.         0.         0.01251319 0.         0.\n",
      "  0.44482484 0.60384643 0.         0.         0.09652814 0.\n",
      "  0.16829005 0.4659146  0.16137028 0.55678207 0.         0.\n",
      "  0.         0.02207145 0.55716056 0.21809101 0.         0.84415925\n",
      "  0.308295   0.5987237  0.3842779  0.3893273  0.2929326  0.83965343\n",
      "  0.         0.03353566 0.1252373  0.         0.07692312 0.\n",
      "  0.         0.369801   0.62260455 0.45667246]]\n",
      "Hi!\n",
      "[[0.5238099  0.47714955 1.0386199  0.         0.         1.0523635\n",
      "  0.         0.22270177 0.1819965  0.15195453 0.4353988  0.\n",
      "  0.05702058 0.         0.         0.         0.05829644 0.14423098\n",
      "  0.         0.87010103 0.60047466 0.         0.         0.16445735\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02259085 0.32950914 0.12395382 0.         0.         0.\n",
      "  0.         0.08404797 0.         0.47417298 0.         0.\n",
      "  0.         0.         0.37293345 0.66344476 0.         0.45498255\n",
      "  0.66074866 0.6806451  0.         0.6034278  0.7237584  0.72374445\n",
      "  0.         1.0447698  0.         0.         0.0516731  0.\n",
      "  0.24539518 0.08349671 0.3000329  0.10716375]]\n",
      "Hi!\n",
      "[[0.373131   0.15959994 0.63271934 0.         0.         0.7128836\n",
      "  0.8149212  0.84453887 0.3769625  0.         0.34336266 0.\n",
      "  0.34296876 0.         0.         0.28152487 0.         0.6579056\n",
      "  0.         0.20594707 0.6029357  0.         0.         0.\n",
      "  0.07134689 0.         0.         0.06649283 0.         0.\n",
      "  0.586805   0.4225971  0.         0.         0.3280464  0.\n",
      "  0.         0.87785995 0.         0.4211602  0.         0.\n",
      "  0.         0.35366365 0.5404545  0.7040415  0.         0.42503372\n",
      "  0.         0.7822681  0.34054315 0.37887573 0.38710508 0.55003774\n",
      "  0.         0.24160954 0.0991578  0.         0.         0.\n",
      "  0.         0.62767774 0.7343855  0.05953058]]\n",
      "Hi!\n",
      "[[0.6339731  0.         0.8171549  0.0339044  0.         0.744162\n",
      "  0.78571904 0.7858115  0.55554426 0.09431873 0.38281825 0.\n",
      "  0.         0.         0.         0.25492048 0.2701916  0.6991499\n",
      "  0.         0.07951102 0.7007495  0.12843862 0.         0.3161195\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00315213 0.03616992 0.16731878 0.         0.03622616 0.\n",
      "  0.         0.56658185 0.         0.7894461  0.         0.\n",
      "  0.         0.93459296 0.         0.5071477  0.         0.\n",
      "  0.         1.0214535  0.28671545 0.18840966 0.49345988 0.02280009\n",
      "  0.         0.524078   0.         0.         0.         0.\n",
      "  0.12826712 0.9677407  0.33939105 0.12953348]]\n",
      "Hi!\n",
      "[[0.68690896 0.45935446 1.1712523  0.         0.         0.993087\n",
      "  0.18664342 0.43808475 0.4118054  0.06737047 0.49692532 0.\n",
      "  0.29337284 0.         0.         0.0815323  0.06697341 0.53070146\n",
      "  0.         0.56168133 0.86883974 0.         0.         0.35629815\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2294809  0.50699455 0.05658368 0.         0.         0.\n",
      "  0.         0.35433802 0.         0.63606095 0.         0.\n",
      "  0.         0.20109805 0.25894526 0.57088566 0.         0.31857997\n",
      "  0.32787955 0.98251337 0.15631968 0.4452544  0.82802993 0.45531073\n",
      "  0.         0.83733255 0.         0.         0.04380342 0.\n",
      "  0.07982147 0.5263422  0.6544242  0.23372744]]\n",
      "Hi!\n",
      "[[0.35493863 0.51884437 1.0513822  0.         0.         0.6290328\n",
      "  0.34105876 0.5403968  1.1350412  0.         0.60443664 0.\n",
      "  1.2812821  0.         0.         0.79117787 0.         0.81231046\n",
      "  0.8018003  0.03991572 1.0020007  0.         0.         0.\n",
      "  0.27103397 0.         0.         0.22900577 0.         0.\n",
      "  0.65921795 0.45832992 0.         0.         0.4227669  0.\n",
      "  0.48447594 1.1308894  0.         0.62041306 0.10986622 0.\n",
      "  0.         0.47783956 0.41516352 0.20623937 0.         0.9827122\n",
      "  0.         0.8048874  0.91198283 0.29823056 0.3530843  0.501139\n",
      "  0.         0.         0.22051947 0.13161239 0.         0.\n",
      "  0.         0.71787304 1.2397914  0.8224138 ]]\n",
      "Hi!\n",
      "[[1.0084589  0.44291255 1.8490164  0.         0.         1.1904203\n",
      "  0.11698934 0.12610722 0.87450635 0.04400092 0.6946042  0.\n",
      "  0.20057777 0.         0.         0.31927732 0.65427256 0.73609567\n",
      "  0.         0.43244973 1.3316678  0.08046839 0.         0.6587193\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33818707 0.09036364 0.         0.         0.\n",
      "  0.         0.3781155  0.         0.95420974 0.         0.\n",
      "  0.         0.7275841  0.         0.19913673 0.         0.61614615\n",
      "  0.34419307 0.9685206  0.42997923 0.27561623 0.6624432  0.3020988\n",
      "  0.         1.0574944  0.         0.3916138  0.13612762 0.\n",
      "  0.20396644 0.6850162  0.7714862  0.7881604 ]]\n",
      "Hi!\n",
      "[[0.58963925 0.3717058  0.9151496  0.01093583 0.         1.0932913\n",
      "  0.3428991  0.6233042  0.09629894 0.20492986 0.34100327 0.\n",
      "  0.         0.         0.         0.01282407 0.         0.26880294\n",
      "  0.         0.7652824  0.5342691  0.         0.         0.28060824\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31436148 0.2610424  0.         0.         0.\n",
      "  0.         0.15978475 0.         0.77434295 0.         0.\n",
      "  0.         0.27509534 0.24316363 0.9495484  0.         0.04040352\n",
      "  0.4725645  1.1813967  0.         0.49826908 1.0415984  0.38665408\n",
      "  0.         1.1575806  0.         0.         0.02897817 0.\n",
      "  0.4268699  0.5696202  0.11723224 0.        ]]\n",
      "Hi!\n",
      "[[0.44093922 0.         0.         0.51410383 0.         0.46316954\n",
      "  1.7586321  2.0001507  0.22636916 0.         0.1222977  0.\n",
      "  0.8390975  0.88647294 0.         0.49418145 0.         0.5905541\n",
      "  0.0968519  0.         0.21929108 0.4315436  0.         0.\n",
      "  0.3812743  0.         0.         0.8997997  0.         0.\n",
      "  1.559533   0.6465616  0.29596627 0.         1.0102073  0.\n",
      "  0.40884787 1.4125885  0.12203244 0.2666234  0.3140714  0.\n",
      "  0.         0.58273363 1.4295422  1.4484453  0.         0.3203872\n",
      "  0.         0.969672   0.640151   0.64258933 0.82444906 0.96245414\n",
      "  0.         0.         0.5186825  0.         0.         0.\n",
      "  0.         0.6068857  0.9481112  0.        ]]\n",
      "Hi!\n",
      "[[0.12033203 0.5300302  0.7968315  0.         0.         0.4098795\n",
      "  0.         0.         0.3384201  0.00502367 0.37734905 0.\n",
      "  0.4362756  0.         0.         0.06690986 0.06571993 0.12011384\n",
      "  0.         0.5618655  0.47271755 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00506434 0.18113153 0.01043228 0.         0.         0.\n",
      "  0.         0.         0.04655439 0.32305473 0.         0.\n",
      "  0.         0.         0.         0.06598093 0.         0.4799934\n",
      "  0.38773403 0.39320654 0.12121993 0.27901846 0.3450753  0.50382495\n",
      "  0.         0.09212807 0.         0.         0.22749445 0.\n",
      "  0.14686137 0.0638563  0.17293282 0.297038  ]]\n",
      "Hi!\n",
      "[[0.17287578 0.18154101 0.477794   0.         0.         0.530185\n",
      "  0.         0.01489675 0.         0.06768412 0.28207675 0.\n",
      "  0.         0.04224445 0.         0.         0.         0.\n",
      "  0.         0.5008845  0.20427749 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25567737 0.09650862 0.         0.         0.\n",
      "  0.         0.         0.22812651 0.25316748 0.         0.\n",
      "  0.         0.         0.26308677 0.49942994 0.         0.25297785\n",
      "  0.37757975 0.21635558 0.         0.39036754 0.2796677  0.50943446\n",
      "  0.         0.52444804 0.         0.         0.04804837 0.\n",
      "  0.09095187 0.         0.0489329  0.        ]]\n",
      "Hi!\n",
      "[[0.00378187 0.19625007 0.2712152  0.         0.         0.31094047\n",
      "  0.         0.07147023 0.029355   0.10430863 0.20538875 0.\n",
      "  0.         0.03676905 0.         0.         0.         0.06623754\n",
      "  0.         0.3381224  0.13004969 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11081755 0.06126625 0.         0.         0.\n",
      "  0.         0.         0.06938762 0.19674927 0.         0.\n",
      "  0.         0.         0.08378831 0.34485596 0.         0.14785701\n",
      "  0.2794694  0.21303949 0.         0.24311906 0.14041087 0.30902815\n",
      "  0.         0.26629788 0.         0.         0.04766605 0.\n",
      "  0.15213129 0.09967922 0.         0.02664976]]\n",
      "Hi!\n",
      "[[0.15013385 0.27376574 0.3601535  0.         0.         0.2848525\n",
      "  0.         0.         0.2122382  0.04831281 0.21634689 0.\n",
      "  0.28433847 0.         0.         0.1038821  0.         0.01877776\n",
      "  0.         0.29248708 0.22673838 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15950374 0.02765006 0.         0.         0.\n",
      "  0.         0.         0.         0.16622925 0.         0.\n",
      "  0.         0.         0.         0.01444024 0.         0.24547859\n",
      "  0.11734776 0.18132131 0.05217882 0.16526827 0.13836895 0.30982924\n",
      "  0.         0.         0.01700935 0.         0.10507718 0.\n",
      "  0.1423404  0.02842086 0.         0.13321343]]\n",
      "Hi!\n",
      "[[1.1593122  0.1689521  2.2165523  0.         0.         0.9807766\n",
      "  0.39979315 0.25427184 1.8685795  0.         0.89128613 0.\n",
      "  0.13248375 0.         0.         1.034157   1.2512146  1.097362\n",
      "  0.08591916 0.         1.7442306  0.8514744  0.         0.92459244\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04534782 0.         0.         0.\n",
      "  0.29632065 0.93607575 0.         1.3143482  0.2063922  0.\n",
      "  0.         1.8018492  0.         0.         0.         0.7142461\n",
      "  0.         1.1330137  1.1043772  0.         0.24023922 0.\n",
      "  0.         0.38436964 0.         1.2043781  0.         0.\n",
      "  0.         1.223201   1.1253412  1.4146812 ]]\n",
      "Hi!\n",
      "[[0.05417687 0.24113683 0.07743692 0.03099045 0.         0.17869978\n",
      "  0.02066454 0.24589524 0.         0.04746435 0.05520684 0.\n",
      "  0.08972891 0.2968584  0.         0.         0.         0.09961589\n",
      "  0.         0.2005737  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11308587 0.2969593  0.19619183 0.         0.         0.\n",
      "  0.         0.         0.22199124 0.10024559 0.         0.\n",
      "  0.         0.         0.37701654 0.45176744 0.         0.01688339\n",
      "  0.2901127  0.26521105 0.         0.23309764 0.16742279 0.49262485\n",
      "  0.         0.2541332  0.06865076 0.         0.         0.\n",
      "  0.09169845 0.13352391 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.62363726 0.14972648 1.4969535  0.         0.         0.86816615\n",
      "  0.33596912 0.47009248 1.1579616  0.         0.6814026  0.\n",
      "  0.47225496 0.         0.         0.6934305  0.3990037  0.88985205\n",
      "  0.14597875 0.         1.2835705  0.17443886 0.         0.4486034\n",
      "  0.01758481 0.         0.         0.         0.         0.\n",
      "  0.08842951 0.2872727  0.         0.         0.09666675 0.\n",
      "  0.14323303 0.967699   0.         0.79624814 0.11740364 0.\n",
      "  0.         0.9215629  0.         0.13683477 0.         0.6906006\n",
      "  0.         0.7846764  0.6273754  0.16573747 0.38246217 0.17310974\n",
      "  0.         0.24921452 0.         0.4623009  0.01517678 0.\n",
      "  0.         0.93142706 1.2220495  0.7488524 ]]\n",
      "Hi!\n",
      "[[0.2094146  0.         0.36143392 0.23996753 0.         0.70948964\n",
      "  1.301037   1.4312599  0.456467   0.         0.2812877  0.\n",
      "  0.08866123 0.         0.         0.292853   0.         0.6270053\n",
      "  0.         0.         0.4932855  0.         0.         0.09484398\n",
      "  0.         0.         0.         0.25204173 0.         0.\n",
      "  0.85719895 0.32274672 0.13111936 0.         0.46725237 0.\n",
      "  0.         0.8923344  0.         0.52140087 0.09306462 0.\n",
      "  0.         0.7255463  0.3843628  1.0101029  0.         0.\n",
      "  0.         1.1157385  0.3216783  0.4832076  0.87835354 0.08840732\n",
      "  0.         0.17693177 0.         0.         0.         0.\n",
      "  0.         0.874813   0.8125589  0.        ]]\n",
      "Hi!\n",
      "[[0.30941668 0.13178703 0.23698322 0.         0.         0.40559402\n",
      "  1.1290761  1.1207162  0.7525189  0.         0.33105984 0.\n",
      "  0.8519193  0.13167715 0.         0.74974173 0.         0.7861792\n",
      "  0.44512302 0.         0.48195437 0.1165028  0.         0.\n",
      "  0.41145438 0.         0.         0.3401592  0.         0.\n",
      "  0.91607213 0.3422575  0.         0.         0.83860654 0.\n",
      "  0.62741166 1.432497   0.         0.32839075 0.13671403 0.\n",
      "  0.         0.627564   0.7222094  0.61751735 0.         0.75695264\n",
      "  0.         0.64095974 0.7797372  0.29650557 0.18754262 0.6219922\n",
      "  0.         0.         0.4437971  0.         0.         0.\n",
      "  0.         0.6939551  0.9901224  0.22919124]]\n",
      "Hi!\n",
      "[[0.07518115 0.28967056 0.34200326 0.         0.         0.29421735\n",
      "  0.         0.00878143 0.09146741 0.07597032 0.24904114 0.\n",
      "  0.12935607 0.05202519 0.         0.         0.         0.12510245\n",
      "  0.         0.3742612  0.17902707 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15273775 0.01467479 0.         0.         0.\n",
      "  0.         0.         0.08333804 0.19661026 0.         0.\n",
      "  0.         0.         0.13080226 0.28339988 0.         0.19357163\n",
      "  0.3090181  0.15445904 0.         0.22672996 0.10838779 0.43715572\n",
      "  0.         0.19090751 0.         0.         0.07605053 0.\n",
      "  0.10276672 0.08385947 0.         0.05087307]]\n",
      "Hi!\n",
      "[[0.21590163 0.24810296 0.2346039  0.         0.         0.3064656\n",
      "  0.94279367 1.0132483  0.48072886 0.         0.30743295 0.\n",
      "  0.5854118  0.20963147 0.         0.5028493  0.         0.6781786\n",
      "  0.         0.06653561 0.36788437 0.02276734 0.         0.\n",
      "  0.21960156 0.         0.         0.21768384 0.         0.\n",
      "  0.82167953 0.35809964 0.         0.         0.54086137 0.\n",
      "  0.15451887 1.0405923  0.         0.36253607 0.         0.\n",
      "  0.         0.42786524 0.6159248  0.71311164 0.         0.28297454\n",
      "  0.         0.75615716 0.5809481  0.2718697  0.41479918 0.4115884\n",
      "  0.         0.         0.20195875 0.         0.         0.\n",
      "  0.         0.7629224  0.52469766 0.08322276]]\n",
      "Hi!\n",
      "[[0.10428701 0.31090212 0.3591984  0.         0.         0.41464135\n",
      "  0.         0.11777788 0.0647662  0.12831022 0.26850387 0.\n",
      "  0.01782944 0.05415275 0.         0.         0.         0.13406192\n",
      "  0.         0.45420736 0.20222609 0.         0.         0.00506048\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07683691 0.0250837  0.         0.         0.\n",
      "  0.         0.         0.         0.2270643  0.         0.\n",
      "  0.         0.         0.1326533  0.41654763 0.         0.23286463\n",
      "  0.29355705 0.3364566  0.         0.26284942 0.2689818  0.445787\n",
      "  0.         0.3151759  0.         0.         0.05256696 0.\n",
      "  0.1551918  0.16089927 0.         0.01395691]]\n",
      "Hi!\n",
      "[[0.06501785 0.3845859  0.02832275 0.00456537 0.         0.03961133\n",
      "  0.         0.16376041 0.         0.         0.07340512 0.\n",
      "  0.4396603  0.38083735 0.         0.         0.         0.18084964\n",
      "  0.         0.14329238 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.1867539  0.         0.\n",
      "  0.25059986 0.31798556 0.16462548 0.         0.         0.\n",
      "  0.         0.         0.43287474 0.         0.         0.\n",
      "  0.         0.         0.38289958 0.2272224  0.         0.01902088\n",
      "  0.21496177 0.13839866 0.         0.1570855  0.10925528 0.5719547\n",
      "  0.         0.01620402 0.23343015 0.         0.         0.\n",
      "  0.14912258 0.16456231 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07601313 0.37943903 0.43797982 0.         0.         0.24091756\n",
      "  0.         0.         0.19093448 0.01282514 0.24191152 0.\n",
      "  0.26557797 0.0089087  0.         0.11268    0.         0.07924029\n",
      "  0.         0.4060686  0.24155815 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01550334 0.18715273 0.00743322 0.         0.         0.\n",
      "  0.         0.         0.08990269 0.17738406 0.         0.\n",
      "  0.         0.         0.06261086 0.12707217 0.         0.25074148\n",
      "  0.27808207 0.23303686 0.02963309 0.25780204 0.1219062  0.45652524\n",
      "  0.         0.08219782 0.01746563 0.         0.12818098 0.\n",
      "  0.13944627 0.11626134 0.         0.1334212 ]]\n",
      "Hi!\n",
      "[[0.06410149 0.27453104 0.37323135 0.         0.         0.3753203\n",
      "  0.         0.09487262 0.03129642 0.13747643 0.23663485 0.\n",
      "  0.         0.00224656 0.         0.         0.         0.13608775\n",
      "  0.         0.4669603  0.18076108 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11343465 0.02122838 0.         0.         0.\n",
      "  0.         0.         0.0095704  0.25571528 0.         0.\n",
      "  0.         0.         0.06960474 0.43315017 0.         0.16115181\n",
      "  0.32592556 0.30353054 0.         0.25160363 0.21624747 0.3363844\n",
      "  0.         0.3622722  0.         0.         0.09191062 0.\n",
      "  0.18418859 0.15418938 0.         0.05756952]]\n",
      "Hi!\n",
      "[[1.57153495e-02 7.50738904e-02 1.00065731e-01 1.29777435e-02\n",
      "  0.00000000e+00 0.00000000e+00 7.31996959e-03 1.26159266e-01\n",
      "  0.00000000e+00 6.77495077e-02 8.03731531e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.10302076e-01 3.73456023e-05 2.73236707e-02\n",
      "  0.00000000e+00 5.38257174e-02 0.00000000e+00 4.90294211e-02\n",
      "  2.47015860e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.15342163e-01\n",
      "  1.57035664e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.92382276e-01 7.23621324e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.60012648e-01 1.97238371e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.07897736e-01 2.06204262e-02 0.00000000e+00 1.10410944e-01\n",
      "  7.90306628e-02 1.66301280e-01 0.00000000e+00 9.14790332e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.45348644e-02 1.24854054e-02 0.00000000e+00 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.71763444 1.2025342  0.32059243 0.         0.         0.39843905\n",
      "  0.06730093 0.87987465 0.511599   0.         0.42172393 0.\n",
      "  2.3100524  0.9798756  0.         0.5925286  0.         0.54641914\n",
      "  0.9953042  0.53997815 0.46626732 0.19706567 0.         0.2442816\n",
      "  0.1342307  0.         0.         0.84415317 0.         0.\n",
      "  1.5354733  1.0507338  0.         0.         0.6953419  0.\n",
      "  0.610396   0.89367956 0.7948646  0.25543988 0.02629095 0.\n",
      "  0.         0.5360259  1.4313135  0.742175   0.         1.0386975\n",
      "  0.         0.7018417  0.92687833 0.44892275 0.8052775  1.4363304\n",
      "  0.         0.         0.5860262  0.         0.         0.\n",
      "  0.         0.21562566 1.0694205  0.1791677 ]]\n",
      "Hi!\n",
      "[[0.15093201 0.08684535 1.0210873  0.         0.         0.6852204\n",
      "  0.9320122  0.8391597  1.424582   0.         0.6176643  0.\n",
      "  0.8727469  0.         0.         1.07668    0.         0.966522\n",
      "  0.85805166 0.         1.0501575  0.27104855 0.         0.\n",
      "  0.44042176 0.         0.         0.29694608 0.         0.\n",
      "  0.56951284 0.12942643 0.         0.         0.6858954  0.\n",
      "  0.6811474  1.4887168  0.         0.55479133 0.22026196 0.\n",
      "  0.         1.1434723  0.28176734 0.12646084 0.         0.9746344\n",
      "  0.         0.7869192  1.054279   0.21514943 0.12127133 0.2392869\n",
      "  0.         0.         0.3168723  0.46056953 0.         0.\n",
      "  0.         1.0410814  1.4068896  0.8674553 ]]\n",
      "Hi!\n",
      "[[1.1156328  0.53258556 2.2003078  0.         0.         1.2462146\n",
      "  0.         0.         1.0471174  0.         0.7918122  0.\n",
      "  0.4092137  0.         0.         0.56598806 0.9193952  0.8767622\n",
      "  0.         0.5791457  1.5027331  0.25915053 0.         0.53354967\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34904376 0.         0.         0.         0.\n",
      "  0.11549771 0.55325973 0.         1.2243174  0.         0.\n",
      "  0.         0.82651377 0.         0.08595588 0.         1.0119904\n",
      "  0.39909643 0.9965352  0.56046873 0.21472313 0.41315696 0.46772742\n",
      "  0.         0.9224548  0.         0.72638655 0.20151305 0.\n",
      "  0.17048009 0.7119495  1.0423944  1.0359037 ]]\n",
      "Hi!\n",
      "[[0.48821738 0.         0.8714622  0.09258518 0.         0.66430676\n",
      "  1.3018645  1.2794836  0.9635199  0.         0.4429919  0.\n",
      "  0.         0.         0.         0.6803727  0.11490358 0.8238689\n",
      "  0.         0.         0.9371017  0.12990695 0.         0.30618238\n",
      "  0.02653155 0.         0.         0.09739031 0.         0.\n",
      "  0.4231488  0.14047389 0.08164541 0.         0.45111224 0.\n",
      "  0.         1.2266028  0.         0.5924796  0.12288077 0.\n",
      "  0.         1.1980641  0.10890456 0.55273736 0.         0.16167007\n",
      "  0.         0.8089802  0.47197822 0.26909703 0.47302976 0.\n",
      "  0.         0.08824474 0.         0.11507816 0.         0.\n",
      "  0.         1.1355673  1.252187   0.2023977 ]]\n",
      "Hi!\n",
      "[[0.03983666 0.16855739 0.23733273 0.         0.         0.0965377\n",
      "  0.         0.         0.09686664 0.04752616 0.1341753  0.\n",
      "  0.12441263 0.03976837 0.         0.04925981 0.         0.01704704\n",
      "  0.         0.14973398 0.13057266 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08700886 0.06818113 0.         0.         0.\n",
      "  0.         0.         0.10390769 0.086505   0.         0.\n",
      "  0.         0.         0.10032368 0.14653224 0.         0.09295662\n",
      "  0.13419937 0.02377734 0.         0.20080347 0.01717557 0.29897895\n",
      "  0.         0.04199237 0.01405566 0.         0.02483154 0.\n",
      "  0.02988838 0.08213751 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.54372805 0.         0.36983028 0.37067673 0.         0.84032136\n",
      "  1.1801969  1.371052   0.0317741  0.         0.18332703 0.\n",
      "  0.3235511  0.2433984  0.         0.14011778 0.         0.4207515\n",
      "  0.         0.25207335 0.3977331  0.         0.         0.\n",
      "  0.         0.         0.         0.43652737 0.         0.\n",
      "  0.9474431  0.7222372  0.11163708 0.         0.5088671  0.\n",
      "  0.0785054  1.0001936  0.07242574 0.20861773 0.11654116 0.\n",
      "  0.         0.33550286 1.0582975  1.138092   0.         0.3731513\n",
      "  0.08814923 0.7614039  0.06233888 0.6172781  0.6584373  0.77746546\n",
      "  0.         0.46380836 0.33098388 0.         0.         0.\n",
      "  0.         0.41173846 1.015128   0.        ]]\n",
      "Hi!\n",
      "[[0.44445026 0.5212331  0.25024888 0.         0.         0.32367232\n",
      "  0.7370927  1.1621096  0.7567095  0.         0.3627096  0.\n",
      "  1.5699055  0.652401   0.         0.72635317 0.         0.62975717\n",
      "  0.6819993  0.11677945 0.5048566  0.123529   0.         0.01789113\n",
      "  0.33559194 0.         0.         0.6587496  0.         0.\n",
      "  1.3023103  0.6772455  0.         0.         0.75322294 0.\n",
      "  0.45184544 1.2491974  0.01542451 0.23089023 0.05555663 0.\n",
      "  0.         0.37943912 1.0140936  0.7267582  0.         0.6367036\n",
      "  0.         0.78186095 0.92046857 0.41937044 0.6672965  0.7815311\n",
      "  0.         0.         0.43375823 0.         0.         0.\n",
      "  0.         0.533177   1.07238    0.18629578]]\n",
      "Hi!\n",
      "[[0.07853675 0.23106223 0.20069271 0.         0.         0.29761016\n",
      "  0.00553385 0.15619802 0.         0.06493229 0.12130804 0.\n",
      "  0.10603283 0.18314552 0.         0.         0.         0.03207565\n",
      "  0.         0.29029843 0.05358017 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09034744 0.21001683 0.11180223 0.         0.         0.\n",
      "  0.         0.         0.14760296 0.11310268 0.         0.\n",
      "  0.         0.         0.25707084 0.43545836 0.         0.15407401\n",
      "  0.2973759  0.2477878  0.         0.26382545 0.11361079 0.5270026\n",
      "  0.         0.24894768 0.01998323 0.         0.         0.\n",
      "  0.10735649 0.05865396 0.         0.        ]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.924471   0.00144653 1.2633455  0.14778306 0.         1.0941275\n",
      "  0.5147442  0.71652645 0.46586835 0.08621788 0.4440587  0.\n",
      "  0.         0.         0.         0.11411099 0.4438606  0.58128625\n",
      "  0.         0.25589418 0.90700704 0.         0.         0.5484229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30122203 0.17038064 0.         0.         0.\n",
      "  0.         0.43211886 0.         0.83935237 0.         0.\n",
      "  0.         0.8529682  0.         0.54847825 0.         0.02168008\n",
      "  0.22099671 1.1151153  0.12603745 0.3487649  0.7899111  0.1734832\n",
      "  0.         1.2129874  0.         0.         0.         0.\n",
      "  0.3024834  0.75700927 0.654326   0.06014198]]\n",
      "Hi!\n",
      "[[0.12002937 0.23523071 0.22539186 0.00975317 0.         0.32925266\n",
      "  0.         0.16963886 0.         0.01003344 0.14293998 0.\n",
      "  0.05091197 0.25690773 0.         0.         0.         0.03346648\n",
      "  0.         0.35638222 0.07427003 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0969711  0.32481414 0.16558054 0.         0.         0.\n",
      "  0.         0.         0.26390988 0.14773282 0.         0.\n",
      "  0.         0.         0.36411256 0.4883375  0.         0.10830745\n",
      "  0.37165824 0.2703875  0.         0.3417515  0.271848   0.5456092\n",
      "  0.         0.36133727 0.03907347 0.         0.         0.\n",
      "  0.11468457 0.06227785 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.7203174  0.30430114 1.6779108  0.         0.         0.7302335\n",
      "  0.16428997 0.00300035 1.1473366  0.         0.71795905 0.\n",
      "  0.24554957 0.         0.         0.64645636 0.68899447 0.8995318\n",
      "  0.         0.15311597 1.3278079  0.33779734 0.         0.40840003\n",
      "  0.01021399 0.         0.         0.         0.         0.\n",
      "  0.         0.07890712 0.0078094  0.         0.         0.\n",
      "  0.10390577 0.71452355 0.         0.9238006  0.         0.\n",
      "  0.         0.8704562  0.         0.0439483  0.         0.67743576\n",
      "  0.00448686 0.8242019  0.6425116  0.02623929 0.19772448 0.04206815\n",
      "  0.         0.27411687 0.         0.64750785 0.15936849 0.\n",
      "  0.         0.931581   0.8368673  0.924308  ]]\n",
      "Hi!\n",
      "[[0.44262674 0.92134637 0.5270192  0.         0.         0.4454879\n",
      "  0.13058859 0.6261228  0.5177643  0.         0.44613415 0.\n",
      "  1.5536269  0.6035676  0.         0.4166497  0.         0.541644\n",
      "  0.47321555 0.5299176  0.5982691  0.         0.         0.18730235\n",
      "  0.04038702 0.         0.         0.4358153  0.         0.\n",
      "  1.0824225  0.72759724 0.         0.         0.3627079  0.\n",
      "  0.16766001 0.6642073  0.31021956 0.27123025 0.         0.\n",
      "  0.         0.1647771  0.92695224 0.6226758  0.         0.6971745\n",
      "  0.         0.6935154  0.6178653  0.3553487  0.6721967  0.8787574\n",
      "  0.         0.         0.2909109  0.         0.         0.\n",
      "  0.         0.39281926 0.7206255  0.29495645]]\n",
      "Hi!\n",
      "[[0.61196494 0.         0.5051013  0.48235327 0.         0.9566859\n",
      "  1.7961172  1.5611628  0.05712591 0.03075961 0.21617073 0.\n",
      "  0.         0.         0.         0.18785441 0.00263289 0.6477069\n",
      "  0.         0.0173996  0.40883666 0.10947119 0.         0.10195959\n",
      "  0.         0.         0.         0.02128605 0.         0.\n",
      "  0.3729573  0.33327675 0.30136928 0.         0.3180937  0.\n",
      "  0.         0.7078241  0.         0.79089236 0.17559248 0.\n",
      "  0.         1.0010153  0.41012594 1.1269441  0.         0.\n",
      "  0.0380605  1.0951322  0.         0.49824086 0.711637   0.30928907\n",
      "  0.         0.9263333  0.         0.         0.         0.\n",
      "  0.10102644 0.97866607 0.6012715  0.        ]]\n",
      "Hi!\n",
      "[[0.56309843 0.         0.         0.59054244 0.         0.6117198\n",
      "  1.6512938  2.042215   0.22692177 0.         0.16612497 0.\n",
      "  0.8922507  0.87133926 0.         0.41798815 0.         0.5387985\n",
      "  0.18189631 0.         0.2849528  0.41928533 0.         0.02496844\n",
      "  0.19022536 0.         0.         1.0320798  0.         0.\n",
      "  1.6351222  0.82946575 0.26910874 0.         1.0602586  0.\n",
      "  0.33754236 1.2796487  0.18798628 0.15894571 0.40603858 0.\n",
      "  0.         0.59803796 1.5478817  1.5480183  0.         0.2963521\n",
      "  0.         0.9227402  0.43323684 0.72441095 0.91658217 0.98003066\n",
      "  0.         0.         0.6541809  0.         0.         0.\n",
      "  0.         0.4837345  1.2213333  0.        ]]\n",
      "Hi!\n",
      "[[0.5781824  0.         1.0821168  0.04286593 0.         0.82594013\n",
      "  0.9419057  1.1248063  1.047444   0.         0.49285212 0.\n",
      "  0.20784909 0.         0.         0.6109386  0.1873098  0.75215167\n",
      "  0.         0.         1.0258492  0.0538815  0.         0.4530142\n",
      "  0.         0.         0.         0.06718007 0.         0.\n",
      "  0.3952335  0.28578    0.04658597 0.         0.26895148 0.\n",
      "  0.         1.0907297  0.         0.65499234 0.11200567 0.\n",
      "  0.         1.0591011  0.02250616 0.5341606  0.         0.27228862\n",
      "  0.         0.8899114  0.5604186  0.35372066 0.6475098  0.05931526\n",
      "  0.         0.30433217 0.         0.1629432  0.         0.\n",
      "  0.         0.96900964 1.31708    0.34627876]]\n",
      "Hi!\n",
      "[[0.54352254 0.3512147  0.4265766  0.16090049 0.         0.6877811\n",
      "  0.35375592 0.41552955 0.         0.         0.07975554 0.\n",
      "  0.28493133 0.12611069 0.         0.         0.         0.07698582\n",
      "  0.         0.68191326 0.05031827 0.         0.         0.\n",
      "  0.         0.         0.         0.22329749 0.         0.\n",
      "  0.3684287  0.7001178  0.11207038 0.         0.         0.\n",
      "  0.         0.2122225  0.41747972 0.25053513 0.         0.\n",
      "  0.         0.17138454 0.7212845  0.67469084 0.         0.41823134\n",
      "  0.61809677 0.48461723 0.         0.5133325  0.3936194  1.0859225\n",
      "  0.         0.8195482  0.13150002 0.         0.         0.\n",
      "  0.12009469 0.14994481 0.30974862 0.        ]]\n",
      "Hi!\n",
      "[[1.0494703  0.43757913 1.9478136  0.         0.         1.270388\n",
      "  0.13298003 0.35772768 0.9392076  0.         0.7433489  0.\n",
      "  0.26364985 0.         0.         0.37764314 0.69931155 0.7451904\n",
      "  0.         0.3945581  1.442645   0.13876663 0.         0.72531384\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40958127 0.06175137 0.         0.         0.\n",
      "  0.         0.44354948 0.         0.9468928  0.         0.\n",
      "  0.         0.83481795 0.         0.226649   0.         0.556504\n",
      "  0.2305679  1.1328603  0.49748898 0.35638922 0.76867276 0.39216962\n",
      "  0.         1.1778551  0.         0.35678524 0.07002991 0.\n",
      "  0.09594892 0.67138326 0.9793097  0.7407914 ]]\n",
      "Hi!\n",
      "[[0.01137305 0.18220776 0.         0.00228849 0.         0.10473989\n",
      "  0.12617181 0.25597474 0.01139146 0.05313535 0.03393973 0.\n",
      "  0.06661917 0.19192868 0.         0.0576903  0.         0.05849686\n",
      "  0.         0.12907493 0.08599066 0.         0.         0.\n",
      "  0.         0.         0.         0.02589378 0.         0.\n",
      "  0.14907257 0.23392488 0.24355964 0.         0.         0.\n",
      "  0.         0.         0.25181714 0.04512372 0.         0.\n",
      "  0.         0.         0.23920728 0.40405923 0.         0.01868093\n",
      "  0.16856706 0.2431485  0.         0.17388931 0.04451673 0.41484892\n",
      "  0.         0.12237483 0.09568499 0.         0.         0.\n",
      "  0.08272102 0.19298907 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5917278  0.59021914 0.131499   0.12230375 0.         0.37143543\n",
      "  0.75474465 1.179406   0.49073488 0.         0.34353146 0.\n",
      "  1.6031129  0.8393716  0.         0.6711438  0.         0.6755873\n",
      "  0.6499335  0.19449274 0.44530487 0.21346685 0.         0.08650433\n",
      "  0.3121176  0.         0.         0.7987686  0.         0.\n",
      "  1.3893107  0.7857161  0.         0.         0.84156096 0.\n",
      "  0.5632054  1.1558466  0.2489773  0.21103334 0.08058563 0.\n",
      "  0.         0.46063596 1.306252   0.88490474 0.         0.71660596\n",
      "  0.         0.747416   0.8036679  0.43427077 0.632624   1.010958\n",
      "  0.         0.         0.554452   0.         0.         0.\n",
      "  0.         0.40695456 0.99204344 0.01992474]]\n",
      "Hi!\n",
      "[[0.01556009 0.31314743 0.22961001 0.         0.         0.1505339\n",
      "  0.         0.06404249 0.         0.         0.09623542 0.\n",
      "  0.25539532 0.16906631 0.         0.         0.         0.03532876\n",
      "  0.         0.21421832 0.05437848 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07949761 0.27091035 0.10471224 0.         0.         0.\n",
      "  0.         0.         0.24841633 0.06681947 0.         0.\n",
      "  0.         0.         0.21771224 0.22443481 0.         0.04988416\n",
      "  0.21371464 0.1853794  0.         0.24910411 0.18097006 0.4691275\n",
      "  0.         0.11045334 0.07543865 0.         0.         0.\n",
      "  0.05771028 0.17239663 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0166699  0.26358846 0.25804433 0.         0.         0.18890712\n",
      "  0.         0.         0.07347146 0.04619377 0.19103609 0.\n",
      "  0.16298954 0.06833304 0.         0.0178514  0.         0.08146894\n",
      "  0.         0.28521782 0.14661443 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01800373 0.15228248 0.03239669 0.         0.         0.\n",
      "  0.         0.         0.10568635 0.13462666 0.         0.\n",
      "  0.         0.         0.1138761  0.20783803 0.         0.16515468\n",
      "  0.22762807 0.12073802 0.         0.16870812 0.06611956 0.35800725\n",
      "  0.         0.11160032 0.00234852 0.         0.08327617 0.\n",
      "  0.114941   0.0517275  0.         0.02125175]]\n",
      "Hi!\n",
      "[[0.5011173  0.58254087 0.16103904 0.13272983 0.         0.535383\n",
      "  0.2793469  0.5677695  0.         0.         0.15565442 0.\n",
      "  0.50482255 0.6456038  0.         0.         0.         0.17075683\n",
      "  0.         0.7541137  0.07001168 0.         0.         0.18413901\n",
      "  0.         0.         0.         0.12194642 0.         0.\n",
      "  0.8045973  0.68602777 0.32019746 0.         0.09708972 0.\n",
      "  0.         0.20944878 0.4966743  0.1534244  0.         0.\n",
      "  0.         0.04027086 0.9727241  1.0253719  0.         0.3322736\n",
      "  0.5493427  0.6625422  0.         0.5100423  0.6149661  1.0026412\n",
      "  0.         0.53464454 0.26577762 0.         0.         0.\n",
      "  0.         0.09017427 0.07817764 0.        ]]\n",
      "Hi!\n",
      "[[0.0512734  0.15650105 0.48471236 0.         0.         0.34310266\n",
      "  0.         0.         0.20671703 0.14158194 0.3297263  0.\n",
      "  0.         0.         0.         0.16787139 0.0059986  0.\n",
      "  0.         0.40300164 0.3026515  0.         0.         0.00286114\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06911514 0.         0.         0.\n",
      "  0.         0.         0.03726982 0.29266483 0.         0.\n",
      "  0.         0.         0.         0.20290636 0.         0.271582\n",
      "  0.19165641 0.03869615 0.10238124 0.2681443  0.07559996 0.25862262\n",
      "  0.         0.22215953 0.         0.         0.15651101 0.\n",
      "  0.05216857 0.         0.00793654 0.11724823]]\n",
      "Hi!\n",
      "[[0.53270715 1.4453069  0.8549559  0.         0.         0.61430824\n",
      "  0.         0.30693468 0.47502267 0.         0.59226143 0.\n",
      "  2.0437171  0.39302647 0.         0.24914809 0.         0.4069515\n",
      "  0.4732674  0.93483615 0.65779644 0.         0.         0.28170264\n",
      "  0.         0.         0.         0.36565545 0.         0.\n",
      "  1.0719999  0.90989125 0.         0.         0.18876816 0.\n",
      "  0.04903099 0.30123708 0.78963554 0.32140702 0.         0.\n",
      "  0.         0.2271636  0.88683563 0.5264674  0.         0.92664665\n",
      "  0.34883302 0.75355357 0.64480495 0.5168812  0.9039784  1.3170258\n",
      "  0.         0.         0.3206423  0.         0.06656708 0.\n",
      "  0.         0.15037733 0.7085778  0.3502274 ]]\n",
      "Hi!\n",
      "[[0.47126397 0.         0.5342179  0.5416731  0.         0.90878814\n",
      "  2.0260882  2.0919843  0.52530295 0.         0.22377193 0.\n",
      "  0.         0.         0.         0.41965798 0.         0.68993145\n",
      "  0.         0.         0.59272486 0.171009   0.         0.02614301\n",
      "  0.         0.         0.         0.5450511  0.         0.\n",
      "  0.9025461  0.4761908  0.20225659 0.         0.69783944 0.\n",
      "  0.         1.2930284  0.         0.4982813  0.41243696 0.\n",
      "  0.         1.1611401  0.6869954  1.035518   0.         0.\n",
      "  0.         0.9098397  0.12004692 0.59306246 0.9270228  0.06640721\n",
      "  0.         0.52523375 0.23763198 0.         0.         0.\n",
      "  0.         0.9364916  1.4891266  0.        ]]\n",
      "Hi!\n",
      "[[0.2523601  0.2867727  0.91945976 0.         0.         0.6080824\n",
      "  0.5780214  0.8354299  1.32942    0.         0.5495236  0.\n",
      "  1.159416   0.         0.         0.9144757  0.         0.77880496\n",
      "  0.9019521  0.         0.9951009  0.0930284  0.         0.03401152\n",
      "  0.28254762 0.         0.         0.35100278 0.         0.\n",
      "  0.72750354 0.35957128 0.         0.         0.5069884  0.\n",
      "  0.52825886 1.3136107  0.         0.5520677  0.19779094 0.\n",
      "  0.         0.81066203 0.28927478 0.22238536 0.         0.8471507\n",
      "  0.         0.81594706 1.005642   0.29052857 0.33240777 0.3093131\n",
      "  0.         0.         0.24622674 0.2442293  0.         0.\n",
      "  0.         0.7968963  1.3692524  0.7614882 ]]\n",
      "Hi!\n",
      "[[0.08502686 0.21753214 0.0906981  0.01217023 0.         0.1445529\n",
      "  0.         0.18118823 0.         0.05343934 0.08654174 0.\n",
      "  0.17471866 0.28944626 0.         0.         0.         0.0063821\n",
      "  0.         0.20960714 0.02036842 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10262889 0.26954636 0.17480473 0.         0.         0.\n",
      "  0.         0.         0.24616942 0.07900302 0.         0.\n",
      "  0.         0.         0.31899002 0.39250752 0.         0.05488323\n",
      "  0.21221387 0.17892267 0.         0.21573518 0.13333844 0.5105151\n",
      "  0.         0.11112574 0.11127001 0.         0.         0.\n",
      "  0.07597037 0.05766668 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6695578  0.08905046 0.8655283  0.17063953 0.         1.0196576\n",
      "  0.60944086 0.9103943  0.30065396 0.11940616 0.34702262 0.\n",
      "  0.         0.         0.         0.06078824 0.02985562 0.510665\n",
      "  0.         0.26281938 0.6856827  0.         0.         0.42691508\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20330192 0.38032162 0.19705616 0.         0.         0.\n",
      "  0.         0.424743   0.         0.7088855  0.         0.\n",
      "  0.         0.566513   0.15705167 0.8003105  0.         0.\n",
      "  0.17430446 1.1789192  0.02742974 0.49257824 0.9197423  0.15695333\n",
      "  0.         0.96388984 0.         0.         0.         0.\n",
      "  0.11443044 0.74601454 0.5867257  0.        ]]\n",
      "Hi!\n",
      "[[0.19527131 0.4708015  0.23288244 0.00806704 0.         0.21691416\n",
      "  0.         0.1513263  0.         0.         0.17814448 0.\n",
      "  0.35262442 0.38374528 0.         0.         0.         0.11951379\n",
      "  0.         0.41844144 0.08647223 0.         0.         0.05614044\n",
      "  0.         0.         0.         0.03629844 0.         0.\n",
      "  0.25742477 0.4319375  0.15945654 0.         0.         0.\n",
      "  0.         0.         0.45165223 0.08366852 0.         0.\n",
      "  0.         0.         0.42493442 0.41373903 0.         0.08209406\n",
      "  0.38927475 0.24135065 0.         0.2939983  0.2544275  0.674282\n",
      "  0.         0.22918393 0.16385424 0.         0.0052739  0.\n",
      "  0.1808055  0.09663524 0.03634195 0.        ]]\n",
      "Hi!\n",
      "[[3.1834951e-01 0.0000000e+00 2.2211580e-01 4.2125025e-01 0.0000000e+00\n",
      "  6.5565962e-01 2.0629413e+00 1.9224777e+00 5.2754450e-01 0.0000000e+00\n",
      "  2.1193923e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.2691317e-01 0.0000000e+00 7.1983886e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.9072695e-01 2.4747981e-01 0.0000000e+00 0.0000000e+00 1.1270813e-01\n",
      "  0.0000000e+00 0.0000000e+00 4.2635408e-01 0.0000000e+00 0.0000000e+00\n",
      "  9.4726825e-01 2.7753463e-01 1.4427851e-01 0.0000000e+00 7.8308493e-01\n",
      "  0.0000000e+00 0.0000000e+00 1.4318960e+00 0.0000000e+00 4.9875823e-01\n",
      "  3.5914996e-01 0.0000000e+00 0.0000000e+00 1.1088109e+00 6.4136720e-01\n",
      "  1.0867376e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.2271084e-01\n",
      "  3.5574490e-01 4.7259966e-01 6.4332747e-01 1.1347643e-01 0.0000000e+00\n",
      "  8.9881819e-04 2.0365855e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0525379e+00 1.2244637e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.         0.00280877 0.00358525 0.         0.         0.11942241\n",
      "  0.18097948 0.31641966 0.04769531 0.09478042 0.06243751 0.\n",
      "  0.         0.12814549 0.         0.02457676 0.         0.01064985\n",
      "  0.         0.07113853 0.09054402 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03990088 0.08128248 0.19777688 0.         0.         0.\n",
      "  0.         0.         0.22217563 0.15870154 0.         0.\n",
      "  0.         0.         0.22872485 0.4531469  0.         0.00887058\n",
      "  0.15644923 0.17758356 0.         0.24554014 0.05485956 0.3400995\n",
      "  0.         0.11069533 0.00209443 0.         0.         0.\n",
      "  0.01783253 0.14842619 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.83730733 0.1559341  1.3854938  0.         0.         1.0665848\n",
      "  0.4249442  0.37643996 0.6175826  0.15633135 0.5139335  0.\n",
      "  0.         0.         0.         0.1470106  0.62564784 0.5922006\n",
      "  0.         0.43355587 0.9648792  0.15136161 0.         0.44550702\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22672883 0.         0.         0.\n",
      "  0.         0.2776312  0.         0.94937825 0.         0.\n",
      "  0.         0.96885955 0.         0.3880217  0.         0.10706579\n",
      "  0.3765031  1.1485171  0.24183169 0.14738862 0.5602146  0.03375687\n",
      "  0.         1.0567989  0.         0.15161473 0.03394455 0.\n",
      "  0.56984735 0.9685444  0.16063854 0.35992876]]\n",
      "Hi!\n",
      "[[0.36347154 0.7912228  0.27881175 0.         0.         0.28298467\n",
      "  0.45027438 0.6995794  0.6547488  0.         0.37643665 0.\n",
      "  1.4907191  0.44979826 0.         0.66671795 0.         0.6717994\n",
      "  0.5412571  0.36424324 0.4676441  0.         0.         0.\n",
      "  0.2903325  0.         0.         0.3551392  0.         0.\n",
      "  0.9746897  0.58232474 0.         0.         0.5862856  0.\n",
      "  0.46368754 1.0251849  0.         0.3949447  0.         0.\n",
      "  0.         0.3288592  0.82421017 0.46746656 0.         0.84048736\n",
      "  0.         0.6859086  0.828456   0.2317267  0.341426   0.77502936\n",
      "  0.         0.         0.40092784 0.         0.         0.\n",
      "  0.         0.5048931  0.62598634 0.3336621 ]]\n",
      "Hi!\n",
      "[[0.651345   0.9093773  0.5193155  0.         0.         0.43557504\n",
      "  0.21158059 0.88290304 0.61320835 0.         0.4507573  0.\n",
      "  1.8443589  0.6840656  0.         0.56639117 0.         0.553453\n",
      "  0.7366169  0.41699183 0.6134661  0.01421932 0.         0.23128928\n",
      "  0.04950424 0.         0.         0.6895547  0.         0.\n",
      "  1.2692604  0.9005311  0.         0.         0.5285062  0.\n",
      "  0.44248453 0.903825   0.3870101  0.29381838 0.         0.\n",
      "  0.         0.31565148 1.1365088  0.6551515  0.         0.7884565\n",
      "  0.         0.70470375 0.7765395  0.45683324 0.70866114 1.0459455\n",
      "  0.         0.         0.4034814  0.         0.         0.\n",
      "  0.         0.32668903 1.0835279  0.21179755]]\n",
      "Hi!\n",
      "[[0.3560309  0.55175906 1.2751435  0.         0.         0.8524088\n",
      "  0.16308676 0.41406518 0.9400797  0.         0.61511    0.\n",
      "  1.1356614  0.         0.         0.5562985  0.         0.72402406\n",
      "  0.4638073  0.26843017 1.0519938  0.         0.         0.09269656\n",
      "  0.06308211 0.         0.         0.07863071 0.         0.\n",
      "  0.5416704  0.5774891  0.         0.         0.18342245 0.\n",
      "  0.21502972 0.8521824  0.         0.63190746 0.04719861 0.\n",
      "  0.         0.28563794 0.38470343 0.2809933  0.         0.8872851\n",
      "  0.00599677 0.762853   0.7034345  0.43373275 0.57809687 0.62312245\n",
      "  0.         0.08691721 0.03030939 0.11773967 0.04092354 0.\n",
      "  0.         0.5261828  1.1836404  0.73267275]]\n",
      "Hi!\n",
      "[[0.30134308 0.5806197  0.2149202  0.         0.         0.17652434\n",
      "  0.         0.208273   0.         0.         0.19677088 0.\n",
      "  0.57803243 0.5142044  0.         0.         0.         0.16214703\n",
      "  0.         0.41589427 0.10533588 0.         0.         0.14799997\n",
      "  0.         0.         0.         0.18067887 0.         0.\n",
      "  0.37927026 0.45795417 0.16225794 0.         0.         0.\n",
      "  0.         0.         0.52960217 0.08460408 0.         0.\n",
      "  0.         0.         0.5164804  0.40558007 0.         0.12568948\n",
      "  0.3560357  0.2457368  0.         0.285642   0.253481   0.809331\n",
      "  0.         0.11254744 0.291251   0.         0.         0.\n",
      "  0.23411131 0.1212832  0.04922056 0.        ]]\n",
      "Hi!\n",
      "[[0.7479964  0.25027856 1.4798899  0.         0.         1.028815\n",
      "  0.12335666 0.18493953 0.5738967  0.03587111 0.49313718 0.\n",
      "  0.         0.         0.         0.15978761 0.53290504 0.6505267\n",
      "  0.         0.57108104 0.8678482  0.         0.         0.194488\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27910084 0.12018576 0.         0.         0.\n",
      "  0.         0.2979828  0.         0.7476023  0.         0.\n",
      "  0.         0.5717321  0.         0.292519   0.         0.62216944\n",
      "  0.38879624 0.70429176 0.22602059 0.3013814  0.29321176 0.4643694\n",
      "  0.         1.0443054  0.         0.09165471 0.02240683 0.\n",
      "  0.42661598 0.6289073  0.62856776 0.4019244 ]]\n",
      "Hi!\n",
      "[[0.00429109 0.14241312 0.09379736 0.         0.         0.05381622\n",
      "  0.         0.09181327 0.02003233 0.05376456 0.1061855  0.\n",
      "  0.09867988 0.11711293 0.         0.05520901 0.         0.01551941\n",
      "  0.         0.13790305 0.09058107 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01179116 0.12002985 0.15226679 0.         0.         0.\n",
      "  0.         0.         0.10941411 0.04774427 0.         0.\n",
      "  0.         0.         0.12727213 0.22717044 0.         0.05398206\n",
      "  0.13351618 0.06283747 0.         0.14175336 0.         0.32740209\n",
      "  0.         0.05605186 0.07242039 0.         0.         0.\n",
      "  0.07225405 0.06145358 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.53910387 0.05758853 1.3824934  0.         0.         0.60200214\n",
      "  0.5537891  0.43493697 1.2347958  0.         0.62276846 0.\n",
      "  0.1724179  0.         0.         0.78320986 0.47923574 0.9625783\n",
      "  0.0664306  0.         1.1893053  0.34732    0.         0.30349743\n",
      "  0.17823546 0.         0.         0.         0.         0.\n",
      "  0.         0.00607469 0.         0.         0.21234395 0.\n",
      "  0.22469328 1.0673946  0.         0.7196625  0.10655497 0.\n",
      "  0.         1.041611   0.         0.02169999 0.         0.66279477\n",
      "  0.         0.69469017 0.6808271  0.01365151 0.09381352 0.\n",
      "  0.         0.         0.         0.6243228  0.         0.\n",
      "  0.         1.1166358  1.0569316  0.77297103]]\n",
      "Hi!\n",
      "[[0.49958277 0.4976765  1.0898373  0.         0.         0.7547946\n",
      "  0.         0.1651581  0.22491957 0.         0.4391845  0.\n",
      "  0.44954225 0.         0.         0.14558606 0.06071416 0.5164006\n",
      "  0.         0.64225066 0.70311844 0.         0.         0.02376993\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2705287  0.5918808  0.         0.         0.         0.\n",
      "  0.01088289 0.42504087 0.         0.58998716 0.         0.\n",
      "  0.         0.03482408 0.48896155 0.3963239  0.         0.61537653\n",
      "  0.4252853  0.5551155  0.11507205 0.3449348  0.35560694 0.6548473\n",
      "  0.         0.539616   0.01230943 0.         0.06058536 0.\n",
      "  0.01488893 0.42971817 0.70914495 0.18493982]]\n",
      "Hi!\n",
      "[[0.0714732  0.07624145 0.         0.05607954 0.         0.05908176\n",
      "  0.3831464  0.50587445 0.04835289 0.02387586 0.         0.\n",
      "  0.0444875  0.33154294 0.         0.13230747 0.         0.13913135\n",
      "  0.         0.12356206 0.05997989 0.         0.         0.\n",
      "  0.         0.         0.         0.13416256 0.         0.\n",
      "  0.2978986  0.2041565  0.34649083 0.         0.         0.\n",
      "  0.         0.05598743 0.3111655  0.00904031 0.         0.\n",
      "  0.         0.07300428 0.378437   0.60725194 0.         0.\n",
      "  0.15070449 0.29419208 0.0290558  0.22224781 0.06844488 0.4837493\n",
      "  0.         0.1417884  0.18591991 0.         0.         0.\n",
      "  0.01184862 0.23803478 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.15367247 0.07911211 0.         0.         0.12043233\n",
      "  0.0894772  0.22369368 0.         0.03232507 0.05898957 0.\n",
      "  0.11324846 0.24325952 0.         0.         0.         0.01565244\n",
      "  0.         0.10618737 0.03887911 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.106312   0.19075069 0.17211024 0.         0.         0.\n",
      "  0.         0.         0.26480153 0.0813966  0.         0.\n",
      "  0.         0.         0.28067452 0.39731067 0.         0.00172659\n",
      "  0.11801466 0.19453652 0.         0.17182209 0.16048817 0.39196002\n",
      "  0.         0.08754887 0.09134571 0.         0.         0.\n",
      "  0.0209437  0.10759383 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.88976663 0.         1.2093544  0.05872032 0.         0.9896921\n",
      "  0.5771507  0.6807784  0.51605433 0.09527364 0.48294154 0.\n",
      "  0.         0.         0.         0.18955633 0.5591645  0.6580122\n",
      "  0.         0.2179855  0.8740762  0.15884003 0.         0.44495612\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04904654 0.25090182 0.         0.         0.\n",
      "  0.         0.40504843 0.         0.9328187  0.         0.\n",
      "  0.         1.1148134  0.         0.4649294  0.         0.\n",
      "  0.14073087 1.1085572  0.15314624 0.2007137  0.6030111  0.\n",
      "  0.         1.0025232  0.         0.05099327 0.         0.\n",
      "  0.38958925 0.930209   0.3722656  0.10768244]]\n",
      "Hi!\n",
      "[[0.20293057 0.62126297 0.         0.         0.         0.4086045\n",
      "  0.54571617 0.71480286 0.16334525 0.         0.14942802 0.\n",
      "  0.98679906 0.4808158  0.         0.23944299 0.         0.37770632\n",
      "  0.         0.3957924  0.1010103  0.         0.         0.\n",
      "  0.07453588 0.         0.         0.30500478 0.         0.\n",
      "  0.8511238  0.46216345 0.04119296 0.         0.38456014 0.\n",
      "  0.15544775 0.6635689  0.02714245 0.12233482 0.         0.\n",
      "  0.         0.1322077  0.71508294 0.7111592  0.         0.5009579\n",
      "  0.         0.6511839  0.49381122 0.2762801  0.20911953 0.9026829\n",
      "  0.         0.         0.3628644  0.         0.         0.\n",
      "  0.         0.29871926 0.23518722 0.        ]]\n",
      "Hi!\n",
      "[[0.74728173 0.74667    1.548148   0.         0.         1.1240332\n",
      "  0.00369259 0.2445319  0.51860535 0.         0.6348737  0.\n",
      "  0.65678126 0.         0.         0.05736756 0.15672706 0.5222409\n",
      "  0.         0.7489263  1.051135   0.         0.         0.3848118\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29065484 0.64706    0.0440538  0.         0.         0.\n",
      "  0.         0.25843024 0.         0.66414225 0.         0.\n",
      "  0.         0.09130207 0.30010507 0.47970244 0.         0.5354531\n",
      "  0.49640402 0.98101956 0.2980467  0.53725374 0.9890177  0.7015687\n",
      "  0.         1.0550301  0.         0.         0.13252781 0.\n",
      "  0.         0.4040234  0.79980206 0.45232323]]\n",
      "Hi!\n",
      "[[0.22386023 0.10667097 0.6900431  0.         0.         0.55909455\n",
      "  0.9255112  1.161203   1.3326561  0.         0.47741804 0.\n",
      "  1.1308469  0.         0.         0.9635531  0.         0.76625246\n",
      "  0.8397072  0.         0.9002238  0.06982645 0.         0.\n",
      "  0.28363386 0.         0.         0.4845285  0.         0.\n",
      "  0.9281626  0.31014094 0.         0.         0.61332697 0.\n",
      "  0.53438205 1.4040343  0.         0.4150047  0.22768056 0.\n",
      "  0.         0.92402345 0.36179096 0.39755094 0.         0.68639463\n",
      "  0.         0.77675265 1.0288488  0.34296203 0.4109006  0.18822464\n",
      "  0.         0.         0.2893641  0.17999299 0.         0.\n",
      "  0.         0.8020618  1.4225475  0.63029903]]\n",
      "Hi!\n",
      "[[0.05374594 0.13872944 0.23899353 0.         0.         0.11074892\n",
      "  0.10817131 0.14160508 0.18109702 0.15834114 0.1451466  0.\n",
      "  0.         0.         0.         0.13629152 0.         0.23013982\n",
      "  0.         0.20843455 0.14940175 0.         0.         0.01036032\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01644844 0.         0.1776819  0.         0.\n",
      "  0.         0.06248312 0.00480167 0.28407994 0.         0.\n",
      "  0.12142244 0.25334582 0.1297489  0.11606742 0.04594732 0.0885272\n",
      "  0.         0.14401299 0.         0.         0.         0.\n",
      "  0.12159713 0.28591812 0.         0.0524387 ]]\n",
      "Hi!\n",
      "[[0.61465853 0.72127354 0.7289781  0.08364701 0.         0.79508376\n",
      "  0.12527458 0.59843785 0.         0.         0.31141844 0.\n",
      "  0.75170785 0.40813792 0.         0.         0.         0.26500112\n",
      "  0.         0.91757196 0.3882663  0.         0.         0.2075793\n",
      "  0.         0.         0.         0.21654038 0.         0.\n",
      "  0.83755714 0.8423895  0.07062872 0.         0.1929869  0.\n",
      "  0.         0.18007854 0.48243594 0.22444043 0.         0.\n",
      "  0.         0.07519104 0.9637984  0.91173124 0.         0.40584022\n",
      "  0.5922347  0.7854007  0.         0.66091806 0.97377574 1.0207493\n",
      "  0.         0.7886014  0.22673269 0.         0.0606729  0.\n",
      "  0.         0.10914149 0.5714463  0.        ]]\n",
      "Hi!\n",
      "[[0.629915   0.339937   0.8748681  0.         0.         1.0700903\n",
      "  0.23432907 0.54256046 0.         0.25749913 0.3216351  0.\n",
      "  0.         0.         0.         0.03528151 0.         0.29068813\n",
      "  0.         0.7648661  0.5223455  0.         0.         0.23173296\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07448734 0.3034707  0.14982884 0.         0.         0.\n",
      "  0.         0.16010848 0.         0.6418323  0.         0.\n",
      "  0.         0.06331802 0.3636352  0.928347   0.         0.1347512\n",
      "  0.5877185  0.95389855 0.         0.5084861  0.81530553 0.4762324\n",
      "  0.         1.1541291  0.         0.         0.01534507 0.\n",
      "  0.42957345 0.41298288 0.10290891 0.        ]]\n",
      "Hi!\n",
      "[[0.53727216 0.5412919  1.5207691  0.         0.         0.9248811\n",
      "  0.14135587 0.1569422  1.0589606  0.         0.70019335 0.\n",
      "  0.9957111  0.         0.         0.6375762  0.22364742 0.8023799\n",
      "  0.40581167 0.32185975 1.2231293  0.04835987 0.         0.22580777\n",
      "  0.1346164  0.         0.         0.         0.         0.\n",
      "  0.23029494 0.48540068 0.         0.         0.07683384 0.\n",
      "  0.24936132 0.8420822  0.         0.8173649  0.         0.\n",
      "  0.         0.4172177  0.16505212 0.0609987  0.         0.99298215\n",
      "  0.04940623 0.83968115 0.723609   0.34911895 0.4248861  0.5384892\n",
      "  0.         0.20518473 0.         0.3094692  0.101134   0.\n",
      "  0.         0.68644404 1.1290056  0.9214661 ]]\n",
      "Hi!\n",
      "[[0.35394663 0.7086613  0.21095496 0.         0.         0.15361594\n",
      "  0.62814677 1.0284384  0.6205634  0.         0.35519627 0.\n",
      "  1.6160755  0.7519341  0.         0.6442426  0.         0.5886195\n",
      "  0.49552363 0.20872383 0.49609873 0.03152184 0.         0.15162481\n",
      "  0.19784632 0.         0.         0.6718446  0.         0.\n",
      "  1.3363985  0.66824114 0.         0.         0.64860725 0.\n",
      "  0.25329074 1.04916    0.16933368 0.23131604 0.         0.\n",
      "  0.         0.28363642 0.9408667  0.746133   0.         0.42859918\n",
      "  0.         0.8715093  0.8867544  0.34963194 0.7849747  0.7616176\n",
      "  0.         0.         0.33906764 0.         0.         0.\n",
      "  0.         0.6017558  0.79773337 0.1755723 ]]\n",
      "Hi!\n",
      "[[0.25890762 0.62330836 0.8608285  0.         0.         0.652365\n",
      "  0.3468468  0.5106858  1.137042   0.         0.5186466  0.\n",
      "  1.2583379  0.         0.         0.6645919  0.         0.663643\n",
      "  0.6670181  0.1927365  0.9354051  0.02746813 0.         0.01632774\n",
      "  0.18294887 0.         0.         0.09615141 0.         0.\n",
      "  0.67018265 0.4261951  0.         0.         0.33612308 0.\n",
      "  0.2773722  0.93587226 0.         0.53222024 0.01394113 0.\n",
      "  0.         0.4032958  0.30057156 0.18025951 0.         0.9151422\n",
      "  0.         0.8113885  0.82722485 0.31038094 0.4068139  0.4423555\n",
      "  0.         0.         0.11807935 0.00676631 0.         0.\n",
      "  0.         0.6768255  0.95609766 0.7916861 ]]\n",
      "Hi!\n",
      "[[0.33388236 0.5651011  1.344764   0.         0.         0.48589066\n",
      "  0.         0.         0.8720574  0.         0.41690922 0.\n",
      "  0.51801664 0.         0.         0.38657054 0.69400036 0.6105891\n",
      "  0.03094265 0.4309893  0.93598586 0.14043544 0.         0.08607706\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07847135 0.         0.         0.\n",
      "  0.         0.2583222  0.         0.6771978  0.         0.\n",
      "  0.         0.25198478 0.         0.         0.         0.7152432\n",
      "  0.24054809 0.78605753 0.44977337 0.01546865 0.05764031 0.30691856\n",
      "  0.         0.12986714 0.         0.5744437  0.18937474 0.\n",
      "  0.19585629 0.59868723 0.59841996 0.73535174]]\n",
      "Hi!\n",
      "[[0.29575893 0.         0.09981507 0.5566943  0.         0.7588189\n",
      "  1.9411373  1.9499683  0.11554086 0.         0.11999147 0.\n",
      "  0.         0.20728482 0.         0.25289595 0.         0.6445196\n",
      "  0.         0.         0.31268856 0.21238941 0.         0.\n",
      "  0.         0.         0.         0.52686256 0.         0.\n",
      "  1.1631235  0.49341422 0.2728865  0.         0.7455703  0.\n",
      "  0.         1.1790072  0.         0.39049932 0.29966414 0.\n",
      "  0.         0.72976893 0.94281906 1.408287   0.         0.\n",
      "  0.         0.99644166 0.12945738 0.65783864 0.96074665 0.30874556\n",
      "  0.         0.3025592  0.19810495 0.         0.         0.\n",
      "  0.         0.8573906  1.03818    0.        ]]\n",
      "Hi!\n",
      "[[0.8286971  0.6373191  0.08823601 0.2772841  0.         0.57611847\n",
      "  0.72583824 0.96737826 0.         0.         0.05621329 0.\n",
      "  1.1475456  0.86037    0.         0.19563635 0.         0.35861313\n",
      "  0.11876406 0.55006754 0.08800928 0.05293731 0.         0.19924165\n",
      "  0.09404452 0.         0.         0.78286254 0.         0.\n",
      "  1.2474539  0.8994404  0.3504809  0.         0.56310064 0.\n",
      "  0.41954073 0.90577257 0.5020557  0.144861   0.         0.\n",
      "  0.         0.51942587 1.4131584  1.0680991  0.         0.8446883\n",
      "  0.21059157 0.6698121  0.37566718 0.4841997  0.5033808  1.3907285\n",
      "  0.         0.12392482 0.5808343  0.         0.         0.\n",
      "  0.         0.15631315 0.62341136 0.        ]]\n",
      "Hi!\n",
      "[[0.46185556 0.5227096  0.8726366  0.10480334 0.         0.947197\n",
      "  0.         0.38226098 0.         0.03440574 0.31522486 0.\n",
      "  0.2032021  0.17795593 0.         0.         0.         0.17430137\n",
      "  0.         0.85875833 0.43250954 0.         0.         0.0557174\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3324325  0.7009789  0.12010343 0.         0.         0.\n",
      "  0.         0.07436705 0.16879623 0.36798483 0.         0.\n",
      "  0.         0.         0.6645191  0.7697832  0.         0.23972507\n",
      "  0.7467224  0.80153334 0.         0.5555398  0.827831   0.84457767\n",
      "  0.         1.0179701  0.         0.         0.         0.\n",
      "  0.27272776 0.19258034 0.30862746 0.        ]]\n",
      "Hi!\n",
      "[[0.03046088 0.22344479 0.1775113  0.         0.         0.18587244\n",
      "  0.         0.06449258 0.08901279 0.08512871 0.185899   0.\n",
      "  0.05599139 0.         0.         0.06788319 0.         0.0509523\n",
      "  0.         0.28026256 0.14140247 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04716539 0.06428024 0.         0.         0.\n",
      "  0.         0.         0.00582374 0.13729703 0.         0.\n",
      "  0.         0.         0.0183125  0.2637806  0.         0.1249394\n",
      "  0.16061987 0.14268193 0.00529838 0.16675441 0.04476024 0.2975952\n",
      "  0.         0.04794352 0.         0.         0.08625498 0.\n",
      "  0.08966233 0.1637584  0.         0.04387349]]\n",
      "Hi!\n",
      "[[0.49593934 0.36779934 0.733319   0.         0.         0.8707026\n",
      "  0.07148268 0.3052776  0.05840356 0.19881804 0.32766584 0.\n",
      "  0.         0.         0.         0.08810258 0.         0.3299538\n",
      "  0.         0.7526399  0.4195732  0.         0.         0.05880721\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02519274 0.25421092 0.08220607 0.         0.         0.\n",
      "  0.         0.06885931 0.         0.47910565 0.         0.\n",
      "  0.         0.06966528 0.22950695 0.6994523  0.         0.29403007\n",
      "  0.52423203 0.7976585  0.         0.43728814 0.51982725 0.46026883\n",
      "  0.         0.9182735  0.         0.         0.04449783 0.\n",
      "  0.40992975 0.41907528 0.0935846  0.05960087]]\n",
      "Hi!\n",
      "[[0.03281418 0.09273076 0.24778971 0.         0.         0.16650075\n",
      "  0.         0.         0.12671636 0.08145169 0.17511213 0.\n",
      "  0.         0.         0.         0.05842065 0.         0.\n",
      "  0.         0.22335452 0.16712403 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02744843 0.06792428 0.         0.         0.\n",
      "  0.         0.         0.04753877 0.13241003 0.         0.\n",
      "  0.         0.         0.04723817 0.20790294 0.         0.13914125\n",
      "  0.16205725 0.01932053 0.         0.19299637 0.         0.22410145\n",
      "  0.         0.12741296 0.         0.         0.04882678 0.\n",
      "  0.06951888 0.01889085 0.         0.01127744]]\n",
      "Hi!\n",
      "[[2.6200193e-01 0.0000000e+00 0.0000000e+00 3.0963755e-01 0.0000000e+00\n",
      "  4.3149659e-01 1.7115164e+00 1.9260335e+00 6.4408231e-01 0.0000000e+00\n",
      "  2.1869959e-01 0.0000000e+00 6.3426042e-01 4.6693772e-01 0.0000000e+00\n",
      "  6.8017673e-01 0.0000000e+00 6.4923334e-01 1.7296911e-04 0.0000000e+00\n",
      "  4.0673375e-01 2.5646874e-01 0.0000000e+00 0.0000000e+00 2.6685718e-01\n",
      "  0.0000000e+00 0.0000000e+00 7.5520003e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.4276545e+00 3.4421033e-01 3.7619825e-02 0.0000000e+00 9.8277032e-01\n",
      "  0.0000000e+00 1.8024407e-01 1.4004685e+00 0.0000000e+00 2.6929212e-01\n",
      "  3.0779231e-01 0.0000000e+00 0.0000000e+00 8.5272801e-01 9.5305854e-01\n",
      "  1.1499383e+00 0.0000000e+00 3.1319503e-02 0.0000000e+00 9.3411183e-01\n",
      "  6.6522264e-01 5.7199663e-01 8.1977612e-01 3.2381541e-01 0.0000000e+00\n",
      "  0.0000000e+00 3.7268129e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.9820192e-01 1.2565550e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.6448645  1.4967278  0.7372347  0.         0.         0.36946943\n",
      "  0.         0.521853   0.9149452  0.         0.5894901  0.\n",
      "  2.713919   0.75808454 0.         0.83702147 0.         0.7013269\n",
      "  1.4565398  0.6283203  0.72487557 0.07984031 0.         0.29525587\n",
      "  0.3129807  0.         0.         0.6862918  0.         0.\n",
      "  1.3645337  1.0968462  0.         0.         0.52131903 0.\n",
      "  0.77040374 0.93073374 0.7628939  0.45594966 0.03308114 0.\n",
      "  0.         0.5190379  1.224232   0.37762433 0.         1.3740877\n",
      "  0.         0.91643065 1.1803548  0.39875    0.70812243 1.4397401\n",
      "  0.         0.         0.54554874 0.         0.02387374 0.\n",
      "  0.         0.3079346  1.1671183  0.66874355]]\n",
      "Hi!\n",
      "[[0.5120847  0.19534051 0.         0.29849923 0.         0.46822158\n",
      "  0.69461155 0.753229   0.         0.         0.00165746 0.\n",
      "  0.14256765 0.5552117  0.         0.07540108 0.         0.09488866\n",
      "  0.         0.47374704 0.         0.         0.         0.07336821\n",
      "  0.         0.         0.         0.37995267 0.         0.\n",
      "  0.66727686 0.6935738  0.4760483  0.         0.06217825 0.\n",
      "  0.         0.23486646 0.49055183 0.06220648 0.         0.\n",
      "  0.         0.16272098 0.90296894 1.0281792  0.         0.01058331\n",
      "  0.44568822 0.689796   0.         0.6091679  0.49945024 1.0417222\n",
      "  0.         0.6617861  0.28343043 0.         0.         0.\n",
      "  0.         0.2741225  0.01819796 0.        ]]\n",
      "Hi!\n",
      "[[0.42859384 0.         0.6001682  0.13486405 0.         0.64693296\n",
      "  0.90759665 1.0333276  0.54174423 0.04734884 0.3574163  0.\n",
      "  0.         0.         0.         0.27566817 0.07277459 0.66243523\n",
      "  0.         0.         0.6145997  0.11779132 0.         0.31038356\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24903184 0.07242264 0.23133177 0.         0.0964563  0.\n",
      "  0.         0.6230014  0.         0.74658924 0.         0.\n",
      "  0.         1.0383704  0.         0.6893189  0.         0.\n",
      "  0.06501193 1.1720172  0.2559107  0.24367768 0.7018429  0.\n",
      "  0.         0.32238126 0.         0.         0.         0.\n",
      "  0.         1.090961   0.23317112 0.        ]]\n",
      "Hi!\n",
      "[[0.49728152 0.         0.         0.70377743 0.         0.72825086\n",
      "  2.0658484  2.0722134  0.         0.         0.04229841 0.\n",
      "  0.         0.4235278  0.         0.21390232 0.         0.51460737\n",
      "  0.         0.0278594  0.17153949 0.2654639  0.         0.\n",
      "  0.         0.         0.         0.69181895 0.         0.\n",
      "  1.3004227  0.60132223 0.48566124 0.         0.7719253  0.\n",
      "  0.         1.1440804  0.11747119 0.34552777 0.35567373 0.\n",
      "  0.         0.6071482  1.2904471  1.5545924  0.         0.\n",
      "  0.         1.0210485  0.04591344 0.77655786 0.9131328  0.6212583\n",
      "  0.         0.3994269  0.35441    0.         0.         0.\n",
      "  0.         0.6613248  0.94984657 0.        ]]\n",
      "Hi!\n",
      "[[4.95310068e-01 0.00000000e+00 3.19301516e-01 5.25850117e-01\n",
      "  0.00000000e+00 8.36085677e-01 1.76797247e+00 1.64525616e+00\n",
      "  1.03370078e-01 5.98232087e-04 2.07207114e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.81258559e-01\n",
      "  0.00000000e+00 6.43011093e-01 0.00000000e+00 0.00000000e+00\n",
      "  3.68204236e-01 5.25864027e-02 0.00000000e+00 6.38367161e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.88185722e-01\n",
      "  0.00000000e+00 0.00000000e+00 5.56898296e-01 3.01314592e-01\n",
      "  3.63623530e-01 0.00000000e+00 4.21157688e-01 0.00000000e+00\n",
      "  0.00000000e+00 7.89881647e-01 0.00000000e+00 6.91080153e-01\n",
      "  2.16226295e-01 0.00000000e+00 0.00000000e+00 9.27528203e-01\n",
      "  4.47542280e-01 1.14175355e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.77909467e-02 1.18180263e+00 0.00000000e+00 4.72883403e-01\n",
      "  7.59688139e-01 1.21262774e-01 0.00000000e+00 6.73567832e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.67758119e-01 5.82072198e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.6501213  0.26105607 0.94114786 0.1911957  0.         1.146198\n",
      "  0.44060615 0.8162612  0.         0.04853932 0.31943065 0.\n",
      "  0.         0.         0.         0.         0.         0.27780822\n",
      "  0.         0.8532361  0.5036916  0.         0.         0.05213206\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4546158  0.69513994 0.11429387 0.         0.         0.\n",
      "  0.         0.25911722 0.         0.4066654  0.         0.\n",
      "  0.         0.         0.74198425 1.0389185  0.         0.2098785\n",
      "  0.6200971  0.92467433 0.         0.73316145 1.068397   0.7785655\n",
      "  0.         1.3389263  0.         0.         0.04155912 0.\n",
      "  0.18050028 0.24565154 0.7360183  0.        ]]\n",
      "Hi!\n",
      "[[0.5273922  0.84891796 0.07081886 0.06467766 0.         0.41855553\n",
      "  0.46167004 0.8991512  0.09422067 0.         0.2526939  0.\n",
      "  1.4002296  0.9835937  0.         0.27485335 0.         0.40801135\n",
      "  0.13901295 0.5696571  0.21608546 0.         0.         0.19751944\n",
      "  0.         0.         0.         0.640968   0.         0.\n",
      "  1.249954   0.7846345  0.10902772 0.         0.48083434 0.\n",
      "  0.21048862 0.68440324 0.4673763  0.13835877 0.         0.\n",
      "  0.         0.19782986 1.183105   0.9903572  0.         0.55062854\n",
      "  0.06647686 0.7794673  0.5421117  0.4124695  0.62943566 1.1070437\n",
      "  0.         0.         0.4553704  0.         0.         0.\n",
      "  0.         0.24293837 0.44066703 0.        ]]\n",
      "Hi!\n",
      "[[0.6411042  0.07607163 1.1549559  0.         0.         0.9826824\n",
      "  0.5785966  0.57391554 0.41146973 0.         0.47346714 0.\n",
      "  0.15476774 0.         0.         0.2061844  0.14755437 0.7057833\n",
      "  0.         0.41285047 0.8440051  0.         0.         0.02926353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21584326 0.5262376  0.04662429 0.         0.12862049 0.\n",
      "  0.         0.7454616  0.         0.60769904 0.         0.\n",
      "  0.         0.41223344 0.39689204 0.56700236 0.         0.5991006\n",
      "  0.20327123 0.70541954 0.25302225 0.37162623 0.4381353  0.5523963\n",
      "  0.         0.637482   0.00117087 0.         0.         0.\n",
      "  0.         0.6323488  0.92743087 0.16699591]]\n",
      "Hi!\n",
      "[[0.00328322 0.13742495 0.11146489 0.02605567 0.         0.2519398\n",
      "  0.1057014  0.32085326 0.         0.10127896 0.07594825 0.\n",
      "  0.         0.16341314 0.         0.05682756 0.         0.10141046\n",
      "  0.         0.25711858 0.01657497 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0403982  0.23890832 0.2250494  0.         0.         0.\n",
      "  0.         0.00860471 0.14383727 0.18681829 0.         0.\n",
      "  0.         0.         0.25652298 0.5399658  0.         0.01348959\n",
      "  0.26577297 0.39172253 0.         0.26181337 0.17358372 0.42899364\n",
      "  0.         0.4063956  0.         0.         0.         0.\n",
      "  0.20855881 0.235915   0.         0.        ]]\n",
      "Hi!\n",
      "[[0.55117047 0.22838019 0.         0.47792378 0.         0.38813248\n",
      "  1.3568398  1.8327852  0.1412418  0.         0.14514057 0.\n",
      "  1.246136   1.1725233  0.         0.41033822 0.         0.50333315\n",
      "  0.13997087 0.07062087 0.23956287 0.41901022 0.         0.14101756\n",
      "  0.15585676 0.         0.         1.0640378  0.         0.\n",
      "  1.7666391  0.9316824  0.23497434 0.         0.95794666 0.\n",
      "  0.15005444 1.1274122  0.33679166 0.11147859 0.29352382 0.\n",
      "  0.         0.49278364 1.5321877  1.4409064  0.         0.25701892\n",
      "  0.         0.9763895  0.5590518  0.5827397  1.0350479  1.1036245\n",
      "  0.         0.         0.6131641  0.         0.         0.\n",
      "  0.         0.5260871  0.9677979  0.        ]]\n",
      "Hi!\n",
      "[[0.10746478 0.79568696 0.7255427  0.         0.         0.41947243\n",
      "  0.14964585 0.0769383  0.75101537 0.         0.4375032  0.\n",
      "  0.8971551  0.         0.         0.43323615 0.         0.43766105\n",
      "  0.06071698 0.42382237 0.6373091  0.         0.         0.04777641\n",
      "  0.         0.         0.         0.0327845  0.         0.\n",
      "  0.29786348 0.16759053 0.         0.         0.05200758 0.\n",
      "  0.         0.2684006  0.         0.35003787 0.         0.\n",
      "  0.         0.04098997 0.00234653 0.         0.         0.43246347\n",
      "  0.         0.608874   0.598942   0.00756043 0.13450018 0.26761872\n",
      "  0.         0.         0.         0.         0.1410301  0.\n",
      "  0.         0.5615906  0.3081027  0.56200045]]\n",
      "Hi!\n",
      "[[0.580704   0.         0.5685581  0.5170984  0.         0.823007\n",
      "  2.4750612  2.4125998  0.83289963 0.         0.28607416 0.\n",
      "  0.         0.         0.         0.638008   0.01711804 0.8186805\n",
      "  0.         0.         0.72872865 0.32696652 0.         0.16349772\n",
      "  0.         0.         0.         0.4335129  0.         0.\n",
      "  0.83473337 0.24128097 0.26904637 0.         0.78124803 0.\n",
      "  0.         1.5494102  0.         0.6400787  0.503895   0.\n",
      "  0.         1.7542126  0.39672393 0.9901988  0.         0.\n",
      "  0.         0.9736066  0.3020851  0.4982103  0.8785084  0.\n",
      "  0.         0.36776903 0.12657432 0.         0.         0.\n",
      "  0.         1.2605133  1.574303   0.        ]]\n",
      "Hi!\n",
      "[[0.36264622 0.00414276 0.62851816 0.10745734 0.         0.69049484\n",
      "  0.92042786 1.1172894  0.3973166  0.         0.37180743 0.\n",
      "  0.13584863 0.         0.         0.3100316  0.         0.6111624\n",
      "  0.         0.10496318 0.61647105 0.         0.         0.03231599\n",
      "  0.         0.         0.         0.2679664  0.         0.\n",
      "  0.8128419  0.48235005 0.07799737 0.         0.43244213 0.\n",
      "  0.         0.7598664  0.         0.3748152  0.02247452 0.\n",
      "  0.         0.51985914 0.5049444  0.90256137 0.         0.\n",
      "  0.         1.0005794  0.20361884 0.4357174  0.85426265 0.22045359\n",
      "  0.         0.24947995 0.         0.         0.         0.\n",
      "  0.         0.71152335 0.8288966  0.        ]]\n",
      "Hi!\n",
      "[[0.9644973  0.15536657 1.5061859  0.         0.         1.0827507\n",
      "  0.23512241 0.5093744  0.6052294  0.03002949 0.57303286 0.\n",
      "  0.         0.         0.         0.19209553 0.5534515  0.65563345\n",
      "  0.         0.3637865  1.0841672  0.03717801 0.         0.5232308\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27965185 0.1236018  0.         0.         0.\n",
      "  0.         0.43811658 0.         0.8218937  0.         0.\n",
      "  0.         0.8005345  0.         0.3877525  0.         0.17131096\n",
      "  0.26795337 0.99036324 0.18846239 0.28984922 0.7214237  0.18531553\n",
      "  0.         1.1013498  0.         0.1234196  0.05545584 0.\n",
      "  0.2782054  0.72972476 0.72820455 0.27459148]]\n",
      "Hi!\n",
      "[[0.08193858 0.31254238 0.24538368 0.00755166 0.         0.00184134\n",
      "  0.         0.18557116 0.04146254 0.         0.09994072 0.\n",
      "  0.27854502 0.25645    0.         0.12723233 0.         0.13132319\n",
      "  0.         0.12613016 0.03574107 0.         0.         0.\n",
      "  0.         0.         0.         0.04221313 0.         0.\n",
      "  0.15265605 0.29805872 0.07256693 0.         0.         0.\n",
      "  0.         0.07420661 0.2657385  0.08786648 0.         0.\n",
      "  0.         0.         0.34439906 0.22689873 0.         0.05382393\n",
      "  0.02281411 0.10897384 0.         0.09129588 0.21760333 0.30970913\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04651247 0.12818246 0.1181775  0.        ]]\n",
      "Hi!\n",
      "[[0.5304962  1.0348374  0.5161493  0.         0.         0.32857877\n",
      "  0.129335   0.57739216 0.6601098  0.         0.45701966 0.\n",
      "  1.7656956  0.55921996 0.         0.66547287 0.         0.7057019\n",
      "  0.7438295  0.48548466 0.5879479  0.         0.         0.11884426\n",
      "  0.20670426 0.         0.         0.40050477 0.         0.\n",
      "  1.0401565  0.7333073  0.         0.         0.5111316  0.\n",
      "  0.5063872  0.90708697 0.21668454 0.46745634 0.         0.\n",
      "  0.         0.31257665 0.9650897  0.45410982 0.         0.9634933\n",
      "  0.         0.727411   0.80572444 0.32689217 0.43232232 0.9604001\n",
      "  0.         0.         0.38393512 0.         0.         0.\n",
      "  0.         0.45475617 0.8183423  0.43740365]]\n",
      "Hi!\n",
      "[[0.         0.18179134 0.24223751 0.         0.         0.21405503\n",
      "  0.         0.05207117 0.07033622 0.09261831 0.19417116 0.\n",
      "  0.01765087 0.03897985 0.         0.02128129 0.         0.05764553\n",
      "  0.         0.2704584  0.14648998 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0581853  0.06156321 0.         0.         0.\n",
      "  0.         0.         0.03639919 0.13684267 0.         0.\n",
      "  0.         0.         0.05560451 0.25827056 0.         0.11868522\n",
      "  0.17205623 0.11960222 0.         0.18665488 0.05904025 0.27418038\n",
      "  0.         0.12389661 0.         0.         0.05826815 0.\n",
      "  0.10011229 0.12781613 0.         0.00122291]]\n",
      "Hi!\n",
      "[[0.60027814 0.78877085 1.3587018  0.         0.         1.0946192\n",
      "  0.         0.28820464 0.3772864  0.0132879  0.57296556 0.\n",
      "  0.69883895 0.         0.         0.00142834 0.         0.38810465\n",
      "  0.         0.89082116 0.8465874  0.         0.         0.265595\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37267098 0.675513   0.         0.         0.         0.\n",
      "  0.         0.174854   0.         0.5408931  0.         0.\n",
      "  0.         0.         0.45950666 0.53214836 0.         0.5281975\n",
      "  0.515339   0.9404586  0.14860918 0.5743165  0.9529709  0.7802892\n",
      "  0.         0.9797102  0.         0.         0.1819402  0.\n",
      "  0.         0.27818546 0.7492199  0.29793957]]\n",
      "Hi!\n",
      "[[0.3739716  0.8014092  1.0937903  0.         0.         0.6383283\n",
      "  0.04876418 0.09846283 0.8377219  0.         0.5745445  0.\n",
      "  1.2916865  0.         0.         0.5846311  0.         0.6735546\n",
      "  0.5470775  0.43816596 0.8991036  0.         0.         0.\n",
      "  0.10592575 0.         0.         0.00865591 0.         0.\n",
      "  0.47105727 0.49201652 0.         0.         0.14815934 0.\n",
      "  0.3255932  0.74186605 0.         0.6658154  0.         0.\n",
      "  0.         0.08031832 0.3675332  0.04486885 0.         0.9812969\n",
      "  0.00983736 0.74374664 0.6508597  0.2956911  0.23771194 0.62449616\n",
      "  0.         0.         0.0826812  0.00960484 0.10349978 0.\n",
      "  0.         0.4819252  0.90423226 0.78991055]]\n",
      "Hi!\n",
      "[[0.09816635 0.4726439  0.669565   0.         0.         0.24246939\n",
      "  0.         0.         0.13016243 0.         0.28212968 0.\n",
      "  0.37563094 0.         0.         0.07878833 0.         0.09639435\n",
      "  0.         0.49181747 0.31261808 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28199378 0.         0.         0.         0.\n",
      "  0.         0.         0.11205084 0.2499045  0.         0.\n",
      "  0.         0.         0.05060605 0.08334218 0.         0.34990436\n",
      "  0.3683075  0.33616182 0.04340696 0.2988128  0.1804013  0.5228445\n",
      "  0.         0.17314689 0.         0.         0.17602254 0.\n",
      "  0.1708169  0.05565392 0.08214954 0.19169313]]\n",
      "Hi!\n",
      "[[0.9929845  0.09181061 1.5658207  0.         0.         1.0952346\n",
      "  0.38336158 0.588085   0.8183565  0.07210195 0.5693405  0.\n",
      "  0.         0.         0.         0.2929315  0.5110467  0.708577\n",
      "  0.         0.17348847 1.1448549  0.07134558 0.         0.6489474\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30410185 0.12516132 0.         0.         0.\n",
      "  0.         0.55687726 0.         0.86854506 0.         0.\n",
      "  0.         0.9075935  0.         0.43055388 0.         0.33398712\n",
      "  0.19993006 1.0160908  0.35477918 0.3294315  0.7463961  0.16153932\n",
      "  0.         1.0543171  0.         0.22661097 0.         0.\n",
      "  0.08913761 0.81162727 0.8317072  0.44990936]]\n",
      "Hi!\n",
      "[[0.35431632 0.         0.         0.5102044  0.         0.7561928\n",
      "  1.8469826  1.9147902  0.08961804 0.         0.12630951 0.\n",
      "  0.         0.39508638 0.         0.2235949  0.         0.48083207\n",
      "  0.         0.         0.25426582 0.21070008 0.         0.\n",
      "  0.         0.         0.         0.54255664 0.         0.\n",
      "  1.1779175  0.4491981  0.3203626  0.         0.7023522  0.\n",
      "  0.         1.063414   0.         0.33967608 0.30116436 0.\n",
      "  0.         0.6287247  1.0099483  1.3894606  0.         0.\n",
      "  0.         1.0962678  0.13831607 0.699017   0.9551453  0.43956614\n",
      "  0.         0.28881487 0.1919554  0.         0.         0.\n",
      "  0.         0.7663355  0.92912376 0.        ]]\n",
      "Hi!\n",
      "[[0.5123452  0.         0.03739879 0.5075057  0.         0.7201222\n",
      "  1.6272396  1.9587626  0.35156444 0.         0.20391233 0.\n",
      "  0.85670173 0.69275475 0.         0.48558056 0.         0.5797327\n",
      "  0.18276863 0.         0.41571942 0.32004088 0.         0.\n",
      "  0.20453088 0.         0.         0.9693963  0.         0.\n",
      "  1.5186754  0.7283176  0.13757715 0.         0.98189735 0.\n",
      "  0.30485004 1.3377208  0.11600854 0.11393677 0.40848386 0.\n",
      "  0.         0.55294853 1.4005759  1.3868058  0.         0.33983478\n",
      "  0.         0.86309594 0.44232032 0.72198474 0.79861    0.7844986\n",
      "  0.         0.         0.5815194  0.         0.         0.\n",
      "  0.         0.5352705  1.3350581  0.        ]]\n",
      "Hi!\n",
      "[[0.01052544 0.19576985 0.         0.         0.         0.03751093\n",
      "  0.0318315  0.2258162  0.         0.01826991 0.08489426 0.\n",
      "  0.15025024 0.25375998 0.         0.00480047 0.         0.09739164\n",
      "  0.         0.13226612 0.03054114 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14515786 0.17689839 0.21540983 0.         0.         0.\n",
      "  0.         0.         0.22397833 0.02784571 0.         0.\n",
      "  0.         0.         0.25944424 0.34760368 0.         0.\n",
      "  0.13497235 0.17235802 0.         0.17243879 0.06705622 0.42028552\n",
      "  0.         0.08428334 0.1052425  0.         0.         0.\n",
      "  0.09823187 0.16303474 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.43496636 0.         0.62555254 0.24481106 0.         0.51337576\n",
      "  1.7528759  1.7307688  1.0291468  0.         0.40764657 0.\n",
      "  0.         0.         0.         0.7829688  0.07401302 0.8503491\n",
      "  0.         0.         0.73133683 0.28192583 0.         0.21388626\n",
      "  0.03089443 0.         0.         0.18419088 0.         0.\n",
      "  0.58880985 0.         0.12139564 0.         0.58255595 0.\n",
      "  0.         1.3113903  0.         0.7163829  0.313269   0.\n",
      "  0.         1.637429   0.01648813 0.6781392  0.         0.\n",
      "  0.         0.95917773 0.6380247  0.24615613 0.6928166  0.\n",
      "  0.         0.         0.         0.08012772 0.         0.\n",
      "  0.         1.3492033  1.0514879  0.        ]]\n",
      "Hi!\n",
      "[[0.32377774 0.6916107  0.5370123  0.         0.         0.3032021\n",
      "  0.         0.05646824 0.         0.         0.25287223 0.\n",
      "  0.51830095 0.29077512 0.         0.         0.         0.19695956\n",
      "  0.         0.6446911  0.21711189 0.         0.         0.05029909\n",
      "  0.         0.         0.         0.06768809 0.         0.\n",
      "  0.26559067 0.5884447  0.11398946 0.         0.         0.\n",
      "  0.         0.         0.5306488  0.19806845 0.         0.\n",
      "  0.         0.         0.48468223 0.4331165  0.         0.24172705\n",
      "  0.4903573  0.32901743 0.         0.38982022 0.36570805 0.8447521\n",
      "  0.         0.36140394 0.14957859 0.         0.07196489 0.\n",
      "  0.07763384 0.07618801 0.1954331  0.        ]]\n",
      "Hi!\n",
      "[[0.62855685 0.23256284 0.         0.5329576  0.         0.40483472\n",
      "  1.2584381  1.7036206  0.01128845 0.         0.13703977 0.\n",
      "  1.049332   1.106261   0.         0.32707262 0.         0.42019886\n",
      "  0.04843024 0.2411479  0.18072769 0.29031217 0.         0.11451914\n",
      "  0.15048221 0.         0.         0.94479114 0.         0.\n",
      "  1.6248415  0.85989    0.32816806 0.         0.84892166 0.\n",
      "  0.27897644 1.1128025  0.4116935  0.18961295 0.2503919  0.\n",
      "  0.         0.49412945 1.5771784  1.430073   0.         0.36836448\n",
      "  0.         0.9081249  0.43051246 0.62256736 0.9128923  1.1061814\n",
      "  0.         0.         0.5735568  0.         0.         0.\n",
      "  0.         0.30349267 0.76415664 0.        ]]\n",
      "Hi!\n",
      "[[0.1285475  0.32794872 0.4297811  0.         0.         0.2112144\n",
      "  0.         0.         0.15924515 0.04425936 0.22826454 0.\n",
      "  0.15746462 0.         0.         0.10034884 0.02516829 0.14658599\n",
      "  0.         0.35784897 0.2085427  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11127236 0.03824442 0.         0.         0.\n",
      "  0.         0.         0.         0.1830642  0.         0.\n",
      "  0.         0.         0.05241611 0.22612174 0.         0.23823877\n",
      "  0.23315705 0.2579785  0.01791838 0.1935293  0.0256298  0.3653834\n",
      "  0.         0.11146121 0.         0.         0.12062585 0.\n",
      "  0.17953877 0.19396263 0.         0.1060892 ]]\n",
      "Hi!\n",
      "[[0.66075295 0.         1.28255    0.0244574  0.         0.69970244\n",
      "  1.1386986  1.2261395  1.3615034  0.         0.55029494 0.\n",
      "  0.         0.         0.         0.8381479  0.42188457 0.9120732\n",
      "  0.         0.         1.1588154  0.31559262 0.         0.653873\n",
      "  0.         0.         0.         0.09772521 0.         0.\n",
      "  0.27813524 0.1631307  0.1098625  0.         0.27181897 0.\n",
      "  0.         1.1861224  0.         0.72757256 0.23417695 0.\n",
      "  0.         1.5673455  0.         0.35053733 0.         0.13788375\n",
      "  0.         0.8691312  0.6895078  0.21110575 0.5985835  0.\n",
      "  0.         0.2199835  0.         0.3854991  0.         0.\n",
      "  0.         1.2391087  1.3477188  0.47233087]]\n",
      "Hi!\n",
      "[[0.62941855 0.04249416 1.2331975  0.         0.         1.0624053\n",
      "  0.66433096 0.7746099  0.6560112  0.         0.5131192  0.\n",
      "  0.23205253 0.         0.         0.33189976 0.16482699 0.7331959\n",
      "  0.         0.18336903 1.0170825  0.         0.         0.21590663\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26838306 0.44665107 0.07123107 0.         0.19184773 0.\n",
      "  0.         0.8148143  0.         0.5728504  0.         0.\n",
      "  0.         0.6218003  0.285403   0.54918474 0.         0.50830084\n",
      "  0.08187833 0.8042885  0.32089823 0.43969473 0.5950993  0.3627884\n",
      "  0.         0.6201973  0.         0.01752928 0.         0.\n",
      "  0.         0.75867313 1.1349477  0.28295416]]\n",
      "Hi!\n",
      "[[0.28868237 0.3099772  0.20718463 0.         0.         0.40160212\n",
      "  0.99850535 1.2058932  0.6332281  0.         0.3201354  0.\n",
      "  1.0441005  0.4329792  0.         0.62891525 0.         0.69434845\n",
      "  0.26221362 0.05134325 0.50255996 0.06338754 0.         0.\n",
      "  0.28284338 0.         0.         0.54643625 0.         0.\n",
      "  1.1532396  0.4769048  0.         0.         0.7523857  0.\n",
      "  0.24659586 1.1891878  0.         0.23337099 0.06842161 0.\n",
      "  0.         0.38231772 0.8741325  0.79206604 0.         0.43647534\n",
      "  0.         0.8267125  0.68798965 0.4190401  0.59583026 0.5506994\n",
      "  0.         0.         0.3293973  0.         0.         0.\n",
      "  0.         0.659792   0.91178024 0.05455505]]\n",
      "Hi!\n",
      "[[0.5013744  0.         0.50302637 0.36637923 0.         0.7350206\n",
      "  1.9062154  1.8666799  0.6864004  0.         0.2841     0.\n",
      "  0.         0.         0.         0.52815974 0.         0.6852797\n",
      "  0.         0.         0.6711411  0.17680432 0.         0.11276452\n",
      "  0.00745745 0.         0.         0.20717238 0.         0.\n",
      "  0.6643473  0.20949273 0.17690636 0.         0.6175046  0.\n",
      "  0.         1.3070259  0.         0.60949725 0.32039204 0.\n",
      "  0.         1.3097473  0.35885015 0.8939088  0.         0.\n",
      "  0.         0.936378   0.36983705 0.4353814  0.6595831  0.00812484\n",
      "  0.         0.25127792 0.0393139  0.         0.         0.\n",
      "  0.         1.1113375  1.2253913  0.        ]]\n",
      "Hi!\n",
      "[[0.05035464 0.19043796 0.12057518 0.         0.         0.02143861\n",
      "  0.         0.0775021  0.00586451 0.01442789 0.07227528 0.\n",
      "  0.2033181  0.12224396 0.         0.         0.         0.0155165\n",
      "  0.         0.09934661 0.04240341 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04263009 0.14763981 0.10982799 0.         0.         0.\n",
      "  0.         0.         0.1798123  0.01139018 0.         0.\n",
      "  0.         0.         0.1684984  0.17564474 0.         0.03871118\n",
      "  0.08312096 0.01293694 0.         0.18169494 0.02971299 0.3180668\n",
      "  0.         0.01185458 0.08615849 0.         0.         0.\n",
      "  0.03212679 0.08659808 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6807068  0.08777251 0.2841751  0.4975112  0.         0.81422746\n",
      "  1.0453727  1.080756   0.         0.         0.         0.\n",
      "  0.         0.34619373 0.         0.06825509 0.         0.22059204\n",
      "  0.         0.66186786 0.06675119 0.         0.         0.06746046\n",
      "  0.         0.         0.         0.41882056 0.         0.\n",
      "  0.81436455 0.9014659  0.39153823 0.         0.21846724 0.\n",
      "  0.         0.48846868 0.43121448 0.18687601 0.01610451 0.\n",
      "  0.         0.32337478 1.2222832  1.2512898  0.         0.25756475\n",
      "  0.60778946 0.8373567  0.         0.7600181  0.7951021  1.1630803\n",
      "  0.         1.0373358  0.37961915 0.         0.         0.\n",
      "  0.         0.2072619  0.6513357  0.        ]]\n",
      "Hi!\n",
      "[[0.06226403 0.05953669 0.24533409 0.05840088 0.         0.14344099\n",
      "  0.05124081 0.24177141 0.         0.00203859 0.         0.\n",
      "  0.12129806 0.23945865 0.         0.         0.         0.05550361\n",
      "  0.         0.11241251 0.02827338 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08584394 0.24621198 0.2215665  0.         0.         0.\n",
      "  0.         0.         0.33838323 0.05267068 0.         0.\n",
      "  0.         0.         0.37040472 0.31139755 0.         0.08713258\n",
      "  0.2607084  0.14274591 0.         0.27862784 0.06999091 0.46778512\n",
      "  0.         0.3075898  0.10149908 0.         0.         0.\n",
      "  0.03303855 0.04968016 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.50896204 0.33738264 1.15398    0.         0.         0.71558815\n",
      "  0.3752121  0.34420174 0.90940964 0.01177368 0.55972385 0.\n",
      "  0.3263672  0.         0.         0.44557393 0.24740292 0.81271607\n",
      "  0.         0.15791976 1.0101279  0.17573072 0.         0.373074\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06177349 0.19095434 0.         0.         0.01303709 0.\n",
      "  0.         0.67415136 0.         0.762558   0.         0.\n",
      "  0.         0.6756039  0.         0.19010818 0.         0.438582\n",
      "  0.         0.87519044 0.5028355  0.18355992 0.44506186 0.09971643\n",
      "  0.         0.15002076 0.         0.17861947 0.03707745 0.\n",
      "  0.         0.8977431  0.6528099  0.6442357 ]]\n",
      "Hi!\n",
      "[[0.3471903  0.         0.15268664 0.33433437 0.         0.5670927\n",
      "  1.4010676  1.6690613  0.3802895  0.         0.23643653 0.\n",
      "  0.43441758 0.3688229  0.         0.41756094 0.         0.5521531\n",
      "  0.         0.         0.42786273 0.09152029 0.         0.00454532\n",
      "  0.         0.         0.         0.657988   0.         0.\n",
      "  1.288588   0.5045402  0.07890418 0.         0.7671905  0.\n",
      "  0.         1.0938251  0.         0.2449371  0.25142315 0.\n",
      "  0.         0.60651165 0.937798   1.2132794  0.         0.\n",
      "  0.         0.9089401  0.31393725 0.5801715  0.874477   0.37614703\n",
      "  0.         0.         0.26955402 0.         0.         0.\n",
      "  0.         0.64923745 1.093626   0.        ]]\n",
      "Hi!\n",
      "[[0.3827036  0.26498327 1.0148065  0.         0.         0.8883971\n",
      "  0.43119234 0.7637652  0.6922027  0.         0.49724853 0.\n",
      "  0.7827736  0.         0.         0.44179937 0.         0.56897646\n",
      "  0.14254531 0.22612932 0.8918867  0.         0.         0.07850976\n",
      "  0.         0.         0.         0.22211681 0.         0.\n",
      "  0.58793664 0.5923907  0.         0.         0.2248312  0.\n",
      "  0.09351744 0.87619716 0.         0.4915691  0.         0.\n",
      "  0.         0.36173865 0.5037806  0.5299404  0.         0.61674243\n",
      "  0.00654487 0.7319626  0.45709705 0.47320455 0.60584706 0.5349961\n",
      "  0.         0.24018289 0.08667196 0.         0.         0.\n",
      "  0.         0.5290523  1.1977044  0.30455366]]\n",
      "Hi!\n",
      "[[0.33985892 0.11244588 0.6541398  0.         0.         0.52399683\n",
      "  0.68485695 0.73204124 0.64257276 0.02629486 0.3935311  0.\n",
      "  0.         0.         0.         0.38507405 0.         0.7340548\n",
      "  0.         0.06550282 0.6512078  0.08207375 0.         0.1783118\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22663754 0.10426956 0.0866043  0.         0.17401886 0.\n",
      "  0.         0.670057   0.         0.6152148  0.         0.\n",
      "  0.         0.7577711  0.         0.4913137  0.         0.\n",
      "  0.         0.9243889  0.39393803 0.1909937  0.4522208  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.964139   0.32364312 0.22042914]]\n",
      "Hi!\n",
      "[[0.3054472  0.24891756 0.8340318  0.         0.         0.6399385\n",
      "  0.66615504 0.9594746  1.1692148  0.         0.5085366  0.\n",
      "  1.1988542  0.         0.         0.806947   0.         0.7311991\n",
      "  0.81770396 0.         0.91421795 0.         0.         0.\n",
      "  0.24818194 0.         0.         0.43508625 0.         0.\n",
      "  0.84586656 0.44900987 0.         0.         0.54625076 0.\n",
      "  0.47698873 1.2711556  0.         0.4534366  0.1757233  0.\n",
      "  0.         0.67158467 0.4515401  0.40402603 0.         0.7982607\n",
      "  0.         0.7674     0.9148575  0.36363068 0.4904523  0.3855275\n",
      "  0.         0.         0.29615223 0.07213541 0.         0.\n",
      "  0.         0.6898227  1.4201341  0.6302498 ]]\n",
      "Hi!\n",
      "[[0.31358773 0.7991293  1.0427395  0.         0.         0.7160897\n",
      "  0.         0.07772865 0.6501466  0.         0.5527869  0.\n",
      "  1.1194478  0.         0.         0.3554223  0.         0.50659156\n",
      "  0.2713687  0.5730371  0.7903682  0.         0.         0.04111725\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40996563 0.48465717 0.         0.         0.00345416 0.\n",
      "  0.06299176 0.42935088 0.         0.5296479  0.         0.\n",
      "  0.         0.         0.32392362 0.20632179 0.         0.75574774\n",
      "  0.21155195 0.68110514 0.42665246 0.35800278 0.4392325  0.58495545\n",
      "  0.         0.06981874 0.         0.         0.11612178 0.\n",
      "  0.         0.345979   0.75283456 0.63096017]]\n",
      "Hi!\n",
      "[[0.09682991 0.3596831  0.36653316 0.         0.         0.20071436\n",
      "  0.         0.         0.14778331 0.03512443 0.2491468  0.\n",
      "  0.29154193 0.         0.         0.08010926 0.         0.02587931\n",
      "  0.         0.3328482  0.23881608 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08425251 0.15781303 0.         0.         0.         0.\n",
      "  0.         0.         0.09472975 0.15664713 0.         0.\n",
      "  0.         0.         0.02449997 0.07739805 0.         0.23023179\n",
      "  0.18449391 0.1452583  0.06158866 0.19383636 0.139268   0.37877855\n",
      "  0.         0.         0.01852305 0.         0.13698626 0.\n",
      "  0.08310626 0.02102695 0.         0.10221781]]\n",
      "Hi!\n",
      "[[0.9679522  0.         1.4440739  0.16591315 0.         0.8696506\n",
      "  0.9763347  1.0594974  1.1438526  0.         0.5416539  0.\n",
      "  0.         0.         0.         0.56786495 0.75879025 0.856688\n",
      "  0.         0.         1.1783704  0.43681616 0.         0.7956928\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07770907 0.23431209 0.         0.         0.\n",
      "  0.         0.8521211  0.         1.027368   0.07312366 0.\n",
      "  0.         1.6866635  0.         0.35696667 0.         0.\n",
      "  0.         1.1955949  0.46172386 0.09450821 0.7247988  0.\n",
      "  0.         0.81906575 0.         0.37104258 0.         0.\n",
      "  0.         1.2279601  0.940533   0.2405565 ]]\n",
      "Hi!\n",
      "[[0.04459519 0.26113886 0.17928497 0.         0.         0.13057838\n",
      "  0.         0.04553195 0.12991416 0.07289884 0.18407024 0.\n",
      "  0.21315023 0.04015512 0.         0.05148363 0.         0.08825998\n",
      "  0.         0.19588368 0.13796763 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08643544 0.11097353 0.00122251 0.         0.         0.\n",
      "  0.         0.         0.02760295 0.082348   0.         0.\n",
      "  0.         0.         0.08402898 0.11542655 0.         0.10616148\n",
      "  0.03021238 0.10025157 0.03628651 0.04437849 0.00244554 0.26004612\n",
      "  0.         0.         0.08660338 0.         0.05475644 0.\n",
      "  0.08750504 0.12349697 0.         0.05948446]]\n",
      "Hi!\n",
      "[[0.5345869  0.         0.5093515  0.41246045 0.         0.8957676\n",
      "  1.1593549  1.3067073  0.03193941 0.04975673 0.21858743 0.\n",
      "  0.         0.         0.         0.1360244  0.         0.47216684\n",
      "  0.         0.23197109 0.40045777 0.         0.         0.14222346\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.48933595 0.4339658  0.2554111  0.         0.19384848 0.\n",
      "  0.         0.49215087 0.         0.62662    0.0892275  0.\n",
      "  0.         0.57489926 0.4468674  1.0416883  0.         0.\n",
      "  0.19376105 1.1237335  0.         0.537709   0.9594993  0.19600196\n",
      "  0.         0.90513337 0.         0.         0.         0.\n",
      "  0.03158848 0.6750955  0.53639466 0.        ]]\n",
      "Hi!\n",
      "[[0.13823071 0.37617442 0.25528196 0.         0.         0.2729141\n",
      "  0.         0.14717402 0.         0.02671206 0.1614208  0.\n",
      "  0.18281831 0.2661798  0.         0.         0.         0.13758744\n",
      "  0.         0.4140869  0.08176051 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18416308 0.38302657 0.1365575  0.         0.         0.\n",
      "  0.         0.         0.2561659  0.1186648  0.         0.\n",
      "  0.         0.         0.38422266 0.4339319  0.         0.12277313\n",
      "  0.3835782  0.3155409  0.         0.2971312  0.245093   0.55038416\n",
      "  0.         0.32690936 0.05102506 0.         0.00785908 0.\n",
      "  0.1464882  0.12139753 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.03494447 0.16055688 0.06135309 0.         0.         0.1812645\n",
      "  0.05446782 0.21418913 0.         0.12029913 0.15849388 0.\n",
      "  0.         0.17433748 0.         0.         0.         0.08671736\n",
      "  0.         0.2161994  0.0614811  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0007703  0.09937091 0.19137223 0.         0.         0.\n",
      "  0.         0.         0.1321503  0.12000514 0.         0.\n",
      "  0.         0.         0.22019391 0.4399347  0.         0.00629093\n",
      "  0.22226839 0.15226856 0.         0.2025589  0.12885402 0.38493848\n",
      "  0.         0.1740193  0.00761079 0.         0.         0.\n",
      "  0.0420813  0.11833054 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.1617751  0.         1.8458925  0.         0.         1.0675842\n",
      "  0.37558833 0.5881203  1.0386243  0.         0.654304   0.\n",
      "  0.         0.         0.         0.50597626 0.8941856  0.7862594\n",
      "  0.         0.02826781 1.383076   0.3267185  0.         0.80594385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17890981 0.15519403 0.         0.         0.\n",
      "  0.         0.6026295  0.         0.9809809  0.         0.\n",
      "  0.         1.3619807  0.         0.23913781 0.         0.18328625\n",
      "  0.05975698 1.0902714  0.45036444 0.15439077 0.7118332  0.\n",
      "  0.         1.143308   0.         0.50431484 0.         0.\n",
      "  0.14831664 0.9887323  0.8903157  0.52361274]]\n",
      "Hi!\n",
      "[[0.43294582 0.         0.9660628  0.13524316 0.         0.68540376\n",
      "  1.4147319  1.5854024  1.2215137  0.         0.46701416 0.\n",
      "  0.31172344 0.         0.         0.84678924 0.06499478 0.83821356\n",
      "  0.08364438 0.         1.0240035  0.13367872 0.         0.37763703\n",
      "  0.         0.         0.         0.4101928  0.         0.\n",
      "  0.7002812  0.28247133 0.07949734 0.         0.5657585  0.\n",
      "  0.06921143 1.3896629  0.         0.52748334 0.23363623 0.\n",
      "  0.         1.4057927  0.0905897  0.59172225 0.         0.1879001\n",
      "  0.         0.8292977  0.66158444 0.37322354 0.7609989  0.\n",
      "  0.         0.01186305 0.07716517 0.13283855 0.         0.\n",
      "  0.         1.098802   1.5866265  0.24417023]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1492128  0.47717315 0.6159812  0.         0.         0.42766607\n",
      "  0.         0.         0.30321038 0.05953288 0.31109568 0.\n",
      "  0.33588102 0.         0.         0.09920906 0.0958402  0.31989804\n",
      "  0.         0.5032523  0.4397165  0.         0.         0.0067963\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1273378  0.04473404 0.         0.         0.\n",
      "  0.         0.         0.         0.31113383 0.         0.\n",
      "  0.         0.         0.         0.10731058 0.         0.33426636\n",
      "  0.32054445 0.4386231  0.13412857 0.14844474 0.0488909  0.34089172\n",
      "  0.         0.21484423 0.         0.         0.1288798  0.\n",
      "  0.25809917 0.37024432 0.10080861 0.31290153]]\n",
      "Hi!\n",
      "[[1.19774446e-01 6.77254677e-01 5.79639375e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.36395556e-01 1.28124937e-01 2.82030582e-01\n",
      "  5.31042457e-01 0.00000000e+00 4.41253096e-01 0.00000000e+00\n",
      "  8.40292275e-01 0.00000000e+00 0.00000000e+00 3.47840667e-01\n",
      "  0.00000000e+00 4.79813814e-01 0.00000000e+00 4.24377620e-01\n",
      "  4.92562443e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.52189952e-01 3.63832146e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.48222581e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.74085391e-01 0.00000000e+00 3.41763020e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.24065511e-02\n",
      "  1.88747436e-01 2.85696208e-01 0.00000000e+00 3.72787952e-01\n",
      "  0.00000000e+00 6.72902167e-01 5.56392968e-01 1.79811388e-01\n",
      "  2.62276262e-01 4.35619503e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.89792961e-02 0.00000000e+00 5.23515278e-04 0.00000000e+00\n",
      "  0.00000000e+00 4.92000610e-01 3.13130409e-01 3.81710649e-01]]\n",
      "Hi!\n",
      "[[0.5040737  0.3252823  0.8720791  0.         0.         0.7663807\n",
      "  0.03248693 0.26561087 0.11017796 0.13303581 0.35909864 0.\n",
      "  0.         0.         0.         0.         0.0615584  0.3530989\n",
      "  0.         0.6043439  0.522561   0.         0.         0.22808313\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01581581 0.33179766 0.08552974 0.         0.         0.\n",
      "  0.         0.09383473 0.         0.44172052 0.         0.\n",
      "  0.         0.05372072 0.20730364 0.5707674  0.         0.190742\n",
      "  0.4381492  0.69394153 0.         0.38592315 0.51620704 0.41346854\n",
      "  0.         0.8503385  0.         0.         0.08307488 0.\n",
      "  0.33101207 0.36914477 0.24142118 0.07856512]]\n",
      "Hi!\n",
      "[[0.07729214 0.25205782 0.11801326 0.         0.         0.43142843\n",
      "  0.27913573 0.4398569  0.         0.11935108 0.16920848 0.\n",
      "  0.00441787 0.19697545 0.         0.01907862 0.         0.18746766\n",
      "  0.         0.44601157 0.11362857 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21307707 0.16441116 0.08376904 0.         0.         0.\n",
      "  0.         0.13093469 0.         0.2345952  0.         0.\n",
      "  0.         0.         0.3308549  0.7288191  0.         0.09894785\n",
      "  0.27314404 0.5189932  0.         0.34707615 0.33227408 0.47292164\n",
      "  0.         0.3035939  0.         0.         0.         0.\n",
      "  0.12565418 0.2846098  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.05097164 0.20577535 0.2602448  0.         0.         0.29749963\n",
      "  0.         0.12260819 0.         0.11009624 0.16134521 0.\n",
      "  0.         0.05685913 0.         0.01333338 0.         0.15550546\n",
      "  0.         0.33339193 0.1251118  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00641293 0.14827937 0.04679443 0.         0.         0.\n",
      "  0.         0.         0.00066683 0.16953585 0.         0.\n",
      "  0.         0.         0.17306128 0.3978109  0.         0.12754287\n",
      "  0.29341453 0.25548252 0.         0.20845552 0.10034364 0.34397087\n",
      "  0.         0.34697077 0.         0.         0.03709885 0.\n",
      "  0.19103958 0.14728494 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.38162744 0.24609847 1.0006596  0.         0.         0.79966766\n",
      "  0.523799   0.7794283  0.72554135 0.         0.5364162  0.\n",
      "  0.72001886 0.         0.         0.48968172 0.         0.6685435\n",
      "  0.16205297 0.18594219 0.9188106  0.         0.         0.04985784\n",
      "  0.         0.         0.         0.2756644  0.         0.\n",
      "  0.6673609  0.59442896 0.         0.         0.34042382 0.\n",
      "  0.18059985 0.95032513 0.         0.5037372  0.04546398 0.\n",
      "  0.         0.45595974 0.4947534  0.54077893 0.         0.5737082\n",
      "  0.         0.7093688  0.48831475 0.35847464 0.60508084 0.47625148\n",
      "  0.         0.11110855 0.18306608 0.         0.         0.\n",
      "  0.         0.6455576  1.2427533  0.28756937]]\n",
      "Hi!\n",
      "[[0.2828444  1.0484253  1.355331   0.         0.         0.7766197\n",
      "  0.         0.         0.8793983  0.         0.6352945  0.\n",
      "  1.1957617  0.         0.         0.45541662 0.30466282 0.57040435\n",
      "  0.30615065 0.8026591  0.92853665 0.         0.         0.06464602\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23381338 0.27052638 0.         0.         0.02132048 0.\n",
      "  0.         0.36857656 0.         0.65156174 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.94423264\n",
      "  0.2966178  0.8005084  0.6687493  0.14324208 0.32071722 0.63933676\n",
      "  0.         0.         0.         0.14301468 0.2602184  0.\n",
      "  0.12316179 0.45284802 0.6065822  0.9003349 ]]\n",
      "Hi!\n",
      "[[0.64909816 0.72793794 0.17887366 0.31698886 0.         0.43933904\n",
      "  0.32273823 0.8437166  0.         0.         0.15141198 0.\n",
      "  0.8030242  0.91726446 0.         0.         0.         0.19172132\n",
      "  0.         0.74143237 0.11259607 0.         0.         0.34372088\n",
      "  0.         0.         0.         0.4245815  0.         0.\n",
      "  1.1404346  0.8295747  0.40164676 0.         0.2425576  0.\n",
      "  0.         0.27581093 0.7114955  0.12671405 0.         0.\n",
      "  0.         0.1032804  1.2560141  1.1042258  0.         0.26540792\n",
      "  0.54251236 0.7721505  0.         0.5897047  0.8183908  1.0922465\n",
      "  0.         0.41965178 0.38141617 0.         0.         0.\n",
      "  0.         0.14164641 0.19433768 0.        ]]\n",
      "Hi!\n",
      "[[0.6621516  0.13319533 1.29476    0.         0.         0.6682214\n",
      "  0.26724863 0.25171107 0.88806653 0.06093503 0.5332855  0.\n",
      "  0.         0.         0.         0.33213964 0.5119088  0.75121295\n",
      "  0.         0.14010142 1.0339861  0.20379548 0.         0.4190746\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07806928 0.         0.         0.\n",
      "  0.         0.5499231  0.         0.65939045 0.         0.\n",
      "  0.         0.78981966 0.         0.14650568 0.         0.3217678\n",
      "  0.         0.75961345 0.37616926 0.07895915 0.32116666 0.\n",
      "  0.         0.4271268  0.         0.36556196 0.07991046 0.\n",
      "  0.0901041  0.9041833  0.6533977  0.5451457 ]]\n",
      "Hi!\n",
      "[[0.22604588 0.02557059 0.68539757 0.         0.         0.5689903\n",
      "  0.9663485  0.8677708  0.6546368  0.         0.41776595 0.\n",
      "  0.24939205 0.         0.         0.49512014 0.         0.8289842\n",
      "  0.         0.02137741 0.703777   0.         0.         0.\n",
      "  0.14471987 0.         0.         0.13873482 0.         0.\n",
      "  0.5367126  0.217032   0.         0.         0.51067257 0.\n",
      "  0.05700452 1.031022   0.         0.32579267 0.0366548  0.\n",
      "  0.         0.6241822  0.41894895 0.5782547  0.         0.37642577\n",
      "  0.         0.7423951  0.48426497 0.2666461  0.35862836 0.16342233\n",
      "  0.         0.         0.10387278 0.         0.         0.\n",
      "  0.         0.92822146 0.8590514  0.22320437]]\n",
      "Hi!\n",
      "[[0.4503835  0.45181006 0.5462586  0.11866768 0.         0.62311345\n",
      "  0.         0.24759842 0.         0.         0.22669363 0.\n",
      "  0.29928195 0.3786944  0.         0.         0.         0.\n",
      "  0.         0.6097429  0.20129867 0.         0.         0.00341752\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32103086 0.63071686 0.12764235 0.         0.         0.\n",
      "  0.         0.         0.5347822  0.12269513 0.         0.\n",
      "  0.         0.         0.6799958  0.58359367 0.         0.21865897\n",
      "  0.6961311  0.44411123 0.         0.5593874  0.55570894 0.99606997\n",
      "  0.         0.6780233  0.04901125 0.         0.         0.\n",
      "  0.15521942 0.         0.17711781 0.        ]]\n",
      "Hi!\n",
      "[[0.17277572 0.         0.44505817 0.         0.         0.467292\n",
      "  1.3131756  1.3659363  0.8505752  0.         0.34889495 0.\n",
      "  0.19062847 0.         0.         0.715524   0.         0.76883256\n",
      "  0.         0.         0.6357382  0.06462252 0.         0.03435572\n",
      "  0.12513216 0.         0.         0.23282987 0.         0.\n",
      "  0.67436093 0.13999581 0.         0.         0.5787504  0.\n",
      "  0.02502614 1.2335265  0.         0.48338512 0.13028733 0.\n",
      "  0.         1.0428301  0.24499789 0.6690091  0.         0.06375257\n",
      "  0.         0.8133413  0.6017944  0.2842638  0.45373404 0.\n",
      "  0.         0.         0.02783396 0.         0.         0.\n",
      "  0.         1.0345204  0.9564198  0.17005222]]\n",
      "Hi!\n",
      "[[0.22910804 0.53392243 0.65163136 0.         0.         0.595422\n",
      "  0.12359948 0.25797284 0.386358   0.00307717 0.41737992 0.\n",
      "  0.62693554 0.         0.         0.23814203 0.         0.5415828\n",
      "  0.         0.51487416 0.52561307 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37494966 0.35481194 0.         0.         0.0973269  0.\n",
      "  0.         0.48570156 0.         0.39198264 0.         0.\n",
      "  0.         0.         0.351786   0.47764876 0.         0.59873104\n",
      "  0.16036914 0.6190642  0.31189862 0.29397127 0.32883272 0.52930975\n",
      "  0.         0.06242584 0.01074724 0.         0.0337311  0.\n",
      "  0.         0.47654012 0.40877306 0.33147198]]\n",
      "Hi!\n",
      "[[0.5151252  0.         1.2589382  0.         0.         0.6451937\n",
      "  0.93165565 1.0138223  1.5160738  0.         0.62332195 0.\n",
      "  0.37884015 0.         0.         0.99529094 0.37134558 0.94279623\n",
      "  0.25105715 0.         1.2289345  0.3380489  0.         0.5270862\n",
      "  0.06369469 0.         0.         0.11757788 0.         0.\n",
      "  0.31775412 0.1132578  0.02652643 0.         0.34132472 0.\n",
      "  0.24234745 1.2839351  0.         0.7109862  0.27893746 0.\n",
      "  0.         1.5079366  0.         0.18901764 0.         0.42116296\n",
      "  0.         0.80866313 0.8688668  0.16943713 0.38769972 0.\n",
      "  0.         0.         0.         0.53412175 0.         0.\n",
      "  0.         1.1838269  1.3482877  0.7050265 ]]\n",
      "Hi!\n",
      "[[0.41256234 0.53061426 1.3509955  0.         0.         0.767713\n",
      "  0.         0.00990436 0.11553644 0.         0.4269132  0.\n",
      "  0.56003493 0.         0.         0.         0.1152259  0.28984827\n",
      "  0.         0.7067495  0.6847312  0.         0.         0.07906412\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05997371 0.67615217 0.11194491 0.         0.         0.\n",
      "  0.         0.09249165 0.19831221 0.6341192  0.         0.\n",
      "  0.         0.         0.28053048 0.24677317 0.         0.56323636\n",
      "  0.6261904  0.5213724  0.13173197 0.46718526 0.6582324  0.8240858\n",
      "  0.         0.74869215 0.         0.         0.13023205 0.\n",
      "  0.1618622  0.20085731 0.6872922  0.1953013 ]]\n",
      "Hi!\n",
      "[[0.3533449  0.46662936 0.4622662  0.         0.         0.39511102\n",
      "  0.5725203  0.80260646 0.67713237 0.         0.42520186 0.\n",
      "  1.0981456  0.26923767 0.         0.6490634  0.         0.68491054\n",
      "  0.36029202 0.18977249 0.58186305 0.         0.         0.\n",
      "  0.1950643  0.         0.         0.32896262 0.         0.\n",
      "  0.91805965 0.48002666 0.         0.         0.547664   0.\n",
      "  0.3321166  1.0377011  0.         0.36613408 0.         0.\n",
      "  0.         0.27869606 0.6908682  0.52784663 0.         0.5861922\n",
      "  0.         0.70516896 0.69381887 0.3248377  0.45188704 0.53463846\n",
      "  0.         0.         0.25563684 0.         0.         0.\n",
      "  0.         0.6126719  0.85400033 0.28997308]]\n",
      "Hi!\n",
      "[[0.65448815 0.1644428  0.         0.58204234 0.         0.5386624\n",
      "  1.2146125  1.9324868  0.28386265 0.         0.17981353 0.\n",
      "  1.2633402  0.9848456  0.         0.37268227 0.         0.43390074\n",
      "  0.35027128 0.09395479 0.39232567 0.34844065 0.         0.12748471\n",
      "  0.08953544 0.         0.         1.0737946  0.         0.\n",
      "  1.7911333  0.9398226  0.21817504 0.         0.9967239  0.\n",
      "  0.20203088 1.1541562  0.4672903  0.08409168 0.34157443 0.\n",
      "  0.         0.5282539  1.5864992  1.4301344  0.         0.3653087\n",
      "  0.         0.88099235 0.51183945 0.7079903  1.1425017  1.0966867\n",
      "  0.         0.         0.6494519  0.         0.         0.\n",
      "  0.         0.33941194 1.3377824  0.        ]]\n",
      "Hi!\n",
      "[[0.05275213 0.33295715 0.3382402  0.         0.         0.25435913\n",
      "  0.         0.24273598 0.         0.06237462 0.18345699 0.\n",
      "  0.         0.10005599 0.         0.         0.         0.23650208\n",
      "  0.         0.41431305 0.13778245 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01783941 0.23205008 0.0737083  0.         0.         0.\n",
      "  0.         0.         0.17274691 0.13947637 0.         0.\n",
      "  0.         0.         0.26109713 0.45134574 0.         0.\n",
      "  0.33641276 0.33850384 0.         0.25691772 0.26591    0.5004576\n",
      "  0.         0.34664103 0.         0.         0.         0.\n",
      "  0.17558911 0.26894945 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3630131  0.23586027 0.13911866 0.05483844 0.         0.44340792\n",
      "  1.1408938  1.3465087  0.6556527  0.         0.3005301  0.\n",
      "  1.1296344  0.50174606 0.         0.6685093  0.         0.7059357\n",
      "  0.43982285 0.         0.46864894 0.15901592 0.         0.\n",
      "  0.370819   0.         0.         0.57430524 0.         0.\n",
      "  1.214296   0.52233005 0.         0.         0.8338064  0.\n",
      "  0.43385342 1.3222768  0.         0.22545385 0.10720152 0.\n",
      "  0.         0.46451056 0.9862282  0.860897   0.         0.5864748\n",
      "  0.         0.75573784 0.77465886 0.4593605  0.509651   0.6695324\n",
      "  0.         0.         0.43444538 0.         0.         0.\n",
      "  0.         0.6280707  1.0014459  0.080982  ]]\n",
      "Hi!\n",
      "[[0.501888   0.11880801 1.2804152  0.         0.         0.8596675\n",
      "  0.5518377  0.57528806 1.1159693  0.         0.6170074  0.\n",
      "  0.582025   0.         0.         0.7299121  0.24232565 0.8901769\n",
      "  0.35217422 0.         1.1399652  0.18838778 0.         0.24799277\n",
      "  0.19447906 0.         0.         0.         0.         0.\n",
      "  0.2598547  0.28440824 0.         0.         0.28677768 0.\n",
      "  0.33332184 1.1517025  0.         0.7053625  0.12040243 0.\n",
      "  0.         0.892844   0.08823743 0.19042766 0.         0.84514916\n",
      "  0.         0.710117   0.69284946 0.19474095 0.21407312 0.3000475\n",
      "  0.         0.         0.07333447 0.42287397 0.         0.\n",
      "  0.         0.935323   1.2582774  0.7350826 ]]\n",
      "Hi!\n",
      "[[0.55662954 0.         0.47359258 0.3654569  0.         0.8869962\n",
      "  1.2048501  1.2202569  0.         0.07384809 0.22024913 0.\n",
      "  0.         0.         0.         0.09179629 0.         0.4759623\n",
      "  0.         0.24984154 0.4043453  0.         0.         0.12860969\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.42891428 0.42212093 0.24795352 0.         0.16957203 0.\n",
      "  0.         0.4906049  0.         0.6285308  0.02778099 0.\n",
      "  0.         0.5835482  0.49638632 1.003833   0.         0.\n",
      "  0.14654072 1.0614806  0.         0.56126535 0.8384172  0.34912682\n",
      "  0.         0.8694091  0.         0.         0.         0.\n",
      "  0.12711875 0.7158822  0.41814238 0.        ]]\n",
      "Hi!\n",
      "[[0.08981799 0.43985724 0.4671976  0.         0.         0.20740426\n",
      "  0.         0.         0.18928692 0.         0.24934237 0.\n",
      "  0.44188654 0.0824917  0.         0.12398856 0.         0.08431594\n",
      "  0.         0.33560017 0.27238312 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17283422 0.27570066 0.         0.         0.         0.\n",
      "  0.         0.         0.25088975 0.15375412 0.         0.\n",
      "  0.         0.         0.14021309 0.06077966 0.         0.23963414\n",
      "  0.30358154 0.23273002 0.08861876 0.23177081 0.19296615 0.5444152\n",
      "  0.         0.04381916 0.084872   0.         0.08613555 0.\n",
      "  0.08731779 0.09680574 0.04951553 0.08436741]]\n",
      "Hi!\n",
      "[[0.5960574  0.919535   0.7204967  0.         0.         0.63548595\n",
      "  0.01776428 0.6732139  0.446792   0.         0.47538596 0.\n",
      "  1.5641283  0.4172678  0.         0.31812164 0.         0.49617583\n",
      "  0.3750727  0.59767216 0.60570204 0.         0.         0.19567744\n",
      "  0.         0.         0.         0.4307039  0.         0.\n",
      "  1.083078   0.88015825 0.         0.         0.36823612 0.\n",
      "  0.14670055 0.6867029  0.37513342 0.31924197 0.         0.\n",
      "  0.         0.22175996 0.9680234  0.6418658  0.         0.71882606\n",
      "  0.13404755 0.7847586  0.5550628  0.53914285 0.838997   1.0811185\n",
      "  0.         0.03523055 0.3159584  0.         0.00868224 0.\n",
      "  0.         0.20933524 1.0073401  0.20290165]]\n",
      "Hi!\n",
      "[[0.43361756 0.05677228 0.         0.32363215 0.         0.45874017\n",
      "  1.3765423  1.3522973  0.         0.         0.05022126 0.\n",
      "  0.22429617 0.495753   0.         0.15674476 0.         0.47260943\n",
      "  0.         0.22317328 0.11713446 0.06597997 0.         0.\n",
      "  0.08449079 0.         0.         0.4619353  0.         0.\n",
      "  1.0685505  0.5125035  0.3027772  0.         0.5059771  0.\n",
      "  0.05482483 0.94211596 0.05099551 0.2951955  0.09470834 0.\n",
      "  0.         0.25214338 1.0903366  1.2207403  0.         0.06954154\n",
      "  0.         0.9047413  0.17544512 0.53374565 0.4826565  0.7866743\n",
      "  0.         0.12831755 0.31463212 0.         0.         0.\n",
      "  0.         0.5592897  0.42886087 0.        ]]\n",
      "Hi!\n",
      "[[0.45375925 0.5368245  1.3123678  0.         0.         0.8837274\n",
      "  0.22128198 0.2451151  0.9997395  0.         0.63064605 0.\n",
      "  0.95309    0.         0.         0.5444407  0.09677147 0.75308424\n",
      "  0.32347038 0.25679544 1.127741   0.         0.         0.24950573\n",
      "  0.0654943  0.         0.         0.         0.         0.\n",
      "  0.27239245 0.44873866 0.         0.         0.06660637 0.\n",
      "  0.09136348 0.74106246 0.         0.7869025  0.         0.\n",
      "  0.         0.3541128  0.16292186 0.11280654 0.         0.8196236\n",
      "  0.0322378  0.76263577 0.64804286 0.3364606  0.5245994  0.44645298\n",
      "  0.         0.12549812 0.         0.16897105 0.06013167 0.\n",
      "  0.         0.67056924 0.94619495 0.86153054]]\n",
      "Hi!\n",
      "[[0.64740753 0.4371228  1.361503   0.         0.         0.8942905\n",
      "  0.15882482 0.2023021  0.84656835 0.00193109 0.6114264  0.\n",
      "  0.44966954 0.         0.         0.40738553 0.3323913  0.7116868\n",
      "  0.         0.30818528 1.0981218  0.06321904 0.         0.4488089\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01491685 0.30803853 0.01297036 0.         0.         0.\n",
      "  0.         0.52221334 0.         0.77721804 0.         0.\n",
      "  0.         0.55127686 0.         0.17494208 0.         0.53821564\n",
      "  0.12754144 0.8809685  0.4550546  0.22707942 0.47498468 0.28373393\n",
      "  0.         0.4208804  0.         0.21321473 0.0761174  0.\n",
      "  0.         0.6991623  0.72157276 0.6776436 ]]\n",
      "Hi!\n",
      "[[0.5306846  0.         0.7790803  0.         0.         0.6050911\n",
      "  0.69832206 0.6412069  0.59178144 0.07226016 0.36901453 0.\n",
      "  0.         0.         0.         0.30818993 0.3083268  0.732748\n",
      "  0.         0.03476388 0.6627024  0.27260315 0.         0.15897518\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13010953 0.         0.00647504 0.\n",
      "  0.         0.5583805  0.         0.67454165 0.         0.\n",
      "  0.         0.9933615  0.         0.33399987 0.         0.\n",
      "  0.         0.8746062  0.29690188 0.04472556 0.09334042 0.\n",
      "  0.         0.3238968  0.         0.10556672 0.         0.\n",
      "  0.09625631 0.96868193 0.16891344 0.25795498]]\n",
      "Hi!\n",
      "[[0.         0.13971858 0.04549259 0.         0.         0.11158752\n",
      "  0.27238804 0.31989354 0.11745175 0.1642822  0.15070762 0.\n",
      "  0.         0.00502004 0.         0.01616872 0.         0.18301149\n",
      "  0.         0.18198119 0.17000934 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11431536 0.         0.         0.\n",
      "  0.         0.01801507 0.         0.31448445 0.         0.\n",
      "  0.         0.06973233 0.04732598 0.38950452 0.         0.\n",
      "  0.03600698 0.30959293 0.08983149 0.1256178  0.10406813 0.12995507\n",
      "  0.         0.08985155 0.         0.         0.         0.\n",
      "  0.01531078 0.33576775 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.8569556  0.29961473 1.7733552  0.         0.         1.0789835\n",
      "  0.1619238  0.23821749 1.0726959  0.         0.71747005 0.\n",
      "  0.46808645 0.         0.         0.58362037 0.54090655 0.84058857\n",
      "  0.00288082 0.2401359  1.3462057  0.11787055 0.         0.5272072\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3448694  0.02046521 0.         0.         0.\n",
      "  0.11353046 0.76773137 0.         0.93391585 0.         0.\n",
      "  0.         0.78774685 0.         0.16973136 0.         0.8491457\n",
      "  0.17649558 0.7901876  0.55052334 0.2531654  0.43054834 0.3628401\n",
      "  0.         0.63268447 0.         0.5161417  0.08241357 0.\n",
      "  0.         0.80124074 1.1271055  0.8722051 ]]\n",
      "Hi!\n",
      "[[0.06254239 0.16079491 0.21640079 0.         0.         0.28594875\n",
      "  0.00915989 0.19691628 0.         0.09065121 0.1101223  0.\n",
      "  0.02269758 0.16953096 0.         0.         0.         0.0111922\n",
      "  0.         0.26117843 0.07159936 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02063125 0.21901576 0.1193355  0.         0.         0.\n",
      "  0.         0.         0.15798055 0.1653277  0.         0.\n",
      "  0.         0.         0.28919202 0.3589433  0.         0.07149666\n",
      "  0.26981646 0.24990618 0.         0.25003746 0.27539578 0.36991113\n",
      "  0.         0.30547062 0.         0.         0.         0.\n",
      "  0.1295788  0.10204912 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.735003   0.         0.84863085 0.24526511 0.         1.0716435\n",
      "  0.7803784  1.022227   0.30887777 0.13870847 0.32958037 0.\n",
      "  0.         0.         0.         0.12844461 0.0779235  0.5731241\n",
      "  0.         0.23686466 0.6779813  0.         0.         0.49493727\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15931058 0.27883285 0.2841914  0.         0.         0.\n",
      "  0.         0.40271816 0.         0.8939317  0.         0.\n",
      "  0.         0.7885059  0.02396464 0.95905715 0.         0.\n",
      "  0.27964762 1.3420922  0.03500724 0.45465568 1.0398867  0.05203896\n",
      "  0.         1.0656278  0.         0.         0.         0.\n",
      "  0.19643967 0.8769016  0.43558446 0.        ]]\n",
      "Hi!\n",
      "[[0.5217367  0.         0.         0.4680025  0.         0.58519524\n",
      "  1.7374483  1.8728684  0.13587652 0.         0.07900175 0.\n",
      "  0.57395834 0.5411389  0.         0.39984024 0.         0.5909262\n",
      "  0.         0.         0.21334541 0.33984432 0.         0.\n",
      "  0.28166497 0.         0.         0.69077736 0.         0.\n",
      "  1.3498201  0.5756575  0.29681516 0.         0.839155   0.\n",
      "  0.37635893 1.3489629  0.1356338  0.19333754 0.23837559 0.\n",
      "  0.         0.597949   1.2907687  1.3917556  0.         0.3356991\n",
      "  0.         0.8776575  0.38827312 0.6212557  0.5867372  0.89682734\n",
      "  0.         0.         0.4804889  0.         0.         0.\n",
      "  0.         0.60510623 0.9713453  0.        ]]\n",
      "Hi!\n",
      "[[0.37526459 0.37532    0.97252524 0.         0.         0.6996285\n",
      "  0.56579137 0.77745515 1.1598929  0.         0.5431915  0.\n",
      "  1.1604338  0.         0.         0.7995289  0.         0.81751925\n",
      "  0.82612836 0.         0.9360773  0.02883887 0.         0.\n",
      "  0.36789307 0.         0.         0.32398883 0.         0.\n",
      "  0.7473876  0.4665025  0.         0.         0.5602905  0.\n",
      "  0.54939246 1.3121364  0.         0.54137874 0.17238447 0.\n",
      "  0.         0.6573104  0.44343033 0.30923703 0.         0.9535472\n",
      "  0.         0.72910064 0.9444328  0.37538067 0.2934235  0.5546317\n",
      "  0.         0.         0.30266437 0.12130941 0.         0.\n",
      "  0.         0.74924326 1.4050957  0.7449452 ]]\n",
      "Hi!\n",
      "[[1.074164   0.         1.5828456  0.11321074 0.         1.2124426\n",
      "  0.64317    0.83261216 0.6998639  0.         0.5582597  0.\n",
      "  0.         0.         0.         0.2935653  0.6875817  0.6708838\n",
      "  0.         0.14546636 1.1927398  0.17125344 0.         0.596478\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28310975 0.13754018 0.         0.         0.\n",
      "  0.         0.60954875 0.         0.89942604 0.         0.\n",
      "  0.         1.1552656  0.         0.43333447 0.         0.179053\n",
      "  0.16597496 0.99648464 0.22705373 0.3110859  0.78555673 0.12016967\n",
      "  0.         1.2904844  0.         0.21652824 0.         0.\n",
      "  0.20980588 0.8597411  1.0303681  0.18329011]]\n",
      "Hi!\n",
      "[[0.28933477 0.38379285 0.58706665 0.         0.         0.604033\n",
      "  0.         0.11956958 0.03133839 0.1437157  0.23892611 0.\n",
      "  0.         0.         0.         0.         0.         0.16937473\n",
      "  0.         0.62452334 0.26330218 0.         0.         0.00824753\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21933037 0.09645062 0.         0.         0.\n",
      "  0.         0.00975066 0.         0.3599383  0.         0.\n",
      "  0.         0.         0.19893989 0.57932764 0.         0.29311985\n",
      "  0.4887512  0.54048276 0.         0.39479262 0.41588292 0.5295154\n",
      "  0.         0.71495414 0.         0.         0.062801   0.\n",
      "  0.27852443 0.20203441 0.01367186 0.0550226 ]]\n",
      "Hi!\n",
      "[[0.72077173 0.5822931  0.47319654 0.27725053 0.         0.71613485\n",
      "  0.4362756  1.1814231  0.1723913  0.         0.334247   0.\n",
      "  1.3331046  0.7196221  0.         0.17411248 0.         0.36825296\n",
      "  0.2740146  0.5291789  0.49003282 0.01821653 0.         0.23034583\n",
      "  0.         0.         0.         0.76616544 0.         0.\n",
      "  1.3306937  1.0766412  0.04570077 0.         0.5071759  0.\n",
      "  0.24151386 0.77739936 0.5579604  0.10718558 0.08833665 0.\n",
      "  0.         0.3277106  1.3713193  1.0724757  0.         0.57726556\n",
      "  0.20487295 0.79839057 0.32692045 0.706802   0.9168551  1.2270911\n",
      "  0.         0.24911219 0.50203127 0.         0.         0.\n",
      "  0.         0.17629504 1.1689352  0.        ]]\n",
      "Hi!\n",
      "[[0.45339602 0.         0.6886111  0.13834773 0.         0.56126106\n",
      "  1.5671614  1.4445984  1.0366504  0.         0.3824368  0.\n",
      "  0.         0.         0.         0.7365318  0.13480854 0.8259134\n",
      "  0.         0.         0.79802984 0.28311053 0.         0.18399942\n",
      "  0.11662125 0.         0.         0.06893987 0.         0.\n",
      "  0.47532594 0.04235834 0.01773539 0.         0.5955566  0.\n",
      "  0.11717132 1.3760555  0.         0.6825662  0.23422746 0.\n",
      "  0.         1.4055603  0.03040808 0.5231525  0.         0.15358141\n",
      "  0.         0.793295   0.6220076  0.20657702 0.37599504 0.\n",
      "  0.         0.         0.04228574 0.18421501 0.         0.\n",
      "  0.         1.2046584  1.1193918  0.20384392]]\n",
      "Hi!\n",
      "[[0.27162904 0.         0.5842423  0.02484575 0.         0.7891404\n",
      "  1.8737105  1.5660888  0.9622041  0.         0.31549692 0.\n",
      "  0.24256475 0.         0.         0.78830636 0.         0.9745914\n",
      "  0.2577984  0.         0.72645366 0.30064934 0.         0.\n",
      "  0.40491456 0.         0.         0.3960522  0.         0.\n",
      "  0.7747756  0.12491685 0.         0.         0.9139957  0.\n",
      "  0.6421232  1.6285616  0.         0.36380762 0.34210405 0.\n",
      "  0.         1.3782114  0.5316564  0.67952675 0.         0.66513777\n",
      "  0.         0.67831975 0.61819285 0.3346286  0.15292628 0.35598016\n",
      "  0.         0.         0.3995896  0.13776992 0.         0.\n",
      "  0.         1.0552919  1.3159361  0.24605139]]\n",
      "Hi!\n",
      "[[1.2062795  0.44435093 2.281945   0.         0.         1.255086\n",
      "  0.         0.         1.0233756  0.         0.8169152  0.\n",
      "  0.09722165 0.         0.         0.5061599  1.0363938  0.82936156\n",
      "  0.         0.58094645 1.5165265  0.28764293 0.         0.64619476\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2457579  0.04468539 0.         0.         0.\n",
      "  0.         0.47268185 0.         1.1830456  0.         0.\n",
      "  0.         1.0049903  0.         0.20460966 0.         0.7598679\n",
      "  0.39756924 0.98394525 0.5405     0.15670067 0.57867664 0.31778684\n",
      "  0.         1.1224531  0.         0.7366943  0.18335117 0.\n",
      "  0.32578322 0.76093805 0.8961628  0.95483476]]\n",
      "Hi!\n",
      "[[0.37766454 0.22243907 0.05868943 0.07356447 0.         0.20240217\n",
      "  0.8048091  0.7324686  0.1344144  0.         0.         0.\n",
      "  0.28731784 0.1614986  0.         0.28483573 0.         0.28971177\n",
      "  0.         0.21976297 0.0112742  0.         0.         0.\n",
      "  0.09015481 0.         0.         0.39605153 0.         0.\n",
      "  0.6473359  0.34199652 0.23005262 0.         0.3251404  0.\n",
      "  0.15994936 0.7176783  0.29087597 0.10622577 0.         0.\n",
      "  0.         0.22535251 0.65055794 0.8321372  0.         0.3208817\n",
      "  0.06170922 0.50926495 0.21776628 0.3265898  0.13487683 0.8464129\n",
      "  0.         0.21642715 0.27934268 0.         0.         0.\n",
      "  0.         0.27525428 0.34637696 0.        ]]\n",
      "Hi!\n",
      "[[0.4126564  0.         0.42766812 0.36934832 0.         0.8346956\n",
      "  1.4171059  1.3703963  0.03784039 0.         0.19257775 0.\n",
      "  0.         0.         0.         0.15798563 0.         0.5538658\n",
      "  0.         0.17891884 0.43382677 0.02722812 0.         0.\n",
      "  0.         0.         0.         0.17484055 0.         0.\n",
      "  0.7219553  0.48623303 0.12896104 0.         0.45103702 0.\n",
      "  0.         0.9271037  0.         0.400305   0.12152204 0.\n",
      "  0.         0.47954795 0.8279092  1.110159   0.         0.15749747\n",
      "  0.03857494 0.8546547  0.06962423 0.55165154 0.6055658  0.54330885\n",
      "  0.         0.51839167 0.161477   0.         0.         0.\n",
      "  0.         0.7527854  0.75979954 0.        ]]\n",
      "Hi!\n",
      "[[0.53595096 0.63926476 0.54740477 0.         0.         0.34684357\n",
      "  0.6584104  1.0236167  1.3451232  0.         0.5391432  0.\n",
      "  2.1143994  0.45117718 0.         1.1146674  0.         0.80689675\n",
      "  1.5367625  0.         0.854534   0.18980667 0.         0.05872212\n",
      "  0.5429929  0.         0.         0.83924294 0.         0.\n",
      "  1.271028   0.71421504 0.         0.         0.8341756  0.\n",
      "  1.0641603  1.438946   0.         0.3924422  0.19646199 0.\n",
      "  0.         0.51562095 0.9508946  0.3144281  0.         1.2568867\n",
      "  0.         0.8708911  1.3615038  0.29211143 0.32770666 0.85359937\n",
      "  0.         0.         0.58991504 0.         0.         0.\n",
      "  0.         0.5466331  1.5139256  0.6730253 ]]\n",
      "Hi!\n",
      "[[0.921634   0.07090462 1.5600783  0.         0.         0.9258054\n",
      "  0.38542852 0.5201909  1.0112672  0.00939433 0.61667997 0.\n",
      "  0.         0.         0.         0.44323298 0.5774406  0.8170975\n",
      "  0.         0.0732012  1.2141699  0.21488068 0.         0.5931115\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13418111 0.09996872 0.         0.         0.\n",
      "  0.         0.73543847 0.         0.8477066  0.         0.\n",
      "  0.         1.045444   0.         0.25744164 0.         0.42853054\n",
      "  0.03072105 0.87858415 0.48622787 0.20045441 0.48539063 0.09231649\n",
      "  0.         0.68367904 0.         0.4245325  0.         0.\n",
      "  0.00255751 0.9426368  0.87676257 0.6447159 ]]\n",
      "Hi!\n",
      "[[0.29011998 0.         0.6119244  0.11985209 0.         0.6884841\n",
      "  0.95484257 1.2620518  0.6494504  0.         0.37628266 0.\n",
      "  0.50015575 0.         0.         0.5036352  0.         0.6105698\n",
      "  0.         0.         0.704      0.         0.         0.01468421\n",
      "  0.         0.         0.         0.42829934 0.         0.\n",
      "  0.89425206 0.4831295  0.02554987 0.         0.5144881  0.\n",
      "  0.         1.0446364  0.         0.3355923  0.09735739 0.\n",
      "  0.         0.630808   0.5603135  0.8038403  0.         0.20313627\n",
      "  0.         0.8184277  0.38601846 0.48043793 0.69665116 0.23781595\n",
      "  0.         0.         0.16096495 0.         0.         0.\n",
      "  0.         0.7457729  1.1985615  0.        ]]\n",
      "Hi!\n",
      "[[0.42222875 0.10451351 1.3214581  0.         0.         0.7068721\n",
      "  0.51362133 0.56311727 1.4784745  0.         0.684833   0.\n",
      "  0.77049524 0.         0.         1.0145977  0.25445336 0.9160572\n",
      "  0.6383063  0.         1.2482951  0.28876102 0.         0.27488735\n",
      "  0.2586558  0.         0.         0.02094476 0.         0.\n",
      "  0.29048234 0.24479106 0.         0.         0.30516607 0.\n",
      "  0.5644528  1.2286733  0.         0.77886975 0.23685    0.\n",
      "  0.         1.0928137  0.         0.03426205 0.         0.89193416\n",
      "  0.         0.84574264 0.9701309  0.15325005 0.25870395 0.11899305\n",
      "  0.         0.         0.0614701  0.63392705 0.         0.\n",
      "  0.         0.9867755  1.3499314  0.97801167]]\n",
      "Hi!\n",
      "[[0.62799644 0.59181684 1.2941381  0.         0.         1.013655\n",
      "  0.         0.         0.39183024 0.18990807 0.5194738  0.\n",
      "  0.07486447 0.         0.         0.         0.31063774 0.25769693\n",
      "  0.         0.8907914  0.6558559  0.         0.         0.27916512\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25265568 0.16092892 0.         0.         0.\n",
      "  0.         0.07237779 0.         0.5855809  0.         0.\n",
      "  0.         0.         0.06547111 0.3484845  0.         0.560577\n",
      "  0.56031567 0.71265393 0.04990257 0.49764875 0.6575642  0.52254915\n",
      "  0.         1.0304649  0.         0.         0.21216615 0.\n",
      "  0.39360765 0.3441467  0.40576243 0.4225348 ]]\n",
      "Hi!\n",
      "[[0.58269465 0.18717702 0.5961317  0.29463148 0.         0.92952\n",
      "  0.7977281  1.2018956  0.07958049 0.         0.3113732  0.\n",
      "  0.6864867  0.3074572  0.         0.08538321 0.         0.40126458\n",
      "  0.         0.46365607 0.55325425 0.         0.         0.06133067\n",
      "  0.         0.         0.         0.50628823 0.         0.\n",
      "  1.0514549  0.85950005 0.01089489 0.         0.46933395 0.\n",
      "  0.         0.7575812  0.16990764 0.1984408  0.1189017  0.\n",
      "  0.         0.17527185 1.1183659  1.111587   0.         0.38284388\n",
      "  0.22889102 0.83089757 0.125275   0.71191156 0.98711354 0.88870174\n",
      "  0.         0.59984344 0.30205446 0.         0.         0.\n",
      "  0.         0.26958907 1.1672444  0.        ]]\n",
      "Hi!\n",
      "[[0.25400904 0.         0.27655295 0.20584618 0.         0.571293\n",
      "  1.6638021  1.79662    0.87826234 0.         0.32559457 0.\n",
      "  0.6158099  0.06136721 0.         0.7792197  0.         0.73520356\n",
      "  0.28653726 0.         0.6018499  0.24748512 0.         0.\n",
      "  0.2880304  0.         0.         0.6385293  0.         0.\n",
      "  1.1942952  0.33798897 0.         0.         0.9157326  0.\n",
      "  0.3625527  1.5430944  0.         0.30227938 0.33255807 0.\n",
      "  0.         1.0159222  0.75837165 0.975799   0.         0.29119122\n",
      "  0.         0.7598573  0.72796005 0.47346506 0.6096184  0.28764054\n",
      "  0.         0.         0.4301723  0.         0.         0.\n",
      "  0.         0.85749084 1.4876747  0.01365503]]\n",
      "Hi!\n",
      "[[0.81818026 0.         1.27659    0.05662712 0.         0.88956267\n",
      "  0.6094262  0.72198486 0.7475319  0.05964215 0.509424   0.\n",
      "  0.         0.         0.         0.30081046 0.42200664 0.75367916\n",
      "  0.         0.09357227 1.0230234  0.135312   0.         0.50005496\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11060147 0.17034656 0.         0.         0.\n",
      "  0.         0.629615   0.         0.7938035  0.         0.\n",
      "  0.         0.9802415  0.         0.45776504 0.         0.11230359\n",
      "  0.02516163 0.9837675  0.27199283 0.24554695 0.6334599  0.\n",
      "  0.         0.7761033  0.         0.16366167 0.         0.\n",
      "  0.09865978 0.9667885  0.7478041  0.27793986]]\n",
      "Hi!\n",
      "[[0.14532721 0.539407   0.50514877 0.         0.         0.61337477\n",
      "  0.40749282 0.5998166  0.24725167 0.04311392 0.3244203  0.\n",
      "  0.068098   0.         0.         0.04034704 0.         0.40113157\n",
      "  0.         0.4870544  0.47596303 0.         0.         0.18454662\n",
      "  0.         0.         0.         0.04935748 0.         0.\n",
      "  0.19399564 0.23925102 0.05752914 0.         0.         0.\n",
      "  0.         0.06784361 0.         0.57136303 0.         0.\n",
      "  0.         0.24656366 0.15834989 0.68436944 0.         0.\n",
      "  0.15391287 0.900499   0.17945963 0.30768982 0.6148506  0.29408565\n",
      "  0.         0.18309921 0.         0.         0.         0.\n",
      "  0.04398747 0.6420398  0.         0.06184928]]\n",
      "Hi!\n",
      "[[0.5300541  0.5931852  0.7277006  0.         0.         0.69617903\n",
      "  0.05726002 0.24713643 0.11527187 0.         0.30779776 0.\n",
      "  0.8345696  0.18607378 0.         0.19102056 0.         0.4331442\n",
      "  0.         0.65460044 0.43275687 0.         0.         0.11247056\n",
      "  0.         0.         0.         0.15495867 0.         0.\n",
      "  0.5830213  0.6629973  0.         0.         0.13193087 0.\n",
      "  0.25423446 0.55606365 0.19533364 0.41848278 0.         0.\n",
      "  0.         0.13268194 0.761476   0.52975047 0.         0.8369664\n",
      "  0.364401   0.5040754  0.2047678  0.4275198  0.24722196 1.0266747\n",
      "  0.         0.33602828 0.21379767 0.         0.         0.\n",
      "  0.         0.14431952 0.6074146  0.13574788]]\n",
      "Hi!\n",
      "[[0.2599333  0.2837641  0.4978645  0.16777232 0.         0.78222007\n",
      "  0.6779875  1.0692753  0.11088811 0.         0.2749755  0.\n",
      "  0.23162633 0.30731732 0.         0.         0.         0.36772332\n",
      "  0.         0.47136328 0.445482   0.         0.         0.15377995\n",
      "  0.         0.         0.         0.20880833 0.         0.\n",
      "  0.8790768  0.51197916 0.13734362 0.         0.25394213 0.\n",
      "  0.         0.39823246 0.04046781 0.40381926 0.         0.\n",
      "  0.         0.16335411 0.6582779  1.1152996  0.         0.\n",
      "  0.17413568 1.0904301  0.01854403 0.64365906 1.173791   0.49072933\n",
      "  0.         0.5363606  0.         0.         0.         0.\n",
      "  0.         0.59264976 0.46523362 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.03945335 0.06159668 0.         0.         0.05210574\n",
      "  0.13491456 0.25381577 0.01427515 0.13360702 0.115933   0.\n",
      "  0.         0.04896548 0.         0.07699551 0.         0.01624505\n",
      "  0.         0.03250928 0.15137018 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16491713 0.         0.         0.\n",
      "  0.         0.         0.11841199 0.12044413 0.         0.\n",
      "  0.         0.         0.119441   0.3184894  0.         0.\n",
      "  0.116643   0.09116708 0.         0.20072404 0.04281016 0.16617048\n",
      "  0.         0.19035582 0.         0.         0.         0.\n",
      "  0.0540878  0.19628936 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.02227486 0.09535168 0.22994396 0.         0.         0.10531487\n",
      "  0.         0.08427142 0.06151794 0.06479879 0.11893602 0.\n",
      "  0.02091133 0.00701616 0.         0.04221484 0.         0.\n",
      "  0.         0.1568186  0.1654394  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06576913 0.10738426 0.         0.         0.\n",
      "  0.         0.         0.0652486  0.11073747 0.         0.\n",
      "  0.         0.         0.15338942 0.21277472 0.         0.14399174\n",
      "  0.09758063 0.00136137 0.         0.21581727 0.01241513 0.24379292\n",
      "  0.         0.0766449  0.         0.         0.00970363 0.\n",
      "  0.         0.         0.         0.03140926]]\n",
      "Hi!\n",
      "[[0.50654054 0.36921078 0.81331223 0.15179157 0.         0.9441127\n",
      "  0.13093098 0.5013628  0.         0.00497999 0.21817318 0.\n",
      "  0.06878165 0.11168222 0.         0.         0.         0.\n",
      "  0.         0.86054236 0.2797475  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.31465033 0.65985876 0.21149236 0.         0.         0.\n",
      "  0.         0.0158921  0.2497205  0.20946479 0.         0.\n",
      "  0.         0.01462182 0.7480655  0.9274011  0.         0.40669388\n",
      "  0.71389663 0.6414742  0.         0.6899357  0.7701898  0.9721929\n",
      "  0.         1.2459695  0.01859434 0.         0.06151412 0.\n",
      "  0.14899927 0.         0.5258286  0.        ]]\n",
      "Hi!\n",
      "[[0.50599504 0.7631391  0.6324476  0.         0.         0.4358013\n",
      "  0.3293315  0.8819442  1.1017106  0.         0.50995415 0.\n",
      "  1.9778714  0.38378808 0.         0.9183412  0.         0.7080153\n",
      "  1.27121    0.12479502 0.7972057  0.0520582  0.         0.\n",
      "  0.42024526 0.         0.         0.6029115  0.         0.\n",
      "  1.1655757  0.6999771  0.         0.         0.637555   0.\n",
      "  0.69973403 1.2562394  0.         0.42927012 0.11414158 0.\n",
      "  0.         0.393051   0.8921452  0.37835634 0.         1.1052946\n",
      "  0.         0.8826342  1.162469   0.4073519  0.45148674 0.919946\n",
      "  0.         0.         0.46654987 0.         0.         0.\n",
      "  0.         0.48937452 1.3269829  0.65899783]]\n",
      "Hi!\n",
      "[[0.7308676  0.         0.9414247  0.2802952  0.         0.92856294\n",
      "  1.110702   1.2403125  0.6935015  0.08415772 0.38721097 0.\n",
      "  0.         0.         0.         0.28846776 0.25218365 0.69353086\n",
      "  0.         0.         0.81078476 0.06792696 0.         0.5364798\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19941005 0.1719182  0.25477806 0.         0.08295001 0.\n",
      "  0.         0.73603684 0.         0.85784864 0.0356262  0.\n",
      "  0.         1.1374557  0.         0.74652845 0.         0.\n",
      "  0.         1.1448212  0.2381778  0.35169578 0.8604843  0.\n",
      "  0.         0.8044898  0.         0.         0.         0.\n",
      "  0.         1.0528619  0.8406443  0.        ]]\n",
      "Hi!\n",
      "[[0.9060483  0.15575428 1.4117736  0.         0.         1.0628673\n",
      "  0.21564654 0.42150322 0.6246856  0.13021223 0.54582417 0.\n",
      "  0.         0.         0.         0.16071124 0.524686   0.6067584\n",
      "  0.         0.416881   0.9464577  0.         0.         0.45891923\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2151603  0.12670779 0.         0.         0.\n",
      "  0.         0.33329028 0.         0.74474186 0.         0.\n",
      "  0.         0.72431517 0.         0.44615227 0.         0.34149736\n",
      "  0.3218741  0.977267   0.24411404 0.30367997 0.65051395 0.24917252\n",
      "  0.         1.0956365  0.         0.09755732 0.07232985 0.\n",
      "  0.29842937 0.73897535 0.48679563 0.3400542 ]]\n",
      "Hi!\n",
      "[[0.0376091  0.23013107 0.10040399 0.         0.         0.05864064\n",
      "  0.21432886 0.1711597  0.08492706 0.12889269 0.15415166 0.\n",
      "  0.07066734 0.03400281 0.         0.06262975 0.         0.1288872\n",
      "  0.         0.10247994 0.11928317 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02963936 0.03957784 0.04078486 0.         0.         0.\n",
      "  0.         0.         0.05867947 0.1682918  0.         0.\n",
      "  0.         0.         0.17244077 0.30730596 0.         0.\n",
      "  0.04213964 0.07502796 0.11702273 0.06871522 0.06723434 0.23392777\n",
      "  0.         0.05985549 0.11207893 0.         0.03878338 0.\n",
      "  0.12524253 0.15202415 0.         0.02388068]]\n",
      "Hi!\n",
      "[[0.22848623 0.         0.74351597 0.         0.         0.43222037\n",
      "  1.0693841  1.1795812  1.2568868  0.         0.50738555 0.\n",
      "  0.5083621  0.         0.         0.8444847  0.         0.881058\n",
      "  0.17833705 0.         0.84941936 0.09647688 0.         0.16289704\n",
      "  0.13368979 0.         0.         0.30927834 0.         0.\n",
      "  0.73648405 0.15432867 0.         0.         0.5436109  0.\n",
      "  0.25643632 1.2815065  0.         0.50321084 0.23540996 0.\n",
      "  0.         1.1327453  0.12203019 0.46855617 0.         0.23895527\n",
      "  0.         0.8571932  0.8647922  0.24718754 0.5594121  0.\n",
      "  0.         0.         0.0711358  0.12547469 0.         0.\n",
      "  0.         1.0385023  1.1666846  0.51201427]]\n",
      "Hi!\n",
      "[[0.50736195 0.2677349  0.922337   0.08705951 0.         0.8934665\n",
      "  0.5086338  0.76773804 0.24368623 0.         0.44236225 0.\n",
      "  0.6351804  0.         0.         0.22615351 0.         0.5332327\n",
      "  0.         0.5076515  0.69604707 0.         0.         0.08768516\n",
      "  0.         0.         0.         0.3119269  0.         0.\n",
      "  0.74776965 0.84886044 0.03945711 0.         0.29032087 0.\n",
      "  0.07603252 0.6971681  0.02983156 0.43249267 0.         0.\n",
      "  0.         0.14238478 0.81816524 0.81236076 0.         0.5057861\n",
      "  0.1984189  0.7158503  0.16515428 0.50133497 0.71586156 0.7429848\n",
      "  0.         0.5119839  0.24854939 0.         0.         0.\n",
      "  0.         0.3595619  1.1278207  0.        ]]\n",
      "Hi!\n",
      "[[0.3604646  0.         0.27414107 0.38888374 0.         0.6778167\n",
      "  1.3546596  1.4936517  0.24278943 0.         0.24332014 0.\n",
      "  0.         0.         0.         0.23638548 0.         0.57101303\n",
      "  0.         0.         0.40058908 0.         0.         0.05243359\n",
      "  0.         0.         0.         0.18619211 0.         0.\n",
      "  0.7306581  0.26997718 0.20451908 0.         0.42650494 0.\n",
      "  0.         0.75617224 0.         0.54711676 0.11221596 0.\n",
      "  0.         0.86932176 0.4219398  1.0569017  0.         0.\n",
      "  0.         1.1773367  0.10083512 0.45659503 0.871017   0.\n",
      "  0.         0.35616773 0.         0.         0.         0.\n",
      "  0.         0.8713783  0.53570366 0.        ]]\n",
      "Hi!\n",
      "[[0.21227698 0.39222237 0.21550386 0.12207842 0.         0.4213616\n",
      "  0.31658405 0.5685707  0.         0.03464075 0.1111109  0.\n",
      "  0.09564837 0.35534948 0.         0.         0.         0.22312729\n",
      "  0.         0.535053   0.08181739 0.         0.         0.07956152\n",
      "  0.         0.         0.         0.03454001 0.         0.\n",
      "  0.46322677 0.42729574 0.24013706 0.         0.02020453 0.\n",
      "  0.         0.06875727 0.21356152 0.20171045 0.         0.\n",
      "  0.         0.         0.64289427 0.8257214  0.         0.05412791\n",
      "  0.40229616 0.61199147 0.         0.4116081  0.46433932 0.6092909\n",
      "  0.         0.4309842  0.07795172 0.         0.         0.\n",
      "  0.14650027 0.32729596 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0638157  0.         1.4435707  0.2525523  0.         1.4021705\n",
      "  0.67904234 0.8742601  0.3528228  0.05462825 0.45569602 0.\n",
      "  0.         0.         0.         0.08364914 0.5163778  0.52477795\n",
      "  0.         0.43858728 0.9618013  0.0025888  0.         0.44012636\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40950763 0.17784125 0.         0.         0.\n",
      "  0.         0.41633278 0.         0.9026267  0.         0.\n",
      "  0.         0.8872357  0.12713873 0.687215   0.         0.26722467\n",
      "  0.3792631  1.0792906  0.04857323 0.47819808 0.8698649  0.48175725\n",
      "  0.         1.6096861  0.         0.         0.         0.\n",
      "  0.47972873 0.63327265 0.867864   0.        ]]\n",
      "Hi!\n",
      "[[0.10444541 0.2407407  0.32455412 0.         0.         0.1607881\n",
      "  0.         0.         0.15594675 0.05273414 0.15590687 0.\n",
      "  0.17452033 0.         0.         0.11096855 0.         0.01037117\n",
      "  0.         0.22887619 0.17231038 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11575293 0.08153301 0.         0.         0.\n",
      "  0.         0.         0.03684536 0.12298824 0.         0.\n",
      "  0.         0.         0.00712145 0.09080038 0.         0.12504095\n",
      "  0.14522809 0.12687527 0.02224572 0.21964622 0.07725914 0.30776918\n",
      "  0.         0.01669709 0.         0.         0.07851367 0.\n",
      "  0.08750107 0.10261194 0.         0.06442466]]\n",
      "Hi!\n",
      "[[0.54044616 1.2117828  0.519927   0.         0.         0.47235042\n",
      "  0.         0.6186727  0.27079216 0.         0.44313908 0.\n",
      "  1.7126538  0.68211234 0.         0.26048312 0.         0.39554092\n",
      "  0.27589697 0.8069411  0.43821847 0.         0.         0.33647448\n",
      "  0.         0.         0.         0.42987788 0.         0.\n",
      "  1.1750696  0.88079166 0.         0.         0.30505028 0.\n",
      "  0.         0.42312887 0.6639451  0.22897989 0.         0.\n",
      "  0.         0.24357435 1.0325729  0.7367746  0.         0.6992864\n",
      "  0.30414906 0.7786671  0.49784425 0.5013494  0.872985   1.1951959\n",
      "  0.         0.         0.36357918 0.         0.         0.\n",
      "  0.         0.1423598  0.6365077  0.11038165]]\n",
      "Hi!\n",
      "[[0.03987304 0.17801794 0.06857143 0.         0.         0.06773379\n",
      "  0.         0.11939456 0.0364879  0.03565291 0.13190632 0.\n",
      "  0.20744798 0.09963863 0.         0.06069539 0.         0.01621756\n",
      "  0.         0.14160451 0.05742988 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02859906 0.12839966 0.09683684 0.         0.         0.\n",
      "  0.         0.         0.19618537 0.00653305 0.         0.\n",
      "  0.         0.         0.12572992 0.1945255  0.         0.0124821\n",
      "  0.06508692 0.07953508 0.         0.16347308 0.06131165 0.37222716\n",
      "  0.         0.         0.087841   0.         0.         0.\n",
      "  0.01398596 0.13351382 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3879262  0.         0.85453725 0.         0.         0.76757884\n",
      "  0.96153235 0.9023591  0.7797767  0.         0.46146727 0.\n",
      "  0.37369904 0.         0.         0.5545823  0.         0.78246343\n",
      "  0.01266677 0.         0.83309937 0.         0.         0.00159971\n",
      "  0.14606215 0.         0.         0.05050081 0.         0.\n",
      "  0.48615035 0.28680754 0.         0.         0.44269606 0.\n",
      "  0.19418147 1.1253213  0.         0.48845088 0.09967203 0.\n",
      "  0.         0.7695162  0.34523353 0.5323023  0.         0.6057402\n",
      "  0.         0.67752486 0.5286722  0.31125206 0.31981513 0.3868782\n",
      "  0.         0.00611582 0.14000094 0.0798533  0.         0.\n",
      "  0.         0.83774495 1.0382606  0.32372952]]\n",
      "Hi!\n",
      "[[0.00469172 0.18901211 0.20450841 0.         0.         0.26845708\n",
      "  0.07074635 0.15147106 0.02076164 0.14452931 0.220262   0.\n",
      "  0.         0.07057812 0.         0.         0.         0.12151545\n",
      "  0.         0.33203176 0.15634677 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04721487 0.07958    0.         0.         0.\n",
      "  0.         0.         0.07647415 0.184987   0.         0.\n",
      "  0.         0.         0.13263282 0.386141   0.         0.08016525\n",
      "  0.20844266 0.16294207 0.         0.2050329  0.16918209 0.32216114\n",
      "  0.         0.20886292 0.         0.         0.05105824 0.\n",
      "  0.08404496 0.10498956 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.57805157 0.         0.8414313  0.4227878  0.         0.9067053\n",
      "  1.7481608  1.850978   0.87052786 0.         0.3400866  0.\n",
      "  0.         0.         0.         0.54482245 0.10553265 0.78048056\n",
      "  0.         0.         0.8555963  0.13890791 0.         0.32957858\n",
      "  0.         0.         0.         0.29034764 0.         0.\n",
      "  0.61924744 0.32296702 0.18280546 0.         0.5531441  0.\n",
      "  0.         1.3078892  0.         0.6856876  0.33795372 0.\n",
      "  0.         1.3792284  0.18875854 0.8191778  0.         0.\n",
      "  0.         0.8827114  0.36393955 0.44449714 0.9057826  0.\n",
      "  0.         0.47962025 0.02149553 0.         0.         0.\n",
      "  0.         1.1289439  1.5450513  0.        ]]\n",
      "Hi!\n",
      "[[0.36444187 0.         0.476564   0.35694712 0.         0.70261353\n",
      "  2.0790322  2.0032914  0.8426784  0.         0.31587207 0.\n",
      "  0.         0.         0.         0.7055949  0.         0.7874562\n",
      "  0.         0.         0.6795318  0.30452746 0.         0.\n",
      "  0.12283003 0.         0.         0.42324588 0.         0.\n",
      "  0.9102433  0.21690811 0.10315269 0.         0.84224874 0.\n",
      "  0.10562427 1.5503844  0.         0.55831915 0.45603284 0.\n",
      "  0.         1.4277846  0.4697523  0.930237   0.         0.\n",
      "  0.         0.83747643 0.4838526  0.43540892 0.68929034 0.\n",
      "  0.         0.         0.26006916 0.         0.         0.\n",
      "  0.         1.1719886  1.4909058  0.        ]]\n",
      "Hi!\n",
      "[[0.24372764 0.         0.3897427  0.22350314 0.         0.6258074\n",
      "  1.3892652  1.5051033  0.5621874  0.         0.29889017 0.\n",
      "  0.23175555 0.         0.         0.4813554  0.         0.6759313\n",
      "  0.         0.         0.57703906 0.01268538 0.         0.\n",
      "  0.00954445 0.         0.         0.4080942  0.         0.\n",
      "  0.9460672  0.3566712  0.04753748 0.         0.64909345 0.\n",
      "  0.         1.19209    0.         0.43500355 0.18982011 0.\n",
      "  0.         0.76801646 0.58584857 0.9274475  0.         0.03836296\n",
      "  0.         0.87566483 0.37808642 0.4538174  0.7137951  0.1640647\n",
      "  0.         0.         0.14381327 0.         0.         0.\n",
      "  0.         0.8652974  1.1134628  0.        ]]\n",
      "Hi!\n",
      "[[1.079959   0.5086015  2.0014267  0.         0.         1.2336324\n",
      "  0.         0.05389236 0.8739881  0.         0.74502003 0.\n",
      "  0.2623861  0.         0.         0.3746961  0.76617527 0.74529773\n",
      "  0.         0.570425   1.3980949  0.13101065 0.         0.61709267\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.324078   0.04248264 0.         0.         0.\n",
      "  0.         0.44836926 0.         1.0314164  0.         0.\n",
      "  0.         0.73553616 0.         0.21745427 0.         0.76371187\n",
      "  0.38925108 0.86192    0.45058006 0.26006666 0.61663526 0.42016268\n",
      "  0.         1.1283969  0.         0.50830245 0.15949775 0.\n",
      "  0.24581993 0.6377129  0.89096713 0.8302727 ]]\n",
      "Hi!\n",
      "[[0.04033143 0.19776419 0.15903991 0.         0.         0.19590724\n",
      "  0.         0.0407573  0.09111409 0.02769693 0.18585315 0.\n",
      "  0.06255986 0.0825866  0.         0.0209632  0.         0.03452379\n",
      "  0.         0.2629505  0.15331402 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08427412 0.09076869 0.         0.         0.\n",
      "  0.         0.         0.10204775 0.1092144  0.         0.\n",
      "  0.         0.         0.09128214 0.30937937 0.         0.13609631\n",
      "  0.16519743 0.12299774 0.01768573 0.22863586 0.01857118 0.32885858\n",
      "  0.         0.08947293 0.03890588 0.         0.05128563 0.\n",
      "  0.04560245 0.06348055 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.39619145 0.2321486  0.4778232  0.25509197 0.         0.9100828\n",
      "  0.6708474  1.0212437  0.         0.10025133 0.21365842 0.\n",
      "  0.         0.28880197 0.         0.04406112 0.         0.25370848\n",
      "  0.         0.607233   0.33568278 0.         0.         0.10353565\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6151001  0.5076721  0.31459045 0.         0.00428542 0.\n",
      "  0.         0.21112193 0.         0.50179106 0.         0.\n",
      "  0.         0.06542216 0.68255043 1.2099451  0.         0.\n",
      "  0.43199852 1.1204925  0.         0.64844143 1.0759859  0.46211904\n",
      "  0.         0.93421715 0.         0.         0.         0.\n",
      "  0.14305218 0.5119539  0.2429682  0.        ]]\n",
      "Hi!\n",
      "[[0.6567314  0.         0.         1.0806543  0.         0.5238834\n",
      "  2.4964025  2.6754696  0.         0.         0.         0.\n",
      "  0.41114843 1.1602198  0.         0.47464123 0.         0.46952057\n",
      "  0.         0.         0.         0.81094927 0.         0.\n",
      "  0.30492562 0.         0.         1.222131   0.         0.\n",
      "  1.814807   0.8708537  1.0452023  0.         1.0969009  0.\n",
      "  0.5053544  1.3786411  0.58642167 0.22156389 0.5359713  0.\n",
      "  0.         1.0761933  2.1710038  2.0776155  0.         0.25455785\n",
      "  0.         1.047242   0.2122691  0.81788355 0.99631    1.5183089\n",
      "  0.         0.26862913 0.90392786 0.         0.         0.\n",
      "  0.         0.5587401  0.72860694 0.        ]]\n",
      "Hi!\n",
      "[[0.00208034 0.10089184 0.13300787 0.         0.         0.00254819\n",
      "  0.24760956 0.31154108 0.21508029 0.00983551 0.09157519 0.\n",
      "  0.         0.19688256 0.         0.26178318 0.01398513 0.08840286\n",
      "  0.         0.08219602 0.14643207 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10862233 0.13762517 0.19887517 0.         0.         0.\n",
      "  0.         0.1395903  0.06362519 0.06450617 0.         0.\n",
      "  0.         0.04072792 0.24605563 0.4214682  0.         0.02198567\n",
      "  0.13576719 0.2402828  0.08485211 0.15347691 0.         0.32262525\n",
      "  0.         0.11248993 0.07136934 0.         0.         0.\n",
      "  0.05526568 0.18060085 0.         0.01838599]]\n",
      "Hi!\n",
      "[[2.21407130e-01 0.00000000e+00 5.97068846e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.86598790e-01 1.43642807e+00 1.25897419e+00\n",
      "  9.38967168e-01 0.00000000e+00 3.95203203e-01 0.00000000e+00\n",
      "  2.48987004e-02 0.00000000e+00 0.00000000e+00 7.41330683e-01\n",
      "  0.00000000e+00 8.66459966e-01 0.00000000e+00 0.00000000e+00\n",
      "  7.46179342e-01 1.76176965e-01 0.00000000e+00 4.94099280e-04\n",
      "  2.65522867e-01 0.00000000e+00 0.00000000e+00 6.59266189e-02\n",
      "  0.00000000e+00 0.00000000e+00 4.92192328e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.42139971e-01 0.00000000e+00\n",
      "  1.55646294e-01 1.28360033e+00 0.00000000e+00 4.10086453e-01\n",
      "  1.20009325e-01 0.00000000e+00 0.00000000e+00 1.23395550e+00\n",
      "  1.83345482e-01 5.03404737e-01 0.00000000e+00 2.97778219e-01\n",
      "  0.00000000e+00 7.08887458e-01 6.23263061e-01 2.14403018e-01\n",
      "  2.72510380e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.40459561e-02 1.54963657e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.13976252e+00 8.96414220e-01 3.04022312e-01]]\n",
      "Hi!\n",
      "[[0.42485455 1.0352116  0.8939314  0.         0.         0.62130296\n",
      "  0.         0.01615004 0.1337055  0.         0.40196055 0.\n",
      "  1.0337132  0.26908803 0.         0.03041162 0.         0.31385928\n",
      "  0.         0.9571458  0.4536982  0.         0.         0.13859524\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.41098735 0.63157445 0.         0.         0.         0.\n",
      "  0.         0.04220348 0.4549784  0.3899825  0.         0.\n",
      "  0.         0.         0.6040991  0.41452727 0.         0.6345507\n",
      "  0.5807053  0.5461005  0.08550423 0.51713014 0.51728886 0.9992927\n",
      "  0.         0.3946288  0.13843215 0.         0.08068911 0.\n",
      "  0.04303936 0.16372123 0.31514034 0.17838125]]\n",
      "Hi!\n",
      "[[0.         0.23595163 0.40734196 0.         0.         0.35578004\n",
      "  0.         0.01065354 0.1800975  0.11519898 0.26721376 0.\n",
      "  0.09676357 0.         0.         0.04823111 0.         0.1126921\n",
      "  0.         0.36209735 0.2711408  0.         0.         0.07264598\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02381934 0.03915707 0.         0.         0.\n",
      "  0.         0.         0.09974612 0.23118244 0.         0.\n",
      "  0.         0.         0.05102506 0.32789502 0.         0.22350018\n",
      "  0.21554627 0.16527316 0.013124   0.25208512 0.1297999  0.3057439\n",
      "  0.         0.18481296 0.         0.         0.09853917 0.\n",
      "  0.09297919 0.15389681 0.         0.10806995]]\n",
      "Hi!\n",
      "[[0.5231335  0.         0.6879071  0.18968242 0.         0.7232312\n",
      "  1.0707375  0.8870041  0.24118696 0.         0.25060433 0.\n",
      "  0.         0.         0.         0.21730722 0.12941939 0.6172257\n",
      "  0.         0.19813761 0.5253174  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22906968 0.30824852 0.08009904 0.         0.22866169 0.\n",
      "  0.         0.80729705 0.         0.43226156 0.00456119 0.\n",
      "  0.         0.62590617 0.3406091  0.668452   0.         0.25394303\n",
      "  0.01127773 0.69809663 0.13045    0.30139714 0.28242335 0.40899196\n",
      "  0.         0.5345346  0.01228635 0.         0.         0.\n",
      "  0.06943066 0.73529154 0.535011   0.        ]]\n",
      "Hi!\n",
      "[[0.6519299  0.47408646 0.2633514  0.09887785 0.         0.55532783\n",
      "  0.7482245  0.9425455  0.25937432 0.         0.22970861 0.\n",
      "  1.0816381  0.51918626 0.         0.39690885 0.         0.55746317\n",
      "  0.26588905 0.3467143  0.32182935 0.03362779 0.         0.00466595\n",
      "  0.23334473 0.         0.         0.62328106 0.         0.\n",
      "  1.0831959  0.737739   0.01272191 0.         0.63490015 0.\n",
      "  0.46211562 1.0857469  0.18632808 0.20053458 0.02772111 0.\n",
      "  0.         0.32824185 1.1837974  0.82314116 0.         0.8939929\n",
      "  0.         0.66742414 0.5597633  0.46645448 0.35340005 1.0619049\n",
      "  0.         0.         0.48033267 0.         0.         0.\n",
      "  0.         0.32511982 0.8718945  0.        ]]\n",
      "Hi!\n",
      "[[0.01848262 0.20263435 0.25017124 0.         0.         0.28783494\n",
      "  0.02581188 0.19618872 0.         0.11655235 0.20372026 0.\n",
      "  0.         0.08750165 0.         0.         0.         0.1340339\n",
      "  0.         0.34835437 0.12151633 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.091612   0.10032523 0.         0.         0.\n",
      "  0.         0.         0.1283547  0.2115533  0.         0.\n",
      "  0.         0.         0.16741826 0.45372048 0.         0.07858883\n",
      "  0.25373274 0.21671462 0.         0.226132   0.2205756  0.34550738\n",
      "  0.         0.30995035 0.         0.         0.02332569 0.\n",
      "  0.12590224 0.14263396 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.59806436 0.4962617  0.         0.29789373 0.         0.36008316\n",
      "  0.97985274 1.682964   0.6013146  0.         0.25033146 0.\n",
      "  1.9318666  1.1972524  0.         0.71768856 0.         0.57055706\n",
      "  0.95323396 0.05451508 0.44707158 0.40306395 0.         0.04643644\n",
      "  0.39101824 0.         0.         1.1079665  0.         0.\n",
      "  1.7552186  0.96919763 0.01427242 0.         1.0041476  0.\n",
      "  0.6051096  1.3765408  0.384853   0.05385565 0.21022746 0.\n",
      "  0.         0.5825638  1.5776603  1.1057025  0.         0.82475257\n",
      "  0.         0.7718246  0.9876711  0.53560257 0.79584813 1.2283643\n",
      "  0.         0.         0.68739384 0.         0.         0.\n",
      "  0.         0.36187428 1.2762797  0.        ]]\n",
      "Hi!\n",
      "[[0.45239818 0.         0.55178785 0.38209212 0.         0.7532073\n",
      "  1.77765    1.8336939  0.7219553  0.         0.29199207 0.\n",
      "  0.         0.         0.         0.5487935  0.         0.69579446\n",
      "  0.         0.         0.7183897  0.14060082 0.         0.16079031\n",
      "  0.         0.         0.         0.34471124 0.         0.\n",
      "  0.7655254  0.30337292 0.1794712  0.         0.62395066 0.\n",
      "  0.         1.317103   0.         0.57282597 0.3099133  0.\n",
      "  0.         1.1825501  0.3795252  0.91289014 0.         0.\n",
      "  0.         0.9062666  0.3349475  0.4322971  0.8265444  0.\n",
      "  0.         0.26326922 0.06589161 0.         0.         0.\n",
      "  0.         1.072413   1.4249969  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07485078 0.13725694 0.         0.         0.24329121\n",
      "  0.11310133 0.26934454 0.00946403 0.15741289 0.16220872 0.\n",
      "  0.         0.02960811 0.         0.02146025 0.         0.14156547\n",
      "  0.         0.2695454  0.08191211 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01609904 0.10855012 0.         0.         0.\n",
      "  0.         0.008659   0.         0.1831641  0.         0.\n",
      "  0.         0.02472536 0.10710941 0.5388423  0.         0.03696783\n",
      "  0.22484541 0.2799401  0.         0.26188186 0.0963502  0.2689659\n",
      "  0.         0.3037698  0.         0.         0.         0.\n",
      "  0.10886923 0.23346736 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5957181  0.         1.3158637  0.         0.         0.8465821\n",
      "  0.727      0.80851763 1.1153854  0.         0.5497966  0.\n",
      "  0.28826058 0.         0.         0.6456852  0.34739503 0.79020834\n",
      "  0.09589527 0.         1.13221    0.18242057 0.         0.4419361\n",
      "  0.03028163 0.         0.         0.         0.         0.\n",
      "  0.16430943 0.26201686 0.         0.         0.14775835 0.\n",
      "  0.11563696 1.0787522  0.         0.7077066  0.05314473 0.\n",
      "  0.         1.0823854  0.         0.30222198 0.         0.59373134\n",
      "  0.         0.65316725 0.6097105  0.26681122 0.35066304 0.1484148\n",
      "  0.         0.32067436 0.         0.3936399  0.         0.\n",
      "  0.         0.95282775 1.2793376  0.5716659 ]]\n",
      "Hi!\n",
      "[[0.48328075 0.         0.31611335 0.5974406  0.         0.7685702\n",
      "  2.222557   1.8794836  0.22211976 0.         0.18653648 0.\n",
      "  0.         0.         0.         0.31396607 0.         0.6751119\n",
      "  0.         0.         0.4400429  0.2249935  0.         0.\n",
      "  0.         0.         0.         0.29958254 0.         0.\n",
      "  0.63264984 0.26079765 0.2518868  0.         0.56951934 0.\n",
      "  0.         1.1191174  0.         0.6830705  0.35890484 0.\n",
      "  0.         1.1980689  0.6076808  1.1334708  0.         0.\n",
      "  0.         0.95187765 0.10271236 0.501223   0.60967565 0.21510516\n",
      "  0.         0.4236026  0.0521836  0.         0.         0.\n",
      "  0.         1.0922142  0.81849915 0.        ]]\n",
      "Hi!\n",
      "[[0.04724234 0.17652838 0.0250522  0.         0.         0.06826879\n",
      "  0.02162253 0.15950052 0.03066762 0.04057509 0.10125872 0.\n",
      "  0.12063158 0.18237577 0.         0.04017591 0.         0.03224484\n",
      "  0.         0.14522743 0.11708206 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05921376 0.12083709 0.13411239 0.         0.         0.\n",
      "  0.         0.         0.15771325 0.0334261  0.         0.\n",
      "  0.         0.         0.16670512 0.296913   0.         0.05569814\n",
      "  0.09485218 0.13186203 0.         0.13749413 0.         0.35162613\n",
      "  0.         0.03819945 0.06844273 0.         0.         0.\n",
      "  0.05882979 0.14384842 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4153635  0.62147194 0.35622478 0.19446424 0.         0.29160893\n",
      "  0.         0.33873948 0.         0.         0.1088188  0.\n",
      "  0.5990671  0.6754818  0.         0.         0.         0.05334732\n",
      "  0.         0.46114725 0.06167724 0.         0.         0.08975879\n",
      "  0.         0.         0.         0.24530351 0.         0.\n",
      "  0.51830065 0.7075104  0.28676003 0.         0.         0.\n",
      "  0.         0.         0.8006295  0.06388016 0.         0.\n",
      "  0.         0.         0.87166804 0.5242526  0.         0.0827013\n",
      "  0.5785511  0.39048213 0.         0.49562785 0.5157019  1.0415893\n",
      "  0.         0.38320324 0.28542688 0.         0.         0.\n",
      "  0.21299134 0.09052517 0.20131566 0.        ]]\n",
      "Hi!\n",
      "[[0.4034625  0.03910748 0.79939115 0.         0.         0.66933906\n",
      "  0.73573834 0.50496453 0.5398489  0.         0.22815496 0.\n",
      "  0.         0.         0.         0.25279236 0.24804245 0.69292396\n",
      "  0.         0.10606947 0.6064714  0.03390155 0.         0.\n",
      "  0.13780348 0.         0.         0.         0.         0.\n",
      "  0.09530507 0.21978526 0.07031284 0.         0.11210414 0.\n",
      "  0.10690836 0.6988633  0.         0.49190354 0.         0.\n",
      "  0.         0.6425604  0.1439663  0.40337723 0.         0.60587156\n",
      "  0.02221667 0.57406855 0.31154272 0.25466332 0.0363545  0.4766928\n",
      "  0.         0.4342418  0.         0.0950999  0.         0.\n",
      "  0.01135222 0.67355156 0.47767466 0.24252923]]\n",
      "Hi!\n",
      "[[0.36397433 0.         0.11025456 0.15048687 0.         0.5423297\n",
      "  1.6204019  1.7195551  0.7716137  0.         0.28626478 0.\n",
      "  0.8017762  0.29271764 0.         0.7749843  0.         0.75750107\n",
      "  0.43138492 0.         0.4988828  0.32598495 0.         0.\n",
      "  0.3796766  0.         0.         0.7013289  0.         0.\n",
      "  1.20337    0.4049482  0.         0.         0.9137942  0.\n",
      "  0.5824713  1.5659848  0.         0.21448125 0.30404794 0.\n",
      "  0.         0.89155066 0.96026474 1.0198566  0.         0.5280374\n",
      "  0.         0.76063514 0.7964874  0.46960923 0.34557116 0.60365\n",
      "  0.         0.         0.51693    0.         0.         0.\n",
      "  0.         0.7452599  1.3181834  0.03235316]]\n",
      "Hi!\n",
      "[[0.84928983 0.3177156  2.0297852  0.         0.         0.78950024\n",
      "  0.22083743 0.         1.5821637  0.         0.8910386  0.\n",
      "  0.51738775 0.         0.         0.96178955 0.8834727  1.0824331\n",
      "  0.25124332 0.         1.5804228  0.53328377 0.         0.61470896\n",
      "  0.10314418 0.         0.         0.         0.         0.\n",
      "  0.         0.07105886 0.         0.         0.         0.\n",
      "  0.38871065 0.9749435  0.         1.1456205  0.10590386 0.\n",
      "  0.         1.2301018  0.         0.         0.         0.85722834\n",
      "  0.         1.0318459  0.8985555  0.         0.2452113  0.03253645\n",
      "  0.         0.13739091 0.         0.9740707  0.12146236 0.\n",
      "  0.         1.1020103  1.1625441  1.2701539 ]]\n",
      "Hi!\n",
      "[[0.18074587 0.28344926 0.         0.         0.         0.\n",
      "  0.32961148 0.51169413 0.17445314 0.09476566 0.10680075 0.\n",
      "  0.06601871 0.11910581 0.         0.19562887 0.         0.24258137\n",
      "  0.         0.12235133 0.1815905  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10935451 0.01212157 0.06877783 0.         0.         0.\n",
      "  0.         0.0218046  0.09747247 0.12514886 0.         0.\n",
      "  0.         0.26867685 0.08649282 0.3405287  0.         0.\n",
      "  0.         0.1638016  0.28796494 0.08556585 0.         0.2904667\n",
      "  0.         0.         0.10880657 0.         0.         0.\n",
      "  0.04785569 0.34739688 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.38873821 0.30138853 1.3789005  0.         0.         0.6595085\n",
      "  0.40687478 0.41515738 1.4473143  0.         0.70250165 0.\n",
      "  0.9485896  0.         0.         0.9420525  0.24688858 0.93868077\n",
      "  0.7263774  0.         1.2614778  0.27229887 0.         0.32494214\n",
      "  0.21450962 0.         0.         0.03645391 0.         0.\n",
      "  0.3045048  0.2464987  0.         0.         0.25434402 0.\n",
      "  0.48702055 1.1692438  0.         0.8058974  0.18128128 0.\n",
      "  0.         0.9018769  0.         0.         0.         0.91536283\n",
      "  0.         0.8709985  0.936278   0.1224773  0.21343394 0.16162834\n",
      "  0.         0.         0.06450939 0.5659317  0.         0.\n",
      "  0.         0.95523816 1.314996   1.0544133 ]]\n",
      "Hi!\n",
      "[[0.44216183 0.9672808  0.9115181  0.         0.         0.68781453\n",
      "  0.         0.22418344 0.18856455 0.         0.4720397  0.\n",
      "  1.0387195  0.24255335 0.         0.         0.         0.29141206\n",
      "  0.         0.8884209  0.5187663  0.         0.         0.1408863\n",
      "  0.         0.         0.         0.04679008 0.         0.\n",
      "  0.62405837 0.7042279  0.         0.         0.01889948 0.\n",
      "  0.         0.13098174 0.380266   0.29229206 0.         0.\n",
      "  0.         0.         0.61583596 0.5392374  0.         0.50586474\n",
      "  0.52868825 0.74398607 0.14857076 0.49034166 0.8109249  0.93642825\n",
      "  0.         0.44606027 0.08923658 0.         0.09223419 0.\n",
      "  0.         0.15514015 0.44410262 0.17962961]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34129366 1.0711846  0.4484379  0.         0.         0.20166427\n",
      "  0.         0.19640896 0.1584704  0.         0.34221458 0.\n",
      "  1.2710856  0.66219026 0.         0.17297906 0.         0.23226154\n",
      "  0.13720869 0.73188746 0.3605938  0.         0.         0.20648815\n",
      "  0.         0.         0.         0.4705147  0.         0.\n",
      "  0.6402773  0.621774   0.         0.         0.10280556 0.\n",
      "  0.01010141 0.         0.7805728  0.09670197 0.         0.\n",
      "  0.         0.         0.62371886 0.4348323  0.         0.46145293\n",
      "  0.25471383 0.45758095 0.39822564 0.35081545 0.49985784 1.0080659\n",
      "  0.         0.         0.40529847 0.         0.11037511 0.\n",
      "  0.18705821 0.11596794 0.32917756 0.04737429]]\n",
      "Hi!\n",
      "[[0.9544095  0.18517253 1.5985887  0.         0.         1.1038611\n",
      "  0.21215117 0.3887757  0.6722765  0.05859281 0.5953764  0.\n",
      "  0.         0.         0.         0.21188073 0.53551155 0.71229035\n",
      "  0.         0.39339763 1.1277162  0.03803395 0.         0.49649596\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27630463 0.11907492 0.         0.         0.\n",
      "  0.         0.46685588 0.         0.84216064 0.         0.\n",
      "  0.         0.76346326 0.         0.34242183 0.         0.38854653\n",
      "  0.3247187  0.90676373 0.26481053 0.3025454  0.6268867  0.23030305\n",
      "  0.         1.0282156  0.         0.21230036 0.06989237 0.\n",
      "  0.23938043 0.7375314  0.75757766 0.4662777 ]]\n",
      "Hi!\n",
      "[[0.4409986  1.069961   0.54785013 0.         0.         0.36521724\n",
      "  0.05069042 0.5519987  0.572738   0.         0.48385504 0.\n",
      "  1.7698135  0.6044317  0.         0.56877714 0.         0.61600727\n",
      "  0.5774627  0.5588068  0.5814423  0.         0.         0.23541424\n",
      "  0.07313517 0.         0.         0.46341723 0.         0.\n",
      "  1.1178994  0.7379467  0.         0.         0.39311135 0.\n",
      "  0.26378816 0.71709186 0.36536703 0.35814    0.         0.\n",
      "  0.         0.21547507 0.86634046 0.54053867 0.         0.7134708\n",
      "  0.         0.7533175  0.74986076 0.31692445 0.6535271  0.884778\n",
      "  0.         0.         0.31428877 0.         0.0098111  0.\n",
      "  0.         0.39451608 0.7594842  0.34183678]]\n",
      "Hi!\n",
      "[[0.26171732 0.07152002 0.3737401  0.27101126 0.         0.79560095\n",
      "  1.0762302  1.3794831  0.16637847 0.         0.24153467 0.\n",
      "  0.19324276 0.20778628 0.         0.15785082 0.         0.38469246\n",
      "  0.         0.27932736 0.4544021  0.         0.         0.\n",
      "  0.         0.         0.         0.33638537 0.         0.\n",
      "  0.90933996 0.55808055 0.08371574 0.         0.4517673  0.\n",
      "  0.         0.64373815 0.         0.39828855 0.10153845 0.\n",
      "  0.         0.42569116 0.7355327  1.0514035  0.         0.\n",
      "  0.04113852 0.9919005  0.04278621 0.60485476 1.0136036  0.32232514\n",
      "  0.         0.3874879  0.08368598 0.         0.         0.\n",
      "  0.         0.5893697  0.82096875 0.        ]]\n",
      "Hi!\n",
      "[[0.36148763 0.5897453  1.4821453  0.         0.         0.7395782\n",
      "  0.14679614 0.14050563 1.1687505  0.         0.70034844 0.\n",
      "  1.1331321  0.         0.         0.7631409  0.16989756 0.8379805\n",
      "  0.6160707  0.21060011 1.209065   0.14052519 0.         0.21745287\n",
      "  0.18293752 0.         0.         0.         0.         0.\n",
      "  0.30750182 0.44795743 0.         0.         0.12741213 0.\n",
      "  0.39991438 0.9562169  0.         0.8253157  0.         0.\n",
      "  0.         0.48569658 0.19723721 0.         0.         1.0192114\n",
      "  0.         0.8421017  0.81429726 0.260571   0.25473374 0.47041345\n",
      "  0.         0.         0.02175088 0.36615717 0.08531239 0.\n",
      "  0.         0.7305219  1.1695307  1.0150404 ]]\n",
      "Hi!\n",
      "[[0.03229285 0.19803251 0.14941934 0.         0.         0.07562768\n",
      "  0.         0.07570435 0.         0.0361242  0.09235169 0.\n",
      "  0.18603177 0.15098558 0.         0.         0.         0.01046321\n",
      "  0.         0.11830598 0.04217842 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.024679   0.17403574 0.15141195 0.         0.         0.\n",
      "  0.         0.         0.21210577 0.06001999 0.         0.\n",
      "  0.         0.         0.21868947 0.23846725 0.         0.03776511\n",
      "  0.18452585 0.05877293 0.         0.20369625 0.07334591 0.36990485\n",
      "  0.         0.0739515  0.05662278 0.         0.         0.\n",
      "  0.05690466 0.02424631 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.02559197 0.17423488 0.1075135  0.         0.         0.05771866\n",
      "  0.         0.0790424  0.03264343 0.06661108 0.1005035  0.\n",
      "  0.11055035 0.10585885 0.         0.06967986 0.         0.04728026\n",
      "  0.         0.131237   0.09285374 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01531557 0.11077588 0.11837929 0.         0.         0.\n",
      "  0.         0.         0.09690171 0.04790263 0.         0.\n",
      "  0.         0.         0.12191903 0.2132018  0.         0.03780792\n",
      "  0.07945091 0.11860638 0.         0.12373246 0.00308975 0.29515812\n",
      "  0.         0.00312766 0.06578869 0.         0.         0.\n",
      "  0.07856052 0.14067431 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3645807  0.4087708  0.43069798 0.04239512 0.         0.62323517\n",
      "  0.56989175 1.0640119  0.22476639 0.         0.31020793 0.\n",
      "  0.80212265 0.42080802 0.         0.20548789 0.         0.39248523\n",
      "  0.         0.3678678  0.45873815 0.         0.         0.12542927\n",
      "  0.         0.         0.         0.4749717  0.         0.\n",
      "  1.0519673  0.7015976  0.         0.         0.40657994 0.\n",
      "  0.         0.57608736 0.12463439 0.2207237  0.         0.\n",
      "  0.         0.13191351 0.8253691  0.94366646 0.         0.13095061\n",
      "  0.11728548 0.95571417 0.2505246  0.57706463 0.96976876 0.63936436\n",
      "  0.         0.2008895  0.13839492 0.         0.         0.\n",
      "  0.         0.4042945  0.78633714 0.        ]]\n",
      "Hi!\n",
      "[[0.5693491  0.6766721  0.6635647  0.         0.         0.62979203\n",
      "  0.2634247  0.5231231  0.46474046 0.         0.38437417 0.\n",
      "  1.1803559  0.21802789 0.         0.43245918 0.         0.60797346\n",
      "  0.37337866 0.48354107 0.561625   0.         0.         0.02501225\n",
      "  0.12062361 0.         0.         0.3192793  0.         0.\n",
      "  0.7996531  0.66521883 0.         0.         0.39590484 0.\n",
      "  0.41762552 0.892074   0.04899105 0.39354947 0.         0.\n",
      "  0.         0.15458372 0.8562662  0.46243253 0.         0.9657229\n",
      "  0.         0.59262747 0.52653974 0.37721348 0.24889438 0.88515663\n",
      "  0.         0.         0.3351541  0.         0.         0.\n",
      "  0.         0.3608359  0.88540024 0.2765189 ]]\n",
      "Hi!\n",
      "[[0.03259538 0.22188203 0.17815994 0.         0.         0.12361883\n",
      "  0.         0.20273696 0.         0.00771181 0.09033024 0.\n",
      "  0.08215666 0.21507393 0.         0.02533094 0.         0.07137742\n",
      "  0.         0.21594131 0.00200966 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12001672 0.31879458 0.13939491 0.         0.         0.\n",
      "  0.         0.         0.17343678 0.10348675 0.         0.\n",
      "  0.         0.         0.3310517  0.33135733 0.         0.04132695\n",
      "  0.23940817 0.2654711  0.         0.18194512 0.17633829 0.4172081\n",
      "  0.         0.16377375 0.04588028 0.         0.         0.\n",
      "  0.12930992 0.11521775 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.55480033 0.         0.74826044 0.49940544 0.         0.921892\n",
      "  1.5040052  1.7008221  0.6806594  0.         0.2876933  0.\n",
      "  0.         0.         0.         0.32150996 0.         0.6971819\n",
      "  0.         0.         0.74986124 0.01823265 0.         0.42191347\n",
      "  0.         0.         0.         0.16418365 0.         0.\n",
      "  0.67522514 0.26083636 0.32837608 0.         0.36699843 0.\n",
      "  0.         0.9436147  0.         0.74574053 0.21996588 0.\n",
      "  0.         1.210706   0.12214392 1.0077646  0.         0.\n",
      "  0.         1.1490896  0.21001743 0.47784492 1.1397365  0.\n",
      "  0.         0.64767796 0.         0.         0.         0.\n",
      "  0.         1.0380462  1.1204557  0.        ]]\n",
      "Hi!\n",
      "[[0.36669397 0.13303527 0.3242199  0.08546941 0.         0.6144893\n",
      "  0.24256869 0.65138054 0.         0.10839539 0.12189267 0.\n",
      "  0.         0.3010114  0.         0.04453733 0.         0.02567015\n",
      "  0.         0.51659316 0.09700025 0.         0.         0.04022846\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12952782 0.25279537 0.316416   0.         0.         0.\n",
      "  0.         0.15578155 0.10737345 0.37947378 0.         0.\n",
      "  0.         0.         0.44279882 0.8257479  0.         0.\n",
      "  0.38274875 0.6529869  0.         0.48775172 0.7239414  0.45403075\n",
      "  0.         0.6549303  0.         0.         0.         0.\n",
      "  0.15737778 0.2892769  0.00564286 0.        ]]\n",
      "Hi!\n",
      "[[0.62846035 0.25151512 1.0961384  0.         0.         0.8301281\n",
      "  0.34450254 0.52788746 0.5697686  0.06912152 0.5009562  0.\n",
      "  0.04308823 0.         0.         0.24759693 0.14549239 0.7069982\n",
      "  0.         0.28388864 0.8881115  0.         0.         0.36004007\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15448086 0.27785385 0.087478   0.         0.00963219 0.\n",
      "  0.         0.50652045 0.         0.640807   0.         0.\n",
      "  0.         0.5788026  0.06344427 0.5155371  0.         0.153645\n",
      "  0.09666324 0.97430336 0.23708743 0.3191766  0.66656196 0.15177019\n",
      "  0.         0.5703721  0.         0.         0.01824218 0.\n",
      "  0.03284223 0.79509765 0.6108742  0.24354723]]\n",
      "Hi!\n",
      "[[0.0524197  0.78904384 0.30324408 0.         0.         0.04351059\n",
      "  0.10872543 0.16570485 0.6988129  0.         0.3536122  0.\n",
      "  0.831541   0.06643903 0.         0.51650447 0.         0.45646724\n",
      "  0.         0.35482502 0.40536442 0.         0.         0.\n",
      "  0.         0.         0.         0.15148412 0.         0.\n",
      "  0.2775512  0.08884224 0.         0.         0.15010618 0.\n",
      "  0.         0.37866905 0.         0.23073259 0.         0.\n",
      "  0.         0.05378326 0.01724129 0.         0.         0.25476903\n",
      "  0.         0.45203835 0.6274922  0.         0.         0.4550241\n",
      "  0.         0.         0.0780042  0.         0.         0.\n",
      "  0.         0.4939895  0.09794605 0.402922  ]]\n",
      "Hi!\n",
      "[[0.22598645 0.9966996  0.82388544 0.         0.         0.60089976\n",
      "  0.         0.         0.34554666 0.         0.480881   0.\n",
      "  0.9633391  0.10127703 0.         0.19794887 0.         0.3980587\n",
      "  0.         0.87918615 0.49913183 0.         0.         0.00348941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3267689  0.3753435  0.         0.         0.         0.\n",
      "  0.         0.0714857  0.13191345 0.39352462 0.         0.\n",
      "  0.         0.         0.32908964 0.25662455 0.         0.64859986\n",
      "  0.37624604 0.47082892 0.29204437 0.32680845 0.351994   0.74445784\n",
      "  0.         0.0771217  0.05933044 0.         0.16240987 0.\n",
      "  0.15745664 0.33337492 0.35779837 0.41378936]]\n",
      "Hi!\n",
      "[[0.6675755  0.         0.7308506  0.46024844 0.         0.8713192\n",
      "  1.6251432  1.5389599  0.44872382 0.         0.3196401  0.\n",
      "  0.         0.         0.         0.23362951 0.21170118 0.70746416\n",
      "  0.         0.         0.62988263 0.14996037 0.         0.28670597\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27211702 0.18591863 0.29548672 0.         0.2749669  0.\n",
      "  0.         0.80996513 0.         0.8545191  0.21747294 0.\n",
      "  0.         1.3115367  0.05749481 0.89714646 0.         0.\n",
      "  0.         1.125964   0.10958566 0.3288877  0.7947116  0.\n",
      "  0.         0.7546845  0.         0.         0.         0.\n",
      "  0.         1.1365262  0.7171845  0.        ]]\n",
      "Hi!\n",
      "[[0.7151786  0.754353   0.66654843 0.         0.         0.6353593\n",
      "  0.22106487 0.7246272  0.6245266  0.         0.4384511  0.\n",
      "  1.6759304  0.4129542  0.         0.54359126 0.         0.5806386\n",
      "  0.89126784 0.4525255  0.6753993  0.         0.         0.15907598\n",
      "  0.202013   0.         0.         0.60195315 0.         0.\n",
      "  1.1018553  0.85162294 0.         0.         0.47799745 0.\n",
      "  0.6905079  1.0125222  0.29168236 0.3771126  0.         0.\n",
      "  0.         0.34456816 1.097468   0.5586012  0.         1.0519931\n",
      "  0.         0.6653032  0.74085456 0.5117338  0.45708555 1.1439347\n",
      "  0.         0.         0.48434338 0.         0.         0.\n",
      "  0.         0.23703955 1.2578558  0.34333408]]\n",
      "Hi!\n",
      "[[0.9382238  0.         1.5293388  0.         0.         1.019577\n",
      "  0.5038783  0.7472714  0.885922   0.         0.5727605  0.\n",
      "  0.         0.         0.         0.42391714 0.52961594 0.70809245\n",
      "  0.         0.02493906 1.206783   0.11612994 0.         0.6500202\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30771357 0.09094373 0.         0.         0.\n",
      "  0.         0.7407066  0.         0.77554446 0.         0.\n",
      "  0.         1.0088449  0.         0.4066433  0.         0.26798043\n",
      "  0.01053685 0.95680165 0.36939752 0.30409253 0.6971263  0.14110933\n",
      "  0.         0.9190397  0.         0.26465005 0.         0.\n",
      "  0.         0.87077963 1.0743963  0.3771671 ]]\n",
      "Hi!\n",
      "[[0.49475378 0.0653969  0.1966745  0.29072094 0.         0.6181524\n",
      "  1.1687232  1.4876139  0.38041362 0.         0.29494673 0.\n",
      "  0.90588105 0.5261817  0.         0.4707891  0.         0.58939636\n",
      "  0.17802243 0.06908782 0.43017322 0.15789245 0.         0.\n",
      "  0.17891353 0.         0.         0.76016426 0.         0.\n",
      "  1.3056653  0.681018   0.         0.         0.8270102  0.\n",
      "  0.31397787 1.1885827  0.06768695 0.1319978  0.23553522 0.\n",
      "  0.         0.36046094 1.1825753  1.1293566  0.         0.41138637\n",
      "  0.         0.7934144  0.47496495 0.59446305 0.7163706  0.7514386\n",
      "  0.         0.         0.47897008 0.         0.         0.\n",
      "  0.         0.48434675 1.1814598  0.        ]]\n",
      "Hi!\n",
      "[[0.4213871  0.         0.55189544 0.26531246 0.         0.7877741\n",
      "  1.2367805  1.3510242  0.43411702 0.         0.32951313 0.\n",
      "  0.40809223 0.         0.         0.40420657 0.         0.6052823\n",
      "  0.         0.05876362 0.6252874  0.04147007 0.         0.\n",
      "  0.04412268 0.         0.         0.49186757 0.         0.\n",
      "  0.93360716 0.5986847  0.0363966  0.         0.60456204 0.\n",
      "  0.11804509 1.1460102  0.         0.30273634 0.1934983  0.\n",
      "  0.         0.5463452  0.85070914 0.9704574  0.         0.3697757\n",
      "  0.         0.7424312  0.28182748 0.4907974  0.6521539  0.47712332\n",
      "  0.         0.1708115  0.33263278 0.         0.         0.\n",
      "  0.         0.6572708  1.2841005  0.        ]]\n",
      "Hi!\n",
      "[[0.11751444 0.4903826  0.5020469  0.         0.         0.43667522\n",
      "  0.         0.01890221 0.09274118 0.05125239 0.29282776 0.\n",
      "  0.34580272 0.027158   0.         0.02017255 0.         0.30477718\n",
      "  0.         0.5802954  0.29147065 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12264877 0.24102984 0.         0.         0.         0.\n",
      "  0.         0.02790898 0.         0.2653858  0.         0.\n",
      "  0.         0.         0.22673468 0.36877358 0.         0.3629222\n",
      "  0.35436353 0.37608472 0.01418691 0.25066885 0.16533165 0.48647743\n",
      "  0.         0.2528912  0.         0.         0.09249779 0.\n",
      "  0.1977739  0.23036185 0.06907798 0.16087449]]\n",
      "Hi!\n",
      "[[0.81187576 0.         1.4272369  0.0166456  0.         0.7241767\n",
      "  0.7325991  0.72533774 1.0716636  0.         0.567069   0.\n",
      "  0.         0.         0.         0.56209576 0.72353196 0.9058177\n",
      "  0.         0.         1.1808074  0.44624949 0.         0.5452127\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13562731 0.         0.         0.\n",
      "  0.         0.80879056 0.         0.84866077 0.04738059 0.\n",
      "  0.         1.4234666  0.         0.19006    0.         0.03579079\n",
      "  0.         0.89802194 0.48176032 0.00170387 0.39845207 0.\n",
      "  0.         0.47405413 0.         0.46301383 0.         0.\n",
      "  0.02586748 1.180374   0.7471872  0.4139123 ]]\n",
      "Hi!\n",
      "[[0.43981352 0.22727601 0.17701156 0.05494602 0.         0.26035425\n",
      "  0.784629   0.8099277  0.26241362 0.         0.1340991  0.\n",
      "  0.538015   0.25887144 0.         0.3695973  0.         0.44565344\n",
      "  0.         0.15606745 0.17444137 0.01293943 0.         0.\n",
      "  0.15476353 0.         0.         0.47756425 0.         0.\n",
      "  0.8350289  0.43967578 0.05788893 0.         0.500587   0.\n",
      "  0.23925488 0.8924928  0.06338912 0.15698788 0.06267741 0.\n",
      "  0.         0.22095238 0.69333    0.7884413  0.         0.5174085\n",
      "  0.         0.5424046  0.42372194 0.30968377 0.13912702 0.718421\n",
      "  0.         0.         0.2799521  0.         0.         0.\n",
      "  0.         0.38648582 0.6603115  0.        ]]\n",
      "Hi!\n",
      "[[0.07392689 0.28164896 0.6021743  0.         0.         0.50813323\n",
      "  0.         0.         0.19955242 0.14129707 0.36736417 0.\n",
      "  0.06442303 0.         0.         0.08603994 0.         0.04669707\n",
      "  0.         0.55859506 0.35904947 0.         0.         0.04271061\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04487068 0.05386657 0.         0.         0.\n",
      "  0.         0.         0.02086035 0.34801602 0.         0.\n",
      "  0.         0.         0.         0.28127733 0.         0.4044583\n",
      "  0.3650665  0.17458731 0.01244388 0.35931128 0.16120271 0.37103343\n",
      "  0.         0.35089943 0.         0.         0.15224151 0.\n",
      "  0.13575822 0.04095074 0.07524806 0.20364705]]\n",
      "Hi!\n",
      "[[0.87159926 0.         1.0387795  0.42296785 0.         1.0274479\n",
      "  1.6024318  1.5492799  0.6951093  0.         0.37138456 0.\n",
      "  0.         0.         0.         0.3024682  0.38667133 0.74509287\n",
      "  0.         0.         0.89088035 0.18063097 0.         0.4713696\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18325503 0.2640991  0.23708506 0.         0.20124774 0.\n",
      "  0.         0.9746974  0.         0.8580834  0.21296564 0.\n",
      "  0.         1.4056686  0.0070819  0.75618213 0.         0.\n",
      "  0.         1.0637105  0.22313096 0.3481337  0.7939465  0.01412203\n",
      "  0.         0.9575131  0.         0.         0.         0.\n",
      "  0.         1.1289481  1.1546464  0.        ]]\n",
      "Hi!\n",
      "[[0.14567982 0.26472777 0.11767229 0.         0.         0.11779306\n",
      "  0.         0.01006666 0.08766527 0.         0.1845533  0.\n",
      "  0.35044113 0.14832343 0.         0.03903923 0.         0.01503953\n",
      "  0.         0.21271108 0.10662962 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08849365 0.18907367 0.0660937  0.         0.         0.\n",
      "  0.         0.         0.22014344 0.05897506 0.         0.\n",
      "  0.         0.01199503 0.09580858 0.16311459 0.         0.10905866\n",
      "  0.09007051 0.06110507 0.03354817 0.1755144  0.04472674 0.45070028\n",
      "  0.         0.         0.14269258 0.         0.0212866  0.\n",
      "  0.06279289 0.04078014 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.26339284 0.1419238  0.         0.         0.06236407\n",
      "  0.         0.         0.17654186 0.04130792 0.147181   0.\n",
      "  0.22051612 0.03003851 0.         0.11074443 0.         0.04828278\n",
      "  0.         0.2020196  0.17215644 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02700016 0.08166785 0.02851872 0.         0.         0.\n",
      "  0.         0.         0.05392639 0.03883392 0.         0.\n",
      "  0.         0.         0.07791433 0.10135079 0.         0.13906696\n",
      "  0.         0.0220616  0.07723311 0.06584092 0.         0.24319212\n",
      "  0.         0.         0.09164542 0.         0.         0.\n",
      "  0.03561652 0.09140047 0.         0.05041364]]\n",
      "Hi!\n",
      "[[0.         0.04667173 0.         0.         0.         0.0129778\n",
      "  0.2237322  0.354549   0.         0.16108112 0.12203598 0.\n",
      "  0.         0.1749749  0.         0.05774849 0.         0.1348596\n",
      "  0.         0.12033291 0.06899546 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.20811945 0.         0.         0.\n",
      "  0.         0.         0.06855537 0.11967361 0.         0.\n",
      "  0.         0.         0.19064017 0.47041708 0.         0.\n",
      "  0.18084157 0.11105458 0.         0.18119942 0.         0.20149426\n",
      "  0.         0.16328222 0.         0.         0.         0.\n",
      "  0.05367829 0.2037926  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.24041912 0.47809583 0.11785673 0.         0.         0.01009565\n",
      "  0.20016812 0.24086739 0.59786475 0.         0.24151409 0.\n",
      "  0.69221634 0.04110481 0.         0.41548267 0.         0.15727146\n",
      "  0.         0.2893766  0.30880445 0.         0.         0.02645964\n",
      "  0.         0.         0.         0.16145875 0.00163652 0.\n",
      "  0.4957354  0.18753135 0.         0.         0.15679254 0.\n",
      "  0.         0.048279   0.13138884 0.08121468 0.         0.\n",
      "  0.         0.31867054 0.04104273 0.0514852  0.         0.19303116\n",
      "  0.         0.35677996 0.6135651  0.         0.07277041 0.5743363\n",
      "  0.         0.         0.22884911 0.         0.         0.\n",
      "  0.01450789 0.22602311 0.         0.23044062]]\n",
      "Hi!\n",
      "[[0.40570837 0.5235786  0.3556723  0.         0.         0.60212797\n",
      "  0.55201685 0.8933823  0.10949994 0.         0.27899775 0.\n",
      "  0.74489015 0.39506778 0.         0.11820608 0.         0.41622257\n",
      "  0.         0.5260035  0.3387993  0.         0.         0.07068661\n",
      "  0.         0.         0.         0.22292365 0.         0.\n",
      "  0.9174896  0.5717831  0.         0.         0.2664229  0.\n",
      "  0.         0.6267275  0.04168576 0.30252147 0.         0.\n",
      "  0.         0.0958266  0.7964023  0.9492924  0.         0.3280981\n",
      "  0.20923495 0.866432   0.29807103 0.54471916 0.80366004 0.77111113\n",
      "  0.         0.173798   0.10205625 0.         0.         0.\n",
      "  0.         0.39681193 0.4801652  0.        ]]\n",
      "Hi!\n",
      "[[0.01310281 0.19324793 0.0887491  0.         0.         0.11152136\n",
      "  0.         0.09504153 0.         0.04296524 0.10268316 0.\n",
      "  0.21680948 0.20158297 0.         0.         0.         0.0292589\n",
      "  0.         0.14469779 0.03221935 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11923353 0.18086287 0.14751525 0.         0.         0.\n",
      "  0.         0.         0.18288049 0.05423451 0.         0.\n",
      "  0.         0.         0.21911164 0.24057114 0.         0.05872748\n",
      "  0.14591464 0.16086589 0.         0.18111506 0.09417971 0.3894987\n",
      "  0.         0.03522528 0.11118328 0.         0.         0.\n",
      "  0.10391457 0.05408345 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.89681345 0.0835675  1.2776687  0.12857668 0.         1.1583844\n",
      "  0.5176789  0.86671984 0.42276025 0.07462077 0.45137617 0.\n",
      "  0.         0.         0.         0.07595029 0.25095698 0.53796357\n",
      "  0.         0.35086447 0.900187   0.         0.         0.4678181\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13951458 0.48356032 0.13446312 0.         0.         0.\n",
      "  0.         0.4582734  0.         0.7664997  0.         0.\n",
      "  0.         0.5979407  0.15670377 0.7528794  0.         0.08005015\n",
      "  0.26420784 1.0889081  0.07359665 0.5252216  1.0347741  0.31644565\n",
      "  0.         1.275229   0.         0.         0.         0.\n",
      "  0.10665037 0.63958687 0.8682079  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07895601 0.22235954 0.         0.         0.22343451\n",
      "  0.05721504 0.08877999 0.06867266 0.16709383 0.20085992 0.\n",
      "  0.         0.         0.         0.         0.         0.05496266\n",
      "  0.         0.23510137 0.132027   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06754971 0.         0.         0.\n",
      "  0.         0.         0.08511355 0.19391547 0.         0.\n",
      "  0.         0.         0.07040564 0.3796372  0.         0.11677583\n",
      "  0.16142358 0.07502278 0.         0.21447751 0.077857   0.21237041\n",
      "  0.         0.23616286 0.         0.         0.0428008  0.\n",
      "  0.01106906 0.08929504 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.13606572 0.19963518 0.28070334 0.         0.         0.4789532\n",
      "  0.14065048 0.23295331 0.         0.05417188 0.13560079 0.\n",
      "  0.08523732 0.16194114 0.         0.         0.         0.05796028\n",
      "  0.         0.42984188 0.10588706 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13081728 0.31418276 0.08334439 0.         0.         0.\n",
      "  0.         0.02589163 0.19039834 0.20077594 0.         0.\n",
      "  0.         0.03844071 0.39726105 0.58614403 0.         0.27232647\n",
      "  0.42085385 0.32164425 0.         0.3829842  0.15254362 0.6611211\n",
      "  0.         0.49773076 0.03855477 0.         0.         0.\n",
      "  0.11410221 0.09263596 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.30831602 0.32631862 0.7074734  0.         0.         0.52551717\n",
      "  0.6711271  0.96046144 1.3056357  0.         0.50970167 0.\n",
      "  1.39861    0.         0.         0.95778644 0.         0.76065993\n",
      "  1.0264683  0.         0.9020755  0.         0.         0.\n",
      "  0.33766428 0.         0.         0.49905232 0.         0.\n",
      "  0.9492445  0.41149795 0.         0.         0.6097214  0.\n",
      "  0.5994533  1.3403093  0.         0.44596052 0.20689334 0.\n",
      "  0.         0.69765556 0.4730581  0.3347714  0.         0.8736981\n",
      "  0.         0.82723093 1.0708237  0.3220776  0.37318397 0.37664235\n",
      "  0.         0.         0.34506267 0.09898812 0.         0.\n",
      "  0.         0.70376587 1.3768228  0.71112216]]\n",
      "Hi!\n",
      "[[0.34702075 0.         0.7017483  0.13544299 0.         0.890765\n",
      "  1.0525055  1.2771417  0.49816555 0.         0.3706493  0.\n",
      "  0.49678436 0.         0.         0.3527293  0.         0.5716634\n",
      "  0.         0.10628545 0.72115386 0.04926314 0.         0.\n",
      "  0.         0.         0.         0.33677027 0.         0.\n",
      "  0.85709614 0.61171424 0.         0.         0.51385736 0.\n",
      "  0.         1.0521429  0.         0.40071902 0.12244059 0.\n",
      "  0.         0.4877057  0.7029513  0.9388041  0.         0.37355983\n",
      "  0.         0.84806687 0.4054352  0.57964087 0.83906096 0.5954554\n",
      "  0.         0.3042898  0.20527333 0.         0.         0.\n",
      "  0.         0.59587973 1.2464592  0.        ]]\n",
      "Hi!\n",
      "[[0.02467041 0.14601108 0.21687801 0.         0.         0.22864635\n",
      "  0.00894674 0.11507876 0.         0.13835879 0.20655657 0.\n",
      "  0.         0.06366825 0.         0.         0.         0.04248037\n",
      "  0.         0.25335035 0.11879377 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07385057 0.10967185 0.         0.         0.\n",
      "  0.         0.         0.11454471 0.1614913  0.         0.\n",
      "  0.         0.         0.12188625 0.3239853  0.         0.09468393\n",
      "  0.20894232 0.11639536 0.         0.20294932 0.14816308 0.30524316\n",
      "  0.         0.17827196 0.         0.         0.04446255 0.\n",
      "  0.03508599 0.06710741 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.02997923 0.         0.11142261 0.         0.         0.\n",
      "  0.18521607 0.15759411 0.08577842 0.19304784 0.14416872 0.\n",
      "  0.         0.         0.         0.09538671 0.         0.09670683\n",
      "  0.         0.0703387  0.1730389  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11108724 0.         0.         0.\n",
      "  0.         0.         0.04454667 0.16397431 0.         0.\n",
      "  0.         0.         0.04995089 0.3055972  0.         0.\n",
      "  0.09499678 0.0071563  0.00498094 0.20068556 0.         0.04916874\n",
      "  0.         0.22004192 0.         0.         0.         0.\n",
      "  0.06650278 0.1922082  0.         0.00753756]]\n",
      "Hi!\n",
      "[[0.5604583  0.43373746 1.791447   0.         0.         0.70074475\n",
      "  0.2820765  0.10307581 1.6268436  0.         0.842003   0.\n",
      "  0.94844425 0.         0.         1.0726128  0.5581423  1.0687449\n",
      "  0.662529   0.         1.4992135  0.40205613 0.         0.46665186\n",
      "  0.25018162 0.         0.         0.         0.         0.\n",
      "  0.07233306 0.17978212 0.         0.         0.08081835 0.\n",
      "  0.5295039  1.1481602  0.         1.0371492  0.1509109  0.\n",
      "  0.         1.0377707  0.         0.         0.         1.0283751\n",
      "  0.         1.0068027  1.025825   0.05051751 0.16658801 0.13055995\n",
      "  0.         0.         0.         0.82090646 0.08341332 0.\n",
      "  0.         1.0754943  1.3215151  1.3265097 ]]\n",
      "Hi!\n",
      "[[0.00802733 0.2013664  0.25381443 0.         0.         0.24071448\n",
      "  0.40423274 0.22314563 0.3155918  0.1818519  0.23427    0.\n",
      "  0.         0.         0.         0.07944126 0.         0.20837224\n",
      "  0.         0.26885647 0.34919798 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08235384 0.         0.         0.\n",
      "  0.         0.0713871  0.         0.29961324 0.         0.\n",
      "  0.         0.15467887 0.         0.31904066 0.         0.02514473\n",
      "  0.         0.3102012  0.24945743 0.14237192 0.10482774 0.06017772\n",
      "  0.         0.05837716 0.         0.         0.00898484 0.\n",
      "  0.09220811 0.41440547 0.         0.11474893]]\n",
      "Hi!\n",
      "[[0.15659244 0.38163728 0.09378764 0.1049659  0.         0.31093702\n",
      "  0.21944387 0.499633   0.         0.08261137 0.1284615  0.\n",
      "  0.09765644 0.43064937 0.         0.         0.         0.19821954\n",
      "  0.         0.47367713 0.09505448 0.         0.         0.08392105\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3471865  0.3574527  0.27940103 0.         0.         0.\n",
      "  0.         0.02978421 0.32168362 0.22388653 0.         0.\n",
      "  0.         0.         0.6004909  0.76653594 0.         0.\n",
      "  0.3129182  0.4944693  0.         0.3261781  0.43566298 0.5944915\n",
      "  0.         0.3182801  0.07044853 0.         0.         0.\n",
      "  0.10175463 0.32311064 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.04570122 0.06857466 0.         0.         0.15166688\n",
      "  0.23127605 0.22932331 0.07341334 0.2161343  0.21025798 0.\n",
      "  0.         0.         0.         0.06189468 0.         0.0663876\n",
      "  0.         0.16164982 0.17097422 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08447742 0.         0.         0.\n",
      "  0.         0.03538956 0.03972587 0.18789239 0.         0.\n",
      "  0.         0.00676148 0.00875581 0.37407693 0.         0.\n",
      "  0.06916933 0.11700667 0.00445754 0.19079396 0.11280899 0.21037418\n",
      "  0.         0.17743684 0.         0.         0.02675571 0.\n",
      "  0.06811457 0.2616609  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.09009909 0.02818514 0.         0.         0.00329807\n",
      "  0.06505314 0.17181942 0.05615569 0.05238333 0.06374035 0.\n",
      "  0.04340747 0.1526811  0.         0.09382271 0.         0.05340141\n",
      "  0.         0.04008828 0.12565775 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01331346 0.08788716 0.18578662 0.         0.         0.\n",
      "  0.         0.         0.1518654  0.01314062 0.         0.\n",
      "  0.         0.         0.20661372 0.22406432 0.         0.00596926\n",
      "  0.08249289 0.02906935 0.         0.13862288 0.         0.26107374\n",
      "  0.         0.04348988 0.08477579 0.         0.         0.\n",
      "  0.05503012 0.09061358 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4287092  0.8517489  1.0192931  0.         0.         0.7490092\n",
      "  0.         0.18888618 0.1751629  0.         0.47373432 0.\n",
      "  0.6626045  0.         0.         0.01977539 0.         0.521938\n",
      "  0.         0.8428481  0.58254915 0.         0.         0.09460668\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.438846   0.6539467  0.         0.         0.00133567 0.\n",
      "  0.         0.19465986 0.21312052 0.51192045 0.         0.\n",
      "  0.         0.         0.5403374  0.5410759  0.         0.425535\n",
      "  0.4847853  0.7772203  0.13273525 0.4359434  0.69716746 0.7390015\n",
      "  0.         0.58635205 0.         0.         0.11330977 0.\n",
      "  0.09539679 0.38868776 0.39490914 0.10090937]]\n",
      "Hi!\n",
      "[[0.6121269  0.10366965 0.         0.6005948  0.         0.5759619\n",
      "  1.4460207  1.751861   0.         0.         0.05826417 0.\n",
      "  0.58849657 0.98716074 0.         0.17020297 0.         0.3908217\n",
      "  0.         0.26114744 0.12756844 0.22029026 0.         0.10834197\n",
      "  0.         0.         0.         0.82817054 0.         0.\n",
      "  1.4851937  0.855153   0.52718914 0.         0.71472514 0.\n",
      "  0.03306883 0.9406593  0.30426583 0.22813745 0.22119695 0.\n",
      "  0.         0.43754023 1.5717136  1.6095726  0.         0.17369987\n",
      "  0.1726041  0.9910451  0.13165691 0.7615991  0.9165727  1.0387902\n",
      "  0.         0.26391837 0.4915788  0.         0.         0.\n",
      "  0.         0.39327198 0.62307656 0.        ]]\n",
      "Hi!\n",
      "[[0.22111021 0.         0.         0.1465265  0.         0.\n",
      "  0.82606274 0.74526834 0.26488614 0.         0.         0.\n",
      "  0.14861244 0.5173639  0.         0.3461294  0.         0.19556051\n",
      "  0.         0.         0.12280562 0.         0.         0.\n",
      "  0.00908508 0.         0.         0.41313878 0.         0.\n",
      "  0.50939155 0.34688392 0.45883635 0.         0.16961835 0.\n",
      "  0.32572538 0.33182007 0.59575677 0.         0.         0.\n",
      "  0.         0.437943   0.54462814 0.67054194 0.         0.21777928\n",
      "  0.14726552 0.3290636  0.07772742 0.23986743 0.         0.70485806\n",
      "  0.         0.13582115 0.29166806 0.         0.         0.\n",
      "  0.         0.36270168 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.29805496 0.22389983 0.8756218  0.         0.         0.7640731\n",
      "  0.54679424 0.8790497  0.9293293  0.         0.46323586 0.\n",
      "  0.75243545 0.         0.         0.4942263  0.         0.6943384\n",
      "  0.13094115 0.         0.87442446 0.         0.         0.22855465\n",
      "  0.         0.         0.         0.17235418 0.         0.\n",
      "  0.6403922  0.3904252  0.         0.         0.2927209  0.\n",
      "  0.         0.90130764 0.         0.48891988 0.0498723  0.\n",
      "  0.         0.59199417 0.21205796 0.5504127  0.         0.42961723\n",
      "  0.         0.84687877 0.5912756  0.41701302 0.71110475 0.24706417\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.733259   1.0444324  0.4812751 ]]\n",
      "Hi!\n",
      "[[0.63682115 0.5880351  0.4185869  0.08092217 0.         0.6370586\n",
      "  0.41220737 0.8157641  0.09178744 0.         0.31607258 0.\n",
      "  1.0182974  0.53743863 0.         0.2081897  0.         0.4861149\n",
      "  0.00844798 0.5489448  0.3958473  0.         0.         0.128504\n",
      "  0.         0.         0.         0.42300743 0.         0.\n",
      "  1.0185891  0.84347767 0.         0.         0.3933566  0.\n",
      "  0.21462092 0.74658203 0.2776398  0.2658854  0.         0.\n",
      "  0.         0.21686248 1.1504399  0.90282595 0.         0.63602567\n",
      "  0.17056577 0.7315582  0.32152447 0.5131069  0.560294   1.0528901\n",
      "  0.         0.18297628 0.37307674 0.         0.         0.\n",
      "  0.         0.25517738 0.78395957 0.        ]]\n",
      "Hi!\n",
      "[[0.637577   0.13049227 1.1059073  0.         0.         0.73464215\n",
      "  0.23634952 0.26196256 0.5487249  0.08047703 0.4195022  0.\n",
      "  0.         0.         0.         0.16685687 0.3666102  0.61411184\n",
      "  0.         0.34297794 0.7977627  0.         0.         0.24078427\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18086717 0.04523468 0.         0.         0.\n",
      "  0.         0.4716698  0.         0.61725867 0.         0.\n",
      "  0.         0.48123264 0.         0.31993398 0.         0.47632653\n",
      "  0.1955169  0.6013804  0.23385142 0.20815748 0.25425902 0.25308764\n",
      "  0.         0.6431741  0.         0.15853283 0.03015114 0.\n",
      "  0.17369296 0.6808828  0.49918056 0.37889045]]\n",
      "Hi!\n",
      "[[0.02214951 0.14912196 0.07695115 0.         0.         0.14076106\n",
      "  0.01766397 0.1726271  0.         0.0503785  0.1083381  0.\n",
      "  0.06984481 0.18942644 0.         0.         0.         0.03699329\n",
      "  0.         0.1594423  0.05625159 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03039216 0.1431949  0.17210229 0.         0.         0.\n",
      "  0.         0.         0.18033203 0.0643442  0.         0.\n",
      "  0.         0.         0.23630393 0.33479327 0.         0.01845725\n",
      "  0.1640195  0.11739745 0.         0.19315882 0.05018343 0.4231501\n",
      "  0.         0.1630245  0.05820106 0.         0.         0.\n",
      "  0.03544446 0.05998199 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0663075  0.15510502 1.9273051  0.         0.         1.0945774\n",
      "  0.1207667  0.2372457  1.0422155  0.         0.6981736  0.\n",
      "  0.         0.         0.         0.49539503 0.8879374  0.85381943\n",
      "  0.         0.25520745 1.3623037  0.30653766 0.         0.5379524\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20028311 0.04559934 0.         0.         0.\n",
      "  0.         0.6406645  0.         1.0129355  0.         0.\n",
      "  0.         1.0696373  0.         0.23892754 0.         0.65401316\n",
      "  0.20318556 0.8104169  0.5246987  0.11844063 0.40580148 0.24705747\n",
      "  0.         0.8741686  0.         0.65336716 0.07080142 0.\n",
      "  0.17538609 0.834179   0.89240485 0.7765663 ]]\n",
      "Hi!\n",
      "[[0.18107076 0.49645615 1.0603508  0.         0.         0.5412334\n",
      "  0.         0.         0.5819141  0.08218256 0.47124004 0.\n",
      "  0.28968763 0.         0.         0.21928075 0.33184758 0.15962674\n",
      "  0.         0.54215264 0.5873386  0.         0.         0.07119961\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10322412 0.07184555 0.         0.         0.\n",
      "  0.         0.         0.         0.49272138 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.52529484\n",
      "  0.18985036 0.29004595 0.42015556 0.10856862 0.35112348 0.32916325\n",
      "  0.         0.13738337 0.         0.16558492 0.2700872  0.\n",
      "  0.21644418 0.12487449 0.36586875 0.5140766 ]]\n",
      "Hi!\n",
      "[[0.4229849  0.11259325 0.801124   0.         0.         0.722835\n",
      "  0.         0.18831404 0.13018253 0.0461086  0.25409642 0.\n",
      "  0.         0.         0.         0.00707877 0.09376929 0.\n",
      "  0.         0.5498288  0.33345562 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.32909065 0.2306825  0.         0.         0.\n",
      "  0.         0.00880984 0.12213186 0.333712   0.         0.\n",
      "  0.         0.         0.22741687 0.4172243  0.         0.4610884\n",
      "  0.34110805 0.19117194 0.05249107 0.5680658  0.3874752  0.70860887\n",
      "  0.         0.7621786  0.         0.         0.02593668 0.\n",
      "  0.         0.         0.504682   0.        ]]\n",
      "Hi!\n",
      "[[0.7336041  0.         1.3972975  0.         0.         0.70608246\n",
      "  1.0071971  0.99127406 1.3537787  0.         0.6021738  0.\n",
      "  0.         0.         0.         0.79352134 0.64902776 0.94061863\n",
      "  0.         0.         1.2742335  0.47922167 0.         0.5761321\n",
      "  0.01417855 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06763621 0.         0.18982325 0.\n",
      "  0.04997854 1.1613683  0.         0.81151974 0.12059856 0.\n",
      "  0.         1.6076907  0.         0.16901535 0.         0.31943384\n",
      "  0.         0.70423114 0.6448073  0.04506413 0.36156756 0.\n",
      "  0.         0.24896298 0.         0.62393045 0.         0.\n",
      "  0.         1.2883694  1.209674   0.57454103]]\n",
      "Hi!\n",
      "[[0.41298506 0.         0.5953956  0.18017057 0.         0.74255925\n",
      "  1.1738769  1.2832487  0.50851566 0.         0.32085264 0.\n",
      "  0.         0.         0.         0.3747588  0.         0.68128127\n",
      "  0.         0.         0.6687142  0.         0.         0.15573479\n",
      "  0.         0.         0.         0.19507274 0.         0.\n",
      "  0.6160719  0.3749154  0.07784095 0.         0.37279445 0.\n",
      "  0.         0.9675824  0.         0.5185352  0.08445909 0.\n",
      "  0.         0.7333182  0.3556676  0.8592279  0.         0.\n",
      "  0.         0.9817963  0.27588484 0.36929822 0.690507   0.15154247\n",
      "  0.         0.22936948 0.         0.         0.         0.\n",
      "  0.         0.9057805  0.96653867 0.        ]]\n",
      "Hi!\n",
      "[[0.6432253  1.2164603  1.1738296  0.         0.         0.54928386\n",
      "  0.         0.21513666 0.9919686  0.         0.66239935 0.\n",
      "  1.943384   0.04639081 0.         0.74537367 0.         0.78212583\n",
      "  1.0131397  0.60995346 0.9451581  0.         0.         0.09857486\n",
      "  0.2551743  0.         0.         0.38973996 0.         0.\n",
      "  0.9070333  0.8306605  0.         0.         0.41886288 0.\n",
      "  0.6121605  0.9206722  0.33363345 0.69191515 0.         0.\n",
      "  0.         0.3112813  0.81292695 0.06315367 0.         1.277503\n",
      "  0.         0.816787   1.0112079  0.40640152 0.42139387 1.0933635\n",
      "  0.         0.         0.29892102 0.         0.10686357 0.\n",
      "  0.         0.5225054  1.2221234  0.8025041 ]]\n",
      "Hi!\n",
      "[[0.         0.07386232 0.1777066  0.         0.         0.18584125\n",
      "  0.05587558 0.14817497 0.04866261 0.1369225  0.12901397 0.\n",
      "  0.         0.01350335 0.         0.0157311  0.         0.04651992\n",
      "  0.         0.1588216  0.09776563 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13212438 0.         0.         0.\n",
      "  0.         0.         0.05997786 0.15112562 0.         0.\n",
      "  0.         0.         0.11083391 0.3274874  0.         0.05337917\n",
      "  0.13894926 0.08167489 0.         0.2392508  0.05523822 0.2446737\n",
      "  0.         0.16775328 0.         0.         0.         0.\n",
      "  0.06721777 0.13824332 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.46527693 0.5721297  1.017065   0.         0.         1.024986\n",
      "  0.07678116 0.6229866  0.16793132 0.         0.42809305 0.\n",
      "  0.63564706 0.         0.         0.         0.         0.3689442\n",
      "  0.         0.7843283  0.6960932  0.         0.         0.08786644\n",
      "  0.         0.         0.         0.03152608 0.         0.\n",
      "  0.6155992  0.7284895  0.         0.         0.00890349 0.\n",
      "  0.         0.33632228 0.03411366 0.42579794 0.         0.\n",
      "  0.         0.         0.6749791  0.7548345  0.         0.37167764\n",
      "  0.47927177 0.92613834 0.07039986 0.60083675 0.9891155  0.78608304\n",
      "  0.         0.8840253  0.         0.         0.07078455 0.\n",
      "  0.         0.24874471 0.7887325  0.        ]]\n",
      "Hi!\n",
      "[[0.98771375 0.14407755 1.8862022  0.         0.         0.94558585\n",
      "  0.2950473  0.3226742  1.1882586  0.         0.72593683 0.\n",
      "  0.         0.         0.         0.6197198  0.85787207 0.8741564\n",
      "  0.         0.04443811 1.4365354  0.33014044 0.         0.719276\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12508601 0.10886007 0.         0.         0.\n",
      "  0.         0.68597895 0.         0.99582285 0.04112252 0.\n",
      "  0.         1.2225175  0.         0.11577018 0.         0.41006473\n",
      "  0.0632479  0.9329882  0.5955924  0.12296245 0.5111381  0.02258318\n",
      "  0.         0.7859563  0.         0.64892465 0.05514849 0.\n",
      "  0.02237    0.95756847 0.917109   0.7735039 ]]\n",
      "Hi!\n",
      "[[0.18272208 0.55456924 0.636293   0.         0.         0.54370046\n",
      "  0.         0.         0.06416453 0.05456411 0.32055682 0.\n",
      "  0.22196136 0.03706456 0.         0.         0.         0.23059775\n",
      "  0.         0.69845635 0.3013832  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06071838 0.3414004  0.         0.         0.         0.\n",
      "  0.         0.         0.07472292 0.34305617 0.         0.\n",
      "  0.         0.         0.2737798  0.37877804 0.         0.40488052\n",
      "  0.5311142  0.41312826 0.         0.36256322 0.2938145  0.6477005\n",
      "  0.         0.49757615 0.         0.         0.09624602 0.\n",
      "  0.277216   0.19587313 0.03691923 0.1534954 ]]\n",
      "Hi!\n",
      "[[0.03927391 0.328211   0.34902185 0.         0.         0.2811638\n",
      "  0.         0.01944854 0.11062699 0.07974338 0.22959507 0.\n",
      "  0.10846521 0.00780377 0.         0.04940433 0.         0.18335973\n",
      "  0.         0.41196725 0.20344439 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08495718 0.01277795 0.         0.         0.\n",
      "  0.         0.         0.         0.17659543 0.         0.\n",
      "  0.         0.         0.04127138 0.2594319  0.         0.17821515\n",
      "  0.2604722  0.21214393 0.01488707 0.17727351 0.0271646  0.31083205\n",
      "  0.         0.16424124 0.         0.         0.09717884 0.\n",
      "  0.19993359 0.17853229 0.         0.13047801]]\n",
      "Hi!\n",
      "[[0.3146076  0.         0.44717097 0.27904814 0.         0.65956825\n",
      "  2.434625   2.21195    1.1385428  0.         0.35890582 0.\n",
      "  0.00506585 0.         0.         1.0054553  0.         0.9122857\n",
      "  0.13353354 0.         0.7371672  0.49539134 0.         0.\n",
      "  0.36379394 0.         0.         0.645252   0.         0.\n",
      "  1.0385443  0.10703664 0.         0.         1.0227525  0.\n",
      "  0.4947193  1.8195875  0.         0.45569462 0.54192406 0.\n",
      "  0.         1.836965   0.55239934 0.90695167 0.         0.19501539\n",
      "  0.         0.8103131  0.7595588  0.40352967 0.40720218 0.\n",
      "  0.         0.         0.47336262 0.14802802 0.         0.\n",
      "  0.         1.2479317  1.5863256  0.        ]]\n",
      "Hi!\n",
      "[[0.43976036 0.55929834 0.5776816  0.         0.         0.55371356\n",
      "  0.10508757 0.22785427 0.         0.         0.24198824 0.\n",
      "  0.5566706  0.22588448 0.         0.09514811 0.         0.37048838\n",
      "  0.         0.66194457 0.26179287 0.         0.         0.09560627\n",
      "  0.         0.         0.         0.22105697 0.         0.\n",
      "  0.50022763 0.6375352  0.0164869  0.         0.04192381 0.\n",
      "  0.04411615 0.32748494 0.24987887 0.31275716 0.         0.\n",
      "  0.         0.02555041 0.6723138  0.6635095  0.         0.58751506\n",
      "  0.3891683  0.50748783 0.06292826 0.3540512  0.28626317 0.87090373\n",
      "  0.         0.4579757  0.18445893 0.         0.         0.\n",
      "  0.06521428 0.19940592 0.39552954 0.        ]]\n",
      "Hi!\n",
      "[[0.4169336  0.5245148  0.17364305 0.         0.         0.31683818\n",
      "  0.77240705 1.1033238  0.7247697  0.         0.36320394 0.\n",
      "  1.4694835  0.6370963  0.         0.7667754  0.         0.6996205\n",
      "  0.69593483 0.11413001 0.5046897  0.11584488 0.         0.\n",
      "  0.36393505 0.         0.         0.58240855 0.         0.\n",
      "  1.2221663  0.5581264  0.         0.         0.8042185  0.\n",
      "  0.55375177 1.249187   0.         0.26287547 0.05161021 0.\n",
      "  0.         0.3790663  1.0137578  0.65804607 0.         0.7928392\n",
      "  0.         0.70110166 0.90078497 0.34074268 0.45294136 0.7276528\n",
      "  0.         0.         0.46196067 0.         0.         0.\n",
      "  0.         0.5421645  0.9732759  0.21893716]]\n",
      "Hi!\n",
      "[[0.06168236 0.23001304 0.35154998 0.         0.         0.22558618\n",
      "  0.         0.         0.16899936 0.08319625 0.23621288 0.\n",
      "  0.11438885 0.         0.         0.03608977 0.         0.02079624\n",
      "  0.         0.3106842  0.20400572 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06547812 0.01624956 0.         0.         0.\n",
      "  0.         0.         0.05239382 0.1840289  0.         0.\n",
      "  0.         0.         0.01921001 0.16893321 0.         0.19887868\n",
      "  0.19203229 0.08586679 0.01467338 0.20519614 0.07321496 0.31283605\n",
      "  0.         0.0532326  0.         0.         0.11030927 0.\n",
      "  0.05196516 0.0228717  0.         0.07321627]]\n",
      "Hi!\n",
      "[[0.13026404 0.         0.67712235 0.         0.         0.6041316\n",
      "  1.2894405  1.4195513  1.2254759  0.         0.44302985 0.\n",
      "  0.65054625 0.         0.         0.9189199  0.         0.8006734\n",
      "  0.47202173 0.         0.8867582  0.08241217 0.         0.0722143\n",
      "  0.24762882 0.         0.         0.42756248 0.         0.\n",
      "  0.8452735  0.23640792 0.         0.         0.69835365 0.\n",
      "  0.3425584  1.4676851  0.         0.38793987 0.24230894 0.\n",
      "  0.         1.2204808  0.28926864 0.5422767  0.         0.4489733\n",
      "  0.         0.662236   0.8582596  0.3689824  0.4458877  0.01593263\n",
      "  0.         0.         0.25199318 0.15207452 0.         0.\n",
      "  0.         0.9776998  1.462481   0.40559885]]\n",
      "Hi!\n",
      "[[0.         0.05113171 0.00317339 0.         0.         0.00990322\n",
      "  0.20496947 0.26692635 0.01037939 0.07698386 0.08156042 0.\n",
      "  0.         0.12424539 0.         0.05068807 0.         0.07726587\n",
      "  0.         0.03376463 0.11556339 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02421799 0.05321494 0.14581041 0.         0.         0.\n",
      "  0.         0.         0.1364093  0.12647    0.         0.\n",
      "  0.         0.         0.20195358 0.40418175 0.         0.\n",
      "  0.16365199 0.12906045 0.         0.2234652  0.09451734 0.24201442\n",
      "  0.         0.16230333 0.         0.         0.         0.\n",
      "  0.06697085 0.21181484 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07282545 0.2801836  0.         0.         0.24024463\n",
      "  0.         0.01139922 0.270266   0.14149714 0.2376171  0.\n",
      "  0.         0.         0.         0.17518829 0.         0.00763517\n",
      "  0.         0.17367132 0.25580585 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06516084 0.         0.         0.\n",
      "  0.         0.         0.         0.1900551  0.         0.\n",
      "  0.         0.         0.         0.15722638 0.         0.2311038\n",
      "  0.04731373 0.04930272 0.03362195 0.14337927 0.         0.21260704\n",
      "  0.         0.03253354 0.         0.         0.05364874 0.\n",
      "  0.00241283 0.08550347 0.         0.07239827]]\n",
      "Hi!\n",
      "[[2.44212113e-02 3.38740379e-01 2.55650759e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.93675488e-01 0.00000000e+00 1.37432860e-02\n",
      "  5.93725853e-02 3.03480662e-02 2.04150870e-01 0.00000000e+00\n",
      "  2.34045327e-01 1.11489341e-01 0.00000000e+00 1.76275671e-02\n",
      "  0.00000000e+00 9.27885026e-02 0.00000000e+00 3.26420993e-01\n",
      "  1.66099176e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.04737766e-01 1.35749713e-01\n",
      "  4.00486551e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.01987384e-01 9.27292705e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.34415746e-01 2.13646173e-01 0.00000000e+00 1.44953474e-01\n",
      "  2.02727854e-01 1.46674529e-01 3.58944351e-04 1.55125499e-01\n",
      "  7.57423043e-02 3.89066249e-01 0.00000000e+00 6.58053765e-03\n",
      "  5.77845983e-02 0.00000000e+00 7.40412250e-02 0.00000000e+00\n",
      "  9.03454795e-02 9.38420743e-02 0.00000000e+00 1.97294038e-02]]\n",
      "Hi!\n",
      "[[0.5901152  0.         1.0190368  0.         0.         0.53719294\n",
      "  1.0825876  1.019157   1.1233362  0.         0.53922135 0.\n",
      "  0.         0.         0.         0.6737927  0.4433041  0.93415004\n",
      "  0.         0.         0.9603673  0.4478733  0.         0.3755684\n",
      "  0.00946426 0.         0.         0.         0.         0.\n",
      "  0.03167143 0.         0.13995637 0.         0.2664959  0.\n",
      "  0.         1.0397762  0.         0.7357233  0.06831439 0.\n",
      "  0.         1.5321461  0.         0.27960387 0.         0.01722758\n",
      "  0.         0.8390123  0.60562503 0.         0.26040015 0.\n",
      "  0.         0.         0.         0.37232065 0.         0.\n",
      "  0.         1.3311946  0.7343256  0.38653672]]\n",
      "Hi!\n",
      "[[0.5797921  1.1270183  0.62506783 0.         0.         0.41130686\n",
      "  0.14089562 0.61832666 1.0301692  0.         0.51385593 0.\n",
      "  2.3150737  0.5792778  0.         0.9132109  0.         0.79569983\n",
      "  1.3776296  0.34294644 0.76510066 0.13824813 0.         0.13558345\n",
      "  0.51208127 0.         0.         0.6245036  0.         0.\n",
      "  1.1727872  0.9084179  0.         0.         0.67229354 0.\n",
      "  0.8884184  1.1645699  0.3136931  0.50252146 0.07684266 0.\n",
      "  0.         0.51920336 1.097537   0.3092047  0.         1.4406786\n",
      "  0.         0.88643754 1.1985056  0.3669022  0.38481975 1.2273142\n",
      "  0.         0.         0.57267314 0.         0.         0.\n",
      "  0.         0.371641   1.1236582  0.72544664]]\n",
      "Hi!\n",
      "[[0.35402128 0.01795118 0.         0.27996507 0.         0.4476675\n",
      "  1.5287079  1.7372669  0.44600165 0.         0.1945701  0.\n",
      "  0.8921328  0.65940803 0.         0.5812655  0.         0.6442744\n",
      "  0.16459471 0.         0.33854964 0.29524368 0.         0.\n",
      "  0.3343425  0.         0.         0.7385999  0.         0.\n",
      "  1.3886175  0.5407714  0.09812085 0.         0.9149445  0.\n",
      "  0.30534598 1.3780696  0.         0.2236969  0.243244   0.\n",
      "  0.         0.5395184  1.1505176  1.1873673  0.         0.3158147\n",
      "  0.         0.9155386  0.6672726  0.5649605  0.6537265  0.7095169\n",
      "  0.         0.         0.44086292 0.         0.         0.\n",
      "  0.         0.6409789  0.99492884 0.        ]]\n",
      "Hi!\n",
      "[[0.20578353 0.         0.35539865 0.21113816 0.         0.6455372\n",
      "  1.7420257  1.713642   0.78370774 0.         0.32188985 0.\n",
      "  0.4038888  0.         0.         0.7100855  0.         0.7818589\n",
      "  0.09962691 0.         0.64266217 0.21319085 0.         0.\n",
      "  0.26626053 0.         0.         0.55080277 0.         0.\n",
      "  1.0698528  0.30710217 0.         0.         0.9016998  0.\n",
      "  0.22095864 1.4796748  0.         0.28294092 0.33413553 0.\n",
      "  0.         1.032168   0.71707946 0.965404   0.         0.26419425\n",
      "  0.         0.76736385 0.56581223 0.44442672 0.59894776 0.19162835\n",
      "  0.         0.         0.3771583  0.         0.         0.\n",
      "  0.         0.9412141  1.3927044  0.        ]]\n",
      "Hi!\n",
      "[[0.44774574 0.         0.4175506  0.39854547 0.         0.881201\n",
      "  1.4201537  1.5488561  0.10350695 0.         0.21194045 0.\n",
      "  0.         0.0387654  0.         0.13009362 0.         0.4504793\n",
      "  0.         0.12767741 0.47176704 0.00205889 0.         0.\n",
      "  0.         0.         0.         0.33655494 0.         0.\n",
      "  0.89051956 0.6170303  0.20476785 0.         0.49963203 0.\n",
      "  0.         0.911894   0.         0.39764735 0.16839138 0.\n",
      "  0.         0.52242893 0.8584016  1.2058672  0.         0.\n",
      "  0.04722745 0.97804224 0.01090517 0.62380815 0.8537808  0.47811812\n",
      "  0.         0.59202045 0.14428219 0.         0.         0.\n",
      "  0.         0.6223072  0.96683544 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.22642152 0.24215111 0.         0.         0.22110161\n",
      "  0.         0.04595334 0.04098847 0.10278856 0.16822487 0.\n",
      "  0.11199505 0.06706082 0.         0.00842894 0.         0.08450919\n",
      "  0.         0.26635733 0.13097563 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00446969 0.10573133 0.03768876 0.         0.         0.\n",
      "  0.         0.         0.01778419 0.11850396 0.         0.\n",
      "  0.         0.         0.1289811  0.22865017 0.         0.14450341\n",
      "  0.1882555  0.13605516 0.         0.14764936 0.0729514  0.27547395\n",
      "  0.         0.12106069 0.00140186 0.         0.06100219 0.\n",
      "  0.11632737 0.08784358 0.         0.03177886]]\n",
      "Hi!\n",
      "[[0.03907568 0.24906057 0.2607817  0.         0.         0.10743702\n",
      "  0.         0.02346667 0.06593268 0.         0.10264739 0.\n",
      "  0.18513678 0.0506109  0.         0.06101425 0.         0.01576448\n",
      "  0.         0.22233959 0.12877858 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2126142  0.07046689 0.         0.         0.\n",
      "  0.         0.         0.16420738 0.11378849 0.         0.\n",
      "  0.         0.         0.13061178 0.15925187 0.         0.13499595\n",
      "  0.20599675 0.09626261 0.         0.24707395 0.03426455 0.40927193\n",
      "  0.         0.10594069 0.03634494 0.         0.00903935 0.\n",
      "  0.0710443  0.02975225 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.12648562 0.13070779 0.21036014 0.00781535 0.         0.3472281\n",
      "  0.14890294 0.31104964 0.         0.05521454 0.12493657 0.\n",
      "  0.         0.24977487 0.         0.         0.         0.04202152\n",
      "  0.         0.31956428 0.02392256 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10233629 0.24022147 0.2337896  0.         0.         0.\n",
      "  0.         0.00836128 0.22389394 0.16966107 0.         0.\n",
      "  0.         0.         0.38359106 0.66799146 0.         0.07535385\n",
      "  0.29798436 0.30540687 0.         0.342      0.20946273 0.54863226\n",
      "  0.         0.3635643  0.08017461 0.         0.         0.\n",
      "  0.07305784 0.06026612 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.8236714  0.         1.1434219  0.21062624 0.         0.92756253\n",
      "  1.0220286  1.1436836  0.7845507  0.01827126 0.43094078 0.\n",
      "  0.         0.         0.         0.36392602 0.36316222 0.70258564\n",
      "  0.         0.         0.9683085  0.11407777 0.         0.5711035\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1097841  0.23320976 0.17384616 0.         0.06089561 0.\n",
      "  0.         0.82266384 0.         0.80910844 0.02382071 0.\n",
      "  0.         1.1400386  0.         0.6088503  0.         0.\n",
      "  0.         0.9926605  0.26283586 0.28967127 0.7625678  0.\n",
      "  0.         0.819633   0.         0.05187248 0.         0.\n",
      "  0.         1.0316919  1.0322931  0.05498415]]\n",
      "Hi!\n",
      "[[0.4288309  0.01964428 0.7406085  0.19814466 0.         0.8297861\n",
      "  0.9318071  1.088149   0.33485937 0.         0.34484914 0.\n",
      "  0.24071237 0.         0.         0.22976355 0.         0.51579756\n",
      "  0.         0.25230664 0.6422224  0.         0.         0.\n",
      "  0.         0.         0.         0.18269663 0.         0.\n",
      "  0.6494242  0.5624014  0.02573692 0.         0.2974563  0.\n",
      "  0.         0.8816993  0.         0.43467832 0.05183765 0.\n",
      "  0.         0.38575906 0.6488497  0.8273404  0.         0.30719367\n",
      "  0.05785754 0.8051641  0.23410206 0.49606246 0.67319846 0.5016579\n",
      "  0.         0.5177464  0.10549341 0.         0.         0.\n",
      "  0.         0.5847614  1.0403521  0.        ]]\n",
      "Hi!\n",
      "[[0.15554053 1.1832353  1.4979074  0.         0.         0.5155298\n",
      "  0.09928937 0.         1.4494114  0.         0.75023806 0.\n",
      "  1.7511665  0.         0.         0.8298088  0.28368235 0.8231328\n",
      "  0.99951404 0.61834586 1.2305523  0.19255506 0.         0.02102315\n",
      "  0.21731034 0.         0.         0.09143724 0.         0.\n",
      "  0.35998082 0.3813029  0.         0.         0.2795857  0.\n",
      "  0.21701099 0.8313025  0.         0.82168764 0.05370398 0.\n",
      "  0.         0.08528478 0.02032522 0.         0.         1.1756076\n",
      "  0.         1.0533724  1.1754729  0.         0.2315475  0.5134404\n",
      "  0.         0.         0.12457556 0.28434524 0.21214637 0.\n",
      "  0.         0.7953738  1.0247914  1.1996065 ]]\n",
      "Hi!\n",
      "[[0.33015415 0.         0.43985456 0.04858571 0.         0.42942604\n",
      "  0.96573615 0.79548293 0.39938036 0.05276627 0.2501568  0.\n",
      "  0.         0.         0.         0.24215262 0.         0.6361317\n",
      "  0.         0.05742011 0.4494424  0.00269919 0.         0.03063099\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.28344962 0.12899944 0.06522474 0.         0.27093562 0.\n",
      "  0.         0.7397303  0.         0.41349894 0.         0.\n",
      "  0.         0.6300702  0.16113448 0.5638457  0.         0.10349993\n",
      "  0.02999904 0.7499776  0.23031211 0.22567952 0.33170977 0.12285602\n",
      "  0.         0.11589967 0.         0.         0.         0.\n",
      "  0.         0.95022833 0.37869042 0.04297991]]\n",
      "Hi!\n",
      "[[0.61469513 1.1324375  0.6800208  0.         0.         0.38467598\n",
      "  0.05829955 0.69230354 0.97457343 0.         0.5498331  0.\n",
      "  2.3677125  0.5869744  0.         0.7954643  0.         0.68281376\n",
      "  1.3049176  0.30467907 0.7427402  0.09004277 0.         0.2071099\n",
      "  0.3128792  0.         0.         0.6637947  0.         0.\n",
      "  1.3068137  0.9426569  0.         0.         0.59633213 0.\n",
      "  0.6629582  1.0724804  0.42946756 0.36049628 0.08507352 0.\n",
      "  0.         0.45765832 1.0609665  0.40606505 0.         1.1774993\n",
      "  0.         0.86451936 1.1433663  0.39197242 0.65151393 1.168933\n",
      "  0.         0.         0.5147887  0.         0.         0.\n",
      "  0.         0.36042106 1.2643753  0.65922076]]\n",
      "Hi!\n",
      "[[0.         0.02020067 0.         0.00935441 0.         0.06196481\n",
      "  0.11443691 0.33916917 0.03229446 0.09901828 0.05611236 0.\n",
      "  0.         0.05352825 0.         0.10466451 0.         0.1031237\n",
      "  0.         0.11457868 0.06777645 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06371525 0.23241545 0.         0.         0.\n",
      "  0.         0.01340002 0.01775701 0.13884032 0.         0.\n",
      "  0.         0.         0.14116257 0.4790704  0.         0.\n",
      "  0.24875325 0.23909897 0.         0.24258767 0.03582032 0.26706812\n",
      "  0.         0.21738176 0.         0.         0.         0.\n",
      "  0.1282351  0.22499618 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.09028457 0.2801044  0.1873434  0.         0.         0.17299502\n",
      "  0.         0.03638317 0.0479132  0.         0.15835218 0.\n",
      "  0.29773557 0.23381045 0.         0.03748356 0.         0.03900538\n",
      "  0.         0.21320502 0.12794149 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1092595  0.22108847 0.11950683 0.         0.         0.\n",
      "  0.         0.         0.25735682 0.06916653 0.         0.\n",
      "  0.         0.01079507 0.22625808 0.236428   0.         0.18530077\n",
      "  0.19423991 0.09953535 0.         0.2221407  0.01167073 0.5316459\n",
      "  0.         0.07132069 0.17818302 0.         0.         0.\n",
      "  0.14659876 0.05147171 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.7949882  0.         1.232792   0.06695373 0.         0.90244347\n",
      "  0.62494266 0.79747283 0.8748221  0.02225963 0.51975363 0.\n",
      "  0.         0.         0.         0.37817863 0.49991465 0.7370512\n",
      "  0.         0.         1.0475359  0.27302    0.         0.6671027\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15041596 0.19590145 0.         0.         0.\n",
      "  0.         0.6274636  0.         0.87938756 0.         0.\n",
      "  0.         1.1698296  0.         0.3776369  0.         0.\n",
      "  0.         1.0979575  0.34245372 0.19756971 0.6821669  0.\n",
      "  0.         0.7443914  0.         0.18810175 0.         0.\n",
      "  0.         1.0008485  0.7850363  0.2713947 ]]\n",
      "Hi!\n",
      "[[0.478396   0.5250865  0.4127625  0.         0.         0.27139157\n",
      "  0.16932467 0.26054123 0.01158965 0.         0.21577914 0.\n",
      "  0.6055796  0.29987496 0.         0.12924954 0.         0.312508\n",
      "  0.         0.54108405 0.17263542 0.         0.         0.10163812\n",
      "  0.         0.         0.         0.18443604 0.         0.\n",
      "  0.5685626  0.5238238  0.         0.         0.15994315 0.\n",
      "  0.00486727 0.39761168 0.14048839 0.2248981  0.         0.\n",
      "  0.         0.02840197 0.5925341  0.5614962  0.         0.39797416\n",
      "  0.20743553 0.45788705 0.12877733 0.2827897  0.2176811  0.6834113\n",
      "  0.         0.1190554  0.14997011 0.         0.         0.\n",
      "  0.02873117 0.22755224 0.354816   0.        ]]\n",
      "Hi!\n",
      "[[0.29285425 0.         0.4804318  0.21707623 0.         0.6106233\n",
      "  1.6601846  1.5363092  0.7132879  0.         0.32559532 0.\n",
      "  0.03796593 0.         0.         0.5936387  0.         0.8037253\n",
      "  0.         0.         0.6718728  0.11746049 0.         0.\n",
      "  0.15287635 0.         0.         0.2581739  0.         0.\n",
      "  0.75697255 0.18433025 0.05585133 0.         0.7000746  0.\n",
      "  0.03413888 1.3597969  0.         0.45679536 0.24351454 0.\n",
      "  0.         1.0543817  0.4384161  0.8147393  0.         0.13125123\n",
      "  0.         0.79311246 0.44856533 0.34949583 0.4929471  0.03518705\n",
      "  0.         0.         0.18086286 0.         0.         0.\n",
      "  0.         1.0574117  1.1806016  0.        ]]\n",
      "Hi!\n",
      "[[0.56281555 0.39771843 0.01334061 0.26328403 0.         0.42039037\n",
      "  0.9748239  1.4380931  0.17068969 0.         0.24731801 0.\n",
      "  1.1210071  0.8450758  0.         0.352448   0.         0.5300442\n",
      "  0.09078992 0.21774319 0.2812602  0.2430764  0.         0.17798094\n",
      "  0.09962562 0.         0.         0.7657781  0.         0.\n",
      "  1.4875774  0.83226484 0.0802818  0.         0.7879956  0.\n",
      "  0.13171712 0.98352486 0.34615618 0.16639788 0.12629907 0.\n",
      "  0.         0.4463346  1.2887949  1.221128   0.         0.27694687\n",
      "  0.         0.94519013 0.50341815 0.57853514 0.9236776  0.9919764\n",
      "  0.         0.         0.4632453  0.         0.         0.\n",
      "  0.         0.450793   0.851904   0.        ]]\n",
      "Hi!\n",
      "[[0.23360328 0.18648425 1.0112958  0.         0.         0.624462\n",
      "  0.6242047  0.7638467  1.2649909  0.         0.5723924  0.\n",
      "  0.8575867  0.         0.         0.847606   0.01238584 0.826529\n",
      "  0.61573064 0.         1.0475082  0.13960162 0.         0.1955526\n",
      "  0.15893345 0.         0.         0.20762669 0.         0.\n",
      "  0.5046331  0.26811153 0.         0.         0.3884754  0.\n",
      "  0.33717415 1.2070161  0.         0.6253011  0.16042964 0.\n",
      "  0.         0.87918794 0.14699261 0.22410543 0.         0.70338935\n",
      "  0.         0.7782027  0.8401557  0.23057355 0.32630634 0.15742648\n",
      "  0.         0.         0.12046196 0.28729197 0.         0.\n",
      "  0.         0.91145915 1.2640835  0.72841173]]\n",
      "Hi!\n",
      "[[0.37696457 0.59889907 1.0693581  0.         0.         0.68249816\n",
      "  0.         0.         0.22591309 0.09397849 0.44042873 0.\n",
      "  0.2015401  0.         0.         0.0398837  0.179915   0.33463165\n",
      "  0.         0.853234   0.5036155  0.         0.         0.10217824\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30077517 0.02052118 0.         0.         0.\n",
      "  0.         0.         0.         0.55951315 0.         0.\n",
      "  0.         0.         0.03769899 0.33675456 0.         0.5654259\n",
      "  0.60563236 0.50409794 0.05717151 0.4159885  0.4342594  0.5667286\n",
      "  0.         0.7605539  0.         0.         0.25223207 0.\n",
      "  0.3606684  0.22407904 0.23481385 0.38660878]]\n",
      "Hi!\n",
      "[[0.53780305 0.         0.         0.6738852  0.         0.8286791\n",
      "  2.1301064  2.2614808  0.16923769 0.         0.04939208 0.\n",
      "  0.37939104 0.4770428  0.         0.3786633  0.         0.5768572\n",
      "  0.         0.         0.29739392 0.44669268 0.         0.\n",
      "  0.25091648 0.         0.         0.94014984 0.         0.\n",
      "  1.4002787  0.7009077  0.38737926 0.         0.9674671  0.\n",
      "  0.39196938 1.5361254  0.2274542  0.22762239 0.44204628 0.\n",
      "  0.         0.83844405 1.5020456  1.5206494  0.         0.3515662\n",
      "  0.         0.8910273  0.32652992 0.7962626  0.6832392  0.9714133\n",
      "  0.         0.17875707 0.61601573 0.         0.         0.\n",
      "  0.         0.63079447 1.3784729  0.        ]]\n",
      "Hi!\n",
      "[[0.44856322 0.30795702 0.93845785 0.         0.         0.77850723\n",
      "  0.34426552 0.50622636 0.6166725  0.03083826 0.44964173 0.\n",
      "  0.31167167 0.         0.         0.27218068 0.03487911 0.6904573\n",
      "  0.         0.23020664 0.83332527 0.         0.         0.25949332\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24558507 0.2720732  0.         0.         0.07136054 0.\n",
      "  0.         0.6000588  0.         0.5726175  0.         0.\n",
      "  0.         0.44585937 0.10100711 0.45213735 0.         0.3291813\n",
      "  0.01607476 0.8667564  0.32124314 0.29541007 0.5472355  0.22817248\n",
      "  0.         0.28510597 0.         0.         0.         0.\n",
      "  0.         0.7491543  0.6298848  0.34232125]]\n",
      "Hi!\n",
      "[[0.1529945  0.12409429 0.37636873 0.         0.         0.48317245\n",
      "  0.         0.16594663 0.08637623 0.18672359 0.31170875 0.\n",
      "  0.         0.         0.         0.01109966 0.         0.\n",
      "  0.         0.37465838 0.23529948 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02971798 0.04967313 0.         0.         0.\n",
      "  0.         0.16608909 0.00329338 0.24609143 0.         0.\n",
      "  0.         0.         0.1741942  0.46488813 0.         0.21975258\n",
      "  0.24229392 0.29382285 0.         0.28937262 0.30421668 0.39430994\n",
      "  0.         0.346331   0.         0.         0.04058952 0.\n",
      "  0.         0.01695064 0.03372009 0.        ]]\n",
      "Hi!\n",
      "[[0.07778022 0.47396457 0.31992385 0.         0.         0.16761257\n",
      "  0.         0.0100882  0.03056394 0.         0.18187672 0.\n",
      "  0.4517072  0.21058762 0.         0.01339311 0.         0.10992406\n",
      "  0.         0.31438357 0.16527002 0.         0.         0.\n",
      "  0.         0.         0.         0.04602984 0.         0.\n",
      "  0.1894823  0.2829932  0.06206117 0.         0.         0.\n",
      "  0.         0.         0.3007528  0.08747007 0.         0.\n",
      "  0.         0.         0.22116536 0.10742306 0.         0.17707524\n",
      "  0.23409371 0.17621198 0.02829473 0.22901952 0.13861413 0.49746943\n",
      "  0.         0.         0.12973878 0.         0.05226423 0.\n",
      "  0.13314405 0.10744954 0.0292115  0.03072557]]\n",
      "Hi!\n",
      "[[0.00400167 0.25971064 0.02675095 0.01237774 0.         0.0412984\n",
      "  0.00449944 0.2766942  0.         0.09961858 0.1019573  0.\n",
      "  0.12364348 0.14850006 0.         0.02533913 0.         0.05734732\n",
      "  0.         0.08619415 0.01835429 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00522228 0.1098287  0.16132443 0.         0.         0.\n",
      "  0.         0.         0.21633455 0.060007   0.         0.\n",
      "  0.         0.         0.1869424  0.30702397 0.         0.01726935\n",
      "  0.1624448  0.09106509 0.         0.17166553 0.11469515 0.33451527\n",
      "  0.         0.05842822 0.03437538 0.         0.         0.\n",
      "  0.04864907 0.18366319 0.         0.        ]]\n",
      "Hi!\n",
      "[[5.6180751e-01 2.7663708e-01 6.7892140e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0142659e+00 2.7724463e-01 5.3941697e-01 0.0000000e+00 2.0154665e-01\n",
      "  2.6156616e-01 0.0000000e+00 0.0000000e+00 2.3397589e-04 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.3433345e-01 0.0000000e+00 7.3256123e-01\n",
      "  3.5037470e-01 0.0000000e+00 0.0000000e+00 7.8715190e-02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.8409697e-02 3.5654506e-01 1.8524331e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.1630329e-02 0.0000000e+00 4.4148323e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2868536e-02 4.5286313e-01\n",
      "  9.7422642e-01 0.0000000e+00 2.9675466e-01 5.6066757e-01 8.1282824e-01\n",
      "  0.0000000e+00 6.6322845e-01 7.0664126e-01 6.3422549e-01 0.0000000e+00\n",
      "  1.1198266e+00 0.0000000e+00 0.0000000e+00 3.0286264e-02 0.0000000e+00\n",
      "  2.9952011e-01 2.1909878e-01 2.2600897e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.40135473 0.512039   1.054966   0.         0.         0.60195965\n",
      "  0.40923738 0.6355406  1.4377756  0.         0.61864686 0.\n",
      "  1.5330067  0.         0.         0.99250054 0.         0.812998\n",
      "  1.2520261  0.         1.1088684  0.11132188 0.         0.\n",
      "  0.46761408 0.         0.         0.377574   0.         0.\n",
      "  0.7812531  0.47595567 0.         0.         0.540778   0.\n",
      "  0.84574467 1.3246444  0.         0.58333266 0.18689305 0.\n",
      "  0.         0.6332856  0.42626598 0.02533675 0.         1.190372\n",
      "  0.         0.8716073  1.1562241  0.26827818 0.23825599 0.54680324\n",
      "  0.         0.         0.34065577 0.27732962 0.         0.\n",
      "  0.         0.6802126  1.4566524  0.95578706]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03131448 0.25087318 0.3322746  0.         0.         0.30460405\n",
      "  0.         0.11610945 0.11489117 0.04994692 0.1698227  0.\n",
      "  0.08332427 0.         0.         0.06166828 0.         0.02976954\n",
      "  0.         0.40072432 0.21209033 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13176249 0.10768427 0.         0.         0.\n",
      "  0.         0.         0.04860345 0.225644   0.         0.\n",
      "  0.         0.01484087 0.07351375 0.35201004 0.         0.26549816\n",
      "  0.28847104 0.14737518 0.         0.26367745 0.03582482 0.4405043\n",
      "  0.         0.29448926 0.         0.         0.06107136 0.\n",
      "  0.08059368 0.         0.02042213 0.02918343]]\n",
      "Hi!\n",
      "[[0.9006567  0.0287985  1.5324131  0.         0.         1.0369691\n",
      "  0.43844083 0.65996104 0.94778264 0.01937324 0.58868533 0.\n",
      "  0.0053002  0.         0.         0.44487357 0.5109366  0.7328099\n",
      "  0.         0.06683264 1.2012537  0.09097124 0.         0.61680746\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31414288 0.10347883 0.         0.         0.\n",
      "  0.         0.69847    0.         0.81844753 0.         0.\n",
      "  0.         0.9736018  0.         0.3694942  0.         0.38323334\n",
      "  0.09391701 0.9448884  0.43994924 0.33136937 0.67386466 0.15034404\n",
      "  0.         0.87292266 0.         0.30362448 0.         0.\n",
      "  0.         0.87311256 1.0038872  0.5004814 ]]\n",
      "Hi!\n",
      "[[1.6504292e-01 1.8431118e-04 7.7119395e-02 0.0000000e+00 0.0000000e+00\n",
      "  4.6559876e-01 9.7077149e-01 8.3796471e-01 2.9844683e-01 4.1434602e-03\n",
      "  1.6452143e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4791542e-01 0.0000000e+00 4.6309987e-01 0.0000000e+00 4.1237663e-02\n",
      "  1.2221810e-01 3.3578698e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.3993316e-01 8.4894247e-02 7.7017784e-02 0.0000000e+00 2.3971227e-01\n",
      "  0.0000000e+00 0.0000000e+00 4.0564975e-01 0.0000000e+00 4.6395540e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.4570657e-01 1.7240597e-01\n",
      "  5.9995383e-01 0.0000000e+00 0.0000000e+00 1.0978055e-01 8.6002058e-01\n",
      "  2.2991697e-01 1.8462767e-01 4.1437885e-01 1.4242503e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 8.3675665e-01 8.9322910e-02 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.18661511 0.53928846 0.53644824 0.         0.         0.60312635\n",
      "  0.         0.1580382  0.00204594 0.0666661  0.2887481  0.\n",
      "  0.22996345 0.10954091 0.         0.         0.         0.25726345\n",
      "  0.         0.7720289  0.28444606 0.         0.         0.02422761\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18920021 0.3618404  0.         0.         0.         0.\n",
      "  0.         0.         0.05751019 0.27298352 0.         0.\n",
      "  0.         0.         0.41242886 0.58545595 0.         0.3902739\n",
      "  0.45574316 0.52604    0.         0.37888867 0.43281323 0.6911505\n",
      "  0.         0.49749193 0.         0.         0.0507656  0.\n",
      "  0.22550288 0.2369516  0.01178663 0.00354942]]\n",
      "Hi!\n",
      "[[0.4689628  1.3513824  0.614718   0.         0.         0.40974018\n",
      "  0.         0.15414326 0.48510087 0.         0.46987787 0.\n",
      "  1.914532   0.5661441  0.         0.4368434  0.         0.508527\n",
      "  0.6875016  0.8309066  0.45167372 0.         0.         0.19433922\n",
      "  0.         0.         0.         0.406337   0.         0.\n",
      "  0.9011322  0.75272256 0.         0.         0.28035742 0.\n",
      "  0.3409483  0.38228473 0.5616429  0.3671407  0.         0.\n",
      "  0.         0.08743955 0.8523079  0.39748642 0.         1.0112631\n",
      "  0.11817953 0.6889673  0.7271057  0.4067526  0.5030827  1.1310084\n",
      "  0.         0.         0.39445668 0.         0.07839534 0.\n",
      "  0.         0.2847253  0.5838194  0.40168187]]\n",
      "Hi!\n",
      "[[0.59156257 0.6532737  0.57758546 0.01546602 0.         0.60900086\n",
      "  0.44790202 1.1130086  0.7809352  0.         0.46974733 0.\n",
      "  1.9298289  0.5179752  0.         0.66585237 0.         0.6305374\n",
      "  1.0728658  0.18610261 0.7188256  0.17070512 0.         0.\n",
      "  0.31918848 0.         0.         0.7435662  0.         0.\n",
      "  1.3331207  0.93037665 0.         0.         0.6954721  0.\n",
      "  0.61560017 1.1748438  0.27667308 0.22599344 0.16858354 0.\n",
      "  0.         0.44483203 1.155661   0.6805386  0.         1.019784\n",
      "  0.         0.7330391  0.98001415 0.57226837 0.7234051  1.1862913\n",
      "  0.         0.         0.51706505 0.         0.         0.\n",
      "  0.         0.3053177  1.4463542  0.34322563]]\n",
      "Hi!\n",
      "[[0.73754436 0.26818404 1.2794921  0.         0.         0.84985423\n",
      "  0.17090422 0.16846995 0.64603305 0.10268022 0.53071356 0.\n",
      "  0.         0.         0.         0.20837635 0.47259837 0.66962254\n",
      "  0.         0.38749802 0.91319567 0.05679483 0.         0.37920877\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1538983  0.07000949 0.         0.         0.\n",
      "  0.         0.37531382 0.         0.77568364 0.         0.\n",
      "  0.         0.58751166 0.         0.25194702 0.         0.38023055\n",
      "  0.24357355 0.8267126  0.29167    0.17633033 0.377379   0.1657406\n",
      "  0.         0.6951046  0.         0.18192117 0.09344694 0.\n",
      "  0.25011134 0.7248076  0.36953822 0.5137878 ]]\n",
      "Hi!\n",
      "[[0.5991591  0.         0.78534055 0.10364839 0.         0.83689237\n",
      "  0.73080146 0.9307719  0.5183694  0.10840751 0.38498914 0.\n",
      "  0.         0.         0.         0.16945526 0.11960804 0.65985763\n",
      "  0.         0.08953284 0.66211903 0.03065399 0.         0.35677117\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15449105 0.14801799 0.22357285 0.         0.01419785 0.\n",
      "  0.         0.5649858  0.         0.8137511  0.         0.\n",
      "  0.         0.8497987  0.         0.67033565 0.         0.\n",
      "  0.03670016 1.1559942  0.2369887  0.32712418 0.7467601  0.01012707\n",
      "  0.         0.59955907 0.         0.         0.         0.\n",
      "  0.         0.9304417  0.42193764 0.        ]]\n",
      "Hi!\n",
      "[[4.39317137e-01 0.00000000e+00 2.50441413e-02 4.94764030e-01\n",
      "  0.00000000e+00 8.13664019e-01 1.49385464e+00 1.57905877e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.72787412e-02 0.00000000e+00\n",
      "  0.00000000e+00 4.23962742e-01 0.00000000e+00 7.38945901e-02\n",
      "  0.00000000e+00 4.36373174e-01 0.00000000e+00 3.71066719e-01\n",
      "  1.00394644e-01 0.00000000e+00 0.00000000e+00 1.72338390e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.03342426e-01\n",
      "  0.00000000e+00 0.00000000e+00 9.39975500e-01 5.98677278e-01\n",
      "  5.32250226e-01 0.00000000e+00 4.10682619e-01 0.00000000e+00\n",
      "  0.00000000e+00 6.30642414e-01 7.76497796e-02 4.24652845e-01\n",
      "  1.19178437e-01 0.00000000e+00 0.00000000e+00 2.73521781e-01\n",
      "  1.07649219e+00 1.38909721e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.35714823e-01 1.09898877e+00 0.00000000e+00 7.55640984e-01\n",
      "  9.19263124e-01 6.62947536e-01 0.00000000e+00 7.39434183e-01\n",
      "  1.31815627e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.06879985e-01 4.24798161e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.38180932 0.7698117  0.66100544 0.         0.         0.5188894\n",
      "  0.         0.16261324 0.05633268 0.         0.33286437 0.\n",
      "  0.5604744  0.11154401 0.         0.07338004 0.         0.40389886\n",
      "  0.         0.727518   0.2871395  0.         0.         0.06331807\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32702857 0.48536614 0.         0.         0.         0.\n",
      "  0.         0.25116026 0.18932362 0.3482444  0.         0.\n",
      "  0.         0.         0.560808   0.52693635 0.         0.5197182\n",
      "  0.4087796  0.49944684 0.09043077 0.33964995 0.31949806 0.733573\n",
      "  0.         0.41379148 0.05201354 0.         0.03280315 0.\n",
      "  0.12240584 0.32577217 0.26832834 0.00092276]]\n",
      "Hi!\n",
      "[[0.01252936 0.0670112  0.05117152 0.         0.         0.07371109\n",
      "  0.04192523 0.1705261  0.09493695 0.10994472 0.13357772 0.\n",
      "  0.         0.02624567 0.         0.08080304 0.         0.04362087\n",
      "  0.         0.12601608 0.12930548 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13748431 0.         0.         0.\n",
      "  0.         0.         0.0485651  0.0903789  0.         0.\n",
      "  0.         0.00525899 0.09111203 0.26859233 0.         0.10653108\n",
      "  0.09269807 0.06839347 0.         0.19402298 0.         0.24127156\n",
      "  0.         0.07087351 0.         0.         0.         0.\n",
      "  0.         0.10380721 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.56512386 0.         0.0347948  0.55937856 0.         0.6924673\n",
      "  1.5590962  1.7428071  0.         0.         0.1428955  0.\n",
      "  0.1907743  0.49181    0.         0.1522164  0.         0.42661425\n",
      "  0.         0.2011325  0.19967611 0.14746214 0.         0.00941913\n",
      "  0.         0.         0.         0.66392124 0.         0.\n",
      "  1.2591769  0.6462129  0.36794886 0.         0.6970861  0.\n",
      "  0.         1.0018383  0.11977459 0.27782753 0.25099826 0.\n",
      "  0.         0.379744   1.2456566  1.4338993  0.         0.\n",
      "  0.02540022 0.9646196  0.06560415 0.7211705  0.89792633 0.6954705\n",
      "  0.         0.3264904  0.373024   0.         0.         0.\n",
      "  0.         0.47468615 0.85351795 0.        ]]\n",
      "Hi!\n",
      "[[0.3529429  0.54758614 0.79349697 0.         0.         0.79123235\n",
      "  0.         0.04016631 0.01367158 0.08463704 0.3414454  0.\n",
      "  0.22557485 0.         0.         0.         0.         0.25399557\n",
      "  0.         0.8610996  0.37898198 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07718486 0.41333574 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42213136 0.         0.\n",
      "  0.         0.         0.3890151  0.50736076 0.         0.48428237\n",
      "  0.59429914 0.5578121  0.         0.44059885 0.45523062 0.7094821\n",
      "  0.         0.70939684 0.         0.         0.09090793 0.\n",
      "  0.28971866 0.23649868 0.16788472 0.07265033]]\n",
      "Hi!\n",
      "[[0.11361905 1.0881227  0.727359   0.         0.         0.5008916\n",
      "  0.         0.00426963 0.49224645 0.         0.47407067 0.\n",
      "  1.213914   0.1392588  0.         0.30601215 0.         0.4102582\n",
      "  0.06915152 0.78375465 0.5472557  0.         0.         0.02587668\n",
      "  0.         0.         0.         0.14337078 0.         0.\n",
      "  0.5165628  0.300999   0.         0.         0.06988562 0.\n",
      "  0.         0.04628685 0.1738762  0.34284845 0.         0.\n",
      "  0.         0.         0.29341134 0.20660686 0.         0.57415986\n",
      "  0.19904935 0.585917   0.5051402  0.23302265 0.30316716 0.7039582\n",
      "  0.         0.         0.16752453 0.         0.21493332 0.\n",
      "  0.03735987 0.41524765 0.33696508 0.46864244]]\n",
      "Hi!\n",
      "[[0.4802231  0.         0.         0.59546036 0.         0.57887673\n",
      "  1.8338346  2.1833959  0.3349124  0.         0.15610397 0.\n",
      "  0.6652153  0.7840571  0.         0.5115887  0.         0.51691276\n",
      "  0.00750295 0.         0.32055593 0.39743137 0.         0.\n",
      "  0.13407679 0.         0.         1.0156878  0.         0.\n",
      "  1.6581962  0.6417271  0.250902   0.         1.0553683  0.\n",
      "  0.17957345 1.3146644  0.05687499 0.15524805 0.44954303 0.\n",
      "  0.         0.6597445  1.4080904  1.5098149  0.         0.0622949\n",
      "  0.         0.9390476  0.4119871  0.71294194 1.0235486  0.6738319\n",
      "  0.         0.         0.57923704 0.         0.         0.\n",
      "  0.         0.6006902  1.336348   0.        ]]\n",
      "Hi!\n",
      "[[0.35803038 0.7811707  0.49927875 0.         0.         0.34078282\n",
      "  0.         0.2435102  0.07986484 0.         0.34037775 0.\n",
      "  0.7968912  0.3313171  0.         0.         0.         0.11409765\n",
      "  0.         0.7022431  0.3451873  0.         0.         0.16381396\n",
      "  0.         0.         0.         0.3872843  0.         0.\n",
      "  0.39803123 0.5532594  0.0350902  0.         0.06024422 0.\n",
      "  0.         0.05191972 0.66468    0.0514667  0.         0.\n",
      "  0.         0.         0.55650896 0.529632   0.         0.3719746\n",
      "  0.31114715 0.50259537 0.23056535 0.5063645  0.7375488  0.95944935\n",
      "  0.         0.21034583 0.27330893 0.         0.00244045 0.\n",
      "  0.09374801 0.19722852 0.439316   0.        ]]\n",
      "Hi!\n",
      "[[0.4838613  0.20773672 1.3438487  0.         0.         0.553758\n",
      "  0.47569498 0.49611327 1.4701562  0.         0.70321506 0.\n",
      "  0.6119708  0.         0.         0.9680109  0.37698746 0.96167153\n",
      "  0.33705986 0.         1.2481545  0.31906083 0.         0.41436636\n",
      "  0.11380498 0.         0.         0.         0.         0.\n",
      "  0.24203408 0.12858881 0.         0.         0.27342445 0.\n",
      "  0.28276545 1.1300832  0.         0.8488832  0.20533067 0.\n",
      "  0.         1.138929   0.         0.         0.         0.6582993\n",
      "  0.         0.8674885  0.8822885  0.05825111 0.27779758 0.\n",
      "  0.         0.         0.         0.5674301  0.         0.\n",
      "  0.         1.1246432  1.1558639  0.9243798 ]]\n",
      "Hi!\n",
      "[[0.07807673 0.42973152 0.20336947 0.         0.         0.1028489\n",
      "  0.         0.1385275  0.13345721 0.05209397 0.20898508 0.\n",
      "  0.3099238  0.13205804 0.         0.06048797 0.         0.16632746\n",
      "  0.         0.31738055 0.22051714 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18428935 0.13073008 0.04762117 0.         0.         0.\n",
      "  0.         0.         0.19950779 0.14461388 0.         0.\n",
      "  0.         0.         0.15340932 0.21262804 0.         0.11906172\n",
      "  0.17184834 0.1832559  0.12253972 0.13667476 0.07939373 0.3226527\n",
      "  0.         0.         0.08835356 0.         0.05625766 0.\n",
      "  0.05586779 0.13962778 0.         0.04928917]]\n",
      "Hi!\n",
      "[[0.86257565 0.         1.4763057  0.         0.         0.8092912\n",
      "  0.7722531  0.843945   1.3722013  0.         0.6469286  0.\n",
      "  0.         0.         0.         0.7450343  0.7498951  0.94049853\n",
      "  0.         0.         1.3157462  0.53423643 0.         0.74282014\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01969428 0.0987068  0.         0.02162413 0.\n",
      "  0.         0.99441874 0.         0.95157087 0.15838532 0.\n",
      "  0.         1.6235584  0.         0.10708058 0.         0.1678128\n",
      "  0.         0.93804336 0.7033137  0.05135252 0.4790877  0.\n",
      "  0.         0.4213075  0.         0.62116    0.         0.\n",
      "  0.         1.2605817  1.0881069  0.6624082 ]]\n",
      "Hi!\n",
      "[[0.42747137 0.         0.         0.35402605 0.         0.42841956\n",
      "  1.8473835  2.0285816  0.6672006  0.         0.21362846 0.\n",
      "  0.8998058  0.6460569  0.         0.79230547 0.         0.7282617\n",
      "  0.45546037 0.         0.3513061  0.48717204 0.         0.\n",
      "  0.43994275 0.         0.         0.87682635 0.         0.\n",
      "  1.4896157  0.46248025 0.07863303 0.         1.1275444  0.\n",
      "  0.628984   1.645849   0.         0.1890795  0.3920258  0.\n",
      "  0.         0.86554736 1.2268364  1.2307295  0.         0.3768572\n",
      "  0.         0.81538683 0.86699885 0.56469655 0.571882   0.704743\n",
      "  0.         0.         0.6027542  0.         0.         0.\n",
      "  0.         0.648481   1.2812499  0.        ]]\n",
      "Hi!\n",
      "[[0.5068664  0.5440872  1.014351   0.         0.         0.7614571\n",
      "  0.28849918 0.53829944 0.811592   0.         0.568668   0.\n",
      "  1.1984917  0.         0.         0.6513448  0.         0.7631063\n",
      "  0.6246216  0.29861063 0.89928275 0.         0.         0.\n",
      "  0.24441415 0.         0.         0.28006116 0.         0.\n",
      "  0.7398265  0.60939586 0.         0.         0.4662874  0.\n",
      "  0.51900536 1.0721573  0.         0.5766565  0.0292421  0.\n",
      "  0.         0.28739667 0.7088916  0.29104736 0.         1.0383587\n",
      "  0.         0.6858219  0.7404792  0.37079126 0.3202672  0.8183157\n",
      "  0.         0.         0.2841578  0.         0.         0.\n",
      "  0.         0.5495097  1.2189002  0.56250095]]\n",
      "Hi!\n",
      "[[0.693637   1.5280999  0.5501834  0.         0.         0.4011221\n",
      "  0.         0.60068834 0.42253658 0.         0.51483226 0.\n",
      "  2.3421664  0.8206469  0.         0.4412477  0.         0.55308104\n",
      "  0.70314443 0.81326205 0.48125875 0.         0.         0.44421282\n",
      "  0.         0.         0.         0.7261386  0.         0.\n",
      "  1.4582024  1.0758696  0.         0.         0.48959103 0.\n",
      "  0.31348938 0.54891545 0.9700579  0.26386702 0.         0.\n",
      "  0.         0.44301403 1.2328825  0.7460927  0.         0.9277095\n",
      "  0.14621082 0.727234   0.7735998  0.4814781  0.93599397 1.4309644\n",
      "  0.         0.         0.5117374  0.         0.         0.\n",
      "  0.         0.20954043 0.8547653  0.1780191 ]]\n",
      "Hi!\n",
      "[[0.54909384 0.         0.5483574  0.34417674 0.         0.99281824\n",
      "  1.7106724  1.4586939  0.158015   0.         0.20523095 0.\n",
      "  0.         0.         0.         0.15685314 0.         0.5877145\n",
      "  0.         0.0528806  0.47320595 0.18036951 0.         0.\n",
      "  0.         0.         0.         0.25220183 0.         0.\n",
      "  0.5148179  0.54952925 0.1159744  0.         0.5295641  0.\n",
      "  0.         1.0415374  0.         0.41534275 0.23846817 0.\n",
      "  0.         0.77001613 0.6565362  1.0092075  0.         0.24181454\n",
      "  0.         0.8633939  0.06278054 0.52105534 0.5767587  0.6415294\n",
      "  0.         0.6310284  0.19196314 0.         0.         0.\n",
      "  0.         0.7546352  1.0014116  0.        ]]\n",
      "Hi!\n",
      "[[0.00989759 0.28598392 0.26624855 0.         0.         0.37834808\n",
      "  0.03222736 0.07292774 0.07716208 0.15842418 0.24311706 0.\n",
      "  0.07403286 0.03491329 0.         0.         0.         0.10123633\n",
      "  0.         0.41009408 0.21073923 0.         0.         0.01935057\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03384309 0.00081451 0.         0.         0.\n",
      "  0.         0.         0.         0.19902466 0.         0.\n",
      "  0.         0.         0.09363566 0.37501472 0.         0.23378962\n",
      "  0.24943782 0.20637777 0.         0.22999167 0.17668563 0.32277688\n",
      "  0.         0.15365134 0.         0.         0.08830137 0.\n",
      "  0.07312437 0.13245161 0.         0.02716721]]\n",
      "Hi!\n",
      "[[0.42940617 0.24152271 0.71482056 0.         0.         0.816622\n",
      "  0.26533294 0.27547    0.17605257 0.26211217 0.32696593 0.\n",
      "  0.         0.         0.         0.05894811 0.01158034 0.14978302\n",
      "  0.         0.6080856  0.41579393 0.         0.         0.1507428\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06170563 0.1454701  0.         0.         0.\n",
      "  0.         0.150232   0.         0.5241661  0.         0.\n",
      "  0.         0.         0.08601157 0.6431073  0.         0.22606818\n",
      "  0.40856856 0.68170404 0.         0.37738308 0.5585566  0.2922267\n",
      "  0.         0.8337699  0.         0.         0.04814329 0.\n",
      "  0.31432548 0.31822124 0.06636278 0.08375792]]\n",
      "Hi!\n",
      "[[0.06094799 0.3005659  0.4799668  0.         0.         0.34794396\n",
      "  0.         0.         0.19536841 0.09519395 0.3174412  0.\n",
      "  0.16154315 0.         0.         0.09213786 0.         0.06126995\n",
      "  0.         0.44736046 0.28435472 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06571508 0.02348551 0.         0.         0.\n",
      "  0.         0.         0.04195028 0.25549728 0.         0.\n",
      "  0.         0.         0.         0.17775571 0.         0.30500993\n",
      "  0.29405302 0.15425138 0.05130905 0.274418   0.13880123 0.37131578\n",
      "  0.         0.13545474 0.         0.         0.15508407 0.\n",
      "  0.10302485 0.06258221 0.01075953 0.1870137 ]]\n",
      "Hi!\n",
      "[[0.3905197  0.49125883 0.2782954  0.         0.         0.5561389\n",
      "  0.42414975 0.6012714  0.         0.         0.24569467 0.\n",
      "  0.44350445 0.39149004 0.         0.         0.         0.3863618\n",
      "  0.         0.6544697  0.19899838 0.         0.         0.09525633\n",
      "  0.         0.         0.         0.08102635 0.         0.\n",
      "  0.7119551  0.5363411  0.08290245 0.         0.17953153 0.\n",
      "  0.         0.35799724 0.12083887 0.2519888  0.         0.\n",
      "  0.         0.0128549  0.7698815  0.940946   0.         0.2904992\n",
      "  0.35694027 0.78268284 0.05321074 0.45848185 0.5614414  0.74300444\n",
      "  0.         0.37870735 0.10098801 0.         0.         0.\n",
      "  0.         0.3200636  0.17547359 0.        ]]\n",
      "Hi!\n",
      "[[0.3756755  0.21190344 0.7019531  0.08536729 0.         0.61688113\n",
      "  0.37155336 0.37216938 0.         0.00587048 0.18370514 0.\n",
      "  0.         0.         0.         0.09189163 0.         0.29804972\n",
      "  0.         0.5977012  0.30425307 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21214586 0.5991406  0.11137217 0.         0.         0.\n",
      "  0.         0.29685807 0.06119026 0.39031738 0.         0.\n",
      "  0.         0.         0.46232378 0.63428646 0.         0.31662363\n",
      "  0.42780668 0.54398805 0.         0.43372226 0.4155136  0.69462156\n",
      "  0.         0.7718224  0.03462357 0.         0.         0.\n",
      "  0.1643208  0.32891107 0.4823371  0.        ]]\n",
      "Hi!\n",
      "[[0.5796982  0.7120828  1.6079086  0.         0.         0.96683174\n",
      "  0.         0.10603149 0.8148866  0.         0.70200753 0.\n",
      "  1.0287014  0.         0.         0.50637877 0.16986679 0.69419295\n",
      "  0.28923926 0.5683191  1.1650388  0.         0.         0.23484889\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3296184  0.6237103  0.         0.         0.         0.\n",
      "  0.20822059 0.6546576  0.         0.7513898  0.         0.\n",
      "  0.         0.17045175 0.32527056 0.15420775 0.         0.95945925\n",
      "  0.22588354 0.7948809  0.52886826 0.40949968 0.50753546 0.71439624\n",
      "  0.         0.43193337 0.         0.14662029 0.1479032  0.\n",
      "  0.         0.48518935 1.1363717  0.78752524]]\n",
      "Hi!\n",
      "[[0.36319062 0.29858038 0.9784217  0.         0.         0.67463243\n",
      "  0.4602978  0.63706034 0.82435    0.         0.53170055 0.\n",
      "  0.63578135 0.         0.         0.5408345  0.         0.70725566\n",
      "  0.         0.12160899 0.90373755 0.         0.         0.13593277\n",
      "  0.         0.         0.         0.06985286 0.         0.\n",
      "  0.5056983  0.38998112 0.         0.         0.2724932  0.\n",
      "  0.01681108 0.8530689  0.         0.5657646  0.02565902 0.\n",
      "  0.         0.50749093 0.2802259  0.4048858  0.         0.46850097\n",
      "  0.         0.7651784  0.51913625 0.3227355  0.5152024  0.31103343\n",
      "  0.         0.02087201 0.         0.         0.         0.\n",
      "  0.         0.7259937  0.97560537 0.40267333]]\n",
      "Hi!\n",
      "[[0.18749699 0.2855306  0.3279269  0.         0.         0.5551168\n",
      "  0.71700966 0.83386624 0.294437   0.         0.29481035 0.\n",
      "  0.27955717 0.05494874 0.         0.21761599 0.         0.5686025\n",
      "  0.         0.3194862  0.41312137 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6009414  0.2904927  0.         0.         0.33510756 0.\n",
      "  0.         0.71390104 0.         0.3993658  0.         0.\n",
      "  0.         0.32159477 0.4807812  0.7602321  0.         0.16436379\n",
      "  0.         0.8621367  0.27794918 0.33283108 0.4950767  0.35010365\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.74227935 0.34488615 0.00295367]]\n",
      "Hi!\n",
      "[[0.49438843 0.5904525  0.4150256  0.         0.         0.51801056\n",
      "  0.2832103  0.62456906 0.0051396  0.         0.32227993 0.\n",
      "  0.7947121  0.4896438  0.         0.10849734 0.         0.4086488\n",
      "  0.         0.6437341  0.2966788  0.         0.         0.1481453\n",
      "  0.         0.         0.         0.19056743 0.         0.\n",
      "  0.85916525 0.7001144  0.         0.         0.27954492 0.\n",
      "  0.         0.47275195 0.25366828 0.22859241 0.         0.\n",
      "  0.         0.07690834 0.89395607 0.81998926 0.         0.42087495\n",
      "  0.30477655 0.7451583  0.19170165 0.4905527  0.5873642  0.8799743\n",
      "  0.         0.2465195  0.22858381 0.         0.         0.\n",
      "  0.         0.24635376 0.44713613 0.        ]]\n",
      "Hi!\n",
      "[[0.5245554  0.31354114 0.19186923 0.29062906 0.         0.7013543\n",
      "  0.8445805  1.2655398  0.         0.         0.17568982 0.\n",
      "  0.59622294 0.6595295  0.         0.         0.         0.29689053\n",
      "  0.         0.51727426 0.26441228 0.         0.         0.10856652\n",
      "  0.         0.         0.         0.42469826 0.         0.\n",
      "  1.1387242  0.71349925 0.20842527 0.         0.38031602 0.\n",
      "  0.         0.6367926  0.22839014 0.21865278 0.04405238 0.\n",
      "  0.         0.11334234 1.1230184  1.2881081  0.         0.18557912\n",
      "  0.299259   0.9529252  0.07575684 0.684518   0.99166065 0.9282748\n",
      "  0.         0.4601008  0.21648861 0.         0.         0.\n",
      "  0.         0.31977257 0.59135264 0.        ]]\n",
      "Hi!\n",
      "[[0.30520532 0.22557068 0.96946263 0.         0.         0.45449367\n",
      "  0.5317857  0.53352404 1.077357   0.         0.5557964  0.\n",
      "  0.35611317 0.         0.         0.69909745 0.18005124 0.8815078\n",
      "  0.02279501 0.         0.96277887 0.27590114 0.         0.25106117\n",
      "  0.07547005 0.         0.         0.         0.         0.\n",
      "  0.21788424 0.0856545  0.         0.         0.26492625 0.\n",
      "  0.06786768 0.9577656  0.         0.71139044 0.06202574 0.\n",
      "  0.         0.9284354  0.         0.09210464 0.         0.38864356\n",
      "  0.         0.7577537  0.69251597 0.06922254 0.25272015 0.\n",
      "  0.         0.         0.         0.23233195 0.         0.\n",
      "  0.         1.0566865  0.72149473 0.6325487 ]]\n",
      "Hi!\n",
      "[[0.7126871  0.         0.75469923 0.4843969  0.         0.68659174\n",
      "  2.3257997  2.1989822  1.084272   0.         0.33848265 0.\n",
      "  0.         0.         0.         0.76759994 0.35389522 0.8902713\n",
      "  0.         0.         0.903078   0.43647137 0.         0.3511399\n",
      "  0.         0.         0.         0.2107299  0.         0.\n",
      "  0.5325631  0.02092437 0.29066068 0.         0.5688749  0.\n",
      "  0.         1.4253039  0.         0.8355515  0.45124254 0.\n",
      "  0.         2.0697515  0.         0.7154844  0.         0.\n",
      "  0.         1.0094014  0.46449557 0.25518787 0.8239879  0.\n",
      "  0.         0.4379182  0.         0.12481226 0.         0.\n",
      "  0.         1.4044662  1.3060983  0.        ]]\n",
      "Hi!\n",
      "[[0.3871204  0.20772684 0.7308006  0.         0.         0.65430623\n",
      "  0.89392275 1.0674893  1.0760106  0.         0.5208545  0.\n",
      "  1.3295895  0.         0.         0.8935011  0.         0.81450343\n",
      "  1.0161251  0.         0.8221555  0.10675889 0.         0.\n",
      "  0.45677954 0.         0.         0.58373743 0.         0.\n",
      "  0.99902403 0.54116327 0.         0.         0.78927195 0.\n",
      "  0.70026255 1.4480019  0.         0.38094744 0.23076274 0.\n",
      "  0.         0.6266477  0.8098475  0.5051878  0.         1.008446\n",
      "  0.         0.6984828  1.0040387  0.39735878 0.36098862 0.6830535\n",
      "  0.         0.         0.50261945 0.         0.         0.\n",
      "  0.         0.66101485 1.538586   0.5850107 ]]\n",
      "Hi!\n",
      "[[0.58403987 0.         0.02066979 0.3734826  0.         0.59461695\n",
      "  1.355587   1.5536155  0.1328003  0.         0.14251179 0.\n",
      "  0.64569056 0.60591024 0.         0.34665784 0.         0.519404\n",
      "  0.         0.08782018 0.2269009  0.17318197 0.         0.\n",
      "  0.16590147 0.         0.         0.6365303  0.         0.\n",
      "  1.2312132  0.64636296 0.18387179 0.         0.71730417 0.\n",
      "  0.3746196  1.2030526  0.10614017 0.2039082  0.15585418 0.\n",
      "  0.         0.44248924 1.2327367  1.2490776  0.         0.42416924\n",
      "  0.         0.8157316  0.38164434 0.5860519  0.56232584 0.89162105\n",
      "  0.         0.         0.46472743 0.         0.         0.\n",
      "  0.         0.45879897 0.89959407 0.        ]]\n",
      "Hi!\n",
      "[[0.06630677 0.11746573 0.32260597 0.         0.         0.3942964\n",
      "  0.13499956 0.19071785 0.06185153 0.21384962 0.24487245 0.\n",
      "  0.         0.         0.         0.03778047 0.         0.08308116\n",
      "  0.         0.3547018  0.18942314 0.         0.         0.03445163\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07147298 0.         0.         0.\n",
      "  0.         0.03706108 0.0397005  0.28807592 0.         0.\n",
      "  0.         0.         0.06592159 0.47759682 0.         0.15916936\n",
      "  0.22206908 0.2860026  0.         0.24999125 0.2425136  0.27059948\n",
      "  0.         0.32457387 0.         0.         0.03477663 0.\n",
      "  0.09894382 0.18383387 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06708793 0.29309872 0.05006049 0.02882775 0.         0.15388897\n",
      "  0.03556165 0.2512675  0.         0.00235204 0.09887385 0.\n",
      "  0.19425683 0.31260195 0.         0.         0.         0.12870601\n",
      "  0.         0.21425802 0.03321701 0.         0.         0.\n",
      "  0.         0.         0.         0.00427457 0.         0.\n",
      "  0.20620513 0.2998051  0.21341912 0.         0.         0.\n",
      "  0.         0.         0.24721177 0.04076291 0.         0.\n",
      "  0.         0.         0.37071052 0.4031695  0.         0.05537917\n",
      "  0.24774192 0.22781287 0.         0.20139593 0.11635108 0.50850976\n",
      "  0.         0.18702751 0.14868796 0.         0.         0.\n",
      "  0.11286423 0.14597405 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.42411184 0.28504837 0.4672533  0.04426355 0.         0.8065487\n",
      "  0.45753792 0.63518107 0.         0.14458245 0.20798494 0.\n",
      "  0.         0.05856449 0.         0.05350332 0.         0.32254568\n",
      "  0.         0.6604699  0.30614197 0.         0.         0.03919414\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27863118 0.41822928 0.11006557 0.         0.         0.\n",
      "  0.         0.13650912 0.         0.52734214 0.         0.\n",
      "  0.         0.14760421 0.4419444  0.8565194  0.         0.00108276\n",
      "  0.39149007 0.8962787  0.         0.4758844  0.68612975 0.4216968\n",
      "  0.         0.80880886 0.         0.         0.         0.\n",
      "  0.35671887 0.49174622 0.01006723 0.        ]]\n",
      "Hi!\n",
      "[[0.49523693 0.91013956 0.618077   0.         0.         0.40898407\n",
      "  0.2407065  0.57707715 0.8077312  0.         0.51031417 0.\n",
      "  1.7477666  0.4271694  0.         0.7715735  0.         0.74463826\n",
      "  0.850657   0.40392837 0.68533754 0.         0.         0.05268618\n",
      "  0.34335348 0.         0.         0.45075965 0.         0.\n",
      "  1.0176417  0.70511526 0.         0.         0.56237495 0.\n",
      "  0.5359647  1.0661484  0.10719411 0.49539694 0.         0.\n",
      "  0.         0.33757645 0.9294408  0.3784169  0.         1.0240253\n",
      "  0.         0.7481989  0.8994219  0.3168193  0.45709497 0.93991613\n",
      "  0.         0.         0.3809798  0.         0.         0.\n",
      "  0.         0.48125225 0.94176966 0.52141774]]\n",
      "Hi!\n",
      "[[0.7676917  0.35678327 2.05641    0.         0.         0.9233111\n",
      "  0.01403208 0.         1.4349226  0.         0.82682616 0.\n",
      "  0.48885226 0.         0.         0.8033591  0.844113   0.98500526\n",
      "  0.41453576 0.1742728  1.5119725  0.4899253  0.         0.315769\n",
      "  0.1743261  0.         0.         0.         0.         0.\n",
      "  0.         0.12203896 0.         0.         0.         0.\n",
      "  0.4144668  0.939627   0.         0.99471277 0.01300752 0.\n",
      "  0.         0.9779369  0.         0.         0.         1.1485742\n",
      "  0.         1.0085872  0.8692715  0.00521482 0.14477476 0.16021647\n",
      "  0.         0.08923318 0.         0.9635277  0.22006872 0.\n",
      "  0.0046799  0.98678035 1.1840565  1.2380266 ]]\n",
      "Hi!\n",
      "[[0.37695    0.52021116 0.9626155  0.         0.         0.52517855\n",
      "  0.5695278  0.71989834 1.5733513  0.         0.6007254  0.\n",
      "  1.72664    0.         0.         1.1470387  0.         0.87297297\n",
      "  1.498506   0.         1.0940677  0.1796216  0.         0.\n",
      "  0.61346084 0.         0.         0.47821024 0.         0.\n",
      "  0.8728888  0.43293908 0.         0.         0.68643093 0.\n",
      "  0.9839935  1.492841   0.         0.61078453 0.2348986  0.\n",
      "  0.         0.71925104 0.45652142 0.         0.         1.3146371\n",
      "  0.         0.92329    1.3412004  0.2596236  0.1523263  0.5974931\n",
      "  0.         0.         0.42444608 0.29160166 0.         0.\n",
      "  0.         0.6904052  1.523426   1.0698271 ]]\n",
      "Hi!\n",
      "[[0.40683448 0.45063967 0.62279606 0.         0.         0.6533929\n",
      "  0.39910874 0.6307925  0.31080464 0.         0.40208188 0.\n",
      "  0.8437383  0.1912475  0.         0.33006242 0.         0.5330163\n",
      "  0.         0.4232158  0.5362467  0.         0.         0.00848861\n",
      "  0.00845319 0.         0.         0.17908354 0.         0.\n",
      "  0.7388807  0.58795947 0.         0.         0.30347025 0.\n",
      "  0.14373392 0.7499555  0.         0.35710683 0.         0.\n",
      "  0.         0.12833942 0.7421477  0.66183114 0.         0.60463095\n",
      "  0.0907027  0.72301847 0.37571245 0.41264293 0.42931783 0.7490207\n",
      "  0.         0.04162305 0.21161203 0.         0.         0.\n",
      "  0.         0.3962858  0.7371476  0.14904873]]\n",
      "Hi!\n",
      "[[0.65476614 1.1049982  0.9622824  0.         0.         0.63089377\n",
      "  0.         0.35113353 0.5573947  0.         0.5539909  0.\n",
      "  1.7524067  0.31833407 0.         0.39922804 0.         0.55272293\n",
      "  0.57421184 0.70222366 0.7211484  0.         0.         0.19208907\n",
      "  0.         0.         0.         0.28750026 0.         0.\n",
      "  0.93411046 0.90231156 0.         0.         0.2430599  0.\n",
      "  0.27110505 0.61822814 0.39943567 0.42856216 0.         0.\n",
      "  0.         0.2181109  0.9186944  0.42658308 0.         0.9695342\n",
      "  0.21651384 0.7390868  0.62402207 0.4707443  0.71338224 1.176554\n",
      "  0.         0.         0.26349366 0.         0.08396734 0.\n",
      "  0.         0.1933708  0.96345204 0.4693834 ]]\n",
      "Hi!\n",
      "[[0.52655447 0.         0.77115846 0.40529323 0.         1.0255418\n",
      "  1.2435052  1.4727399  0.42906076 0.         0.28981876 0.\n",
      "  0.06785695 0.         0.         0.26367542 0.         0.57401264\n",
      "  0.         0.01257966 0.758751   0.         0.         0.13990436\n",
      "  0.         0.         0.         0.34768724 0.         0.\n",
      "  0.7193392  0.62443763 0.11767682 0.         0.38727424 0.\n",
      "  0.         1.062784   0.         0.50600475 0.1519025  0.\n",
      "  0.         0.6524673  0.63769776 0.9794356  0.         0.1612609\n",
      "  0.         0.8825969  0.1850119  0.59179586 0.8299084  0.41095042\n",
      "  0.         0.63068044 0.14376591 0.         0.         0.\n",
      "  0.         0.75638455 1.3999422  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.12661889 0.19228415 0.         0.         0.11405435\n",
      "  0.         0.1918843  0.         0.01201701 0.02338401 0.\n",
      "  0.08385187 0.15237053 0.         0.         0.         0.\n",
      "  0.         0.09560711 0.05260669 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01551069 0.17754672 0.17215502 0.         0.         0.\n",
      "  0.         0.         0.21452558 0.08464522 0.         0.\n",
      "  0.         0.         0.20878117 0.2765444  0.         0.06663807\n",
      "  0.19386142 0.09663998 0.         0.24795498 0.0382201  0.3665935\n",
      "  0.         0.16691354 0.03792262 0.         0.         0.\n",
      "  0.0455011  0.01325688 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.14200713 0.04677042 0.         0.         0.03468451\n",
      "  0.         0.17308466 0.         0.09675933 0.09605458 0.\n",
      "  0.05286241 0.15072672 0.         0.         0.         0.02882827\n",
      "  0.         0.09422448 0.02114708 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02311512 0.13601777 0.1817331  0.         0.         0.\n",
      "  0.         0.         0.13415986 0.06872007 0.         0.\n",
      "  0.         0.         0.19663101 0.25356495 0.         0.\n",
      "  0.1548332  0.08894835 0.         0.13462256 0.0403622  0.263217\n",
      "  0.         0.07731503 0.05226073 0.         0.         0.\n",
      "  0.06442717 0.11767476 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.09730796 0.35922274 0.57929116 0.         0.         0.3133986\n",
      "  0.         0.         0.26108426 0.0709756  0.25122708 0.\n",
      "  0.1989756  0.         0.         0.09467411 0.05972138 0.19226359\n",
      "  0.         0.43465075 0.32374093 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15172598 0.01805769 0.         0.         0.\n",
      "  0.         0.         0.         0.23396525 0.         0.\n",
      "  0.         0.         0.         0.11307827 0.         0.29389226\n",
      "  0.29006937 0.26530713 0.06370258 0.24014053 0.11188884 0.36278576\n",
      "  0.         0.23503871 0.         0.         0.14436193 0.\n",
      "  0.21735792 0.27011383 0.10043007 0.22118095]]\n",
      "Hi!\n",
      "[[0.01594365 0.10880798 0.1389321  0.         0.         0.06728005\n",
      "  0.         0.11590438 0.08605508 0.08911975 0.11961577 0.\n",
      "  0.         0.         0.         0.13632219 0.         0.02806314\n",
      "  0.         0.1946048  0.16361877 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03704252 0.13864437 0.         0.         0.\n",
      "  0.         0.         0.04410739 0.10980371 0.         0.\n",
      "  0.         0.         0.09118201 0.26468715 0.         0.13176113\n",
      "  0.08388656 0.11105481 0.         0.15499873 0.         0.2831137\n",
      "  0.         0.10116518 0.         0.         0.         0.\n",
      "  0.04867379 0.15410867 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07817771 0.28179967 0.07962915 0.01054924 0.         0.02698153\n",
      "  0.         0.15180036 0.         0.         0.09318719 0.\n",
      "  0.23639038 0.3268497  0.         0.         0.         0.12274829\n",
      "  0.         0.14413656 0.03925399 0.         0.         0.\n",
      "  0.         0.         0.         0.04010168 0.         0.\n",
      "  0.14680962 0.25910094 0.20447898 0.         0.         0.\n",
      "  0.         0.         0.3554085  0.02614199 0.         0.\n",
      "  0.         0.         0.32283244 0.27274922 0.         0.\n",
      "  0.21245982 0.10133842 0.         0.21450357 0.07373234 0.46397248\n",
      "  0.         0.07518382 0.15726408 0.         0.         0.\n",
      "  0.12078514 0.08572951 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0312305  0.05146576 0.04281154 0.         0.         0.00731681\n",
      "  0.02112711 0.1479988  0.09206586 0.12282168 0.10226382 0.\n",
      "  0.         0.0043965  0.         0.12094001 0.         0.01030514\n",
      "  0.         0.12633693 0.12283035 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15177938 0.         0.         0.\n",
      "  0.         0.         0.03533999 0.07671427 0.         0.\n",
      "  0.         0.         0.11846346 0.21270075 0.         0.07828178\n",
      "  0.08374652 0.01892729 0.         0.13546558 0.         0.19640417\n",
      "  0.         0.04746321 0.00412727 0.         0.         0.\n",
      "  0.0081032  0.07423497 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.15692803 0.16063167 0.         0.         0.08798272\n",
      "  0.00772413 0.12328606 0.         0.09096413 0.11883605 0.\n",
      "  0.         0.05944335 0.         0.         0.         0.09379748\n",
      "  0.         0.18521418 0.07825805 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0690335  0.11533089 0.         0.         0.\n",
      "  0.         0.         0.11025897 0.11996072 0.         0.\n",
      "  0.         0.         0.1291682  0.30256373 0.         0.0111279\n",
      "  0.17775205 0.12233848 0.         0.18788745 0.06674168 0.22893326\n",
      "  0.         0.18306527 0.         0.         0.0045935  0.\n",
      "  0.08629982 0.13485801 0.         0.        ]]\n",
      "Hi!\n",
      "[[6.2778789e-01 2.4627137e-01 3.2293954e-01 4.1030970e-01 0.0000000e+00\n",
      "  3.8137993e-01 2.8299013e-01 5.5899888e-01 0.0000000e+00 0.0000000e+00\n",
      "  2.4522254e-02 0.0000000e+00 3.9747944e-01 6.8727803e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.2329354e-02 0.0000000e+00 3.5941049e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2703504e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 4.0268809e-01 0.0000000e+00 0.0000000e+00\n",
      "  6.5966028e-01 7.9679924e-01 4.2108032e-01 0.0000000e+00 1.1292114e-03\n",
      "  0.0000000e+00 0.0000000e+00 1.0266205e-01 8.4763360e-01 8.1412606e-02\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.8287349e-02 9.3545634e-01\n",
      "  7.8042227e-01 0.0000000e+00 0.0000000e+00 4.7731972e-01 6.5014237e-01\n",
      "  0.0000000e+00 5.7361120e-01 5.2354532e-01 1.1700505e+00 0.0000000e+00\n",
      "  4.7386476e-01 3.4040138e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2748975e-01 2.6627770e-01 2.0289452e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.00496156 0.23908299 0.15487652 0.         0.         0.0194931\n",
      "  0.         0.1644337  0.         0.         0.02476559 0.\n",
      "  0.30636647 0.18495224 0.         0.         0.         0.05133563\n",
      "  0.         0.02357479 0.02208333 0.         0.         0.\n",
      "  0.         0.         0.         0.04567094 0.         0.\n",
      "  0.11489439 0.28686583 0.178816   0.         0.         0.\n",
      "  0.         0.         0.37199    0.         0.         0.\n",
      "  0.         0.         0.34422252 0.20730309 0.         0.\n",
      "  0.17443033 0.08675808 0.         0.26713938 0.12991112 0.5057037\n",
      "  0.         0.07396221 0.09056155 0.         0.         0.\n",
      "  0.00256156 0.16824801 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.01351207 0.22267714 0.13319941 0.         0.         0.3059593\n",
      "  0.07389583 0.3232979  0.         0.1040365  0.1470546  0.\n",
      "  0.         0.1748135  0.         0.00340128 0.         0.2038644\n",
      "  0.         0.3422889  0.05107637 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06374434 0.1632837  0.18504691 0.         0.         0.\n",
      "  0.         0.         0.09021116 0.17943561 0.         0.\n",
      "  0.         0.         0.26410472 0.55037975 0.         0.\n",
      "  0.26520008 0.35659766 0.         0.24492054 0.23542197 0.36467457\n",
      "  0.         0.30480513 0.         0.         0.         0.\n",
      "  0.19787405 0.24888568 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.43809733 0.14301628 1.3622606  0.         0.         0.5122558\n",
      "  0.42938778 0.35349888 1.3630921  0.         0.6339768  0.\n",
      "  0.19540004 0.         0.         0.8298229  0.5406425  0.95704925\n",
      "  0.14466694 0.         1.2031841  0.45610633 0.         0.24237733\n",
      "  0.17171013 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.1913788  0.\n",
      "  0.17434463 1.0228053  0.         0.68744045 0.10439742 0.\n",
      "  0.         1.1831733  0.         0.         0.         0.6194486\n",
      "  0.         0.81818664 0.83505774 0.         0.00863709 0.\n",
      "  0.         0.         0.         0.71146965 0.05998359 0.\n",
      "  0.         1.1913973  0.9049134  0.9206462 ]]\n",
      "Hi!\n",
      "[[0.28829682 0.         0.         0.27073136 0.         0.3172739\n",
      "  1.6425505  1.7846668  0.47788212 0.         0.1780086  0.\n",
      "  0.7079809  0.6142916  0.         0.6357577  0.         0.63074046\n",
      "  0.02349161 0.         0.27327162 0.3024033  0.         0.\n",
      "  0.3185964  0.         0.         0.69595    0.         0.\n",
      "  1.3638269  0.40878406 0.10254241 0.         0.9621145  0.\n",
      "  0.24809298 1.3953792  0.         0.25473052 0.26264876 0.\n",
      "  0.         0.6467327  1.0261528  1.1255007  0.         0.12122372\n",
      "  0.         0.941282   0.6870152  0.4995502  0.7170479  0.51734155\n",
      "  0.         0.         0.38193208 0.         0.         0.\n",
      "  0.         0.7138222  0.913083   0.        ]]\n",
      "Hi!\n",
      "[[0.0777294  0.41921744 0.3656902  0.         0.         0.20641954\n",
      "  0.         0.         0.11946712 0.         0.24572116 0.\n",
      "  0.4083793  0.09919503 0.         0.01056688 0.         0.08667994\n",
      "  0.         0.3756048  0.22562587 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10806369 0.20979998 0.00197068 0.         0.         0.\n",
      "  0.         0.         0.16658567 0.12852201 0.         0.\n",
      "  0.         0.         0.12805878 0.12220139 0.         0.25119278\n",
      "  0.28352684 0.22257939 0.04875903 0.1950509  0.11990484 0.52304524\n",
      "  0.         0.         0.10560822 0.         0.11886251 0.\n",
      "  0.11309905 0.04300486 0.         0.04856912]]\n",
      "Hi!\n",
      "[[0.82751656 0.06768581 1.6333541  0.         0.         0.9313047\n",
      "  0.37133598 0.50745237 1.1755877  0.         0.6696066  0.\n",
      "  0.14934592 0.         0.         0.619096   0.60714084 0.8428139\n",
      "  0.         0.         1.3253564  0.24711812 0.         0.6491311\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22137952 0.06531501 0.         0.         0.\n",
      "  0.         0.8221792  0.         0.8848662  0.04450874 0.\n",
      "  0.         1.0912917  0.         0.15361594 0.         0.4929522\n",
      "  0.         0.85282344 0.5934109  0.2124754  0.49796554 0.06723875\n",
      "  0.         0.58544415 0.         0.4969649  0.         0.\n",
      "  0.         0.94811875 1.0961953  0.70581377]]\n",
      "Hi!\n",
      "[[0.6062543  0.         0.5546365  0.39384887 0.         0.86593974\n",
      "  1.633849   1.4334552  0.22518937 0.         0.26966512 0.\n",
      "  0.         0.         0.         0.18903948 0.         0.6361371\n",
      "  0.         0.         0.5328374  0.05930443 0.         0.09296167\n",
      "  0.         0.         0.         0.02315265 0.         0.\n",
      "  0.4114447  0.30645055 0.23432377 0.         0.33516872 0.\n",
      "  0.         0.80407727 0.         0.65885645 0.14728445 0.\n",
      "  0.         0.9553566  0.38765442 0.9665784  0.         0.\n",
      "  0.00521568 0.99544513 0.03728283 0.44566375 0.6488827  0.1691571\n",
      "  0.         0.645437   0.         0.         0.         0.\n",
      "  0.         0.97643405 0.6299619  0.        ]]\n",
      "Hi!\n",
      "[[1.1765904  0.05290703 1.7792307  0.         0.         1.16355\n",
      "  0.35344434 0.43063152 0.7971432  0.03421455 0.6152469  0.\n",
      "  0.         0.         0.         0.2199303  0.8962571  0.75921696\n",
      "  0.         0.2853935  1.1987846  0.2918726  0.         0.6365069\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05853134 0.2239168  0.         0.         0.\n",
      "  0.         0.3755842  0.         1.0793525  0.         0.\n",
      "  0.         1.3139087  0.         0.3709608  0.         0.09254631\n",
      "  0.22901805 1.245142   0.34447032 0.11748569 0.7522036  0.\n",
      "  0.         1.2977061  0.         0.41114613 0.01341278 0.\n",
      "  0.4719294  0.95267075 0.52802455 0.4470796 ]]\n",
      "Hi!\n",
      "[[0.26570994 0.41973966 1.2701335  0.         0.         0.67126775\n",
      "  0.32149494 0.2661435  1.2700585  0.         0.6393963  0.\n",
      "  0.95744264 0.         0.         0.90836126 0.2025689  0.9141436\n",
      "  0.7449744  0.0429625  1.1198671  0.2514782  0.         0.03259382\n",
      "  0.34178406 0.         0.         0.00874972 0.         0.\n",
      "  0.3013372  0.22500077 0.         0.         0.36054033 0.\n",
      "  0.5840621  1.1979597  0.         0.72873414 0.14847499 0.\n",
      "  0.         0.69594216 0.14700224 0.         0.         1.1343265\n",
      "  0.         0.81434333 0.9557059  0.14182861 0.07828086 0.3383189\n",
      "  0.         0.         0.15125239 0.5107604  0.0343079  0.\n",
      "  0.         0.85356116 1.2005756  1.018199  ]]\n",
      "Hi!\n",
      "[[0.         0.1614955  0.14992194 0.         0.         0.22810632\n",
      "  0.         0.12245829 0.         0.09804562 0.15766667 0.\n",
      "  0.0192821  0.11654738 0.         0.         0.         0.05090885\n",
      "  0.         0.25196153 0.0745895  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11110087 0.10905274 0.         0.         0.\n",
      "  0.         0.         0.06702052 0.11284403 0.         0.\n",
      "  0.         0.         0.14134665 0.35479152 0.         0.11067273\n",
      "  0.21481231 0.17617907 0.         0.21729268 0.06920821 0.33729798\n",
      "  0.         0.16562709 0.         0.         0.00565615 0.\n",
      "  0.07246794 0.08333047 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.42934194 0.28469262 0.14295055 0.09548407 0.         0.48974964\n",
      "  0.8531901  1.0219609  0.02429328 0.         0.19488803 0.\n",
      "  0.5042681  0.44368792 0.         0.18966438 0.         0.45860142\n",
      "  0.         0.33926418 0.23657556 0.         0.         0.01164031\n",
      "  0.         0.         0.         0.30347425 0.         0.\n",
      "  0.94240224 0.5484389  0.0806579  0.         0.40548977 0.\n",
      "  0.         0.7986393  0.         0.26477453 0.         0.\n",
      "  0.         0.1354183  0.89795804 1.0033059  0.         0.19202532\n",
      "  0.02743715 0.83949935 0.24582903 0.43468285 0.52511895 0.67734534\n",
      "  0.         0.014573   0.23454578 0.         0.         0.\n",
      "  0.         0.470688   0.41376    0.        ]]\n",
      "Hi!\n",
      "[[0.13047114 0.3065945  0.36608285 0.         0.         0.44650576\n",
      "  0.         0.1528173  0.         0.11972614 0.1859325  0.\n",
      "  0.01756146 0.12055597 0.         0.02219329 0.         0.1840472\n",
      "  0.         0.47639644 0.1642046  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09464346 0.27940834 0.07708673 0.         0.         0.\n",
      "  0.         0.         0.         0.21157491 0.         0.\n",
      "  0.         0.         0.30445033 0.49047637 0.         0.19945125\n",
      "  0.38663533 0.4237044  0.         0.27683166 0.28483012 0.5163366\n",
      "  0.         0.4825341  0.         0.         0.01888587 0.\n",
      "  0.2195639  0.21539456 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.17808117 0.459169   0.17261483 0.03363301 0.         0.04699142\n",
      "  0.         0.20766266 0.         0.         0.13092288 0.\n",
      "  0.23856816 0.3540731  0.         0.         0.         0.16862896\n",
      "  0.         0.3841159  0.04305962 0.         0.         0.04842928\n",
      "  0.         0.         0.         0.07226157 0.         0.\n",
      "  0.25427493 0.40626496 0.2098456  0.         0.         0.\n",
      "  0.         0.         0.39430884 0.05393896 0.         0.\n",
      "  0.         0.         0.4371934  0.41134357 0.         0.\n",
      "  0.26713866 0.27919415 0.         0.24283744 0.19920251 0.5656732\n",
      "  0.         0.15232792 0.15367334 0.         0.         0.\n",
      "  0.13127103 0.1964569  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.7009586  0.5382046  0.58060163 0.14006963 0.         0.76652336\n",
      "  0.47549334 0.8145133  0.26137382 0.         0.36285427 0.\n",
      "  1.1450578  0.4211725  0.         0.27447733 0.         0.49496558\n",
      "  0.2651704  0.55523217 0.48415974 0.         0.         0.12127957\n",
      "  0.07034578 0.         0.         0.5484893  0.         0.\n",
      "  1.0364305  0.9058674  0.         0.         0.47133595 0.\n",
      "  0.4517837  0.9244532  0.3518684  0.22539848 0.         0.\n",
      "  0.         0.2579182  1.2095499  0.7700466  0.         0.82697344\n",
      "  0.05615104 0.67685026 0.4099839  0.55604726 0.5161589  1.0632619\n",
      "  0.         0.13326712 0.44743708 0.         0.         0.\n",
      "  0.         0.24776533 1.083915   0.        ]]\n",
      "Hi!\n",
      "[[0.15085748 0.63662267 0.9213294  0.         0.         0.5475018\n",
      "  0.27495918 0.22876418 0.92937636 0.         0.529591   0.\n",
      "  0.88357264 0.         0.         0.5309173  0.         0.70437\n",
      "  0.29794455 0.28934693 0.880342   0.04923961 0.         0.06302506\n",
      "  0.06767286 0.         0.         0.         0.         0.\n",
      "  0.326182   0.32830116 0.         0.         0.16270423 0.\n",
      "  0.05354396 0.690589   0.         0.5833187  0.         0.\n",
      "  0.         0.30003655 0.12069309 0.10722524 0.         0.67335695\n",
      "  0.         0.6781219  0.6437617  0.19760093 0.3567774  0.27348188\n",
      "  0.         0.         0.         0.         0.05380325 0.\n",
      "  0.         0.73950213 0.62014085 0.73959273]]\n",
      "Hi!\n",
      "[[0.23819706 0.19624123 0.9607754  0.         0.         0.579415\n",
      "  0.69451874 0.73482907 1.3730547  0.         0.5685175  0.\n",
      "  1.0473996  0.         0.         1.0032334  0.         0.8921963\n",
      "  0.87874657 0.         1.0058352  0.20546024 0.         0.\n",
      "  0.3535562  0.         0.         0.24203092 0.         0.\n",
      "  0.58727986 0.24138737 0.         0.         0.50985736 0.\n",
      "  0.6729046  1.3572432  0.         0.62636113 0.2025771  0.\n",
      "  0.         0.898709   0.26643905 0.1539647  0.         0.9273263\n",
      "  0.         0.796889   1.005825   0.20337352 0.11908682 0.27121392\n",
      "  0.         0.         0.2726932  0.38034332 0.         0.\n",
      "  0.         0.87184    1.3133409  0.85694104]]\n",
      "Hi!\n",
      "[[0.83582574 0.466387   1.5271536  0.         0.         1.0968273\n",
      "  0.2313024  0.37903562 0.81280494 0.02548842 0.6136871  0.\n",
      "  0.39787716 0.         0.         0.25877422 0.37122986 0.6625354\n",
      "  0.         0.34800333 1.1343966  0.         0.         0.58329284\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06391808 0.41165388 0.08676578 0.         0.         0.\n",
      "  0.         0.41170812 0.         0.7594923  0.         0.\n",
      "  0.         0.5362151  0.         0.3919125  0.         0.42227504\n",
      "  0.24110802 1.0589544  0.41119614 0.39663002 0.8317933  0.35220215\n",
      "  0.         0.8796398  0.         0.09667778 0.06192793 0.\n",
      "  0.         0.6491211  0.8197057  0.5778621 ]]\n",
      "Hi!\n",
      "[[0.21216394 0.2615278  0.70332444 0.         0.         0.4817832\n",
      "  0.6814094  0.8124531  0.8544526  0.         0.49505994 0.\n",
      "  0.7152089  0.         0.         0.6699581  0.         0.7444931\n",
      "  0.08746877 0.05340492 0.76341754 0.         0.         0.\n",
      "  0.08163562 0.         0.         0.21649279 0.         0.\n",
      "  0.7252176  0.32690266 0.         0.         0.4854371  0.\n",
      "  0.12848917 1.0377603  0.         0.4301506  0.07396092 0.\n",
      "  0.         0.57577103 0.40591007 0.47040027 0.         0.39050505\n",
      "  0.         0.75055885 0.6221788  0.2787609  0.4868693  0.23957121\n",
      "  0.         0.         0.16076677 0.         0.         0.\n",
      "  0.         0.819968   0.9964608  0.3290931 ]]\n",
      "Hi!\n",
      "[[0.         0.07903174 0.0622702  0.         0.         0.21419846\n",
      "  0.15762007 0.2628201  0.         0.17190711 0.1463829  0.\n",
      "  0.         0.0847671  0.         0.03477833 0.         0.08449193\n",
      "  0.         0.20621867 0.0851461  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15238856 0.         0.         0.\n",
      "  0.         0.         0.01668241 0.18758903 0.         0.\n",
      "  0.         0.         0.1296582  0.44933715 0.         0.06421237\n",
      "  0.16668989 0.20708703 0.         0.23058291 0.1417256  0.28903574\n",
      "  0.         0.12944159 0.         0.         0.         0.\n",
      "  0.06207009 0.21921717 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.87978405 0.         1.1336198  0.30402285 0.         1.1724851\n",
      "  0.7663812  0.96980494 0.26979452 0.08458652 0.37723732 0.\n",
      "  0.         0.         0.         0.18786664 0.34870675 0.5387188\n",
      "  0.         0.2926351  0.7740001  0.         0.         0.4527272\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3437792  0.22465217 0.         0.         0.\n",
      "  0.         0.41154674 0.         0.8828171  0.         0.\n",
      "  0.         0.86135256 0.08375877 0.7592662  0.         0.\n",
      "  0.21517166 1.1638254  0.         0.44035277 1.0004216  0.15559842\n",
      "  0.         1.3804036  0.         0.         0.         0.\n",
      "  0.3741645  0.7373811  0.6513531  0.        ]]\n",
      "Hi!\n",
      "[[0.17841674 1.0206195  1.0607703  0.         0.         0.60897\n",
      "  0.02269474 0.11816997 0.9217619  0.         0.60533595 0.\n",
      "  1.3549677  0.         0.         0.5211131  0.04967529 0.6288904\n",
      "  0.2795131  0.5062899  0.9145599  0.         0.         0.12889494\n",
      "  0.         0.         0.         0.02502347 0.         0.\n",
      "  0.40916407 0.39144537 0.         0.         0.05366985 0.\n",
      "  0.         0.4806318  0.         0.5961035  0.         0.\n",
      "  0.         0.15167844 0.12709992 0.05105408 0.         0.7075874\n",
      "  0.         0.89861965 0.783321   0.21983479 0.41887242 0.59499705\n",
      "  0.         0.         0.         0.         0.07316604 0.\n",
      "  0.         0.6719949  0.56684715 0.78881085]]\n",
      "Hi!\n",
      "[[0.24343789 0.32915267 0.5404554  0.         0.         0.48885378\n",
      "  0.03522816 0.11992516 0.02194896 0.12591943 0.25104004 0.\n",
      "  0.         0.         0.         0.05320689 0.         0.3213897\n",
      "  0.         0.56135434 0.2971386  0.         0.         0.03428893\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01998679 0.23666297 0.04810451 0.         0.         0.\n",
      "  0.         0.04181364 0.         0.31066146 0.         0.\n",
      "  0.         0.00591019 0.19014068 0.4489614  0.         0.19719873\n",
      "  0.34423912 0.516187   0.         0.23922114 0.24473171 0.3685658\n",
      "  0.         0.428193   0.         0.         0.03515108 0.\n",
      "  0.30242023 0.3811119  0.01233457 0.05434364]]\n",
      "Hi!\n",
      "[[0.03644469 0.2102423  0.08002841 0.         0.         0.04536087\n",
      "  0.         0.10519236 0.05005836 0.03718942 0.11261583 0.\n",
      "  0.1915955  0.16116445 0.         0.05204804 0.         0.03658773\n",
      "  0.         0.13221845 0.09437455 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04316772 0.14328253 0.11594382 0.         0.         0.\n",
      "  0.         0.         0.18848506 0.01355429 0.         0.\n",
      "  0.         0.         0.17168826 0.22500594 0.         0.02044716\n",
      "  0.10482097 0.06001502 0.         0.14898014 0.01322671 0.38107547\n",
      "  0.         0.         0.07383019 0.         0.         0.\n",
      "  0.01594727 0.14516771 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.47052366 0.10519957 0.7228639  0.         0.         0.6573643\n",
      "  0.33455575 0.36732832 0.2623482  0.21422444 0.28997463 0.\n",
      "  0.         0.         0.         0.2118975  0.21823074 0.4398771\n",
      "  0.         0.332454   0.5373811  0.         0.         0.22842818\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01546125 0.09982608 0.         0.         0.\n",
      "  0.         0.16987292 0.         0.6008913  0.         0.\n",
      "  0.         0.4732658  0.         0.4643206  0.         0.07792952\n",
      "  0.23165244 0.77146083 0.02896152 0.15699603 0.35786316 0.04918511\n",
      "  0.         0.5762634  0.         0.         0.03111163 0.\n",
      "  0.3734285  0.72092104 0.07401825 0.12068459]]\n",
      "Hi!\n",
      "[[0.4027162  1.0960118  0.43885365 0.         0.         0.38339642\n",
      "  0.         0.32604212 0.1874057  0.         0.4036846  0.\n",
      "  1.3312733  0.51352215 0.         0.07596105 0.         0.31040862\n",
      "  0.1151166  0.7334468  0.40498048 0.         0.         0.29264516\n",
      "  0.         0.         0.         0.47121075 0.         0.\n",
      "  0.769595   0.6292642  0.         0.         0.08797941 0.\n",
      "  0.         0.07298837 0.7446407  0.20060703 0.         0.\n",
      "  0.         0.07351895 0.8820062  0.629682   0.         0.5294476\n",
      "  0.306607   0.4761549  0.36720735 0.41853592 0.7454989  1.0656607\n",
      "  0.         0.         0.36520886 0.         0.01671379 0.\n",
      "  0.         0.0998304  0.33902067 0.1067704 ]]\n",
      "Hi!\n",
      "[[0.6360853  0.10144632 0.8939403  0.04739689 0.         0.9358397\n",
      "  0.6372021  0.83966017 0.5511638  0.11876057 0.37588933 0.\n",
      "  0.         0.         0.         0.12595895 0.02803508 0.6535635\n",
      "  0.         0.15590954 0.7779835  0.         0.         0.46036822\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24350107 0.2602623  0.18259658 0.         0.         0.\n",
      "  0.         0.48709092 0.         0.8010161  0.         0.\n",
      "  0.         0.6751276  0.         0.8149662  0.         0.\n",
      "  0.074705   1.210959   0.22092412 0.40648553 0.9642691  0.10072145\n",
      "  0.         0.7059133  0.         0.         0.         0.\n",
      "  0.         0.8844376  0.49588302 0.10266351]]\n",
      "Hi!\n",
      "[[2.5604934e-01 3.1121984e-01 1.2706543e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.9704098e-01 4.4824031e-01 5.1562494e-01 1.4004130e+00 0.0000000e+00\n",
      "  6.6458708e-01 0.0000000e+00 1.1124887e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.3999130e-01 6.1193906e-02 9.0432823e-01 8.9360321e-01 0.0000000e+00\n",
      "  1.1799564e+00 1.8678294e-01 0.0000000e+00 1.0996875e-01 3.3557901e-01\n",
      "  0.0000000e+00 0.0000000e+00 1.5608156e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.5597526e-01 3.2820472e-01 0.0000000e+00 0.0000000e+00 4.4388974e-01\n",
      "  0.0000000e+00 6.1897814e-01 1.2668084e+00 0.0000000e+00 6.9083798e-01\n",
      "  1.8771243e-01 0.0000000e+00 0.0000000e+00 7.7362102e-01 1.7341164e-01\n",
      "  3.2138947e-04 0.0000000e+00 1.0339342e+00 0.0000000e+00 8.5497797e-01\n",
      "  1.0267383e+00 2.0613876e-01 2.5901183e-01 2.8123850e-01 0.0000000e+00\n",
      "  0.0000000e+00 1.6377789e-01 4.4435716e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 8.7682188e-01 1.4120675e+00 1.0206497e+00]]\n",
      "Hi!\n",
      "[[0.41411096 0.         0.70248556 0.2782795  0.         0.7962418\n",
      "  1.7119547  1.7980024  0.94228315 0.         0.35557976 0.\n",
      "  0.08006896 0.         0.         0.7152581  0.         0.74597114\n",
      "  0.         0.         0.8466974  0.1801112  0.         0.1857144\n",
      "  0.06093917 0.         0.         0.41686666 0.         0.\n",
      "  0.770394   0.32056457 0.1072934  0.         0.65941125 0.\n",
      "  0.         1.4519993  0.         0.51746756 0.32435808 0.\n",
      "  0.         1.2903194  0.37459302 0.8211943  0.         0.09974872\n",
      "  0.         0.8355414  0.4809639  0.47745624 0.6835055  0.\n",
      "  0.         0.0930932  0.18336748 0.         0.         0.\n",
      "  0.         1.0912957  1.5943867  0.        ]]\n",
      "Hi!\n",
      "[[1.1207039  0.         1.7447201  0.03382967 0.         1.0744833\n",
      "  0.89007306 1.0738618  1.2846911  0.         0.6247747  0.\n",
      "  0.         0.         0.         0.64067876 0.7799936  0.8218831\n",
      "  0.         0.         1.3800237  0.3981052  0.         0.82970065\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26488492 0.11493129 0.         0.         0.\n",
      "  0.         0.984268   0.         0.9195027  0.06675538 0.\n",
      "  0.         1.5922145  0.         0.31526932 0.         0.3657073\n",
      "  0.         0.98146266 0.6324644  0.25019953 0.6767415  0.\n",
      "  0.         0.918336   0.         0.56993484 0.         0.\n",
      "  0.         1.1742996  1.3896978  0.5823195 ]]\n",
      "Hi!\n",
      "[[0.48286155 0.26199377 0.5436956  0.07776607 0.         0.81615347\n",
      "  0.3457287  0.55758566 0.         0.18392794 0.22339685 0.\n",
      "  0.         0.         0.         0.11751584 0.         0.33014527\n",
      "  0.         0.63646924 0.35313913 0.         0.         0.03672262\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11648809 0.33875564 0.1294761  0.         0.         0.\n",
      "  0.         0.12274928 0.         0.5719909  0.         0.\n",
      "  0.         0.19679685 0.3540752  0.82143736 0.         0.08622922\n",
      "  0.42855477 0.869817   0.         0.4459067  0.6320177  0.43800938\n",
      "  0.         0.9528318  0.         0.         0.         0.\n",
      "  0.44726184 0.49856675 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06043635 0.20390597 0.35313144 0.         0.         0.28437567\n",
      "  0.         0.16993043 0.         0.08987076 0.14167643 0.\n",
      "  0.         0.01201834 0.         0.02474358 0.         0.\n",
      "  0.         0.35073382 0.1298794  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14160413 0.08656383 0.         0.         0.\n",
      "  0.         0.03744202 0.0953382  0.17391276 0.         0.\n",
      "  0.         0.         0.23347144 0.36849228 0.         0.10851831\n",
      "  0.2087025  0.28467995 0.         0.30708203 0.270879   0.38112125\n",
      "  0.         0.34848014 0.         0.         0.         0.\n",
      "  0.1376747  0.17006737 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0169849  0.15689415 0.09673875 0.         0.         0.08962297\n",
      "  0.         0.17896318 0.         0.07663801 0.10872275 0.\n",
      "  0.         0.14616008 0.         0.0071895  0.         0.07198632\n",
      "  0.         0.1759304  0.05642308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00036905 0.13582523 0.14905795 0.         0.         0.\n",
      "  0.         0.         0.10532162 0.08995763 0.         0.\n",
      "  0.         0.         0.16810973 0.3184802  0.         0.\n",
      "  0.19446597 0.15618733 0.         0.19783847 0.03986544 0.3171497\n",
      "  0.         0.14854427 0.00092173 0.         0.         0.\n",
      "  0.05875344 0.11896847 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.27947402 0.81615174 1.0097971  0.         0.         0.62802786\n",
      "  0.06230247 0.13374153 0.8782208  0.         0.5297654  0.\n",
      "  1.2329365  0.         0.         0.6151188  0.         0.67529744\n",
      "  0.4718804  0.44759786 0.8515371  0.03220665 0.         0.\n",
      "  0.11436236 0.         0.         0.         0.         0.\n",
      "  0.43336067 0.42566147 0.         0.         0.22956361 0.\n",
      "  0.2633499  0.83156544 0.         0.6459372  0.         0.\n",
      "  0.         0.18257497 0.29529586 0.00559677 0.         0.98938006\n",
      "  0.         0.7694522  0.7189662  0.22156002 0.14638461 0.6112197\n",
      "  0.         0.         0.09708329 0.         0.08110229 0.\n",
      "  0.         0.58530253 0.7788726  0.77983487]]\n",
      "Hi!\n",
      "[[0.18887752 0.         0.69636524 0.05846246 0.         0.72710484\n",
      "  1.4851406  1.6347699  1.226426   0.         0.45237038 0.\n",
      "  0.7724298  0.         0.         0.9460933  0.         0.80363566\n",
      "  0.72918034 0.         0.9286414  0.22976117 0.         0.\n",
      "  0.29941443 0.         0.         0.691499   0.         0.\n",
      "  1.0326198  0.37445185 0.         0.         0.7630076  0.\n",
      "  0.53932214 1.6081719  0.         0.3381885  0.33202434 0.\n",
      "  0.         1.2557541  0.56116253 0.74037504 0.         0.5514279\n",
      "  0.         0.6645885  0.876208   0.42976758 0.4127545  0.24026705\n",
      "  0.         0.         0.4687826  0.16601679 0.         0.\n",
      "  0.         0.8958001  1.75266    0.37993538]]\n",
      "Hi!\n",
      "[[0.4939213  0.5088486  0.3823056  0.06360456 0.         0.4671596\n",
      "  0.2010646  0.32023302 0.         0.         0.09374606 0.\n",
      "  0.55859375 0.38296235 0.         0.         0.         0.16087727\n",
      "  0.         0.6139952  0.0720081  0.         0.         0.07184938\n",
      "  0.         0.         0.         0.38783804 0.         0.\n",
      "  0.60999835 0.7244744  0.21115471 0.         0.07097916 0.\n",
      "  0.         0.2215085  0.44836718 0.20782237 0.         0.\n",
      "  0.         0.13465412 0.75286114 0.7129328  0.         0.42917463\n",
      "  0.49532753 0.50004214 0.         0.42857566 0.37157968 1.0883749\n",
      "  0.         0.5255718  0.22715154 0.         0.         0.\n",
      "  0.05151629 0.07165928 0.21450217 0.        ]]\n",
      "Hi!\n",
      "[[0.26671228 0.07312017 0.         0.2475395  0.         0.31303582\n",
      "  1.3533738  1.3296973  0.         0.         0.00166843 0.\n",
      "  0.09315776 0.47636077 0.         0.24335764 0.         0.3935386\n",
      "  0.         0.22654493 0.         0.12849668 0.         0.\n",
      "  0.15191443 0.         0.         0.3220571  0.         0.\n",
      "  0.8439281  0.3327813  0.39737386 0.         0.4796083  0.\n",
      "  0.08388989 0.83004934 0.00933179 0.30507997 0.04353286 0.\n",
      "  0.         0.24682489 0.93795073 1.1650738  0.         0.02681414\n",
      "  0.         0.81842947 0.17500846 0.43711844 0.36470166 0.72217906\n",
      "  0.         0.10098441 0.2820667  0.         0.         0.\n",
      "  0.         0.5338775  0.1930577  0.        ]]\n",
      "Hi!\n",
      "[[0.22212851 0.         0.14770727 0.34723598 0.         0.6023525\n",
      "  1.9764335  1.9964527  0.66657    0.         0.23618792 0.\n",
      "  0.27640012 0.09321487 0.         0.66162723 0.         0.72860867\n",
      "  0.         0.         0.51493657 0.27801672 0.         0.\n",
      "  0.20288089 0.         0.         0.6389537  0.         0.\n",
      "  1.2362052  0.29564518 0.01534915 0.         0.9481584  0.\n",
      "  0.13421096 1.4946979  0.         0.3389661  0.3984112  0.\n",
      "  0.         1.0674666  0.79765844 1.1525791  0.         0.01064579\n",
      "  0.         0.8796305  0.50381106 0.52446586 0.76666546 0.17801076\n",
      "  0.         0.         0.36790165 0.         0.         0.\n",
      "  0.         0.9615548  1.4036703  0.        ]]\n",
      "Hi!\n",
      "[[0.17774126 0.24354005 0.         0.10976012 0.         0.21418068\n",
      "  0.42338982 0.48036954 0.         0.0121463  0.         0.\n",
      "  0.23566881 0.4584304  0.         0.03304345 0.         0.09757879\n",
      "  0.         0.22200727 0.         0.         0.         0.05128575\n",
      "  0.         0.         0.         0.27859125 0.         0.\n",
      "  0.46980888 0.40934962 0.38594815 0.         0.03599678 0.\n",
      "  0.         0.07979556 0.38336655 0.05553129 0.         0.\n",
      "  0.         0.07349995 0.58704364 0.66071993 0.         0.03735604\n",
      "  0.26611125 0.40410423 0.         0.34183285 0.22182512 0.64513284\n",
      "  0.         0.28982818 0.22218856 0.         0.         0.\n",
      "  0.05985419 0.22890718 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.14589883 0.6239664  0.50164795 0.         0.         0.3886055\n",
      "  0.         0.14363661 0.15054749 0.01733254 0.31673604 0.\n",
      "  0.43200755 0.13699086 0.         0.02531599 0.         0.2834832\n",
      "  0.         0.6262547  0.32127026 0.         0.         0.04044225\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17642608 0.3107977  0.         0.         0.         0.\n",
      "  0.         0.         0.20084028 0.24388704 0.         0.\n",
      "  0.         0.         0.2750317  0.39644685 0.         0.247868\n",
      "  0.29968348 0.35405535 0.03886441 0.3231283  0.28664193 0.5330291\n",
      "  0.         0.17484735 0.07410325 0.         0.10545841 0.\n",
      "  0.04216091 0.21519014 0.14630507 0.04404627]]\n",
      "Hi!\n",
      "[[0.14376363 0.34886253 0.23921101 0.         0.         0.3764121\n",
      "  0.         0.13013732 0.         0.03399313 0.20256941 0.\n",
      "  0.18476391 0.21686123 0.         0.         0.         0.11167245\n",
      "  0.         0.4349291  0.13977242 0.         0.         0.01380491\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14572626 0.29744577 0.10167343 0.         0.         0.\n",
      "  0.         0.         0.17054777 0.18269873 0.         0.\n",
      "  0.         0.         0.33832368 0.49451947 0.         0.24419278\n",
      "  0.37996653 0.29164055 0.         0.3314083  0.20083919 0.5506541\n",
      "  0.         0.32983062 0.05043304 0.         0.0554823  0.\n",
      "  0.11042112 0.05644173 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0270718  0.         1.5496453  0.14690118 0.         0.9623452\n",
      "  0.9187322  1.0288152  1.1009738  0.         0.58744836 0.\n",
      "  0.         0.         0.         0.571355   0.7603141  0.7972632\n",
      "  0.         0.         1.261745   0.3740491  0.         0.738944\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13030839 0.16859896 0.         0.         0.\n",
      "  0.         0.9205497  0.         0.9328708  0.09012693 0.\n",
      "  0.         1.4995488  0.         0.3284698  0.         0.07361364\n",
      "  0.         1.0134438  0.45805934 0.17170195 0.7129675  0.\n",
      "  0.         0.88292414 0.         0.45050764 0.         0.\n",
      "  0.         1.1697049  1.2104281  0.3315674 ]]\n",
      "Hi!\n",
      "[[0.04024446 0.16825815 0.1712698  0.         0.         0.07306362\n",
      "  0.         0.06044498 0.08266289 0.09960806 0.11823453 0.\n",
      "  0.104142   0.03949594 0.         0.0754839  0.         0.03464263\n",
      "  0.         0.12831976 0.10280883 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07778634 0.08885161 0.         0.         0.\n",
      "  0.         0.         0.05324032 0.08030832 0.         0.\n",
      "  0.         0.         0.07112931 0.16958836 0.         0.05026683\n",
      "  0.10618823 0.07847637 0.         0.13441263 0.0188019  0.23589963\n",
      "  0.         0.         0.03933926 0.         0.00194678 0.\n",
      "  0.07282291 0.13492599 0.         0.00176091]]\n",
      "Hi!\n",
      "[[0.17815486 0.         0.447362   0.05198487 0.         0.5233989\n",
      "  1.4615222  1.4925435  0.93164444 0.         0.39762726 0.\n",
      "  0.4882793  0.         0.         0.7951062  0.         0.77772796\n",
      "  0.16639097 0.         0.6827095  0.14379658 0.         0.\n",
      "  0.27626556 0.         0.         0.4628062  0.         0.\n",
      "  0.9553957  0.23611362 0.         0.         0.7888589  0.\n",
      "  0.30774447 1.4211854  0.         0.35259312 0.2284711  0.\n",
      "  0.         1.0414518  0.5299935  0.7262588  0.         0.2920177\n",
      "  0.         0.6974477  0.71291596 0.35706937 0.502586   0.10505436\n",
      "  0.         0.         0.26697886 0.         0.         0.\n",
      "  0.         0.94213265 1.2900627  0.15140095]]\n",
      "Hi!\n",
      "[[0.55112493 0.9533921  0.8032146  0.         0.         0.59095985\n",
      "  0.05272652 0.5759997  0.9038382  0.         0.5368666  0.\n",
      "  1.8874093  0.3375129  0.         0.569218   0.         0.5697664\n",
      "  0.9491971  0.43826962 0.767979   0.         0.         0.09476988\n",
      "  0.1860939  0.         0.         0.32390183 0.         0.\n",
      "  1.0239539  0.7918131  0.         0.         0.41231725 0.\n",
      "  0.37855485 0.9076988  0.15980628 0.35443366 0.         0.\n",
      "  0.         0.30376488 0.8460232  0.41474223 0.         1.1230125\n",
      "  0.         0.75603133 0.89692223 0.45293832 0.7289774  1.036975\n",
      "  0.         0.         0.35288522 0.         0.         0.\n",
      "  0.         0.30527192 1.1434789  0.66619354]]\n",
      "Hi!\n",
      "[[0.57093924 0.4127528  1.2996645  0.         0.         1.0202032\n",
      "  0.17138155 0.41570318 0.83496714 0.         0.5930194  0.\n",
      "  0.70160335 0.         0.         0.3781114  0.12475788 0.63860583\n",
      "  0.09028567 0.33285478 1.0405864  0.         0.         0.28373158\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29131815 0.4884214  0.         0.         0.02186583 0.\n",
      "  0.         0.68535346 0.         0.6816167  0.         0.\n",
      "  0.         0.35406372 0.2152471  0.34317082 0.         0.7213009\n",
      "  0.14687157 0.82926077 0.47416753 0.41816428 0.63342434 0.48382834\n",
      "  0.         0.47409537 0.         0.10872052 0.04512349 0.\n",
      "  0.         0.5661235  1.0288746  0.61809564]]\n",
      "Hi!\n",
      "[[0.6115846  0.74957824 1.4930097  0.         0.         1.0003873\n",
      "  0.         0.         0.5884453  0.         0.65951276 0.\n",
      "  0.6811712  0.         0.         0.31082818 0.30398992 0.70979834\n",
      "  0.         0.85271317 1.0168735  0.         0.         0.06836571\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.48847046 0.         0.         0.         0.\n",
      "  0.04314495 0.32749957 0.         0.79619056 0.         0.\n",
      "  0.         0.05249652 0.25032172 0.15987611 0.         0.9349765\n",
      "  0.439418   0.72347766 0.41629407 0.32030922 0.4021445  0.6745258\n",
      "  0.         0.54838085 0.         0.08616225 0.1522952  0.\n",
      "  0.10630593 0.47223535 0.75104237 0.64547205]]\n",
      "Hi!\n",
      "[[0.5418082  0.         0.2151997  0.30385673 0.         0.81120527\n",
      "  1.2059846  1.2732306  0.         0.         0.10372949 0.\n",
      "  0.12218173 0.23466457 0.         0.09127334 0.         0.33152178\n",
      "  0.         0.3996725  0.18222998 0.09060259 0.         0.\n",
      "  0.         0.         0.         0.29063508 0.         0.\n",
      "  0.8939294  0.67350864 0.29553568 0.         0.39959654 0.\n",
      "  0.         0.7967638  0.13207927 0.263616   0.06699724 0.\n",
      "  0.         0.26415887 1.0237561  1.221513   0.         0.32942593\n",
      "  0.24942228 0.79974484 0.03841115 0.6715579  0.5960142  1.0546247\n",
      "  0.         0.76382846 0.31610253 0.         0.         0.\n",
      "  0.         0.27562118 0.64992744 0.        ]]\n",
      "Hi!\n",
      "[[0.12351994 0.42672276 0.16887939 0.         0.         0.21932235\n",
      "  0.         0.10611251 0.03814963 0.         0.09637357 0.\n",
      "  0.573147   0.31928283 0.         0.02038045 0.         0.0620331\n",
      "  0.         0.32705462 0.02146165 0.         0.         0.01383635\n",
      "  0.         0.         0.         0.09656391 0.         0.\n",
      "  0.310626   0.35945567 0.09534652 0.         0.05225545 0.\n",
      "  0.06280877 0.05305155 0.2564901  0.10579196 0.         0.\n",
      "  0.         0.         0.42017925 0.35818562 0.         0.3552553\n",
      "  0.09757761 0.2218992  0.         0.2242199  0.0784168  0.5611608\n",
      "  0.         0.0141004  0.26374117 0.         0.         0.\n",
      "  0.04672791 0.10733663 0.0250347  0.        ]]\n",
      "Hi!\n",
      "[[0.7825842  0.48451808 1.7141215  0.         0.         0.8827915\n",
      "  0.         0.         0.9059615  0.         0.6850922  0.\n",
      "  0.48844582 0.         0.         0.49425605 0.5823698  0.75094664\n",
      "  0.         0.39430234 1.2120417  0.17689604 0.         0.395416\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28173232 0.03944856 0.         0.         0.\n",
      "  0.1100384  0.5309932  0.         0.9502674  0.         0.\n",
      "  0.         0.5498098  0.         0.         0.         0.7936667\n",
      "  0.29257768 0.79165745 0.48135284 0.18398178 0.28051516 0.33166707\n",
      "  0.         0.534205   0.         0.49435273 0.16169737 0.\n",
      "  0.07363832 0.6722054  0.8436174  0.9092049 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "[[0.12378486 0.         0.         0.03296105 0.         0.03708513\n",
      "  1.0985967  0.98649037 0.50203705 0.         0.         0.\n",
      "  0.03616188 0.22615336 0.         0.38284308 0.00493672 0.39331844\n",
      "  0.         0.         0.35281634 0.         0.         0.\n",
      "  0.         0.         0.         0.27298585 0.         0.\n",
      "  0.5353464  0.26899362 0.47803167 0.         0.2452488  0.\n",
      "  0.19587412 0.53575313 0.33614048 0.24064784 0.         0.\n",
      "  0.         0.3486137  0.6263156  1.0114233  0.         0.00574009\n",
      "  0.03000637 0.6505454  0.3292363  0.21589285 0.32455397 0.566976\n",
      "  0.         0.05984015 0.195829   0.         0.         0.\n",
      "  0.         0.55567867 0.03686945 0.15465097]]\n",
      "Hi!\n",
      "[[0.36477682 0.         1.0134333  0.         0.         0.8596992\n",
      "  0.8444439  0.8573072  0.87011206 0.         0.52872366 0.\n",
      "  0.5494575  0.         0.         0.64091426 0.01301334 0.7654755\n",
      "  0.31549144 0.         0.90872484 0.02078557 0.         0.03012531\n",
      "  0.15010653 0.         0.         0.17716621 0.         0.\n",
      "  0.50127035 0.4447084  0.         0.         0.39423048 0.\n",
      "  0.42425373 1.2014878  0.         0.5622953  0.08177266 0.\n",
      "  0.         0.7926826  0.37255627 0.4673875  0.         0.80308133\n",
      "  0.         0.55185723 0.59930223 0.2968682  0.29544967 0.41999358\n",
      "  0.         0.00694075 0.25319576 0.22017153 0.         0.\n",
      "  0.         0.7336046  1.2910609  0.4390816 ]]\n",
      "Hi!\n",
      "[[0.12359653 0.37154484 0.15180995 0.         0.         0.07713251\n",
      "  0.         0.0782833  0.00912062 0.         0.14750029 0.\n",
      "  0.36409432 0.31017074 0.         0.         0.         0.10647371\n",
      "  0.         0.20652875 0.09166253 0.         0.         0.\n",
      "  0.         0.         0.         0.07079795 0.         0.\n",
      "  0.18134442 0.29132426 0.14035873 0.         0.         0.\n",
      "  0.         0.         0.37844163 0.02051232 0.         0.\n",
      "  0.         0.         0.30169144 0.2056257  0.         0.06820554\n",
      "  0.23460914 0.10586395 0.         0.23734072 0.11236494 0.518117\n",
      "  0.         0.01942469 0.20162192 0.         0.         0.\n",
      "  0.15925433 0.09567503 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.59542763 0.         1.0109247  0.1251572  0.         0.7043834\n",
      "  1.518994   1.31348    1.0290222  0.         0.46048075 0.\n",
      "  0.         0.         0.         0.6886893  0.3109782  0.8836828\n",
      "  0.         0.         0.95631105 0.33341253 0.         0.24010637\n",
      "  0.11439127 0.         0.         0.02844957 0.         0.\n",
      "  0.28688163 0.09513565 0.03778528 0.         0.52214074 0.\n",
      "  0.1979434  1.3234214  0.         0.6262755  0.19994043 0.\n",
      "  0.         1.4383839  0.05157075 0.5019911  0.         0.37990728\n",
      "  0.         0.6570574  0.5308156  0.15151162 0.2892922  0.\n",
      "  0.         0.047557   0.11266063 0.34193483 0.         0.\n",
      "  0.         1.2457602  1.241387   0.27634782]]\n",
      "Hi!\n",
      "[[0.08022416 0.41341308 0.31516382 0.         0.         0.21186532\n",
      "  0.         0.10652756 0.         0.         0.20852345 0.\n",
      "  0.28345126 0.2203736  0.         0.         0.         0.11520675\n",
      "  0.         0.35664132 0.13797924 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10905009 0.31847313 0.10769178 0.         0.         0.\n",
      "  0.         0.         0.3010611  0.10719357 0.         0.\n",
      "  0.         0.         0.27034798 0.25660697 0.         0.10936904\n",
      "  0.34241858 0.19853996 0.         0.2436984  0.19187297 0.5225089\n",
      "  0.         0.1883794  0.07445557 0.         0.02489742 0.\n",
      "  0.12369852 0.13433295 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.41635576 0.50103873 0.12322201 0.14884923 0.         0.51998144\n",
      "  0.40260565 0.70511854 0.         0.         0.14326815 0.\n",
      "  0.29626647 0.549097   0.         0.         0.         0.1912054\n",
      "  0.         0.71494234 0.05894709 0.         0.         0.13392815\n",
      "  0.         0.         0.         0.15551384 0.         0.\n",
      "  0.7395309  0.5826763  0.33575195 0.         0.10225631 0.\n",
      "  0.         0.20676233 0.37199587 0.22733213 0.         0.\n",
      "  0.         0.02754163 0.89455944 1.0410284  0.         0.14288579\n",
      "  0.48711136 0.7480372  0.         0.5564771  0.59253925 0.8844279\n",
      "  0.         0.5355951  0.27188382 0.         0.         0.\n",
      "  0.01113975 0.17811769 0.02019753 0.        ]]\n",
      "Hi!\n",
      "[[0.7277287  0.         1.3266885  0.         0.         0.8320721\n",
      "  0.5845132  0.72691363 1.0097351  0.         0.57264394 0.\n",
      "  0.04549399 0.         0.         0.5689231  0.40775135 0.79181546\n",
      "  0.         0.         1.1322776  0.16184732 0.         0.54512614\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0617869  0.22599189 0.07640174 0.         0.03599411 0.\n",
      "  0.         0.8455423  0.         0.7685377  0.03264176 0.\n",
      "  0.         1.0235133  0.         0.33579722 0.         0.28145054\n",
      "  0.         0.90689737 0.49429196 0.24263722 0.5313155  0.06816769\n",
      "  0.         0.47367078 0.         0.30371603 0.         0.\n",
      "  0.         0.9627486  0.99310124 0.4697483 ]]\n",
      "Hi!\n",
      "[[0.78205466 0.6226801  1.4792665  0.         0.         1.131962\n",
      "  0.         0.03369295 0.3172494  0.19661348 0.5267776  0.\n",
      "  0.02004933 0.         0.         0.01285056 0.33026168 0.37043816\n",
      "  0.         0.9573246  0.7512275  0.         0.         0.31913897\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39727756 0.11723054 0.         0.         0.\n",
      "  0.         0.1375605  0.         0.76748776 0.         0.\n",
      "  0.         0.03743302 0.1197496  0.46378407 0.         0.62029046\n",
      "  0.6626346  0.82642204 0.05916057 0.44472218 0.72594714 0.60015845\n",
      "  0.         1.2874125  0.         0.         0.22818632 0.\n",
      "  0.46571943 0.37438697 0.41767907 0.40134737]]\n",
      "Hi!\n",
      "[[0.41588995 0.11176538 0.32300586 0.1636973  0.         0.69716007\n",
      "  1.1744399  1.3996878  0.7237854  0.         0.34994325 0.\n",
      "  1.2049537  0.36914465 0.         0.6786268  0.         0.72163856\n",
      "  0.72672886 0.         0.5648514  0.21735515 0.         0.\n",
      "  0.4248607  0.         0.         0.7778681  0.         0.\n",
      "  1.2399081  0.6582923  0.         0.         0.9486197  0.\n",
      "  0.56269157 1.4308429  0.         0.17321727 0.2422431  0.\n",
      "  0.         0.47986948 1.1247432  0.9028836  0.         0.8518297\n",
      "  0.         0.7312358  0.79515225 0.55824673 0.50824684 0.87508845\n",
      "  0.         0.         0.55531937 0.         0.         0.\n",
      "  0.         0.5714744  1.3773724  0.14527069]]\n",
      "Hi!\n",
      "[[0.71908885 0.6432617  0.27726275 0.24771522 0.         0.5381528\n",
      "  0.479234   1.168669   0.19191942 0.         0.31874704 0.\n",
      "  1.3769921  0.8079018  0.         0.29060173 0.         0.44238266\n",
      "  0.2942366  0.49802706 0.3971472  0.06276943 0.         0.22472131\n",
      "  0.         0.         0.         0.7594539  0.         0.\n",
      "  1.3783729  0.9736955  0.0480729  0.         0.59010506 0.\n",
      "  0.2841521  0.8653651  0.55535203 0.14698614 0.06730921 0.\n",
      "  0.         0.32622552 1.3602811  1.0585619  0.         0.5476286\n",
      "  0.06025297 0.79299444 0.417448   0.6006646  0.87058145 1.141136\n",
      "  0.         0.00890233 0.47477594 0.         0.         0.\n",
      "  0.         0.21386595 0.9809973  0.        ]]\n",
      "Hi!\n",
      "[[0.18152002 0.         0.34453678 0.20433731 0.         0.5956084\n",
      "  1.6552117  1.6600156  0.72672606 0.         0.3023669  0.\n",
      "  0.25509974 0.         0.         0.66813904 0.         0.7632777\n",
      "  0.         0.         0.60832655 0.14808361 0.         0.\n",
      "  0.18595734 0.         0.         0.45327744 0.         0.\n",
      "  0.97509366 0.27535275 0.         0.         0.7957375  0.\n",
      "  0.12292687 1.4249897  0.         0.40164876 0.26895452 0.\n",
      "  0.         0.9956168  0.59649754 0.9434106  0.         0.14213955\n",
      "  0.         0.8339242  0.5051221  0.45261753 0.6055831  0.13686955\n",
      "  0.         0.         0.25415108 0.         0.         0.\n",
      "  0.         1.0009394  1.2921364  0.        ]]\n",
      "Hi!\n",
      "[[0.3348988  0.22551002 1.1844404  0.         0.         0.58060926\n",
      "  0.5065533  0.6858062  1.5432587  0.         0.64659584 0.\n",
      "  0.8970335  0.         0.         0.9903699  0.21516156 0.89607227\n",
      "  0.6973043  0.         1.1726682  0.3156962  0.         0.32707974\n",
      "  0.11314601 0.         0.         0.17209826 0.         0.\n",
      "  0.45708102 0.21857874 0.         0.         0.3037583  0.\n",
      "  0.39454544 1.1997561  0.         0.747934   0.2448092  0.\n",
      "  0.         1.0759238  0.         0.04382215 0.         0.72002715\n",
      "  0.         0.9075899  1.0007254  0.16403638 0.31209698 0.03455359\n",
      "  0.         0.         0.00992974 0.5235742  0.         0.\n",
      "  0.         1.0031842  1.2646434  0.9564887 ]]\n",
      "Hi!\n",
      "[[0.888524   0.13174407 1.5588028  0.         0.         1.225627\n",
      "  0.2911946  0.5137705  0.53212154 0.04469899 0.570486   0.\n",
      "  0.02559998 0.         0.         0.21692973 0.3806246  0.63372636\n",
      "  0.         0.4887323  1.053127   0.         0.         0.3679351\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46794942 0.08504879 0.         0.         0.\n",
      "  0.         0.48935798 0.         0.73264456 0.         0.\n",
      "  0.         0.56781083 0.07651822 0.5046671  0.         0.50632256\n",
      "  0.35841212 0.84826326 0.21010567 0.45062497 0.69454235 0.43846473\n",
      "  0.         1.1246059  0.         0.09431236 0.06918678 0.\n",
      "  0.10210906 0.61147994 0.9513451  0.31139028]]\n",
      "Hi!\n",
      "[[0.9669196  0.         1.3639148  0.18239793 0.         0.9924992\n",
      "  1.1233785  1.1394932  0.91861373 0.         0.5029393  0.\n",
      "  0.         0.         0.         0.45953077 0.60418636 0.7336252\n",
      "  0.         0.         1.114868   0.25816682 0.         0.60810405\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22087282 0.15511975 0.         0.04519573 0.\n",
      "  0.         0.8758369  0.         0.8840868  0.08688746 0.\n",
      "  0.         1.3988453  0.         0.48034114 0.         0.06433855\n",
      "  0.         0.9929678  0.37945002 0.2365687  0.6928659  0.\n",
      "  0.         0.91386676 0.         0.24983732 0.         0.\n",
      "  0.         1.1256318  1.0931203  0.14508437]]\n",
      "Hi!\n",
      "[[0.19532655 0.38732013 1.036895   0.         0.         0.4501302\n",
      "  0.42151952 0.35597646 1.0847518  0.         0.5677522  0.\n",
      "  0.6120608  0.         0.         0.722855   0.15310368 0.8812929\n",
      "  0.3032562  0.09025486 0.9779054  0.26765558 0.         0.05499829\n",
      "  0.18133263 0.         0.         0.         0.         0.\n",
      "  0.22431388 0.10964264 0.         0.         0.38561812 0.\n",
      "  0.17015463 0.9990926  0.         0.5749192  0.06600916 0.\n",
      "  0.         0.68815434 0.         0.         0.         0.6959281\n",
      "  0.         0.6695989  0.81366885 0.04509829 0.13053808 0.07491735\n",
      "  0.         0.         0.         0.27499878 0.03799008 0.\n",
      "  0.         0.98469687 0.88350946 0.7619459 ]]\n",
      "Hi!\n",
      "[[0.6140352  0.19575475 0.90164095 0.         0.         0.81134754\n",
      "  0.29370192 0.37094703 0.23543857 0.11957248 0.36444712 0.\n",
      "  0.         0.         0.         0.1446774  0.21082091 0.5327287\n",
      "  0.         0.5070858  0.59869903 0.         0.         0.1547891\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23294531 0.10161497 0.         0.         0.\n",
      "  0.         0.28959313 0.         0.585962   0.         0.\n",
      "  0.         0.36146557 0.13061665 0.54457724 0.         0.21006423\n",
      "  0.28856874 0.74716103 0.06255228 0.2918997  0.3955522  0.2732524\n",
      "  0.         0.7841885  0.         0.         0.01243084 0.\n",
      "  0.36172867 0.5795046  0.22127035 0.10854894]]\n",
      "Hi!\n",
      "[[0.01460707 0.28396282 0.25213656 0.         0.         0.34479064\n",
      "  0.         0.17378458 0.         0.09507725 0.2195251  0.\n",
      "  0.         0.11259887 0.         0.         0.         0.12438554\n",
      "  0.         0.41869316 0.14540964 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09794437 0.05027972 0.         0.         0.\n",
      "  0.         0.         0.05870619 0.18316197 0.         0.\n",
      "  0.         0.         0.13941279 0.45970574 0.         0.12429236\n",
      "  0.29659867 0.2887792  0.         0.26884878 0.23328048 0.39323404\n",
      "  0.         0.27828884 0.         0.         0.05285256 0.\n",
      "  0.13123439 0.15986644 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.45287845 0.         0.15392959 0.64441264 0.         0.8925508\n",
      "  1.8787746  2.0557263  0.1338511  0.         0.11325816 0.\n",
      "  0.18223272 0.298424   0.         0.2604199  0.         0.5074447\n",
      "  0.         0.         0.39483085 0.18445328 0.         0.\n",
      "  0.         0.         0.         0.7652049  0.         0.\n",
      "  1.3050092  0.63652885 0.24167342 0.         0.7924719  0.\n",
      "  0.         1.2679282  0.0554615  0.27080235 0.39248046 0.\n",
      "  0.         0.64831144 1.2095186  1.4620456  0.         0.00965167\n",
      "  0.         0.96265393 0.10763848 0.80208915 0.9270353  0.58212346\n",
      "  0.         0.35954186 0.40180534 0.         0.         0.\n",
      "  0.         0.6713474  1.332773   0.        ]]\n",
      "Hi!\n",
      "[[0.05533682 0.29520783 0.07322773 0.         0.         0.43185958\n",
      "  0.21781921 0.44398633 0.         0.11146013 0.12595224 0.\n",
      "  0.         0.14875251 0.         0.02353577 0.         0.24007931\n",
      "  0.         0.471925   0.06228595 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13483374 0.15545255 0.20724969 0.         0.         0.\n",
      "  0.         0.         0.07188397 0.26691166 0.         0.\n",
      "  0.         0.         0.25802612 0.73233557 0.         0.\n",
      "  0.27933395 0.5303606  0.         0.34746313 0.29507235 0.4177882\n",
      "  0.         0.37832612 0.         0.         0.         0.\n",
      "  0.24109955 0.3936859  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.34974203 0.         0.         0.60144424 0.         0.61342347\n",
      "  2.228038   2.2657409  0.24049498 0.         0.08013576 0.\n",
      "  0.09434392 0.4368945  0.         0.45115796 0.         0.58647615\n",
      "  0.         0.         0.28425667 0.3523793  0.         0.\n",
      "  0.1142455  0.         0.         0.77933234 0.         0.\n",
      "  1.4047894  0.39150205 0.30529743 0.         0.9617612  0.\n",
      "  0.         1.3868032  0.         0.30967826 0.4318063  0.\n",
      "  0.         0.91455996 1.1346852  1.4882463  0.         0.\n",
      "  0.         0.9984474  0.26810327 0.6915426  0.98135287 0.33484027\n",
      "  0.         0.01951033 0.34475443 0.         0.         0.\n",
      "  0.         0.83178747 1.2394705  0.        ]]\n",
      "Hi!\n",
      "[[0.05042927 0.1440096  0.2815184  0.         0.         0.20731169\n",
      "  0.         0.04044781 0.1302474  0.1308609  0.1886568  0.\n",
      "  0.07270201 0.         0.         0.08151428 0.         0.05068337\n",
      "  0.         0.1919536  0.19519639 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00948298 0.09718838 0.         0.         0.\n",
      "  0.         0.         0.11032959 0.1667636  0.         0.\n",
      "  0.         0.         0.10051775 0.20707253 0.         0.09871355\n",
      "  0.13269651 0.07844207 0.         0.198882   0.07629725 0.26914755\n",
      "  0.         0.06387867 0.         0.         0.05052713 0.\n",
      "  0.05640157 0.15682448 0.         0.0377014 ]]\n",
      "Hi!\n",
      "[[5.6618899e-01 3.4695056e-01 6.2323546e-01 6.0950775e-02 0.0000000e+00\n",
      "  7.6934850e-01 5.3649503e-01 1.0560747e+00 4.8390558e-01 0.0000000e+00\n",
      "  3.9153627e-01 0.0000000e+00 1.1839081e+00 2.5758052e-01 0.0000000e+00\n",
      "  4.0592331e-01 0.0000000e+00 4.9489030e-01 3.8715455e-01 2.7456683e-01\n",
      "  6.5615922e-01 0.0000000e+00 0.0000000e+00 3.3013560e-02 1.8645095e-02\n",
      "  0.0000000e+00 0.0000000e+00 5.9534729e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0768929e+00 7.9176468e-01 0.0000000e+00 0.0000000e+00 4.4165665e-01\n",
      "  0.0000000e+00 3.0194208e-01 9.9439305e-01 4.7106124e-02 2.6334274e-01\n",
      "  1.9458929e-02 0.0000000e+00 0.0000000e+00 2.1435596e-01 9.6403104e-01\n",
      "  8.1555867e-01 0.0000000e+00 6.3579452e-01 0.0000000e+00 7.0015687e-01\n",
      "  4.9151301e-01 5.8841848e-01 7.1860784e-01 8.3813238e-01 0.0000000e+00\n",
      "  6.1609212e-04 3.7042883e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 3.0635792e-01 1.2931719e+00 6.8978786e-02]]\n",
      "Hi!\n",
      "[[0.7645983  0.71279675 0.67122704 0.27961528 0.         0.80294645\n",
      "  0.19219126 0.9008975  0.         0.         0.3004496  0.\n",
      "  1.019337   0.64647967 0.         0.         0.         0.21165957\n",
      "  0.         0.91714215 0.40594468 0.         0.         0.27248174\n",
      "  0.         0.         0.         0.45165628 0.         0.\n",
      "  1.2091426  1.0296824  0.19375141 0.         0.25658184 0.\n",
      "  0.         0.31131357 0.7090264  0.14458284 0.         0.\n",
      "  0.         0.17612365 1.2669867  1.1004131  0.         0.39817706\n",
      "  0.5952831  0.8232067  0.         0.744951   1.1043011  1.2299472\n",
      "  0.         0.7746182  0.37422475 0.         0.02209635 0.\n",
      "  0.         0.11907518 0.83607334 0.        ]]\n",
      "Hi!\n",
      "[[0.12387462 0.         0.5345084  0.02417635 0.         0.5596916\n",
      "  1.6196848  1.6517231  1.2202443  0.         0.41161293 0.\n",
      "  0.50864065 0.         0.         0.9560306  0.         0.8245188\n",
      "  0.4227915  0.         0.80760306 0.20400219 0.         0.\n",
      "  0.30490097 0.         0.         0.4364467  0.         0.\n",
      "  0.91763103 0.1498951  0.         0.         0.82442975 0.\n",
      "  0.42754385 1.598789   0.         0.40550655 0.28808537 0.\n",
      "  0.         1.3936698  0.3475703  0.6125628  0.         0.36307353\n",
      "  0.         0.6767321  0.8768946  0.34112614 0.4290454  0.\n",
      "  0.         0.         0.2953524  0.18785803 0.         0.\n",
      "  0.         1.0488371  1.4695351  0.31860688]]\n",
      "Hi!\n",
      "[[0.2147534  0.4958487  0.48282915 0.         0.         0.6505351\n",
      "  0.13394953 0.2804166  0.15952612 0.07241218 0.3215038  0.\n",
      "  0.30891097 0.09491044 0.         0.04111329 0.         0.35086617\n",
      "  0.         0.6052334  0.34782016 0.         0.         0.00967753\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30789596 0.2845383  0.         0.         0.         0.\n",
      "  0.         0.2040778  0.         0.3095511  0.         0.\n",
      "  0.         0.         0.3805407  0.6278682  0.         0.46316963\n",
      "  0.2878576  0.57398367 0.09816405 0.32944328 0.3827023  0.5356003\n",
      "  0.         0.315086   0.         0.         0.01691761 0.\n",
      "  0.07875891 0.32381144 0.12264864 0.09146122]]\n",
      "Hi!\n",
      "[[0.07442082 0.39356297 0.2652975  0.         0.         0.20242378\n",
      "  0.         0.03914044 0.         0.         0.15206733 0.\n",
      "  0.35606438 0.20500016 0.         0.         0.         0.09901857\n",
      "  0.         0.3028535  0.12225709 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12997691 0.27776712 0.09573966 0.         0.         0.\n",
      "  0.         0.         0.19277842 0.07451955 0.         0.\n",
      "  0.         0.         0.2832324  0.22040503 0.         0.21178603\n",
      "  0.26599038 0.18178369 0.         0.23131129 0.07004311 0.49331385\n",
      "  0.         0.08928779 0.13525212 0.         0.013948   0.\n",
      "  0.11839326 0.09233852 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.35263    0.9782011  0.39505282 0.         0.         0.16862728\n",
      "  0.         0.34231123 0.22269061 0.         0.29758912 0.\n",
      "  1.4106305  0.67843705 0.         0.17506678 0.         0.20357846\n",
      "  0.17946245 0.6045311  0.39193237 0.         0.         0.18669796\n",
      "  0.         0.         0.         0.7791763  0.         0.\n",
      "  0.77934045 0.43034878 0.         0.         0.1345761  0.\n",
      "  0.         0.         0.8497784  0.03659531 0.         0.\n",
      "  0.         0.         0.5590895  0.33424342 0.         0.3021509\n",
      "  0.2276355  0.349418   0.5981344  0.2409555  0.4546451  0.98967236\n",
      "  0.         0.         0.47219825 0.         0.06731071 0.\n",
      "  0.2086521  0.20551412 0.54000366 0.        ]]\n",
      "Hi!\n",
      "[[0.9246239  0.         1.148807   0.32764986 0.         1.1606481\n",
      "  0.93600494 1.0835961  0.38675073 0.11654449 0.40179285 0.\n",
      "  0.         0.         0.         0.20729236 0.42284825 0.587029\n",
      "  0.         0.15665242 0.80387425 0.         0.         0.5614338\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24422362 0.3041372  0.         0.         0.\n",
      "  0.         0.41129965 0.         1.009228   0.         0.\n",
      "  0.         1.1460781  0.         0.79277146 0.         0.\n",
      "  0.1681225  1.3019292  0.01771663 0.4064344  0.9871619  0.00684986\n",
      "  0.         1.3759329  0.         0.         0.         0.\n",
      "  0.34423715 0.9132311  0.57422525 0.        ]]\n",
      "Hi!\n",
      "[[0.4996055  0.         1.1428497  0.03647215 0.         0.8232509\n",
      "  1.0382316  1.2474471  1.2333847  0.         0.5326493  0.\n",
      "  0.46793622 0.         0.         0.77981067 0.13311334 0.77676165\n",
      "  0.37861085 0.         1.1199088  0.07939224 0.         0.41088912\n",
      "  0.00880817 0.         0.         0.33166718 0.         0.\n",
      "  0.5620186  0.41802153 0.02716993 0.         0.40290403 0.\n",
      "  0.19955766 1.3120037  0.         0.5695451  0.25272885 0.\n",
      "  0.         1.180303   0.1436246  0.4998782  0.         0.4786524\n",
      "  0.         0.7385435  0.6966757  0.33960515 0.60996217 0.11098962\n",
      "  0.         0.10636107 0.15149994 0.2542533  0.         0.\n",
      "  0.         0.965522   1.635419   0.47760618]]\n",
      "Hi!\n",
      "[[0.35781115 0.         0.7844579  0.10504438 0.         0.80987525\n",
      "  0.97355187 1.0336436  0.5722324  0.         0.42057586 0.\n",
      "  0.41283852 0.         0.         0.44544178 0.         0.64396834\n",
      "  0.         0.05831222 0.7533856  0.         0.         0.\n",
      "  0.04862964 0.         0.         0.27318576 0.         0.\n",
      "  0.65030575 0.5050319  0.         0.         0.42908117 0.\n",
      "  0.16639626 1.0972122  0.         0.42627466 0.08119549 0.\n",
      "  0.         0.6146634  0.56113636 0.6813589  0.         0.5237745\n",
      "  0.         0.67491925 0.36670753 0.378394   0.46671006 0.4462729\n",
      "  0.         0.19113293 0.24383746 0.         0.         0.\n",
      "  0.         0.69438875 1.1524664  0.09141491]]\n",
      "Hi!\n",
      "[[0.01393356 0.1418049  0.15626922 0.         0.         0.23980516\n",
      "  0.02955114 0.21498999 0.         0.13319008 0.1367469  0.\n",
      "  0.         0.13883491 0.         0.         0.         0.09419197\n",
      "  0.         0.2524611  0.04197164 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10146014 0.15030874 0.         0.         0.\n",
      "  0.         0.         0.06947879 0.16645122 0.         0.\n",
      "  0.         0.         0.19506598 0.44906613 0.         0.03376376\n",
      "  0.24475294 0.23910177 0.         0.2251203  0.17092061 0.33825892\n",
      "  0.         0.23221424 0.         0.         0.         0.\n",
      "  0.0945847  0.12865897 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5648451  0.         0.817906   0.05244153 0.         0.66967255\n",
      "  1.1756454  0.8574736  0.67194426 0.         0.326124   0.\n",
      "  0.         0.         0.         0.36783478 0.37911084 0.78969985\n",
      "  0.         0.         0.7220729  0.28272098 0.         0.06641772\n",
      "  0.06908464 0.         0.         0.         0.         0.\n",
      "  0.01971176 0.         0.09147117 0.         0.26693502 0.\n",
      "  0.         0.83554834 0.         0.57018304 0.01359188 0.\n",
      "  0.         1.1317565  0.         0.38870624 0.         0.19175617\n",
      "  0.         0.6791055  0.32217965 0.14024101 0.1093206  0.113589\n",
      "  0.         0.31283885 0.         0.15898    0.         0.\n",
      "  0.00999043 1.0025902  0.46407366 0.14548123]]\n",
      "Hi!\n",
      "[[0.06015609 0.         0.10234569 0.         0.         0.22746705\n",
      "  0.26007497 0.27653924 0.00150301 0.22695464 0.1931398  0.\n",
      "  0.         0.05673957 0.         0.03129057 0.         0.02955354\n",
      "  0.         0.21198002 0.10649072 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14010955 0.         0.         0.\n",
      "  0.         0.05898126 0.0418393  0.25755277 0.         0.\n",
      "  0.         0.         0.11695598 0.51972747 0.         0.0532355\n",
      "  0.18143539 0.16905323 0.         0.29035047 0.1472428  0.2693317\n",
      "  0.         0.24896193 0.         0.         0.         0.\n",
      "  0.         0.18692712 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.18895382 0.20664954 0.06931692 0.03809776 0.         0.23496075\n",
      "  0.25257742 0.34397158 0.         0.01122882 0.04421382 0.\n",
      "  0.         0.19844161 0.         0.13939022 0.         0.06201215\n",
      "  0.         0.33694398 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02657486 0.         0.\n",
      "  0.27268836 0.38051388 0.27371323 0.         0.         0.\n",
      "  0.         0.14931113 0.19294444 0.10902303 0.         0.\n",
      "  0.         0.06013258 0.37733197 0.5634479  0.         0.07342126\n",
      "  0.27133155 0.4874499  0.         0.32241485 0.13610895 0.5718595\n",
      "  0.         0.40112925 0.08736914 0.         0.         0.\n",
      "  0.10595116 0.06766783 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.45575812 0.         1.1856772  0.         0.         0.59214324\n",
      "  1.1396097  1.1595529  1.3975111  0.         0.58073235 0.\n",
      "  0.24829982 0.         0.         0.9231403  0.30134994 0.95781344\n",
      "  0.08411802 0.         1.170232   0.31150162 0.         0.44513112\n",
      "  0.07323528 0.         0.         0.10584597 0.         0.\n",
      "  0.36147487 0.03158487 0.06104902 0.         0.42205986 0.\n",
      "  0.16813909 1.2897829  0.         0.6376048  0.2275176  0.\n",
      "  0.         1.51973    0.         0.27485093 0.         0.34111288\n",
      "  0.         0.74791926 0.7792766  0.1786554  0.43667763 0.\n",
      "  0.         0.         0.         0.43349898 0.         0.\n",
      "  0.         1.1949303  1.3560102  0.529829  ]]\n",
      "Hi!\n",
      "[[0.65491915 1.3456101  0.49178332 0.         0.         0.3666869\n",
      "  0.         0.82798487 0.88799804 0.         0.48478445 0.\n",
      "  2.7375371  0.9616718  0.         0.8519663  0.         0.6505281\n",
      "  1.5218408  0.43829075 0.60706216 0.2709916  0.         0.18970744\n",
      "  0.41342592 0.         0.         0.90550095 0.         0.\n",
      "  1.4747378  1.1387861  0.         0.         0.6862051  0.\n",
      "  0.89974886 1.1194077  0.73052156 0.3291954  0.12053601 0.\n",
      "  0.         0.6302522  1.3992442  0.5036496  0.         1.3748846\n",
      "  0.         0.8967415  1.2445801  0.39103276 0.6416967  1.5660813\n",
      "  0.         0.         0.62659466 0.         0.         0.\n",
      "  0.         0.25632435 1.186553   0.5652278 ]]\n",
      "Hi!\n",
      "[[0.28194764 0.         0.10304222 0.43962225 0.         0.63636976\n",
      "  2.0246835  1.9523124  0.48693848 0.         0.1828395  0.\n",
      "  0.12732702 0.05785448 0.         0.5310068  0.         0.6993523\n",
      "  0.         0.         0.41208118 0.28800523 0.         0.\n",
      "  0.19756375 0.         0.         0.5334693  0.         0.\n",
      "  1.1376176  0.3351485  0.09092008 0.         0.8813051  0.\n",
      "  0.12412357 1.4845195  0.         0.38075542 0.3729926  0.\n",
      "  0.         0.9609715  0.84147125 1.2042128  0.         0.03415621\n",
      "  0.         0.8873239  0.43185976 0.51671344 0.6904404  0.29775086\n",
      "  0.         0.         0.32868427 0.         0.         0.\n",
      "  0.         0.928637   1.2625997  0.        ]]\n",
      "Hi!\n",
      "[[0.08527083 0.26540217 0.1274247  0.         0.         0.04694456\n",
      "  0.         0.06259512 0.02708181 0.         0.14048046 0.\n",
      "  0.2989426  0.19086857 0.         0.01429559 0.         0.05312579\n",
      "  0.         0.14780374 0.05514599 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11233284 0.16017589 0.0956593  0.         0.         0.\n",
      "  0.         0.         0.24622852 0.02760009 0.         0.\n",
      "  0.         0.         0.1989015  0.1611695  0.         0.04516061\n",
      "  0.12313763 0.06521145 0.         0.12103291 0.05361648 0.41360322\n",
      "  0.         0.         0.14850232 0.         0.0130128  0.\n",
      "  0.12964599 0.08796914 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.46381637 0.         0.29867518 0.56940794 0.         0.673097\n",
      "  2.3875341  2.218391   0.5812948  0.         0.21307299 0.\n",
      "  0.         0.         0.         0.4826456  0.         0.7535845\n",
      "  0.         0.         0.5656427  0.25851017 0.         0.0575276\n",
      "  0.         0.         0.         0.34363148 0.         0.\n",
      "  0.805936   0.14536227 0.3052979  0.         0.72004133 0.\n",
      "  0.         1.356341   0.         0.6772812  0.43845817 0.\n",
      "  0.         1.5158833  0.45422518 1.0852792  0.         0.\n",
      "  0.         1.0649129  0.22014101 0.44412228 0.80864155 0.\n",
      "  0.         0.2632378  0.00758132 0.         0.         0.\n",
      "  0.         1.2253833  1.148941   0.        ]]\n",
      "Hi!\n",
      "[[9.3597591e-01 2.7832720e-01 1.3607813e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1593674e+00 3.2899815e-01 4.5027754e-01 4.6796665e-01 1.8193273e-01\n",
      "  4.9946430e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2597947e-02 3.7555790e-01 6.0865045e-01 0.0000000e+00 4.9256796e-01\n",
      "  9.8613882e-01 0.0000000e+00 0.0000000e+00 5.6706369e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.3288935e-01 2.0011653e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 2.6126716e-01 0.0000000e+00 9.0179318e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.5762162e-01 0.0000000e+00\n",
      "  6.0200530e-01 0.0000000e+00 1.4293920e-01 4.0783322e-01 1.1957468e+00\n",
      "  1.3780268e-01 3.2829028e-01 8.6656147e-01 1.8370059e-01 0.0000000e+00\n",
      "  1.2239665e+00 0.0000000e+00 1.0236899e-03 3.8501155e-02 0.0000000e+00\n",
      "  3.7826705e-01 7.5602835e-01 3.8497457e-01 2.6477271e-01]]\n",
      "Hi!\n",
      "[[0.0260609  0.21026331 0.03561439 0.         0.         0.05671227\n",
      "  0.04902039 0.19797689 0.03363244 0.0611789  0.13164817 0.\n",
      "  0.15465832 0.16949758 0.         0.02617886 0.         0.05397003\n",
      "  0.         0.11903978 0.07666832 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01605819 0.13444418 0.14173742 0.         0.         0.\n",
      "  0.         0.         0.15675126 0.03433261 0.         0.\n",
      "  0.         0.         0.17019308 0.28204674 0.         0.\n",
      "  0.09983108 0.1183466  0.         0.1279341  0.04510658 0.33765948\n",
      "  0.         0.02884531 0.0587436  0.         0.         0.\n",
      "  0.0693906  0.20804283 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4333906  0.         0.75335276 0.04631029 0.         0.5813363\n",
      "  1.2539512  1.0541626  0.75867045 0.         0.40460253 0.\n",
      "  0.         0.         0.         0.5317154  0.03820673 0.8715257\n",
      "  0.         0.         0.79008263 0.10710432 0.         0.10927745\n",
      "  0.12307439 0.         0.         0.         0.         0.\n",
      "  0.39386728 0.11061295 0.03752633 0.         0.47799912 0.\n",
      "  0.         1.1242952  0.         0.52465665 0.06181313 0.\n",
      "  0.         0.96690154 0.19449292 0.55669814 0.         0.228793\n",
      "  0.         0.76252973 0.43199182 0.20172815 0.28499067 0.00954273\n",
      "  0.         0.         0.00427891 0.0260638  0.         0.\n",
      "  0.         1.0725405  0.9006578  0.19496329]]\n",
      "Hi!\n",
      "[[0.60543257 0.4185038  1.100611   0.         0.         0.94545615\n",
      "  0.22290699 0.47413325 0.3621585  0.         0.48697025 0.\n",
      "  0.4188982  0.         0.         0.15983269 0.03699766 0.5966314\n",
      "  0.         0.566242   0.8226552  0.         0.         0.05841589\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34984773 0.53950125 0.         0.         0.0714858  0.\n",
      "  0.         0.54636973 0.         0.53233165 0.         0.\n",
      "  0.         0.16000603 0.4838352  0.5311136  0.         0.5261087\n",
      "  0.32212642 0.7963044  0.20790255 0.41094056 0.5417424  0.63322\n",
      "  0.         0.6155817  0.00531413 0.         0.         0.\n",
      "  0.         0.45606384 0.7697479  0.18259802]]\n",
      "Hi!\n",
      "[[0.40763313 0.64994276 0.71947163 0.         0.         0.6148356\n",
      "  0.08064515 0.31944993 0.3892219  0.         0.42216548 0.\n",
      "  0.96400833 0.05633947 0.         0.29941136 0.         0.5663564\n",
      "  0.01581125 0.5461663  0.58034396 0.         0.         0.02705686\n",
      "  0.         0.         0.         0.03744432 0.         0.\n",
      "  0.5874094  0.5343466  0.         0.         0.17176007 0.\n",
      "  0.03387737 0.59381884 0.         0.45527217 0.         0.\n",
      "  0.         0.02931278 0.5592085  0.5121406  0.         0.66954255\n",
      "  0.16280182 0.68445987 0.40659776 0.36377075 0.48295736 0.7059618\n",
      "  0.         0.02410644 0.07319336 0.         0.02914037 0.\n",
      "  0.         0.42060107 0.61052316 0.32679498]]\n",
      "Hi!\n",
      "[[0.48265034 0.         1.0848572  0.03988938 0.         0.76614684\n",
      "  1.4749067  1.3634663  1.2570546  0.         0.5206097  0.\n",
      "  0.         0.         0.         0.8477308  0.28653923 0.9010613\n",
      "  0.01925082 0.         1.0644853  0.38539782 0.         0.2984623\n",
      "  0.18065847 0.         0.         0.11661988 0.         0.\n",
      "  0.34667832 0.04889866 0.09004644 0.         0.5335066  0.\n",
      "  0.24525267 1.4141072  0.         0.58087385 0.18393846 0.\n",
      "  0.         1.6289225  0.         0.38250187 0.         0.41892183\n",
      "  0.         0.6316293  0.6706387  0.20358242 0.26516104 0.\n",
      "  0.         0.         0.10248468 0.43850315 0.         0.\n",
      "  0.         1.2824333  1.390892   0.46114781]]\n",
      "Hi!\n",
      "[[0.         0.05845236 0.07545125 0.         0.         0.051772\n",
      "  0.04726185 0.12218811 0.09343516 0.09049892 0.0830402  0.\n",
      "  0.03283801 0.02013266 0.         0.07656722 0.         0.0059831\n",
      "  0.         0.10288639 0.10665189 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04768176 0.1016498  0.         0.         0.\n",
      "  0.         0.         0.1288319  0.07185584 0.         0.\n",
      "  0.         0.         0.09567224 0.2455541  0.         0.0716688\n",
      "  0.05083886 0.09466726 0.         0.18199176 0.03956487 0.25702152\n",
      "  0.         0.06777083 0.03376003 0.         0.         0.\n",
      "  0.00716233 0.13748147 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5444988  0.61447716 1.4505991  0.         0.         0.9555306\n",
      "  0.060879   0.10983276 0.87235355 0.         0.65863395 0.\n",
      "  1.0336156  0.         0.         0.5108037  0.14238645 0.7617711\n",
      "  0.39687338 0.41755223 1.1191751  0.         0.         0.13760601\n",
      "  0.07700194 0.         0.         0.         0.         0.\n",
      "  0.297818   0.54523903 0.         0.         0.03814682 0.\n",
      "  0.25794947 0.72378945 0.         0.7935657  0.         0.\n",
      "  0.         0.25804913 0.27818677 0.13482137 0.         1.0275207\n",
      "  0.0835174  0.7815726  0.66408974 0.38575444 0.44215378 0.65706646\n",
      "  0.         0.26055133 0.         0.17228751 0.09538665 0.\n",
      "  0.         0.55335826 1.1044782  0.833894  ]]\n",
      "Hi!\n",
      "[[0.6379319  0.35245305 1.1903324  0.05836254 0.         1.0810083\n",
      "  0.28669217 0.8109167  0.3437525  0.         0.45519727 0.\n",
      "  0.37500507 0.         0.         0.06659114 0.         0.4318466\n",
      "  0.         0.49240077 0.8493255  0.         0.         0.29939073\n",
      "  0.         0.         0.         0.03326098 0.         0.\n",
      "  0.54314    0.6893453  0.08981438 0.         0.04964414 0.\n",
      "  0.         0.42120224 0.         0.49752876 0.         0.\n",
      "  0.         0.28067252 0.43949527 0.7420629  0.         0.18897739\n",
      "  0.32956392 1.0244519  0.07148525 0.6309478  1.0408224  0.5794473\n",
      "  0.         1.0316212  0.         0.         0.02733875 0.\n",
      "  0.         0.40795603 0.9691941  0.        ]]\n",
      "Hi!\n",
      "[[0.02211363 0.27300057 0.19285987 0.         0.         0.1661506\n",
      "  0.         0.11116477 0.         0.04852692 0.16405079 0.\n",
      "  0.1934784  0.17785409 0.         0.         0.         0.06286536\n",
      "  0.         0.2194469  0.08457606 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04777635 0.185878   0.09300098 0.         0.         0.\n",
      "  0.         0.         0.19137377 0.08508015 0.         0.\n",
      "  0.         0.         0.21774472 0.27993557 0.         0.06132231\n",
      "  0.23245    0.1601327  0.         0.21306527 0.14255537 0.4226532\n",
      "  0.         0.08361845 0.04844476 0.         0.01047819 0.\n",
      "  0.06098674 0.13617185 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.48913717 0.32137647 1.0513848  0.         0.         0.85832375\n",
      "  0.21605653 0.26596853 0.4169019  0.         0.45217094 0.\n",
      "  0.39718518 0.         0.         0.23921345 0.10880184 0.6122453\n",
      "  0.         0.4801336  0.7601622  0.         0.         0.01762114\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20953533 0.45713514 0.         0.         0.03945647 0.\n",
      "  0.07924944 0.62054557 0.         0.58083665 0.         0.\n",
      "  0.         0.18975292 0.32820362 0.41367373 0.         0.7276651\n",
      "  0.21663092 0.57685655 0.32599494 0.36388594 0.29320383 0.6261142\n",
      "  0.         0.4551767  0.         0.         0.02409506 0.\n",
      "  0.         0.4677506  0.726688   0.29911423]]\n",
      "Hi!\n",
      "[[0.543978   1.1714815  0.7312046  0.         0.         0.4132613\n",
      "  0.02549145 0.37802637 0.73325866 0.         0.5263352  0.\n",
      "  1.8602946  0.39996976 0.         0.64642334 0.         0.74316293\n",
      "  0.7708089  0.5909853  0.697514   0.         0.         0.14161783\n",
      "  0.2094991  0.         0.         0.35387638 0.         0.\n",
      "  0.99928284 0.8068945  0.         0.         0.44701594 0.\n",
      "  0.42853358 0.79820985 0.28994533 0.49435362 0.         0.\n",
      "  0.         0.26793402 0.88386565 0.29817694 0.         1.0295589\n",
      "  0.         0.8021928  0.8427342  0.31124187 0.554353   0.96337396\n",
      "  0.         0.         0.32745093 0.         0.02101839 0.\n",
      "  0.         0.44945067 0.8808217  0.5530108 ]]\n",
      "Hi!\n",
      "[[0.42011052 0.0380199  0.23493408 0.40773544 0.         0.16057985\n",
      "  0.66822624 0.94144505 0.         0.         0.         0.\n",
      "  0.45131767 0.5344429  0.         0.04608135 0.         0.20626827\n",
      "  0.         0.04261874 0.01722613 0.         0.         0.\n",
      "  0.         0.         0.         0.720455   0.         0.\n",
      "  0.6797075  0.765387   0.5819858  0.         0.00309233 0.\n",
      "  0.22961432 0.1410966  0.9441789  0.         0.         0.\n",
      "  0.         0.48146892 0.9067351  0.7264756  0.         0.\n",
      "  0.2932247  0.777664   0.         0.46183953 0.5981952  1.2596946\n",
      "  0.         0.45964566 0.4311735  0.         0.         0.\n",
      "  0.06866303 0.56877756 0.0623839  0.        ]]\n",
      "Hi!\n",
      "[[0.33877176 0.         0.43900466 0.19858874 0.         0.61902463\n",
      "  1.6223426  1.4483991  0.54642904 0.         0.3095149  0.\n",
      "  0.         0.         0.         0.49243858 0.         0.78935105\n",
      "  0.         0.         0.5683404  0.14423163 0.         0.\n",
      "  0.1295627  0.         0.         0.26654342 0.         0.\n",
      "  0.7425509  0.27720937 0.06012041 0.         0.6488602  0.\n",
      "  0.01750344 1.2687757  0.         0.41449863 0.2008914  0.\n",
      "  0.         0.89493823 0.541738   0.90655285 0.         0.1100824\n",
      "  0.         0.8447276  0.3922923  0.35178158 0.45244732 0.16516162\n",
      "  0.         0.         0.16757971 0.         0.         0.\n",
      "  0.         1.0176377  1.0376575  0.        ]]\n",
      "Hi!\n",
      "[[0.36256564 0.         0.2976318  0.4371416  0.         0.77663827\n",
      "  1.7313895  1.7121539  0.29365358 0.         0.21135345 0.\n",
      "  0.         0.         0.         0.3276008  0.         0.58126605\n",
      "  0.         0.         0.45816094 0.11655702 0.         0.\n",
      "  0.         0.         0.         0.4450829  0.         0.\n",
      "  0.93551224 0.48694155 0.14416637 0.         0.6687346  0.\n",
      "  0.         1.209609   0.         0.4451819  0.27932805 0.\n",
      "  0.         0.73772115 0.7946475  1.1388718  0.         0.\n",
      "  0.         0.9054836  0.1730205  0.54177207 0.7685669  0.30931312\n",
      "  0.         0.28169814 0.2116586  0.         0.         0.\n",
      "  0.         0.8286844  1.1458069  0.        ]]\n",
      "Hi!\n",
      "[[0.3772946  0.         0.85831404 0.         0.         0.6184061\n",
      "  1.081881   1.0480509  1.0093945  0.         0.4811859  0.\n",
      "  0.19415574 0.         0.         0.70771927 0.06988036 0.8216659\n",
      "  0.         0.         0.9055747  0.13436872 0.         0.1978186\n",
      "  0.08681743 0.         0.         0.04792807 0.         0.\n",
      "  0.4236574  0.1103847  0.         0.         0.42009786 0.\n",
      "  0.08854784 1.1394638  0.         0.5518811  0.12741734 0.\n",
      "  0.         1.1306056  0.06578678 0.441333   0.         0.32072878\n",
      "  0.         0.72685313 0.6150966  0.24836645 0.37192175 0.\n",
      "  0.         0.         0.         0.19690236 0.         0.\n",
      "  0.         1.0036032  1.0266831  0.37614197]]\n",
      "Hi!\n",
      "[[0.02769335 0.19940142 0.19865184 0.         0.         0.3011356\n",
      "  0.01621549 0.12486042 0.         0.11200618 0.1895436  0.\n",
      "  0.         0.03564736 0.         0.         0.         0.16572466\n",
      "  0.         0.3078628  0.13300999 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08663686 0.05572718 0.         0.         0.\n",
      "  0.         0.         0.         0.17553745 0.         0.\n",
      "  0.         0.         0.13855825 0.44406554 0.         0.11338707\n",
      "  0.21838614 0.2153141  0.         0.2388285  0.06310342 0.30076754\n",
      "  0.         0.2930442  0.         0.         0.04288529 0.\n",
      "  0.13285688 0.145039   0.         0.        ]]\n",
      "Hi!\n",
      "[[0.45046026 0.5881874  0.5700132  0.         0.         0.55803496\n",
      "  0.56423414 0.9912261  0.9960578  0.         0.4641289  0.\n",
      "  1.7337904  0.3236927  0.         0.8237874  0.         0.7427085\n",
      "  1.110799   0.08901303 0.72547185 0.07975429 0.         0.\n",
      "  0.4581861  0.         0.         0.623396   0.         0.\n",
      "  1.1245465  0.67347956 0.         0.         0.7154799  0.\n",
      "  0.67747504 1.3286954  0.         0.39421973 0.11352939 0.\n",
      "  0.         0.37191102 0.9292135  0.51115954 0.         1.0758137\n",
      "  0.         0.80667734 1.0698389  0.46038306 0.40485337 0.94535273\n",
      "  0.         0.         0.48630798 0.         0.         0.\n",
      "  0.         0.5334663  1.2942166  0.53651285]]\n",
      "Hi!\n",
      "[[0.0825548  0.22010083 0.05416904 0.         0.         0.07670008\n",
      "  0.         0.16926807 0.04347768 0.0658324  0.15449563 0.\n",
      "  0.12830101 0.20159146 0.         0.         0.         0.06859262\n",
      "  0.         0.19044897 0.06989367 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08024147 0.14747387 0.1411308  0.         0.         0.\n",
      "  0.         0.         0.25154468 0.05473179 0.         0.\n",
      "  0.         0.         0.18970765 0.28527373 0.         0.\n",
      "  0.17479087 0.06232044 0.         0.18662566 0.04117674 0.3723992\n",
      "  0.         0.12199    0.07523599 0.         0.         0.\n",
      "  0.07678556 0.07420193 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.529484   0.         0.         0.8213997  0.         0.5036048\n",
      "  2.0147405  2.1744907  0.         0.         0.         0.\n",
      "  0.14534365 0.9902722  0.         0.2459308  0.         0.3892479\n",
      "  0.         0.08776898 0.         0.4485412  0.         0.02927181\n",
      "  0.0371681  0.         0.         0.8607525  0.         0.\n",
      "  1.5212207  0.76458627 0.79100126 0.         0.8030433  0.\n",
      "  0.11116299 1.0342305  0.34274584 0.2861121  0.32211867 0.\n",
      "  0.         0.572505   1.6921557  1.8250432  0.         0.\n",
      "  0.08027504 1.0662917  0.09060616 0.78441477 1.0084676  1.005953\n",
      "  0.         0.34169874 0.54922813 0.         0.         0.\n",
      "  0.         0.572456   0.560509   0.        ]]\n",
      "Hi!\n",
      "[[0.10025989 0.31584513 0.6301     0.         0.         0.2949564\n",
      "  0.         0.05565599 0.17383888 0.0253042  0.1892425  0.\n",
      "  0.15574467 0.         0.         0.11025582 0.05041654 0.03949432\n",
      "  0.         0.41792253 0.26706666 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18951465 0.11253962 0.         0.         0.\n",
      "  0.         0.         0.02080528 0.23736694 0.         0.\n",
      "  0.         0.         0.         0.12633725 0.         0.3035196\n",
      "  0.28098843 0.21255553 0.09345208 0.2956766  0.07629915 0.40067026\n",
      "  0.         0.2508004  0.         0.         0.12801059 0.\n",
      "  0.1472535  0.04363801 0.10898227 0.1356138 ]]\n",
      "Hi!\n",
      "[[0.16998397 0.7488978  0.614536   0.         0.         0.51698697\n",
      "  0.1534089  0.5546681  0.4031298  0.         0.40929013 0.\n",
      "  0.81175053 0.17744899 0.         0.19069366 0.         0.517417\n",
      "  0.         0.53378975 0.5554187  0.         0.         0.12077447\n",
      "  0.         0.         0.         0.17321418 0.         0.\n",
      "  0.7071427  0.43944806 0.         0.         0.15369985 0.\n",
      "  0.         0.30877262 0.17137589 0.31841993 0.         0.\n",
      "  0.         0.         0.5176198  0.6504611  0.         0.27163252\n",
      "  0.09598229 0.79220176 0.26311976 0.37989235 0.7340513  0.5754357\n",
      "  0.         0.         0.06501825 0.         0.         0.\n",
      "  0.         0.5164339  0.33698866 0.16795869]]\n",
      "Hi!\n",
      "[[0.0195826  0.08177657 0.19011334 0.         0.         0.08368391\n",
      "  0.         0.01251353 0.03853362 0.03505051 0.07918942 0.\n",
      "  0.04970061 0.         0.         0.         0.         0.\n",
      "  0.         0.11177989 0.05967976 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00395957 0.06702721 0.01594416 0.         0.         0.\n",
      "  0.         0.         0.01095086 0.07004368 0.         0.\n",
      "  0.         0.01206383 0.04440068 0.09962785 0.         0.08480541\n",
      "  0.04870498 0.02821561 0.         0.13647713 0.00437655 0.14106452\n",
      "  0.         0.06008409 0.01640335 0.         0.01013606 0.\n",
      "  0.02859378 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.05263754 0.20303653 0.51438683 0.         0.         0.33112228\n",
      "  0.8474981  0.91566086 0.98496747 0.         0.43988025 0.\n",
      "  0.55929184 0.         0.         0.75019354 0.         0.7292593\n",
      "  0.17644091 0.         0.72568315 0.1480264  0.         0.\n",
      "  0.22071727 0.         0.         0.10275158 0.         0.\n",
      "  0.58063924 0.09280169 0.         0.         0.5317218  0.\n",
      "  0.18391189 1.1525999  0.         0.4072873  0.05371932 0.\n",
      "  0.         0.83617085 0.172663   0.31850064 0.         0.37222657\n",
      "  0.         0.6887126  0.7531867  0.11352289 0.28118646 0.02801977\n",
      "  0.         0.         0.08842554 0.         0.         0.\n",
      "  0.         0.9514273  0.76072115 0.4412281 ]]\n",
      "Hi!\n",
      "[[0.92859334 0.13277951 1.357308   0.02999235 0.         1.1964679\n",
      "  0.3454497  0.6077551  0.54849684 0.15507333 0.5105522  0.\n",
      "  0.         0.         0.         0.06091218 0.45357534 0.5886246\n",
      "  0.         0.38962185 0.9456705  0.         0.         0.5903061\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22975136 0.20479336 0.         0.         0.\n",
      "  0.         0.306274   0.         0.8749641  0.         0.\n",
      "  0.         0.82038283 0.         0.58057076 0.         0.08264904\n",
      "  0.33119676 1.2285565  0.15579203 0.40452933 0.8682946  0.1661098\n",
      "  0.         1.2565504  0.         0.         0.0338829  0.\n",
      "  0.31479657 0.77493095 0.54949033 0.14818364]]\n",
      "Hi!\n",
      "[[3.57494317e-02 1.76501557e-01 2.70843297e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.87589103e-01 0.00000000e+00 0.00000000e+00\n",
      "  7.61518404e-02 9.98856500e-02 2.48882517e-01 0.00000000e+00\n",
      "  4.51921634e-02 3.07947717e-04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.22530514e-03 0.00000000e+00 3.19735467e-01\n",
      "  1.56864449e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.77283522e-02\n",
      "  6.21368214e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.32179719e-02 1.74370900e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.85352290e-02 3.30547512e-01 0.00000000e+00 1.75342396e-01\n",
      "  2.23766163e-01 8.65045786e-02 0.00000000e+00 2.58477032e-01\n",
      "  1.08014956e-01 3.41178805e-01 0.00000000e+00 1.78125530e-01\n",
      "  0.00000000e+00 0.00000000e+00 6.17690943e-02 0.00000000e+00\n",
      "  3.09994241e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.28624532 0.         0.02850115 0.2603217  0.         0.50477576\n",
      "  1.452756   1.5289899  0.16889255 0.         0.18212868 0.\n",
      "  0.17678303 0.32194948 0.         0.31738174 0.         0.5635219\n",
      "  0.         0.         0.28444263 0.10939473 0.         0.\n",
      "  0.00624029 0.         0.         0.43053204 0.         0.\n",
      "  1.0435102  0.44400594 0.17033239 0.         0.6556086  0.\n",
      "  0.         1.0635551  0.         0.29017165 0.16539368 0.\n",
      "  0.         0.5120703  0.8312985  1.1732427  0.         0.\n",
      "  0.         0.93604    0.2602799  0.48234138 0.6825996  0.36889154\n",
      "  0.         0.00746882 0.16604756 0.         0.         0.\n",
      "  0.         0.7165589  0.7016994  0.        ]]\n",
      "Hi!\n",
      "[[0.20984755 0.5259631  0.9736221  0.         0.         0.4842661\n",
      "  0.45332766 0.6588827  1.4694327  0.         0.6054121  0.\n",
      "  1.4544737  0.         0.         1.0076486  0.         0.83356893\n",
      "  1.0671445  0.         1.0748562  0.13517606 0.         0.00831815\n",
      "  0.3275455  0.         0.         0.33698344 0.         0.\n",
      "  0.7491666  0.41664577 0.         0.         0.47834113 0.\n",
      "  0.5687664  1.2261895  0.         0.6146251  0.1814399  0.\n",
      "  0.         0.668393   0.2758348  0.02598621 0.         0.9556086\n",
      "  0.         0.9471367  1.1171085  0.21982726 0.43550906 0.3004621\n",
      "  0.         0.         0.21204767 0.217459   0.         0.\n",
      "  0.         0.8415079  1.3024274  0.905616  ]]\n",
      "Hi!\n",
      "[[0.12605976 0.3161932  0.07992758 0.         0.         0.19038334\n",
      "  1.1124307  1.133748   0.54742324 0.         0.28604233 0.\n",
      "  0.72432125 0.5004202  0.         0.63560885 0.         0.7293009\n",
      "  0.02997932 0.07944707 0.32057616 0.08399492 0.         0.\n",
      "  0.30064774 0.         0.         0.4028392  0.         0.\n",
      "  0.9681282  0.3022191  0.         0.         0.70652115 0.\n",
      "  0.2461804  1.1129644  0.         0.2760292  0.02110488 0.\n",
      "  0.         0.47943568 0.69475806 0.7452706  0.         0.30227733\n",
      "  0.         0.80914414 0.6887736  0.21912332 0.45084584 0.35257694\n",
      "  0.         0.         0.24251062 0.         0.         0.\n",
      "  0.         0.81215525 0.45026684 0.04056001]]\n",
      "Hi!\n",
      "[[0.64222485 0.53345686 0.5842283  0.25929037 0.         0.7675161\n",
      "  0.01963782 0.38581342 0.         0.         0.22489284 0.\n",
      "  0.5093961  0.5061414  0.         0.         0.         0.07132248\n",
      "  0.         0.8522679  0.16143577 0.         0.         0.07853998\n",
      "  0.         0.         0.         0.2114245  0.         0.\n",
      "  0.64084244 0.910069   0.1752769  0.         0.         0.\n",
      "  0.         0.08818042 0.6841769  0.12259848 0.         0.\n",
      "  0.         0.04717565 0.96781856 0.8647189  0.         0.42291802\n",
      "  0.77454036 0.55627334 0.         0.6188296  0.6395557  1.2491348\n",
      "  0.         0.8668003  0.25293583 0.         0.         0.\n",
      "  0.03502341 0.00163085 0.46218282 0.        ]]\n",
      "Hi!\n",
      "[[0.2820603  0.         0.9314551  0.         0.         0.6490083\n",
      "  1.0816947  1.0736783  1.2408773  0.         0.5231295  0.\n",
      "  0.48939678 0.         0.         0.87247664 0.00733425 0.8450888\n",
      "  0.39302328 0.         0.97883135 0.17708483 0.         0.12252768\n",
      "  0.22639604 0.         0.         0.15928869 0.         0.\n",
      "  0.5192848  0.14877164 0.         0.         0.53506434 0.\n",
      "  0.3764471  1.3417112  0.         0.5010904  0.1904746  0.\n",
      "  0.         1.169492   0.16549541 0.37598705 0.         0.59742576\n",
      "  0.         0.6242214  0.83640325 0.27342767 0.35431346 0.03695691\n",
      "  0.         0.         0.14617473 0.3479322  0.         0.\n",
      "  0.         1.0218315  1.3428602  0.57006675]]\n",
      "Hi!\n",
      "[[0.3953505  0.         0.36738688 0.14657028 0.         0.6458591\n",
      "  1.1336966  1.258043   0.4148625  0.         0.29495582 0.\n",
      "  0.54753375 0.15213831 0.         0.42871243 0.         0.579859\n",
      "  0.         0.03103609 0.504854   0.01422421 0.         0.\n",
      "  0.09832133 0.         0.         0.37206963 0.         0.\n",
      "  0.9392832  0.50586486 0.         0.         0.570264   0.\n",
      "  0.14923538 1.1156338  0.         0.27710986 0.11221801 0.\n",
      "  0.         0.48744345 0.80876505 0.91034466 0.         0.3701762\n",
      "  0.         0.76601094 0.38377023 0.46671933 0.5165947  0.53787863\n",
      "  0.         0.         0.29382417 0.         0.         0.\n",
      "  0.         0.57873225 0.9946782  0.        ]]\n",
      "Hi!\n",
      "[[0.8899346  0.42271826 2.032679   0.         0.         0.9279776\n",
      "  0.09208835 0.         1.4780755  0.         0.87806034 0.\n",
      "  0.6054385  0.         0.         0.8844341  0.8308349  1.0277382\n",
      "  0.298281   0.09991829 1.5522735  0.49075016 0.         0.65229154\n",
      "  0.02174179 0.         0.         0.         0.         0.\n",
      "  0.         0.15385729 0.         0.         0.         0.\n",
      "  0.2700729  0.88715726 0.         1.1594584  0.06795518 0.\n",
      "  0.         1.0842904  0.         0.         0.         0.92981124\n",
      "  0.         1.0235964  0.86496705 0.06263687 0.32343373 0.17652944\n",
      "  0.         0.3167151  0.         0.9455325  0.09976387 0.\n",
      "  0.         0.92081904 1.1720333  1.2825565 ]]\n",
      "Hi!\n",
      "[[0.48161548 0.         0.35110724 0.5306064  0.         0.98270726\n",
      "  2.073603   1.9656006  0.11082004 0.         0.16541354 0.\n",
      "  0.         0.         0.         0.23646191 0.         0.5673385\n",
      "  0.         0.         0.38662395 0.25269485 0.         0.\n",
      "  0.         0.         0.         0.2780598  0.         0.\n",
      "  0.81391853 0.44489327 0.2387359  0.         0.59977883 0.\n",
      "  0.         1.0758195  0.         0.5787516  0.31597668 0.\n",
      "  0.         0.89474565 0.8006531  1.3320309  0.         0.\n",
      "  0.         1.0175964  0.01114013 0.6701444  0.9307455  0.42606702\n",
      "  0.         0.6397708  0.10052723 0.         0.         0.\n",
      "  0.         0.85998726 1.07611    0.        ]]\n",
      "Hi!\n",
      "[[0.37787274 0.4334617  1.2887963  0.         0.         0.6510933\n",
      "  0.36269236 0.54234856 1.4402953  0.         0.66492206 0.\n",
      "  1.3726491  0.         0.         1.0107706  0.05789629 0.898268\n",
      "  1.1435974  0.         1.2004241  0.20934054 0.         0.02266169\n",
      "  0.38943616 0.         0.         0.30862656 0.         0.\n",
      "  0.6244392  0.3992013  0.         0.         0.44220248 0.\n",
      "  0.8240122  1.3224297  0.         0.7551553  0.17230052 0.\n",
      "  0.         0.76622057 0.29933056 0.         0.         1.1366537\n",
      "  0.         0.8767855  1.1192925  0.2418356  0.22754245 0.46946862\n",
      "  0.         0.         0.27521378 0.46002707 0.         0.\n",
      "  0.         0.74050385 1.5145419  1.0958477 ]]\n",
      "Hi!\n",
      "[[0.3108116  0.6685885  0.80890197 0.         0.         0.72310656\n",
      "  0.         0.         0.1256149  0.         0.45621318 0.\n",
      "  0.56413144 0.18462805 0.         0.         0.         0.09119909\n",
      "  0.         0.88298225 0.4119799  0.         0.         0.04466909\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18025564 0.5098948  0.         0.         0.         0.\n",
      "  0.         0.         0.35327655 0.2927513  0.         0.\n",
      "  0.         0.         0.45582673 0.46525866 0.         0.58682406\n",
      "  0.64136803 0.42595813 0.         0.5281475  0.53579855 0.92845124\n",
      "  0.         0.5583038  0.05874832 0.         0.16118261 0.\n",
      "  0.00680488 0.         0.3337872  0.03124912]]\n",
      "Hi!\n",
      "[[3.1553152e-01 4.5321709e-01 5.8380961e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.4024625e-01 5.9849095e-01 7.7020651e-01 7.7965695e-01 0.0000000e+00\n",
      "  4.7033164e-01 0.0000000e+00 1.0372505e+00 7.4126326e-02 0.0000000e+00\n",
      "  6.7193043e-01 0.0000000e+00 7.1512932e-01 3.1591916e-01 1.6874206e-01\n",
      "  6.7560661e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9979307e-01\n",
      "  0.0000000e+00 0.0000000e+00 3.1430745e-01 0.0000000e+00 0.0000000e+00\n",
      "  8.4152341e-01 4.3225104e-01 0.0000000e+00 0.0000000e+00 5.4421216e-01\n",
      "  0.0000000e+00 2.7705976e-01 1.0588336e+00 0.0000000e+00 4.0988854e-01\n",
      "  4.4447643e-04 0.0000000e+00 0.0000000e+00 3.6457059e-01 6.1560005e-01\n",
      "  4.4195399e-01 0.0000000e+00 5.6811363e-01 0.0000000e+00 7.3113644e-01\n",
      "  7.0965564e-01 3.2100958e-01 5.0240463e-01 4.4726917e-01 0.0000000e+00\n",
      "  0.0000000e+00 2.1015850e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 6.8720114e-01 9.1020489e-01 3.3171824e-01]]\n",
      "Hi!\n",
      "[[0.05793497 0.3586308  0.29708028 0.         0.         0.32371786\n",
      "  0.         0.08089671 0.         0.02723147 0.16327474 0.\n",
      "  0.19101788 0.21391162 0.         0.         0.         0.09594101\n",
      "  0.         0.383543   0.11232094 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1144772  0.32068953 0.11779001 0.         0.         0.\n",
      "  0.         0.         0.20804581 0.13722318 0.         0.\n",
      "  0.         0.         0.31941625 0.33248663 0.         0.16310257\n",
      "  0.39298606 0.27017978 0.         0.29764456 0.19971836 0.5122017\n",
      "  0.         0.2890394  0.03693982 0.         0.00143496 0.\n",
      "  0.16315265 0.10508383 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.46658584 0.50697714 0.3442137  0.03182857 0.         0.5858338\n",
      "  0.51820964 0.9044825  0.12684697 0.         0.3200337  0.\n",
      "  0.9473027  0.536645   0.         0.2087313  0.         0.4377394\n",
      "  0.         0.49341118 0.42476672 0.         0.         0.0782528\n",
      "  0.         0.         0.         0.38073453 0.         0.\n",
      "  1.0407027  0.76549226 0.         0.         0.47804925 0.\n",
      "  0.         0.6705758  0.15893452 0.22533631 0.         0.\n",
      "  0.         0.22600307 0.9897587  0.8856294  0.         0.4217564\n",
      "  0.2008935  0.8102167  0.28726763 0.50934756 0.7575345  0.86365235\n",
      "  0.         0.18007676 0.25312316 0.         0.         0.\n",
      "  0.         0.28150922 0.6737289  0.        ]]\n",
      "Hi!\n",
      "[[0.73075134 0.1293505  1.3670915  0.         0.         0.9487834\n",
      "  0.33743966 0.46066624 0.7696006  0.00674496 0.5558879  0.\n",
      "  0.14848451 0.         0.         0.35528544 0.3553168  0.76600575\n",
      "  0.         0.17601456 1.0663078  0.04820576 0.         0.37283456\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2980698  0.00673897 0.         0.         0.\n",
      "  0.         0.7003336  0.         0.73816985 0.         0.\n",
      "  0.         0.68559575 0.         0.35595658 0.         0.53761774\n",
      "  0.10761455 0.71694237 0.38285267 0.2777681  0.45037368 0.24483539\n",
      "  0.         0.6154449  0.         0.24193023 0.03366739 0.\n",
      "  0.         0.78113896 0.9036534  0.5212189 ]]\n",
      "Hi!\n",
      "[[0.179551   0.35678303 1.18531    0.         0.         0.5394336\n",
      "  0.57802993 0.6246039  1.7788503  0.         0.67127764 0.\n",
      "  1.3485461  0.         0.         1.2043409  0.09230652 0.9092957\n",
      "  1.2972978  0.         1.2543069  0.3790556  0.         0.08326186\n",
      "  0.4947268  0.         0.         0.24707255 0.         0.\n",
      "  0.5992392  0.24536581 0.         0.         0.5355447  0.\n",
      "  0.8562385  1.4248277  0.         0.7412011  0.3004568  0.\n",
      "  0.         1.0456195  0.08570229 0.         0.         1.1341728\n",
      "  0.         0.97252876 1.3272525  0.12689532 0.12007096 0.16377279\n",
      "  0.         0.         0.2730975  0.6179915  0.         0.\n",
      "  0.         0.93664616 1.4719777  1.2038826 ]]\n",
      "Hi!\n",
      "[[1.1171234e-01 4.6734622e-01 1.7829011e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.4538012e-01 3.9513126e-01 6.2077820e-01 0.0000000e+00 0.0000000e+00\n",
      "  2.2469203e-01 0.0000000e+00 2.5324234e-01 2.9912770e-01 0.0000000e+00\n",
      "  3.4116827e-02 0.0000000e+00 3.2444462e-01 0.0000000e+00 5.8489263e-01\n",
      "  1.9078292e-01 0.0000000e+00 0.0000000e+00 6.3242234e-04 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.9097250e-02 0.0000000e+00 0.0000000e+00\n",
      "  5.0730705e-01 3.5385987e-01 1.8087962e-01 0.0000000e+00 1.7838885e-01\n",
      "  0.0000000e+00 0.0000000e+00 2.3287056e-01 9.5198460e-02 3.1384528e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.1915318e-02 4.7678784e-01\n",
      "  7.2812903e-01 0.0000000e+00 6.0348511e-02 2.1469359e-01 7.6477247e-01\n",
      "  9.5761284e-02 3.7731236e-01 4.4232321e-01 5.7104343e-01 0.0000000e+00\n",
      "  2.4606711e-01 1.1321259e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.0221910e-02 3.7954104e-01 0.0000000e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.13398822 0.3874368  0.06668257 0.         0.         0.3297254\n",
      "  0.23648347 0.30218065 0.01392219 0.         0.13535449 0.\n",
      "  0.44972274 0.3184367  0.         0.         0.         0.05843701\n",
      "  0.         0.3820747  0.04162516 0.         0.         0.\n",
      "  0.         0.         0.         0.12290656 0.         0.\n",
      "  0.36570403 0.33939338 0.15000923 0.         0.07500723 0.\n",
      "  0.         0.11720484 0.2296396  0.03539022 0.         0.\n",
      "  0.         0.00664446 0.41089696 0.6114641  0.         0.3311675\n",
      "  0.17353918 0.34241843 0.02806922 0.3257344  0.23634377 0.65251005\n",
      "  0.         0.13830969 0.27840194 0.         0.         0.\n",
      "  0.02236987 0.11407613 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.25678933 0.14044021 1.039538   0.         0.         0.586901\n",
      "  0.6613812  0.82634294 1.495      0.         0.5976951  0.\n",
      "  0.90274185 0.         0.         1.0093356  0.07896379 0.83639026\n",
      "  0.79663324 0.         1.1009316  0.27681157 0.         0.22333452\n",
      "  0.20016484 0.         0.         0.24587362 0.         0.\n",
      "  0.53475803 0.22404182 0.         0.         0.41447788 0.\n",
      "  0.46896282 1.3102012  0.         0.65426755 0.2368513  0.\n",
      "  0.         1.0883639  0.03714207 0.14152955 0.         0.7623661\n",
      "  0.         0.8423269  1.0214493  0.21576832 0.24462536 0.0858078\n",
      "  0.         0.         0.13226835 0.4697998  0.         0.\n",
      "  0.         0.95851463 1.3376976  0.8457115 ]]\n",
      "Hi!\n",
      "[[0.26796728 0.03406719 0.5747292  0.         0.         0.47103378\n",
      "  1.1169116  1.3662223  1.496046   0.         0.48390016 0.\n",
      "  1.4188943  0.         0.         1.1507691  0.         0.7998757\n",
      "  1.2737561  0.         0.91403025 0.18373065 0.         0.\n",
      "  0.50138474 0.         0.         0.692236   0.         0.\n",
      "  1.115927   0.35902327 0.         0.         0.85677135 0.\n",
      "  0.86280745 1.639545   0.         0.3405072  0.33655366 0.\n",
      "  0.         1.0430899  0.58976585 0.40954208 0.         0.91148233\n",
      "  0.         0.81720906 1.2682579  0.339996   0.26512495 0.338302\n",
      "  0.         0.         0.5015365  0.19056684 0.         0.\n",
      "  0.         0.7658204  1.6215698  0.67489564]]\n",
      "Hi!\n",
      "[[0.4792149  0.         0.5871123  0.05708642 0.         0.6453374\n",
      "  1.0661346  0.9435415  0.43647504 0.06154437 0.31271613 0.\n",
      "  0.         0.         0.         0.2516715  0.03886033 0.65677214\n",
      "  0.         0.06031484 0.5777088  0.02435601 0.         0.11999373\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23535419 0.11046666 0.10162839 0.         0.2624967  0.\n",
      "  0.         0.74433315 0.         0.5734024  0.         0.\n",
      "  0.         0.758662   0.1375216  0.6384573  0.         0.04009008\n",
      "  0.         0.83008695 0.20749079 0.28502032 0.41907135 0.13999255\n",
      "  0.         0.2726561  0.         0.         0.         0.\n",
      "  0.         0.9173591  0.44324425 0.02537738]]\n",
      "Hi!\n",
      "[[0.25603387 0.505931   1.1971203  0.         0.         0.64691365\n",
      "  0.3242819  0.29433578 1.2329584  0.         0.6400834  0.\n",
      "  1.098848   0.         0.         0.8066571  0.08894794 0.83768815\n",
      "  0.69978124 0.0485135  1.1236202  0.13585693 0.         0.14189285\n",
      "  0.23832509 0.         0.         0.         0.         0.\n",
      "  0.36948067 0.34631136 0.         0.         0.19816275 0.\n",
      "  0.43788472 0.96076965 0.         0.7618592  0.07510529 0.\n",
      "  0.         0.57812697 0.11946527 0.         0.         0.94249403\n",
      "  0.         0.83271044 0.90022033 0.21415357 0.320173   0.30722967\n",
      "  0.         0.         0.00164721 0.3301266  0.02523149 0.\n",
      "  0.         0.7834387  1.0831219  0.98907936]]\n",
      "Hi!\n",
      "[[0.599583   1.1608207  0.71570927 0.         0.         0.47373766\n",
      "  0.         0.34746915 0.62200093 0.         0.49167404 0.\n",
      "  1.8372442  0.47403726 0.         0.58172154 0.         0.6519595\n",
      "  0.7563099  0.6881546  0.6275388  0.         0.         0.15294185\n",
      "  0.20105512 0.         0.         0.37211943 0.         0.\n",
      "  0.9729089  0.8763207  0.         0.         0.44642296 0.\n",
      "  0.4692625  0.7783721  0.3909706  0.505328   0.         0.\n",
      "  0.         0.28981957 0.9790641  0.38055134 0.         1.1353788\n",
      "  0.         0.7554456  0.7839177  0.3657201  0.55152065 1.1360961\n",
      "  0.         0.         0.39800203 0.         0.04355515 0.\n",
      "  0.         0.34163034 0.8272331  0.48568276]]\n",
      "Hi!\n",
      "[[0.36246777 0.10908098 0.5307879  0.00744567 0.         0.62666506\n",
      "  0.89819026 1.1918533  0.7549919  0.         0.37980342 0.\n",
      "  0.84394795 0.00811278 0.         0.59981096 0.         0.6019333\n",
      "  0.27038354 0.         0.6538186  0.         0.         0.\n",
      "  0.11775465 0.         0.         0.48418432 0.         0.\n",
      "  0.9629317  0.47819978 0.         0.         0.5422409  0.\n",
      "  0.25317544 1.1839645  0.         0.32433027 0.08104523 0.\n",
      "  0.         0.557676   0.6247025  0.69200736 0.         0.44651031\n",
      "  0.         0.71654713 0.6070727  0.4532717  0.5798404  0.38307038\n",
      "  0.         0.         0.25936726 0.         0.         0.\n",
      "  0.         0.6108256  1.2207142  0.1547888 ]]\n",
      "Hi!\n",
      "[[0.15999353 0.6304501  0.41751906 0.         0.         0.37598217\n",
      "  0.         0.02713944 0.04558982 0.         0.26473063 0.\n",
      "  0.56646466 0.25365442 0.         0.         0.         0.21263969\n",
      "  0.         0.59021807 0.20418775 0.         0.         0.01197717\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21536459 0.33279955 0.         0.         0.         0.\n",
      "  0.         0.         0.29742748 0.10781743 0.         0.\n",
      "  0.         0.         0.36995527 0.3388852  0.         0.3425964\n",
      "  0.33996236 0.29727274 0.02679246 0.28733876 0.2143117  0.6626737\n",
      "  0.         0.1078694  0.15678878 0.         0.04552043 0.\n",
      "  0.08067345 0.12304164 0.07372192 0.0427107 ]]\n",
      "Hi!\n",
      "[[0.20444196 0.5512778  0.4283034  0.         0.         0.5046326\n",
      "  0.24515884 0.4205393  0.6587869  0.         0.32188973 0.\n",
      "  0.8632834  0.0427844  0.         0.37296653 0.         0.51165634\n",
      "  0.08354065 0.32434905 0.4597238  0.         0.         0.\n",
      "  0.0893068  0.         0.         0.         0.         0.\n",
      "  0.5002126  0.2716252  0.         0.         0.20303245 0.\n",
      "  0.03183429 0.7000945  0.         0.30953765 0.         0.\n",
      "  0.         0.12204991 0.30081868 0.338831   0.         0.6417027\n",
      "  0.         0.53890765 0.51585567 0.28468585 0.13996933 0.45904744\n",
      "  0.         0.         0.09789816 0.         0.         0.\n",
      "  0.         0.46831828 0.4595352  0.39132905]]\n",
      "Hi!\n",
      "[[5.69162011e-01 0.00000000e+00 1.15255380e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.73381245e-01 8.93758953e-01 7.93937385e-01\n",
      "  1.23912001e+00 0.00000000e+00 5.76926291e-01 0.00000000e+00\n",
      "  1.58950908e-03 0.00000000e+00 0.00000000e+00 7.97259152e-01\n",
      "  4.01269168e-01 9.31702197e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.09141910e+00 3.24857235e-01 0.00000000e+00 4.38610196e-01\n",
      "  6.49600029e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.26244888e-01 9.04896203e-03\n",
      "  1.11810642e-03 0.00000000e+00 2.63609380e-01 0.00000000e+00\n",
      "  1.21814586e-01 1.12374461e+00 0.00000000e+00 7.73885429e-01\n",
      "  1.68272868e-01 0.00000000e+00 0.00000000e+00 1.30589914e+00\n",
      "  0.00000000e+00 1.98117971e-01 0.00000000e+00 3.45690370e-01\n",
      "  0.00000000e+00 7.31477082e-01 6.81466937e-01 4.98410724e-02\n",
      "  2.29610518e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.49225783e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.19141114e+00 1.00856674e+00 5.97164392e-01]]\n",
      "Hi!\n",
      "[[0.99526244 0.         1.256444   0.48093337 0.         1.0184653\n",
      "  1.404693   1.3897622  0.80173457 0.0139898  0.4462363  0.\n",
      "  0.         0.         0.         0.35259327 0.72648203 0.8643081\n",
      "  0.         0.         0.9957696  0.41675124 0.         0.74446565\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02587811 0.41242626 0.         0.         0.\n",
      "  0.         0.639698   0.         1.2022167  0.16429743 0.\n",
      "  0.         1.8781956  0.         0.6028638  0.         0.\n",
      "  0.00972718 1.4675503  0.25384757 0.18705247 0.9966043  0.\n",
      "  0.         1.3232244  0.         0.09172628 0.         0.\n",
      "  0.15681644 1.2406585  0.7295933  0.        ]]\n",
      "Hi!\n",
      "[[0.5304053  0.         0.42850158 0.4258374  0.         0.8447474\n",
      "  1.427128   1.4624819  0.17907804 0.04972508 0.22649127 0.\n",
      "  0.         0.         0.         0.17900546 0.         0.54509133\n",
      "  0.         0.01149807 0.39631328 0.01393674 0.         0.15481557\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38096845 0.2926368  0.31387058 0.         0.25766635 0.\n",
      "  0.         0.6031693  0.         0.74151367 0.18133837 0.\n",
      "  0.         0.90454805 0.26047707 1.0249159  0.         0.\n",
      "  0.13420206 1.1504118  0.         0.47572958 0.9087446  0.\n",
      "  0.         0.7479348  0.         0.         0.         0.\n",
      "  0.         0.9174464  0.4430341  0.        ]]\n",
      "Hi!\n",
      "[[1.0543506  0.52026194 2.179385   0.         0.         1.2354239\n",
      "  0.         0.         0.94606835 0.         0.80018413 0.\n",
      "  0.29225034 0.         0.         0.46759704 0.8561227  0.8200639\n",
      "  0.         0.6501199  1.4465228  0.19660279 0.         0.50619125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33409223 0.03653292 0.         0.         0.\n",
      "  0.         0.45013973 0.         1.1458793  0.         0.\n",
      "  0.         0.7511269  0.         0.17170067 0.         0.87091756\n",
      "  0.45895177 0.9860248  0.50996166 0.22033267 0.52654123 0.39777264\n",
      "  0.         0.99999523 0.         0.6086746  0.23279576 0.\n",
      "  0.27057183 0.7347178  0.9246083  0.97180325]]\n",
      "Hi!\n",
      "[[0.44057536 0.         0.78784627 0.02181917 0.         0.34156734\n",
      "  0.91731733 0.6922563  0.78519505 0.01262198 0.3481847  0.\n",
      "  0.         0.         0.         0.41873834 0.3637675  0.73360044\n",
      "  0.         0.         0.6673651  0.258131   0.         0.11528458\n",
      "  0.02832148 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11181998 0.         0.18667735 0.\n",
      "  0.         0.7693998  0.         0.5115338  0.         0.\n",
      "  0.         0.96976113 0.         0.2616576  0.         0.10642901\n",
      "  0.         0.60468847 0.3764979  0.02672252 0.09454577 0.\n",
      "  0.         0.07771322 0.         0.22152168 0.         0.\n",
      "  0.         1.0268492  0.4958724  0.2389143 ]]\n",
      "Hi!\n",
      "[[0.         0.22724546 0.19418056 0.         0.         0.24824226\n",
      "  0.         0.2030672  0.         0.08154028 0.14252205 0.\n",
      "  0.         0.1030416  0.         0.         0.         0.09276685\n",
      "  0.         0.29954708 0.0832751  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14712328 0.13378896 0.         0.         0.\n",
      "  0.         0.         0.11924756 0.15214396 0.         0.\n",
      "  0.         0.         0.11812514 0.39498967 0.         0.02021661\n",
      "  0.2520821  0.3054222  0.         0.22113693 0.13032079 0.3179473\n",
      "  0.         0.25803953 0.         0.         0.         0.\n",
      "  0.20438398 0.20076475 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.23326409 0.04330954 0.7517982  0.         0.         0.646449\n",
      "  0.90983164 1.1673259  1.0910498  0.         0.46407387 0.\n",
      "  0.85858387 0.         0.         0.7689656  0.         0.7448602\n",
      "  0.46102035 0.         0.8580594  0.         0.         0.06312104\n",
      "  0.13161874 0.         0.         0.4134181  0.         0.\n",
      "  0.8306208  0.3736805  0.         0.         0.5445082  0.\n",
      "  0.24028969 1.2755126  0.         0.40483606 0.18844217 0.\n",
      "  0.         0.84791553 0.34182036 0.52423185 0.         0.49839482\n",
      "  0.         0.6962899  0.775873   0.37594217 0.5330797  0.18843393\n",
      "  0.         0.         0.20965159 0.02829483 0.         0.\n",
      "  0.         0.8105355  1.3566545  0.43381196]]\n",
      "Hi!\n",
      "[[1.2215559e-01 1.4945440e-01 7.2917044e-01 0.0000000e+00 0.0000000e+00\n",
      "  3.5889149e-01 0.0000000e+00 0.0000000e+00 4.4248211e-01 3.9148770e-02\n",
      "  4.2105624e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.7024418e-01 1.0168234e-01 0.0000000e+00 0.0000000e+00 3.7185404e-01\n",
      "  3.7071285e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 9.2874944e-02 1.3983269e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.6431920e-01 5.6935929e-02 4.5651677e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3134696e-01\n",
      "  1.3437422e-01 0.0000000e+00 4.6672079e-01 7.4116468e-02 0.0000000e+00\n",
      "  3.7498629e-01 3.3930108e-01 3.3335421e-02 3.2996303e-01 0.0000000e+00\n",
      "  3.5535389e-01 0.0000000e+00 1.9094003e-02 1.5801093e-01 0.0000000e+00\n",
      "  0.0000000e+00 5.0274382e-04 1.6287191e-01 3.3823514e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "[[0.72832733 0.         1.2881031  0.         0.         0.8389196\n",
      "  0.61309665 0.690344   1.1137985  0.         0.57316005 0.\n",
      "  0.         0.         0.         0.5256244  0.517118   0.87006325\n",
      "  0.         0.         1.1224117  0.37850857 0.         0.69553703\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16630952 0.19657964 0.         0.         0.\n",
      "  0.         0.7254804  0.         0.8737593  0.04872182 0.\n",
      "  0.         1.2526187  0.         0.24142851 0.         0.\n",
      "  0.         1.1470641  0.55235976 0.12306012 0.5815458  0.0127139\n",
      "  0.         0.47579947 0.         0.3095209  0.         0.\n",
      "  0.         1.092304   0.7669295  0.49940357]]\n",
      "Hi!\n",
      "[[1.0444303  0.         1.8094358  0.         0.         0.92390233\n",
      "  0.6067776  0.7644331  1.3962622  0.         0.6844974  0.\n",
      "  0.         0.         0.         0.73235613 0.9371491  0.91772765\n",
      "  0.         0.         1.465661   0.4965452  0.         0.8264852\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05566292 0.11632621 0.         0.         0.\n",
      "  0.         0.92334497 0.         0.98560506 0.14658293 0.\n",
      "  0.         1.6171446  0.         0.11087742 0.         0.31956077\n",
      "  0.         0.9421471  0.67890567 0.09507335 0.5471421  0.\n",
      "  0.         0.75822556 0.         0.77001476 0.         0.\n",
      "  0.         1.1954186  1.1747241  0.72473127]]\n",
      "Hi!\n",
      "[[0.0000000e+00 1.8039954e-01 4.3051988e-02 0.0000000e+00 0.0000000e+00\n",
      "  1.6591960e-01 1.8071699e-01 2.9442486e-01 2.2921900e-01 7.0104286e-02\n",
      "  1.6825578e-01 0.0000000e+00 4.3407254e-02 9.3228127e-06 0.0000000e+00\n",
      "  1.3771175e-01 0.0000000e+00 1.8852124e-01 0.0000000e+00 1.4730835e-01\n",
      "  1.3486312e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.6844397e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 9.8637618e-02 0.0000000e+00 1.7132895e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 7.2190225e-02 7.8173712e-02\n",
      "  2.5025809e-01 0.0000000e+00 1.4964633e-02 0.0000000e+00 3.1614938e-01\n",
      "  1.7569846e-01 3.5703756e-02 0.0000000e+00 1.4294837e-01 0.0000000e+00\n",
      "  0.0000000e+00 5.6546912e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  4.9363188e-02 2.7253753e-01 0.0000000e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.07852771 0.32363278 0.20166774 0.         0.         0.0945216\n",
      "  0.         0.04681169 0.07176647 0.00414245 0.13907737 0.\n",
      "  0.32313827 0.12215355 0.         0.03707316 0.         0.05683809\n",
      "  0.         0.21452032 0.0967617  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09780487 0.20538753 0.07677418 0.         0.         0.\n",
      "  0.         0.         0.2390016  0.0282189  0.         0.\n",
      "  0.         0.         0.14149141 0.18594976 0.         0.06924459\n",
      "  0.12701327 0.1548921  0.0087177  0.18404688 0.12627153 0.41575107\n",
      "  0.         0.         0.12965406 0.         0.01477177 0.\n",
      "  0.06027782 0.19366181 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.1223326  0.43527865 2.3685117  0.         0.         1.0466381\n",
      "  0.         0.         1.3393966  0.         0.8516904  0.\n",
      "  0.24516904 0.         0.         0.73005843 1.1892182  0.9957449\n",
      "  0.02783323 0.42519563 1.601449   0.4741668  0.         0.5045197\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13258845 0.         0.         0.         0.\n",
      "  0.26841828 0.68745935 0.         1.295062   0.         0.\n",
      "  0.         1.1294961  0.         0.         0.         1.0458676\n",
      "  0.2710752  1.1238766  0.73151374 0.02813533 0.23970406 0.2386362\n",
      "  0.         0.5841015  0.         1.0228871  0.232224   0.\n",
      "  0.06519198 0.9226529  1.0504564  1.1953572 ]]\n",
      "Hi!\n",
      "[[1.0465261  0.22157985 1.9781972  0.         0.         1.15817\n",
      "  0.01883843 0.12204123 1.0225424  0.         0.69765615 0.\n",
      "  0.         0.         0.         0.4258524  0.863966   0.8340942\n",
      "  0.         0.42401606 1.343221   0.30990648 0.         0.48171866\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24958937 0.07147162 0.         0.         0.\n",
      "  0.         0.5173209  0.         1.0874228  0.         0.\n",
      "  0.         1.0266993  0.         0.19787265 0.         0.8141317\n",
      "  0.31452343 0.90071255 0.49384046 0.11754719 0.36718428 0.29163712\n",
      "  0.         0.9101879  0.         0.627246   0.11173266 0.\n",
      "  0.25834325 0.8936721  0.8072139  0.8081885 ]]\n",
      "Hi!\n",
      "[[0.         0.16353193 0.17016762 0.         0.         0.17444263\n",
      "  0.25383434 0.31430766 0.0963968  0.18556753 0.23076451 0.\n",
      "  0.         0.01257279 0.         0.08147425 0.         0.12099342\n",
      "  0.         0.2937541  0.17242205 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.12374901 0.         0.         0.\n",
      "  0.         0.06691791 0.07266063 0.23098081 0.         0.\n",
      "  0.         0.00398347 0.032717   0.42625743 0.         0.\n",
      "  0.13233128 0.32441837 0.01121796 0.20380767 0.12202376 0.2574629\n",
      "  0.         0.25504202 0.         0.         0.         0.\n",
      "  0.07160279 0.32720178 0.         0.        ]]\n",
      "Hi!\n",
      "[[9.1404325e-01 4.2107567e-02 1.6634718e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0231768e+00 3.7957457e-01 4.2500991e-01 9.6173310e-01 0.0000000e+00\n",
      "  6.2764323e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0118983e-01 6.4508504e-01 8.2841796e-01 0.0000000e+00 1.3553439e-01\n",
      "  1.2432477e+00 2.0436373e-01 0.0000000e+00 4.0621287e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.5617307e-01 2.3043234e-02 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.0238272e-02 7.8569442e-01 0.0000000e+00 8.7370676e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.8540246e-01 0.0000000e+00\n",
      "  2.2357847e-01 0.0000000e+00 6.9360155e-01 1.2115009e-01 7.4158943e-01\n",
      "  4.7984257e-01 1.7193346e-01 3.5768151e-01 2.9656669e-01 0.0000000e+00\n",
      "  6.9270062e-01 0.0000000e+00 5.2698249e-01 1.5423384e-03 0.0000000e+00\n",
      "  6.4118863e-03 8.6928648e-01 9.5056790e-01 6.6472572e-01]]\n",
      "Hi!\n",
      "[[0.27037427 0.4242928  0.53520656 0.         0.         0.60192955\n",
      "  0.         0.13692667 0.24842952 0.14135954 0.32307842 0.\n",
      "  0.         0.         0.         0.01271905 0.         0.2656287\n",
      "  0.         0.5503925  0.34372354 0.         0.         0.08191776\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06940031 0.04757818 0.         0.         0.\n",
      "  0.         0.         0.         0.31866038 0.         0.\n",
      "  0.         0.00562814 0.         0.42914417 0.         0.23984468\n",
      "  0.3082529  0.5206327  0.06976148 0.3058047  0.16960867 0.26353773\n",
      "  0.         0.4427904  0.         0.         0.07093766 0.\n",
      "  0.31652066 0.37544674 0.         0.20113648]]\n",
      "Hi!\n",
      "[[0.63974893 0.3539478  1.0304408  0.         0.         0.9366979\n",
      "  0.04286084 0.21512614 0.08042519 0.07397798 0.40065527 0.\n",
      "  0.06436014 0.         0.         0.03633808 0.11141506 0.40184283\n",
      "  0.         0.80076414 0.55831504 0.         0.         0.09418175\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02469452 0.51659316 0.07164177 0.         0.         0.\n",
      "  0.         0.18856494 0.         0.58281195 0.         0.\n",
      "  0.         0.         0.34035513 0.6509719  0.         0.5047723\n",
      "  0.56348807 0.6751325  0.         0.46550184 0.5388671  0.687332\n",
      "  0.         1.061151   0.         0.         0.09629984 0.\n",
      "  0.3262887  0.25129497 0.41158208 0.0549257 ]]\n",
      "Hi!\n",
      "[[6.7232764e-01 0.0000000e+00 1.4481949e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.2708428e-01 9.3067491e-01 8.9378786e-01 1.5200676e+00 0.0000000e+00\n",
      "  6.5676409e-01 0.0000000e+00 1.6882366e-02 0.0000000e+00 0.0000000e+00\n",
      "  9.2927343e-01 6.3313353e-01 9.5893210e-01 1.3288164e-01 0.0000000e+00\n",
      "  1.3272511e+00 5.1663089e-01 0.0000000e+00 5.4851240e-01 1.0532155e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.3023478e-04 1.1563764e-02 2.5240986e-02 0.0000000e+00 2.0919679e-01\n",
      "  0.0000000e+00 2.7767402e-01 1.2521148e+00 0.0000000e+00 8.4393585e-01\n",
      "  1.9919027e-01 0.0000000e+00 0.0000000e+00 1.6552384e+00 0.0000000e+00\n",
      "  6.9027655e-02 0.0000000e+00 5.6603771e-01 0.0000000e+00 7.1712512e-01\n",
      "  8.0920374e-01 3.6159556e-02 2.1180752e-01 0.0000000e+00 0.0000000e+00\n",
      "  3.6618672e-02 0.0000000e+00 7.6570684e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.2994632e+00 1.3082374e+00 7.7677697e-01]]\n",
      "Hi!\n",
      "[[0.15097372 0.42014658 0.50739604 0.         0.         0.55414945\n",
      "  0.         0.08412441 0.00539064 0.11605332 0.3006786  0.\n",
      "  0.0933791  0.03839984 0.         0.         0.         0.22404478\n",
      "  0.         0.6524254  0.24914567 0.         0.         0.00120434\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03548898 0.20123817 0.         0.         0.         0.\n",
      "  0.         0.         0.04187102 0.30007583 0.         0.\n",
      "  0.         0.         0.2515218  0.5005262  0.         0.31111524\n",
      "  0.45469454 0.37055942 0.         0.35677075 0.3391626  0.5177981\n",
      "  0.         0.49038556 0.         0.         0.10211938 0.\n",
      "  0.21352388 0.1305665  0.         0.07807492]]\n",
      "Hi!\n",
      "[[0.49983752 0.14715904 1.1441512  0.         0.         0.717325\n",
      "  0.5363068  0.58954555 1.0901343  0.         0.57187814 0.\n",
      "  0.33646044 0.         0.         0.6016774  0.24791153 0.8362171\n",
      "  0.         0.         1.0293993  0.18515354 0.         0.41752702\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17635462 0.1798691  0.00651489 0.         0.14124358 0.\n",
      "  0.         0.8595936  0.         0.7436515  0.04489374 0.\n",
      "  0.         0.9382604  0.         0.2434833  0.         0.3680084\n",
      "  0.         0.84383297 0.6277276  0.20303047 0.49084678 0.\n",
      "  0.         0.1041664  0.         0.26062945 0.         0.\n",
      "  0.         0.9560164  0.87152356 0.6188514 ]]\n",
      "Hi!\n",
      "[[0.6669817  0.30718482 1.3763621  0.03326877 0.         1.3530905\n",
      "  0.2587116  0.5096804  0.14589086 0.         0.51578736 0.\n",
      "  0.50153637 0.         0.         0.05071279 0.05284645 0.4818299\n",
      "  0.         0.82572216 0.86011696 0.         0.         0.\n",
      "  0.         0.         0.         0.008898   0.         0.\n",
      "  0.348245   0.8815751  0.00852841 0.         0.         0.\n",
      "  0.02028115 0.5725274  0.         0.60763866 0.         0.\n",
      "  0.         0.10323972 0.7169949  0.7601228  0.         0.9500951\n",
      "  0.6019281  0.6798909  0.07747133 0.61612463 0.71222997 1.0531793\n",
      "  0.         1.1202745  0.16167398 0.         0.02491024 0.\n",
      "  0.         0.24078606 1.1283603  0.08259004]]\n",
      "Hi!\n",
      "[[0.4963068  0.35550946 0.44732657 0.07458758 0.         0.69915175\n",
      "  0.50235164 0.93245465 0.03391694 0.         0.2727164  0.\n",
      "  0.6463388  0.33922037 0.         0.0906649  0.         0.37567616\n",
      "  0.         0.5041149  0.37924656 0.         0.         0.03217338\n",
      "  0.         0.         0.         0.26986966 0.         0.\n",
      "  0.8923139  0.7051322  0.00310983 0.         0.25465003 0.\n",
      "  0.         0.6206629  0.10294594 0.27306256 0.         0.\n",
      "  0.         0.09249037 0.8895666  0.97297275 0.         0.32684794\n",
      "  0.2670209  0.823335   0.14497712 0.547349   0.71843046 0.81811523\n",
      "  0.         0.42648116 0.1753743  0.         0.         0.\n",
      "  0.         0.26106787 0.6325422  0.        ]]\n",
      "Hi!\n",
      "[[0.6016143  0.1627485  0.3356128  0.3202713  0.         0.8593471\n",
      "  0.861658   0.98520684 0.         0.06025239 0.05274772 0.\n",
      "  0.         0.3329276  0.         0.04302945 0.         0.22020116\n",
      "  0.         0.6680869  0.16585992 0.         0.         0.06281939\n",
      "  0.         0.         0.         0.10614621 0.         0.\n",
      "  0.71648026 0.69891775 0.27994755 0.         0.09463778 0.\n",
      "  0.         0.4362126  0.20356436 0.3037275  0.         0.\n",
      "  0.         0.09976973 1.0395116  1.2206515  0.         0.23052488\n",
      "  0.5627209  0.83936757 0.         0.7333545  0.733523   0.97104806\n",
      "  0.         1.0023304  0.14652032 0.         0.         0.\n",
      "  0.11393118 0.27085447 0.4045842  0.        ]]\n",
      "Hi!\n",
      "[[0.7341179  0.79442954 0.5862232  0.11546969 0.         0.7225625\n",
      "  0.         0.44253933 0.         0.         0.26865438 0.\n",
      "  1.0065831  0.63528085 0.         0.         0.         0.24654615\n",
      "  0.         0.92136955 0.2416746  0.         0.         0.26384956\n",
      "  0.         0.         0.         0.3438939  0.         0.\n",
      "  0.88423854 0.96938515 0.1097846  0.         0.16647975 0.\n",
      "  0.14777355 0.25314412 0.6965116  0.2446737  0.         0.\n",
      "  0.         0.16543773 1.154948   0.881075   0.         0.65717447\n",
      "  0.60161114 0.60187536 0.         0.65260804 0.62527436 1.3178198\n",
      "  0.         0.6275626  0.33206093 0.         0.0129237  0.\n",
      "  0.         0.02960171 0.5796739  0.        ]]\n",
      "Hi!\n",
      "[[0.58433104 0.12777328 1.0102993  0.1911864  0.         1.0097884\n",
      "  0.6621157  1.154432   0.44347814 0.         0.39349368 0.\n",
      "  0.32506037 0.         0.         0.20364887 0.         0.48734063\n",
      "  0.         0.23332037 0.8588379  0.         0.         0.25094664\n",
      "  0.         0.         0.         0.29164147 0.         0.\n",
      "  0.70005393 0.67897713 0.09800425 0.         0.21579574 0.\n",
      "  0.         0.7075425  0.         0.41704413 0.05052707 0.\n",
      "  0.         0.4547782  0.5452392  0.80749613 0.         0.13108277\n",
      "  0.09131777 0.9567089  0.11282852 0.5976079  1.0142317  0.43809807\n",
      "  0.         0.7660657  0.02613901 0.         0.         0.\n",
      "  0.         0.5392136  1.2327291  0.        ]]\n",
      "Hi!\n",
      "[[0.23792553 0.2904167  0.         0.15736888 0.         0.4032456\n",
      "  0.8625983  1.141305   0.         0.         0.14448136 0.\n",
      "  0.2701882  0.64808965 0.         0.10826831 0.         0.31716937\n",
      "  0.         0.37204647 0.12678035 0.         0.         0.11256171\n",
      "  0.         0.         0.         0.32128203 0.         0.\n",
      "  0.89687175 0.45873845 0.24526827 0.         0.32728592 0.\n",
      "  0.         0.40079236 0.16492356 0.3187463  0.         0.\n",
      "  0.         0.17348243 0.79411036 1.0698848  0.         0.\n",
      "  0.1187688  0.9575725  0.12208728 0.42098925 0.7921905  0.48683563\n",
      "  0.         0.08368859 0.11427105 0.         0.         0.\n",
      "  0.         0.52497566 0.13239995 0.        ]]\n",
      "Hi!\n",
      "[[0.11842715 0.67433125 0.4307167  0.         0.         0.3339702\n",
      "  0.         0.         0.14888814 0.         0.29822665 0.\n",
      "  0.66920555 0.1997853  0.         0.07256553 0.         0.16806652\n",
      "  0.         0.54802585 0.26731622 0.         0.         0.02669689\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29638168 0.27886102 0.         0.         0.         0.\n",
      "  0.         0.         0.2160868  0.15307392 0.         0.\n",
      "  0.         0.         0.23676531 0.18323345 0.         0.41003132\n",
      "  0.30126676 0.3327092  0.1136232  0.24779268 0.14253198 0.57884836\n",
      "  0.03984788 0.         0.14508605 0.         0.13652788 0.\n",
      "  0.09526388 0.08281098 0.0668717  0.14434095]]\n",
      "Hi!\n",
      "[[0.6639864  0.249563   0.1216478  0.39247286 0.         0.613448\n",
      "  1.0108155  1.3958962  0.14727059 0.         0.2548168  0.\n",
      "  0.9924453  0.7691549  0.         0.31631532 0.         0.50384676\n",
      "  0.11911812 0.32356703 0.33086187 0.12943101 0.         0.14539158\n",
      "  0.06623493 0.         0.         0.82038647 0.         0.\n",
      "  1.3811495  0.85431117 0.11322577 0.         0.7765772  0.\n",
      "  0.3335881  1.0309905  0.35553968 0.10630661 0.18863356 0.\n",
      "  0.         0.35743755 1.4060965  1.1968246  0.         0.4753235\n",
      "  0.         0.79875576 0.36628458 0.61808026 0.7602183  0.97970456\n",
      "  0.         0.01838284 0.5195712  0.         0.         0.\n",
      "  0.         0.3155445  1.0103886  0.        ]]\n",
      "Hi!\n",
      "[[0.21187295 0.         0.         0.19765092 0.         0.36702046\n",
      "  1.7475222  1.5691931  0.39713833 0.         0.183001   0.\n",
      "  0.13442598 0.20598565 0.         0.5185337  0.         0.7299195\n",
      "  0.         0.         0.28040323 0.23264955 0.         0.\n",
      "  0.31635824 0.         0.         0.41617048 0.         0.\n",
      "  0.963168   0.21728462 0.08630214 0.         0.83306307 0.\n",
      "  0.24966715 1.3373346  0.         0.36025006 0.21381241 0.\n",
      "  0.         0.7651934  0.7494652  1.0462372  0.         0.10290898\n",
      "  0.         0.8388436  0.46647772 0.3973875  0.36660123 0.38577908\n",
      "  0.         0.         0.2710612  0.         0.         0.\n",
      "  0.         0.8614463  0.68779373 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.16701244 0.17021644 0.         0.         0.06691562\n",
      "  0.         0.05129614 0.04661467 0.05139792 0.09334496 0.\n",
      "  0.1329808  0.0620578  0.         0.0535424  0.         0.0638845\n",
      "  0.         0.08330169 0.09779713 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10361077 0.06818844 0.         0.         0.\n",
      "  0.         0.         0.08582774 0.06082475 0.         0.\n",
      "  0.         0.         0.10593905 0.17756179 0.         0.05507748\n",
      "  0.1021476  0.08532274 0.         0.14059424 0.02812739 0.28538892\n",
      "  0.         0.03521726 0.04417387 0.         0.0071845  0.\n",
      "  0.08647878 0.16273391 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0334167  0.10796973 1.506459   0.06703093 0.         1.2242544\n",
      "  0.40970823 0.5944149  0.52417153 0.11666061 0.50664705 0.\n",
      "  0.         0.         0.         0.14332199 0.5438106  0.60429883\n",
      "  0.         0.37290287 1.0042529  0.09634443 0.         0.57692546\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18807971 0.22498578 0.         0.         0.\n",
      "  0.         0.31588376 0.         1.0321821  0.         0.\n",
      "  0.         1.0360678  0.         0.52727395 0.         0.03809977\n",
      "  0.33921573 1.3058561  0.1565976  0.28093305 0.9208835  0.05355191\n",
      "  0.         1.4372741  0.         0.04328442 0.         0.\n",
      "  0.5366304  0.85165673 0.41736484 0.20685604]]\n",
      "Hi!\n",
      "[[0.56625307 0.3829409  0.9984089  0.         0.         0.9020472\n",
      "  0.08775789 0.2819004  0.18026447 0.12572242 0.4176226  0.\n",
      "  0.         0.         0.         0.02514735 0.05713618 0.49028268\n",
      "  0.         0.6866287  0.63100636 0.         0.         0.21422844\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02064714 0.3682134  0.05961833 0.         0.         0.\n",
      "  0.         0.15475914 0.         0.5156129  0.         0.\n",
      "  0.         0.14833756 0.19409734 0.56809086 0.         0.2780097\n",
      "  0.4388752  0.8170827  0.02491137 0.3874777  0.59641874 0.38116193\n",
      "  0.         0.8377566  0.         0.         0.09278294 0.\n",
      "  0.30699676 0.46707505 0.29114515 0.13661738]]\n",
      "Hi!\n",
      "[[0.41021848 0.         1.1541619  0.         0.         0.6756282\n",
      "  1.1364732  0.9063156  1.3333251  0.         0.49524462 0.\n",
      "  0.12468887 0.         0.         0.8862782  0.39187744 0.9853504\n",
      "  0.23753425 0.         1.0750996  0.42787886 0.         0.14845607\n",
      "  0.30847055 0.         0.         0.02585275 0.         0.\n",
      "  0.17054293 0.         0.         0.         0.46293426 0.\n",
      "  0.48833314 1.3326566  0.         0.6280242  0.11665572 0.\n",
      "  0.         1.5050467  0.         0.10484302 0.         0.72423667\n",
      "  0.         0.7827045  0.7773057  0.08674231 0.         0.08021498\n",
      "  0.         0.         0.10167579 0.5876438  0.         0.\n",
      "  0.         1.1969577  1.1784966  0.7013166 ]]\n",
      "Hi!\n",
      "[[0.39679673 0.         0.52788836 0.19313541 0.         0.5492364\n",
      "  1.6342558  1.3905035  0.64530855 0.         0.3218485  0.\n",
      "  0.         0.         0.         0.53698957 0.         0.82622975\n",
      "  0.         0.         0.6395333  0.13961835 0.         0.01087276\n",
      "  0.12762561 0.         0.         0.12494155 0.         0.\n",
      "  0.5634452  0.12550057 0.07301435 0.         0.60388464 0.\n",
      "  0.         1.2501131  0.         0.5328551  0.19433323 0.\n",
      "  0.         1.0720025  0.31244004 0.75834996 0.         0.06242254\n",
      "  0.         0.821835   0.3942054  0.25017166 0.37585956 0.00850724\n",
      "  0.         0.         0.07436095 0.         0.         0.\n",
      "  0.         1.1112329  0.9229824  0.        ]]\n",
      "Hi!\n",
      "[[0.37985057 0.7895686  1.3105516  0.         0.         0.61970705\n",
      "  0.20912722 0.29756978 1.3871632  0.         0.69243485 0.\n",
      "  1.5520861  0.         0.         0.98464525 0.01646728 0.9185516\n",
      "  1.1217955  0.18740422 1.1561096  0.18626896 0.         0.\n",
      "  0.48168328 0.         0.         0.24330096 0.         0.\n",
      "  0.6402023  0.4902034  0.         0.         0.5107475  0.\n",
      "  0.67238253 1.2630347  0.         0.8345835  0.11220516 0.\n",
      "  0.         0.5127692  0.39685088 0.         0.         1.3444343\n",
      "  0.         0.9392649  1.1395055  0.28551495 0.17308228 0.69993883\n",
      "  0.         0.         0.2735983  0.25093216 0.05753747 0.\n",
      "  0.         0.77245945 1.3061817  1.116028  ]]\n",
      "Hi!\n",
      "[[0.5646563  0.23466527 0.8395038  0.         0.         0.8041457\n",
      "  0.47850344 0.64590305 0.38749805 0.10433709 0.3845164  0.\n",
      "  0.03169497 0.         0.         0.14700377 0.         0.60866374\n",
      "  0.         0.34071052 0.69296956 0.         0.         0.24766873\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29552522 0.34112954 0.03493392 0.         0.01718526 0.\n",
      "  0.         0.49731582 0.         0.57954043 0.         0.\n",
      "  0.         0.3189188  0.2782716  0.7336154  0.         0.15118347\n",
      "  0.0802108  0.92728543 0.13489407 0.35334757 0.6743047  0.29004622\n",
      "  0.         0.4985848  0.         0.         0.         0.\n",
      "  0.05302111 0.75697154 0.4597414  0.12416552]]\n",
      "Hi!\n",
      "[[0.60958683 0.10669021 0.00440127 0.48481327 0.         0.62981373\n",
      "  1.1674287  1.337286   0.         0.         0.01067448 0.\n",
      "  0.15853697 0.6662676  0.         0.07955918 0.         0.26065135\n",
      "  0.         0.5707489  0.0570078  0.08044932 0.         0.0773276\n",
      "  0.         0.         0.         0.47927165 0.         0.\n",
      "  1.1191846  0.74367833 0.50341415 0.         0.46624395 0.\n",
      "  0.         0.5762199  0.3224588  0.24775204 0.08774237 0.\n",
      "  0.         0.30825537 1.3708655  1.3502545  0.         0.14632149\n",
      "  0.38222378 0.9018374  0.         0.7069763  0.76207966 1.1102967\n",
      "  0.         0.65251344 0.42815223 0.         0.         0.\n",
      "  0.         0.31132165 0.48803082 0.        ]]\n",
      "Hi!\n",
      "[[0.28844997 1.087165   0.6592107  0.         0.         0.52685124\n",
      "  0.0972923  0.3975735  0.6125005  0.         0.4619287  0.\n",
      "  1.64329    0.41213143 0.         0.42675376 0.         0.54030406\n",
      "  0.47489017 0.64324385 0.59223557 0.         0.         0.06476185\n",
      "  0.00613594 0.         0.         0.25774297 0.         0.\n",
      "  0.899184   0.66868615 0.         0.         0.29304567 0.\n",
      "  0.0746295  0.54617596 0.16802342 0.34309408 0.         0.\n",
      "  0.         0.04521258 0.61103237 0.49248004 0.         0.8012462\n",
      "  0.         0.73515517 0.7498883  0.32503322 0.6868856  0.8419171\n",
      "  0.         0.         0.26205748 0.         0.06218515 0.\n",
      "  0.         0.44714683 0.5622761  0.43899268]]\n",
      "Hi!\n",
      "[[0.5402953  0.         0.05488649 0.4503506  0.         0.71977514\n",
      "  1.4927317  1.8592242  0.29101962 0.         0.14918524 0.\n",
      "  0.8569873  0.53735906 0.         0.3712615  0.         0.56627756\n",
      "  0.1323455  0.         0.39888212 0.26952636 0.         0.\n",
      "  0.20895797 0.         0.         0.79390115 0.         0.\n",
      "  1.4475873  0.76901656 0.19466566 0.         0.807144   0.\n",
      "  0.27273786 1.311157   0.15714155 0.20421429 0.2800219  0.\n",
      "  0.         0.47410977 1.2919626  1.3333629  0.         0.4386815\n",
      "  0.         0.8418964  0.46472678 0.702094   0.7466005  0.95425975\n",
      "  0.         0.06127645 0.54256135 0.         0.         0.\n",
      "  0.         0.5072258  1.2533507  0.        ]]\n",
      "Hi!\n",
      "[[0.85620606 0.         1.6959331  0.         0.         0.81241566\n",
      "  0.6097354  0.7327876  1.4688104  0.         0.6988212  0.\n",
      "  0.05671849 0.         0.         0.85275054 0.76770264 0.9558237\n",
      "  0.         0.         1.4732108  0.45350027 0.         0.7810147\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07840074 0.05353514 0.         0.01357538 0.\n",
      "  0.05350004 1.0753006  0.         0.93821794 0.1928476  0.\n",
      "  0.         1.5376744  0.         0.0547463  0.         0.42609006\n",
      "  0.         0.8566451  0.7043924  0.05470276 0.41681653 0.\n",
      "  0.         0.43082613 0.         0.75460446 0.         0.\n",
      "  0.         1.1639761  1.2922611  0.8094895 ]]\n",
      "Hi!\n",
      "[[0.90317136 0.         1.6203791  0.         0.         0.8149301\n",
      "  1.2740266  1.3181471  1.679712   0.         0.6645027  0.\n",
      "  0.         0.         0.         1.0597068  0.79225653 0.9832959\n",
      "  0.09015013 0.         1.4662662  0.5953395  0.         0.729689\n",
      "  0.         0.         0.         0.05467123 0.         0.\n",
      "  0.09256038 0.13397034 0.08130831 0.         0.2043059  0.\n",
      "  0.2989791  1.3716397  0.         0.8837566  0.32248932 0.\n",
      "  0.         2.076102   0.         0.15053543 0.         0.41683307\n",
      "  0.         0.78147006 0.8858744  0.12005947 0.4572477  0.\n",
      "  0.         0.32167763 0.         0.82180977 0.         0.\n",
      "  0.         1.3961978  1.6057587  0.69676816]]\n",
      "Hi!\n",
      "[[0.6938883  0.35304856 0.33630303 0.35478908 0.         0.7646695\n",
      "  0.70165557 1.1712509  0.11955687 0.         0.3004357  0.\n",
      "  1.0641106  0.68801737 0.         0.20442389 0.         0.4566515\n",
      "  0.24152249 0.4576308  0.41607347 0.04032435 0.         0.14183202\n",
      "  0.         0.         0.         0.8067466  0.         0.\n",
      "  1.2504512  0.98387814 0.06103476 0.         0.6171391  0.\n",
      "  0.39349788 0.9090096  0.4847313  0.16686395 0.12587984 0.\n",
      "  0.         0.34179866 1.4227624  1.1041548  0.         0.6906374\n",
      "  0.09674019 0.70472497 0.2973835  0.65958816 0.66860956 1.1099313\n",
      "  0.         0.15996166 0.5424737  0.         0.         0.\n",
      "  0.         0.20734836 1.115999   0.        ]]\n",
      "Hi!\n",
      "[[0.122116   0.21440025 0.12075073 0.01602763 0.         0.09226426\n",
      "  0.         0.1134758  0.         0.0213983  0.10429861 0.\n",
      "  0.17621763 0.2506915  0.         0.         0.         0.03342658\n",
      "  0.         0.14999403 0.03736768 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09284834 0.22368908 0.18917161 0.         0.         0.\n",
      "  0.         0.         0.28345558 0.06981149 0.         0.\n",
      "  0.         0.         0.28473485 0.29041347 0.         0.05041264\n",
      "  0.23523176 0.09641873 0.         0.25117642 0.10630389 0.48696527\n",
      "  0.         0.15305458 0.09060208 0.         0.         0.\n",
      "  0.09959947 0.04131339 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.48123127 0.21566632 1.3212945  0.         0.         0.74496275\n",
      "  0.40884    0.5709317  1.2476676  0.         0.6603939  0.\n",
      "  0.7501533  0.         0.         0.77286994 0.21172848 0.81687313\n",
      "  0.4564697  0.         1.1764636  0.17430912 0.         0.32886323\n",
      "  0.09311657 0.         0.         0.069266   0.         0.\n",
      "  0.3807701  0.3407467  0.         0.         0.2467631  0.\n",
      "  0.3406633  1.0925512  0.         0.7220047  0.13627845 0.\n",
      "  0.         0.85626817 0.07429571 0.14750987 0.         0.74618405\n",
      "  0.         0.7442001  0.7676631  0.20092602 0.3537039  0.19722019\n",
      "  0.         0.         0.05474389 0.37590078 0.         0.\n",
      "  0.         0.86819935 1.3338674  0.7863196 ]]\n",
      "Hi!\n",
      "[[0.10286959 0.         0.         0.25885645 0.         0.27380472\n",
      "  1.9013978  1.651341   0.23248038 0.         0.08516825 0.\n",
      "  0.         0.24423312 0.         0.4029195  0.         0.60330683\n",
      "  0.         0.         0.12062284 0.23989047 0.         0.\n",
      "  0.24615306 0.         0.         0.43261525 0.         0.\n",
      "  0.8886433  0.16051732 0.32712543 0.         0.76642513 0.\n",
      "  0.22897068 1.2106979  0.         0.42718387 0.24385713 0.\n",
      "  0.         0.7774277  0.7187985  1.0459939  0.         0.\n",
      "  0.         0.8089725  0.3562165  0.39393377 0.3277457  0.35313463\n",
      "  0.         0.         0.27636993 0.         0.         0.\n",
      "  0.         0.84841686 0.46929315 0.        ]]\n",
      "Hi!\n",
      "[[8.81023467e-01 5.33757135e-02 1.86309874e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.18810427e-01 3.40196669e-01 3.57410640e-01\n",
      "  1.45296979e+00 0.00000000e+00 7.70607829e-01 0.00000000e+00\n",
      "  2.54214555e-01 0.00000000e+00 0.00000000e+00 8.28847349e-01\n",
      "  8.10192764e-01 9.42041576e-01 4.48098518e-02 0.00000000e+00\n",
      "  1.50056887e+00 3.85631591e-01 0.00000000e+00 6.88297570e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.08413824e-01\n",
      "  3.51338871e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.86580166e-01 9.25119877e-01 0.00000000e+00 1.04409373e+00\n",
      "  1.16772220e-01 0.00000000e+00 0.00000000e+00 1.32199466e+00\n",
      "  0.00000000e+00 1.03378128e-02 0.00000000e+00 7.05547750e-01\n",
      "  0.00000000e+00 9.21376824e-01 7.90803134e-01 1.07923105e-01\n",
      "  4.15514648e-01 4.87292605e-03 0.00000000e+00 5.07761955e-01\n",
      "  0.00000000e+00 8.39612663e-01 1.28963961e-06 0.00000000e+00\n",
      "  0.00000000e+00 1.03180075e+00 1.16876769e+00 1.00454068e+00]]\n",
      "Hi!\n",
      "[[0.35191008 0.         0.98841983 0.         0.         0.7239464\n",
      "  1.0896083  1.2217649  1.2783551  0.         0.51676345 0.\n",
      "  0.512301   0.         0.         0.8712808  0.07388579 0.8086539\n",
      "  0.4335382  0.         1.047128   0.16817361 0.         0.31677112\n",
      "  0.1313495  0.         0.         0.2694787  0.         0.\n",
      "  0.5593622  0.25347665 0.         0.         0.49270868 0.\n",
      "  0.25060406 1.3752319  0.         0.5213397  0.24013034 0.\n",
      "  0.         1.2481014  0.09373788 0.42266193 0.         0.5110213\n",
      "  0.         0.68821347 0.7858542  0.2926085  0.42863584 0.02495171\n",
      "  0.         0.         0.13092817 0.33038095 0.         0.\n",
      "  0.         1.0123003  1.5083386  0.5198156 ]]\n",
      "Hi!\n",
      "[[0.02206347 0.11381784 0.07867309 0.         0.         0.\n",
      "  0.07239027 0.17997774 0.0027911  0.00399364 0.03247345 0.\n",
      "  0.18755025 0.17556398 0.         0.00609566 0.         0.02804594\n",
      "  0.         0.07730344 0.09312888 0.         0.         0.\n",
      "  0.         0.         0.         0.03585424 0.         0.\n",
      "  0.0929031  0.1773093  0.24368328 0.         0.         0.\n",
      "  0.         0.         0.24978077 0.         0.         0.\n",
      "  0.         0.         0.22506523 0.25264633 0.         0.\n",
      "  0.12847012 0.08552039 0.         0.17300606 0.03237662 0.3774466\n",
      "  0.         0.03513806 0.13238177 0.         0.         0.\n",
      "  0.07376402 0.10249452 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.16279791 0.         0.64844155 0.         0.         0.6370864\n",
      "  1.3325846  1.478561   1.2058283  0.         0.4384927  0.\n",
      "  0.7471619  0.         0.         0.91021436 0.         0.7953163\n",
      "  0.56386584 0.         0.858308   0.12160803 0.         0.\n",
      "  0.2872755  0.         0.         0.51605207 0.         0.\n",
      "  0.94057417 0.28924355 0.         0.         0.75041413 0.\n",
      "  0.41551894 1.5194157  0.         0.34435073 0.2649807  0.\n",
      "  0.         1.1744431  0.40079677 0.6073176  0.         0.48299316\n",
      "  0.         0.6452011  0.8716875  0.3922585  0.46834058 0.10131813\n",
      "  0.         0.         0.33187678 0.11509758 0.         0.\n",
      "  0.         0.915577   1.5265965  0.3906116 ]]\n",
      "Hi!\n",
      "[[0.0060276  0.23404408 0.3360765  0.         0.         0.22040224\n",
      "  0.         0.         0.0889215  0.07997499 0.21539895 0.\n",
      "  0.04747529 0.         0.         0.05335797 0.         0.07089467\n",
      "  0.         0.35383713 0.15980616 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1100215  0.04013467 0.         0.         0.\n",
      "  0.         0.         0.05068646 0.15212539 0.         0.\n",
      "  0.         0.         0.04608837 0.22471435 0.         0.15400158\n",
      "  0.23590624 0.141745   0.         0.19414802 0.09935881 0.31405902\n",
      "  0.         0.14142567 0.         0.         0.0921828  0.\n",
      "  0.11746521 0.07680574 0.         0.06024749]]\n",
      "Hi!\n",
      "[[0.61821127 0.3962734  1.2716492  0.         0.         0.9477855\n",
      "  0.132782   0.44602075 0.53209084 0.         0.54622126 0.\n",
      "  0.57439876 0.         0.         0.31699622 0.11576517 0.5821085\n",
      "  0.         0.47349325 0.9644084  0.         0.         0.19615549\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32770395 0.60838497 0.         0.         0.         0.\n",
      "  0.00247867 0.6723963  0.         0.6452855  0.         0.\n",
      "  0.         0.2805653  0.39441708 0.4410136  0.         0.6794735\n",
      "  0.2576474  0.71751124 0.34919783 0.40187478 0.5382638  0.6347989\n",
      "  0.         0.6426302  0.         0.         0.03111043 0.\n",
      "  0.         0.49801695 1.0291826  0.3041219 ]]\n",
      "Hi!\n",
      "[[0.         0.06850818 0.08881306 0.         0.         0.10585535\n",
      "  0.02879929 0.16668154 0.00089537 0.13109168 0.13115452 0.\n",
      "  0.         0.02686008 0.         0.02134212 0.         0.03479947\n",
      "  0.         0.15399456 0.06132924 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1381081  0.         0.         0.\n",
      "  0.         0.         0.08186914 0.15754665 0.         0.\n",
      "  0.         0.         0.07881793 0.32721892 0.         0.0474528\n",
      "  0.10518112 0.07753576 0.         0.17264004 0.02701302 0.18590261\n",
      "  0.         0.12098341 0.         0.         0.00524866 0.\n",
      "  0.05384987 0.10090472 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.1879243  0.         0.54711735 0.2213005  0.         0.73608017\n",
      "  1.761309   1.8629317  1.0236056  0.         0.35217506 0.\n",
      "  0.47077456 0.         0.         0.8108197  0.         0.7723507\n",
      "  0.25381443 0.         0.7983686  0.2422433  0.         0.\n",
      "  0.1918218  0.         0.         0.61916816 0.         0.\n",
      "  1.0592792  0.33606654 0.00456968 0.         0.82947195 0.\n",
      "  0.20692478 1.5501062  0.         0.35770684 0.35863915 0.\n",
      "  0.         1.2667035  0.5434827  0.8662405  0.         0.21617934\n",
      "  0.         0.76713574 0.66576236 0.49557152 0.6886524  0.04129519\n",
      "  0.         0.         0.3642929  0.         0.         0.\n",
      "  0.         0.9728674  1.6693462  0.06238626]]\n",
      "Hi!\n",
      "[[0.43130353 0.03576219 0.43709058 0.11158597 0.         0.69742554\n",
      "  0.88905334 0.848061   0.16889621 0.06530568 0.26490834 0.\n",
      "  0.         0.         0.         0.12261416 0.         0.5383936\n",
      "  0.         0.26983958 0.42040133 0.01939647 0.         0.1084007\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20363511 0.11966428 0.1565743  0.         0.13968578 0.\n",
      "  0.         0.4501021  0.         0.643743   0.         0.\n",
      "  0.         0.62949437 0.2132466  0.7110778  0.         0.\n",
      "  0.07120255 0.94768053 0.06840913 0.2861358  0.47059265 0.08008599\n",
      "  0.         0.44524455 0.         0.         0.         0.\n",
      "  0.15731482 0.82684565 0.16834801 0.        ]]\n",
      "Hi!\n",
      "[[0.003881   0.10493148 0.14135358 0.         0.         0.10679458\n",
      "  0.         0.10878881 0.01248908 0.0470774  0.10507236 0.\n",
      "  0.04790967 0.14266288 0.         0.         0.         0.\n",
      "  0.         0.10444495 0.05576165 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0019854  0.13209523 0.13021882 0.         0.         0.\n",
      "  0.         0.         0.14750326 0.09336541 0.         0.\n",
      "  0.         0.         0.16219276 0.28996184 0.         0.08434088\n",
      "  0.135875   0.08402831 0.         0.17007335 0.03840117 0.31122115\n",
      "  0.         0.13670939 0.05219654 0.         0.         0.\n",
      "  0.0177565  0.03748267 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0778792  0.         1.8868308  0.         0.         0.8598731\n",
      "  1.0876614  1.1651437  1.9174068  0.         0.73337924 0.\n",
      "  0.         0.         0.         1.12977    1.0327137  1.0255373\n",
      "  0.04236937 0.         1.6480228  0.7506749  0.         0.93448126\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04593744 0.05412429 0.         0.         0.\n",
      "  0.23572789 1.278083   0.         1.0950142  0.33422896 0.\n",
      "  0.         2.2686138  0.         0.         0.         0.42590556\n",
      "  0.         0.90252554 1.0254635  0.         0.46178403 0.\n",
      "  0.         0.43764538 0.         1.0693845  0.         0.\n",
      "  0.         1.4636631  1.5375599  0.9397306 ]]\n",
      "Hi!\n",
      "[[0.63905287 0.8541096  0.6960675  0.         0.         0.36284748\n",
      "  0.2569946  0.86375743 1.2454156  0.         0.56413853 0.\n",
      "  2.201643   0.3699917  0.         0.9326773  0.         0.7414294\n",
      "  1.5223379  0.09754346 0.9201759  0.10573781 0.         0.12825698\n",
      "  0.3554925  0.         0.         0.7983855  0.         0.\n",
      "  1.2516313  0.81401885 0.         0.         0.68342173 0.\n",
      "  0.9400035  1.2336886  0.21150248 0.38187352 0.12269944 0.\n",
      "  0.         0.5243798  0.97759485 0.2830836  0.         1.1994431\n",
      "  0.         0.88405335 1.2455626  0.375294   0.4730548  0.9781808\n",
      "  0.         0.         0.5450362  0.         0.         0.\n",
      "  0.         0.43799743 1.555556   0.6879902 ]]\n",
      "Hi!\n",
      "[[0.05871674 0.23814869 0.38189453 0.         0.         0.22898678\n",
      "  0.         0.         0.22834481 0.10906844 0.22699685 0.\n",
      "  0.17528947 0.         0.         0.10644941 0.         0.04619811\n",
      "  0.         0.30484653 0.268648   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00353703 0.02564085 0.         0.         0.\n",
      "  0.         0.         0.03487731 0.1576135  0.         0.\n",
      "  0.         0.         0.         0.15393648 0.         0.1961842\n",
      "  0.16123775 0.12826306 0.06286294 0.19090846 0.14653282 0.2926919\n",
      "  0.         0.01027295 0.         0.         0.10183598 0.\n",
      "  0.05720555 0.09844211 0.         0.12387341]]\n",
      "Hi!\n",
      "[[0.         0.05521058 0.1811322  0.         0.         0.2114029\n",
      "  0.11905916 0.1898424  0.030678   0.19996007 0.15928598 0.\n",
      "  0.         0.         0.         0.06761009 0.         0.08385087\n",
      "  0.         0.23280245 0.1293249  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09453142 0.         0.         0.\n",
      "  0.         0.01500244 0.         0.21534468 0.         0.\n",
      "  0.         0.         0.02201798 0.39889705 0.         0.09589325\n",
      "  0.15246665 0.2155836  0.         0.20710425 0.08882187 0.19392681\n",
      "  0.         0.21620996 0.         0.         0.01128671 0.\n",
      "  0.10114487 0.2297518  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.08218335 0.2053851  0.         0.         0.22483404\n",
      "  0.10400318 0.15528111 0.14810906 0.0761421  0.15702997 0.\n",
      "  0.         0.         0.         0.08796026 0.         0.05204287\n",
      "  0.         0.14979404 0.15031466 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06335012 0.1176369  0.         0.         0.\n",
      "  0.         0.         0.03724562 0.13656439 0.         0.\n",
      "  0.         0.         0.08886594 0.31315127 0.         0.14079785\n",
      "  0.07339233 0.22447735 0.06152632 0.19577639 0.         0.21154638\n",
      "  0.         0.2687231  0.         0.         0.         0.\n",
      "  0.06198387 0.10856007 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.42053914 0.         0.4303122  0.22611539 0.         0.5220656\n",
      "  1.8783892  1.6539116  0.7334415  0.         0.312704   0.\n",
      "  0.         0.         0.         0.617829   0.         0.8250319\n",
      "  0.         0.         0.627053   0.20663796 0.         0.01474231\n",
      "  0.13323657 0.         0.         0.20325564 0.         0.\n",
      "  0.63539535 0.09726767 0.11478329 0.         0.6715065  0.\n",
      "  0.00349324 1.3407564  0.         0.60401434 0.27029872 0.\n",
      "  0.         1.3300813  0.27825034 0.8025466  0.         0.\n",
      "  0.         0.9191793  0.46196023 0.30073857 0.39462593 0.\n",
      "  0.         0.         0.0591586  0.         0.         0.\n",
      "  0.         1.2022554  0.9254892  0.        ]]\n",
      "Hi!\n",
      "[[0.00446468 0.19620804 0.24207959 0.         0.         0.18016873\n",
      "  0.         0.0226301  0.07315797 0.07701554 0.18498582 0.\n",
      "  0.06557079 0.04372584 0.         0.03022257 0.         0.03283333\n",
      "  0.         0.25581288 0.14542729 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07402531 0.0553733  0.         0.         0.\n",
      "  0.         0.         0.07909936 0.11269901 0.         0.\n",
      "  0.         0.         0.08303121 0.21573767 0.         0.1185298\n",
      "  0.18074894 0.10561992 0.         0.18428841 0.02798808 0.25297457\n",
      "  0.         0.10241706 0.00195766 0.         0.0343471  0.\n",
      "  0.11383931 0.06714718 0.         0.01431162]]\n",
      "Hi!\n",
      "[[7.14091063e-01 0.00000000e+00 9.40617979e-01 1.22669704e-01\n",
      "  0.00000000e+00 8.42801034e-01 8.91016066e-01 9.14286554e-01\n",
      "  5.00673652e-01 5.87241203e-02 4.12917018e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.21183479e-01\n",
      "  2.98375905e-01 6.93701386e-01 0.00000000e+00 6.53936267e-02\n",
      "  7.73224473e-01 1.01163656e-01 0.00000000e+00 3.61234277e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.56877442e-02 1.30718365e-01\n",
      "  1.90472335e-01 0.00000000e+00 4.91633117e-02 0.00000000e+00\n",
      "  0.00000000e+00 5.89948297e-01 0.00000000e+00 7.77265847e-01\n",
      "  5.73185214e-04 0.00000000e+00 0.00000000e+00 9.90649760e-01\n",
      "  0.00000000e+00 6.04064643e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.03771913e+00 2.09282622e-01 2.41559342e-01\n",
      "  5.82178175e-01 0.00000000e+00 0.00000000e+00 7.33623624e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.01690739e-01 9.27721024e-01 5.27432919e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.15627591 0.20336145 0.33127564 0.         0.         0.15203959\n",
      "  0.3930252  0.27081934 0.2848063  0.         0.12297264 0.\n",
      "  0.2135025  0.         0.         0.28317082 0.06728359 0.38332385\n",
      "  0.         0.15806703 0.22821508 0.         0.         0.\n",
      "  0.08088081 0.         0.         0.         0.         0.\n",
      "  0.15273477 0.12375642 0.0034998  0.         0.11144958 0.\n",
      "  0.02364889 0.5158515  0.         0.1831723  0.         0.\n",
      "  0.         0.1792811  0.10719817 0.38204083 0.         0.36086604\n",
      "  0.03235565 0.37572706 0.24924074 0.21099514 0.         0.41909134\n",
      "  0.         0.04546455 0.05809715 0.         0.         0.\n",
      "  0.         0.39906153 0.25911784 0.08239025]]\n",
      "Hi!\n",
      "[[0.04567999 0.10985331 0.         0.         0.         0.05882974\n",
      "  0.11734119 0.27799124 0.         0.04243839 0.06237723 0.\n",
      "  0.11844108 0.2697034  0.         0.00368908 0.         0.0530601\n",
      "  0.         0.08604744 0.06079752 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18944123 0.18411244 0.23040774 0.         0.         0.\n",
      "  0.         0.         0.27083388 0.05726961 0.         0.\n",
      "  0.         0.00982352 0.28921455 0.39643663 0.         0.00651587\n",
      "  0.12791798 0.18878004 0.         0.1922872  0.05137047 0.46560472\n",
      "  0.         0.07353488 0.10342815 0.         0.         0.\n",
      "  0.09372123 0.144764   0.         0.        ]]\n",
      "Hi!\n",
      "[[0.50328004 1.100026   1.5984377  0.         0.         1.0975177\n",
      "  0.         0.         0.6126865  0.         0.72126067 0.\n",
      "  1.1989748  0.         0.         0.19698979 0.07459047 0.49988002\n",
      "  0.         0.97911626 1.0227133  0.         0.         0.23408823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37031433 0.6534333  0.         0.         0.         0.\n",
      "  0.         0.2183039  0.14696449 0.6795533  0.         0.\n",
      "  0.         0.         0.40967575 0.20692554 0.         0.87943345\n",
      "  0.5614152  0.761141   0.3819233  0.57647604 0.84718466 0.9259692\n",
      "  0.         0.68337405 0.         0.         0.1593025  0.\n",
      "  0.         0.24188565 0.80637175 0.7514696 ]]\n",
      "Hi!\n",
      "[[0.04118208 0.05204502 0.46507615 0.         0.         0.32328653\n",
      "  0.10660873 0.06204842 0.13798067 0.24661252 0.32984522 0.\n",
      "  0.         0.         0.         0.11289465 0.         0.00249859\n",
      "  0.         0.32179534 0.29312813 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09411481 0.         0.         0.\n",
      "  0.         0.17947787 0.08954646 0.22100313 0.         0.\n",
      "  0.         0.         0.10706148 0.38220596 0.         0.17037462\n",
      "  0.16327164 0.16499236 0.02555431 0.25236467 0.180622   0.22412534\n",
      "  0.         0.3314617  0.         0.         0.06678905 0.\n",
      "  0.         0.13250725 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.36796176 0.85093886 1.494211   0.         0.         0.75110334\n",
      "  0.11288098 0.04210852 1.287666   0.         0.74576133 0.\n",
      "  1.3423473  0.         0.         0.75403136 0.20640707 0.86865944\n",
      "  0.6641589  0.32799503 1.2542855  0.12469365 0.         0.24250972\n",
      "  0.15401798 0.         0.         0.         0.         0.\n",
      "  0.33707017 0.47147807 0.         0.         0.10809004 0.\n",
      "  0.27117154 0.8121291  0.         0.8778617  0.00443207 0.\n",
      "  0.         0.37241247 0.1227679  0.         0.         1.0610976\n",
      "  0.         0.9169769  0.89076227 0.2954638  0.45227012 0.5169516\n",
      "  0.         0.         0.         0.27099505 0.10195317 0.\n",
      "  0.         0.7691837  1.0278445  1.1527479 ]]\n",
      "Hi!\n",
      "[[0.05232022 0.1219665  0.03407394 0.         0.         0.01773393\n",
      "  0.07159194 0.16785753 0.04772275 0.11467743 0.14976057 0.\n",
      "  0.01351387 0.10880606 0.         0.08131827 0.         0.05693583\n",
      "  0.         0.16481204 0.10318229 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0365376  0.13478228 0.         0.         0.\n",
      "  0.         0.         0.09020948 0.09957605 0.         0.\n",
      "  0.         0.         0.07573167 0.2627887  0.         0.\n",
      "  0.05951798 0.13020033 0.0127602  0.11160362 0.01048896 0.26967108\n",
      "  0.         0.04976361 0.04801559 0.         0.         0.\n",
      "  0.09094024 0.18893602 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.08243722 0.32450265 0.22397028 0.         0.         0.21274468\n",
      "  0.         0.08961248 0.         0.02254232 0.15332635 0.\n",
      "  0.15935904 0.20519249 0.         0.         0.         0.10639202\n",
      "  0.         0.31497782 0.11438432 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10102679 0.23678966 0.10224885 0.         0.         0.\n",
      "  0.         0.         0.1695565  0.0806955  0.         0.\n",
      "  0.         0.         0.25356793 0.3274969  0.         0.14938131\n",
      "  0.26411343 0.21809058 0.         0.25334835 0.0985516  0.45135477\n",
      "  0.         0.15182777 0.06229942 0.         0.         0.\n",
      "  0.10567395 0.1306881  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.37397805 0.27417096 0.41908753 0.         0.         0.48136708\n",
      "  0.95795715 1.3108679  1.1999416  0.         0.43274915 0.\n",
      "  1.7064282  0.3695808  0.         1.0408307  0.         0.729774\n",
      "  1.2530277  0.         0.77030665 0.18989424 0.         0.\n",
      "  0.47270626 0.         0.         0.7745922  0.         0.\n",
      "  1.2472045  0.56463087 0.         0.         0.83527756 0.\n",
      "  0.7991129  1.519906   0.         0.29040188 0.23046774 0.\n",
      "  0.         0.60548514 0.9158895  0.5250155  0.         0.9674847\n",
      "  0.         0.827882   1.1812408  0.38224328 0.39499432 0.64753705\n",
      "  0.         0.         0.52466106 0.         0.         0.\n",
      "  0.         0.579052   1.5198507  0.5325265 ]]\n",
      "Hi!\n",
      "[[0.7188925  0.         0.7347444  0.47835734 0.         0.7688191\n",
      "  2.063539   1.9464402  0.8217606  0.         0.33054498 0.\n",
      "  0.         0.         0.         0.49887666 0.32862148 0.87253237\n",
      "  0.         0.         0.8055296  0.33701098 0.         0.38119927\n",
      "  0.         0.         0.         0.05151688 0.         0.\n",
      "  0.36734894 0.0525388  0.27476984 0.         0.46305668 0.\n",
      "  0.         1.2054343  0.         0.88388056 0.33637452 0.\n",
      "  0.         1.739532   0.00387236 0.8133414  0.         0.\n",
      "  0.         1.0197933  0.27422726 0.28502035 0.8188274  0.\n",
      "  0.         0.5614237  0.         0.         0.         0.\n",
      "  0.         1.3564132  1.1776217  0.        ]]\n",
      "Hi!\n",
      "[[0.03732779 0.02375937 0.01599906 0.02017474 0.         0.03919454\n",
      "  0.18024018 0.26770478 0.05606826 0.04704165 0.02959603 0.\n",
      "  0.00047501 0.16812964 0.         0.01917903 0.         0.02387912\n",
      "  0.         0.05280692 0.10493239 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07755698 0.14367992 0.27883556 0.         0.         0.\n",
      "  0.         0.         0.27110726 0.04116033 0.         0.\n",
      "  0.         0.         0.2442297  0.4080616  0.         0.\n",
      "  0.14810021 0.08066304 0.         0.2467227  0.02495809 0.3643232\n",
      "  0.         0.12521549 0.09870796 0.         0.         0.\n",
      "  0.01910206 0.11664014 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.37662143 0.         0.06858902 0.49597287 0.         0.7088009\n",
      "  1.9416016  1.8216072  0.08140589 0.         0.13851655 0.\n",
      "  0.         0.         0.         0.28240007 0.         0.61584824\n",
      "  0.         0.         0.24356648 0.10642237 0.         0.\n",
      "  0.         0.         0.         0.23656733 0.         0.\n",
      "  0.6910271  0.24755779 0.4655611  0.         0.5094981  0.\n",
      "  0.         0.84077936 0.         0.6474801  0.2636998  0.\n",
      "  0.         0.96106726 0.5603214  1.1806952  0.         0.\n",
      "  0.         1.1450257  0.         0.5399857  0.81648743 0.08689\n",
      "  0.         0.48013544 0.         0.         0.         0.\n",
      "  0.         0.9312992  0.45149958 0.        ]]\n",
      "Hi!\n",
      "[[0.59143496 0.3259047  0.4029431  0.19864015 0.         0.7711112\n",
      "  0.64356226 0.96314985 0.         0.         0.24085847 0.\n",
      "  0.61258763 0.45472854 0.         0.         0.         0.37639254\n",
      "  0.         0.56984466 0.3411127  0.         0.         0.06204065\n",
      "  0.         0.         0.         0.32944083 0.         0.\n",
      "  0.9487581  0.79063094 0.09883341 0.         0.32276195 0.\n",
      "  0.         0.6358532  0.20790882 0.22206582 0.         0.\n",
      "  0.         0.17778952 1.1144623  1.0972004  0.         0.4771\n",
      "  0.3586229  0.78958744 0.0938507  0.63519466 0.7033128  1.0031562\n",
      "  0.         0.5466222  0.27069345 0.         0.         0.\n",
      "  0.         0.19351143 0.6864716  0.        ]]\n",
      "Hi!\n",
      "[[0.5455362  0.         0.7528877  0.21565154 0.         0.5566025\n",
      "  1.6717256  1.4991959  0.9295025  0.         0.40081385 0.\n",
      "  0.         0.         0.         0.6553658  0.19244899 0.8592098\n",
      "  0.         0.         0.8369969  0.2686183  0.         0.2664927\n",
      "  0.02703631 0.         0.         0.05008812 0.         0.\n",
      "  0.386862   0.04360299 0.1451972  0.         0.49855065 0.\n",
      "  0.         1.2439786  0.         0.70090985 0.21444348 0.\n",
      "  0.         1.4631836  0.01935126 0.6152004  0.         0.\n",
      "  0.         0.88799566 0.49745852 0.20087028 0.44677955 0.\n",
      "  0.         0.08971817 0.         0.10136757 0.         0.\n",
      "  0.         1.2785958  1.0570862  0.06380937]]\n",
      "Hi!\n",
      "[[0.         0.0456609  0.08261032 0.         0.         0.06757562\n",
      "  0.09203062 0.1631088  0.02123367 0.09540487 0.12196011 0.\n",
      "  0.         0.01207414 0.         0.04968682 0.         0.\n",
      "  0.         0.06694259 0.10190459 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15297592 0.         0.         0.\n",
      "  0.         0.04735063 0.08435061 0.11061408 0.         0.\n",
      "  0.         0.         0.14185095 0.2896316  0.         0.\n",
      "  0.06450785 0.         0.         0.19615726 0.01385905 0.18526986\n",
      "  0.         0.11094221 0.         0.         0.         0.\n",
      "  0.         0.13208625 0.         0.        ]]\n",
      "Hi!\n",
      "[[4.7354770e-01 9.7454488e-01 1.0836576e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.6532916e-01 0.0000000e+00 0.0000000e+00 1.6026273e-01 0.0000000e+00\n",
      "  4.5453873e-01 0.0000000e+00 1.0836855e+00 9.6269481e-02 0.0000000e+00\n",
      "  5.0697423e-04 0.0000000e+00 3.0677411e-01 0.0000000e+00 9.6007150e-01\n",
      "  4.9308822e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.9241052e-01 6.5885079e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.7309849e-01 4.6219614e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.1995999e-01\n",
      "  2.3610851e-01 0.0000000e+00 7.0460254e-01 7.0261854e-01 5.1108706e-01\n",
      "  1.0011952e-01 6.5769792e-01 5.5576533e-01 1.0611798e+00 0.0000000e+00\n",
      "  5.0375527e-01 3.2226708e-02 0.0000000e+00 9.5808737e-02 0.0000000e+00\n",
      "  1.1690505e-01 7.2348833e-02 4.6154594e-01 3.0797753e-01]]\n",
      "Hi!\n",
      "[[0.5421131  0.7253292  0.48150215 0.00914946 0.         0.54702693\n",
      "  0.42793113 1.1319225  0.5318796  0.         0.38392863 0.\n",
      "  1.6541886  0.6469006  0.         0.42572707 0.         0.47676283\n",
      "  0.47789007 0.30190483 0.60941523 0.04897771 0.         0.22415228\n",
      "  0.         0.         0.         0.7760604  0.         0.\n",
      "  1.3789585  0.88780177 0.         0.         0.5775484  0.\n",
      "  0.15678988 0.8860733  0.3619124  0.15652214 0.         0.\n",
      "  0.         0.3297157  1.0837802  0.84221035 0.         0.5415394\n",
      "  0.         0.86379546 0.65027153 0.5562462  0.9379305  1.0016868\n",
      "  0.         0.         0.4069512  0.         0.         0.\n",
      "  0.         0.3081479  1.2424542  0.05178009]]\n",
      "Hi!\n",
      "[[0.20556459 0.08352979 0.25699666 0.         0.         0.45711702\n",
      "  0.36622354 0.45585203 0.         0.25939026 0.14191984 0.\n",
      "  0.         0.         0.         0.09002469 0.         0.1771356\n",
      "  0.         0.37899467 0.13342954 0.         0.         0.05001369\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14378247 0.         0.         0.\n",
      "  0.         0.09285428 0.         0.4036839  0.         0.\n",
      "  0.         0.09670206 0.10004845 0.6403019  0.         0.\n",
      "  0.3679912  0.5425848  0.         0.29661202 0.34283808 0.23142496\n",
      "  0.         0.52592576 0.         0.         0.         0.\n",
      "  0.2567167  0.40146342 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3461727  0.         0.29298222 0.30451652 0.         0.6340497\n",
      "  1.728075   1.6653268  0.4081163  0.         0.24226442 0.\n",
      "  0.         0.         0.         0.3983737  0.         0.61985946\n",
      "  0.         0.         0.5143098  0.08809032 0.         0.\n",
      "  0.02728306 0.         0.         0.27949244 0.         0.\n",
      "  0.7858021  0.30006397 0.15487242 0.         0.6030155  0.\n",
      "  0.         1.1433265  0.         0.47320113 0.22821109 0.\n",
      "  0.         0.9323361  0.57786    0.9632356  0.         0.\n",
      "  0.         0.9279512  0.23462863 0.44191572 0.5968328  0.13037676\n",
      "  0.         0.09711203 0.09916    0.         0.         0.\n",
      "  0.         0.9331035  0.9288542  0.        ]]\n",
      "Hi!\n",
      "[[0.04686619 0.24424763 0.49970266 0.         0.         0.31071702\n",
      "  0.         0.01129587 0.14525872 0.08329394 0.23637703 0.\n",
      "  0.05974884 0.         0.         0.06853269 0.         0.\n",
      "  0.         0.38999027 0.20520245 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11273345 0.12642527 0.         0.         0.\n",
      "  0.         0.         0.06409984 0.2867177  0.         0.\n",
      "  0.         0.         0.01689565 0.23058449 0.         0.25822413\n",
      "  0.2811335  0.17287979 0.01685063 0.29864487 0.10485949 0.34044534\n",
      "  0.         0.29011425 0.         0.         0.09828217 0.\n",
      "  0.14516088 0.05350565 0.         0.12153142]]\n",
      "Hi!\n",
      "[[0.47997093 0.07208338 0.2364634  0.33628774 0.         0.6578142\n",
      "  1.2021092  1.6718824  0.5630558  0.         0.27409136 0.\n",
      "  1.1580427  0.50839084 0.         0.4826491  0.         0.5854231\n",
      "  0.40439293 0.         0.49958953 0.25815246 0.         0.\n",
      "  0.22004002 0.         0.         0.82576615 0.         0.\n",
      "  1.4740099  0.7650594  0.         0.         0.8563083  0.\n",
      "  0.26049477 1.2597487  0.07155869 0.16443154 0.26037404 0.\n",
      "  0.         0.40683216 1.1558867  1.1398158  0.         0.4304114\n",
      "  0.         0.8458585  0.6454775  0.64430445 0.88283247 0.8140869\n",
      "  0.         0.         0.5335985  0.         0.         0.\n",
      "  0.         0.504145   1.4310561  0.        ]]\n",
      "Hi!\n",
      "[[0.5239997  0.         0.78581303 0.34882188 0.         0.95969135\n",
      "  1.2946398  1.4871469  0.530876   0.         0.309406   0.\n",
      "  0.05718285 0.         0.         0.34450653 0.         0.57175195\n",
      "  0.         0.         0.7898265  0.         0.         0.13540478\n",
      "  0.         0.         0.         0.37316176 0.         0.\n",
      "  0.6821575  0.60349435 0.12164719 0.         0.4235396  0.\n",
      "  0.         1.1278868  0.         0.49603355 0.15420073 0.\n",
      "  0.         0.76260906 0.6198663  0.9033687  0.         0.22297114\n",
      "  0.         0.82347107 0.20364907 0.54704434 0.71468663 0.3387668\n",
      "  0.         0.53826725 0.17446102 0.         0.         0.\n",
      "  0.         0.8331801  1.3986079  0.        ]]\n",
      "Hi!\n",
      "[[0.4509344  0.3826338  0.0611636  0.17520171 0.         0.49075827\n",
      "  1.0285999  1.2983379  0.4066349  0.         0.28559792 0.\n",
      "  1.2108706  0.7670951  0.         0.5299113  0.         0.6298126\n",
      "  0.40492606 0.17396224 0.3899904  0.15079996 0.         0.\n",
      "  0.2940245  0.         0.         0.78230613 0.         0.\n",
      "  1.2920653  0.71604943 0.         0.         0.8504457  0.\n",
      "  0.42734003 1.1877623  0.09328125 0.1944183  0.12601799 0.\n",
      "  0.         0.4221249  1.2812616  1.0170901  0.         0.672651\n",
      "  0.         0.8327438  0.64113045 0.5030654  0.6165397  0.92957497\n",
      "  0.         0.         0.49469337 0.         0.         0.\n",
      "  0.         0.48744094 0.8940612  0.        ]]\n",
      "Hi!\n",
      "[[0.37728423 0.         0.6513395  0.21045981 0.         0.7121883\n",
      "  1.3847016  1.5506049  0.851141   0.         0.36651087 0.\n",
      "  0.2344686  0.         0.         0.6089071  0.         0.71856886\n",
      "  0.         0.         0.8107928  0.06667835 0.         0.18800494\n",
      "  0.         0.         0.         0.36708376 0.         0.\n",
      "  0.789075   0.33113113 0.08284434 0.         0.562382   0.\n",
      "  0.         1.270829   0.         0.5030474  0.18424736 0.\n",
      "  0.         1.0100869  0.33583722 0.7975478  0.         0.09504679\n",
      "  0.         0.87845975 0.48702025 0.42334488 0.742186   0.04059291\n",
      "  0.         0.06476804 0.08768195 0.         0.         0.\n",
      "  0.         0.98038304 1.3926908  0.01954637]]\n",
      "Hi!\n",
      "[[0.88879585 0.43810573 1.7399992  0.         0.         0.9764158\n",
      "  0.         0.         0.8062983  0.         0.689185   0.\n",
      "  0.3075673  0.         0.         0.47582328 0.5979844  0.7964141\n",
      "  0.         0.5247932  1.1819127  0.13626522 0.         0.3556276\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.35125595 0.00252851 0.         0.         0.\n",
      "  0.04309275 0.53877634 0.         0.99707025 0.         0.\n",
      "  0.         0.57746005 0.         0.09319536 0.         0.7072142\n",
      "  0.27465507 0.78216225 0.4424863  0.21252608 0.36156785 0.41611645\n",
      "  0.         0.65787506 0.         0.38231394 0.13671932 0.\n",
      "  0.10102152 0.67789984 0.8283818  0.75272983]]\n",
      "Hi!\n",
      "[[0.6437382  0.15301608 1.3979633  0.         0.         0.7055764\n",
      "  0.25742286 0.23303068 0.96323764 0.         0.61237127 0.\n",
      "  0.07651608 0.         0.         0.53647494 0.51135993 0.9063007\n",
      "  0.         0.12007783 1.1228664  0.24298689 0.         0.31868845\n",
      "  0.01768202 0.         0.         0.         0.         0.\n",
      "  0.         0.06982159 0.         0.         0.         0.\n",
      "  0.01374643 0.7404069  0.         0.80148387 0.         0.\n",
      "  0.         0.84533674 0.         0.1006441  0.         0.5251104\n",
      "  0.         0.69300646 0.53072315 0.08305386 0.1960631  0.05809692\n",
      "  0.         0.20897575 0.         0.43218577 0.07496704 0.\n",
      "  0.         0.95718205 0.73576355 0.7065352 ]]\n",
      "Hi!\n",
      "[[0.3640231  1.1442485  0.5870478  0.         0.         0.41403425\n",
      "  0.         0.02543833 0.38194382 0.         0.4208025  0.\n",
      "  1.4721297  0.33973816 0.         0.32957003 0.         0.46215954\n",
      "  0.32858434 0.78480285 0.4007254  0.         0.         0.1257989\n",
      "  0.         0.         0.         0.14977486 0.         0.\n",
      "  0.6182718  0.549495   0.         0.         0.1684695  0.\n",
      "  0.1256427  0.29819927 0.28428414 0.36993918 0.         0.\n",
      "  0.         0.00445628 0.55560756 0.3080332  0.         0.8384867\n",
      "  0.13903558 0.64837027 0.56343853 0.3320284  0.3146466  0.92967534\n",
      "  0.         0.         0.303111   0.         0.07925352 0.\n",
      "  0.         0.24728395 0.39885315 0.38029197]]\n",
      "Hi!\n",
      "[[0.13018142 0.63656664 0.7228249  0.         0.         0.4968887\n",
      "  0.         0.         0.17147204 0.00764196 0.3787291  0.\n",
      "  0.45236397 0.         0.         0.0107501  0.         0.20700288\n",
      "  0.         0.73111475 0.38661546 0.         0.         0.02836502\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08409188 0.25011042 0.         0.         0.         0.\n",
      "  0.         0.         0.16944608 0.29221788 0.         0.\n",
      "  0.         0.         0.18404885 0.1842889  0.         0.34979197\n",
      "  0.50756    0.34122023 0.03392638 0.33542785 0.358029   0.6228152\n",
      "  0.         0.31364593 0.         0.         0.14307682 0.\n",
      "  0.22394203 0.19407776 0.12283771 0.22085053]]\n",
      "Hi!\n",
      "[[0.73630965 0.44110096 0.         0.61016756 0.         0.41179132\n",
      "  1.2724589  1.955481   0.10717768 0.         0.07586568 0.\n",
      "  1.7309924  1.3954424  0.         0.45138696 0.         0.4446447\n",
      "  0.5926501  0.20011377 0.20994352 0.56297183 0.         0.05419723\n",
      "  0.30813417 0.         0.         1.2967772  0.         0.\n",
      "  1.9783485  1.1065727  0.42717677 0.         1.0626825  0.\n",
      "  0.5938416  1.223854   0.6117972  0.07278919 0.38332942 0.\n",
      "  0.         0.8033433  1.9212066  1.5114177  0.         0.7939266\n",
      "  0.         0.8275655  0.67645866 0.63550436 0.8760361  1.6501676\n",
      "  0.         0.         0.8879689  0.         0.         0.\n",
      "  0.         0.21440709 0.9941224  0.        ]]\n",
      "Hi!\n",
      "[[0.01737649 0.27317217 0.33743188 0.         0.         0.31116575\n",
      "  0.         0.07132112 0.01095039 0.0436244  0.21894239 0.\n",
      "  0.05127638 0.06278194 0.         0.01035715 0.         0.05869335\n",
      "  0.         0.36378345 0.14659703 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18045531 0.08495466 0.         0.         0.\n",
      "  0.         0.         0.15488647 0.20482735 0.         0.\n",
      "  0.         0.         0.11740228 0.37538207 0.         0.13650131\n",
      "  0.2990315  0.16682559 0.         0.27489418 0.18704614 0.44101432\n",
      "  0.         0.26996434 0.         0.         0.01615036 0.\n",
      "  0.10811422 0.07014132 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.13777553 0.14173712 0.         0.         0.13751179\n",
      "  0.         0.1002503  0.05006527 0.101023   0.178339   0.\n",
      "  0.         0.0530685  0.         0.05017672 0.         0.0748919\n",
      "  0.         0.21393926 0.10913925 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00479734 0.07367458 0.         0.         0.\n",
      "  0.         0.         0.07057036 0.11024984 0.         0.\n",
      "  0.         0.         0.08282337 0.29591545 0.         0.03449307\n",
      "  0.1447849  0.07462261 0.         0.16054025 0.04205861 0.27580512\n",
      "  0.         0.11511442 0.         0.         0.01940583 0.\n",
      "  0.04144118 0.09336752 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.49361038 1.3041389  0.560185   0.         0.         0.46053496\n",
      "  0.         0.4601324  0.34967887 0.         0.46035454 0.\n",
      "  1.8354192  0.65945494 0.         0.3125228  0.         0.5032187\n",
      "  0.42836392 0.8399933  0.47043854 0.         0.         0.27875218\n",
      "  0.         0.         0.         0.34854582 0.         0.\n",
      "  1.0835075  0.84470624 0.         0.         0.3059495  0.\n",
      "  0.12421117 0.45993987 0.60548156 0.2774592  0.         0.\n",
      "  0.         0.19917548 0.951583   0.6572493  0.         0.8326538\n",
      "  0.2270409  0.7010496  0.65359795 0.41987243 0.8155201  1.2119434\n",
      "  0.         0.         0.3688866  0.         0.01810613 0.\n",
      "  0.         0.22551389 0.5099357  0.26111993]]\n",
      "Hi!\n",
      "[[0.2567646  0.4262956  0.46839342 0.         0.         0.58229524\n",
      "  0.28741163 0.32947078 0.         0.0073099  0.28605917 0.\n",
      "  0.2700932  0.12370077 0.         0.01369347 0.         0.392062\n",
      "  0.         0.68013763 0.26916587 0.         0.         0.06041389\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38348746 0.4361291  0.         0.         0.0465491  0.\n",
      "  0.         0.26058403 0.         0.38218492 0.         0.\n",
      "  0.         0.         0.52309805 0.72660047 0.         0.35504594\n",
      "  0.38593775 0.63919544 0.12512976 0.4105913  0.33027115 0.7636661\n",
      "  0.         0.45372048 0.03895271 0.         0.0039727  0.\n",
      "  0.0844787  0.2948091  0.14008017 0.        ]]\n",
      "Hi!\n",
      "[[0.85806596 0.35058728 1.2740989  0.         0.         1.1909478\n",
      "  0.16730326 0.40106377 0.22386043 0.2155894  0.427993   0.\n",
      "  0.         0.         0.         0.02776776 0.22984616 0.4313172\n",
      "  0.         0.7027762  0.81179196 0.         0.         0.33431828\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40448508 0.18916693 0.         0.         0.\n",
      "  0.         0.21789572 0.         0.69608796 0.         0.\n",
      "  0.         0.31672817 0.21225533 0.6983745  0.         0.38034478\n",
      "  0.5960482  0.9833038  0.         0.46517232 0.7988737  0.5628744\n",
      "  0.         1.3605503  0.         0.         0.04548267 0.\n",
      "  0.3708683  0.5057077  0.44293463 0.12238333]]\n",
      "Hi!\n",
      "[[0.50780594 0.69339126 1.1542007  0.         0.         1.0753453\n",
      "  0.         0.31063148 0.4105552  0.04781562 0.50343204 0.\n",
      "  0.69179595 0.         0.         0.0404411  0.         0.4054287\n",
      "  0.         0.7496198  0.7774443  0.         0.         0.25130674\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3205537  0.5007992  0.         0.         0.         0.\n",
      "  0.         0.28606358 0.         0.47270536 0.         0.\n",
      "  0.         0.         0.31331173 0.53663516 0.         0.58997726\n",
      "  0.44543985 0.8713872  0.23457165 0.52005535 0.7726629  0.69907176\n",
      "  0.         0.71488136 0.         0.         0.08597633 0.\n",
      "  0.00732323 0.33331594 0.5899612  0.3848523 ]]\n",
      "Hi!\n",
      "[[0.5648016  0.8682774  0.6194216  0.         0.         0.5049403\n",
      "  0.20262936 0.6666045  0.59500825 0.         0.4739241  0.\n",
      "  1.5743082  0.4217923  0.         0.55770314 0.         0.6639373\n",
      "  0.56558436 0.432828   0.64111423 0.         0.         0.12423642\n",
      "  0.1470726  0.         0.         0.4260415  0.         0.\n",
      "  1.0411165  0.758726   0.         0.         0.5058776  0.\n",
      "  0.3807657  0.8848421  0.20275815 0.3884703  0.         0.\n",
      "  0.         0.25809574 0.9785061  0.5258227  0.         0.842902\n",
      "  0.         0.69570434 0.70207494 0.42061397 0.5457737  0.9503098\n",
      "  0.         0.         0.3609659  0.         0.         0.\n",
      "  0.         0.42566332 0.93141603 0.33669856]]\n",
      "Hi!\n",
      "[[0.41282442 0.         0.4150311  0.36667535 0.         0.6850074\n",
      "  1.7164875  1.6293985  0.46778193 0.         0.27646363 0.\n",
      "  0.         0.         0.         0.39659256 0.         0.7261179\n",
      "  0.         0.         0.5396724  0.11820694 0.         0.04219933\n",
      "  0.         0.         0.         0.23291132 0.         0.\n",
      "  0.6961302  0.25923306 0.20005701 0.         0.5851571  0.\n",
      "  0.         1.1416994  0.         0.5935769  0.23600174 0.\n",
      "  0.         1.0239483  0.43697062 0.99413705 0.         0.\n",
      "  0.         1.0029116  0.24338529 0.3971161  0.69355947 0.02101599\n",
      "  0.         0.17916517 0.         0.         0.         0.\n",
      "  0.         1.0579121  0.9655114  0.        ]]\n",
      "Hi!\n",
      "[[0.56279176 0.         1.270891   0.         0.         0.77670085\n",
      "  0.87632155 1.0301517  1.3076347  0.         0.5827858  0.\n",
      "  0.36408383 0.         0.         0.7966044  0.29482672 0.85189795\n",
      "  0.22564325 0.         1.1853126  0.19947612 0.         0.5238046\n",
      "  0.         0.         0.         0.14019486 0.         0.\n",
      "  0.3706561  0.27264956 0.02609627 0.         0.28914952 0.\n",
      "  0.15006101 1.2251939  0.         0.6801774  0.252469   0.\n",
      "  0.         1.2551469  0.         0.34923095 0.         0.4467326\n",
      "  0.         0.76173985 0.72200483 0.2420307  0.46394908 0.00793742\n",
      "  0.         0.11863199 0.         0.37534145 0.         0.\n",
      "  0.         1.05357    1.4497788  0.5965704 ]]\n",
      "Hi!\n",
      "[[0.3293878  0.39157325 0.7687873  0.         0.         0.6335013\n",
      "  0.11527045 0.27580476 0.31093177 0.02763429 0.37218025 0.\n",
      "  0.5020486  0.         0.         0.21184765 0.         0.49194416\n",
      "  0.         0.44910893 0.5472195  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34213224 0.45473352 0.         0.         0.05227683 0.\n",
      "  0.02983134 0.5051095  0.         0.44274157 0.         0.\n",
      "  0.         0.04335476 0.37705627 0.42116693 0.         0.57895726\n",
      "  0.20284116 0.55804706 0.21063983 0.32079822 0.27710578 0.53648394\n",
      "  0.         0.30794534 0.         0.         0.01687954 0.\n",
      "  0.         0.4302942  0.58952576 0.27817935]]\n",
      "Hi!\n",
      "[[0.7774474  0.37278855 1.0104774  0.         0.         1.277812\n",
      "  0.29937273 0.5880064  0.22243333 0.24865264 0.39951637 0.\n",
      "  0.         0.         0.         0.         0.05014029 0.3381571\n",
      "  0.         0.71383464 0.6733736  0.         0.         0.2636575\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11286327 0.29763922 0.22234245 0.         0.         0.\n",
      "  0.         0.21176729 0.         0.7126427  0.         0.\n",
      "  0.         0.2765838  0.30071318 0.86441076 0.         0.32346565\n",
      "  0.51106566 1.0742104  0.         0.58375627 0.8713768  0.45839006\n",
      "  0.         1.253551   0.         0.         0.         0.\n",
      "  0.3465475  0.51617336 0.3340917  0.04724799]]\n",
      "Hi!\n",
      "[[0.355392   0.18963765 0.34057915 0.0258777  0.         0.5378165\n",
      "  0.9484311  1.2796141  0.63693887 0.         0.34606594 0.\n",
      "  0.94041    0.27419788 0.         0.5817502  0.         0.5896403\n",
      "  0.22170232 0.02503016 0.55121434 0.         0.         0.\n",
      "  0.12049346 0.         0.         0.54789406 0.         0.\n",
      "  1.1140164  0.504249   0.         0.         0.65619415 0.\n",
      "  0.16293836 1.1690897  0.         0.26912722 0.09019037 0.\n",
      "  0.         0.44298884 0.80443436 0.8282243  0.         0.3788372\n",
      "  0.         0.7917169  0.58785737 0.46449712 0.67162305 0.47260323\n",
      "  0.         0.         0.27578482 0.         0.         0.\n",
      "  0.         0.6206298  1.1128206  0.03475748]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "[[1.1665249  0.40700838 2.281881   0.         0.         1.2125877\n",
      "  0.         0.         1.1488537  0.         0.8306245  0.\n",
      "  0.16124627 0.         0.         0.5976825  1.0279084  0.8857571\n",
      "  0.         0.45648423 1.5784144  0.3531614  0.         0.66244245\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.260442   0.05019705 0.         0.         0.\n",
      "  0.0392716  0.5560743  0.         1.2340591  0.         0.\n",
      "  0.         1.0829308  0.         0.13436422 0.         0.8441941\n",
      "  0.32172206 1.0212795  0.60828817 0.10857445 0.47739056 0.25595382\n",
      "  0.         1.0061443  0.         0.81773823 0.19431266 0.\n",
      "  0.1996595  0.8390317  0.9857988  1.0471971 ]]\n",
      "Hi!\n",
      "[[0.6256953  1.1086131  0.59331995 0.         0.         0.37792423\n",
      "  0.02099646 0.56555015 0.6619139  0.         0.5047363  0.\n",
      "  1.9403455  0.5858283  0.         0.62367624 0.         0.6451368\n",
      "  0.7875163  0.5370788  0.62071794 0.         0.         0.25545758\n",
      "  0.16512646 0.         0.         0.4953306  0.         0.\n",
      "  1.180653   0.8560339  0.         0.         0.48426315 0.\n",
      "  0.48375586 0.84939575 0.42455152 0.38692325 0.         0.\n",
      "  0.         0.36243054 1.0474817  0.4882114  0.         0.9601541\n",
      "  0.         0.7129589  0.82112163 0.37112543 0.658921   1.0938361\n",
      "  0.         0.         0.4037516  0.         0.00332417 0.\n",
      "  0.         0.32631475 0.9427497  0.4095484 ]]\n",
      "Hi!\n",
      "[[0.6007447  0.5436912  1.217207   0.         0.         0.98691064\n",
      "  0.13126779 0.36512083 0.49964643 0.0202288  0.53526783 0.\n",
      "  0.50991714 0.         0.         0.13340814 0.01547732 0.54370666\n",
      "  0.         0.57484716 0.8827434  0.         0.         0.26308152\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30605242 0.54359305 0.03125445 0.         0.         0.\n",
      "  0.         0.38529015 0.         0.62585366 0.         0.\n",
      "  0.         0.14235339 0.30593526 0.49848652 0.         0.41775352\n",
      "  0.35328794 0.90738374 0.24509811 0.48277697 0.80794114 0.52273643\n",
      "  0.         0.7043097  0.         0.         0.07393029 0.\n",
      "  0.         0.4795423  0.6892571  0.32638335]]\n",
      "Hi!\n",
      "[[0.8267873  0.         1.2343165  0.21868788 0.         0.9992338\n",
      "  1.2222775  1.327125   0.8762563  0.         0.46455663 0.\n",
      "  0.         0.         0.         0.43885756 0.4330849  0.7100713\n",
      "  0.         0.         1.0359532  0.17426358 0.         0.5439442\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16394165 0.2575295  0.17152809 0.         0.17447111 0.\n",
      "  0.         0.9267937  0.         0.83177906 0.15948147 0.\n",
      "  0.         1.3182874  0.         0.6139011  0.         0.03427434\n",
      "  0.         0.9328342  0.34648487 0.35308817 0.8184286  0.\n",
      "  0.         0.87521565 0.         0.11458579 0.         0.\n",
      "  0.         1.0712092  1.2352815  0.03359779]]\n",
      "Hi!\n",
      "[[0.20559086 0.25785068 0.20653473 0.         0.         0.52401644\n",
      "  0.45396477 0.54951084 0.0362084  0.14140733 0.12684041 0.\n",
      "  0.         0.10065056 0.         0.1230129  0.         0.29026058\n",
      "  0.         0.4289919  0.0960433  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13759418 0.15441237 0.11668972 0.         0.         0.\n",
      "  0.         0.14010699 0.         0.3899786  0.         0.\n",
      "  0.         0.1646343  0.29233703 0.71950656 0.         0.01306244\n",
      "  0.3559069  0.657856   0.01973695 0.29008874 0.42159063 0.36572856\n",
      "  0.         0.34839723 0.         0.         0.         0.\n",
      "  0.23815404 0.59919924 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0466173  0.27538764 0.24051139 0.         0.         0.23057218\n",
      "  0.         0.12223686 0.         0.0720655  0.15424798 0.\n",
      "  0.1613258  0.13863501 0.         0.         0.         0.1318924\n",
      "  0.         0.2896933  0.1032287  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07054538 0.23854591 0.07824502 0.         0.         0.\n",
      "  0.         0.         0.08263211 0.09216467 0.         0.\n",
      "  0.         0.         0.22299375 0.3049566  0.         0.14139378\n",
      "  0.25355077 0.19970739 0.         0.2034933  0.11594991 0.38954905\n",
      "  0.         0.18581663 0.05670468 0.         0.03948919 0.\n",
      "  0.09496576 0.13223955 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.9644444  0.26971054 1.4711089  0.         0.         1.2366873\n",
      "  0.29593885 0.4656873  0.44349092 0.21809219 0.5035838  0.\n",
      "  0.         0.         0.         0.0910439  0.45413893 0.5445345\n",
      "  0.         0.57795143 0.9835046  0.         0.         0.54181725\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22674038 0.20437945 0.         0.         0.\n",
      "  0.         0.27716753 0.         0.95007294 0.         0.\n",
      "  0.         0.6573279  0.         0.5946215  0.         0.2258771\n",
      "  0.47522697 1.2089124  0.0677817  0.3664878  0.88834465 0.22596647\n",
      "  0.         1.4077328  0.         0.         0.05853759 0.\n",
      "  0.46704125 0.7400424  0.4245337  0.23417535]]\n",
      "Hi!\n",
      "[[0.4341608  0.15507366 0.7131405  0.0962235  0.         0.8315668\n",
      "  0.7023539  0.7991666  0.17021716 0.         0.3566214  0.\n",
      "  0.33501193 0.         0.         0.11484022 0.         0.54174566\n",
      "  0.         0.44057792 0.5476343  0.         0.         0.\n",
      "  0.         0.         0.         0.11758021 0.         0.\n",
      "  0.63303655 0.6055543  0.00432493 0.         0.27518567 0.\n",
      "  0.         0.7545911  0.         0.40140957 0.         0.\n",
      "  0.         0.15189582 0.73306113 0.81487525 0.         0.43810302\n",
      "  0.20145565 0.72574264 0.19416115 0.47409335 0.5598558  0.6633961\n",
      "  0.         0.46132508 0.13289185 0.         0.         0.\n",
      "  0.         0.43915    0.76136345 0.        ]]\n",
      "Hi!\n",
      "[[0.02210771 0.31208065 0.         0.         0.         0.25648445\n",
      "  0.75605106 0.8750174  0.15631166 0.         0.17551868 0.\n",
      "  0.33919463 0.38059735 0.         0.2984838  0.         0.42060357\n",
      "  0.         0.26839858 0.12721547 0.         0.         0.\n",
      "  0.         0.         0.         0.11127672 0.         0.\n",
      "  0.69948685 0.29292107 0.08259996 0.         0.36231703 0.\n",
      "  0.         0.57548106 0.         0.3537375  0.         0.\n",
      "  0.         0.19536632 0.58332145 0.7235724  0.         0.1142313\n",
      "  0.         0.7317669  0.28251448 0.27781102 0.3914085  0.4190847\n",
      "  0.         0.         0.1724444  0.         0.         0.\n",
      "  0.         0.5828567  0.05965283 0.        ]]\n",
      "Hi!\n",
      "[[0.14654507 0.7162551  0.720378   0.         0.         0.42525798\n",
      "  0.         0.         0.33079118 0.         0.39006832 0.\n",
      "  0.613792   0.         0.         0.11600813 0.02497132 0.2618883\n",
      "  0.         0.65271467 0.41979364 0.         0.         0.00412929\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10645964 0.20862724 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.30978486 0.         0.\n",
      "  0.         0.         0.04666981 0.00572397 0.         0.5336631\n",
      "  0.33797312 0.41566226 0.20231873 0.23329866 0.1313726  0.52432156\n",
      "  0.         0.         0.         0.         0.18769006 0.\n",
      "  0.1687297  0.18448947 0.19503997 0.36212134]]\n",
      "Hi!\n",
      "[[0.44847363 0.         0.87773675 0.01810842 0.         0.5887417\n",
      "  1.2578782  1.2981007  1.1764342  0.         0.48481545 0.\n",
      "  0.1504744  0.         0.         0.82826316 0.12544538 0.855524\n",
      "  0.         0.         0.97134495 0.19892892 0.         0.3529877\n",
      "  0.02412211 0.         0.         0.1355604  0.         0.\n",
      "  0.4852824  0.10077623 0.05513    0.         0.47815883 0.\n",
      "  0.06935321 1.2968634  0.         0.6192446  0.18170998 0.\n",
      "  0.         1.3303499  0.         0.4766664  0.         0.2076292\n",
      "  0.         0.8090513  0.6694682  0.24739885 0.47956088 0.\n",
      "  0.         0.         0.         0.23380722 0.         0.\n",
      "  0.         1.1607089  1.2777823  0.34628546]]\n",
      "Hi!\n",
      "[[0.         0.00325823 0.12679651 0.         0.         0.12926911\n",
      "  0.07386562 0.18757585 0.04486048 0.13229468 0.11818633 0.\n",
      "  0.         0.05053954 0.         0.04110912 0.         0.\n",
      "  0.         0.09519629 0.13816746 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01740601 0.10343929 0.         0.         0.\n",
      "  0.         0.05247791 0.10591058 0.11557931 0.         0.\n",
      "  0.         0.         0.10103508 0.32310143 0.         0.04538527\n",
      "  0.06424934 0.12770642 0.         0.20140672 0.10582305 0.28259864\n",
      "  0.         0.06935915 0.         0.         0.         0.\n",
      "  0.         0.19784054 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4114483  0.07615468 0.49233428 0.3207388  0.         0.97845405\n",
      "  0.98832923 1.3011396  0.         0.         0.22598873 0.\n",
      "  0.20075074 0.24247544 0.         0.         0.         0.36895055\n",
      "  0.         0.45678106 0.43646285 0.         0.         0.\n",
      "  0.         0.         0.         0.30591372 0.         0.\n",
      "  0.9442217  0.66902137 0.16533929 0.         0.39328375 0.\n",
      "  0.         0.5754821  0.02367313 0.39880893 0.08052814 0.\n",
      "  0.         0.11050176 0.9036663  1.2837896  0.         0.02039668\n",
      "  0.26697302 1.0024054  0.         0.74635226 1.1717908  0.66242516\n",
      "  0.         0.840655   0.04353802 0.         0.         0.\n",
      "  0.         0.41308543 0.8011285  0.        ]]\n",
      "Hi!\n",
      "[[0.35835359 0.02599722 0.8220393  0.         0.         0.72430855\n",
      "  0.8584712  0.93507063 0.888718   0.         0.4345701  0.\n",
      "  0.70880777 0.         0.         0.65152985 0.         0.7266691\n",
      "  0.40142834 0.         0.7850731  0.         0.         0.\n",
      "  0.20405637 0.         0.         0.24810697 0.         0.\n",
      "  0.6311259  0.39868444 0.         0.         0.4807651  0.\n",
      "  0.42365766 1.2633998  0.         0.48346493 0.02976575 0.\n",
      "  0.         0.75889874 0.42489555 0.47735512 0.         0.7615309\n",
      "  0.         0.5490743  0.65816724 0.35611165 0.25895146 0.42658657\n",
      "  0.         0.         0.27436763 0.04584285 0.         0.\n",
      "  0.         0.7491217  1.2402999  0.4096471 ]]\n",
      "Hi!\n",
      "[[0.6599957  0.         0.7107309  0.07656127 0.         0.85198766\n",
      "  0.81117153 0.9294497  0.36572248 0.11402362 0.34025276 0.\n",
      "  0.         0.         0.         0.18769902 0.18571138 0.6139661\n",
      "  0.         0.1689984  0.543512   0.05449688 0.         0.26275906\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07033813 0.27732888 0.         0.01285098 0.\n",
      "  0.         0.46091    0.         0.8328483  0.         0.\n",
      "  0.         0.9387219  0.         0.64246976 0.         0.\n",
      "  0.04132747 1.102464   0.12959395 0.2789824  0.5752931  0.\n",
      "  0.         0.7083046  0.         0.         0.         0.\n",
      "  0.18817858 0.9087826  0.17740993 0.        ]]\n",
      "Hi!\n",
      "[[0.4810137  0.6008702  0.8101107  0.         0.         0.60189253\n",
      "  0.28095672 0.8578815  0.88374716 0.         0.5119312  0.\n",
      "  1.4516796  0.04321127 0.         0.60800666 0.         0.6053375\n",
      "  0.7212933  0.17872116 0.82855016 0.         0.         0.08933944\n",
      "  0.05067712 0.         0.         0.5324677  0.         0.\n",
      "  1.0051063  0.70751894 0.         0.         0.48576558 0.\n",
      "  0.44044974 1.0040869  0.04113551 0.3077928  0.07179314 0.\n",
      "  0.         0.2577186  0.7158302  0.49201372 0.         0.7500094\n",
      "  0.         0.74155974 0.7593044  0.44726762 0.61622936 0.6870907\n",
      "  0.         0.         0.34291708 0.         0.         0.\n",
      "  0.         0.472462   1.3321793  0.44708207]]\n",
      "Hi!\n",
      "[[0.12489056 0.34947285 0.86265653 0.         0.         0.36661774\n",
      "  0.01537081 0.08653104 0.4095074  0.         0.21838859 0.\n",
      "  0.2055044  0.         0.         0.19593102 0.2314342  0.30554974\n",
      "  0.         0.38867885 0.43879682 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1864977  0.1355924  0.         0.         0.\n",
      "  0.         0.17399056 0.0540881  0.41595718 0.         0.\n",
      "  0.         0.02111096 0.         0.12594113 0.         0.47977698\n",
      "  0.300696   0.53540075 0.15725699 0.17789501 0.         0.43632638\n",
      "  0.         0.4083254  0.         0.05035969 0.08478507 0.\n",
      "  0.12775229 0.20595023 0.33720434 0.2865457 ]]\n",
      "Hi!\n",
      "[[5.0134838e-01 9.6716031e-02 1.0138823e+00 1.4302599e-01 0.0000000e+00\n",
      "  9.4834971e-01 6.9674987e-01 8.1232619e-01 4.0295193e-01 0.0000000e+00\n",
      "  3.4234783e-01 0.0000000e+00 3.0908126e-01 0.0000000e+00 0.0000000e+00\n",
      "  2.0537414e-01 2.5936384e-02 5.4052740e-01 0.0000000e+00 2.5885278e-01\n",
      "  7.4373829e-01 0.0000000e+00 0.0000000e+00 7.5966833e-05 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.3185850e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.5660797e-01 5.9820157e-01 1.1614760e-02 0.0000000e+00 1.8350576e-01\n",
      "  0.0000000e+00 1.5435661e-01 9.3159485e-01 0.0000000e+00 5.3401428e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.1971400e-01 5.8847237e-01\n",
      "  6.4111543e-01 0.0000000e+00 7.2173476e-01 1.6311353e-01 5.9061533e-01\n",
      "  1.9717401e-01 4.1473928e-01 3.6818469e-01 6.5452576e-01 0.0000000e+00\n",
      "  5.8956891e-01 2.2259925e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 5.7418996e-01 1.0665663e+00 6.5031342e-02]]\n",
      "Hi!\n",
      "[[0.04469997 0.26777756 0.23893535 0.         0.         0.18251368\n",
      "  0.         0.00423931 0.02868199 0.02597397 0.19795679 0.\n",
      "  0.183986   0.10497971 0.         0.03035956 0.         0.07417732\n",
      "  0.         0.29034156 0.13330106 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06572374 0.15764119 0.04590451 0.         0.         0.\n",
      "  0.         0.         0.16441691 0.09663938 0.         0.\n",
      "  0.         0.         0.15315774 0.22616997 0.         0.13155025\n",
      "  0.21564896 0.10610113 0.         0.20214644 0.10488211 0.4198988\n",
      "  0.         0.09587961 0.04917526 0.         0.07005765 0.\n",
      "  0.07974928 0.07017165 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.38847828 0.63282317 0.4362574  0.04592204 0.         0.5662815\n",
      "  0.30362132 0.55396336 0.00733304 0.         0.3250913  0.\n",
      "  0.6669122  0.38451698 0.         0.08920221 0.         0.4792789\n",
      "  0.         0.61882645 0.35273802 0.         0.         0.11015153\n",
      "  0.         0.         0.         0.25329897 0.         0.\n",
      "  0.7604487  0.6359561  0.05069831 0.         0.27755788 0.\n",
      "  0.         0.3474585  0.23284024 0.2755058  0.         0.\n",
      "  0.         0.00902255 0.78258127 0.7710583  0.         0.28625715\n",
      "  0.25234568 0.81043214 0.14081311 0.44467774 0.59402746 0.6701836\n",
      "  0.         0.23063733 0.16916767 0.         0.         0.\n",
      "  0.         0.38579175 0.41020635 0.        ]]\n",
      "Hi!\n",
      "[[0.18912815 0.         0.61051404 0.         0.         0.53083885\n",
      "  1.1051594  1.2722936  1.16696    0.         0.44685754 0.\n",
      "  0.87542087 0.         0.         0.88394034 0.         0.7626585\n",
      "  0.55746555 0.         0.81834227 0.04033438 0.         0.\n",
      "  0.2299955  0.         0.         0.46081185 0.         0.\n",
      "  0.9192668  0.2882287  0.         0.         0.6621722  0.\n",
      "  0.38461748 1.3966318  0.         0.37325004 0.22975744 0.\n",
      "  0.         0.9545697  0.38716385 0.5353783  0.         0.5111078\n",
      "  0.         0.6728865  0.87785053 0.3451279  0.4642735  0.15279943\n",
      "  0.         0.         0.2683164  0.08928356 0.         0.\n",
      "  0.         0.83741397 1.3505297  0.44397765]]\n",
      "Hi!\n",
      "[[0.48297343 0.43053845 1.0407252  0.         0.         0.81729454\n",
      "  0.         0.2509406  0.32792285 0.         0.4375444  0.\n",
      "  0.5814469  0.         0.         0.16700608 0.00561633 0.43868315\n",
      "  0.         0.5629364  0.66042364 0.         0.         0.0587431\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34783635 0.6412605  0.0271238  0.         0.         0.\n",
      "  0.07460574 0.4885988  0.         0.5334907  0.         0.\n",
      "  0.         0.0635991  0.45886183 0.38269874 0.         0.6179893\n",
      "  0.37426782 0.57441026 0.12723747 0.40805945 0.47382933 0.71714497\n",
      "  0.         0.59710175 0.         0.         0.         0.\n",
      "  0.         0.33484188 0.76175    0.21856365]]\n",
      "Hi!\n",
      "[[0.04710865 0.36622664 0.01231498 0.05232552 0.         0.\n",
      "  0.06543311 0.46153733 0.         0.         0.07964932 0.\n",
      "  0.20786378 0.3751144  0.         0.         0.         0.26750037\n",
      "  0.         0.32473403 0.05467708 0.         0.         0.0384338\n",
      "  0.         0.         0.         0.22680975 0.         0.\n",
      "  0.282057   0.33222526 0.25688392 0.         0.0845815  0.\n",
      "  0.         0.         0.5311852  0.11088676 0.         0.\n",
      "  0.         0.         0.44525865 0.46098942 0.         0.\n",
      "  0.14913501 0.32799992 0.0267073  0.23100969 0.39791468 0.39098668\n",
      "  0.         0.09423609 0.14208414 0.         0.         0.\n",
      "  0.         0.26931596 0.02433576 0.        ]]\n",
      "Hi!\n",
      "[[0.39498797 0.         0.28107202 0.33591396 0.         0.7468679\n",
      "  1.0824704  1.0768267  0.         0.04244658 0.09081392 0.\n",
      "  0.         0.18985398 0.         0.10361067 0.         0.30313888\n",
      "  0.         0.43954    0.12423874 0.         0.         0.\n",
      "  0.         0.         0.         0.09249293 0.         0.\n",
      "  0.5895737  0.5972435  0.3111569  0.         0.20515925 0.\n",
      "  0.         0.4301941  0.07079862 0.35876128 0.         0.\n",
      "  0.         0.1519521  0.78445786 1.116491   0.         0.\n",
      "  0.33426574 0.83803624 0.         0.62060905 0.6649317  0.5987811\n",
      "  0.         0.8364129  0.03899394 0.         0.         0.\n",
      "  0.08399466 0.41794354 0.35278472 0.        ]]\n",
      "Hi!\n",
      "[[0.33779144 0.         0.839389   0.01450251 0.         0.69891244\n",
      "  1.279281   1.4107904  1.1812409  0.         0.46376818 0.\n",
      "  0.4095371  0.         0.         0.85497737 0.         0.7847645\n",
      "  0.2591856  0.         0.96796316 0.11175198 0.         0.26254636\n",
      "  0.09532103 0.         0.         0.3331886  0.         0.\n",
      "  0.6538066  0.23434119 0.00641896 0.         0.52696353 0.\n",
      "  0.1663288  1.3865241  0.         0.48309124 0.21142097 0.\n",
      "  0.         1.2439992  0.17729771 0.5539479  0.         0.35140544\n",
      "  0.         0.7312977  0.70285344 0.34740183 0.4884218  0.\n",
      "  0.         0.         0.14832395 0.19497518 0.         0.\n",
      "  0.         1.0184721  1.5071579  0.36418447]]\n",
      "Hi!\n",
      "[[0.32886374 0.         0.         0.42591062 0.         0.5896253\n",
      "  1.8282969  1.8472966  0.2607677  0.         0.15740076 0.\n",
      "  0.32091236 0.35233673 0.         0.40499496 0.         0.6567322\n",
      "  0.         0.         0.3038467  0.2546098  0.         0.\n",
      "  0.24960774 0.         0.         0.6335522  0.         0.\n",
      "  1.2289292  0.45868573 0.19198819 0.         0.84983224 0.\n",
      "  0.13714044 1.3591413  0.         0.32071632 0.28709954 0.\n",
      "  0.         0.6676762  1.0679674  1.308442   0.         0.12270048\n",
      "  0.         0.95990384 0.4015155  0.6012876  0.6539256  0.5713145\n",
      "  0.         0.         0.34192914 0.         0.         0.\n",
      "  0.         0.7987661  0.9729465  0.        ]]\n",
      "Hi!\n",
      "[[0.01005329 0.14071429 0.2025929  0.         0.         0.12525833\n",
      "  0.0241651  0.07456489 0.09610423 0.10907684 0.15342739 0.\n",
      "  0.10922511 0.00191156 0.         0.02483322 0.         0.00923246\n",
      "  0.         0.11162175 0.14192586 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07951719 0.06707426 0.         0.         0.\n",
      "  0.         0.         0.11402756 0.08579005 0.         0.\n",
      "  0.         0.         0.11836468 0.20537113 0.         0.01866098\n",
      "  0.03051164 0.06018397 0.         0.14246413 0.08318684 0.2681415\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04006621 0.17902645 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.14881225 0.2320956  0.38752553 0.         0.         0.41186452\n",
      "  0.         0.2109746  0.         0.02910045 0.10325937 0.\n",
      "  0.09985298 0.03021882 0.         0.01312762 0.         0.1003816\n",
      "  0.         0.4039753  0.1284586  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06176289 0.3559517  0.09052128 0.         0.         0.\n",
      "  0.         0.         0.1408075  0.15927587 0.         0.\n",
      "  0.         0.         0.27475432 0.40453425 0.         0.19708723\n",
      "  0.42290527 0.37339112 0.         0.3377113  0.23023759 0.5896614\n",
      "  0.         0.5070045  0.         0.         0.         0.\n",
      "  0.18129392 0.1516488  0.0332958  0.        ]]\n",
      "Hi!\n",
      "[[0.76245415 0.64409417 1.6353359  0.         0.         1.0713137\n",
      "  0.         0.09481455 0.2644591  0.         0.6250474  0.\n",
      "  0.6402618  0.         0.         0.12132642 0.16660717 0.47778183\n",
      "  0.         0.920693   0.9604142  0.         0.         0.1872346\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27319628 0.8110289  0.06779011 0.         0.         0.\n",
      "  0.         0.28400943 0.11564431 0.6701853  0.         0.\n",
      "  0.         0.05284981 0.5504741  0.4471998  0.         0.8055442\n",
      "  0.6410199  0.618404   0.07704385 0.48473617 0.6504004  0.91353935\n",
      "  0.         1.0041629  0.08008502 0.         0.1797085  0.\n",
      "  0.06326237 0.30347234 0.95864856 0.30862114]]\n",
      "Hi!\n",
      "[[0.03759701 0.11336196 0.21093917 0.         0.         0.1256874\n",
      "  0.         0.05151042 0.         0.02635734 0.13605078 0.\n",
      "  0.02539666 0.04224996 0.         0.         0.         0.\n",
      "  0.         0.20170423 0.05717549 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14171381 0.0494101  0.         0.         0.\n",
      "  0.         0.         0.14972515 0.097675   0.         0.\n",
      "  0.         0.         0.1699401  0.13024923 0.         0.07258103\n",
      "  0.16376431 0.02201683 0.         0.21867537 0.08156151 0.2172453\n",
      "  0.         0.15421258 0.         0.         0.03167154 0.\n",
      "  0.03803309 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.12855259 0.3036377  0.         0.         0.22396538\n",
      "  0.         0.06999001 0.09268557 0.11807109 0.20495333 0.\n",
      "  0.         0.         0.         0.09776586 0.         0.\n",
      "  0.         0.29173505 0.14551486 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00417475 0.09356276 0.         0.         0.\n",
      "  0.         0.04655595 0.00864067 0.21315785 0.         0.\n",
      "  0.         0.02992943 0.04463281 0.3593003  0.         0.28715262\n",
      "  0.1343011  0.14033604 0.         0.2223408  0.13151515 0.30562782\n",
      "  0.         0.21721874 0.         0.         0.03245602 0.\n",
      "  0.03683389 0.07417922 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.2533709  0.2989801  2.0667748  0.         0.         1.193516\n",
      "  0.26373786 0.323199   1.178047   0.         0.7681008  0.\n",
      "  0.         0.         0.         0.41359258 0.9595943  0.8363452\n",
      "  0.         0.21054374 1.4658704  0.34551534 0.         0.8479479\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1808414  0.15453377 0.         0.         0.\n",
      "  0.         0.5398248  0.         1.0393518  0.         0.\n",
      "  0.         1.1863036  0.         0.2668885  0.         0.49689606\n",
      "  0.17187262 1.1318052  0.59685665 0.12877607 0.734924   0.10963513\n",
      "  0.         1.1019973  0.         0.6246519  0.03894034 0.\n",
      "  0.1532093  0.87867486 0.8568987  0.91028804]]\n",
      "Hi!\n",
      "[[0.6754736  0.         1.1154287  0.07305072 0.         0.6736105\n",
      "  1.0159562  1.013191   1.0087227  0.         0.49093282 0.\n",
      "  0.         0.         0.         0.5609691  0.5151622  0.8637414\n",
      "  0.         0.         1.0420531  0.39089856 0.         0.58704895\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16672961 0.         0.08132277 0.\n",
      "  0.         0.87280595 0.         0.82153094 0.06255432 0.\n",
      "  0.         1.4494009  0.         0.33231598 0.         0.\n",
      "  0.         0.9761644  0.43101624 0.07675215 0.50608987 0.\n",
      "  0.         0.4130131  0.         0.28893563 0.         0.\n",
      "  0.         1.2056872  0.8018831  0.23988248]]\n",
      "Hi!\n",
      "[[0.         0.01381441 0.0468986  0.         0.         0.05127145\n",
      "  0.10944215 0.18770348 0.         0.14117725 0.12388261 0.\n",
      "  0.         0.09600708 0.         0.00540586 0.         0.03080362\n",
      "  0.         0.09026515 0.03678357 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00998785 0.15543777 0.         0.         0.\n",
      "  0.         0.         0.09871075 0.14846635 0.         0.\n",
      "  0.         0.         0.17497498 0.34147578 0.         0.\n",
      "  0.14242554 0.01404989 0.         0.19852833 0.05850914 0.14226964\n",
      "  0.         0.18044956 0.         0.         0.00249688 0.\n",
      "  0.05023617 0.04329621 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.77032804 0.         1.3855672  0.         0.         0.8735456\n",
      "  0.6573555  0.810731   0.9568223  0.         0.56847775 0.\n",
      "  0.         0.         0.         0.5153673  0.38731456 0.77248424\n",
      "  0.         0.         1.1386508  0.08008628 0.         0.5629462\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11559001 0.3039235  0.10238273 0.         0.06120846 0.\n",
      "  0.         0.84921795 0.         0.734362   0.03349589 0.\n",
      "  0.         1.0230386  0.         0.42214444 0.         0.2401625\n",
      "  0.         0.93701404 0.43654716 0.27599877 0.64817834 0.0735265\n",
      "  0.         0.6166018  0.         0.20090702 0.         0.\n",
      "  0.         0.94085443 1.1026078  0.364094  ]]\n",
      "Hi!\n",
      "[[0.26099533 0.34584516 0.7030571  0.         0.         0.7532084\n",
      "  0.         0.04339904 0.12995835 0.07075555 0.38824502 0.\n",
      "  0.04349454 0.         0.         0.         0.         0.02399571\n",
      "  0.         0.7139266  0.3368466  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00469277 0.26603416 0.03710797 0.         0.         0.\n",
      "  0.         0.02867271 0.07807429 0.3476806  0.         0.\n",
      "  0.         0.         0.2949517  0.6122949  0.         0.44208527\n",
      "  0.48832613 0.31526837 0.         0.5366424  0.32309505 0.7256148\n",
      "  0.         0.70378476 0.         0.         0.12938914 0.\n",
      "  0.06974214 0.         0.2784997  0.        ]]\n",
      "Hi!\n",
      "[[9.7434521e-01 1.7671183e-01 1.9064928e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.3431807e-01 2.5267756e-01 1.4562270e-01 1.1328062e+00 0.0000000e+00\n",
      "  7.3709238e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.1047319e-01 9.3721443e-01 8.8989127e-01 0.0000000e+00 1.6945852e-01\n",
      "  1.4304996e+00 4.2373791e-01 0.0000000e+00 6.1806726e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0941568e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.6360197e-01 0.0000000e+00 1.0231481e+00\n",
      "  1.3539884e-03 0.0000000e+00 0.0000000e+00 1.1729386e+00 0.0000000e+00\n",
      "  1.6457738e-01 0.0000000e+00 4.3385455e-01 1.3727187e-01 9.2899626e-01\n",
      "  5.6800240e-01 0.0000000e+00 3.1552890e-01 0.0000000e+00 0.0000000e+00\n",
      "  7.1665412e-01 0.0000000e+00 7.1924829e-01 1.2582690e-01 0.0000000e+00\n",
      "  2.2150581e-01 9.7430539e-01 6.7527521e-01 8.4517318e-01]]\n",
      "Hi!\n",
      "[[0.51917595 0.         0.13337605 0.53070056 0.         0.72822744\n",
      "  1.409502   1.7227503  0.         0.         0.15445325 0.\n",
      "  0.2824902  0.5255153  0.         0.14985615 0.         0.41217288\n",
      "  0.         0.16830789 0.23620568 0.12193821 0.         0.04880152\n",
      "  0.         0.         0.         0.679546   0.         0.\n",
      "  1.2716461  0.69984573 0.288752   0.         0.66992944 0.\n",
      "  0.         0.9389167  0.11130039 0.24830648 0.23390748 0.\n",
      "  0.         0.30931994 1.2011253  1.4545023  0.         0.\n",
      "  0.         0.9401363  0.05059127 0.7097951  0.9916725  0.63653487\n",
      "  0.         0.38977623 0.31096905 0.         0.         0.\n",
      "  0.         0.5054149  0.95163566 0.        ]]\n",
      "Hi!\n",
      "[[0.38964346 0.07984327 0.0213408  0.264026   0.         0.6653847\n",
      "  1.2299899  1.313086   0.         0.         0.16516581 0.\n",
      "  0.07938428 0.50301033 0.         0.02333432 0.         0.3574187\n",
      "  0.         0.36822703 0.1297372  0.06824318 0.         0.\n",
      "  0.         0.         0.         0.31879148 0.         0.\n",
      "  0.99900156 0.550569   0.37499425 0.         0.4809516  0.\n",
      "  0.         0.61446726 0.06783566 0.34698033 0.05857109 0.\n",
      "  0.         0.21182288 0.9612525  1.254678   0.         0.\n",
      "  0.20729646 1.0217435  0.         0.65262485 0.8041382  0.6388754\n",
      "  0.         0.5225524  0.18134673 0.         0.         0.\n",
      "  0.         0.42099744 0.40790796 0.        ]]\n",
      "Hi!\n",
      "[[0.17048956 0.11878547 1.0218452  0.         0.         0.5819217\n",
      "  0.7104193  0.7781968  1.4352924  0.         0.6028403  0.\n",
      "  0.87599176 0.         0.         0.9998931  0.02780353 0.86378926\n",
      "  0.7586804  0.         1.0787754  0.24408346 0.         0.14374343\n",
      "  0.2910671  0.         0.         0.20292753 0.         0.\n",
      "  0.49803063 0.19662857 0.         0.         0.48224753 0.\n",
      "  0.49991456 1.3265767  0.         0.6389934  0.21202649 0.\n",
      "  0.         1.0391647  0.11187024 0.12319197 0.         0.77772194\n",
      "  0.         0.822045   0.9842681  0.19071089 0.22817257 0.08456754\n",
      "  0.         0.         0.17332365 0.41224703 0.         0.\n",
      "  0.         0.9963454  1.2960517  0.820621  ]]\n",
      "Hi!\n",
      "[[1.3056879  0.         2.003133   0.         0.         1.0981095\n",
      "  0.7536682  0.8737943  1.5354475  0.         0.71766704 0.\n",
      "  0.         0.         0.         0.7536442  1.2387419  0.9419371\n",
      "  0.         0.         1.6166109  0.8132228  0.         1.034323\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.24656399 0.         0.         0.\n",
      "  0.         0.86583525 0.         1.1327604  0.2093027  0.\n",
      "  0.         2.1242692  0.         0.1720551  0.         0.08948452\n",
      "  0.         1.2209448  0.72293174 0.         0.5750446  0.\n",
      "  0.         0.9822421  0.         0.90004927 0.         0.\n",
      "  0.0177247  1.360184   1.0079589  0.69205236]]\n",
      "Hi!\n",
      "[[0.64650863 0.08244054 0.         0.5169742  0.         0.6495438\n",
      "  1.4202117  1.7263769  0.         0.         0.12212232 0.\n",
      "  0.83534324 0.8233979  0.         0.22850086 0.         0.4864025\n",
      "  0.04659694 0.1466945  0.2450104  0.26407784 0.         0.\n",
      "  0.18994346 0.         0.         0.8689696  0.         0.\n",
      "  1.4265404  0.86579484 0.33537287 0.         0.8242552  0.\n",
      "  0.3588776  1.1561527  0.25226837 0.19533834 0.2553461  0.\n",
      "  0.         0.5446505  1.5617756  1.4621615  0.         0.5011942\n",
      "  0.         0.8802543  0.33544454 0.69227016 0.7353332  1.1677303\n",
      "  0.         0.0780417  0.62020606 0.         0.         0.\n",
      "  0.         0.4000736  0.9315654  0.        ]]\n",
      "Hi!\n",
      "[[0.10463191 0.4466659  0.22744453 0.         0.         0.19649534\n",
      "  0.         0.06072782 0.04086598 0.         0.2073679  0.\n",
      "  0.46200457 0.3149834  0.         0.         0.         0.07921837\n",
      "  0.         0.3172896  0.15073465 0.         0.         0.01407988\n",
      "  0.         0.         0.         0.08774155 0.         0.\n",
      "  0.25608775 0.27907464 0.07310397 0.         0.         0.\n",
      "  0.         0.         0.3896996  0.05234601 0.         0.\n",
      "  0.         0.         0.28425574 0.19226441 0.         0.14612696\n",
      "  0.24601227 0.1590545  0.02138666 0.20880152 0.1648826  0.58601433\n",
      "  0.         0.07290834 0.20408423 0.         0.01452793 0.\n",
      "  0.11578567 0.07801794 0.01891429 0.        ]]\n",
      "Hi!\n",
      "[[0.08868669 0.29549628 0.11219168 0.         0.         0.08918232\n",
      "  0.         0.0757105  0.         0.00556056 0.13091703 0.\n",
      "  0.24248438 0.22655518 0.         0.01766589 0.         0.06932198\n",
      "  0.         0.20490937 0.10034877 0.         0.         0.\n",
      "  0.         0.         0.         0.00698401 0.         0.\n",
      "  0.13088702 0.19548538 0.1355206  0.         0.         0.\n",
      "  0.         0.         0.23378406 0.04226638 0.         0.\n",
      "  0.         0.         0.24461873 0.24745016 0.         0.05784342\n",
      "  0.19530483 0.14516442 0.         0.14542544 0.05527915 0.44759315\n",
      "  0.         0.03995974 0.13448663 0.         0.00435593 0.\n",
      "  0.1560423  0.06961387 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.47838104 0.15846165 0.6295583  0.29845047 0.         0.9686195\n",
      "  0.7371895  1.2495471  0.17918608 0.         0.2721606  0.\n",
      "  0.5015329  0.10864878 0.         0.         0.         0.32518587\n",
      "  0.         0.46470347 0.5488925  0.         0.         0.\n",
      "  0.         0.         0.         0.31527212 0.         0.\n",
      "  0.9636259  0.67228276 0.04911343 0.         0.27909622 0.\n",
      "  0.         0.6943474  0.00729357 0.38205802 0.03073326 0.\n",
      "  0.         0.08677138 0.8724044  1.1329619  0.         0.22681823\n",
      "  0.20829839 0.9257069  0.10070062 0.7404477  1.1200943  0.70147324\n",
      "  0.         0.6844752  0.13845089 0.         0.         0.\n",
      "  0.         0.3511298  1.0571421  0.        ]]\n",
      "Hi!\n",
      "[[0.65882045 0.3558562  1.9943591  0.         0.         0.778125\n",
      "  0.3007238  0.02841016 1.810032   0.         0.8824513  0.\n",
      "  0.9038126  0.         0.         1.1802716  0.756006   1.1158516\n",
      "  0.73223007 0.         1.6421999  0.54040027 0.         0.55230844\n",
      "  0.297922   0.         0.         0.         0.         0.\n",
      "  0.         0.1346587  0.         0.         0.03279389 0.\n",
      "  0.63182306 1.2338694  0.         1.165212   0.17036292 0.\n",
      "  0.         1.2601602  0.         0.         0.         1.1077787\n",
      "  0.         1.108217   1.1313069  0.         0.139879   0.07136485\n",
      "  0.         0.         0.         1.0763171  0.09068429 0.\n",
      "  0.         1.1732746  1.3729861  1.5121921 ]]\n",
      "Hi!\n",
      "[[0.07043185 0.3019667  0.1409421  0.         0.         0.16560651\n",
      "  0.         0.09173681 0.0283825  0.05304086 0.19172448 0.\n",
      "  0.25847495 0.21020304 0.         0.         0.         0.09424032\n",
      "  0.         0.22425571 0.12984134 0.         0.         0.\n",
      "  0.         0.         0.         0.01018506 0.         0.\n",
      "  0.1694271  0.1890125  0.08411411 0.         0.         0.\n",
      "  0.         0.         0.20430283 0.06164421 0.         0.\n",
      "  0.         0.         0.22760217 0.19997212 0.         0.09573517\n",
      "  0.15946196 0.10171037 0.00364098 0.12921722 0.08103552 0.36981985\n",
      "  0.         0.02001619 0.10748054 0.         0.05849919 0.\n",
      "  0.10487136 0.08284499 0.         0.00200057]]\n",
      "Hi!\n",
      "[[0.32610974 0.50686175 0.94357514 0.         0.         0.6902578\n",
      "  0.28127792 0.5035203  0.6510766  0.         0.46218964 0.\n",
      "  0.6024811  0.         0.         0.29412284 0.         0.6437633\n",
      "  0.         0.3202277  0.76292044 0.         0.         0.2818609\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.46035478 0.39616275 0.         0.         0.06358301 0.\n",
      "  0.         0.49284887 0.         0.5479805  0.         0.\n",
      "  0.         0.31564602 0.13297403 0.5358121  0.         0.25648263\n",
      "  0.04993166 1.0154338  0.39571232 0.3515612  0.7771815  0.3206237\n",
      "  0.         0.17491162 0.         0.         0.01191312 0.\n",
      "  0.         0.6884132  0.5218417  0.33213818]]\n",
      "Hi!\n",
      "[[0.4931693  0.         0.         0.7318483  0.         0.4215701\n",
      "  2.0954213  2.273482   0.         0.         0.00653792 0.\n",
      "  0.82271117 1.1528755  0.         0.48543215 0.         0.5260842\n",
      "  0.03345169 0.         0.0587849  0.61863774 0.         0.\n",
      "  0.43150944 0.         0.         1.0912222  0.         0.\n",
      "  1.7143048  0.7413991  0.61233497 0.         1.0663482  0.\n",
      "  0.47554103 1.4011837  0.29788408 0.25288776 0.42436025 0.\n",
      "  0.         0.8564756  1.8052486  1.7140626  0.         0.32713246\n",
      "  0.         1.0206195  0.6126473  0.67120373 0.83605045 1.2426841\n",
      "  0.         0.         0.6988211  0.         0.         0.\n",
      "  0.         0.545437   0.6840397  0.        ]]\n",
      "Hi!\n",
      "[[0.7846917  0.         1.3221549  0.06450809 0.         0.7828794\n",
      "  1.1273569  1.2052497  1.2346522  0.         0.54378176 0.\n",
      "  0.         0.         0.         0.7404672  0.5217169  0.85884213\n",
      "  0.         0.         1.2179523  0.37107018 0.         0.66137856\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10687184 0.12465698 0.10584112 0.         0.18593127 0.\n",
      "  0.         1.1646433  0.         0.75522757 0.11710447 0.\n",
      "  0.         1.5001824  0.         0.35552767 0.         0.17049222\n",
      "  0.         0.84846336 0.5327878  0.17163359 0.5446227  0.\n",
      "  0.         0.4202216  0.         0.42721945 0.         0.\n",
      "  0.         1.2132672  1.3112926  0.389803  ]]\n",
      "Hi!\n",
      "[[0.53715134 1.250165   0.8726692  0.         0.         0.4038077\n",
      "  0.13365822 0.5412416  1.3657932  0.         0.62220585 0.\n",
      "  2.5951567  0.46664873 0.         1.1031597  0.         0.8554783\n",
      "  1.7654449  0.29257235 1.0095801  0.09472282 0.         0.15354916\n",
      "  0.5186466  0.         0.         0.64803135 0.         0.\n",
      "  1.1876252  0.8884878  0.         0.         0.6109458  0.\n",
      "  0.94400984 1.2074224  0.2637035  0.60633385 0.124318   0.\n",
      "  0.         0.49626264 0.9174724  0.09940492 0.         1.5127017\n",
      "  0.         1.0469129  1.3710583  0.3121215  0.44435665 1.1038805\n",
      "  0.         0.         0.5371419  0.         0.03249864 0.\n",
      "  0.         0.47846216 1.3963866  0.9791433 ]]\n",
      "Hi!\n",
      "[[0.5923681  0.13777013 1.3278435  0.         0.         0.718054\n",
      "  0.58780414 0.41897053 0.97266555 0.         0.5023367  0.\n",
      "  0.25742802 0.         0.         0.62160367 0.42004386 0.9184756\n",
      "  0.06438916 0.11650064 1.0237287  0.23941696 0.         0.12039132\n",
      "  0.23646489 0.         0.         0.         0.         0.\n",
      "  0.11678544 0.11815917 0.         0.         0.2459121  0.\n",
      "  0.39862254 1.0799397  0.         0.734851   0.02288965 0.\n",
      "  0.         0.8712561  0.0577117  0.12627262 0.         0.8657665\n",
      "  0.         0.6778829  0.523466   0.12388393 0.1941344  0.4084329\n",
      "  0.         0.0383025  0.05964415 0.4525911  0.         0.\n",
      "  0.         0.94325924 0.9211529  0.66992265]]\n",
      "Hi!\n",
      "[[0.3504218  0.         0.         0.5530018  0.         0.6516356\n",
      "  2.153169   2.1224952  0.24059549 0.         0.10847151 0.\n",
      "  0.22071116 0.39319858 0.         0.4192353  0.         0.60602045\n",
      "  0.         0.         0.31312275 0.333919   0.         0.\n",
      "  0.16138539 0.         0.         0.7348838  0.         0.\n",
      "  1.3569305  0.44111088 0.2588375  0.         0.91905636 0.\n",
      "  0.054401   1.396353   0.         0.24921657 0.3950821  0.\n",
      "  0.         0.8254095  1.129659   1.4225096  0.         0.\n",
      "  0.         1.0013727  0.3339688  0.66259533 0.8289058  0.46928686\n",
      "  0.         0.02489154 0.38338023 0.         0.         0.\n",
      "  0.         0.8236123  1.1755688  0.        ]]\n",
      "Hi!\n",
      "[[0.6426591  0.27603394 0.9396189  0.         0.         0.8654588\n",
      "  0.1706147  0.31174827 0.19231795 0.1462241  0.37960717 0.\n",
      "  0.         0.         0.         0.15270762 0.1682498  0.5153452\n",
      "  0.         0.59112155 0.5725943  0.         0.         0.14263263\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25260288 0.12939632 0.         0.         0.\n",
      "  0.         0.14469923 0.         0.56539136 0.         0.\n",
      "  0.         0.31564826 0.07963421 0.62712556 0.         0.16819008\n",
      "  0.3861371  0.80230826 0.01444181 0.331675   0.4979606  0.28168717\n",
      "  0.         0.8714194  0.         0.         0.05501365 0.\n",
      "  0.41972467 0.59941465 0.15837713 0.06731059]]\n",
      "Hi!\n",
      "[[0.13989435 0.19213118 0.58318365 0.         0.         0.38229927\n",
      "  0.8582854  0.93547803 1.0449706  0.         0.44310713 0.\n",
      "  0.7736779  0.         0.         0.82281905 0.         0.7557819\n",
      "  0.35944688 0.         0.7768434  0.04625032 0.         0.\n",
      "  0.22137773 0.         0.         0.18367085 0.         0.\n",
      "  0.7097039  0.17307056 0.         0.         0.5580156  0.\n",
      "  0.24371646 1.2107093  0.         0.4218796  0.11971958 0.\n",
      "  0.         0.80365187 0.2818812  0.35387373 0.         0.4701293\n",
      "  0.         0.66728026 0.7954519  0.23102838 0.35816252 0.10471459\n",
      "  0.         0.         0.16007085 0.03348306 0.         0.\n",
      "  0.         0.8883823  0.9733425  0.48025003]]\n",
      "Hi!\n",
      "[[0.5973427  0.         0.         0.86227274 0.         0.7324667\n",
      "  2.098047   2.2993174  0.         0.         0.         0.\n",
      "  0.22812504 0.76674044 0.         0.3214684  0.         0.45697826\n",
      "  0.         0.06284865 0.04616265 0.5216834  0.         0.\n",
      "  0.13323773 0.         0.         0.9423273  0.         0.\n",
      "  1.5337958  0.81191725 0.8377026  0.         0.88171166 0.\n",
      "  0.25576997 1.2148015  0.40991607 0.2059731  0.39128026 0.\n",
      "  0.         0.79980755 1.8258225  1.8605275  0.         0.24121486\n",
      "  0.07251579 1.0107235  0.06171763 0.81308395 0.87415147 1.2922611\n",
      "  0.         0.47125417 0.70956206 0.         0.         0.\n",
      "  0.         0.59649825 0.85208553 0.        ]]\n",
      "Hi!\n",
      "[[0.61427414 0.5171407  0.7536303  0.05860207 0.         0.8954\n",
      "  0.27927083 0.5755954  0.         0.         0.3728931  0.\n",
      "  0.7923846  0.28249192 0.         0.03549909 0.         0.4659138\n",
      "  0.         0.7656002  0.5050067  0.         0.         0.06584896\n",
      "  0.         0.         0.         0.2585463  0.         0.\n",
      "  0.7600189  0.8602052  0.         0.         0.20718065 0.\n",
      "  0.0804082  0.5439138  0.26875928 0.39853984 0.         0.\n",
      "  0.         0.15834372 1.0222946  0.86307925 0.         0.7406888\n",
      "  0.44961107 0.690546   0.1641815  0.58903694 0.6539864  1.1103541\n",
      "  0.         0.6285642  0.23905092 0.         0.0028029  0.\n",
      "  0.         0.1261325  0.8277762  0.        ]]\n",
      "Hi!\n",
      "[[0.88579834 0.         1.5799193  0.05484448 0.         0.8506639\n",
      "  1.159915   1.2627361  1.5617896  0.         0.62849075 0.\n",
      "  0.         0.         0.         0.9328707  0.75470173 0.9350807\n",
      "  0.         0.         1.4074928  0.5129856  0.         0.77083385\n",
      "  0.         0.         0.         0.01827322 0.         0.\n",
      "  0.08217793 0.19762444 0.10857021 0.         0.17225823 0.\n",
      "  0.14435162 1.2823251  0.         0.84942406 0.27259672 0.\n",
      "  0.         1.8558893  0.         0.20065917 0.         0.3135137\n",
      "  0.         0.8340596  0.7898448  0.18488659 0.62359726 0.\n",
      "  0.         0.47363865 0.         0.6854023  0.         0.\n",
      "  0.         1.3174651  1.5902408  0.63515013]]\n",
      "Hi!\n",
      "[[0.33960673 0.         0.25376582 0.238454   0.         0.6208402\n",
      "  1.608366   1.7734464  0.7018645  0.         0.30260414 0.\n",
      "  0.71414024 0.22332127 0.         0.67505693 0.         0.68436617\n",
      "  0.24873121 0.         0.55482453 0.2775759  0.         0.\n",
      "  0.2530015  0.         0.         0.6552524  0.         0.\n",
      "  1.2621479  0.4649094  0.         0.         0.9197379  0.\n",
      "  0.3133216  1.4581513  0.         0.21883908 0.3072782  0.\n",
      "  0.         0.83252513 0.90039635 1.0592848  0.         0.31152397\n",
      "  0.         0.7881404  0.6453173  0.52430826 0.6603619  0.4612415\n",
      "  0.         0.         0.4693032  0.         0.         0.\n",
      "  0.         0.7106761  1.4363141  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.04532488 0.         0.         0.         0.\n",
      "  0.16906077 0.3237789  0.         0.06869101 0.05463366 0.\n",
      "  0.         0.19641103 0.         0.01772722 0.         0.08635985\n",
      "  0.         0.02232543 0.0598986  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06171964 0.03667401 0.23061505 0.         0.         0.\n",
      "  0.         0.         0.19370173 0.081721   0.         0.\n",
      "  0.         0.         0.22061338 0.40836906 0.         0.\n",
      "  0.17645217 0.0859723  0.         0.22333774 0.         0.31719524\n",
      "  0.         0.15137446 0.0640215  0.         0.         0.\n",
      "  0.08790893 0.16914937 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.59619194 0.         0.12099919 0.6442819  0.         0.8669748\n",
      "  1.7081198  1.7815932  0.         0.         0.01405938 0.\n",
      "  0.         0.289486   0.         0.13826208 0.         0.463053\n",
      "  0.         0.31474108 0.14521898 0.16123004 0.         0.\n",
      "  0.         0.         0.         0.52045715 0.         0.\n",
      "  1.0696707  0.80324745 0.52985334 0.         0.5224365  0.\n",
      "  0.         0.89075154 0.25893885 0.34044075 0.23937067 0.\n",
      "  0.         0.32827514 1.3526955  1.5626634  0.         0.11161874\n",
      "  0.23931459 0.9618838  0.         0.8011414  0.88625014 0.975825\n",
      "  0.         0.8456847  0.41346544 0.         0.         0.\n",
      "  0.         0.5291118  0.80608666 0.        ]]\n",
      "Hi!\n",
      "[[0.4783223  0.7551243  0.21424817 0.02983517 0.         0.4100318\n",
      "  0.09762698 0.46206895 0.         0.         0.21332458 0.\n",
      "  0.7214555  0.6390798  0.         0.         0.         0.24979271\n",
      "  0.         0.78694415 0.10386249 0.         0.         0.22255497\n",
      "  0.         0.         0.         0.21249619 0.         0.\n",
      "  0.77123165 0.6624122  0.23834196 0.         0.1318769  0.\n",
      "  0.         0.19223039 0.535098   0.13460833 0.         0.\n",
      "  0.         0.         0.9419972  0.85484374 0.         0.36390197\n",
      "  0.49844378 0.5958124  0.         0.46364394 0.5616224  0.99392045\n",
      "  0.         0.3854739  0.29971102 0.         0.         0.\n",
      "  0.00799243 0.10737491 0.09819002 0.        ]]\n",
      "Hi!\n",
      "[[0.04118948 0.15040293 0.39049774 0.         0.         0.13645755\n",
      "  0.         0.19129264 0.00334732 0.         0.05567328 0.\n",
      "  0.19212787 0.1264029  0.         0.01844878 0.         0.\n",
      "  0.         0.11079793 0.10264469 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10449352 0.20992796 0.18560037 0.         0.         0.\n",
      "  0.         0.01852303 0.29449934 0.07534248 0.         0.\n",
      "  0.         0.         0.31410313 0.3080449  0.         0.13902864\n",
      "  0.0955713  0.07293014 0.         0.27025542 0.18105711 0.46784556\n",
      "  0.         0.14828415 0.06994633 0.         0.         0.\n",
      "  0.         0.00155609 0.04827274 0.01932987]]\n",
      "Hi!\n",
      "[[0.81117165 0.         0.93305546 0.44843805 0.         1.1438645\n",
      "  1.3048843  1.3530794  0.25567323 0.10122104 0.32267419 0.\n",
      "  0.         0.         0.         0.21934597 0.23849884 0.6151126\n",
      "  0.         0.09242762 0.66737264 0.         0.         0.42380646\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15403068 0.38465565 0.2772559  0.         0.00486777 0.\n",
      "  0.         0.51280916 0.         0.9048197  0.10651496 0.\n",
      "  0.         1.0332698  0.139345   0.97224265 0.         0.\n",
      "  0.16120222 1.2055184  0.         0.50770056 1.0597214  0.11848518\n",
      "  0.         1.307958   0.         0.         0.         0.\n",
      "  0.22064538 0.8844611  0.7251847  0.        ]]\n",
      "Hi!\n",
      "[[0.41101342 0.3034684  0.5364286  0.         0.         0.87643296\n",
      "  0.65185225 0.78721136 0.17709653 0.1711116  0.2837593  0.\n",
      "  0.         0.         0.         0.06070432 0.         0.41146752\n",
      "  0.         0.51732093 0.49266696 0.         0.         0.27338594\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13822329 0.17263356 0.14359349 0.         0.         0.\n",
      "  0.         0.18471004 0.         0.6755056  0.         0.\n",
      "  0.         0.35755965 0.1565524  0.94220394 0.         0.\n",
      "  0.3427022  1.0662782  0.10069484 0.39892656 0.7811173  0.17052032\n",
      "  0.         0.51956993 0.         0.         0.         0.\n",
      "  0.22315247 0.79277116 0.02402094 0.        ]]\n",
      "Hi!\n",
      "[[0.524555   0.00806779 0.41469583 0.588152   0.         1.1167066\n",
      "  1.2409172  1.4728504  0.         0.05763789 0.09338896 0.\n",
      "  0.         0.1274551  0.         0.14369689 0.         0.41104546\n",
      "  0.         0.51161796 0.29609182 0.         0.         0.\n",
      "  0.         0.         0.         0.1194044  0.         0.\n",
      "  0.68212575 0.68314457 0.4098797  0.         0.12945867 0.\n",
      "  0.         0.46394297 0.06102783 0.48271346 0.05849505 0.\n",
      "  0.         0.3040915  0.922093   1.3407631  0.         0.\n",
      "  0.3502492  1.1305518  0.         0.86202735 1.0986891  0.6223856\n",
      "  0.         1.1177922  0.         0.         0.         0.\n",
      "  0.14456506 0.5380401  0.5739421  0.        ]]\n",
      "Hi!\n",
      "[[1.0108999  0.         1.2359791  0.42598155 0.         1.0608013\n",
      "  1.5208824  1.5083562  0.91481096 0.         0.44100913 0.\n",
      "  0.         0.         0.         0.41596353 0.6435607  0.8595948\n",
      "  0.         0.         1.0486164  0.32518604 0.         0.7237408\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00560625 0.13022557 0.29813558 0.         0.02633165 0.\n",
      "  0.         0.8922835  0.         1.0324194  0.21397328 0.\n",
      "  0.         1.7113931  0.         0.6163485  0.         0.\n",
      "  0.         1.2205484  0.29441515 0.25790405 0.968308   0.\n",
      "  0.         1.104953   0.         0.16450576 0.         0.\n",
      "  0.         1.2284617  1.1536746  0.        ]]\n",
      "Hi!\n",
      "[[0.34748402 0.07867616 0.16426784 0.18169346 0.         0.45665708\n",
      "  1.0282933  1.3164092  0.20228934 0.         0.28109652 0.\n",
      "  0.4686546  0.47208816 0.         0.31067377 0.         0.48572025\n",
      "  0.         0.16676818 0.32711464 0.0615596  0.         0.09208333\n",
      "  0.         0.         0.         0.5617926  0.         0.\n",
      "  1.1997782  0.58347976 0.10391185 0.         0.66408515 0.\n",
      "  0.         0.8442105  0.10205773 0.197169   0.10984851 0.\n",
      "  0.         0.31388047 0.9438026  1.1168611  0.         0.\n",
      "  0.         0.9133965  0.21940368 0.5122997  0.80574757 0.5077354\n",
      "  0.         0.         0.24074264 0.         0.         0.\n",
      "  0.         0.55143297 0.7238565  0.        ]]\n",
      "Hi!\n",
      "[[0.5273375  0.         0.78311896 0.14765455 0.         0.8345785\n",
      "  1.2386552  1.2755307  0.6291397  0.         0.36982942 0.\n",
      "  0.00751863 0.         0.         0.4268705  0.         0.68001413\n",
      "  0.         0.         0.7828811  0.00855375 0.         0.1615924\n",
      "  0.         0.         0.         0.05861188 0.         0.\n",
      "  0.51179147 0.33455306 0.07008703 0.         0.41606972 0.\n",
      "  0.         1.0580893  0.         0.5823946  0.09304152 0.\n",
      "  0.         0.8768296  0.31971487 0.7367481  0.         0.16618034\n",
      "  0.         0.9001765  0.35814363 0.44577172 0.6159497  0.25767\n",
      "  0.         0.36141837 0.         0.         0.         0.\n",
      "  0.         0.89374846 1.085052   0.00266406]]\n",
      "Hi!\n",
      "[[0.2518956  0.         0.42081136 0.16042331 0.         0.6983671\n",
      "  1.7080967  1.836095   1.0895693  0.         0.39243793 0.\n",
      "  0.8435236  0.04000168 0.         0.9380223  0.         0.8108606\n",
      "  0.65755916 0.         0.7488677  0.32532537 0.         0.\n",
      "  0.39519176 0.         0.         0.84645444 0.         0.\n",
      "  1.2689937  0.38867941 0.         0.         0.9798958  0.\n",
      "  0.5969008  1.6801488  0.         0.23250298 0.38432392 0.\n",
      "  0.         1.1778171  0.8298234  0.92716247 0.         0.50067055\n",
      "  0.         0.74422234 0.8878004  0.5228902  0.43417865 0.3706107\n",
      "  0.         0.         0.5664858  0.         0.         0.\n",
      "  0.         0.8495469  1.7214818  0.18693809]]\n",
      "Hi!\n",
      "[[0.04269798 0.29612774 0.08321532 0.         0.         0.14936683\n",
      "  0.         0.150647   0.         0.00453732 0.14238226 0.\n",
      "  0.20522477 0.22813797 0.         0.03390209 0.         0.06528157\n",
      "  0.         0.25398788 0.04141067 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10340928 0.20501679 0.12293515 0.         0.         0.\n",
      "  0.         0.         0.22581337 0.05303649 0.         0.\n",
      "  0.         0.         0.2379084  0.30866605 0.         0.05159419\n",
      "  0.1516493  0.2010856  0.         0.16850993 0.09349045 0.4848705\n",
      "  0.         0.0468632  0.11739621 0.         0.         0.\n",
      "  0.07543984 0.1397197  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.05959712 0.17651519 0.2469414  0.         0.         0.19172421\n",
      "  0.         0.         0.1113625  0.08965698 0.19752042 0.\n",
      "  0.13219358 0.02648872 0.         0.08168567 0.         0.\n",
      "  0.         0.20843951 0.16117376 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05669555 0.06664408 0.         0.         0.\n",
      "  0.         0.         0.09587328 0.09900605 0.         0.\n",
      "  0.         0.         0.06685487 0.14621305 0.         0.0993318\n",
      "  0.12101702 0.01948781 0.         0.1533647  0.05052495 0.30058372\n",
      "  0.         0.         0.01213283 0.         0.0352304  0.\n",
      "  0.02144771 0.03526124 0.         0.00236321]]\n",
      "Hi!\n",
      "[[0.         0.01595776 0.00573066 0.         0.         0.07937565\n",
      "  0.10410232 0.22097707 0.         0.10689633 0.07058457 0.\n",
      "  0.         0.10667688 0.         0.01922605 0.         0.04582768\n",
      "  0.         0.10003441 0.04826296 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05356639 0.17432943 0.         0.         0.\n",
      "  0.         0.         0.10460593 0.12125129 0.         0.\n",
      "  0.         0.         0.17741524 0.36836544 0.         0.\n",
      "  0.18268107 0.09740433 0.         0.20593311 0.         0.21755\n",
      "  0.         0.17314298 0.         0.         0.         0.\n",
      "  0.08122265 0.1074146  0.         0.        ]]\n",
      "Hi!\n",
      "[[2.1839924e-01 5.4912966e-01 5.5526137e-01 0.0000000e+00 0.0000000e+00\n",
      "  7.4701446e-01 2.6263762e-01 5.9315836e-01 1.9788569e-01 0.0000000e+00\n",
      "  3.4206378e-01 0.0000000e+00 4.6107051e-01 2.3068881e-01 0.0000000e+00\n",
      "  2.6390079e-02 0.0000000e+00 3.5584730e-01 0.0000000e+00 6.6486746e-01\n",
      "  4.3047062e-01 0.0000000e+00 0.0000000e+00 1.5098893e-02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.6868416e-01 3.6346644e-01 0.0000000e+00 0.0000000e+00 8.7911583e-04\n",
      "  0.0000000e+00 0.0000000e+00 2.4730198e-01 0.0000000e+00 2.8194794e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.5951560e-01\n",
      "  8.6915272e-01 0.0000000e+00 3.1953222e-01 1.8070401e-01 7.8735846e-01\n",
      "  1.3929595e-01 4.5661581e-01 7.4551350e-01 5.5746549e-01 0.0000000e+00\n",
      "  2.4686666e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.3476027e-01 2.5678107e-01 5.6299573e-04]]\n",
      "Hi!\n",
      "[[0.87711024 0.39377433 1.857457   0.         0.         0.9100554\n",
      "  0.20891537 0.         1.3244607  0.         0.81054616 0.\n",
      "  0.471235   0.         0.         0.7067198  0.7519333  0.9472551\n",
      "  0.05567177 0.15347144 1.4575129  0.35795647 0.         0.62390375\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18553519 0.         0.         0.         0.\n",
      "  0.15591627 0.7205923  0.         1.0515453  0.06043636 0.\n",
      "  0.         0.9662299  0.         0.01030376 0.         0.7623147\n",
      "  0.02127428 0.96273875 0.7536853  0.08636627 0.42482954 0.07791111\n",
      "  0.         0.4076544  0.         0.7510575  0.13480763 0.\n",
      "  0.         0.92363113 0.9633253  1.1285796 ]]\n",
      "Hi!\n",
      "[[0.05173851 0.13924591 0.23411931 0.         0.         0.08891993\n",
      "  0.         0.         0.12381171 0.08222493 0.13817134 0.\n",
      "  0.09407728 0.         0.         0.10984949 0.         0.06316415\n",
      "  0.         0.17516793 0.12909333 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04409541 0.06017679 0.         0.         0.\n",
      "  0.         0.         0.00602289 0.10083739 0.         0.\n",
      "  0.         0.         0.0159654  0.12212489 0.         0.09719203\n",
      "  0.07600269 0.10362149 0.         0.11894864 0.01452693 0.19101267\n",
      "  0.         0.01158554 0.         0.         0.04245402 0.\n",
      "  0.13627702 0.15278447 0.         0.04551686]]\n",
      "Hi!\n",
      "[[0.29964095 0.         0.18475594 0.44649175 0.         0.82476383\n",
      "  2.060179   2.0298412  0.45010945 0.         0.18017183 0.\n",
      "  0.09682487 0.03063157 0.         0.45667523 0.         0.7079925\n",
      "  0.         0.         0.46581274 0.31254467 0.         0.\n",
      "  0.20777486 0.         0.         0.63979006 0.         0.\n",
      "  1.1527854  0.49296212 0.13509288 0.         0.8503954  0.\n",
      "  0.13985343 1.5110562  0.         0.2935705  0.38284448 0.\n",
      "  0.         0.9492563  1.0267204  1.259961   0.         0.19036289\n",
      "  0.         0.92949486 0.34209514 0.645586   0.53783345 0.48505405\n",
      "  0.         0.076874   0.38691136 0.         0.         0.\n",
      "  0.         0.9407331  1.3610969  0.        ]]\n",
      "Hi!\n",
      "[[0.71548945 0.53960294 0.04971829 0.4553424  0.         0.57539046\n",
      "  0.9561714  1.6994398  0.41631225 0.         0.23848449 0.\n",
      "  1.9785897  1.1120853  0.         0.5421676  0.         0.5715404\n",
      "  0.96316516 0.16041178 0.37993726 0.4363472  0.         0.\n",
      "  0.33882332 0.         0.         1.2113601  0.         0.\n",
      "  1.7885103  1.1404953  0.1186863  0.         0.9979622  0.\n",
      "  0.6639452  1.2650903  0.6564468  0.02735036 0.30025294 0.\n",
      "  0.         0.61568034 1.7378447  1.214957   0.         0.9923225\n",
      "  0.         0.7138127  0.83079046 0.6839034  0.7798792  1.5693858\n",
      "  0.         0.         0.8052066  0.         0.         0.\n",
      "  0.         0.20056486 1.2690132  0.        ]]\n",
      "Hi!\n",
      "[[0.38522434 0.         0.28238064 0.57615423 0.         0.8621233\n",
      "  2.2564456  2.3229635  0.4914942  0.         0.14733909 0.\n",
      "  0.         0.         0.         0.4188058  0.         0.6629758\n",
      "  0.         0.         0.532626   0.22447586 0.         0.\n",
      "  0.         0.         0.         0.56656766 0.         0.\n",
      "  1.0816385  0.37600884 0.22228439 0.         0.7490907  0.\n",
      "  0.         1.3589144  0.         0.49300185 0.41106775 0.\n",
      "  0.         1.1976314  0.7816687  1.2702875  0.         0.\n",
      "  0.         1.0164577  0.20290653 0.69095623 1.0349276  0.100926\n",
      "  0.         0.41362807 0.2214119  0.         0.         0.\n",
      "  0.         0.96569985 1.5437037  0.        ]]\n",
      "Hi!\n",
      "[[0.7662706  0.4656317  1.3381226  0.         0.         1.0979093\n",
      "  0.10751261 0.18326366 0.45669463 0.26912794 0.48379546 0.\n",
      "  0.         0.         0.         0.02520066 0.341734   0.31895387\n",
      "  0.         0.8062363  0.74316716 0.         0.         0.3776706\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20378223 0.19730611 0.         0.         0.\n",
      "  0.         0.21197848 0.         0.6128549  0.         0.\n",
      "  0.         0.08751903 0.00839262 0.55304134 0.         0.47669616\n",
      "  0.4392197  0.8941035  0.08466496 0.3715843  0.7144206  0.3952044\n",
      "  0.         1.1380876  0.         0.         0.12305604 0.\n",
      "  0.4389202  0.47512385 0.35595682 0.3867488 ]]\n",
      "Hi!\n",
      "[[0.31999043 0.         0.6225475  0.27701387 0.         0.79488283\n",
      "  2.2756064  2.1721811  1.25438    0.         0.3889034  0.\n",
      "  0.2209859  0.         0.         1.047871   0.         0.8667306\n",
      "  0.3859799  0.         0.8356605  0.45100754 0.         0.\n",
      "  0.33464313 0.         0.         0.69050264 0.         0.\n",
      "  1.0460193  0.19465816 0.         0.         0.9658187  0.\n",
      "  0.5117762  1.8424089  0.         0.4414118  0.5473336  0.\n",
      "  0.         1.8266966  0.53317255 0.8237141  0.         0.30830008\n",
      "  0.         0.74146956 0.8234659  0.47101098 0.41910794 0.02095539\n",
      "  0.         0.         0.49061707 0.21266386 0.         0.\n",
      "  0.         1.1717945  1.85682    0.09797143]]\n",
      "Hi!\n",
      "[[0.45914575 1.0077862  0.7269942  0.         0.         0.557486\n",
      "  0.         0.09647543 0.         0.         0.38569212 0.\n",
      "  0.94984734 0.43713835 0.         0.         0.         0.28838167\n",
      "  0.         0.9800576  0.326936   0.         0.         0.13881049\n",
      "  0.         0.         0.         0.07652774 0.         0.\n",
      "  0.5156919  0.6980091  0.         0.         0.         0.\n",
      "  0.         0.         0.5900809  0.24808283 0.         0.\n",
      "  0.         0.         0.7116013  0.48863918 0.         0.5092094\n",
      "  0.6372875  0.50554794 0.02913776 0.5805205  0.59694827 1.0227153\n",
      "  0.         0.40436628 0.20812741 0.         0.07293295 0.\n",
      "  0.05726891 0.08089491 0.3369251  0.        ]]\n",
      "Hi!\n",
      "[[0.40842417 0.         0.4664141  0.24177997 0.         0.50892466\n",
      "  1.7009269  1.567508   0.7478844  0.         0.34507188 0.\n",
      "  0.         0.         0.         0.5922107  0.         0.78893393\n",
      "  0.         0.         0.666231   0.14443927 0.         0.13046342\n",
      "  0.01794982 0.         0.         0.1070215  0.         0.\n",
      "  0.53270394 0.03220683 0.19363132 0.         0.56690943 0.\n",
      "  0.         1.1934397  0.         0.6157736  0.22764191 0.\n",
      "  0.         1.303646   0.158636   0.7254197  0.         0.\n",
      "  0.         0.9318155  0.4149533  0.23297487 0.57180077 0.\n",
      "  0.         0.00891488 0.         0.         0.         0.\n",
      "  0.         1.2141024  0.87002707 0.        ]]\n",
      "Hi!\n",
      "[[0.7972894  1.339752   0.3529706  0.         0.         0.42294243\n",
      "  0.         0.5872012  0.22946449 0.         0.37518764 0.\n",
      "  1.9956392  0.83635134 0.         0.1859958  0.         0.305318\n",
      "  0.40007308 0.85595095 0.28663564 0.05896818 0.         0.38899046\n",
      "  0.         0.         0.         0.5897025  0.         0.\n",
      "  1.2158085  1.0064625  0.0562585  0.         0.42413893 0.\n",
      "  0.28352422 0.38054317 0.9957715  0.23677547 0.         0.\n",
      "  0.         0.36429307 1.23342    0.8131487  0.         0.9535995\n",
      "  0.36929718 0.6099635  0.52312356 0.54308873 0.8753645  1.5315758\n",
      "  0.         0.03122531 0.48297095 0.         0.         0.\n",
      "  0.06045491 0.03483437 0.6221265  0.        ]]\n",
      "Hi!\n",
      "[[0.05863186 0.15406829 0.         0.08810396 0.         0.17506233\n",
      "  0.34196365 0.42164716 0.         0.04949645 0.         0.\n",
      "  0.01498461 0.32486376 0.         0.05165945 0.         0.11062913\n",
      "  0.         0.20567524 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.11278709 0.         0.\n",
      "  0.28311598 0.3157408  0.36734468 0.         0.         0.\n",
      "  0.         0.06167507 0.33789384 0.08104732 0.         0.\n",
      "  0.         0.06791907 0.44754565 0.63707376 0.         0.01130033\n",
      "  0.26487222 0.37160313 0.         0.3007281  0.11029108 0.5396743\n",
      "  0.         0.34905744 0.13258581 0.         0.         0.\n",
      "  0.09211356 0.15624583 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5184915  0.41540122 0.7771624  0.04347292 0.         0.8276784\n",
      "  0.16771011 0.25361276 0.         0.         0.18017256 0.\n",
      "  0.30067068 0.00146128 0.         0.         0.         0.23530003\n",
      "  0.         0.77649015 0.28209376 0.         0.         0.\n",
      "  0.         0.         0.         0.01285021 0.         0.\n",
      "  0.28847778 0.663969   0.11780775 0.         0.         0.\n",
      "  0.08037865 0.24601378 0.26093072 0.3926207  0.         0.\n",
      "  0.         0.0930116  0.6446311  0.65626293 0.         0.70317346\n",
      "  0.68922645 0.40570414 0.         0.45719552 0.36317542 1.0411894\n",
      "  0.         0.88470215 0.0822291  0.         0.         0.\n",
      "  0.19277817 0.13907705 0.3890429  0.        ]]\n",
      "Hi!\n",
      "[[0.24234475 0.         0.7282043  0.05966309 0.         0.67041266\n",
      "  1.3962212  1.532686   1.193362   0.         0.44668198 0.\n",
      "  0.5204192  0.         0.         0.88153017 0.         0.80400115\n",
      "  0.32438207 0.         0.91076106 0.151379   0.         0.1115905\n",
      "  0.2128684  0.         0.         0.49728107 0.         0.\n",
      "  0.88271487 0.27029666 0.         0.         0.65555894 0.\n",
      "  0.29302776 1.472393   0.         0.44728926 0.26150706 0.\n",
      "  0.         1.2476707  0.341071   0.66159475 0.         0.34516853\n",
      "  0.         0.7394949  0.7795351  0.41363347 0.52307594 0.03114766\n",
      "  0.         0.         0.26862702 0.10628051 0.         0.\n",
      "  0.         0.9879261  1.5809524  0.33070323]]\n",
      "Hi!\n",
      "[[0.9470459  0.03726089 1.6707675  0.         0.         1.0022019\n",
      "  0.38799837 0.5840425  1.0161463  0.         0.6288599  0.\n",
      "  0.         0.         0.         0.4591386  0.67678314 0.78680694\n",
      "  0.         0.01524896 1.3031363  0.23938383 0.         0.7009798\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20773762 0.12981375 0.         0.         0.\n",
      "  0.         0.69922984 0.         0.8719346  0.         0.\n",
      "  0.         1.1234709  0.         0.23191555 0.         0.2918002\n",
      "  0.02398233 0.95156914 0.4468798  0.21210293 0.6032813  0.05551876\n",
      "  0.         0.86074984 0.         0.4139013  0.         0.\n",
      "  0.00364105 0.90647864 1.0029454  0.5368491 ]]\n",
      "Hi!\n",
      "[[0.         0.20789316 0.34262624 0.         0.         0.2663243\n",
      "  0.         0.         0.1364233  0.10429647 0.24588607 0.\n",
      "  0.05332263 0.         0.         0.06223612 0.         0.\n",
      "  0.         0.30134025 0.20709696 0.         0.         0.00800502\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06642138 0.0245032  0.         0.         0.\n",
      "  0.         0.         0.03445151 0.15364785 0.         0.\n",
      "  0.         0.         0.00758642 0.2515663  0.         0.23080206\n",
      "  0.18184893 0.1259317  0.         0.2358294  0.08863585 0.3050899\n",
      "  0.         0.0862111  0.         0.         0.06750648 0.\n",
      "  0.03758507 0.07668123 0.         0.02348255]]\n",
      "Hi!\n",
      "[[0.76722944 0.10787174 0.         0.631489   0.         0.676986\n",
      "  1.4241444  1.8048989  0.         0.         0.05422936 0.\n",
      "  0.8102471  0.9542451  0.         0.21562883 0.         0.37560317\n",
      "  0.         0.27544683 0.19049191 0.30197355 0.         0.08677098\n",
      "  0.06607988 0.         0.         0.92269015 0.         0.\n",
      "  1.5683643  1.0008423  0.4899198  0.         0.79584223 0.\n",
      "  0.29923803 1.0651935  0.44189927 0.17988251 0.25652793 0.\n",
      "  0.         0.5653089  1.7028683  1.6099708  0.         0.4969388\n",
      "  0.08616827 0.87712234 0.2202432  0.756301   0.84173554 1.2911919\n",
      "  0.         0.33089536 0.673586   0.         0.         0.\n",
      "  0.         0.24560429 0.95081687 0.        ]]\n",
      "Hi!\n",
      "[[0.3226179  0.88020164 1.3571286  0.         0.         0.737532\n",
      "  0.         0.         0.5727676  0.         0.58348507 0.\n",
      "  0.81290823 0.         0.         0.28638068 0.3938932  0.53595513\n",
      "  0.         0.94323605 0.8678855  0.         0.         0.05312309\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3806347  0.         0.         0.         0.\n",
      "  0.         0.117916   0.         0.66852105 0.         0.\n",
      "  0.         0.         0.06243116 0.0426221  0.         0.8854074\n",
      "  0.5541501  0.81285685 0.40583745 0.3235767  0.36686417 0.77968806\n",
      "  0.         0.44707203 0.         0.03158556 0.2557011  0.\n",
      "  0.26789993 0.26477614 0.53831017 0.614806  ]]\n",
      "Hi!\n",
      "[[0.00000000e+00 1.24121465e-01 3.95613769e-03 0.00000000e+00\n",
      "  0.00000000e+00 6.48491904e-02 1.00243613e-01 2.39472955e-01\n",
      "  0.00000000e+00 6.25627562e-02 7.45343268e-02 0.00000000e+00\n",
      "  4.53299768e-02 1.64034158e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.72905321e-02 0.00000000e+00 1.24583639e-01\n",
      "  6.44570217e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.41498587e-02 8.23540315e-02\n",
      "  2.09100932e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.89570963e-01 8.83123651e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.91793889e-01 4.00895834e-01 0.00000000e+00 3.05064459e-04\n",
      "  1.01460010e-01 1.52082980e-01 0.00000000e+00 1.76011771e-01\n",
      "  1.01167254e-01 3.57725680e-01 0.00000000e+00 7.60129765e-02\n",
      "  4.94275391e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.79774401e-02 1.59797296e-01 0.00000000e+00 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.10522544 0.34009308 0.28107473 0.         0.         0.25543386\n",
      "  0.         0.05421575 0.00796006 0.04223169 0.22664177 0.\n",
      "  0.14758343 0.12682511 0.         0.         0.         0.12072758\n",
      "  0.         0.36943573 0.11290594 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04996902 0.16189969 0.03903333 0.         0.         0.\n",
      "  0.         0.         0.10788879 0.15632755 0.         0.\n",
      "  0.         0.         0.2125949  0.35960147 0.         0.1741525\n",
      "  0.2690523  0.17507544 0.         0.2375706  0.12464061 0.4478628\n",
      "  0.         0.15666538 0.00235249 0.         0.03092194 0.\n",
      "  0.08828127 0.08573156 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.22835146 0.22054195 0.67165035 0.         0.         0.529033\n",
      "  0.73732793 0.95404714 0.9328439  0.         0.45392522 0.\n",
      "  0.91258246 0.         0.         0.68091226 0.         0.6984942\n",
      "  0.3134568  0.         0.77083933 0.         0.         0.\n",
      "  0.15713523 0.         0.         0.29152983 0.         0.\n",
      "  0.81872797 0.39221612 0.         0.         0.51271385 0.\n",
      "  0.20513944 1.107505   0.         0.38862553 0.09103255 0.\n",
      "  0.         0.57831717 0.42585623 0.52299666 0.         0.48668495\n",
      "  0.         0.74267256 0.7626285  0.3777939  0.6127258  0.3031471\n",
      "  0.         0.         0.12716514 0.         0.         0.\n",
      "  0.         0.7130335  1.0673977  0.41945848]]\n",
      "Hi!\n",
      "[[0.27470857 0.62359524 0.52267545 0.         0.         0.57253\n",
      "  0.         0.21335377 0.         0.01067103 0.2895153  0.\n",
      "  0.3200356  0.26816815 0.         0.         0.         0.21700165\n",
      "  0.         0.722634   0.23932287 0.         0.         0.08580366\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23950815 0.47241664 0.07514452 0.         0.         0.\n",
      "  0.         0.         0.34961784 0.21161056 0.         0.\n",
      "  0.         0.         0.5166027  0.54393566 0.         0.21084961\n",
      "  0.5417455  0.52457786 0.         0.41466194 0.5491415  0.7844825\n",
      "  0.         0.5504369  0.04234392 0.         0.06410591 0.\n",
      "  0.19237831 0.15614508 0.08026643 0.        ]]\n",
      "Hi!\n",
      "[[0.76474243 0.03655966 0.         0.91779846 0.         0.60963523\n",
      "  1.9238269  2.4255164  0.         0.         0.         0.\n",
      "  1.1738036  1.3121762  0.         0.4194227  0.         0.4152106\n",
      "  0.30235982 0.05251202 0.08928829 0.65038556 0.         0.00393645\n",
      "  0.28199074 0.         0.         1.3596239  0.         0.\n",
      "  2.037209   1.0761209  0.7289479  0.         1.1261258  0.\n",
      "  0.53994626 1.3195814  0.6251735  0.15775065 0.47604135 0.\n",
      "  0.         0.9772403  2.1258776  1.8784949  0.         0.63439566\n",
      "  0.         0.9362095  0.45429292 0.825967   0.9410722  1.6803961\n",
      "  0.         0.08636458 0.9526593  0.         0.         0.\n",
      "  0.         0.2928052  1.010793   0.        ]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04890834 0.24661765 0.41996077 0.         0.         0.35031888\n",
      "  0.         0.         0.13847938 0.09215733 0.2707931  0.\n",
      "  0.11336364 0.         0.         0.02893325 0.         0.0442481\n",
      "  0.         0.4159179  0.23838438 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12027528 0.01731111 0.         0.         0.\n",
      "  0.         0.         0.067911   0.21452677 0.         0.\n",
      "  0.         0.         0.0686525  0.23412414 0.         0.29640627\n",
      "  0.2672049  0.0789684  0.         0.28782758 0.11839297 0.37038794\n",
      "  0.         0.2184529  0.         0.         0.12051884 0.\n",
      "  0.10173659 0.         0.01430329 0.08417747]]\n",
      "Hi!\n",
      "[[5.4617786e-01 2.6203382e-01 1.3216814e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.0116061e-01 1.5783286e-01 1.1446637e-01 9.3185276e-01 0.0000000e+00\n",
      "  5.8537900e-01 0.0000000e+00 3.7156457e-01 0.0000000e+00 0.0000000e+00\n",
      "  5.5163848e-01 4.0002069e-01 7.9977655e-01 1.0206613e-02 1.4042591e-01\n",
      "  1.0567697e+00 1.2978390e-01 0.0000000e+00 3.0238879e-01 6.0349908e-02\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.8307905e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.1650151e-01 7.1735722e-01 0.0000000e+00 7.5202489e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2995380e-01 0.0000000e+00\n",
      "  4.9694747e-02 0.0000000e+00 6.7108631e-01 7.9029356e-04 7.0097810e-01\n",
      "  5.5169600e-01 1.3719560e-01 1.7612831e-01 1.8529367e-01 0.0000000e+00\n",
      "  1.8068387e-01 0.0000000e+00 4.2577794e-01 7.6437183e-02 0.0000000e+00\n",
      "  0.0000000e+00 8.0679870e-01 8.0432785e-01 7.5804007e-01]]\n",
      "Hi!\n",
      "[[0.64202344 0.8227641  1.6352012  0.         0.         1.0097915\n",
      "  0.         0.         0.84139514 0.         0.72882915 0.\n",
      "  0.96790874 0.         0.         0.4538735  0.28902042 0.703843\n",
      "  0.13354868 0.5898814  1.1638575  0.01430731 0.         0.40782067\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20668851 0.46254948 0.         0.         0.         0.\n",
      "  0.00743526 0.47570246 0.         0.8345901  0.         0.\n",
      "  0.         0.23781203 0.1228418  0.06437145 0.         0.84496486\n",
      "  0.32144558 0.7868459  0.4763814  0.36321825 0.52868277 0.5773169\n",
      "  0.         0.478168   0.         0.15363447 0.13215448 0.\n",
      "  0.         0.52761453 0.88566834 0.8818704 ]]\n",
      "Hi!\n",
      "[[0.04529386 0.16089097 0.05403311 0.         0.         0.0637929\n",
      "  0.00271418 0.12981938 0.06532689 0.055207   0.1294644  0.\n",
      "  0.09755772 0.07670653 0.         0.04202913 0.         0.01613278\n",
      "  0.         0.19412363 0.12144983 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04641536 0.15088502 0.         0.         0.\n",
      "  0.         0.         0.10702347 0.06641689 0.         0.\n",
      "  0.         0.         0.08332869 0.27910003 0.         0.05753206\n",
      "  0.11529772 0.06719833 0.         0.17137186 0.00297956 0.3608797\n",
      "  0.         0.02030366 0.03375341 0.         0.00861311 0.\n",
      "  0.03437172 0.12063687 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.78558534 0.2923986  1.289674   0.03915241 0.         1.1066955\n",
      "  0.203208   0.6497637  0.36389685 0.00187087 0.48540372 0.\n",
      "  0.15333472 0.         0.         0.03845119 0.14801973 0.45689234\n",
      "  0.         0.5312699  0.8974624  0.         0.         0.3607461\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24275129 0.60520965 0.10943799 0.         0.         0.\n",
      "  0.         0.40444165 0.         0.6299368  0.         0.\n",
      "  0.         0.30674344 0.33419365 0.68189037 0.         0.25513956\n",
      "  0.3782071  0.9501986  0.06607239 0.5166197  0.952194   0.4725592\n",
      "  0.         1.1419997  0.         0.         0.0415024  0.\n",
      "  0.08303379 0.47951838 0.8712355  0.02337966]]\n",
      "Hi!\n",
      "[[0.18616734 0.17244981 1.0838537  0.         0.         0.5375994\n",
      "  0.6463482  0.88637275 1.6228023  0.         0.61357397 0.\n",
      "  1.1508995  0.         0.         1.0541763  0.06205213 0.8895513\n",
      "  1.0181024  0.         1.153332   0.1957948  0.         0.2078798\n",
      "  0.28504205 0.         0.         0.38434818 0.         0.\n",
      "  0.67000794 0.30138814 0.         0.         0.51317286 0.\n",
      "  0.6626876  1.3648667  0.         0.5931953  0.3261038  0.\n",
      "  0.         1.0743861  0.09551993 0.1307334  0.         0.8579997\n",
      "  0.         0.90185523 1.1557238  0.23893978 0.36094415 0.11319924\n",
      "  0.         0.         0.22640155 0.45832497 0.         0.\n",
      "  0.         0.91660243 1.527833   0.9593414 ]]\n",
      "Hi!\n",
      "[[0.44037327 0.         0.69455516 0.10050575 0.         0.4951783\n",
      "  1.3352867  1.2451671  0.911928   0.         0.411642   0.\n",
      "  0.         0.         0.         0.64129215 0.13507609 0.8329349\n",
      "  0.         0.         0.77657723 0.24325271 0.         0.30082214\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3820088  0.01193872 0.12639917 0.         0.42566442 0.\n",
      "  0.         1.1121978  0.         0.68966717 0.08772235 0.\n",
      "  0.         1.2847707  0.         0.5233627  0.         0.\n",
      "  0.         0.9564819  0.55030394 0.18149538 0.46100923 0.\n",
      "  0.         0.         0.         0.03725243 0.         0.\n",
      "  0.         1.1921186  0.7956603  0.12849303]]\n",
      "Hi!\n",
      "[[0.563904   0.1084705  0.5177202  0.18618976 0.         0.9136982\n",
      "  0.61296535 1.0111854  0.         0.2097962  0.17858188 0.\n",
      "  0.         0.02093817 0.         0.21205531 0.         0.3216197\n",
      "  0.         0.60316473 0.29780406 0.         0.         0.11487412\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1760223  0.38649788 0.         0.         0.\n",
      "  0.         0.27046907 0.         0.80435306 0.         0.\n",
      "  0.         0.36848003 0.296637   1.120235   0.         0.\n",
      "  0.5085961  1.173225   0.         0.5091449  0.9918326  0.2958516\n",
      "  0.         0.96643245 0.         0.         0.         0.\n",
      "  0.4473786  0.7370188  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.49886551 0.05848455 0.6208496  0.2098298  0.         0.8187961\n",
      "  0.7677193  0.6865101  0.         0.         0.14249872 0.\n",
      "  0.01166604 0.         0.         0.11662326 0.         0.32404703\n",
      "  0.         0.5604613  0.3060937  0.         0.         0.\n",
      "  0.         0.         0.         0.12124754 0.         0.\n",
      "  0.42731833 0.7209138  0.03255264 0.         0.12330658 0.\n",
      "  0.         0.61627394 0.14318706 0.29086486 0.         0.\n",
      "  0.         0.12675487 0.6894948  0.815717   0.         0.5061097\n",
      "  0.42489648 0.5324433  0.         0.5199965  0.4503001  0.9260723\n",
      "  0.         0.8117866  0.23029803 0.         0.         0.\n",
      "  0.03197865 0.287715   0.68459386 0.        ]]\n",
      "Hi!\n",
      "[[0.27758834 0.6226376  0.28941718 0.01674877 0.         0.2234959\n",
      "  0.         0.21514703 0.         0.         0.1756565  0.\n",
      "  0.6494428  0.49888617 0.         0.         0.         0.12099782\n",
      "  0.         0.39309648 0.13452363 0.         0.         0.11161108\n",
      "  0.         0.         0.         0.1972306  0.         0.\n",
      "  0.3558593  0.45383433 0.13328369 0.         0.         0.\n",
      "  0.00813182 0.         0.5042241  0.01929209 0.         0.\n",
      "  0.         0.         0.48539865 0.3833067  0.         0.25763905\n",
      "  0.33583298 0.28874454 0.         0.32975858 0.24998432 0.76155055\n",
      "  0.         0.09791622 0.23283072 0.         0.         0.\n",
      "  0.26512718 0.10946644 0.15132485 0.        ]]\n",
      "Hi!\n",
      "[[0.7475777  0.44584146 0.         0.4082383  0.         0.46266735\n",
      "  0.89345384 1.5219922  0.23302487 0.         0.23423108 0.\n",
      "  1.4883307  1.07842    0.         0.46339923 0.         0.4948523\n",
      "  0.52483034 0.25563958 0.31378636 0.29405823 0.         0.17252475\n",
      "  0.17082693 0.         0.         0.9545246  0.         0.\n",
      "  1.578352   1.0039384  0.14742588 0.         0.8512663  0.\n",
      "  0.5176005  1.1200929  0.46271572 0.09126954 0.18262613 0.\n",
      "  0.         0.47828692 1.5799513  1.2147623  0.         0.6681173\n",
      "  0.         0.73972285 0.59585863 0.5730254  0.781739   1.268983\n",
      "  0.         0.         0.6756025  0.         0.         0.\n",
      "  0.         0.21719748 1.0127405  0.        ]]\n",
      "Hi!\n",
      "[[0.81401616 0.         1.3573658  0.         0.         0.80393267\n",
      "  0.6566878  0.6986748  1.045995   0.         0.5582901  0.\n",
      "  0.         0.         0.         0.53021634 0.57911927 0.8435401\n",
      "  0.         0.         1.1534548  0.33427656 0.         0.59685385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10056615 0.09491134 0.         0.         0.\n",
      "  0.         0.7919166  0.         0.84958005 0.02566238 0.\n",
      "  0.         1.220332   0.         0.24299198 0.         0.17853406\n",
      "  0.         0.94173795 0.5087822  0.12448398 0.44759038 0.\n",
      "  0.         0.52939576 0.         0.39193925 0.         0.\n",
      "  0.         1.0655478  0.81200194 0.47078007]]\n",
      "Hi!\n",
      "[[0.6938018  0.4516183  0.8587685  0.18955687 0.         1.1150218\n",
      "  0.35553142 0.74726564 0.         0.         0.33140245 0.\n",
      "  0.43842942 0.23248759 0.         0.         0.         0.25890803\n",
      "  0.         0.966126   0.41661736 0.         0.         0.0512936\n",
      "  0.         0.         0.         0.16158426 0.         0.\n",
      "  0.7117193  0.9302917  0.06980015 0.         0.10434261 0.\n",
      "  0.         0.27743196 0.36210883 0.3250642  0.         0.\n",
      "  0.         0.05789508 1.0054879  1.0978647  0.         0.50330544\n",
      "  0.74664444 0.83153194 0.         0.7814099  0.9817379  1.1018591\n",
      "  0.         1.2176251  0.19346184 0.         0.08113797 0.\n",
      "  0.         0.03417676 0.83769554 0.        ]]\n",
      "Hi!\n",
      "[[0.4884583  0.09789388 0.6593889  0.09192151 0.         0.756608\n",
      "  0.7469389  0.804245   0.2986058  0.02505913 0.35254067 0.\n",
      "  0.         0.         0.         0.1567459  0.         0.6114153\n",
      "  0.         0.23356679 0.58330125 0.         0.         0.15837884\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2507295  0.21854351 0.17710006 0.         0.09695031 0.\n",
      "  0.         0.49229604 0.         0.68126035 0.         0.\n",
      "  0.         0.6679843  0.21928915 0.6773039  0.         0.\n",
      "  0.04809967 0.98916346 0.14911123 0.3093123  0.5821931  0.17802833\n",
      "  0.         0.47702667 0.         0.         0.         0.\n",
      "  0.00308528 0.8085662  0.33975753 0.        ]]\n",
      "Hi!\n",
      "[[0.6848607  1.0582606  0.568118   0.         0.         0.42634818\n",
      "  0.13246156 0.8132952  0.9350785  0.         0.48665315 0.\n",
      "  2.3124824  0.68069965 0.         0.82736826 0.         0.65431595\n",
      "  1.3483214  0.3681757  0.7087934  0.14529558 0.         0.12157676\n",
      "  0.39821845 0.         0.         0.80524474 0.         0.\n",
      "  1.3082191  1.0070428  0.         0.         0.6560554  0.\n",
      "  0.85116667 1.1102715  0.4743221  0.39861333 0.03717963 0.\n",
      "  0.         0.4530958  1.2251854  0.4474966  0.         1.2456151\n",
      "  0.         0.837144   1.1084676  0.41439036 0.5409093  1.2933729\n",
      "  0.         0.         0.5357285  0.         0.         0.\n",
      "  0.         0.339803   1.2257679  0.50251687]]\n",
      "Hi!\n",
      "[[0.18643054 0.26016787 0.00380821 0.11965937 0.         0.42459714\n",
      "  0.43122557 0.5409471  0.         0.06241627 0.04404662 0.\n",
      "  0.         0.35154605 0.         0.03942222 0.         0.16474792\n",
      "  0.         0.47770548 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.06279677 0.         0.\n",
      "  0.35727227 0.39397234 0.36881265 0.         0.         0.\n",
      "  0.         0.12583666 0.21933433 0.2397003  0.         0.\n",
      "  0.         0.07660548 0.6106474  0.88942707 0.         0.04736473\n",
      "  0.372595   0.6127164  0.         0.42992014 0.2883869  0.7239498\n",
      "  0.         0.5177025  0.10827416 0.         0.         0.\n",
      "  0.14810768 0.2245131  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07278306 0.34745094 0.19417177 0.         0.         0.20024826\n",
      "  0.         0.03416996 0.03676184 0.         0.1623735  0.\n",
      "  0.35172358 0.2347934  0.         0.         0.         0.06638741\n",
      "  0.         0.278241   0.10853569 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12585132 0.24302483 0.08446714 0.         0.         0.\n",
      "  0.         0.         0.18601823 0.07092057 0.         0.\n",
      "  0.         0.         0.26739496 0.24095178 0.         0.23556115\n",
      "  0.21738708 0.13869244 0.         0.19666192 0.03547483 0.49881452\n",
      "  0.         0.02836127 0.16248433 0.         0.00619091 0.\n",
      "  0.12127174 0.03728623 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0861663  0.41311005 0.49106976 0.         0.         0.47458628\n",
      "  0.         0.         0.22477081 0.04796683 0.26369396 0.\n",
      "  0.31839958 0.02169234 0.         0.         0.         0.11554521\n",
      "  0.         0.51343167 0.32868484 0.         0.         0.07602695\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08300863 0.13271546 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20332548 0.         0.\n",
      "  0.         0.         0.15167393 0.23873506 0.         0.41952476\n",
      "  0.24785995 0.24361159 0.02590133 0.24431995 0.25698972 0.50467116\n",
      "  0.         0.1921044  0.04004493 0.         0.11333163 0.\n",
      "  0.06153276 0.08914098 0.10464573 0.13225195]]\n",
      "Hi!\n",
      "[[0.         0.22764285 0.23327944 0.         0.         0.20534442\n",
      "  0.         0.02558026 0.03893356 0.06698356 0.18159433 0.\n",
      "  0.11681925 0.07616556 0.         0.0103795  0.         0.05952867\n",
      "  0.         0.2610679  0.12549186 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1394562  0.07153617 0.         0.         0.\n",
      "  0.         0.         0.08512237 0.12172965 0.         0.\n",
      "  0.         0.         0.10855351 0.23517141 0.         0.14636025\n",
      "  0.21808742 0.14382583 0.         0.19190215 0.06812902 0.32092527\n",
      "  0.         0.10069212 0.00733234 0.         0.06128573 0.\n",
      "  0.10989229 0.07450203 0.         0.01748087]]\n",
      "Hi!\n",
      "[[3.55547726e-01 4.15322006e-01 5.36767840e-01 0.00000000e+00\n",
      "  0.00000000e+00 7.44872808e-01 0.00000000e+00 3.27316612e-01\n",
      "  0.00000000e+00 1.20190166e-01 2.54837751e-01 0.00000000e+00\n",
      "  5.47030941e-04 2.37075165e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.02601089e-01 0.00000000e+00 7.55551636e-01\n",
      "  2.49132529e-01 0.00000000e+00 0.00000000e+00 2.50302851e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.22495213e-01 4.39848900e-01\n",
      "  1.34027094e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.93080619e-01 3.04913759e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.51941872e-01 7.42124379e-01 0.00000000e+00 2.13715419e-01\n",
      "  6.21699393e-01 6.37015998e-01 0.00000000e+00 5.17272472e-01\n",
      "  6.70259237e-01 7.65132189e-01 0.00000000e+00 8.00032258e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.97674140e-01 1.31361663e-01 3.27498801e-02 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.34543133 0.         0.737045   0.08336601 0.         0.5710134\n",
      "  1.0705084  0.94893694 0.654177   0.         0.36146936 0.\n",
      "  0.04666483 0.         0.         0.4646281  0.         0.7603898\n",
      "  0.         0.         0.71009195 0.01250756 0.         0.09379233\n",
      "  0.09130046 0.         0.         0.00350579 0.         0.\n",
      "  0.40749985 0.21336098 0.02421283 0.         0.38430613 0.\n",
      "  0.02637014 1.0720192  0.         0.4587822  0.01000299 0.\n",
      "  0.         0.8146618  0.26467037 0.54396546 0.         0.30758828\n",
      "  0.         0.6762696  0.3944567  0.25911197 0.2712537  0.1388945\n",
      "  0.         0.05948138 0.05292319 0.         0.         0.\n",
      "  0.         0.9498631  0.8885724  0.20592918]]\n",
      "Hi!\n",
      "[[0.3538189  0.24504712 0.84295845 0.         0.         0.76084113\n",
      "  0.5858709  0.9661523  0.84342784 0.         0.4753544  0.\n",
      "  1.0131607  0.         0.         0.56286585 0.         0.6115217\n",
      "  0.41515353 0.02892009 0.8498485  0.         0.         0.\n",
      "  0.03653645 0.         0.         0.40658292 0.         0.\n",
      "  0.8369349  0.5959478  0.         0.         0.44348407 0.\n",
      "  0.23344544 1.0544294  0.         0.373251   0.08385594 0.\n",
      "  0.         0.46515214 0.568876   0.5663406  0.         0.6021126\n",
      "  0.         0.6783198  0.6267268  0.462812   0.6671159  0.49073535\n",
      "  0.         0.         0.23808917 0.         0.         0.\n",
      "  0.         0.55815405 1.3111824  0.34826732]]\n",
      "Hi!\n",
      "[[0.4490149  0.32757363 0.70076126 0.         0.         0.81839913\n",
      "  0.42825627 0.52438515 0.08928891 0.24796525 0.27187967 0.\n",
      "  0.         0.         0.         0.04045285 0.         0.33335367\n",
      "  0.         0.646806   0.4614346  0.         0.         0.22523871\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15957536 0.18396902 0.         0.         0.\n",
      "  0.         0.10629318 0.         0.6994111  0.         0.\n",
      "  0.         0.34476876 0.07094474 0.7784691  0.         0.\n",
      "  0.38974023 1.0100927  0.         0.35901415 0.7094146  0.23264831\n",
      "  0.         0.7917025  0.         0.         0.03597585 0.\n",
      "  0.4379682  0.67702806 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.21608382 0.4370893  0.48642817 0.         0.         0.5543089\n",
      "  0.07945403 0.25550717 0.         0.09800567 0.27954102 0.\n",
      "  0.14187    0.14938694 0.         0.         0.         0.35831314\n",
      "  0.         0.6632976  0.28715625 0.         0.         0.06946904\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27773875 0.3700235  0.         0.         0.         0.\n",
      "  0.         0.08751415 0.         0.2973728  0.         0.\n",
      "  0.         0.         0.43157604 0.6987014  0.         0.2487532\n",
      "  0.4509883  0.5937705  0.         0.3683421  0.41834733 0.5791466\n",
      "  0.         0.51388836 0.         0.         0.0269873  0.\n",
      "  0.21129462 0.30794537 0.01016083 0.        ]]\n",
      "Hi!\n",
      "[[0.17952485 0.         0.         0.3201071  0.         0.54029506\n",
      "  1.6775864  1.5469837  0.         0.         0.08794067 0.\n",
      "  0.         0.20131958 0.         0.32058132 0.         0.47497538\n",
      "  0.         0.03589268 0.04478757 0.05922803 0.         0.\n",
      "  0.         0.         0.         0.28552192 0.         0.\n",
      "  0.7423314  0.25907093 0.39939663 0.         0.5120376  0.\n",
      "  0.         0.78308296 0.         0.46379912 0.20656586 0.\n",
      "  0.         0.54115695 0.6711603  1.0789636  0.         0.\n",
      "  0.00435451 1.0273898  0.0348394  0.49785635 0.6810651  0.25824457\n",
      "  0.         0.17820947 0.         0.         0.         0.\n",
      "  0.         0.81184417 0.35839447 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07694346 0.07952195 0.         0.         0.\n",
      "  0.09704933 0.1981781  0.08777742 0.00655405 0.01806954 0.\n",
      "  0.14627841 0.17867076 0.         0.06281539 0.         0.07022662\n",
      "  0.         0.         0.11273248 0.         0.         0.\n",
      "  0.         0.         0.         0.04703691 0.         0.\n",
      "  0.09422452 0.15545522 0.18471141 0.         0.         0.\n",
      "  0.         0.         0.25029853 0.         0.         0.\n",
      "  0.         0.         0.22068343 0.22513074 0.         0.06004615\n",
      "  0.11100079 0.0827206  0.         0.12932248 0.         0.34107968\n",
      "  0.         0.02283812 0.15683025 0.         0.         0.\n",
      "  0.03720076 0.13731267 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.2236456  0.05844213 2.2185574  0.         0.         0.91779745\n",
      "  0.26802868 0.20988254 1.4581206  0.         0.8393245  0.\n",
      "  0.         0.         0.         0.73227507 1.363732   0.9872516\n",
      "  0.         0.         1.5976483  0.7022782  0.         0.7241576\n",
      "  0.01752293 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.12609373 0.         0.         0.\n",
      "  0.09073092 0.74878    0.         1.2784992  0.09133392 0.\n",
      "  0.         1.7491142  0.         0.09185795 0.         0.43543425\n",
      "  0.         1.0136074  0.7957928  0.         0.28558236 0.\n",
      "  0.         0.6733797  0.         1.0603352  0.06148892 0.\n",
      "  0.22476323 1.2165784  0.7104201  1.0111395 ]]\n",
      "Hi!\n",
      "[[0.6014109  0.14360598 0.57519674 0.3879063  0.         0.9753145\n",
      "  0.81044525 1.3102572  0.         0.         0.20640552 0.\n",
      "  0.38097936 0.3117293  0.         0.         0.         0.27648592\n",
      "  0.         0.56914276 0.46124572 0.         0.         0.03493137\n",
      "  0.         0.         0.         0.39604464 0.         0.\n",
      "  1.0033331  0.80480444 0.19485524 0.         0.33222547 0.\n",
      "  0.         0.5369363  0.16898043 0.26806894 0.09349313 0.\n",
      "  0.         0.12479709 1.0498378  1.234582   0.         0.10386056\n",
      "  0.40353185 0.93410456 0.         0.8093937  1.1612262  0.7705412\n",
      "  0.         0.93045026 0.18248037 0.         0.         0.\n",
      "  0.         0.24111485 0.99771863 0.        ]]\n",
      "Hi!\n",
      "[[0.4434778  0.4857442  1.1672554  0.         0.         0.5164306\n",
      "  0.         0.         0.50032437 0.06833553 0.47051772 0.\n",
      "  0.10974894 0.         0.         0.13478753 0.42424685 0.4193125\n",
      "  0.         0.54629445 0.6846726  0.         0.         0.14985578\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11968621 0.03202689 0.         0.         0.\n",
      "  0.         0.         0.         0.55634874 0.         0.\n",
      "  0.         0.17723483 0.         0.01883283 0.         0.42678532\n",
      "  0.38592055 0.6039586  0.25754085 0.21917818 0.18576224 0.17090832\n",
      "  0.         0.47927544 0.         0.18292631 0.2538108  0.\n",
      "  0.40189588 0.45256335 0.2969103  0.541148  ]]\n",
      "Hi!\n",
      "[[0.         0.27017018 0.07912353 0.         0.         0.12163548\n",
      "  0.07590412 0.31681463 0.         0.05593314 0.10127817 0.\n",
      "  0.15604246 0.14974828 0.         0.02139086 0.         0.06501366\n",
      "  0.         0.19575836 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02194753 0.10941091 0.08283784 0.         0.         0.\n",
      "  0.         0.04343601 0.16611184 0.13155343 0.         0.\n",
      "  0.         0.         0.1841119  0.45035946 0.         0.\n",
      "  0.14689055 0.31189632 0.         0.18102947 0.27702957 0.37393573\n",
      "  0.         0.05447012 0.03272968 0.         0.         0.\n",
      "  0.02000556 0.3146401  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.13183185 0.22119631 0.3280923  0.         0.         0.23781192\n",
      "  0.00595633 0.14608589 0.16603963 0.         0.12023056 0.\n",
      "  0.3378182  0.12218227 0.         0.08917075 0.07818523 0.09656975\n",
      "  0.         0.2211546  0.27247277 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19206831 0.10752718 0.         0.         0.\n",
      "  0.         0.00313973 0.19501525 0.06701857 0.         0.\n",
      "  0.         0.08184156 0.18966147 0.14891224 0.         0.21230315\n",
      "  0.14037909 0.20007382 0.         0.1569623  0.         0.4223722\n",
      "  0.         0.04163423 0.08727054 0.         0.         0.\n",
      "  0.20173217 0.08110995 0.         0.08661475]]\n",
      "Hi!\n",
      "[[0.37060547 0.260771   1.2404166  0.         0.         0.71948105\n",
      "  0.47145456 0.82337934 1.3708067  0.         0.63031214 0.\n",
      "  1.0130634  0.         0.         0.82625127 0.08960618 0.8290181\n",
      "  0.64077854 0.         1.1819742  0.07079875 0.         0.354474\n",
      "  0.         0.         0.         0.3424983  0.         0.\n",
      "  0.66019493 0.4429726  0.         0.         0.30626285 0.\n",
      "  0.30880344 1.1637363  0.         0.68019474 0.22938094 0.\n",
      "  0.         0.8785003  0.09255525 0.30030736 0.         0.6920093\n",
      "  0.         0.8560249  0.87603337 0.29779696 0.5523568  0.23304375\n",
      "  0.         0.         0.10885838 0.29172197 0.         0.\n",
      "  0.         0.8158835  1.5027319  0.8256387 ]]\n",
      "Hi!\n",
      "[[0.71363145 0.         0.70491546 0.43121126 0.         0.92332095\n",
      "  1.4415938  1.4113113  0.40283304 0.09582187 0.31960917 0.\n",
      "  0.         0.         0.         0.24420144 0.23743111 0.681854\n",
      "  0.         0.         0.598389   0.11726277 0.         0.35656208\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13296495 0.06410635 0.36345372 0.         0.09224293 0.\n",
      "  0.         0.63475317 0.         0.9764451  0.15860106 0.\n",
      "  0.         1.3251123  0.         0.8794471  0.         0.\n",
      "  0.13681251 1.2701664  0.06799947 0.3292776  0.8802472  0.\n",
      "  0.         0.90208584 0.         0.         0.         0.\n",
      "  0.11665007 1.1716567  0.47636744 0.        ]]\n",
      "Hi!\n",
      "[[0.04932783 0.15668994 0.07829756 0.         0.         0.12670054\n",
      "  0.02726057 0.15671967 0.         0.0442713  0.11487906 0.\n",
      "  0.08437558 0.20972013 0.         0.         0.         0.0470736\n",
      "  0.         0.16884637 0.06541395 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09543671 0.193958   0.19184437 0.         0.         0.\n",
      "  0.         0.         0.1957566  0.05150224 0.         0.\n",
      "  0.         0.         0.24454412 0.34540886 0.         0.04736405\n",
      "  0.19740218 0.17067361 0.         0.19875668 0.06513123 0.4363983\n",
      "  0.         0.1395818  0.06639511 0.         0.         0.\n",
      "  0.0976676  0.08193029 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5861693  0.         0.64277595 0.35217425 0.         0.62676615\n",
      "  1.9777263  1.9411812  1.0105941  0.         0.34695932 0.\n",
      "  0.         0.         0.         0.724009   0.1284161  0.7890995\n",
      "  0.         0.         0.83358616 0.29574034 0.         0.31411022\n",
      "  0.         0.         0.         0.23971833 0.         0.\n",
      "  0.5597593  0.06524715 0.23433004 0.         0.58182406 0.\n",
      "  0.         1.3824269  0.         0.7167846  0.34910348 0.\n",
      "  0.         1.6852139  0.06804254 0.7105755  0.         0.\n",
      "  0.         0.9364546  0.4833879  0.29785347 0.68746454 0.\n",
      "  0.         0.23387787 0.         0.0701401  0.         0.\n",
      "  0.         1.3075097  1.3195316  0.        ]]\n",
      "Hi!\n",
      "[[0.8503475  0.640814   0.84736603 0.2347086  0.         0.96687454\n",
      "  0.1521098  0.6285198  0.         0.         0.34127045 0.\n",
      "  0.9073096  0.4200531  0.         0.         0.         0.26623416\n",
      "  0.         1.0248389  0.4374967  0.         0.         0.21617573\n",
      "  0.         0.         0.         0.3322343  0.         0.\n",
      "  0.96347284 1.1514018  0.01405536 0.         0.13932526 0.\n",
      "  0.         0.3088401  0.6720294  0.30551317 0.         0.\n",
      "  0.         0.16732809 1.2753968  1.0436004  0.         0.6460858\n",
      "  0.74919    0.65576786 0.         0.7180372  0.9039199  1.304272\n",
      "  0.         0.99823415 0.4092962  0.         0.07919241 0.\n",
      "  0.         0.09646052 0.97132117 0.        ]]\n",
      "Hi!\n",
      "[[0.14276369 0.36216828 0.42842984 0.         0.         0.45714396\n",
      "  0.         0.12799564 0.01337364 0.13714911 0.2405867  0.\n",
      "  0.01358781 0.01300006 0.         0.         0.         0.20209593\n",
      "  0.         0.51616734 0.22533636 0.         0.         0.04542571\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17799143 0.04209614 0.         0.         0.\n",
      "  0.         0.         0.00197044 0.25357676 0.         0.\n",
      "  0.         0.         0.15730834 0.42236102 0.         0.14457016\n",
      "  0.36733276 0.41936746 0.         0.2777702  0.29373467 0.39619842\n",
      "  0.         0.44147226 0.         0.         0.08455931 0.\n",
      "  0.2821412  0.22675553 0.         0.03814222]]\n",
      "Hi!\n",
      "[[0.40789613 0.16758756 0.7953531  0.03718464 0.         0.8453082\n",
      "  0.6881972  0.89836913 0.42575806 0.         0.3986998  0.\n",
      "  0.5309945  0.         0.         0.29518428 0.         0.56982464\n",
      "  0.         0.26547822 0.7287926  0.         0.         0.\n",
      "  0.         0.         0.         0.19069143 0.         0.\n",
      "  0.6546302  0.5758142  0.         0.         0.2956293  0.\n",
      "  0.         0.8558571  0.         0.4251967  0.         0.\n",
      "  0.         0.27902114 0.6110054  0.6994029  0.         0.43835104\n",
      "  0.04385647 0.7671172  0.30264822 0.45996454 0.6401491  0.53701323\n",
      "  0.         0.3588788  0.11831917 0.         0.         0.\n",
      "  0.         0.53176546 1.0258682  0.0341179 ]]\n",
      "Hi!\n",
      "[[0.46626836 0.21504423 1.223998   0.         0.         0.55636674\n",
      "  0.4820218  0.3794898  1.134426   0.         0.62373006 0.\n",
      "  0.22196685 0.         0.         0.67119116 0.34529668 0.9225089\n",
      "  0.         0.         1.0718359  0.31653765 0.         0.39093736\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04184454 0.0768631  0.01820933 0.         0.10370354 0.\n",
      "  0.         0.8073503  0.         0.8619633  0.04386334 0.\n",
      "  0.         1.0232183  0.         0.0210328  0.         0.27646616\n",
      "  0.         0.8632339  0.6605096  0.05432663 0.30442867 0.01720804\n",
      "  0.         0.         0.         0.28739455 0.         0.\n",
      "  0.         1.095092   0.6172811  0.68054605]]\n",
      "Hi!\n",
      "[[0.721789   0.         0.8096984  0.3660426  0.         1.0186896\n",
      "  1.0322875  1.206774   0.28733683 0.08320075 0.31507808 0.\n",
      "  0.         0.         0.         0.17347845 0.12491497 0.5924697\n",
      "  0.         0.12299255 0.6117956  0.01026054 0.         0.37750176\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22146782 0.23146345 0.3330107  0.         0.         0.\n",
      "  0.         0.48067293 0.         0.9226409  0.04083858 0.\n",
      "  0.         1.0361592  0.02429359 0.9483354  0.         0.\n",
      "  0.24162228 1.3612505  0.00301157 0.43596897 1.0048507  0.\n",
      "  0.         1.0518711  0.         0.         0.         0.\n",
      "  0.15832698 0.90779835 0.45339203 0.        ]]\n",
      "Hi!\n",
      "[[0.16288906 0.45250008 0.45543426 0.         0.         0.4204623\n",
      "  0.13433507 0.16448134 0.2722579  0.07128963 0.25881758 0.\n",
      "  0.21460019 0.         0.         0.22100662 0.         0.30346403\n",
      "  0.         0.4512415  0.28379712 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02243357 0.14077012 0.         0.         0.         0.\n",
      "  0.         0.16286337 0.         0.20457172 0.         0.\n",
      "  0.         0.         0.07750476 0.38413495 0.         0.29483822\n",
      "  0.10509379 0.48724878 0.13475257 0.13730106 0.1520075  0.34217834\n",
      "  0.         0.11625804 0.         0.         0.0568739  0.\n",
      "  0.17577776 0.41178113 0.06563721 0.13584492]]\n",
      "Hi!\n",
      "[[0.9542236  0.5607691  1.7430155  0.         0.         1.3504554\n",
      "  0.         0.268317   0.4980765  0.07101551 0.6424367  0.\n",
      "  0.2825792  0.         0.         0.05727774 0.37830088 0.48649952\n",
      "  0.         0.81539464 1.104207   0.         0.         0.4919144\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.54390514 0.07721452 0.         0.         0.\n",
      "  0.         0.22979334 0.         0.7307565  0.         0.\n",
      "  0.         0.26070833 0.16769099 0.466652   0.         0.59952646\n",
      "  0.5847954  0.988211   0.19628562 0.5577093  0.9469652  0.69037926\n",
      "  0.         1.3831182  0.         0.         0.18153897 0.\n",
      "  0.19758254 0.38897586 0.86776525 0.42313084]]\n",
      "Hi!\n",
      "[[0.62814116 0.7636825  1.3140988  0.         0.         1.0800365\n",
      "  0.         0.         0.26724827 0.11880579 0.54521376 0.\n",
      "  0.3850783  0.         0.         0.         0.25219515 0.28629392\n",
      "  0.         1.126437   0.7251551  0.         0.         0.12265971\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4784041  0.03138659 0.         0.         0.\n",
      "  0.         0.07331235 0.         0.6631413  0.         0.\n",
      "  0.         0.         0.3236743  0.3766816  0.         0.8597751\n",
      "  0.71527576 0.65935194 0.02691779 0.5720419  0.6669273  0.9451778\n",
      "  0.         1.0589799  0.         0.         0.23998915 0.\n",
      "  0.28649795 0.14823318 0.51831913 0.30917707]]\n",
      "Hi!\n",
      "[[0.3621764  0.23240729 0.5518683  0.         0.         0.5279675\n",
      "  0.92118955 1.2201871  1.2715054  0.         0.47186315 0.\n",
      "  1.5636939  0.10234564 0.         1.0097476  0.         0.78062356\n",
      "  1.2430382  0.         0.81728375 0.16365762 0.         0.\n",
      "  0.5228464  0.         0.         0.6950948  0.         0.\n",
      "  1.1252053  0.5320205  0.         0.         0.8167971  0.\n",
      "  0.83177066 1.5362998  0.         0.33629784 0.25859708 0.\n",
      "  0.         0.7086503  0.7760263  0.48456442 0.         0.9959395\n",
      "  0.         0.778127   1.1954085  0.41202456 0.3132456  0.6450516\n",
      "  0.         0.         0.5216013  0.         0.         0.\n",
      "  0.         0.6317606  1.5730919  0.6215573 ]]\n",
      "Hi!\n",
      "[[0.         0.13161276 0.00941271 0.         0.         0.01956811\n",
      "  0.07448041 0.25548998 0.         0.07713405 0.0742318  0.\n",
      "  0.09342418 0.16685754 0.         0.03753596 0.         0.07494603\n",
      "  0.         0.07922572 0.05750939 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02785847 0.09971569 0.17134875 0.         0.         0.\n",
      "  0.         0.         0.17450985 0.02487863 0.         0.\n",
      "  0.         0.         0.21283294 0.32162264 0.         0.\n",
      "  0.10917629 0.14114355 0.         0.1513383  0.06388298 0.31263298\n",
      "  0.         0.03567434 0.07095079 0.         0.         0.\n",
      "  0.00231591 0.24051555 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6702327  0.17228498 0.9785613  0.18059964 0.         1.1386456\n",
      "  0.62142295 0.7452778  0.09915702 0.         0.229103   0.\n",
      "  0.13496965 0.         0.         0.04742655 0.08765613 0.44087607\n",
      "  0.         0.51674503 0.652349   0.         0.         0.\n",
      "  0.         0.         0.         0.00424127 0.         0.\n",
      "  0.29175493 0.6099823  0.04136591 0.         0.         0.\n",
      "  0.         0.60734826 0.         0.4751054  0.         0.\n",
      "  0.         0.32115453 0.58758044 0.7786059  0.         0.6586286\n",
      "  0.49530354 0.73368853 0.0116146  0.5931546  0.475937   0.89120847\n",
      "  0.         1.2294271  0.06518027 0.         0.         0.\n",
      "  0.17837998 0.3788696  0.82936454 0.        ]]\n",
      "Hi!\n",
      "[[0.94489336 0.         1.1376817  0.4929827  0.         1.0658212\n",
      "  1.5242223  1.4482702  0.6015405  0.01025509 0.40611112 0.\n",
      "  0.         0.         0.         0.27716875 0.5870784  0.85801786\n",
      "  0.         0.         0.8661908  0.3014887  0.         0.6465573\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12656511 0.40916693 0.         0.         0.\n",
      "  0.         0.68381804 0.         1.1128688  0.19119182 0.\n",
      "  0.         1.706688   0.         0.7210803  0.         0.\n",
      "  0.03404762 1.3362985  0.14580788 0.29133102 0.97021496 0.\n",
      "  0.         1.2831515  0.         0.         0.         0.\n",
      "  0.1955384  1.1878836  0.7936742  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.01707229 0.         0.         0.         0.01329891\n",
      "  0.09936083 0.2884466  0.00077936 0.10784388 0.07347579 0.\n",
      "  0.         0.08469755 0.         0.05557321 0.         0.03224621\n",
      "  0.         0.05736667 0.10174889 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00593763 0.1859639  0.         0.         0.\n",
      "  0.         0.         0.10664856 0.06900591 0.         0.\n",
      "  0.         0.         0.15015066 0.39459908 0.         0.0295706\n",
      "  0.17895265 0.05358438 0.         0.22244918 0.         0.23877215\n",
      "  0.         0.16855665 0.         0.         0.         0.\n",
      "  0.00162209 0.17945914 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.78837234 0.         0.98790884 0.28789866 0.         1.1208161\n",
      "  0.806695   1.0391709  0.18872644 0.08472978 0.3321623  0.\n",
      "  0.         0.         0.         0.11974844 0.14179069 0.4739573\n",
      "  0.         0.301959   0.71333164 0.         0.         0.34949973\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17324317 0.48742312 0.17845288 0.         0.         0.\n",
      "  0.         0.5031718  0.         0.69252086 0.         0.\n",
      "  0.         0.60650086 0.2781911  0.8386515  0.         0.\n",
      "  0.25660422 1.0352408  0.         0.5126421  0.90959823 0.35257247\n",
      "  0.         1.2398965  0.         0.         0.         0.\n",
      "  0.19105992 0.6401565  0.7982963  0.        ]]\n",
      "Hi!\n",
      "[[0.40187708 0.00891545 1.0886048  0.         0.         0.7892582\n",
      "  0.7231583  1.0212209  1.0450906  0.         0.52809495 0.\n",
      "  0.6498515  0.         0.         0.677087   0.02042857 0.67913115\n",
      "  0.2505464  0.         1.0686532  0.         0.         0.32839873\n",
      "  0.         0.         0.         0.28118822 0.         0.\n",
      "  0.59576434 0.5052327  0.02838526 0.         0.3148796  0.\n",
      "  0.06531519 1.0747677  0.         0.52876914 0.17827968 0.\n",
      "  0.         0.85315174 0.21499828 0.5146069  0.         0.47430813\n",
      "  0.         0.77089775 0.60195047 0.35887212 0.6085859  0.25047272\n",
      "  0.         0.09477795 0.11678831 0.09331237 0.         0.\n",
      "  0.         0.7733527  1.4033318  0.4288251 ]]\n",
      "Hi!\n",
      "[[0.         0.18648727 0.19624627 0.         0.         0.13792205\n",
      "  0.00526595 0.13359536 0.         0.08633218 0.1335678  0.\n",
      "  0.01905027 0.09272338 0.         0.02099292 0.         0.1410825\n",
      "  0.         0.20005071 0.11143899 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14113934 0.08697058 0.         0.         0.\n",
      "  0.         0.         0.06486204 0.1180366  0.         0.\n",
      "  0.         0.         0.18322434 0.27593404 0.         0.02971055\n",
      "  0.21935746 0.19354457 0.         0.14189155 0.02654285 0.2898859\n",
      "  0.         0.15802544 0.         0.         0.00387637 0.\n",
      "  0.12847564 0.17642039 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.3178863  0.22338046 0.         0.         0.23300226\n",
      "  0.         0.14673212 0.         0.07616745 0.15657558 0.\n",
      "  0.03942553 0.13057508 0.         0.04787092 0.         0.11713232\n",
      "  0.         0.38852265 0.10719974 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01235857 0.18105465 0.11295006 0.         0.         0.\n",
      "  0.         0.         0.09328777 0.18625867 0.         0.\n",
      "  0.         0.         0.14141224 0.41323677 0.         0.03914214\n",
      "  0.24424154 0.3675657  0.         0.21151449 0.22749767 0.41359034\n",
      "  0.         0.22705078 0.         0.         0.02167294 0.\n",
      "  0.17921521 0.2645114  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.08417557 0.3246264  0.15213357 0.         0.         0.09476013\n",
      "  0.         0.07335339 0.04359404 0.         0.18223767 0.\n",
      "  0.33840674 0.20208225 0.         0.03063167 0.         0.05522498\n",
      "  0.         0.22686453 0.09580541 0.         0.         0.\n",
      "  0.         0.         0.         0.00749934 0.         0.\n",
      "  0.1481911  0.19764507 0.07539685 0.         0.         0.\n",
      "  0.         0.         0.2604799  0.01835121 0.         0.\n",
      "  0.         0.         0.17986487 0.18385006 0.         0.07601367\n",
      "  0.15739483 0.12838012 0.02471231 0.17002663 0.0802036  0.4647033\n",
      "  0.         0.         0.13959639 0.         0.01587995 0.\n",
      "  0.09960068 0.1258538  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.22617736 0.33297434 0.7385261  0.         0.         0.39836785\n",
      "  0.7913027  0.6928149  1.2299752  0.         0.5045156  0.\n",
      "  0.9848691  0.         0.         0.9740841  0.         0.84225124\n",
      "  0.690634   0.         0.839951   0.11746742 0.         0.\n",
      "  0.43430695 0.         0.         0.23215114 0.         0.\n",
      "  0.6915743  0.16922033 0.         0.         0.6785056  0.\n",
      "  0.5441011  1.3137811  0.         0.44609645 0.20826697 0.\n",
      "  0.         0.7561789  0.33786365 0.13863297 0.         0.8961325\n",
      "  0.         0.76618755 1.0236106  0.12890586 0.13037182 0.23568197\n",
      "  0.         0.         0.2718752  0.20450561 0.         0.\n",
      "  0.         0.84432596 1.1171129  0.641264  ]]\n",
      "Hi!\n",
      "[[0.8774878  0.         1.1264389  0.3034175  0.         0.9870032\n",
      "  1.1949434  1.1946473  0.61096495 0.         0.43012923 0.\n",
      "  0.         0.         0.         0.2957662  0.4653739  0.66799057\n",
      "  0.         0.         0.9212971  0.16584866 0.         0.489931\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04261031 0.22709328 0.25460353 0.         0.04289643 0.\n",
      "  0.         0.73713845 0.         0.8486739  0.09708347 0.\n",
      "  0.         1.3064947  0.         0.6137563  0.         0.\n",
      "  0.         1.1099464  0.16248111 0.3007856  0.80016    0.\n",
      "  0.         1.0116612  0.         0.         0.         0.\n",
      "  0.07971556 1.02411    0.8759117  0.        ]]\n",
      "Hi!\n",
      "[[0.074945   0.47479835 0.21375966 0.         0.         0.14288722\n",
      "  0.         0.07014343 0.05343619 0.         0.14589189 0.\n",
      "  0.51613015 0.29206213 0.         0.01416798 0.         0.10059429\n",
      "  0.         0.30702713 0.11096501 0.         0.         0.\n",
      "  0.         0.         0.         0.08471958 0.         0.\n",
      "  0.20328975 0.28933257 0.10357053 0.         0.         0.\n",
      "  0.         0.         0.28062576 0.         0.         0.\n",
      "  0.         0.         0.3197789  0.24199338 0.         0.26914915\n",
      "  0.13806704 0.20062393 0.00841434 0.2222854  0.09388285 0.5541546\n",
      "  0.         0.         0.23742953 0.         0.         0.\n",
      "  0.10622828 0.10526843 0.00773628 0.        ]]\n",
      "Hi!\n",
      "[[0.3395029  0.2813473  0.5413851  0.02720504 0.         0.69092613\n",
      "  0.14267911 0.3601552  0.         0.16501874 0.21291365 0.\n",
      "  0.         0.03185303 0.         0.04244227 0.         0.20189163\n",
      "  0.         0.61692333 0.281693   0.         0.         0.0517379\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12646416 0.3453035  0.11338814 0.         0.         0.\n",
      "  0.         0.05738851 0.         0.38292566 0.         0.\n",
      "  0.         0.         0.34097123 0.681851   0.         0.12576008\n",
      "  0.47429118 0.7216369  0.         0.4083454  0.5852786  0.4537619\n",
      "  0.         0.79354244 0.         0.         0.00718662 0.\n",
      "  0.37303466 0.34169403 0.04814068 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.06351369 0.0636678  0.         0.         0.05533758\n",
      "  0.09679875 0.1423846  0.06098845 0.10950588 0.15933232 0.\n",
      "  0.         0.05903495 0.         0.02969369 0.         0.08596011\n",
      "  0.         0.13939612 0.08372362 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08474914 0.         0.         0.\n",
      "  0.         0.         0.03004394 0.12474465 0.         0.\n",
      "  0.         0.         0.11684885 0.27550763 0.         0.\n",
      "  0.11556199 0.03884396 0.         0.13536409 0.         0.15752347\n",
      "  0.         0.07248271 0.         0.         0.0332754  0.\n",
      "  0.05152728 0.07513175 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.26109064 0.12735336 1.1196816  0.         0.         0.756172\n",
      "  0.61980945 0.7882292  1.2633888  0.         0.59307176 0.\n",
      "  0.9701251  0.         0.         0.84633327 0.         0.8240099\n",
      "  0.7229234  0.         1.0850589  0.03435087 0.         0.08392721\n",
      "  0.2638902  0.         0.         0.25439674 0.         0.\n",
      "  0.603191   0.4127477  0.         0.         0.44489947 0.\n",
      "  0.5364903  1.252355   0.         0.5749138  0.22665307 0.\n",
      "  0.         0.8044191  0.2735646  0.26679236 0.         0.8504562\n",
      "  0.         0.77356595 0.9176357  0.3209258  0.43683863 0.29867145\n",
      "  0.         0.         0.21282433 0.32412565 0.         0.\n",
      "  0.         0.78884715 1.4774146  0.76380736]]\n",
      "Hi!\n",
      "[[0.23425677 0.         0.765179   0.04288277 0.         0.62313294\n",
      "  0.9172859  1.1865187  0.9794734  0.         0.42921302 0.\n",
      "  0.49762827 0.         0.         0.5596244  0.         0.7105502\n",
      "  0.         0.         0.84749854 0.02238586 0.         0.3147879\n",
      "  0.         0.         0.         0.29615566 0.         0.\n",
      "  0.7082062  0.30879673 0.09585098 0.         0.39121914 0.\n",
      "  0.         0.99353504 0.         0.49660137 0.08686355 0.\n",
      "  0.         0.9172171  0.08217276 0.5949983  0.         0.07296453\n",
      "  0.         0.90204823 0.5920707  0.34990284 0.67366785 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.8686065  1.0997756  0.2468465 ]]\n",
      "Hi!\n",
      "[[0.9237972  0.38581702 2.4810588  0.         0.         0.896665\n",
      "  0.01917109 0.         1.6908365  0.         0.9525262  0.\n",
      "  0.40630433 0.         0.         1.0098667  1.1925185  1.0919154\n",
      "  0.35965934 0.12368823 1.7775502  0.6368715  0.         0.52617383\n",
      "  0.1896588  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00911598 0.         0.         0.\n",
      "  0.4033757  0.9501679  0.         1.2136183  0.         0.\n",
      "  0.         1.3128613  0.         0.         0.         1.174455\n",
      "  0.         1.162924   0.9500966  0.         0.18402345 0.\n",
      "  0.         0.19954042 0.         1.3197012  0.22671707 0.\n",
      "  0.04324511 1.1262566  1.2598308  1.3531141 ]]\n",
      "Hi!\n",
      "[[0.08412145 0.47775143 0.3353427  0.         0.         0.2733512\n",
      "  0.         0.03497584 0.10402974 0.02951709 0.24828392 0.\n",
      "  0.39239678 0.1522141  0.         0.01025992 0.         0.13326246\n",
      "  0.         0.37759265 0.22362234 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18434426 0.1849427  0.         0.         0.         0.\n",
      "  0.         0.         0.16332032 0.1327205  0.         0.\n",
      "  0.         0.         0.19163658 0.21436957 0.         0.23094119\n",
      "  0.26085225 0.17978229 0.06777938 0.20567164 0.13694096 0.44016036\n",
      "  0.         0.00712805 0.07836813 0.         0.1032712  0.\n",
      "  0.12353095 0.15615268 0.         0.09888645]]\n",
      "Hi!\n",
      "[[0.13286997 0.         0.87314945 0.         0.         0.56366175\n",
      "  1.0720137  1.0824144  1.4859213  0.         0.55445606 0.\n",
      "  0.70433486 0.         0.         1.058259   0.         0.8849731\n",
      "  0.67293924 0.         1.0380255  0.29954222 0.         0.04520676\n",
      "  0.37832385 0.         0.         0.2671117  0.         0.\n",
      "  0.61991614 0.09912327 0.         0.         0.66517526 0.\n",
      "  0.52270615 1.4836427  0.         0.5133511  0.25798213 0.\n",
      "  0.         1.3075646  0.14776795 0.19956708 0.         0.67642915\n",
      "  0.         0.77129596 1.0365647  0.2169376  0.2233323  0.\n",
      "  0.         0.         0.22597761 0.40229535 0.         0.\n",
      "  0.         1.101574   1.3809631  0.7052841 ]]\n",
      "Hi!\n",
      "[[9.68335122e-02 3.44082206e-01 3.54693949e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.49226171e-01 0.00000000e+00 1.03182301e-01\n",
      "  1.80059988e-02 1.20284356e-01 2.41943941e-01 0.00000000e+00\n",
      "  2.61142999e-02 3.33902650e-02 0.00000000e+00 2.82179710e-04\n",
      "  0.00000000e+00 1.51257873e-01 0.00000000e+00 4.94200975e-01\n",
      "  1.95619091e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.52737558e-01\n",
      "  2.15437710e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.18856095e-02 2.29046777e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.35685712e-01 4.64186758e-01 0.00000000e+00 1.83990225e-01\n",
      "  3.61212611e-01 3.74570370e-01 0.00000000e+00 2.67307281e-01\n",
      "  2.60493636e-01 3.95306647e-01 0.00000000e+00 3.92413378e-01\n",
      "  0.00000000e+00 0.00000000e+00 8.47879797e-02 0.00000000e+00\n",
      "  1.92093968e-01 1.52073279e-01 0.00000000e+00 2.60791797e-02]]\n",
      "Hi!\n",
      "[[0.2748898  0.16991982 0.37626693 0.         0.         0.47668445\n",
      "  1.0788623  1.3762027  1.0286057  0.         0.3799624  0.\n",
      "  1.2056266  0.25902852 0.         0.8677339  0.         0.70804965\n",
      "  0.60679257 0.         0.72455406 0.06594626 0.         0.\n",
      "  0.30284405 0.         0.         0.6216009  0.         0.\n",
      "  1.1868603  0.38671616 0.         0.         0.7250188  0.\n",
      "  0.3786812  1.3587089  0.         0.27990225 0.12717968 0.\n",
      "  0.         0.7297702  0.6891074  0.651971   0.         0.5311304\n",
      "  0.         0.71555126 0.9222173  0.42592022 0.5179988  0.34048468\n",
      "  0.         0.         0.34232968 0.         0.         0.\n",
      "  0.         0.726969   1.2722424  0.31814396]]\n",
      "Hi!\n",
      "[[0.82959306 0.50646365 0.13602039 0.5050707  0.         0.59135246\n",
      "  0.77320135 1.5928428  0.13662215 0.         0.24284948 0.\n",
      "  1.4643224  1.0129223  0.         0.26417795 0.         0.3816998\n",
      "  0.36265162 0.4192759  0.381415   0.24448833 0.         0.24011314\n",
      "  0.         0.         0.         1.0097928  0.         0.\n",
      "  1.7023916  1.0922018  0.1909704  0.         0.7951692  0.\n",
      "  0.2902376  0.9595873  0.72009605 0.07109927 0.24146648 0.\n",
      "  0.         0.48275924 1.6582923  1.3206104  0.         0.5369284\n",
      "  0.04884223 0.8407597  0.41574305 0.7137187  1.0752605  1.3273942\n",
      "  0.         0.1013835  0.6805088  0.         0.         0.\n",
      "  0.         0.24312888 1.2219973  0.        ]]\n",
      "Hi!\n",
      "[[0.09871406 0.2687982  0.2291019  0.         0.         0.10178944\n",
      "  0.         0.02123824 0.08919834 0.03658696 0.17402552 0.\n",
      "  0.23481154 0.09153058 0.         0.08036578 0.         0.\n",
      "  0.         0.2095364  0.1596695  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09891438 0.15246277 0.08144475 0.         0.         0.\n",
      "  0.         0.         0.23618062 0.10686599 0.         0.\n",
      "  0.         0.         0.10021648 0.13060702 0.         0.06361544\n",
      "  0.17236379 0.05138368 0.0198058  0.21044642 0.09984732 0.3700849\n",
      "  0.         0.01641357 0.07968687 0.         0.02373227 0.\n",
      "  0.0116281  0.00524876 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5555739  1.2439557  1.0183498  0.         0.         0.5556058\n",
      "  0.         0.13654812 0.8159045  0.         0.6335913  0.\n",
      "  1.9090134  0.18649065 0.         0.60665876 0.         0.6948212\n",
      "  0.8164403  0.6888511  0.83820444 0.         0.         0.12853736\n",
      "  0.1327058  0.         0.         0.21041714 0.         0.\n",
      "  0.819808   0.7702272  0.         0.         0.26416096 0.\n",
      "  0.3760599  0.6786208  0.2912993  0.57865417 0.         0.\n",
      "  0.         0.21814308 0.7315653  0.17386563 0.         1.0997527\n",
      "  0.00801234 0.83140814 0.79944366 0.39940503 0.54874426 1.0107524\n",
      "  0.         0.         0.23280543 0.         0.09413963 0.\n",
      "  0.         0.37685913 0.9581669  0.7534346 ]]\n",
      "Hi!\n",
      "[[0.21570463 0.19596624 0.37567344 0.04988432 0.         0.55832565\n",
      "  0.8982381  1.1631858  0.41206163 0.         0.2997493  0.\n",
      "  0.52582556 0.16928941 0.         0.34184608 0.         0.6243056\n",
      "  0.         0.07597914 0.46342987 0.         0.         0.\n",
      "  0.         0.         0.         0.34717682 0.         0.\n",
      "  0.95758003 0.4688623  0.         0.         0.45606604 0.\n",
      "  0.         0.8767187  0.         0.3893929  0.         0.\n",
      "  0.         0.41590178 0.544834   0.8619244  0.         0.\n",
      "  0.         1.0066199  0.4386636  0.4254805  0.82054514 0.32813022\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7172814  0.74303293 0.        ]]\n",
      "Hi!\n",
      "[[0.511516   0.6030677  0.80476165 0.         0.         0.61479086\n",
      "  0.15414855 0.53187555 0.38552    0.         0.46468145 0.\n",
      "  0.9067129  0.0550997  0.         0.3306251  0.         0.5817321\n",
      "  0.         0.49844077 0.6348535  0.         0.         0.09792198\n",
      "  0.         0.         0.         0.2624937  0.         0.\n",
      "  0.74634343 0.65843534 0.         0.         0.23157711 0.\n",
      "  0.12136241 0.6582576  0.08785752 0.4123744  0.         0.\n",
      "  0.         0.04367632 0.714575   0.5836401  0.         0.5424883\n",
      "  0.07546043 0.7088337  0.35819376 0.38040105 0.55376077 0.6698662\n",
      "  0.         0.07094205 0.14817163 0.         0.04470083 0.\n",
      "  0.         0.47211903 0.8550456  0.1444338 ]]\n",
      "Hi!\n",
      "[[1.1218086  0.47507113 1.9581426  0.         0.         1.2897605\n",
      "  0.01471858 0.190834   0.7585302  0.00275422 0.6815989  0.\n",
      "  0.09612252 0.         0.         0.1863347  0.74351835 0.6758452\n",
      "  0.         0.60442847 1.278411   0.00511741 0.         0.5723704\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33524835 0.06508964 0.         0.         0.\n",
      "  0.         0.3976025  0.         0.90925735 0.         0.\n",
      "  0.         0.6510292  0.         0.33069327 0.         0.6884749\n",
      "  0.4915009  0.8967631  0.32926628 0.31228614 0.6691668  0.48055354\n",
      "  0.         1.2779244  0.         0.37212786 0.1102018  0.\n",
      "  0.33067015 0.60453504 0.83375585 0.67691004]]\n",
      "Hi!\n",
      "[[0.04617878 0.4683686  0.45660555 0.         0.         0.33037668\n",
      "  0.40895382 0.58776003 0.48118192 0.         0.3748051  0.\n",
      "  0.2836712  0.         0.         0.36117014 0.         0.67428905\n",
      "  0.         0.29603443 0.52353853 0.12625311 0.         0.\n",
      "  0.         0.         0.         0.01618598 0.         0.\n",
      "  0.16517301 0.16939087 0.         0.         0.08349565 0.\n",
      "  0.         0.48358032 0.         0.5122762  0.         0.\n",
      "  0.         0.5581082  0.07185202 0.34519306 0.         0.03719175\n",
      "  0.         0.73110247 0.4030332  0.06768997 0.26740095 0.20304754\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7980264  0.10212619 0.21437894]]\n",
      "Hi!\n",
      "[[1.48712888e-01 6.22220516e-01 4.87173855e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.67761487e-01 0.00000000e+00 1.63792223e-01\n",
      "  1.03335574e-01 3.39096300e-02 3.31047326e-01 0.00000000e+00\n",
      "  3.72069299e-01 1.19830728e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.29198211e-01 0.00000000e+00 6.68819904e-01\n",
      "  3.06212306e-01 0.00000000e+00 0.00000000e+00 1.26592321e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.03569725e-01 2.55019128e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.28949016e-01 2.58750290e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.09899092e-01 4.89865571e-01 0.00000000e+00 3.09842944e-01\n",
      "  3.33134830e-01 4.23614919e-01 4.04256247e-02 3.07759762e-01\n",
      "  2.65492857e-01 5.67010462e-01 0.00000000e+00 2.23696321e-01\n",
      "  2.15169086e-04 0.00000000e+00 8.89253244e-02 0.00000000e+00\n",
      "  1.50786579e-01 2.71301955e-01 2.48582233e-02 8.42949301e-02]]\n",
      "Hi!\n",
      "[[0.3786828  0.47698435 0.7905138  0.         0.         0.5661436\n",
      "  0.42967057 0.69476944 0.9034344  0.         0.5200353  0.\n",
      "  1.2009648  0.         0.         0.731856   0.         0.7217289\n",
      "  0.5845981  0.09034643 0.8299315  0.         0.         0.\n",
      "  0.15729457 0.         0.         0.31261852 0.         0.\n",
      "  0.7847299  0.4980587  0.         0.         0.47394094 0.\n",
      "  0.42252985 1.0464212  0.         0.4981783  0.03809021 0.\n",
      "  0.         0.38980544 0.59269583 0.35968244 0.         0.77287376\n",
      "  0.         0.72318476 0.7508714  0.32052127 0.38302955 0.54244596\n",
      "  0.         0.         0.26904392 0.         0.         0.\n",
      "  0.         0.63464314 1.10732    0.5233196 ]]\n",
      "Hi!\n",
      "[[0.31578082 0.27799034 0.80485016 0.         0.         0.55084676\n",
      "  0.6802157  1.0088129  1.3451556  0.         0.51568    0.\n",
      "  1.379116   0.         0.         0.9236271  0.         0.745843\n",
      "  1.0815176  0.         0.93990713 0.00744458 0.         0.\n",
      "  0.3687387  0.         0.         0.5017049  0.         0.\n",
      "  0.9255147  0.43936977 0.         0.         0.636913   0.\n",
      "  0.6418384  1.3741426  0.         0.41567057 0.24669203 0.\n",
      "  0.         0.75279605 0.4453402  0.33592165 0.         0.91335446\n",
      "  0.         0.8246378  1.1067754  0.3467682  0.41136968 0.40605012\n",
      "  0.         0.         0.36862263 0.13224506 0.         0.\n",
      "  0.         0.6946115  1.504815   0.7426726 ]]\n",
      "Hi!\n",
      "[[0.36230057 0.5297773  0.8195168  0.         0.         0.87719256\n",
      "  0.26924345 0.673133   0.32791466 0.         0.40457055 0.\n",
      "  0.55589336 0.02093518 0.         0.         0.         0.4504703\n",
      "  0.         0.57535195 0.65856105 0.         0.         0.20355609\n",
      "  0.         0.         0.         0.04100312 0.         0.\n",
      "  0.6773452  0.47325593 0.00607515 0.         0.0150568  0.\n",
      "  0.         0.34615582 0.         0.3816996  0.         0.\n",
      "  0.         0.0016294  0.50453204 0.8983778  0.         0.31165174\n",
      "  0.27533257 0.96778435 0.14460827 0.51158845 0.9141081  0.58066547\n",
      "  0.         0.5201544  0.         0.         0.         0.\n",
      "  0.         0.44635093 0.5301692  0.10925851]]\n",
      "Hi!\n",
      "[[0.02775968 0.20695278 0.         0.         0.         0.1967168\n",
      "  0.12249906 0.26711884 0.         0.04495467 0.07889537 0.\n",
      "  0.05719291 0.19935411 0.         0.01388608 0.         0.07769072\n",
      "  0.         0.22232085 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09597413 0.21434507 0.23281212 0.         0.         0.\n",
      "  0.         0.01461783 0.17321281 0.08017939 0.         0.\n",
      "  0.         0.         0.24708377 0.47831273 0.         0.04570925\n",
      "  0.23912674 0.253522   0.         0.24035466 0.08031426 0.45727503\n",
      "  0.         0.20068891 0.06927212 0.         0.         0.\n",
      "  0.09212101 0.13627993 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.13423158 0.25998038 0.03200998 0.         0.         0.07249057\n",
      "  0.13620923 0.24842338 0.13194875 0.         0.02075298 0.\n",
      "  0.4048635  0.33544073 0.         0.09537258 0.         0.06576421\n",
      "  0.         0.10219389 0.02932487 0.         0.         0.\n",
      "  0.         0.         0.         0.17423841 0.         0.\n",
      "  0.29790133 0.34482506 0.16936593 0.         0.02802649 0.\n",
      "  0.0259163  0.0271511  0.32682195 0.         0.         0.\n",
      "  0.         0.         0.40441158 0.35129914 0.         0.13804989\n",
      "  0.16342676 0.21306735 0.05811519 0.12816676 0.10766555 0.5471045\n",
      "  0.         0.         0.19809492 0.         0.         0.\n",
      "  0.07344768 0.20682527 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.12647654 0.29414013 0.12958525 0.         0.         0.06771081\n",
      "  0.         0.03935844 0.10074838 0.02202682 0.17694986 0.\n",
      "  0.31823274 0.17674349 0.         0.06859127 0.         0.06412052\n",
      "  0.         0.14371966 0.12804335 0.         0.         0.\n",
      "  0.         0.         0.         0.02163038 0.         0.\n",
      "  0.16819814 0.23719607 0.05702825 0.         0.         0.\n",
      "  0.         0.         0.22585797 0.03116568 0.         0.\n",
      "  0.         0.         0.15963444 0.10037158 0.         0.07394385\n",
      "  0.09498058 0.10097936 0.05652364 0.091224   0.02189165 0.41228607\n",
      "  0.         0.         0.15939991 0.         0.0103557  0.\n",
      "  0.11797903 0.08733078 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.33003625 0.52805734 1.2293298  0.         0.         0.61021835\n",
      "  0.35141215 0.4372317  1.427419   0.         0.6692801  0.\n",
      "  1.4373909  0.         0.         0.96993375 0.         0.9007539\n",
      "  1.1058266  0.         1.164794   0.16193266 0.         0.04937311\n",
      "  0.358758   0.         0.         0.2312171  0.         0.\n",
      "  0.5838859  0.39415887 0.         0.         0.4057705  0.\n",
      "  0.6940493  1.2321541  0.         0.7195519  0.15192777 0.\n",
      "  0.         0.61092085 0.26465747 0.         0.         1.1363518\n",
      "  0.         0.9105556  1.0909994  0.23375516 0.25987878 0.4232228\n",
      "  0.         0.         0.22412077 0.37639686 0.         0.\n",
      "  0.         0.7447714  1.3986975  1.1119286 ]]\n",
      "Hi!\n",
      "[[0.51621413 0.6805808  1.2025381  0.         0.         0.87397695\n",
      "  0.         0.         0.3137594  0.09123641 0.531714   0.\n",
      "  0.39010412 0.         0.         0.06252889 0.18019436 0.46942908\n",
      "  0.         0.8657719  0.7190003  0.         0.         0.20776089\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.36790368 0.         0.         0.         0.\n",
      "  0.         0.05318817 0.         0.6484234  0.         0.\n",
      "  0.         0.         0.14979205 0.30943522 0.         0.6116075\n",
      "  0.57416713 0.6024929  0.1117091  0.4059543  0.4881415  0.5813369\n",
      "  0.         0.6956345  0.         0.         0.20254299 0.\n",
      "  0.30609527 0.36442778 0.3681925  0.46162456]]\n",
      "Hi!\n",
      "[[0.54764354 0.         0.5174398  0.43010002 0.         0.83009994\n",
      "  1.6815143  1.6893733  0.45935193 0.01254832 0.26402575 0.\n",
      "  0.         0.         0.         0.27591333 0.         0.6559027\n",
      "  0.         0.         0.5590828  0.10028059 0.         0.24578269\n",
      "  0.         0.         0.         0.004435   0.         0.\n",
      "  0.4843447  0.19574769 0.29551023 0.         0.37651196 0.\n",
      "  0.         0.8900695  0.         0.73190194 0.17814247 0.\n",
      "  0.         1.1749002  0.21444768 1.0232748  0.         0.\n",
      "  0.02931868 1.1436007  0.14566264 0.41620532 0.90931326 0.\n",
      "  0.         0.629326   0.         0.         0.         0.\n",
      "  0.         1.1119672  0.7927601  0.        ]]\n",
      "Hi!\n",
      "[[1.0052685  0.15400757 1.605129   0.         0.         1.162854\n",
      "  0.20246255 0.44888481 0.65154415 0.06811263 0.57597005 0.\n",
      "  0.         0.         0.         0.17659126 0.5660737  0.6874798\n",
      "  0.         0.38167086 1.1368153  0.02175497 0.         0.53208226\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.307724   0.10650754 0.         0.         0.\n",
      "  0.         0.45836207 0.         0.8542902  0.         0.\n",
      "  0.         0.78379655 0.         0.36363354 0.         0.39818582\n",
      "  0.33156934 0.91063714 0.24358462 0.31352228 0.638426   0.29593363\n",
      "  0.         1.1413494  0.         0.19100347 0.05015153 0.\n",
      "  0.2773289  0.7264964  0.75934124 0.42450947]]\n",
      "Hi!\n",
      "[[0.63400155 0.90393245 0.48490158 0.         0.         0.4247748\n",
      "  0.20011602 0.4843134  0.35596195 0.         0.37891978 0.\n",
      "  1.4817113  0.56308025 0.         0.48917216 0.         0.6365157\n",
      "  0.3929762  0.60661066 0.4446262  0.         0.         0.14785841\n",
      "  0.13226426 0.         0.         0.48175347 0.         0.\n",
      "  0.98690015 0.81083214 0.         0.         0.47319272 0.\n",
      "  0.46077824 0.81180686 0.30441818 0.39851907 0.         0.\n",
      "  0.         0.25508898 1.0722715  0.56111693 0.         0.94135255\n",
      "  0.         0.5863706  0.5998885  0.36705637 0.36869237 1.0585794\n",
      "  0.         0.         0.42467165 0.         0.         0.\n",
      "  0.         0.2853821  0.7244031  0.15053916]]\n",
      "Hi!\n",
      "[[0.         0.08141126 0.13788527 0.         0.         0.20417306\n",
      "  0.03806256 0.15380657 0.0076151  0.13764918 0.15614066 0.\n",
      "  0.         0.04871011 0.         0.         0.         0.03089549\n",
      "  0.         0.19250484 0.06919365 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01988879 0.1246521  0.         0.         0.\n",
      "  0.         0.         0.1021919  0.16070955 0.         0.\n",
      "  0.         0.         0.1024911  0.38175413 0.         0.06814005\n",
      "  0.14421499 0.10199247 0.         0.22491294 0.09714586 0.26769766\n",
      "  0.         0.18193997 0.         0.         0.         0.\n",
      "  0.04529418 0.09596734 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06561665 0.23242599 0.21576923 0.         0.         0.09218361\n",
      "  0.         0.03437798 0.05830162 0.01632564 0.14908257 0.\n",
      "  0.17073402 0.12955938 0.         0.02649933 0.         0.02426459\n",
      "  0.         0.17908067 0.11950728 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04772778 0.17877887 0.09418006 0.         0.         0.\n",
      "  0.         0.         0.19328626 0.0888596  0.         0.\n",
      "  0.         0.         0.15058793 0.16906847 0.         0.08397102\n",
      "  0.19356091 0.06138091 0.         0.21972892 0.02737688 0.3949856\n",
      "  0.         0.04261045 0.06275454 0.         0.02543357 0.\n",
      "  0.07179803 0.10900956 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.45261928 0.7850965  0.2255892  0.03451547 0.         0.49580628\n",
      "  0.2228983  0.66804206 0.         0.         0.25419718 0.\n",
      "  0.70690686 0.6531794  0.         0.         0.         0.29146013\n",
      "  0.         0.79881567 0.19770746 0.         0.         0.3016259\n",
      "  0.         0.         0.         0.20194411 0.         0.\n",
      "  0.8775931  0.6243781  0.14230096 0.         0.16752683 0.\n",
      "  0.         0.14345048 0.4863199  0.218347   0.         0.\n",
      "  0.         0.00877155 0.9084995  0.8880704  0.         0.264234\n",
      "  0.43247607 0.7822899  0.06686275 0.52903515 0.77052593 0.9116066\n",
      "  0.         0.27120546 0.23217875 0.         0.         0.\n",
      "  0.         0.29677716 0.12749462 0.        ]]\n",
      "Hi!\n",
      "[[0.18014278 0.31014872 0.7283183  0.         0.         0.48495537\n",
      "  0.69912434 0.47287205 0.7220449  0.         0.3563173  0.\n",
      "  0.5644384  0.         0.         0.64285886 0.07620374 0.7932427\n",
      "  0.14603849 0.20068587 0.6482348  0.06343941 0.         0.\n",
      "  0.29411227 0.         0.         0.07658899 0.         0.\n",
      "  0.42475483 0.12972616 0.         0.         0.48844028 0.\n",
      "  0.41781858 1.0990207  0.         0.4835728  0.04507928 0.\n",
      "  0.         0.56430566 0.3863936  0.24574257 0.         0.8464868\n",
      "  0.         0.58196807 0.6228598  0.11007436 0.1064899  0.52372485\n",
      "  0.         0.         0.23525314 0.12781507 0.         0.\n",
      "  0.         0.72968006 0.76135284 0.4651846 ]]\n",
      "Hi!\n",
      "[[0.33446693 0.         0.5446367  0.03743745 0.         0.64670914\n",
      "  0.99070686 1.1446617  0.62353396 0.         0.36320505 0.\n",
      "  0.62186176 0.         0.         0.5327757  0.         0.6059875\n",
      "  0.08213387 0.         0.6510894  0.         0.         0.\n",
      "  0.09264904 0.         0.         0.3427635  0.         0.\n",
      "  0.8297471  0.4454946  0.         0.         0.5107499  0.\n",
      "  0.17766826 1.1318885  0.         0.32889184 0.06957652 0.\n",
      "  0.         0.5708969  0.6054915  0.7232122  0.         0.4121357\n",
      "  0.         0.6839866  0.4838693  0.41632006 0.53364074 0.3915673\n",
      "  0.         0.         0.21669729 0.         0.         0.\n",
      "  0.         0.63552773 1.0862863  0.10005753]]\n",
      "Hi!\n",
      "[[0.64678466 0.2227982  1.2818805  0.         0.         1.0671419\n",
      "  0.34250188 0.6849389  0.6512996  0.         0.5289153  0.\n",
      "  0.48808897 0.         0.         0.28543538 0.1369138  0.56873864\n",
      "  0.         0.3339134  1.0006955  0.         0.         0.27719\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3128302  0.5900846  0.01918426 0.         0.01052189 0.\n",
      "  0.         0.7166213  0.         0.6084617  0.         0.\n",
      "  0.         0.4389755  0.34501553 0.54441375 0.         0.57549787\n",
      "  0.20522001 0.7958434  0.34859723 0.48205546 0.7321566  0.52368224\n",
      "  0.         0.766962   0.         0.         0.00836475 0.\n",
      "  0.         0.55596656 1.1392239  0.32363695]]\n",
      "Hi!\n",
      "[[0.60039365 0.22735623 1.228133   0.         0.         0.94630253\n",
      "  0.36504403 0.5627362  0.6204586  0.         0.54542357 0.\n",
      "  0.42653003 0.         0.         0.3642758  0.14756829 0.6583705\n",
      "  0.         0.32321417 0.9660634  0.         0.         0.18066947\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26317835 0.49378195 0.         0.         0.08204041 0.\n",
      "  0.         0.76177996 0.         0.63939255 0.         0.\n",
      "  0.         0.44665194 0.3174101  0.4415485  0.         0.5949541\n",
      "  0.15695584 0.7273473  0.37776217 0.38126847 0.53365356 0.4988994\n",
      "  0.         0.5862957  0.         0.05508232 0.00274709 0.\n",
      "  0.         0.61719054 1.0361458  0.32366908]]\n",
      "Hi!\n",
      "[[0.11446059 0.48672295 0.298222   0.         0.         0.143312\n",
      "  0.         0.         0.08235448 0.         0.21663007 0.\n",
      "  0.525865   0.23480278 0.         0.05188826 0.         0.08856506\n",
      "  0.         0.30030304 0.20408884 0.         0.         0.00366603\n",
      "  0.         0.         0.         0.06399143 0.         0.\n",
      "  0.27244693 0.279258   0.03482421 0.         0.         0.\n",
      "  0.         0.         0.31271732 0.04351681 0.         0.\n",
      "  0.         0.         0.20292109 0.07621391 0.         0.20139733\n",
      "  0.22612485 0.17950954 0.07835475 0.19785212 0.10829099 0.53471607\n",
      "  0.         0.         0.19625762 0.         0.04633086 0.\n",
      "  0.19760378 0.0956399  0.04723078 0.00871642]]\n",
      "Hi!\n",
      "[[0.14734963 0.3160242  0.5604599  0.         0.         0.33541816\n",
      "  0.         0.         0.29116887 0.03865796 0.3018006  0.\n",
      "  0.23125455 0.         0.         0.11014605 0.04601026 0.01218155\n",
      "  0.         0.4516122  0.3205392  0.         0.         0.01203268\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09730705 0.03245065 0.         0.         0.\n",
      "  0.         0.         0.         0.25410977 0.         0.\n",
      "  0.         0.         0.         0.05997526 0.         0.3834483\n",
      "  0.24255411 0.2313633  0.11209335 0.25686213 0.20753556 0.3905579\n",
      "  0.         0.06410219 0.         0.         0.19896841 0.\n",
      "  0.13116577 0.         0.05896151 0.20809133]]\n",
      "Hi!\n",
      "[[0.0000000e+00 1.0792941e-01 8.1294939e-02 0.0000000e+00 0.0000000e+00\n",
      "  6.9378585e-02 8.4423065e-02 1.7759597e-01 3.7821583e-02 1.3488851e-01\n",
      "  1.7484845e-01 0.0000000e+00 7.9263272e-03 8.5557856e-02 0.0000000e+00\n",
      "  5.4306623e-02 0.0000000e+00 3.4409821e-02 0.0000000e+00 1.7644978e-01\n",
      "  1.3568152e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0257553e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1149480e-01 7.8355901e-02\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2943310e-02\n",
      "  2.9891896e-01 0.0000000e+00 2.6096994e-04 9.8146446e-02 1.1315389e-01\n",
      "  0.0000000e+00 1.7324989e-01 2.6302032e-02 3.0955437e-01 0.0000000e+00\n",
      "  4.7268886e-02 1.3959184e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  4.9979895e-02 1.8864855e-01 0.0000000e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.39115468 0.5266894  0.3022691  0.11983638 0.         0.48611835\n",
      "  0.0359981  0.43828258 0.         0.         0.1499188  0.\n",
      "  0.34293836 0.5693664  0.         0.         0.         0.13007802\n",
      "  0.         0.6444098  0.09442994 0.         0.         0.14394243\n",
      "  0.         0.         0.         0.07943681 0.         0.\n",
      "  0.5390054  0.6312345  0.26598957 0.         0.         0.\n",
      "  0.         0.         0.53532887 0.15393925 0.         0.\n",
      "  0.         0.         0.8090461  0.7274351  0.         0.08299507\n",
      "  0.54939663 0.5556544  0.         0.4298778  0.57951736 0.9207455\n",
      "  0.         0.48779815 0.20054162 0.         0.         0.\n",
      "  0.09248117 0.17459303 0.06456666 0.        ]]\n",
      "Hi!\n",
      "[[0.48584092 0.02903278 1.2656274  0.         0.         0.6336411\n",
      "  0.6024466  0.5987202  1.2872288  0.         0.65175724 0.\n",
      "  0.40167663 0.         0.         0.82301587 0.29992628 0.93901294\n",
      "  0.2066299  0.         1.1700737  0.26070195 0.         0.41078848\n",
      "  0.11094826 0.         0.         0.         0.         0.\n",
      "  0.18435934 0.15513815 0.         0.         0.2483475  0.\n",
      "  0.25273684 1.1163071  0.         0.77939415 0.1585888  0.\n",
      "  0.         1.0909591  0.         0.14990751 0.         0.58241177\n",
      "  0.         0.6953059  0.7480248  0.07655433 0.28626803 0.\n",
      "  0.         0.         0.         0.45647982 0.         0.\n",
      "  0.         1.0883431  1.1482364  0.77871716]]\n",
      "Hi!\n",
      "[[7.32007980e-01 6.19167984e-02 1.56529415e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.34588718e-01 4.32782501e-01 3.33126754e-01\n",
      "  1.47888052e+00 0.00000000e+00 7.06977606e-01 0.00000000e+00\n",
      "  5.11303991e-02 0.00000000e+00 0.00000000e+00 8.56781185e-01\n",
      "  7.79361010e-01 9.78255093e-01 1.60710260e-04 0.00000000e+00\n",
      "  1.36100364e+00 5.35059154e-01 0.00000000e+00 5.91896534e-01\n",
      "  8.86530280e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.70912739e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.66096732e-01 9.49086905e-01 0.00000000e+00 9.39075768e-01\n",
      "  1.32678881e-01 0.00000000e+00 0.00000000e+00 1.38771558e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.56329429e-01\n",
      "  0.00000000e+00 8.91870618e-01 8.22298825e-01 0.00000000e+00\n",
      "  1.16733186e-01 0.00000000e+00 0.00000000e+00 1.77149475e-02\n",
      "  0.00000000e+00 8.12264502e-01 3.73806641e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.19064128e+00 8.83958578e-01 1.01851416e+00]]\n",
      "Hi!\n",
      "[[0.08065288 0.26628247 0.16017318 0.         0.         0.05723878\n",
      "  0.         0.03999862 0.07220592 0.01791479 0.13524544 0.\n",
      "  0.24025443 0.14180644 0.         0.03351581 0.         0.03486291\n",
      "  0.         0.18730597 0.12421567 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05610847 0.12352571 0.09665719 0.         0.         0.\n",
      "  0.         0.         0.19194268 0.02184763 0.         0.\n",
      "  0.         0.         0.15181983 0.16090882 0.         0.07903943\n",
      "  0.13430083 0.06678979 0.01932094 0.20735109 0.00918308 0.38289276\n",
      "  0.         0.         0.08739799 0.         0.00225119 0.\n",
      "  0.05763911 0.08179985 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.64701414 0.10035283 0.         0.6339688  0.         0.51064533\n",
      "  1.5359863  2.1397681  0.24617133 0.         0.10306634 0.\n",
      "  1.3362372  1.1407608  0.         0.43517324 0.         0.4771137\n",
      "  0.4579298  0.         0.31761858 0.51262194 0.         0.\n",
      "  0.26622802 0.         0.         1.1394292  0.         0.\n",
      "  1.9046968  0.96540153 0.34654313 0.         1.0632547  0.\n",
      "  0.3939214  1.3280573  0.4172589  0.10261735 0.39871782 0.\n",
      "  0.         0.67428434 1.7499685  1.5509902  0.         0.5246936\n",
      "  0.         0.8637393  0.6005891  0.74448943 1.0253398  1.3102115\n",
      "  0.         0.         0.77706385 0.         0.         0.\n",
      "  0.         0.3194784  1.2238839  0.        ]]\n",
      "Hi!\n",
      "[[0.7622286  0.4593186  0.2885999  0.48061612 0.         0.75308895\n",
      "  0.5212213  1.0690227  0.         0.         0.09991326 0.\n",
      "  0.50671864 0.7987495  0.         0.         0.         0.06902386\n",
      "  0.         0.87197745 0.06986063 0.         0.         0.23953198\n",
      "  0.         0.         0.         0.39704353 0.         0.\n",
      "  1.2014806  0.95691895 0.542683   0.         0.20048574 0.\n",
      "  0.         0.26591742 0.7231648  0.14694451 0.         0.\n",
      "  0.         0.17291632 1.411247   1.329095   0.         0.20185871\n",
      "  0.7174867  0.85604125 0.         0.75541663 1.0196376  1.2227982\n",
      "  0.         0.9173068  0.38141677 0.         0.         0.\n",
      "  0.         0.04400025 0.48454064 0.        ]]\n",
      "Hi!\n",
      "[[0.65538204 0.7693023  0.7736546  0.19828396 0.         0.6675847\n",
      "  0.         0.55934566 0.         0.         0.27895573 0.\n",
      "  0.8499997  0.66722006 0.         0.         0.         0.07823367\n",
      "  0.         0.8278846  0.34110278 0.         0.         0.1281269\n",
      "  0.         0.         0.         0.17221795 0.         0.\n",
      "  0.86680806 0.9313621  0.24551171 0.         0.05617822 0.\n",
      "  0.         0.09063674 0.753332   0.13357288 0.         0.\n",
      "  0.         0.         1.0809151  0.7934842  0.         0.20358211\n",
      "  0.76656884 0.764815   0.         0.7442868  0.96303654 1.168349\n",
      "  0.         0.7746518  0.18719801 0.         0.         0.\n",
      "  0.         0.11160078 0.5167054  0.        ]]\n",
      "Hi!\n",
      "[[1.0904269  0.         1.6202686  0.04948036 0.         1.1228999\n",
      "  0.46635148 0.7121484  0.87773263 0.02525319 0.58972806 0.\n",
      "  0.         0.         0.         0.33139044 0.7379516  0.71222645\n",
      "  0.         0.08242308 1.2316761  0.22044483 0.         0.742306\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15718529 0.19843751 0.         0.         0.\n",
      "  0.         0.582371   0.         0.9429792  0.         0.\n",
      "  0.         1.2232472  0.         0.3285651  0.         0.11750383\n",
      "  0.1144194  1.1122991  0.3009667  0.22000019 0.7425674  0.\n",
      "  0.         1.1586509  0.         0.34277415 0.         0.\n",
      "  0.18977268 0.9389002  0.89366984 0.35266122]]\n",
      "Hi!\n",
      "[[0.24895716 0.08927697 0.79637337 0.         0.         0.65054876\n",
      "  0.82535714 1.0840079  1.1101991  0.         0.47725272 0.\n",
      "  0.828566   0.         0.         0.7287449  0.         0.7435209\n",
      "  0.46318606 0.         0.88382536 0.         0.         0.11794126\n",
      "  0.14749016 0.         0.         0.3413662  0.         0.\n",
      "  0.7675783  0.38250098 0.         0.         0.5354937  0.\n",
      "  0.21326424 1.2501084  0.         0.44312602 0.18095556 0.\n",
      "  0.         0.8279505  0.28482863 0.4818788  0.         0.55389005\n",
      "  0.         0.69731474 0.79681116 0.37179524 0.5283688  0.19865356\n",
      "  0.         0.         0.1803173  0.02785121 0.         0.\n",
      "  0.         0.8331068  1.3377031  0.45866117]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47504112 0.98547643 0.82490665 0.         0.         0.4040925\n",
      "  0.22895199 0.6147624  1.3057069  0.         0.5933782  0.\n",
      "  2.1652658  0.30140916 0.         1.0628258  0.         0.8204418\n",
      "  1.4809775  0.19454482 0.9539242  0.01329443 0.         0.04486577\n",
      "  0.4861809  0.         0.         0.5263944  0.         0.\n",
      "  1.0659047  0.70205575 0.         0.         0.5808403  0.\n",
      "  0.8052935  1.2396499  0.         0.60097015 0.09439859 0.\n",
      "  0.         0.40803033 0.7609889  0.11337015 0.         1.3169574\n",
      "  0.         0.97626615 1.267402   0.30586326 0.3715859  0.8772632\n",
      "  0.         0.         0.43988732 0.         0.00677635 0.\n",
      "  0.         0.55786306 1.3213176  0.89795125]]\n",
      "Hi!\n",
      "[[0.65389043 0.21848099 0.89620906 0.16349696 0.         1.16713\n",
      "  0.43399513 0.78393626 0.         0.13438427 0.29951736 0.\n",
      "  0.         0.         0.         0.         0.         0.22337481\n",
      "  0.         0.75320864 0.47447866 0.         0.         0.15947127\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22656906 0.556464   0.1428283  0.         0.         0.\n",
      "  0.         0.1792537  0.         0.48927313 0.         0.\n",
      "  0.         0.14157246 0.5680997  1.0447578  0.         0.1418802\n",
      "  0.5867862  0.9522201  0.         0.70295566 0.98076975 0.65531737\n",
      "  0.         1.3874696  0.         0.         0.02580785 0.\n",
      "  0.33942476 0.29390317 0.5118999  0.        ]]\n",
      "Hi!\n",
      "[[0.9911825  0.         1.8809029  0.         0.         0.8230582\n",
      "  1.0798135  1.0970666  2.0088592  0.         0.76958853 0.\n",
      "  0.         0.         0.         1.2281648  0.9898866  1.077588\n",
      "  0.2714373  0.         1.6564436  0.7962996  0.         0.8357792\n",
      "  0.00812077 0.         0.         0.         0.         0.\n",
      "  0.         0.03881445 0.02286751 0.         0.05610102 0.\n",
      "  0.44862142 1.3612334  0.         1.1029956  0.39615905 0.\n",
      "  0.         2.343314   0.         0.         0.         0.589228\n",
      "  0.         0.9094187  1.1214758  0.         0.28403294 0.\n",
      "  0.         0.18483695 0.         1.1506687  0.         0.\n",
      "  0.         1.4931314  1.5717456  1.0301877 ]]\n",
      "Hi!\n",
      "[[0.47425634 0.7487346  0.65802085 0.         0.         0.6916549\n",
      "  0.         0.2551651  0.07674915 0.         0.3728009  0.\n",
      "  0.8139451  0.233185   0.         0.03728994 0.         0.40758362\n",
      "  0.         0.81918865 0.41376087 0.         0.         0.06814087\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.57565534 0.6354772  0.         0.         0.046346   0.\n",
      "  0.         0.34761685 0.14563625 0.4024531  0.         0.\n",
      "  0.         0.00336709 0.68880165 0.62621224 0.         0.63927335\n",
      "  0.4710932  0.65593654 0.14170104 0.43058372 0.45297235 0.9339852\n",
      "  0.         0.40826327 0.09805759 0.         0.02689626 0.\n",
      "  0.         0.18420063 0.3776964  0.07066123]]\n",
      "Hi!\n",
      "[[0.17875518 0.         0.74018234 0.         0.         0.6279598\n",
      "  1.1890485  1.3515885  1.3503137  0.         0.47039756 0.\n",
      "  0.88796264 0.         0.         0.9533384  0.         0.79958147\n",
      "  0.76815015 0.         0.9188105  0.09875475 0.         0.01975694\n",
      "  0.309907   0.         0.         0.48870528 0.         0.\n",
      "  0.8888638  0.30360413 0.         0.         0.69492346 0.\n",
      "  0.5346681  1.5167696  0.         0.38557163 0.3042858  0.\n",
      "  0.         1.1659881  0.31725156 0.47531748 0.         0.6212303\n",
      "  0.         0.7015891  0.98341405 0.3481988  0.4155837  0.10363264\n",
      "  0.         0.         0.33070287 0.24091712 0.         0.\n",
      "  0.         0.8862901  1.5477197  0.55920875]]\n",
      "Hi!\n",
      "[[0.3214575  0.         0.50660545 0.04288811 0.         0.6051641\n",
      "  1.0566179  1.0524069  0.50914866 0.         0.3095098  0.\n",
      "  0.17254823 0.         0.         0.4416302  0.         0.61237985\n",
      "  0.         0.05388849 0.54125106 0.         0.         0.\n",
      "  0.04131321 0.         0.         0.1502673  0.         0.\n",
      "  0.6065496  0.34295806 0.         0.         0.43238747 0.\n",
      "  0.09062193 1.0239779  0.         0.41536352 0.04670952 0.\n",
      "  0.         0.5606456  0.45310757 0.6663387  0.         0.31867853\n",
      "  0.         0.69328004 0.33990404 0.32987964 0.3413542  0.34955448\n",
      "  0.         0.0900122  0.14781515 0.         0.         0.\n",
      "  0.         0.68785304 0.836117   0.00115823]]\n",
      "Hi!\n",
      "[[0.29723498 0.5599689  0.90031344 0.         0.         0.4909305\n",
      "  0.3770177  0.77479935 1.302664   0.         0.57516617 0.\n",
      "  1.5532461  0.         0.         0.9090775  0.         0.80822676\n",
      "  0.96072793 0.         0.9984232  0.         0.         0.\n",
      "  0.20095715 0.         0.         0.48541784 0.         0.\n",
      "  0.95270663 0.460343   0.         0.         0.4975619  0.\n",
      "  0.4776611  1.1629587  0.         0.52768755 0.16977003 0.\n",
      "  0.         0.5437499  0.42817736 0.26270187 0.         0.8629676\n",
      "  0.         0.9075029  1.0067073  0.31126907 0.48583937 0.40726817\n",
      "  0.         0.         0.25792497 0.03732723 0.         0.\n",
      "  0.         0.68714195 1.3432026  0.8227017 ]]\n",
      "Hi!\n",
      "[[0.04232931 0.22854798 0.19338663 0.         0.         0.13999607\n",
      "  0.         0.         0.0528846  0.06998208 0.18179369 0.\n",
      "  0.14204049 0.07251876 0.         0.03827982 0.         0.05786185\n",
      "  0.         0.23636135 0.13630465 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0250952  0.08248831 0.05307791 0.         0.         0.\n",
      "  0.         0.         0.08372769 0.10932089 0.         0.\n",
      "  0.         0.         0.09430473 0.18101972 0.         0.12223137\n",
      "  0.15820652 0.06410363 0.         0.14132348 0.02089187 0.30241904\n",
      "  0.         0.         0.04209895 0.         0.05996434 0.\n",
      "  0.07343092 0.01619291 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.03547086 0.         0.08186828 0.         0.\n",
      "  0.40075696 0.45710006 0.11856133 0.0421359  0.         0.\n",
      "  0.         0.3512474  0.         0.17247298 0.         0.12594667\n",
      "  0.         0.00982836 0.12222296 0.         0.         0.\n",
      "  0.         0.         0.         0.15925659 0.         0.\n",
      "  0.20045783 0.28992742 0.3418122  0.         0.         0.\n",
      "  0.         0.10851764 0.39768943 0.01475042 0.         0.\n",
      "  0.         0.08712965 0.40820667 0.5513678  0.         0.01053821\n",
      "  0.22217754 0.2742535  0.03082551 0.2681175  0.03484286 0.4276869\n",
      "  0.         0.29249373 0.09024733 0.         0.         0.\n",
      "  0.01775677 0.24675883 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.15770258 0.35705823 0.6820692  0.         0.         0.15905763\n",
      "  0.         0.         0.2452995  0.         0.25632533 0.\n",
      "  0.18949525 0.         0.         0.1710993  0.05302719 0.11806681\n",
      "  0.         0.3993447  0.2275708  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3060035  0.09554908 0.         0.         0.\n",
      "  0.         0.0687546  0.01116438 0.19505942 0.         0.\n",
      "  0.         0.         0.         0.07151505 0.         0.19053079\n",
      "  0.20885366 0.31390974 0.1038606  0.2520326  0.11379827 0.3955852\n",
      "  0.         0.18598902 0.         0.         0.03005278 0.\n",
      "  0.0892814  0.27198073 0.15457788 0.0905235 ]]\n",
      "Hi!\n",
      "[[0.38977396 0.6808532  1.0770915  0.         0.         0.5904317\n",
      "  0.25182182 0.49819067 1.0866573  0.         0.60490197 0.\n",
      "  1.362152   0.         0.         0.73539186 0.         0.74548715\n",
      "  0.77911615 0.1402013  0.9987523  0.         0.         0.02829027\n",
      "  0.14842848 0.         0.         0.22707473 0.         0.\n",
      "  0.717832   0.5156493  0.         0.         0.31635943 0.\n",
      "  0.40207478 1.0014861  0.         0.6328735  0.04366741 0.\n",
      "  0.         0.39264905 0.43689436 0.18697728 0.         0.9234935\n",
      "  0.         0.81441134 0.863385   0.30706415 0.4428925  0.54138076\n",
      "  0.         0.         0.17517422 0.0380792  0.01596021 0.\n",
      "  0.         0.64369935 1.181328   0.7987271 ]]\n",
      "Hi!\n",
      "[[0.45567912 0.         0.5357245  0.33597907 0.         0.908601\n",
      "  1.071405   1.2310902  0.06241819 0.02719785 0.22370577 0.\n",
      "  0.         0.         0.         0.07399759 0.         0.41037476\n",
      "  0.         0.3068482  0.46294102 0.         0.         0.00781605\n",
      "  0.         0.         0.         0.05582079 0.         0.\n",
      "  0.6097644  0.51695555 0.15573771 0.         0.24959818 0.\n",
      "  0.         0.6244111  0.         0.49915484 0.03556168 0.\n",
      "  0.         0.36361116 0.63434535 1.0649247  0.         0.\n",
      "  0.1627611  1.0023675  0.         0.5794191  0.8618277  0.43356216\n",
      "  0.         0.7744777  0.         0.         0.         0.\n",
      "  0.         0.5994805  0.7112855  0.        ]]\n",
      "Hi!\n",
      "[[0.8846513  0.2783928  1.7983218  0.         0.         1.1193331\n",
      "  0.         0.08422042 0.66718    0.         0.65018076 0.\n",
      "  0.12993783 0.         0.         0.29110527 0.5489522  0.6900919\n",
      "  0.         0.62240016 1.1540602  0.00566237 0.         0.37331045\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4336944  0.09467363 0.         0.         0.\n",
      "  0.         0.4643237  0.         0.9302967  0.         0.\n",
      "  0.         0.49163592 0.         0.25990283 0.         0.7719778\n",
      "  0.3693883  0.7517677  0.31500775 0.2641529  0.49406174 0.44532463\n",
      "  0.         0.9181089  0.         0.27719566 0.13879947 0.\n",
      "  0.1871467  0.6065996  0.92914075 0.5653742 ]]\n",
      "Hi!\n",
      "[[0.44614547 0.31731915 1.073621   0.         0.         0.6748819\n",
      "  0.28140274 0.44859475 0.6048219  0.         0.49930507 0.\n",
      "  0.26656088 0.         0.         0.32427472 0.10193091 0.6546654\n",
      "  0.         0.3376617  0.8336717  0.         0.         0.04896288\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23748936 0.33587703 0.02823785 0.         0.10414308 0.\n",
      "  0.         0.68280613 0.         0.55950636 0.         0.\n",
      "  0.         0.33907667 0.2802282  0.38701886 0.         0.39694315\n",
      "  0.01274629 0.70991516 0.341616   0.27958664 0.41990188 0.28120053\n",
      "  0.         0.28777575 0.         0.         0.05573661 0.\n",
      "  0.         0.68321234 0.8821594  0.20474756]]\n",
      "Hi!\n",
      "[[0.09503609 0.1490048  0.3219994  0.         0.         0.15532579\n",
      "  0.11317383 0.08146495 0.31941578 0.0436728  0.17803682 0.\n",
      "  0.03129668 0.         0.         0.2297474  0.02687303 0.2536383\n",
      "  0.         0.10515805 0.2252284  0.         0.         0.\n",
      "  0.04534762 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23848554 0.         0.0718182  0.         0.\n",
      "  0.         0.12434901 0.         0.13548179 0.         0.16596812\n",
      "  0.02158558 0.23654582 0.16623095 0.09235511 0.         0.15027244\n",
      "  0.         0.12830418 0.         0.02195515 0.         0.\n",
      "  0.01857145 0.2308521  0.10910819 0.170513  ]]\n",
      "Hi!\n",
      "[[0.56105137 0.5050377  0.         0.26950163 0.         0.37607935\n",
      "  0.7836723  1.2868363  0.04866641 0.         0.2391428  0.\n",
      "  1.1041247  1.0267657  0.         0.26993588 0.         0.40627915\n",
      "  0.         0.41864014 0.25027934 0.17320019 0.         0.28384066\n",
      "  0.         0.         0.         0.85267496 0.         0.\n",
      "  1.4712986  0.8662588  0.20959012 0.         0.71297544 0.\n",
      "  0.         0.7226307  0.51992875 0.12120056 0.0801918  0.\n",
      "  0.         0.38335475 1.3292125  1.177949   0.         0.20318554\n",
      "  0.0663448  0.9640643  0.3655664  0.5483142  0.9783883  0.99484086\n",
      "  0.         0.         0.39426836 0.         0.         0.\n",
      "  0.         0.3754264  0.6177723  0.        ]]\n",
      "Hi!\n",
      "[[0.50759786 0.         0.9378531  0.         0.         0.732621\n",
      "  0.9954968  0.8593802  0.80298066 0.         0.4733916  0.\n",
      "  0.0586316  0.         0.         0.5625357  0.11605773 0.8219825\n",
      "  0.         0.00207141 0.86134386 0.0662513  0.         0.07053527\n",
      "  0.10299907 0.         0.         0.         0.         0.\n",
      "  0.33564433 0.25194547 0.01895103 0.         0.38950062 0.\n",
      "  0.17336929 1.0706115  0.         0.56047714 0.11124653 0.\n",
      "  0.         0.90140086 0.24198723 0.48601943 0.         0.5299848\n",
      "  0.         0.7256883  0.4743012  0.22979435 0.23467614 0.30057618\n",
      "  0.         0.         0.10773887 0.1602108  0.         0.\n",
      "  0.         0.900416   0.92452353 0.38596383]]\n",
      "Hi!\n",
      "[[0.         0.13119808 0.13033627 0.         0.         0.33434325\n",
      "  0.24111365 0.36892834 0.0794508  0.18681893 0.18604589 0.\n",
      "  0.         0.         0.         0.05516555 0.         0.09083727\n",
      "  0.         0.3102051  0.1268249  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11168635 0.         0.         0.\n",
      "  0.         0.01231846 0.06898771 0.3020231  0.         0.\n",
      "  0.         0.         0.04017019 0.5096929  0.         0.\n",
      "  0.19194293 0.35402063 0.         0.22788766 0.1378934  0.24323146\n",
      "  0.         0.2921195  0.         0.         0.         0.\n",
      "  0.07168222 0.2548929  0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0241048  0.8074543  2.352993   0.         0.         1.5247213\n",
      "  0.         0.         0.8625308  0.         0.8684122  0.\n",
      "  0.76251054 0.         0.         0.42560953 0.937676   0.7603043\n",
      "  0.         1.0796098  1.4178852  0.09017597 0.         0.23635024\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.49687573 0.         0.         0.         0.\n",
      "  0.12989537 0.37946686 0.         1.4398196  0.         0.\n",
      "  0.         0.38177386 0.         0.         0.         1.3250824\n",
      "  0.72388685 1.0666285  0.51108664 0.39724997 0.46466655 0.97270304\n",
      "  0.         1.1029274  0.         0.5602779  0.31937507 0.\n",
      "  0.31347814 0.48018235 1.0452936  0.9695602 ]]\n",
      "Hi!\n",
      "[[0.59394497 0.487065   0.26661235 0.27828932 0.         0.5767774\n",
      "  0.41601703 0.8476848  0.         0.         0.16125709 0.\n",
      "  0.4970055  0.7272375  0.         0.         0.         0.2287989\n",
      "  0.         0.7085484  0.11679726 0.         0.         0.17724004\n",
      "  0.         0.         0.         0.28781012 0.         0.\n",
      "  0.9504797  0.8279466  0.31590444 0.         0.19959168 0.\n",
      "  0.         0.36144063 0.4751362  0.17632212 0.         0.\n",
      "  0.         0.07784756 1.1418073  1.077695   0.         0.1888264\n",
      "  0.51460046 0.8016526  0.         0.5988086  0.73945355 1.0140413\n",
      "  0.         0.5482743  0.2660619  0.         0.         0.\n",
      "  0.         0.195056   0.33871415 0.        ]]\n",
      "Hi!\n",
      "[[0.43649033 0.77205515 1.511557   0.         0.         0.7607947\n",
      "  0.07211195 0.         1.2071505  0.         0.698077   0.\n",
      "  0.8751024  0.         0.         0.62629366 0.4581886  0.7496961\n",
      "  0.323895   0.4672482  1.2486615  0.26262808 0.         0.2789377\n",
      "  0.04436749 0.         0.         0.         0.         0.\n",
      "  0.         0.1930356  0.         0.         0.         0.\n",
      "  0.01578446 0.61488086 0.         0.88901645 0.         0.\n",
      "  0.         0.41936898 0.         0.         0.         0.9139302\n",
      "  0.03667335 0.917878   0.7584081  0.10066172 0.14831777 0.25328025\n",
      "  0.         0.         0.         0.46557546 0.20686014 0.\n",
      "  0.         0.80028355 0.80290437 1.0677946 ]]\n",
      "Hi!\n",
      "[[0.41442144 0.45793253 0.00237455 0.15613152 0.         0.4472722\n",
      "  0.98741496 1.1698365  0.22983174 0.         0.22146498 0.\n",
      "  1.0300455  0.6900905  0.         0.35918772 0.         0.5992759\n",
      "  0.09854393 0.25115678 0.30133307 0.06320199 0.         0.\n",
      "  0.23499268 0.         0.         0.576901   0.         0.\n",
      "  1.1837142  0.64243776 0.10620904 0.         0.70182776 0.\n",
      "  0.28935328 1.0624328  0.01108128 0.21983545 0.07965415 0.\n",
      "  0.         0.32100978 1.1621134  0.99304533 0.         0.6408428\n",
      "  0.         0.82467836 0.50196904 0.41599017 0.53715676 0.86774135\n",
      "  0.         0.         0.43306932 0.         0.         0.\n",
      "  0.         0.474895   0.6995845  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.14479251 0.07752563 0.         0.         0.06982429\n",
      "  0.0102579  0.16508122 0.         0.06361466 0.12881996 0.\n",
      "  0.04761144 0.17375997 0.         0.03372294 0.         0.05594343\n",
      "  0.         0.15758336 0.07413581 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02269842 0.09602711 0.13601166 0.         0.         0.\n",
      "  0.         0.         0.12000942 0.06161912 0.         0.\n",
      "  0.         0.         0.17357165 0.2746839  0.         0.\n",
      "  0.12776697 0.12480789 0.         0.14973117 0.02588834 0.31485474\n",
      "  0.         0.05794473 0.06365461 0.         0.         0.\n",
      "  0.0662304  0.11490136 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3628957  0.9161116  0.2633894  0.         0.         0.0983644\n",
      "  0.45656028 0.88900983 0.8730309  0.         0.38936383 0.\n",
      "  1.8612665  0.7556837  0.         0.8619428  0.         0.6924036\n",
      "  0.96084803 0.24716638 0.50671035 0.16268866 0.         0.10582095\n",
      "  0.3842283  0.         0.         0.5762363  0.         0.\n",
      "  1.1875907  0.6907112  0.         0.         0.68212056 0.\n",
      "  0.66890335 1.1210335  0.14902253 0.3129047  0.0620276  0.\n",
      "  0.         0.4484655  0.93441033 0.55651414 0.         0.92747295\n",
      "  0.         0.74793357 1.0677159  0.24732108 0.48719153 0.8630969\n",
      "  0.         0.         0.5208244  0.         0.         0.\n",
      "  0.         0.5850701  0.7611333  0.3856762 ]]\n",
      "Hi!\n",
      "[[0.02004693 0.16287373 0.19545378 0.         0.         0.18398173\n",
      "  0.00234884 0.0455453  0.07802629 0.11389959 0.1901925  0.\n",
      "  0.12220816 0.06965479 0.         0.         0.         0.07104664\n",
      "  0.         0.15953426 0.13786118 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05797382 0.06481522 0.         0.         0.\n",
      "  0.         0.         0.07672673 0.09909137 0.         0.\n",
      "  0.         0.         0.16085935 0.24350755 0.         0.14252047\n",
      "  0.09136195 0.07025637 0.         0.14069296 0.00861933 0.33282608\n",
      "  0.         0.01405065 0.01123567 0.         0.01444779 0.\n",
      "  0.04428698 0.02635662 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.8654648  0.         1.1290522  0.3169798  0.         1.2789978\n",
      "  1.0949702  1.121605   0.28160065 0.01798007 0.37214887 0.\n",
      "  0.         0.         0.         0.14586212 0.31646255 0.5549509\n",
      "  0.         0.2569714  0.7930199  0.         0.         0.29645348\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10176506 0.46240723 0.17752814 0.         0.03415695 0.\n",
      "  0.         0.5936124  0.         0.7571871  0.06465695 0.\n",
      "  0.         0.9019751  0.22989906 0.83673537 0.         0.08625199\n",
      "  0.2224486  0.9959013  0.         0.52149636 0.83229023 0.36668348\n",
      "  0.         1.3253264  0.         0.         0.         0.\n",
      "  0.256145   0.74813914 0.952414   0.        ]]\n",
      "Hi!\n",
      "[[0.6021391  0.4110642  1.2943816  0.         0.         0.7047364\n",
      "  0.         0.06459726 0.23564768 0.04539502 0.3211111  0.\n",
      "  0.05534072 0.         0.         0.04110863 0.416335   0.23165326\n",
      "  0.         0.56488526 0.62755764 0.         0.         0.1927985\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3691709  0.15988936 0.         0.         0.\n",
      "  0.         0.08731326 0.         0.59334475 0.         0.\n",
      "  0.         0.07834263 0.0501956  0.19825406 0.         0.4467996\n",
      "  0.4832     0.57673687 0.17918114 0.34118742 0.5985549  0.48142493\n",
      "  0.         0.8387843  0.         0.         0.15037426 0.\n",
      "  0.38095364 0.4187128  0.330675   0.34993112]]\n",
      "Hi!\n",
      "[[0.0570558  0.5453217  0.41154867 0.         0.         0.351934\n",
      "  0.52938914 0.76924294 0.4919343  0.         0.35620588 0.\n",
      "  0.8071287  0.303303   0.         0.497375   0.         0.6133882\n",
      "  0.         0.30419847 0.50620395 0.         0.         0.\n",
      "  0.         0.         0.         0.27772638 0.         0.\n",
      "  0.8022384  0.43360376 0.         0.         0.31268582 0.\n",
      "  0.         0.7324841  0.         0.39246634 0.         0.\n",
      "  0.         0.31613815 0.4772683  0.64602625 0.         0.11278973\n",
      "  0.         0.9557318  0.52884364 0.26974756 0.69858027 0.4167155\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7265516  0.36805955 0.09057879]]\n",
      "Hi!\n",
      "[[0.0082711  0.22002663 0.19502835 0.         0.         0.11545577\n",
      "  0.         0.03537478 0.04838551 0.03090439 0.13696133 0.\n",
      "  0.1890228  0.09807575 0.         0.00454309 0.         0.00044055\n",
      "  0.         0.19305873 0.08243234 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01827346 0.14111385 0.06063966 0.         0.         0.\n",
      "  0.         0.         0.09350198 0.06870383 0.         0.\n",
      "  0.         0.         0.14052257 0.16785921 0.         0.17219515\n",
      "  0.11672748 0.04994827 0.         0.15556176 0.01539237 0.34818435\n",
      "  0.         0.00913968 0.07309812 0.         0.02680773 0.\n",
      "  0.04531225 0.00628198 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.2251267  0.10250165 0.7741278  0.         0.         0.43879187\n",
      "  0.8694464  0.628816   0.7322693  0.         0.35466152 0.\n",
      "  0.28007105 0.         0.         0.48577955 0.         0.762044\n",
      "  0.         0.07442205 0.6097339  0.         0.         0.\n",
      "  0.19805309 0.         0.         0.06226116 0.         0.\n",
      "  0.37968686 0.11974935 0.         0.         0.4448768  0.\n",
      "  0.21609399 0.99325573 0.         0.34910828 0.         0.\n",
      "  0.         0.61027634 0.30872488 0.41591194 0.         0.58112496\n",
      "  0.         0.58024967 0.54489607 0.1815374  0.1246084  0.32967514\n",
      "  0.         0.         0.11169297 0.08047523 0.         0.\n",
      "  0.         0.8512257  0.8584508  0.3179147 ]]\n",
      "Hi!\n",
      "[[0.3689048  0.         0.71716046 0.         0.         0.5612854\n",
      "  1.2314192  1.031148   0.86600524 0.         0.38680682 0.\n",
      "  0.07477526 0.         0.         0.6427695  0.01424482 0.8649075\n",
      "  0.         0.         0.7453935  0.1212379  0.         0.03135301\n",
      "  0.23428749 0.         0.         0.05766197 0.         0.\n",
      "  0.4612562  0.09408639 0.         0.         0.5658647  0.\n",
      "  0.2032649  1.2563503  0.         0.5102243  0.12070041 0.\n",
      "  0.         0.97790074 0.24470402 0.49823445 0.         0.42164612\n",
      "  0.         0.67743814 0.534214   0.20555799 0.15315637 0.18087456\n",
      "  0.         0.         0.16150944 0.10222083 0.         0.\n",
      "  0.         1.0094199  0.9619962  0.30981636]]\n",
      "Hi!\n",
      "[[0.01264311 0.22486243 0.20045513 0.         0.         0.1895909\n",
      "  0.         0.12066966 0.102823   0.10324544 0.20912308 0.\n",
      "  0.13381428 0.10238841 0.         0.07567075 0.         0.12212429\n",
      "  0.         0.23017506 0.18541694 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11390163 0.06151029 0.         0.         0.\n",
      "  0.         0.         0.09872536 0.13588962 0.         0.\n",
      "  0.         0.         0.11316504 0.26796973 0.         0.12408625\n",
      "  0.15549892 0.15581547 0.00914379 0.18931471 0.06149965 0.38037044\n",
      "  0.         0.0501026  0.02042775 0.         0.01671186 0.\n",
      "  0.06003452 0.20246218 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.39588064 0.83409035 1.5206373  0.         0.         0.68819\n",
      "  0.05477783 0.04950683 1.2544961  0.         0.74578136 0.\n",
      "  1.4181274  0.         0.         0.9228994  0.11151412 0.90944844\n",
      "  0.88517505 0.34450468 1.2258146  0.14197433 0.         0.\n",
      "  0.297772   0.         0.         0.15217347 0.         0.\n",
      "  0.44513324 0.4560665  0.         0.         0.32185107 0.\n",
      "  0.5363913  1.0528342  0.         0.8065759  0.07143699 0.\n",
      "  0.         0.34774595 0.3690611  0.         0.         1.2846581\n",
      "  0.         0.9201035  1.0085272  0.21163471 0.1790489  0.62360096\n",
      "  0.         0.         0.1718079  0.3225652  0.1345852  0.\n",
      "  0.         0.73799837 1.2703366  1.0906184 ]]\n",
      "Hi!\n",
      "[[0.3315822  0.83623236 0.2810054  0.         0.         0.2721531\n",
      "  0.08787224 0.34176674 0.18883379 0.         0.30673414 0.\n",
      "  1.0448998  0.6464044  0.         0.06617055 0.         0.14406914\n",
      "  0.         0.4135564  0.4031641  0.         0.         0.0731382\n",
      "  0.         0.         0.         0.601652   0.         0.\n",
      "  0.7061365  0.5104041  0.         0.         0.         0.\n",
      "  0.         0.         0.7601386  0.01924822 0.         0.\n",
      "  0.         0.         0.50675917 0.37132075 0.         0.0153719\n",
      "  0.4561889  0.44495374 0.42765203 0.16531886 0.5197127  0.9462486\n",
      "  0.         0.         0.4029358  0.         0.0618315  0.\n",
      "  0.23120993 0.16614033 0.37809542 0.06497859]]\n",
      "Hi!\n",
      "[[0.31832728 0.         0.19770208 0.18483466 0.         0.5299583\n",
      "  1.523025   1.53735    0.5942556  0.         0.27436587 0.\n",
      "  0.52201205 0.13393946 0.         0.5975898  0.         0.7476177\n",
      "  0.01437637 0.         0.44695958 0.16878234 0.         0.\n",
      "  0.27440503 0.         0.         0.45843655 0.         0.\n",
      "  1.0693009  0.37663487 0.         0.         0.79842305 0.\n",
      "  0.2456242  1.4038013  0.         0.3042924  0.20603567 0.\n",
      "  0.         0.73203444 0.78011554 0.9802689  0.         0.30298206\n",
      "  0.         0.8054474  0.5927122  0.46164373 0.4930699  0.41595098\n",
      "  0.         0.         0.34268194 0.         0.         0.\n",
      "  0.         0.8110665  1.0884582  0.        ]]\n",
      "Hi!\n",
      "[[0.21953532 0.4200378  0.6802111  0.         0.         0.913849\n",
      "  0.42986315 0.32802635 0.44784746 0.16360842 0.46115997 0.\n",
      "  0.12766327 0.         0.         0.04780878 0.         0.07669388\n",
      "  0.         0.58331245 0.5988008  0.         0.         0.0223447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0216243  0.         0.00835112 0.         0.         0.\n",
      "  0.         0.14028054 0.         0.50984055 0.         0.\n",
      "  0.         0.024222   0.12212694 0.71515214 0.         0.40178147\n",
      "  0.21656707 0.5280999  0.28181154 0.35969183 0.5060158  0.43243042\n",
      "  0.         0.40894905 0.         0.         0.01173072 0.\n",
      "  0.         0.21354805 0.19694547 0.09411193]]\n",
      "Hi!\n",
      "[[0.45368853 0.         0.08062264 0.4358747  0.         0.68890226\n",
      "  1.5244159  1.8900485  0.37257317 0.         0.23407063 0.\n",
      "  0.813659   0.6052405  0.         0.46721074 0.         0.5808014\n",
      "  0.08072133 0.         0.42962012 0.25865653 0.         0.\n",
      "  0.16851577 0.         0.         0.90490746 0.         0.\n",
      "  1.4786152  0.6904372  0.09449176 0.         0.9363577  0.\n",
      "  0.20619495 1.300584   0.02721456 0.18054366 0.36157507 0.\n",
      "  0.         0.5222823  1.293869   1.3432053  0.         0.25559038\n",
      "  0.         0.8985724  0.41756144 0.70185566 0.8528182  0.6852577\n",
      "  0.         0.         0.49359977 0.         0.         0.\n",
      "  0.         0.6064146  1.3169299  0.        ]]\n",
      "Hi!\n",
      "[[0.02962408 0.24778377 0.31241858 0.         0.         0.12504533\n",
      "  0.         0.         0.06630844 0.04195417 0.1827262  0.\n",
      "  0.14425912 0.02415015 0.         0.05261601 0.         0.02987773\n",
      "  0.         0.26797014 0.16016883 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1379484  0.04659617 0.         0.         0.\n",
      "  0.         0.         0.11257806 0.12413161 0.         0.\n",
      "  0.         0.         0.08956117 0.17711686 0.         0.12769191\n",
      "  0.18551965 0.08962626 0.00929587 0.24187884 0.09214142 0.33443362\n",
      "  0.         0.04547004 0.         0.         0.06488403 0.\n",
      "  0.06002317 0.09448362 0.         0.02169172]]\n",
      "Hi!\n",
      "[[0.24054077 0.7663444  0.5215876  0.         0.         0.5963118\n",
      "  0.         0.21333466 0.0051688  0.         0.3133237  0.\n",
      "  0.5564141  0.28401914 0.         0.         0.         0.25171596\n",
      "  0.         0.79342777 0.29714257 0.         0.         0.06717585\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35598683 0.41936636 0.0024907  0.         0.         0.\n",
      "  0.         0.         0.22215737 0.20705971 0.         0.\n",
      "  0.         0.         0.4715773  0.5411058  0.         0.40379867\n",
      "  0.45665425 0.5332457  0.02174429 0.38553303 0.49318975 0.7052628\n",
      "  0.         0.33738592 0.12327447 0.         0.07158889 0.\n",
      "  0.13167259 0.2056785  0.12221103 0.        ]]\n",
      "Hi!\n",
      "[[1.2270116  0.04373167 1.9145337  0.         0.         1.2700453\n",
      "  0.34446988 0.5510716  0.92091614 0.         0.6652805  0.\n",
      "  0.         0.         0.         0.33146644 0.9599364  0.7981453\n",
      "  0.         0.1619177  1.3983517  0.40039796 0.         0.74313486\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11813822 0.23567924 0.         0.         0.\n",
      "  0.         0.43668428 0.         1.0386176  0.         0.\n",
      "  0.         1.4191282  0.         0.32456046 0.         0.04654608\n",
      "  0.17861904 1.3222331  0.38874203 0.16621329 0.81770444 0.\n",
      "  0.         1.4286602  0.         0.45459962 0.         0.\n",
      "  0.36045972 0.9032991  0.77325046 0.45183614]]\n",
      "Hi!\n",
      "[[0.7336285  0.74499685 0.17634018 0.23447149 0.         0.4608402\n",
      "  0.4520434  1.018103   0.0886724  0.         0.29544216 0.\n",
      "  1.4060926  0.98221296 0.         0.28104407 0.         0.4648969\n",
      "  0.22850303 0.5842747  0.323035   0.04590517 0.         0.28746173\n",
      "  0.         0.         0.         0.761595   0.         0.\n",
      "  1.3729134  0.9583389  0.12470367 0.         0.6130395  0.\n",
      "  0.35732234 0.78103364 0.58072585 0.18663414 0.01511549 0.\n",
      "  0.         0.3381471  1.4365124  1.0356432  0.         0.5892783\n",
      "  0.12130361 0.7720198  0.40881044 0.5245673  0.73938894 1.1626692\n",
      "  0.         0.         0.5153889  0.         0.         0.\n",
      "  0.         0.16083562 0.7469649  0.        ]]\n",
      "Hi!\n",
      "[[0.7798176  0.32274705 1.1153984  0.11113855 0.         1.2786653\n",
      "  0.3185798  0.6319804  0.         0.14842255 0.36378026 0.\n",
      "  0.         0.         0.         0.         0.03303855 0.22281295\n",
      "  0.         0.84134954 0.58756065 0.         0.         0.18130386\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21392801 0.6062645  0.14631248 0.         0.         0.\n",
      "  0.         0.17833075 0.         0.5315689  0.         0.\n",
      "  0.         0.03164108 0.61856264 0.9642724  0.         0.44249415\n",
      "  0.70174795 0.90639347 0.         0.68498486 0.9318101  0.8362811\n",
      "  0.         1.5097318  0.         0.         0.02620884 0.\n",
      "  0.34063053 0.24101849 0.6183347  0.        ]]\n",
      "Hi!\n",
      "[[0.44737238 0.68357956 1.1337878  0.         0.         0.86148673\n",
      "  0.14425388 0.20379259 0.6754061  0.03043981 0.54419607 0.\n",
      "  0.75104135 0.         0.         0.25037158 0.01170538 0.58213335\n",
      "  0.         0.48467004 0.8946363  0.         0.         0.34434104\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.28129125 0.3693895  0.         0.         0.         0.\n",
      "  0.         0.37831566 0.         0.5930262  0.         0.\n",
      "  0.         0.13449116 0.14486447 0.3741062  0.         0.58414346\n",
      "  0.22757904 0.82977754 0.37857354 0.32399294 0.5792528  0.4147753\n",
      "  0.         0.3075213  0.         0.         0.06427059 0.\n",
      "  0.         0.55278414 0.5664224  0.6518868 ]]\n",
      "[[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])], tensor([5, 5, 5,  ..., 5, 5, 5]), tensor([6018, 2194, 7386,  ...,  451, 6547, 2075]), tensor([[0.0243],\n",
      "        [0.0243],\n",
      "        [0.0243],\n",
      "        ...,\n",
      "        [0.0243],\n",
      "        [0.0243],\n",
      "        [0.0243]], dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0891728e-02 2.9298335e-01 2.0808190e-01 ... 4.7482211e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.5459572e-04 7.1132928e-02 2.8490696e-02 ... 1.2237633e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [8.6434120e-01 2.3477215e-01 1.6362664e+00 ... 7.4931586e-01\n",
      "  8.9495152e-01 6.9169378e-01]\n",
      " ...\n",
      " [5.3231776e-01 0.0000000e+00 5.8383352e-01 ... 9.6204078e-01\n",
      "  1.1975595e+00 0.0000000e+00]\n",
      " [9.8908961e-02 3.7857163e-01 2.5451156e-01 ... 7.7752456e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [4.5258913e-02 7.8043565e-02 2.8905728e-01 ... 1.8210934e-03\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "dataset_train.final_weights [0.31409498 0.31049847 0.01970464 0.01970464 0.31168812 0.02430916]\n",
      "[[3.0891728e-02 2.9298335e-01 2.0808190e-01 ... 4.7482211e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [3.5459572e-04 7.1132928e-02 2.8490696e-02 ... 1.2237633e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [8.6434120e-01 2.3477215e-01 1.6362664e+00 ... 7.4931586e-01\n",
      "  8.9495152e-01 6.9169378e-01]\n",
      " ...\n",
      " [6.8048441e-01 6.0925514e-01 5.6816703e-01 ... 2.7706984e-01\n",
      "  1.0042894e+00 1.6298890e-01]\n",
      " [8.9212835e-01 4.1740513e-01 1.4700600e+00 ... 6.3622260e-01\n",
      "  6.6693282e-01 2.5283301e-01]\n",
      " [8.0472463e-01 0.0000000e+00 1.4987009e+00 ... 1.1096411e+00\n",
      "  9.9810576e-01 7.8612834e-01]]\n",
      "[0 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[[0.31409498 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.31049847 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]\n",
      " [0.         0.         0.         0.         0.         0.02430916]]\n",
      "tensor([[0.3141, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3105, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0243]], dtype=torch.float64)\n",
      "tensor([0.3141, 0.3105, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243,\n",
      "        0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243],\n",
      "       dtype=torch.float64)\n",
      "<GCaMP_ROI_classifier.old_stuff.util.dataset_simCLR object at 0x7fa820882070>\n",
      "Hi!\n",
      "[[0.6000123  0.16410181 0.70140606 0.26853845 0.         0.9732799\n",
      "  0.67055464 0.8981342  0.         0.         0.21830024 0.\n",
      "  0.14565673 0.0199881  0.         0.05651439 0.         0.35205394\n",
      "  0.         0.62604666 0.44713393 0.         0.         0.\n",
      "  0.         0.         0.         0.14962193 0.         0.\n",
      "  0.5985136  0.7594314  0.04103209 0.         0.1459532  0.\n",
      "  0.         0.5881473  0.06768851 0.31109706 0.         0.\n",
      "  0.         0.04861007 0.9314582  0.9948026  0.         0.39969826\n",
      "  0.46639854 0.72743213 0.         0.6430888  0.69794977 0.82679546\n",
      "  0.         0.96557355 0.17063446 0.         0.         0.\n",
      "  0.         0.30045134 0.817207   0.        ]]\n",
      "Hi!\n",
      "[[0.8154603  0.18761909 1.1698285  0.07597508 0.         1.0846682\n",
      "  0.30136245 0.58105    0.3280136  0.10221411 0.44386622 0.\n",
      "  0.         0.         0.         0.07504266 0.31447238 0.5432359\n",
      "  0.         0.4646912  0.833439   0.         0.         0.39617008\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.35648713 0.15094326 0.         0.         0.\n",
      "  0.         0.3329011  0.         0.72481227 0.         0.\n",
      "  0.         0.5478338  0.11256384 0.59012246 0.         0.12377959\n",
      "  0.34064716 1.0335037  0.07517429 0.41860276 0.7426885  0.34909135\n",
      "  0.         1.1753939  0.         0.         0.         0.\n",
      "  0.3500394  0.600637   0.5156729  0.04040703]]\n",
      "Hi!\n",
      "[[0.32042122 0.6079157  0.68511224 0.         0.         0.6777358\n",
      "  0.         0.05921859 0.19806287 0.03298879 0.3413612  0.\n",
      "  0.44480702 0.         0.         0.09055201 0.         0.38126704\n",
      "  0.         0.7086087  0.4170321  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11638477 0.2798805  0.         0.         0.         0.\n",
      "  0.         0.19431497 0.         0.47355917 0.         0.\n",
      "  0.         0.         0.26155734 0.39350662 0.         0.59490085\n",
      "  0.3887276  0.4823411  0.1015479  0.31373537 0.21548283 0.65724957\n",
      "  0.         0.3969015  0.         0.         0.06988735 0.\n",
      "  0.22686374 0.36558968 0.17173854 0.26330456]]\n",
      "Hi!\n",
      "[[0.4910209  0.         0.8013036  0.09868556 0.         0.84838927\n",
      "  0.79535705 1.0749012  0.6172884  0.01641221 0.37619555 0.\n",
      "  0.15806375 0.         0.         0.32214868 0.         0.58792794\n",
      "  0.         0.         0.75698286 0.         0.         0.35934246\n",
      "  0.         0.         0.         0.06404048 0.         0.\n",
      "  0.48502365 0.38706934 0.11704725 0.         0.19946456 0.\n",
      "  0.         0.7378374  0.         0.5842004  0.         0.\n",
      "  0.         0.63466877 0.1991661  0.73132527 0.         0.03964242\n",
      "  0.         0.9829991  0.2579254  0.4309241  0.8010795  0.11421187\n",
      "  0.         0.4550175  0.         0.         0.         0.\n",
      "  0.         0.8066255  0.93088734 0.07379051]]\n",
      "Hi!\n",
      "[[0.8568789  0.         0.9981249  0.53451055 0.         0.84757185\n",
      "  1.8191853  1.7121047  0.8565478  0.         0.37331328 0.\n",
      "  0.         0.         0.         0.47208178 0.6055199  0.91406375\n",
      "  0.         0.         0.90959287 0.43007246 0.         0.64715445\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06640323 0.0272569  0.41509128 0.         0.12737554 0.\n",
      "  0.         0.9050732  0.         1.0994716  0.24708267 0.\n",
      "  0.         1.9353824  0.         0.6767025  0.         0.\n",
      "  0.         1.3153404  0.2753052  0.20543672 1.0048932  0.\n",
      "  0.         1.0255325  0.         0.02295705 0.         0.\n",
      "  0.         1.3209858  0.8639976  0.        ]]\n",
      "Hi!\n",
      "[[0.69253385 0.         0.         0.72524035 0.         0.6623518\n",
      "  1.6916555  1.9761872  0.         0.         0.04167675 0.\n",
      "  0.45878163 0.88793236 0.         0.20678759 0.         0.3643074\n",
      "  0.         0.19295672 0.13838919 0.31394312 0.         0.0974749\n",
      "  0.         0.         0.         0.88247395 0.         0.\n",
      "  1.5115134  0.8626315  0.556999   0.         0.8079766  0.\n",
      "  0.07818359 1.0476564  0.33057702 0.22758391 0.3066529  0.\n",
      "  0.         0.5337954  1.6481988  1.6884767  0.         0.15589376\n",
      "  0.08629218 0.99791807 0.11411311 0.834188   0.9665915  1.0564979\n",
      "  0.         0.38644487 0.5730636  0.         0.         0.\n",
      "  0.         0.37183246 0.8799864  0.        ]]\n",
      "Hi!\n",
      "[[0.03283953 0.19935833 0.1781373  0.         0.         0.19658634\n",
      "  0.         0.09648284 0.         0.08013823 0.14678359 0.\n",
      "  0.0815486  0.1657132  0.         0.         0.         0.04652833\n",
      "  0.         0.2279522  0.07059959 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02802178 0.1738209  0.13309927 0.         0.         0.\n",
      "  0.         0.         0.1228563  0.10861903 0.         0.\n",
      "  0.         0.         0.2002409  0.30098486 0.         0.09973642\n",
      "  0.23459715 0.17549297 0.         0.22643761 0.10506793 0.3566435\n",
      "  0.         0.14352725 0.02778268 0.         0.00584018 0.\n",
      "  0.08620735 0.08967642 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.00935862 0.16075812 0.29120886 0.         0.         0.3046922\n",
      "  0.         0.07853749 0.04603787 0.13360004 0.20952454 0.\n",
      "  0.         0.01331395 0.         0.         0.         0.06046551\n",
      "  0.         0.30159217 0.16141501 0.         0.         0.01916787\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05293427 0.05065805 0.         0.         0.\n",
      "  0.         0.         0.07925401 0.1862214  0.         0.\n",
      "  0.         0.         0.08643004 0.32385856 0.         0.17062254\n",
      "  0.23326054 0.16555001 0.         0.24376819 0.14370218 0.28441998\n",
      "  0.         0.23491827 0.         0.         0.04548961 0.\n",
      "  0.09712089 0.10119636 0.         0.00955183]]\n",
      "Hi!\n",
      "[[0.8729377  0.6118805  2.0314608  0.         0.         0.90569437\n",
      "  0.03276912 0.         1.3847874  0.         0.83708066 0.\n",
      "  0.46384305 0.         0.         0.6880774  0.9868782  0.8845999\n",
      "  0.         0.39656144 1.5864526  0.45007035 0.         0.6564915\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02019381 0.006275   0.         0.         0.\n",
      "  0.         0.5048203  0.         1.1550772  0.01357038 0.\n",
      "  0.         0.9490072  0.         0.         0.         0.75786006\n",
      "  0.21513784 1.1916866  0.7707805  0.00426787 0.25513998 0.18694529\n",
      "  0.         0.2934065  0.         0.7823424  0.24720639 0.\n",
      "  0.18069355 1.0341642  0.7795011  1.2523843 ]]\n",
      "Hi!\n",
      "[[0.5005891  0.         1.0170685  0.         0.         0.5646196\n",
      "  0.9954915  1.0372595  1.2685804  0.         0.5415442  0.\n",
      "  0.15710507 0.         0.         0.80664307 0.29720217 0.8947789\n",
      "  0.         0.         1.0413432  0.28941053 0.         0.456834\n",
      "  0.         0.         0.         0.00533992 0.         0.\n",
      "  0.34942514 0.07424793 0.08992203 0.         0.34904468 0.\n",
      "  0.         1.140781   0.         0.7064839  0.15347014 0.\n",
      "  0.         1.336909   0.         0.31547916 0.         0.13088003\n",
      "  0.         0.9213247  0.71315736 0.1635785  0.49217552 0.\n",
      "  0.         0.         0.         0.29489723 0.         0.\n",
      "  0.         1.1717912  1.082299   0.45885497]]\n",
      "Hi!\n",
      "[[0.32594424 0.         0.608525   0.23072217 0.         0.78395784\n",
      "  1.3067528  1.4910413  0.6846196  0.         0.35070527 0.\n",
      "  0.3580415  0.         0.         0.5045443  0.         0.6450801\n",
      "  0.         0.         0.72837406 0.07328484 0.         0.\n",
      "  0.         0.         0.         0.48896417 0.         0.\n",
      "  0.91249    0.4867348  0.03319592 0.         0.61257493 0.\n",
      "  0.03241665 1.2408501  0.         0.44187847 0.22188023 0.\n",
      "  0.         0.78516954 0.60633755 0.88588023 0.         0.2163112\n",
      "  0.         0.7999114  0.41019273 0.46655    0.7601601  0.2751719\n",
      "  0.         0.09153138 0.25198725 0.         0.         0.\n",
      "  0.         0.8190076  1.3872662  0.        ]]\n",
      "Hi!\n",
      "[[0.45927414 0.22077775 0.21063283 0.26335642 0.         0.6469243\n",
      "  0.90630054 1.2639183  0.         0.         0.23743731 0.\n",
      "  0.55901074 0.56825525 0.         0.13892007 0.         0.41553006\n",
      "  0.         0.38332903 0.30429965 0.04503171 0.         0.07754324\n",
      "  0.         0.         0.         0.4825745  0.         0.\n",
      "  1.1666486  0.7729596  0.19182535 0.         0.558985   0.\n",
      "  0.         0.6760749  0.22835368 0.19416925 0.09130575 0.\n",
      "  0.         0.21131304 1.0647691  1.2026808  0.         0.11653459\n",
      "  0.19070677 0.9301279  0.10948885 0.623049   0.9024687  0.7467216\n",
      "  0.         0.36067703 0.28210127 0.         0.         0.\n",
      "  0.         0.3583542  0.69237584 0.        ]]\n",
      "Hi!\n",
      "[[0.31947115 0.94992024 0.42657018 0.         0.         0.43317086\n",
      "  0.         0.2528216  0.         0.         0.29891923 0.\n",
      "  0.82056993 0.48443362 0.         0.01231952 0.         0.32910952\n",
      "  0.         0.84755445 0.22199236 0.         0.         0.1860069\n",
      "  0.         0.         0.         0.20175625 0.         0.\n",
      "  0.5431322  0.54548585 0.0615221  0.         0.0695089  0.\n",
      "  0.         0.         0.49792233 0.12850687 0.         0.\n",
      "  0.         0.         0.60932076 0.4763177  0.         0.31340948\n",
      "  0.42776623 0.52560043 0.17116854 0.40750054 0.54878575 0.87005895\n",
      "  0.         0.18159796 0.28861368 0.         0.062943   0.\n",
      "  0.05643035 0.20872024 0.23905022 0.        ]]\n",
      "Hi!\n",
      "[[0.0790931  0.15047143 0.32099333 0.         0.         0.37176907\n",
      "  0.         0.0252379  0.03631168 0.13421485 0.24203934 0.\n",
      "  0.         0.06336683 0.         0.         0.         0.\n",
      "  0.         0.36316997 0.16906163 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08978459 0.05257427 0.         0.         0.\n",
      "  0.         0.         0.06215695 0.19316635 0.         0.\n",
      "  0.         0.         0.10417236 0.38949636 0.         0.22319578\n",
      "  0.29343456 0.16201054 0.         0.3060139  0.15234683 0.38939968\n",
      "  0.         0.24210267 0.         0.         0.04426371 0.\n",
      "  0.05032547 0.02248133 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5886745  0.4103833  0.         0.26245174 0.         0.33042812\n",
      "  0.79931045 0.8624362  0.         0.         0.         0.\n",
      "  0.6019925  0.6485671  0.         0.23521648 0.         0.26114476\n",
      "  0.         0.43563503 0.         0.         0.         0.09720568\n",
      "  0.03354342 0.         0.         0.5164554  0.         0.\n",
      "  1.0069406  0.6193213  0.45673147 0.         0.4013676  0.\n",
      "  0.29454938 0.7136248  0.42434022 0.12167148 0.         0.\n",
      "  0.         0.41867405 1.0621047  1.018233   0.         0.47381788\n",
      "  0.19585721 0.6209287  0.16270477 0.401847   0.37589753 1.1308956\n",
      "  0.         0.23586836 0.41082266 0.         0.         0.\n",
      "  0.         0.24910544 0.301102   0.        ]]\n",
      "Hi!\n",
      "[[0.6982277  0.         0.8830907  0.3435643  0.         0.577946\n",
      "  2.2561665  2.0891693  1.453564   0.         0.41969568 0.\n",
      "  0.         0.         0.         0.9475933  0.4827194  0.92339796\n",
      "  0.         0.         1.0684103  0.65320385 0.         0.4641735\n",
      "  0.         0.         0.         0.14709456 0.         0.\n",
      "  0.38253456 0.         0.20478399 0.         0.55317724 0.\n",
      "  0.         1.4509528  0.         0.8940736  0.442605   0.\n",
      "  0.         2.3141012  0.         0.5189443  0.         0.\n",
      "  0.         0.9640118  0.7591283  0.12684457 0.61818576 0.\n",
      "  0.         0.18748222 0.         0.44069597 0.         0.\n",
      "  0.         1.5727836  1.2539237  0.02130954]]\n",
      "Hi!\n",
      "[[0.15371875 0.457736   0.18576762 0.         0.         0.2342892\n",
      "  0.26851866 0.35242718 0.2199375  0.         0.2059959  0.\n",
      "  0.2531002  0.13437083 0.         0.03834064 0.         0.20152614\n",
      "  0.         0.36189315 0.24302106 0.         0.         0.\n",
      "  0.         0.         0.         0.07389197 0.         0.\n",
      "  0.23392078 0.02920431 0.         0.         0.         0.\n",
      "  0.         0.         0.04066676 0.23758288 0.         0.\n",
      "  0.         0.06548917 0.10280615 0.44806662 0.         0.0598626\n",
      "  0.         0.43070126 0.25819504 0.06093422 0.147854   0.36395732\n",
      "  0.         0.         0.1231402  0.         0.00078318 0.\n",
      "  0.10520282 0.41174853 0.         0.00092628]]\n",
      "Hi!\n",
      "[[0.00314878 0.08354378 0.         0.         0.         0.\n",
      "  0.12817498 0.22772925 0.         0.10604779 0.06636322 0.\n",
      "  0.         0.1326944  0.         0.07073861 0.         0.1403313\n",
      "  0.         0.05068427 0.04478805 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0105463  0.01291466 0.11091387 0.         0.         0.\n",
      "  0.         0.         0.1266706  0.09049358 0.         0.\n",
      "  0.         0.         0.19691198 0.329001   0.         0.\n",
      "  0.10113423 0.         0.01471271 0.06747206 0.01826299 0.13576773\n",
      "  0.         0.09959569 0.05188632 0.         0.         0.\n",
      "  0.0707287  0.0963363  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6068378  0.19700451 0.74824494 0.14463653 0.         0.9109479\n",
      "  0.5961775  0.8076621  0.23707388 0.14509109 0.33592218 0.\n",
      "  0.         0.         0.         0.07959817 0.         0.5256507\n",
      "  0.         0.4000976  0.5791321  0.         0.         0.30327004\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1798847  0.28039744 0.24768321 0.         0.         0.\n",
      "  0.         0.2758298  0.         0.766471   0.         0.\n",
      "  0.         0.61299354 0.08537737 0.8735507  0.         0.\n",
      "  0.28239658 1.2820818  0.         0.4343284  0.96042013 0.1004122\n",
      "  0.         0.8399357  0.         0.         0.         0.\n",
      "  0.23684934 0.8415643  0.12910739 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.04607499 0.18164507 0.         0.         0.13869646\n",
      "  0.         0.0277838  0.01270789 0.06959458 0.12375615 0.\n",
      "  0.         0.03092458 0.         0.         0.         0.\n",
      "  0.         0.17144227 0.07588151 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0944329  0.08424398 0.         0.         0.\n",
      "  0.         0.         0.09745868 0.11566964 0.         0.\n",
      "  0.         0.         0.12289839 0.17047751 0.         0.11986595\n",
      "  0.13794573 0.00151215 0.         0.17675407 0.         0.19246809\n",
      "  0.         0.11941239 0.00953587 0.         0.0101808  0.\n",
      "  0.04481411 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.26720577 0.19453155 0.         0.         0.25117975\n",
      "  0.         0.1016939  0.         0.05437148 0.12109853 0.\n",
      "  0.1305338  0.16081367 0.         0.         0.         0.09939565\n",
      "  0.         0.31566456 0.09496281 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05545382 0.16202055 0.07301088 0.         0.         0.\n",
      "  0.         0.         0.11431004 0.11420423 0.         0.\n",
      "  0.         0.         0.24324211 0.33500955 0.         0.15699533\n",
      "  0.22129989 0.231874   0.         0.21278207 0.13727619 0.386749\n",
      "  0.         0.16337617 0.04765077 0.         0.         0.\n",
      "  0.09721304 0.11090969 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5603959  0.17658421 0.5237209  0.15353215 0.         0.7568413\n",
      "  0.6231979  0.84209234 0.         0.         0.2570078  0.\n",
      "  0.5109221  0.2586196  0.         0.06895132 0.         0.41844946\n",
      "  0.         0.4662272  0.37563044 0.         0.         0.00868614\n",
      "  0.         0.         0.         0.26638547 0.         0.\n",
      "  0.7928291  0.72301716 0.         0.         0.28164312 0.\n",
      "  0.07730608 0.7290733  0.07410058 0.27736342 0.         0.\n",
      "  0.         0.13525167 0.9262089  0.96252537 0.         0.5254883\n",
      "  0.27301836 0.6836434  0.10091329 0.54798853 0.5254708  0.8967216\n",
      "  0.         0.4946428  0.26747575 0.         0.         0.\n",
      "  0.         0.25904617 0.7507114  0.        ]]\n",
      "Hi!\n",
      "[[2.8147116e-01 2.9157495e-01 1.2838596e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.5429831e-01 4.5523497e-01 5.0785077e-01 1.4384102e+00 0.0000000e+00\n",
      "  6.7612058e-01 0.0000000e+00 1.0558420e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.7772068e-01 1.2254694e-01 9.1761458e-01 8.6522597e-01 0.0000000e+00\n",
      "  1.1872934e+00 2.2580747e-01 0.0000000e+00 1.5547436e-01 3.4256765e-01\n",
      "  0.0000000e+00 0.0000000e+00 1.2714846e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.3493617e-01 3.0229515e-01 0.0000000e+00 0.0000000e+00 4.1963691e-01\n",
      "  0.0000000e+00 6.1658734e-01 1.2831991e+00 0.0000000e+00 7.3277050e-01\n",
      "  1.9356988e-01 0.0000000e+00 0.0000000e+00 8.5081822e-01 1.2613606e-01\n",
      "  7.5900299e-04 0.0000000e+00 1.0112871e+00 0.0000000e+00 8.5911626e-01\n",
      "  1.0343477e+00 1.9984318e-01 2.2237207e-01 2.4962220e-01 0.0000000e+00\n",
      "  0.0000000e+00 1.7262273e-01 4.8690835e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 9.1826576e-01 1.3840882e+00 1.0337691e+00]]\n",
      "Hi!\n",
      "[[1.0127492  0.         1.2199626  0.45430738 0.         0.8566066\n",
      "  1.96374    1.8033233  1.2294847  0.         0.44287258 0.\n",
      "  0.         0.         0.         0.6939669  0.7630841  1.0254674\n",
      "  0.         0.         1.1670204  0.6182334  0.         0.7261107\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02359251 0.         0.32965913 0.         0.19542314 0.\n",
      "  0.         1.1574682  0.         1.0655344  0.2709378  0.\n",
      "  0.         2.2741704  0.         0.5047641  0.         0.\n",
      "  0.         1.16576    0.4576797  0.11876578 0.8461244  0.\n",
      "  0.         0.78335243 0.         0.39042968 0.         0.\n",
      "  0.         1.5231769  1.1242583  0.        ]]\n",
      "Hi!\n",
      "[[1.2105281  0.38696966 2.1538043  0.         0.         1.2140703\n",
      "  0.14964543 0.15031748 1.205503   0.         0.8112072  0.\n",
      "  0.14030577 0.         0.         0.55424225 0.98303026 0.8393167\n",
      "  0.         0.2830721  1.5320536  0.30319113 0.         0.7923027\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27018046 0.06835604 0.         0.         0.\n",
      "  0.         0.542179   0.         1.1018946  0.         0.\n",
      "  0.         1.1329023  0.         0.18595146 0.         0.64751554\n",
      "  0.23449169 1.0197151  0.6693727  0.18409808 0.6778638  0.2371192\n",
      "  0.         1.0430003  0.         0.6969926  0.11131192 0.\n",
      "  0.11099561 0.8127874  0.9253222  0.9909721 ]]\n",
      "Hi!\n",
      "[[0.03117728 0.13683407 0.07906526 0.         0.         0.\n",
      "  0.10381619 0.2399395  0.01870176 0.15886493 0.10165713 0.\n",
      "  0.         0.         0.         0.10285126 0.         0.0958329\n",
      "  0.         0.07600124 0.0638115  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09793416 0.         0.         0.\n",
      "  0.         0.         0.06534713 0.07572368 0.         0.\n",
      "  0.         0.         0.07236574 0.2533675  0.         0.\n",
      "  0.05392407 0.12599503 0.         0.10340794 0.01011639 0.14510256\n",
      "  0.         0.06618141 0.         0.         0.         0.\n",
      "  0.06334118 0.29719144 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3194414  0.         0.11030112 0.3160475  0.         0.71630037\n",
      "  1.3452402  1.4858917  0.         0.         0.17124374 0.\n",
      "  0.         0.3105223  0.         0.04482834 0.         0.4052058\n",
      "  0.         0.20485918 0.215581   0.04947965 0.         0.\n",
      "  0.         0.         0.         0.29468995 0.         0.\n",
      "  0.9688726  0.5168671  0.3171811  0.         0.52687246 0.\n",
      "  0.         0.7151866  0.         0.35591623 0.13528988 0.\n",
      "  0.         0.3965187  0.8161115  1.2397126  0.         0.\n",
      "  0.05975474 1.0367509  0.01006859 0.6274486  0.9208055  0.4129587\n",
      "  0.         0.51003635 0.08044335 0.         0.         0.\n",
      "  0.         0.5419879  0.50084114 0.        ]]\n",
      "Hi!\n",
      "[[0.6269816  0.28532863 0.9625555  0.         0.         0.89598227\n",
      "  0.21318232 0.31415358 0.38061234 0.21507703 0.33068934 0.\n",
      "  0.         0.         0.         0.09186677 0.20651823 0.4890071\n",
      "  0.         0.51802766 0.6683676  0.         0.         0.19554365\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22865656 0.17548627 0.         0.         0.\n",
      "  0.         0.24933624 0.         0.5316173  0.         0.\n",
      "  0.         0.37450662 0.1128632  0.5194219  0.         0.49849832\n",
      "  0.38083264 0.77602583 0.02931847 0.39720005 0.42181858 0.3993516\n",
      "  0.         0.8467334  0.         0.         0.02544438 0.\n",
      "  0.29953817 0.66674715 0.37009713 0.21132568]]\n",
      "Hi!\n",
      "[[0.15799111 0.         0.54688364 0.         0.         0.50589913\n",
      "  1.1449847  1.3181677  0.93466663 0.         0.3802257  0.\n",
      "  0.49624586 0.         0.         0.67256385 0.         0.731288\n",
      "  0.         0.         0.7490677  0.         0.         0.11002403\n",
      "  0.03504915 0.         0.         0.305674   0.         0.\n",
      "  0.81713516 0.23076835 0.         0.         0.5333369  0.\n",
      "  0.         1.2056909  0.         0.45924157 0.0971302  0.\n",
      "  0.         0.92270476 0.26425472 0.6210524  0.         0.14275467\n",
      "  0.         0.8533879  0.6486824  0.34623682 0.5847384  0.01850914\n",
      "  0.         0.         0.04684965 0.         0.         0.\n",
      "  0.         0.9179312  1.1283137  0.21518864]]\n",
      "Hi!\n",
      "[[0.04512385 0.25055313 0.23226899 0.         0.         0.09604983\n",
      "  0.         0.00599555 0.10076448 0.05433588 0.1615541  0.\n",
      "  0.24695963 0.08854757 0.         0.06307907 0.         0.03551109\n",
      "  0.         0.16112381 0.14954126 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07332332 0.18461339 0.07873192 0.         0.         0.\n",
      "  0.         0.         0.1293076  0.05745032 0.         0.\n",
      "  0.         0.         0.10982283 0.0777224  0.         0.13379455\n",
      "  0.12314214 0.08181587 0.         0.12125753 0.02233703 0.3196439\n",
      "  0.         0.         0.09318124 0.         0.03611831 0.\n",
      "  0.08709266 0.03533594 0.         0.0067734 ]]\n",
      "Hi!\n",
      "[[0.19537765 0.39528206 0.19137271 0.         0.         0.14218417\n",
      "  0.         0.01123721 0.18704613 0.         0.2028899  0.\n",
      "  0.4750111  0.15155217 0.         0.11337448 0.         0.08886688\n",
      "  0.         0.22624457 0.16943292 0.         0.         0.06840331\n",
      "  0.         0.         0.         0.05719994 0.00065442 0.\n",
      "  0.27633947 0.2903378  0.         0.         0.         0.\n",
      "  0.         0.         0.17845473 0.04891884 0.         0.\n",
      "  0.         0.         0.19564743 0.00150364 0.         0.16009405\n",
      "  0.00813951 0.12348246 0.12155874 0.         0.11059591 0.4999584\n",
      "  0.         0.         0.23711386 0.         0.06040713 0.\n",
      "  0.19448131 0.07501325 0.         0.11756794]]\n",
      "Hi!\n",
      "[[0.08625624 0.14714028 0.21263477 0.         0.         0.11421318\n",
      "  0.         0.0315669  0.13470167 0.06486548 0.13865022 0.\n",
      "  0.15316346 0.         0.         0.11389239 0.         0.\n",
      "  0.         0.14361133 0.15593202 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07014786 0.06764275 0.         0.         0.\n",
      "  0.         0.         0.08941442 0.08491859 0.         0.\n",
      "  0.         0.         0.06056513 0.1218361  0.         0.13958466\n",
      "  0.03807715 0.         0.01240335 0.19728774 0.03950907 0.28925234\n",
      "  0.         0.         0.04988288 0.         0.01778689 0.\n",
      "  0.01115847 0.03029275 0.         0.03738173]]\n",
      "Hi!\n",
      "[[0.6035881  0.89411604 1.108487   0.         0.         0.78175426\n",
      "  0.         0.30498406 0.5912623  0.         0.55996543 0.\n",
      "  1.3405272  0.01311196 0.         0.2888488  0.         0.5275672\n",
      "  0.41493788 0.7111938  0.8165037  0.         0.         0.09739646\n",
      "  0.         0.         0.         0.12997468 0.         0.\n",
      "  0.7835123  0.7015896  0.         0.         0.13157052 0.\n",
      "  0.2016781  0.57493746 0.20599575 0.48647472 0.         0.\n",
      "  0.         0.14036776 0.7492849  0.37180328 0.         0.9080507\n",
      "  0.23973554 0.59412074 0.4570719  0.47424132 0.53251284 0.9572928\n",
      "  0.         0.22883643 0.14139561 0.         0.08627858 0.\n",
      "  0.         0.28856188 0.95254475 0.5202948 ]]\n",
      "Hi!\n",
      "[[0.5936201  0.5600607  1.2455438  0.         0.         1.0301417\n",
      "  0.05800189 0.22036678 0.42427436 0.08295738 0.51206046 0.\n",
      "  0.27358449 0.         0.         0.05588669 0.16576335 0.49723378\n",
      "  0.         0.6765711  0.8739213  0.         0.         0.34960905\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01297666 0.34537193 0.05777395 0.         0.         0.\n",
      "  0.         0.18142593 0.         0.59179944 0.         0.\n",
      "  0.         0.25055656 0.06054661 0.40443885 0.         0.44134054\n",
      "  0.45282957 0.9303217  0.2111348  0.40104157 0.65581614 0.48234046\n",
      "  0.         0.79504484 0.         0.         0.12736748 0.\n",
      "  0.20310308 0.52614623 0.41214147 0.37547833]]\n",
      "Hi!\n",
      "[[0.         0.08719892 0.11033482 0.         0.         0.15015008\n",
      "  0.08487295 0.22177124 0.         0.14116757 0.14236999 0.\n",
      "  0.         0.06799643 0.         0.00309737 0.         0.07293741\n",
      "  0.         0.20813514 0.06290787 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02983978 0.14964233 0.         0.         0.\n",
      "  0.         0.         0.07431486 0.15967117 0.         0.\n",
      "  0.         0.         0.11315145 0.43313456 0.         0.02986827\n",
      "  0.17886959 0.13953926 0.         0.24137749 0.1091044  0.26070195\n",
      "  0.         0.2135329  0.         0.         0.         0.\n",
      "  0.06794935 0.1535802  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.406454   0.         0.5502626  0.53282535 0.         0.9784483\n",
      "  1.6822609  1.8627628  0.4619631  0.         0.20976192 0.\n",
      "  0.19284716 0.         0.         0.3736752  0.         0.591148\n",
      "  0.         0.         0.5936103  0.13000847 0.         0.\n",
      "  0.         0.         0.         0.64234483 0.         0.\n",
      "  1.003652   0.6563888  0.07060499 0.         0.67773515 0.\n",
      "  0.08665504 1.3681717  0.         0.3719615  0.352936   0.\n",
      "  0.         0.8582862  0.8865912  1.1382471  0.         0.2329975\n",
      "  0.         0.7372379  0.24138159 0.644934   0.86266714 0.46662903\n",
      "  0.         0.41498926 0.4182917  0.         0.         0.\n",
      "  0.         0.71883446 1.6254326  0.        ]]\n",
      "Hi!\n",
      "[[0.7463586  0.75027674 0.11956097 0.24554099 0.         0.50670063\n",
      "  0.477408   1.0310087  0.         0.         0.20382802 0.\n",
      "  1.2166322  0.9918949  0.         0.16572459 0.         0.35426298\n",
      "  0.00746892 0.632466   0.17750286 0.04111425 0.         0.28019097\n",
      "  0.         0.         0.         0.6893376  0.         0.\n",
      "  1.3416324  1.0016694  0.27234104 0.         0.48209393 0.\n",
      "  0.22771546 0.7018522  0.61420333 0.14167775 0.         0.\n",
      "  0.         0.31835487 1.4650747  1.172798   0.         0.6036661\n",
      "  0.28178397 0.7817488  0.2830569  0.54572815 0.71624595 1.2929045\n",
      "  0.         0.15306647 0.51734257 0.         0.         0.\n",
      "  0.         0.08800922 0.55901057 0.        ]]\n",
      "Hi!\n",
      "[[1.0456847  0.2902528  1.7658676  0.         0.         1.1791455\n",
      "  0.03281157 0.15900281 0.7600632  0.08343071 0.64250463 0.\n",
      "  0.         0.         0.         0.18611343 0.7280678  0.68358344\n",
      "  0.         0.5781466  1.1353669  0.07544839 0.         0.46380383\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2387923  0.08445022 0.         0.         0.\n",
      "  0.         0.34771064 0.         0.9215407  0.         0.\n",
      "  0.         0.7479338  0.         0.32498166 0.         0.594484\n",
      "  0.4267878  0.8731404  0.30876678 0.21612155 0.5069211  0.29878098\n",
      "  0.         1.1205323  0.         0.32483205 0.14230813 0.\n",
      "  0.4030271  0.7273963  0.5775847  0.60494846]]\n",
      "Hi!\n",
      "[[0.22043356 0.26437375 1.0220482  0.         0.         0.5493258\n",
      "  0.55377305 0.6437044  1.2880789  0.         0.6081087  0.\n",
      "  0.95791835 0.         0.         0.9199452  0.         0.877779\n",
      "  0.6833327  0.         1.0432223  0.14455368 0.         0.08188977\n",
      "  0.25588077 0.         0.         0.17324872 0.         0.\n",
      "  0.54914254 0.25514966 0.         0.         0.43463123 0.\n",
      "  0.51940584 1.2526729  0.         0.6492092  0.1857641  0.\n",
      "  0.         0.78900856 0.22038731 0.1802801  0.         0.82175064\n",
      "  0.         0.7663447  0.9340612  0.19809577 0.28311172 0.24414241\n",
      "  0.         0.         0.18346511 0.32479748 0.         0.\n",
      "  0.         0.89288294 1.2572016  0.8225101 ]]\n",
      "Hi!\n",
      "[[0.2021839  0.4150727  0.7100598  0.         0.         0.33611\n",
      "  0.6563151  0.70253396 1.2901525  0.         0.556962   0.\n",
      "  1.0753608  0.         0.         1.071828   0.         0.8841561\n",
      "  0.775428   0.         0.84896386 0.12692063 0.         0.\n",
      "  0.4159461  0.         0.         0.26113242 0.         0.\n",
      "  0.65171707 0.1803584  0.         0.         0.61349416 0.\n",
      "  0.68248487 1.3266959  0.         0.57899696 0.16888788 0.\n",
      "  0.         0.8062298  0.35281414 0.08589815 0.         0.8925427\n",
      "  0.         0.7928627  1.0517657  0.17872931 0.13274975 0.2880975\n",
      "  0.         0.         0.26384136 0.20190194 0.         0.\n",
      "  0.         0.90153456 1.0065155  0.75451726]]\n",
      "Hi!\n",
      "[[0.01982281 0.29128763 0.23654209 0.         0.         0.1979486\n",
      "  0.         0.02179369 0.04324042 0.05273206 0.14082384 0.\n",
      "  0.19127518 0.11521552 0.         0.         0.         0.09340171\n",
      "  0.         0.24526551 0.12993215 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03442859 0.16307956 0.03195317 0.         0.         0.\n",
      "  0.         0.         0.07814521 0.10912045 0.         0.\n",
      "  0.         0.         0.17575867 0.24978125 0.         0.18463881\n",
      "  0.22788917 0.12745255 0.         0.2009797  0.0591415  0.34366047\n",
      "  0.         0.12784134 0.04592773 0.         0.0272849  0.\n",
      "  0.09643095 0.09408872 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.35809788 1.3277321  0.5869082  0.         0.         0.3832195\n",
      "  0.         0.22358465 0.4211315  0.         0.482427   0.\n",
      "  1.8530738  0.64153063 0.         0.22102585 0.         0.30397213\n",
      "  0.49613282 0.7454795  0.48471707 0.         0.         0.25777343\n",
      "  0.         0.         0.         0.53070766 0.         0.\n",
      "  0.8031899  0.66723377 0.         0.         0.05110981 0.\n",
      "  0.17718571 0.1188944  0.7330056  0.24795614 0.         0.\n",
      "  0.         0.         0.705465   0.5459061  0.         0.7811737\n",
      "  0.20202148 0.55812544 0.6054235  0.3654257  0.60255224 1.0614195\n",
      "  0.05041928 0.         0.3833021  0.         0.10380294 0.\n",
      "  0.0722165  0.15230756 0.38543665 0.26164272]]\n",
      "Hi!\n",
      "[[0.151074   0.6808857  0.6700474  0.         0.         0.48504585\n",
      "  0.         0.         0.32395795 0.         0.35032937 0.\n",
      "  0.6590611  0.         0.         0.17489873 0.         0.30271232\n",
      "  0.         0.6280939  0.4048155  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15026893 0.28472674 0.         0.         0.         0.\n",
      "  0.         0.08005457 0.         0.33355895 0.         0.\n",
      "  0.         0.         0.14935894 0.14931858 0.         0.5804292\n",
      "  0.35839847 0.45089892 0.24616206 0.22388867 0.15778823 0.6171701\n",
      "  0.         0.12854333 0.03416811 0.         0.11376795 0.\n",
      "  0.14480728 0.14287606 0.1805108  0.3809713 ]]\n",
      "Hi!\n",
      "[[0.362925   0.         0.25044867 0.40403676 0.         0.6477179\n",
      "  1.9464701  1.7804928  0.43355805 0.         0.21752933 0.\n",
      "  0.         0.         0.         0.44188038 0.         0.69262683\n",
      "  0.         0.         0.46423587 0.19608466 0.         0.\n",
      "  0.06230745 0.         0.         0.37381563 0.         0.\n",
      "  0.8740675  0.2934729  0.1618581  0.         0.72075546 0.\n",
      "  0.         1.3236744  0.         0.5123358  0.30283603 0.\n",
      "  0.         1.0134138  0.61929595 1.0582895  0.         0.\n",
      "  0.         0.94656324 0.29980594 0.44258404 0.6014738  0.17291334\n",
      "  0.         0.06881817 0.17825472 0.         0.         0.\n",
      "  0.         1.0046103  1.0512362  0.        ]]\n",
      "Hi!\n",
      "[[0.12874697 0.56676966 0.4827467  0.         0.         0.4794244\n",
      "  0.         0.00447251 0.03231381 0.         0.31203455 0.\n",
      "  0.36206377 0.1878031  0.         0.         0.         0.13730511\n",
      "  0.         0.6561063  0.2745114  0.         0.         0.03210166\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13547811 0.2816666  0.         0.         0.         0.\n",
      "  0.         0.         0.20265396 0.24693103 0.         0.\n",
      "  0.         0.         0.2875252  0.3640116  0.         0.31475964\n",
      "  0.42002368 0.3084999  0.         0.3521831  0.3225731  0.61772764\n",
      "  0.         0.26267776 0.06363824 0.         0.12515637 0.\n",
      "  0.12371744 0.06395517 0.05268164 0.05234108]]\n",
      "Hi!\n",
      "[[0.1178669  0.54307675 0.42587912 0.         0.         0.4442354\n",
      "  0.34415096 0.73301744 0.22682913 0.         0.3371988  0.\n",
      "  0.4745213  0.25332832 0.         0.14788641 0.         0.40058368\n",
      "  0.         0.4668786  0.36742586 0.         0.         0.07972521\n",
      "  0.         0.         0.         0.15079038 0.         0.\n",
      "  0.6633519  0.42319527 0.         0.         0.26671016 0.\n",
      "  0.         0.3085886  0.09227788 0.38203794 0.         0.\n",
      "  0.         0.16408712 0.43983403 0.6366318  0.         0.\n",
      "  0.09248763 0.91278297 0.18979898 0.411485   0.7763771  0.41118303\n",
      "  0.         0.04300581 0.         0.         0.         0.\n",
      "  0.         0.53021705 0.24512576 0.        ]]\n",
      "Hi!\n",
      "[[0.20296471 0.6152296  0.642802   0.         0.         0.80315673\n",
      "  0.15995046 0.2801725  0.2459278  0.06676243 0.39953163 0.\n",
      "  0.38893524 0.10399588 0.         0.         0.         0.24595223\n",
      "  0.         0.6301342  0.5163587  0.         0.         0.11143217\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15277603 0.21475472 0.02656647 0.         0.         0.\n",
      "  0.         0.         0.00118215 0.33992782 0.         0.\n",
      "  0.         0.         0.2726846  0.54622525 0.         0.32819483\n",
      "  0.37129983 0.5825126  0.16387166 0.3716539  0.57183796 0.5322883\n",
      "  0.         0.3623504  0.00229654 0.         0.01986161 0.\n",
      "  0.03782219 0.33189982 0.0686246  0.18134987]]\n",
      "Hi!\n",
      "[[0.41821614 0.32933027 0.7790952  0.         0.         0.72227275\n",
      "  0.5025936  0.8969015  0.8222743  0.         0.44943988 0.\n",
      "  1.0711572  0.         0.         0.5699544  0.         0.62255543\n",
      "  0.51365316 0.09132768 0.77739406 0.         0.         0.\n",
      "  0.09339051 0.         0.         0.39480332 0.         0.\n",
      "  0.8248726  0.55907995 0.         0.         0.37742904 0.\n",
      "  0.32163492 1.08645    0.         0.41201302 0.00549612 0.\n",
      "  0.         0.4426766  0.5483591  0.5510086  0.         0.7251976\n",
      "  0.         0.6514018  0.689192   0.452247   0.51195395 0.5673428\n",
      "  0.         0.         0.24178304 0.         0.         0.\n",
      "  0.         0.5484918  1.2611923  0.39474833]]\n",
      "Hi!\n",
      "[[0.         0.01893181 0.05762368 0.         0.         0.01345096\n",
      "  0.01836355 0.17474875 0.04576702 0.10468981 0.09361234 0.\n",
      "  0.         0.         0.         0.11675975 0.         0.00098968\n",
      "  0.         0.07136628 0.112523   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15311733 0.         0.         0.\n",
      "  0.         0.         0.03219232 0.0871371  0.         0.\n",
      "  0.         0.         0.1380094  0.28773442 0.         0.08555965\n",
      "  0.09648271 0.04720366 0.         0.15429334 0.         0.2005773\n",
      "  0.         0.1483569  0.00228221 0.         0.         0.\n",
      "  0.00541788 0.1324469  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5212681  0.26365533 0.9218148  0.         0.         0.74350566\n",
      "  0.37145907 0.38811722 0.6025528  0.08507796 0.4654729  0.\n",
      "  0.01584988 0.         0.         0.26668411 0.25571296 0.6920963\n",
      "  0.         0.3241113  0.8153154  0.12689963 0.         0.24506369\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14066172 0.0770661  0.         0.02265805 0.\n",
      "  0.         0.48340395 0.         0.6410039  0.         0.\n",
      "  0.         0.64246887 0.         0.24181278 0.         0.22190998\n",
      "  0.058865   0.87650305 0.31663442 0.16808787 0.37741157 0.12942468\n",
      "  0.         0.25705802 0.         0.         0.         0.\n",
      "  0.1141196  0.84397274 0.31568637 0.38143736]]\n",
      "Hi!\n",
      "[[0.13158214 0.21676625 0.03373535 0.02588799 0.         0.0324081\n",
      "  0.04646015 0.2677847  0.         0.         0.         0.\n",
      "  0.39560002 0.32610297 0.         0.         0.         0.09885365\n",
      "  0.         0.11927022 0.01779705 0.         0.         0.\n",
      "  0.         0.         0.         0.20826781 0.         0.\n",
      "  0.2663724  0.35110626 0.24658601 0.         0.         0.\n",
      "  0.         0.         0.39150774 0.         0.         0.\n",
      "  0.         0.01810899 0.3852622  0.256177   0.         0.01446335\n",
      "  0.21893118 0.29861706 0.         0.28024092 0.14036503 0.63429165\n",
      "  0.         0.09968433 0.20721024 0.         0.         0.\n",
      "  0.09916597 0.1932911  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6725615  0.831219   1.648557   0.         0.         1.0213368\n",
      "  0.         0.         0.35720134 0.         0.61092097 0.\n",
      "  0.55748487 0.         0.         0.06712925 0.49261755 0.41603476\n",
      "  0.         1.1514535  0.85458094 0.         0.         0.12407581\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46095985 0.0184971  0.         0.         0.\n",
      "  0.         0.00955314 0.         0.8517441  0.         0.\n",
      "  0.         0.         0.25084776 0.11494068 0.         0.946509\n",
      "  0.8003264  0.7251454  0.26088786 0.5285502  0.5529749  0.96819985\n",
      "  0.         0.9520972  0.         0.         0.25677174 0.\n",
      "  0.4506014  0.20601146 0.57064116 0.58299685]]\n",
      "Hi!\n",
      "[[0.52487016 0.42331097 1.0684448  0.         0.         0.93881595\n",
      "  0.08958296 0.3148518  0.31689137 0.         0.44272262 0.\n",
      "  0.5537591  0.         0.         0.17520127 0.00834914 0.51737356\n",
      "  0.         0.6019872  0.73787034 0.         0.         0.03021256\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35572287 0.59271866 0.         0.         0.         0.\n",
      "  0.05371485 0.5849545  0.         0.58320385 0.         0.\n",
      "  0.         0.08347994 0.4877544  0.49658015 0.         0.782474\n",
      "  0.39119306 0.62273717 0.191974   0.42585734 0.3982172  0.79178375\n",
      "  0.         0.61083496 0.         0.         0.01158561 0.\n",
      "  0.         0.33652604 0.7886509  0.26479334]]\n",
      "Hi!\n",
      "[[0.0412369  0.298776   0.29070893 0.         0.         0.20264897\n",
      "  0.         0.         0.11716384 0.04866562 0.22108784 0.\n",
      "  0.1770362  0.05773425 0.         0.04149796 0.         0.07280744\n",
      "  0.         0.30626976 0.18270092 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05209946 0.11632381 0.01108999 0.         0.         0.\n",
      "  0.         0.         0.08467054 0.12851697 0.         0.\n",
      "  0.         0.         0.09424425 0.16064109 0.         0.16062221\n",
      "  0.19183494 0.11939669 0.         0.15944968 0.04753936 0.3679778\n",
      "  0.         0.01767109 0.02060338 0.         0.09019426 0.\n",
      "  0.09284951 0.05823325 0.         0.05202248]]\n",
      "Hi!\n",
      "[[0.24430624 0.8127303  1.1092155  0.         0.         0.5168938\n",
      "  0.00736468 0.         0.7603415  0.         0.59013873 0.\n",
      "  0.9231337  0.         0.         0.50873715 0.16501987 0.71138275\n",
      "  0.115435   0.5247269  0.89461905 0.13737874 0.         0.04242141\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11992538 0.36698893 0.         0.         0.         0.\n",
      "  0.04072908 0.54157454 0.         0.61902267 0.         0.\n",
      "  0.         0.12837541 0.09621081 0.         0.         0.6302515\n",
      "  0.0379824  0.69653547 0.50635177 0.15442388 0.13161212 0.43834713\n",
      "  0.         0.         0.         0.         0.09674155 0.\n",
      "  0.         0.63324285 0.54192257 0.7195873 ]]\n",
      "Hi!\n",
      "[[1.0754299  0.         1.7168156  0.         0.         1.0857317\n",
      "  0.49146014 0.66287065 1.1580442  0.         0.6442782  0.\n",
      "  0.         0.         0.         0.48024207 0.7479044  0.8423669\n",
      "  0.         0.         1.3280009  0.3520427  0.         0.78510404\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1768159  0.15383893 0.         0.         0.\n",
      "  0.         0.7132311  0.         0.9563463  0.02248306 0.\n",
      "  0.         1.3035394  0.         0.20893387 0.         0.35788402\n",
      "  0.         1.0027372  0.5503697  0.21457818 0.68658924 0.\n",
      "  0.         0.9121594  0.         0.5367226  0.         0.\n",
      "  0.00565045 1.0289062  1.0480978  0.69471365]]\n",
      "Hi!\n",
      "[[0.46112385 0.274355   0.11930323 0.2541042  0.         0.35058635\n",
      "  0.3735301  0.5989022  0.         0.         0.         0.\n",
      "  0.1877207  0.4864801  0.         0.16531822 0.         0.1272281\n",
      "  0.         0.5465954  0.         0.         0.         0.07931571\n",
      "  0.         0.         0.         0.31518382 0.         0.\n",
      "  0.6578138  0.6986261  0.39520386 0.         0.03448836 0.\n",
      "  0.         0.08021541 0.4236389  0.01702032 0.         0.\n",
      "  0.         0.14835744 0.81490546 0.8132271  0.         0.\n",
      "  0.38275546 0.548541   0.         0.5219724  0.4784655  0.97749585\n",
      "  0.         0.577527   0.19303228 0.         0.         0.\n",
      "  0.04312671 0.15046881 0.02896128 0.        ]]\n",
      "Hi!\n",
      "[[0.95454544 0.         1.2945923  0.29343927 0.         1.0077841\n",
      "  1.280997   1.3409708  0.94974643 0.         0.48001713 0.\n",
      "  0.         0.         0.         0.44239116 0.5934366  0.75067466\n",
      "  0.         0.         1.0711933  0.29316399 0.         0.69186664\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03265793 0.16486377 0.21559173 0.         0.06403563 0.\n",
      "  0.         0.9077657  0.         0.9566561  0.18169136 0.\n",
      "  0.         1.5207692  0.         0.56321096 0.         0.\n",
      "  0.         1.1054504  0.37800565 0.29198074 0.8052137  0.\n",
      "  0.         0.9546063  0.         0.2245265  0.         0.\n",
      "  0.         1.1686448  1.192542   0.0862435 ]]\n",
      "Hi!\n",
      "[[1.193962   0.         1.8084768  0.         0.         1.2544901\n",
      "  0.34526953 0.54493505 0.9446748  0.03957805 0.60434675 0.\n",
      "  0.         0.         0.         0.32208103 0.887221   0.7801198\n",
      "  0.         0.10905746 1.3106858  0.33605638 0.         0.7701424\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24191426 0.13713111 0.         0.         0.\n",
      "  0.         0.4602886  0.         1.0438324  0.         0.\n",
      "  0.         1.3952289  0.         0.30379456 0.         0.28893557\n",
      "  0.12894619 1.1946112  0.46601713 0.18156527 0.6784697  0.11693339\n",
      "  0.         1.2774115  0.         0.44731697 0.         0.\n",
      "  0.27796412 0.94811106 0.7571021  0.5545043 ]]\n",
      "Hi!\n",
      "[[0.11970151 0.5593767  0.68736345 0.         0.         0.5927526\n",
      "  0.4340935  0.5690328  0.8262337  0.         0.44993842 0.\n",
      "  0.88540095 0.02008243 0.         0.4640772  0.         0.64458776\n",
      "  0.20287894 0.33191335 0.7650326  0.         0.         0.\n",
      "  0.09537384 0.         0.         0.08122624 0.         0.\n",
      "  0.64299077 0.3772199  0.         0.         0.29037306 0.\n",
      "  0.0535155  0.7569561  0.         0.40243012 0.         0.\n",
      "  0.         0.30406576 0.35774475 0.47021812 0.         0.61095214\n",
      "  0.         0.73507947 0.57496434 0.31197765 0.5372303  0.3816155\n",
      "  0.         0.         0.03110058 0.         0.         0.\n",
      "  0.         0.74748427 0.6133555  0.46618262]]\n",
      "Hi!\n",
      "[[0.5115306  0.6274191  0.60023713 0.         0.         0.7419944\n",
      "  0.         0.2095012  0.03588193 0.         0.2738197  0.\n",
      "  0.6376723  0.414765   0.         0.         0.         0.08798204\n",
      "  0.         0.86331755 0.21357056 0.         0.         0.05118296\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.41312754 0.60826033 0.08481295 0.         0.         0.\n",
      "  0.05508737 0.17302214 0.43577027 0.19883445 0.         0.\n",
      "  0.         0.05876439 0.68456346 0.7535404  0.         0.6843668\n",
      "  0.58524585 0.5103618  0.         0.5839009  0.45824194 1.1123774\n",
      "  0.         0.625894   0.15665129 0.         0.03667989 0.\n",
      "  0.00721769 0.         0.3794901  0.        ]]\n",
      "Hi!\n",
      "[[0.6182656  0.         0.846699   0.20875148 0.         0.84170526\n",
      "  1.0128795  1.1662551  0.68876284 0.05137826 0.39644408 0.\n",
      "  0.         0.         0.         0.3397314  0.14284626 0.67944276\n",
      "  0.         0.         0.800877   0.         0.         0.46274674\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3107102  0.21920088 0.22074476 0.         0.17186917 0.\n",
      "  0.         0.79192305 0.         0.73371816 0.         0.\n",
      "  0.         1.007722   0.         0.7145528  0.         0.\n",
      "  0.         1.1115894  0.27926648 0.3547376  0.78786385 0.\n",
      "  0.         0.58956397 0.         0.         0.         0.\n",
      "  0.         0.9969777  0.8737445  0.0058234 ]]\n",
      "Hi!\n",
      "[[0.3882208  0.5647907  1.2393309  0.         0.         0.76454353\n",
      "  0.         0.09840154 0.39774466 0.         0.33621907 0.\n",
      "  0.6310999  0.         0.         0.1840617  0.29596686 0.14796892\n",
      "  0.         0.7030706  0.5481753  0.         0.         0.\n",
      "  0.         0.         0.         0.01682988 0.         0.\n",
      "  0.         0.5135373  0.18373257 0.         0.         0.\n",
      "  0.         0.04358471 0.02014556 0.5646742  0.         0.\n",
      "  0.         0.         0.04393746 0.05626866 0.         0.9213739\n",
      "  0.39730877 0.5713142  0.376479   0.41601187 0.28925988 1.0600587\n",
      "  0.         0.22862202 0.         0.         0.14444266 0.\n",
      "  0.15573643 0.07945506 0.6718748  0.26550782]]\n",
      "Hi!\n",
      "[[0.15704998 0.33259124 0.22612973 0.06474868 0.         0.312389\n",
      "  0.14489524 0.30597326 0.         0.03696373 0.12954159 0.\n",
      "  0.07263234 0.2756835  0.         0.         0.         0.1570807\n",
      "  0.         0.49069935 0.0540514  0.         0.         0.01889435\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22418895 0.396397   0.20167577 0.         0.         0.\n",
      "  0.         0.         0.19290014 0.17931277 0.         0.\n",
      "  0.         0.         0.42629257 0.62394553 0.         0.05094009\n",
      "  0.38051087 0.42193878 0.         0.3480225  0.2860103  0.5548274\n",
      "  0.         0.39550105 0.06976628 0.         0.01876993 0.\n",
      "  0.14496697 0.19744541 0.         0.        ]]\n",
      "Hi!\n",
      "[[2.78223723e-01 4.53417122e-01 3.45337093e-01 0.00000000e+00\n",
      "  0.00000000e+00 6.67255521e-02 7.04760626e-02 1.85678482e-01\n",
      "  2.46176660e-01 0.00000000e+00 3.42254452e-02 0.00000000e+00\n",
      "  6.86005533e-01 1.51032105e-01 0.00000000e+00 2.23972067e-01\n",
      "  1.18729651e-01 1.81378201e-01 0.00000000e+00 1.22293659e-01\n",
      "  2.20567584e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.55871177e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.63438553e-01 4.07072425e-01\n",
      "  1.00320846e-01 0.00000000e+00 5.59221357e-02 0.00000000e+00\n",
      "  8.52472857e-02 2.68853039e-01 3.87838036e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.74760367e-02\n",
      "  2.99576342e-01 2.55926996e-01 0.00000000e+00 3.65981549e-01\n",
      "  9.18642879e-02 2.26629168e-01 6.11714385e-02 1.26763955e-01\n",
      "  1.90654442e-01 7.58700907e-01 0.00000000e+00 7.55644578e-05\n",
      "  2.06219941e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.00192919e-02 1.93236277e-01 1.76654071e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.39150882 0.11837907 0.63874567 0.06803079 0.         0.6992784\n",
      "  0.7683327  0.8806266  0.47363716 0.07668485 0.3575205  0.\n",
      "  0.         0.         0.         0.22163282 0.         0.6630395\n",
      "  0.         0.1711679  0.60967517 0.         0.         0.18977341\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.39155588 0.20308231 0.12752868 0.         0.15281495 0.\n",
      "  0.         0.62900674 0.         0.6397695  0.         0.\n",
      "  0.         0.61154485 0.21223925 0.7809896  0.         0.\n",
      "  0.04988418 1.0561316  0.24759257 0.36275938 0.7177113  0.11171627\n",
      "  0.         0.3223045  0.         0.         0.         0.\n",
      "  0.         0.9396877  0.3883342  0.01570667]]\n",
      "Hi!\n",
      "[[0.26800883 0.378507   0.954924   0.         0.         0.5555256\n",
      "  0.         0.0567624  0.6968154  0.         0.398781   0.\n",
      "  0.40086517 0.         0.         0.35988393 0.25464615 0.0345657\n",
      "  0.         0.5350641  0.59668875 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26492757 0.20872566 0.         0.         0.\n",
      "  0.         0.18154082 0.         0.56453234 0.         0.\n",
      "  0.         0.18897247 0.         0.         0.         0.7322594\n",
      "  0.00395642 0.5092155  0.42711404 0.3288594  0.0224528  0.6677408\n",
      "  0.         0.10940401 0.         0.19938414 0.22421733 0.\n",
      "  0.01453522 0.0220576  0.2843079  0.35440218]]\n",
      "Hi!\n",
      "[[0.7059113  0.79512656 0.4888388  0.         0.         0.6056469\n",
      "  0.1859328  0.46654344 0.21376581 0.         0.26947996 0.\n",
      "  1.2408062  0.47149673 0.         0.31449178 0.         0.46723938\n",
      "  0.27836546 0.6508051  0.31852788 0.         0.         0.16060306\n",
      "  0.0491088  0.         0.         0.50163865 0.         0.\n",
      "  0.89555156 0.7794685  0.         0.         0.3867945  0.\n",
      "  0.44336864 0.7632901  0.42304564 0.27754536 0.         0.\n",
      "  0.         0.25965685 1.0503527  0.65697455 0.         1.0173944\n",
      "  0.16288899 0.5507659  0.43316242 0.42438355 0.34636477 1.1768105\n",
      "  0.         0.05609142 0.44089112 0.         0.         0.\n",
      "  0.         0.10562481 0.7314103  0.0688869 ]]\n",
      "Hi!\n",
      "[[0.40782404 0.         0.41381085 0.30206263 0.         0.778467\n",
      "  1.2222226  1.2657859  0.00286065 0.         0.19716844 0.\n",
      "  0.         0.         0.         0.08550145 0.         0.44795278\n",
      "  0.         0.21213111 0.37056768 0.         0.         0.\n",
      "  0.         0.         0.         0.15175694 0.         0.\n",
      "  0.7362636  0.54686975 0.15204115 0.         0.3630597  0.\n",
      "  0.         0.7698597  0.         0.4522673  0.03157066 0.\n",
      "  0.         0.38796723 0.7199591  1.0701555  0.         0.04584881\n",
      "  0.10190488 0.94869745 0.04868383 0.55585414 0.66987    0.5540206\n",
      "  0.         0.58561087 0.06247006 0.         0.         0.\n",
      "  0.         0.56376827 0.66688746 0.        ]]\n",
      "Hi!\n",
      "[[0.67309225 0.38602436 1.1716747  0.         0.         0.94234085\n",
      "  0.10163318 0.18421653 0.22045626 0.13562329 0.45788407 0.\n",
      "  0.         0.         0.         0.09686586 0.20394146 0.52992123\n",
      "  0.         0.74165636 0.7085123  0.         0.         0.19591168\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31081077 0.10015153 0.         0.         0.\n",
      "  0.         0.13834047 0.         0.6267583  0.         0.\n",
      "  0.         0.20308973 0.1124896  0.5210248  0.         0.2799963\n",
      "  0.46794483 0.8423007  0.02961504 0.3833425  0.64108115 0.3235499\n",
      "  0.         0.94789004 0.         0.         0.13914727 0.\n",
      "  0.4123573  0.52797145 0.2625889  0.17686114]]\n",
      "Hi!\n",
      "[[0.8068509  0.1923992  1.7342538  0.         0.         0.8739477\n",
      "  0.20898594 0.1909088  1.1966703  0.         0.73632616 0.\n",
      "  0.2621702  0.         0.         0.68983793 0.6513282  0.9087686\n",
      "  0.         0.10972825 1.3614382  0.26392323 0.         0.49437404\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16932169 0.02583434 0.         0.         0.\n",
      "  0.10869248 0.8211046  0.         0.9484035  0.04825502 0.\n",
      "  0.         1.0028324  0.         0.08442407 0.         0.7240902\n",
      "  0.06461673 0.8477789  0.6602567  0.12513332 0.32447052 0.16759889\n",
      "  0.         0.43780562 0.         0.6704141  0.07021832 0.\n",
      "  0.         0.94287944 0.9731856  0.89624006]]\n",
      "Hi!\n",
      "[[0.5808117  0.         0.5601203  0.38351288 0.         1.0159141\n",
      "  1.5992123  1.5916544  0.19142437 0.         0.24398525 0.\n",
      "  0.         0.         0.         0.1449755  0.         0.51747984\n",
      "  0.         0.04548984 0.5671307  0.13749456 0.         0.\n",
      "  0.         0.         0.         0.21604334 0.         0.\n",
      "  0.69560623 0.54559195 0.09884933 0.         0.49056256 0.\n",
      "  0.         1.0394237  0.         0.5112637  0.19892189 0.\n",
      "  0.         0.70136654 0.70444036 1.113081   0.         0.11902929\n",
      "  0.         0.9455024  0.08982311 0.6219644  0.8117772  0.54427195\n",
      "  0.         0.74363065 0.10964123 0.         0.         0.\n",
      "  0.         0.7354099  1.1084448  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.14961478 0.0459526  0.01246708 0.         0.11029527\n",
      "  0.06718985 0.22894914 0.         0.02758628 0.04797727 0.\n",
      "  0.0611386  0.27495012 0.         0.         0.         0.08596933\n",
      "  0.         0.14701799 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12721433 0.25344887 0.20836528 0.         0.         0.\n",
      "  0.         0.         0.23070581 0.04709599 0.         0.\n",
      "  0.         0.         0.319735   0.40309796 0.         0.02379879\n",
      "  0.18916427 0.19732995 0.         0.19193783 0.07353114 0.46725687\n",
      "  0.         0.19945954 0.08362254 0.         0.         0.\n",
      "  0.04134871 0.11253804 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.94015425 1.3825412  0.15546997 0.16111612 0.         0.19207782\n",
      "  0.48588112 1.5832053  0.63168764 0.         0.25943452 0.\n",
      "  3.0586624  1.3852347  0.         0.7585999  0.         0.48274994\n",
      "  1.5257787  0.39346156 0.28736234 0.8318444  0.         0.2733566\n",
      "  0.31640884 0.         0.         1.6708782  0.         0.\n",
      "  2.2443683  1.3942685  0.03959782 0.         1.305444   0.\n",
      "  0.908177   1.0133873  1.4027735  0.12226119 0.2866339  0.\n",
      "  0.         1.1654918  1.9695206  1.0980078  0.         1.2397677\n",
      "  0.         0.9158607  1.1823548  0.45033073 0.9261726  2.1683128\n",
      "  0.         0.         1.1004812  0.         0.         0.\n",
      "  0.         0.35953468 1.2578353  0.        ]]\n",
      "Hi!\n",
      "[[0.5426284  0.36964262 0.76662624 0.         0.         0.70200044\n",
      "  0.5731549  0.8801129  0.81102955 0.         0.49360976 0.\n",
      "  1.2655554  0.0454095  0.         0.661749   0.         0.66854864\n",
      "  0.7795705  0.165409   0.78637344 0.         0.         0.\n",
      "  0.27083942 0.         0.         0.567457   0.         0.\n",
      "  0.95592314 0.65654796 0.         0.         0.5930618  0.\n",
      "  0.6525369  1.1882292  0.         0.39499667 0.02570443 0.\n",
      "  0.         0.37049347 0.8776784  0.5335087  0.         0.9359321\n",
      "  0.         0.6103048  0.77151906 0.46712005 0.3971148  0.7860366\n",
      "  0.         0.         0.44650003 0.         0.         0.\n",
      "  0.         0.4781292  1.3990979  0.40456256]]\n",
      "Hi!\n",
      "[[0.44300026 0.24103062 0.8129673  0.00394329 0.         0.8481529\n",
      "  0.43336597 0.8310056  0.36818627 0.         0.3997791  0.\n",
      "  0.69702697 0.         0.         0.20456259 0.         0.4027348\n",
      "  0.         0.35183734 0.6515397  0.         0.         0.\n",
      "  0.         0.         0.         0.20594475 0.         0.\n",
      "  0.7193606  0.6942422  0.         0.         0.21324736 0.\n",
      "  0.         0.71599555 0.         0.33505857 0.         0.\n",
      "  0.         0.14548686 0.6603553  0.71691424 0.         0.4807685\n",
      "  0.15472026 0.7225711  0.22916299 0.53012407 0.71594226 0.66339535\n",
      "  0.         0.41876572 0.1392357  0.         0.         0.\n",
      "  0.         0.33714136 1.0054455  0.07181883]]\n",
      "Hi!\n",
      "[[0.31783697 0.         0.2459471  0.23590873 0.         0.610703\n",
      "  1.6660734  1.7758087  0.7471283  0.         0.3068258  0.\n",
      "  0.7148349  0.17373839 0.         0.72253984 0.         0.74533874\n",
      "  0.3334446  0.         0.5377147  0.2594389  0.         0.\n",
      "  0.318064   0.         0.         0.6289166  0.         0.\n",
      "  1.2058618  0.41573477 0.         0.         0.9420721  0.\n",
      "  0.39903829 1.5631864  0.         0.23268326 0.3383883  0.\n",
      "  0.         0.9039861  0.8695025  1.0320537  0.         0.38838416\n",
      "  0.         0.74081904 0.6888972  0.4922054  0.5596594  0.42917335\n",
      "  0.         0.         0.47556442 0.         0.         0.\n",
      "  0.         0.8005036  1.410963   0.        ]]\n",
      "Hi!\n",
      "[[0.20824048 0.         0.14116411 0.4182512  0.         0.6615186\n",
      "  2.1469913  2.245765   0.83846414 0.         0.22729743 0.\n",
      "  0.48339343 0.19850272 0.         0.79077876 0.         0.7126206\n",
      "  0.08784857 0.         0.6216239  0.33194998 0.         0.\n",
      "  0.24813788 0.         0.         0.8653923  0.         0.\n",
      "  1.4432611  0.30787653 0.         0.         1.0280317  0.\n",
      "  0.1805199  1.5920342  0.         0.27071095 0.4739756  0.\n",
      "  0.         1.2663702  0.83434707 1.1351442  0.         0.00725588\n",
      "  0.         0.8656601  0.6601702  0.58264637 0.8425489  0.10184961\n",
      "  0.         0.         0.41148072 0.         0.         0.\n",
      "  0.         0.965119   1.6281918  0.        ]]\n",
      "Hi!\n",
      "[[0.17827336 0.         0.26229006 0.24941438 0.         0.5439802\n",
      "  1.7400286  1.7528946  0.69320303 0.         0.2726391  0.\n",
      "  0.16052434 0.         0.         0.6353883  0.         0.74225736\n",
      "  0.         0.         0.56550246 0.15125439 0.         0.\n",
      "  0.15464249 0.         0.         0.43921378 0.         0.\n",
      "  1.004395   0.22823931 0.04081034 0.         0.7956273  0.\n",
      "  0.03124085 1.4025607  0.         0.4390152  0.2882972  0.\n",
      "  0.         1.0474705  0.5682217  0.96141714 0.         0.\n",
      "  0.         0.8877918  0.49827096 0.4442152  0.6569091  0.05690468\n",
      "  0.         0.         0.19450615 0.         0.         0.\n",
      "  0.         1.0072837  1.2194786  0.        ]]\n",
      "Hi!\n",
      "[[0.47345307 0.         0.3537677  0.34554353 0.         0.78016305\n",
      "  1.3544137  1.4996774  0.19631253 0.         0.22299424 0.\n",
      "  0.3644172  0.14422932 0.         0.25240418 0.         0.5176628\n",
      "  0.         0.05587989 0.43845487 0.10974677 0.         0.\n",
      "  0.03184841 0.         0.         0.41720974 0.         0.\n",
      "  1.0187225  0.64639306 0.06755094 0.         0.5944888  0.\n",
      "  0.03419101 1.1224426  0.         0.2849999  0.1791159  0.\n",
      "  0.         0.45259926 0.9611764  1.1441075  0.         0.2866202\n",
      "  0.         0.8495581  0.26024064 0.6128506  0.69933414 0.7147265\n",
      "  0.         0.3177589  0.33763325 0.         0.         0.\n",
      "  0.         0.5530296  1.0906737  0.        ]]\n",
      "Hi!\n",
      "[[0.06220128 0.25143868 0.3423317  0.         0.         0.17880876\n",
      "  0.         0.         0.18162413 0.04695026 0.1937662  0.\n",
      "  0.19247405 0.         0.         0.10659357 0.         0.08067027\n",
      "  0.         0.2527017  0.21854998 0.         0.         0.00691638\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06337241 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.1626797  0.         0.\n",
      "  0.         0.         0.         0.07043032 0.         0.20279193\n",
      "  0.11786342 0.17222427 0.01567054 0.12900785 0.02643084 0.22202422\n",
      "  0.         0.         0.         0.         0.08715606 0.\n",
      "  0.14054896 0.10049502 0.         0.14626862]]\n",
      "Hi!\n",
      "[[0.72589886 0.         0.8310116  0.12967019 0.         0.78746575\n",
      "  0.8716426  0.9616162  0.6443063  0.16098876 0.3764993  0.\n",
      "  0.         0.         0.         0.2524217  0.37264782 0.70661116\n",
      "  0.         0.         0.7044602  0.24968009 0.         0.42761543\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30885535 0.         0.         0.\n",
      "  0.         0.5124602  0.         0.9507978  0.         0.\n",
      "  0.         1.2979645  0.         0.5240381  0.         0.\n",
      "  0.09807634 1.2549027  0.24639173 0.15622427 0.61377186 0.\n",
      "  0.         0.6199804  0.         0.03406195 0.         0.\n",
      "  0.13493063 1.2054846  0.16403233 0.06723355]]\n",
      "Hi!\n",
      "[[0.360238   0.         0.5489945  0.1615625  0.         0.71263444\n",
      "  1.1622313  1.5246992  0.81988114 0.         0.3682235  0.\n",
      "  0.93299943 0.0506865  0.         0.61594766 0.         0.6692411\n",
      "  0.35996756 0.         0.7320724  0.12776253 0.         0.\n",
      "  0.14409775 0.         0.         0.6862845  0.         0.\n",
      "  1.2020907  0.583324   0.         0.         0.7317604  0.\n",
      "  0.15471262 1.2928988  0.         0.2755755  0.19875571 0.\n",
      "  0.         0.67051226 0.7367424  0.91206956 0.         0.3751658\n",
      "  0.         0.815321   0.64635634 0.544116   0.83723205 0.4320998\n",
      "  0.         0.         0.39461288 0.         0.         0.\n",
      "  0.         0.66449    1.5462937  0.07867808]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17364581 0.28612176 0.21502884 0.         0.         0.49267626\n",
      "  0.2595205  0.27071607 0.14173211 0.10586119 0.1744077  0.\n",
      "  0.14285564 0.12576811 0.         0.10453228 0.         0.1931519\n",
      "  0.         0.3985964  0.13263755 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17884006 0.21767512 0.00131121 0.         0.         0.\n",
      "  0.         0.12269422 0.         0.19040501 0.         0.\n",
      "  0.         0.         0.33008623 0.4899769  0.         0.26465183\n",
      "  0.19698915 0.5517692  0.06367631 0.23115614 0.26618022 0.47361118\n",
      "  0.         0.19596203 0.         0.         0.         0.\n",
      "  0.1691017  0.3742107  0.03032136 0.        ]]\n",
      "Hi!\n",
      "[[0.7027769  0.43084955 1.6016097  0.         0.         1.0374334\n",
      "  0.04902717 0.24285838 0.77756274 0.         0.6617235  0.\n",
      "  0.71576107 0.         0.         0.47762355 0.3071916  0.7018751\n",
      "  0.09912548 0.4484752  1.1722783  0.         0.         0.26912776\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18841898 0.56195754 0.         0.         0.         0.\n",
      "  0.16108268 0.75369334 0.         0.7819311  0.         0.\n",
      "  0.         0.44762698 0.27959877 0.23974419 0.         0.87780094\n",
      "  0.27729905 0.7017537  0.4844413  0.35869718 0.47363645 0.6015728\n",
      "  0.         0.6341384  0.         0.26414412 0.0816217  0.\n",
      "  0.         0.57103235 1.1900451  0.6260603 ]]\n",
      "Hi!\n",
      "[[0.10334313 0.29757002 0.10905568 0.         0.         0.1413591\n",
      "  0.         0.18482372 0.         0.03150514 0.11461146 0.\n",
      "  0.31652552 0.3558159  0.         0.         0.         0.07401422\n",
      "  0.         0.19441266 0.03574016 0.         0.         0.04153742\n",
      "  0.         0.         0.         0.05312167 0.         0.\n",
      "  0.19542062 0.30769277 0.18952276 0.         0.         0.\n",
      "  0.         0.         0.3298789  0.07170703 0.         0.\n",
      "  0.         0.         0.3810326  0.31485814 0.         0.06723284\n",
      "  0.26207763 0.19496784 0.         0.21814737 0.1462792  0.50308204\n",
      "  0.         0.13641158 0.16782169 0.         0.         0.\n",
      "  0.16943245 0.10645291 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.798036   0.         1.3190154  0.17763235 0.         0.9427443\n",
      "  1.3073587  1.4802349  1.2434494  0.         0.5140422  0.\n",
      "  0.         0.         0.         0.7207827  0.46364498 0.7772739\n",
      "  0.         0.         1.1765765  0.27074063 0.         0.5951572\n",
      "  0.         0.         0.         0.08986016 0.         0.\n",
      "  0.23708126 0.28217167 0.10856541 0.         0.27087262 0.\n",
      "  0.         1.2424172  0.         0.7496898  0.21260759 0.\n",
      "  0.         1.5544226  0.         0.5055199  0.         0.27037454\n",
      "  0.         0.8201499  0.6171248  0.3767556  0.7373054  0.\n",
      "  0.         0.58621395 0.         0.37111637 0.         0.\n",
      "  0.         1.1680435  1.597463   0.3406271 ]]\n",
      "Hi!\n",
      "[[0.14320008 0.02492224 0.39505348 0.02453012 0.         0.50868875\n",
      "  1.0045063  1.1248533  0.54322314 0.         0.3214329  0.\n",
      "  0.14118457 0.         0.         0.45428386 0.         0.7000896\n",
      "  0.         0.         0.498842   0.         0.         0.\n",
      "  0.         0.         0.         0.14530511 0.         0.\n",
      "  0.6532307  0.2590381  0.00380737 0.         0.42196512 0.\n",
      "  0.         0.92458814 0.         0.50488055 0.         0.\n",
      "  0.         0.6781716  0.34174308 0.734787   0.         0.\n",
      "  0.         0.9729766  0.42348346 0.30821386 0.57582194 0.05934657\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.91661745 0.56940955 0.01052404]]\n",
      "Hi!\n",
      "[[0.55500084 0.1588951  1.1610551  0.         0.         0.9283921\n",
      "  0.4913336  0.63176644 0.83803564 0.         0.5381159  0.\n",
      "  0.41743734 0.         0.         0.4603638  0.14670765 0.7429698\n",
      "  0.         0.10939471 1.0116185  0.         0.         0.27045125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24088794 0.36722696 0.         0.         0.1567723  0.\n",
      "  0.         0.86267823 0.         0.6399739  0.02927147 0.\n",
      "  0.         0.6447577  0.15579087 0.40560666 0.         0.59915024\n",
      "  0.         0.76146704 0.4691638  0.32929388 0.47068724 0.35970315\n",
      "  0.         0.3544617  0.         0.15754405 0.         0.\n",
      "  0.         0.76865184 1.0374607  0.4790482 ]]\n",
      "Hi!\n",
      "[[0.4601045  0.13787213 0.52555144 0.0834799  0.         0.7576263\n",
      "  0.5485153  0.591922   0.00325315 0.18509163 0.17133859 0.\n",
      "  0.         0.         0.         0.14877623 0.         0.3130667\n",
      "  0.         0.5372757  0.28365037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21657518 0.3086377  0.07062056 0.         0.         0.\n",
      "  0.         0.26842964 0.         0.38151807 0.         0.\n",
      "  0.         0.08551294 0.44731575 0.87311375 0.         0.23545009\n",
      "  0.39193225 0.7051553  0.         0.47321022 0.48162365 0.50720644\n",
      "  0.         0.83233774 0.         0.         0.         0.\n",
      "  0.29230168 0.47892246 0.22440818 0.        ]]\n",
      "Hi!\n",
      "[[0.001289   0.00532791 0.03437418 0.00654486 0.         0.\n",
      "  0.15044849 0.27159145 0.04939474 0.04581471 0.05676071 0.\n",
      "  0.         0.15923467 0.         0.08598343 0.         0.05025868\n",
      "  0.         0.00587523 0.12876849 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04040172 0.01036142 0.24488385 0.         0.         0.\n",
      "  0.         0.         0.16064613 0.0478048  0.         0.\n",
      "  0.         0.01170635 0.26270613 0.33810705 0.         0.00183963\n",
      "  0.10663795 0.         0.         0.16228558 0.         0.25532293\n",
      "  0.         0.11673374 0.09435693 0.         0.         0.\n",
      "  0.01099996 0.11854696 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.37618917 0.         1.1291728  0.         0.         0.6907321\n",
      "  0.9403612  1.0386282  1.5415796  0.         0.5983807  0.\n",
      "  0.6910351  0.         0.         1.0356424  0.16071734 0.86256206\n",
      "  0.71995634 0.         1.1609166  0.2980609  0.         0.3123385\n",
      "  0.24045645 0.         0.         0.2967268  0.         0.\n",
      "  0.5213648  0.23026076 0.         0.         0.46700326 0.\n",
      "  0.515467   1.4425863  0.         0.6152219  0.32020053 0.\n",
      "  0.         1.3395107  0.01269466 0.24479207 0.         0.7065894\n",
      "  0.         0.7737837  0.9962188  0.23069833 0.2617117  0.03981182\n",
      "  0.         0.         0.18945694 0.54388905 0.         0.\n",
      "  0.         1.0183951  1.5616345  0.7887871 ]]\n",
      "Hi!\n",
      "[[0.37957704 1.1055948  0.7293713  0.         0.         0.48158768\n",
      "  0.         0.14209375 0.56874466 0.         0.50059026 0.\n",
      "  1.5647327  0.26688266 0.         0.46673837 0.         0.6025032\n",
      "  0.45611557 0.70938873 0.57389116 0.         0.         0.0391851\n",
      "  0.02298738 0.         0.         0.1839646  0.         0.\n",
      "  0.63710153 0.6191538  0.         0.         0.24700084 0.\n",
      "  0.1801317  0.5668071  0.19698381 0.49655327 0.         0.\n",
      "  0.         0.         0.56515    0.25509897 0.         0.8477516\n",
      "  0.01817377 0.6853767  0.7051969  0.24579406 0.342477   0.8622287\n",
      "  0.         0.         0.26946795 0.         0.08238169 0.\n",
      "  0.         0.44619045 0.5342858  0.52120984]]\n",
      "Hi!\n",
      "[[0.54599386 0.34457207 0.87759733 0.06270144 0.         0.82197726\n",
      "  0.0918799  0.35346797 0.         0.17467819 0.2193755  0.\n",
      "  0.         0.         0.         0.04053245 0.         0.2298218\n",
      "  0.         0.6375529  0.4467189  0.         0.         0.24292238\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07073414 0.4802943  0.16953124 0.         0.         0.\n",
      "  0.         0.15398078 0.         0.4722405  0.         0.\n",
      "  0.         0.10469238 0.36577374 0.724535   0.         0.09132957\n",
      "  0.5301432  0.9479552  0.         0.4456172  0.8801785  0.53165126\n",
      "  0.         1.0820097  0.         0.         0.         0.\n",
      "  0.39503777 0.5089387  0.15054408 0.        ]]\n",
      "Hi!\n",
      "[[0.46855634 0.31084168 0.6895859  0.14563213 0.         0.95843863\n",
      "  0.40045908 0.6786035  0.         0.0830012  0.24980819 0.\n",
      "  0.02287832 0.11155426 0.         0.         0.         0.26442516\n",
      "  0.         0.7760275  0.36089838 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.44705194 0.6453193  0.1222924  0.         0.         0.\n",
      "  0.         0.17740011 0.02075475 0.3570672  0.         0.\n",
      "  0.         0.         0.71178025 0.9398473  0.         0.18450318\n",
      "  0.6132964  0.840327   0.         0.60164577 0.7853051  0.7289916\n",
      "  0.         1.0632759  0.         0.         0.         0.\n",
      "  0.2526369  0.2509823  0.38289952 0.        ]]\n",
      "Hi!\n",
      "[[0.5943198  0.         1.0740745  0.04675303 0.         0.864178\n",
      "  0.80494004 1.0307997  0.9000102  0.         0.4705579  0.\n",
      "  0.19110374 0.         0.         0.4615552  0.16035183 0.72020566\n",
      "  0.         0.         0.96910125 0.         0.         0.42850074\n",
      "  0.         0.         0.         0.02125114 0.         0.\n",
      "  0.39436913 0.31252065 0.07305433 0.         0.20356472 0.\n",
      "  0.         0.94222194 0.         0.63963544 0.04991557 0.\n",
      "  0.         0.8949755  0.06485414 0.5585687  0.         0.18820305\n",
      "  0.         0.97141796 0.4551878  0.36943468 0.6952481  0.12041879\n",
      "  0.         0.4251392  0.         0.03235886 0.         0.\n",
      "  0.         0.87268543 1.1962495  0.25496608]]\n",
      "Hi!\n",
      "[[0.26703364 0.40898317 0.49815103 0.         0.         0.34202027\n",
      "  0.04731383 0.3361913  0.01989021 0.         0.01612346 0.\n",
      "  0.62746835 0.15907626 0.         0.07076567 0.         0.18159491\n",
      "  0.         0.32575926 0.1546467  0.         0.         0.\n",
      "  0.         0.         0.         0.3065928  0.         0.\n",
      "  0.3985027  0.5953491  0.13494392 0.         0.02802765 0.\n",
      "  0.16049188 0.22619492 0.4152759  0.23586722 0.         0.\n",
      "  0.         0.16160855 0.54269016 0.40652367 0.         0.6618846\n",
      "  0.34071875 0.3895869  0.         0.36462018 0.08743966 0.9870769\n",
      "  0.         0.24511433 0.18171345 0.         0.         0.\n",
      "  0.05968317 0.0736948  0.29130468 0.        ]]\n",
      "Hi!\n",
      "[[0.3545734  0.         1.0055617  0.         0.         0.74111587\n",
      "  1.0248543  1.0635358  1.1689944  0.         0.53149354 0.\n",
      "  0.5046248  0.         0.         0.79493207 0.05273415 0.8276161\n",
      "  0.37813038 0.         1.0367584  0.0998792  0.         0.2177624\n",
      "  0.20333508 0.         0.         0.2415105  0.         0.\n",
      "  0.5204137  0.28847194 0.         0.         0.47839952 0.\n",
      "  0.29410353 1.3340183  0.         0.5534845  0.19617142 0.\n",
      "  0.         1.0906115  0.21158879 0.4291752  0.         0.5955774\n",
      "  0.         0.630846   0.72401696 0.29146352 0.35898447 0.12407454\n",
      "  0.         0.         0.18305406 0.25266019 0.         0.\n",
      "  0.         1.0019159  1.456175   0.5340264 ]]\n",
      "Hi!\n",
      "[[0.8303377  0.         1.0891111  0.48729026 0.         1.1955656\n",
      "  1.2423413  1.4725686  0.4566084  0.         0.33638334 0.\n",
      "  0.         0.         0.         0.16698053 0.20769191 0.63530487\n",
      "  0.         0.         0.8630356  0.         0.         0.4094865\n",
      "  0.         0.         0.         0.06034131 0.         0.\n",
      "  0.33055255 0.5233602  0.19535317 0.         0.09118222 0.\n",
      "  0.         0.8663996  0.         0.7132124  0.13748845 0.\n",
      "  0.         0.9237349  0.30559832 0.8733911  0.         0.00754469\n",
      "  0.02464972 1.0062803  0.06456851 0.58674335 1.0522062  0.24235877\n",
      "  0.         1.2011187  0.         0.         0.         0.\n",
      "  0.         0.79640144 1.3488595  0.        ]]\n",
      "Hi!\n",
      "[[0.01403564 0.1249957  0.07295673 0.         0.         0.04673326\n",
      "  0.02110079 0.20261267 0.         0.04120173 0.06621496 0.\n",
      "  0.05504728 0.1793023  0.         0.         0.         0.06434707\n",
      "  0.         0.09984574 0.02579942 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04045113 0.12427618 0.17188443 0.         0.         0.\n",
      "  0.         0.         0.2531962  0.06811003 0.         0.\n",
      "  0.         0.         0.24404842 0.32411796 0.         0.00166019\n",
      "  0.13110249 0.04061355 0.         0.18246509 0.10574791 0.33761385\n",
      "  0.         0.1786275  0.0595273  0.         0.         0.\n",
      "  0.00365827 0.09715746 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.18964891 0.49646026 0.         0.         0.         0.36871144\n",
      "  0.7046146  0.9036927  0.         0.         0.17249644 0.\n",
      "  0.5854208  0.59602183 0.         0.1868974  0.         0.3699419\n",
      "  0.         0.44632322 0.11148684 0.         0.         0.03178763\n",
      "  0.         0.         0.         0.26102936 0.         0.\n",
      "  0.87424225 0.41762528 0.16191672 0.         0.28207153 0.\n",
      "  0.         0.51892525 0.06015634 0.27239835 0.         0.\n",
      "  0.         0.09881102 0.77276075 0.9507154  0.         0.12497927\n",
      "  0.11771128 0.8066677  0.2870951  0.3300465  0.50076026 0.6373916\n",
      "  0.         0.         0.22508559 0.         0.         0.\n",
      "  0.         0.47178957 0.04957499 0.        ]]\n",
      "Hi!\n",
      "[[0.6432192  0.         0.71643364 0.5592725  0.         0.86047024\n",
      "  1.9241726  1.9422219  0.75881225 0.         0.29698595 0.\n",
      "  0.         0.         0.         0.39722785 0.18158819 0.8064893\n",
      "  0.         0.         0.8008686  0.23915184 0.         0.4921087\n",
      "  0.         0.         0.         0.15467715 0.         0.\n",
      "  0.5322551  0.22020923 0.39305118 0.         0.36962268 0.\n",
      "  0.         1.0656748  0.         0.85202223 0.28915727 0.\n",
      "  0.         1.5889425  0.00487051 0.8909591  0.         0.\n",
      "  0.         1.15561    0.23377906 0.40757966 0.9137706  0.\n",
      "  0.         0.70185256 0.         0.         0.         0.\n",
      "  0.         1.221079   1.1429391  0.        ]]\n",
      "Hi!\n",
      "[[0.140408   0.6643625  0.80711544 0.         0.         0.36638173\n",
      "  0.32158133 0.23636211 0.9980005  0.         0.4984771  0.\n",
      "  0.80037326 0.         0.         0.69264084 0.0611846  0.78122735\n",
      "  0.31254444 0.30420837 0.7162874  0.13389507 0.         0.\n",
      "  0.23043601 0.         0.         0.         0.         0.\n",
      "  0.29657996 0.15689865 0.         0.         0.32851318 0.\n",
      "  0.15246764 0.8561982  0.         0.53466177 0.04235676 0.\n",
      "  0.         0.37017998 0.         0.         0.         0.78702\n",
      "  0.         0.7120123  0.7815325  0.04417681 0.         0.22402042\n",
      "  0.         0.         0.01892502 0.11702132 0.01084108 0.\n",
      "  0.         0.75668746 0.65848595 0.70192176]]\n",
      "Hi!\n",
      "[[0.25706795 0.33995765 0.22784923 0.02602393 0.         0.49908397\n",
      "  0.1368278  0.30611262 0.         0.00428082 0.14204851 0.\n",
      "  0.15445557 0.2906137  0.         0.         0.         0.06772352\n",
      "  0.         0.53402066 0.07268547 0.         0.         0.\n",
      "  0.         0.         0.         0.064848   0.         0.\n",
      "  0.29504535 0.49148312 0.19481722 0.         0.         0.\n",
      "  0.         0.02652858 0.3249788  0.17658336 0.         0.\n",
      "  0.         0.         0.5223827  0.67893016 0.         0.26024267\n",
      "  0.4423421  0.38635334 0.         0.47063607 0.32852107 0.7877825\n",
      "  0.         0.54926175 0.10453877 0.         0.         0.\n",
      "  0.10065734 0.06494634 0.01525423 0.        ]]\n",
      "Hi!\n",
      "[[0.95862556 0.33494925 1.7994361  0.         0.         0.977404\n",
      "  0.14599068 0.05640268 0.9954854  0.02210608 0.71168053 0.\n",
      "  0.05734937 0.         0.         0.45404384 0.7650226  0.84588104\n",
      "  0.         0.2827947  1.3295944  0.25013843 0.         0.60656404\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14761008 0.09685288 0.         0.         0.\n",
      "  0.         0.46672153 0.         1.0332912  0.         0.\n",
      "  0.         0.94627374 0.         0.1490398  0.         0.54308045\n",
      "  0.2131747  0.87513614 0.4794748  0.09754891 0.459202   0.1090121\n",
      "  0.         0.7682828  0.         0.54535097 0.14063759 0.\n",
      "  0.16870016 0.87424177 0.6688526  0.85180503]]\n",
      "Hi!\n",
      "[[0.529652   0.         1.1972309  0.         0.         0.477949\n",
      "  0.65726054 0.64466935 1.3292365  0.         0.6063172  0.\n",
      "  0.         0.         0.         0.82564944 0.47043285 0.96189773\n",
      "  0.         0.         1.1075737  0.41509902 0.         0.46120822\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04077559 0.         0.07610615 0.         0.14394079 0.\n",
      "  0.0102165  0.95901084 0.         0.8571063  0.10043865 0.\n",
      "  0.         1.3946669  0.         0.04597526 0.         0.21679966\n",
      "  0.         0.8339412  0.73744357 0.         0.20309216 0.\n",
      "  0.         0.         0.         0.49659076 0.         0.\n",
      "  0.         1.2548788  0.7329561  0.6988313 ]]\n",
      "Hi!\n",
      "[[0.76105887 0.5855541  1.5839976  0.         0.         1.1800671\n",
      "  0.0031276  0.19516532 0.63378656 0.         0.6371519  0.\n",
      "  0.70847833 0.         0.         0.26552156 0.24119066 0.5985622\n",
      "  0.         0.64401394 1.1128235  0.         0.         0.3448418\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17589842 0.6055075  0.00563594 0.         0.         0.\n",
      "  0.         0.46292928 0.         0.7837343  0.         0.\n",
      "  0.         0.19678284 0.25727126 0.30744737 0.         0.7712364\n",
      "  0.44188535 0.84708196 0.38263533 0.46596128 0.68182015 0.6672369\n",
      "  0.         0.872325   0.         0.10443147 0.10713699 0.\n",
      "  0.         0.39808935 0.965009   0.58707273]]\n",
      "Hi!\n",
      "[[0.10298074 0.24074055 0.45531803 0.         0.         0.35482493\n",
      "  0.6412399  0.8815955  0.6474137  0.         0.3758865  0.\n",
      "  0.36828008 0.         0.         0.54400414 0.         0.636113\n",
      "  0.         0.0371533  0.55730754 0.         0.         0.0506798\n",
      "  0.         0.         0.         0.0925202  0.         0.\n",
      "  0.58665645 0.2234711  0.         0.         0.33019784 0.\n",
      "  0.         0.79167575 0.         0.5023015  0.         0.\n",
      "  0.         0.6447872  0.16911633 0.47753397 0.         0.\n",
      "  0.         0.9419469  0.52458966 0.23089735 0.49302924 0.14253171\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.8274444  0.45443577 0.18044624]]\n",
      "Hi!\n",
      "[[0.15542927 0.36566523 0.19029926 0.00667058 0.         0.28219163\n",
      "  0.         0.26212496 0.         0.02303639 0.18010189 0.\n",
      "  0.15674382 0.327128   0.         0.         0.         0.15909868\n",
      "  0.         0.40022814 0.08672338 0.         0.         0.04734376\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18997385 0.31253162 0.1763634  0.         0.         0.\n",
      "  0.         0.         0.30715615 0.14455439 0.         0.\n",
      "  0.         0.         0.39895296 0.5200588  0.         0.08054963\n",
      "  0.32327467 0.335143   0.         0.28447947 0.23921013 0.6015871\n",
      "  0.         0.23346509 0.08049221 0.         0.         0.\n",
      "  0.12036718 0.19240941 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.43991256 0.39917442 1.0829227  0.         0.         0.8210395\n",
      "  0.19854699 0.2843652  0.3712037  0.         0.52591884 0.\n",
      "  0.5624986  0.         0.         0.31734633 0.         0.62798977\n",
      "  0.         0.6066063  0.7586374  0.         0.         0.00946317\n",
      "  0.         0.         0.         0.05685696 0.         0.\n",
      "  0.39394504 0.61340827 0.         0.         0.1596188  0.\n",
      "  0.1851376  0.6299786  0.         0.51555234 0.         0.\n",
      "  0.         0.09674501 0.54075193 0.46159664 0.         0.7179082\n",
      "  0.20272595 0.59644645 0.34738427 0.33464333 0.4131221  0.6557665\n",
      "  0.         0.30641702 0.1455907  0.         0.03658179 0.\n",
      "  0.         0.4624293  0.88638484 0.24336761]]\n",
      "Hi!\n",
      "[[0.02497457 0.08191095 0.4649245  0.         0.         0.33575135\n",
      "  0.         0.         0.20070489 0.20442772 0.3284751  0.\n",
      "  0.         0.         0.         0.1163578  0.         0.\n",
      "  0.         0.32410136 0.31338325 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08197708 0.         0.         0.\n",
      "  0.         0.09029034 0.08904861 0.24183615 0.         0.\n",
      "  0.         0.         0.08923304 0.2937638  0.         0.23750193\n",
      "  0.18881582 0.06851263 0.04500834 0.25475627 0.11530293 0.25444368\n",
      "  0.         0.24756478 0.         0.         0.10579997 0.\n",
      "  0.         0.06373575 0.         0.02794348]]\n",
      "Hi!\n",
      "[[0.03579916 0.30360982 0.23647921 0.         0.         0.1624175\n",
      "  0.         0.         0.03151189 0.03557983 0.16806784 0.\n",
      "  0.25107405 0.12190589 0.         0.         0.         0.05884348\n",
      "  0.         0.24877015 0.10516321 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02788428 0.17510161 0.05808173 0.         0.         0.\n",
      "  0.         0.         0.12701032 0.10290387 0.         0.\n",
      "  0.         0.         0.15328366 0.19709958 0.         0.15486039\n",
      "  0.20817858 0.1311009  0.         0.19149418 0.09878948 0.43094063\n",
      "  0.         0.05922557 0.06404442 0.         0.04859978 0.\n",
      "  0.08772007 0.07183857 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.15833703 0.         0.         0.24871781 0.         0.35225537\n",
      "  1.8811044  1.7410659  0.49066335 0.         0.20977949 0.\n",
      "  0.         0.         0.         0.54632616 0.         0.6946535\n",
      "  0.         0.         0.31416208 0.2040705  0.         0.\n",
      "  0.14515024 0.         0.         0.27348384 0.         0.\n",
      "  0.7966901  0.08398408 0.14846028 0.         0.76535493 0.\n",
      "  0.         1.2430329  0.         0.45150596 0.28527135 0.\n",
      "  0.         1.1086727  0.4477001  0.96206874 0.         0.\n",
      "  0.         0.9645781  0.42492735 0.34812507 0.5612721  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.1014459  0.5318946  0.        ]]\n",
      "Hi!\n",
      "[[0.03268463 0.26895186 0.0884821  0.         0.         0.08094464\n",
      "  0.         0.14114721 0.         0.02473328 0.13968967 0.\n",
      "  0.26646337 0.26763123 0.         0.         0.         0.07572697\n",
      "  0.         0.16221519 0.04248545 0.         0.         0.\n",
      "  0.         0.         0.         0.02906604 0.         0.\n",
      "  0.13445358 0.21935745 0.14319517 0.         0.         0.\n",
      "  0.         0.         0.27627584 0.02114704 0.         0.\n",
      "  0.         0.         0.2829872  0.2875804  0.         0.0276236\n",
      "  0.20273459 0.13970335 0.         0.15907079 0.10006136 0.44670945\n",
      "  0.         0.04481934 0.12129929 0.         0.         0.\n",
      "  0.1521445  0.10431152 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.65392834 0.8152564  1.2649142  0.         0.         1.0225966\n",
      "  0.         0.         0.11879503 0.         0.5410155  0.\n",
      "  0.8284138  0.         0.         0.         0.         0.23026977\n",
      "  0.         1.0607011  0.5365175  0.         0.         0.09043353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24956699 0.745988   0.         0.         0.         0.\n",
      "  0.05480811 0.10295384 0.44132707 0.5157245  0.         0.\n",
      "  0.         0.         0.64327    0.47690964 0.         0.88923144\n",
      "  0.7738794  0.45666176 0.02800616 0.7058888  0.5445516  1.2066889\n",
      "  0.         0.91190034 0.03332433 0.         0.16199681 0.\n",
      "  0.04150294 0.02902133 0.68064463 0.1683893 ]]\n",
      "Hi!\n",
      "[[4.6613249e-01 3.4214050e-01 7.5311232e-01 0.0000000e+00 0.0000000e+00\n",
      "  8.3179539e-01 1.1104306e-01 3.1383383e-01 8.9610420e-02 1.6649552e-01\n",
      "  3.2088542e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.0150895e-02 0.0000000e+00 3.8259280e-01 0.0000000e+00 7.2332686e-01\n",
      "  4.4373426e-01 0.0000000e+00 0.0000000e+00 1.0545786e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4356776e-04 2.5025433e-01 4.9587723e-02 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.1877822e-02 0.0000000e+00 4.8653013e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 8.7327741e-02 1.8389642e-01\n",
      "  6.2106967e-01 0.0000000e+00 1.8823771e-01 4.5044458e-01 8.0345345e-01\n",
      "  0.0000000e+00 4.0556723e-01 5.1095915e-01 3.4576708e-01 0.0000000e+00\n",
      "  8.6259288e-01 0.0000000e+00 0.0000000e+00 5.8091350e-02 0.0000000e+00\n",
      "  3.6664748e-01 4.2720991e-01 9.1309212e-02 1.2218789e-02]]\n",
      "Hi!\n",
      "[[1.1043526  0.         1.5238355  0.19239916 0.         1.2805116\n",
      "  0.8400369  0.9339423  0.63174057 0.         0.5123866  0.\n",
      "  0.         0.         0.         0.20584923 0.65156555 0.64014906\n",
      "  0.         0.18243055 1.1101934  0.16024168 0.         0.534229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3428518  0.14333737 0.         0.         0.\n",
      "  0.         0.61583376 0.         0.93120307 0.         0.\n",
      "  0.         1.15662    0.         0.5380275  0.         0.22757806\n",
      "  0.18474135 1.0531132  0.19921839 0.3744152  0.7654087  0.3354848\n",
      "  0.         1.3692577  0.         0.14157248 0.         0.\n",
      "  0.2939531  0.82077223 0.95327663 0.10353271]]\n",
      "Hi!\n",
      "[[0.56621766 0.         1.297123   0.         0.         0.63418895\n",
      "  0.8948159  0.8595967  1.4703226  0.         0.63224864 0.\n",
      "  0.18297376 0.         0.         0.947129   0.45478594 0.94680953\n",
      "  0.17731178 0.         1.2439835  0.4255473  0.         0.5160768\n",
      "  0.09734645 0.         0.         0.         0.         0.\n",
      "  0.14488588 0.01696906 0.00967367 0.         0.26646045 0.\n",
      "  0.2552025  1.2401003  0.         0.7919952  0.23314181 0.\n",
      "  0.         1.4910699  0.         0.12564395 0.         0.51257914\n",
      "  0.         0.7123088  0.8054413  0.06545617 0.21578018 0.\n",
      "  0.         0.         0.         0.6483097  0.         0.\n",
      "  0.         1.2379363  1.2523137  0.7536813 ]]\n",
      "Hi!\n",
      "[[0.7626546  0.         1.1248317  0.10430726 0.         0.9768265\n",
      "  0.89161485 0.8644641  0.5375081  0.03141157 0.43307048 0.\n",
      "  0.         0.         0.         0.20449805 0.31727177 0.71209073\n",
      "  0.         0.12596981 0.8637331  0.0118392  0.         0.31949827\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04780176 0.28264415 0.09754777 0.         0.09283714 0.\n",
      "  0.         0.6412678  0.         0.7372304  0.         0.\n",
      "  0.         0.87803924 0.04449816 0.6117683  0.         0.1893715\n",
      "  0.09790266 0.8971122  0.19642937 0.30825415 0.60752404 0.18442807\n",
      "  0.         0.8057679  0.         0.         0.         0.\n",
      "  0.14877118 0.9037415  0.7100423  0.08503184]]\n",
      "Hi!\n",
      "[[0.65719944 0.34652618 0.9697004  0.04421482 0.         1.1506634\n",
      "  0.4006763  0.63908607 0.15606812 0.22655919 0.3686772  0.\n",
      "  0.         0.         0.         0.03103059 0.00454029 0.3627406\n",
      "  0.         0.62780875 0.68607414 0.         0.         0.374133\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03767865 0.27598244 0.13096954 0.         0.         0.\n",
      "  0.         0.17507866 0.         0.76812625 0.         0.\n",
      "  0.         0.32047316 0.16269064 0.9187654  0.         0.10398622\n",
      "  0.45737723 1.1517425  0.         0.51078993 1.0162352  0.3378689\n",
      "  0.         1.1731288  0.         0.         0.01516359 0.\n",
      "  0.32545465 0.588978   0.27078027 0.        ]]\n",
      "Hi!\n",
      "[[0.36749494 0.         0.5257773  0.45150816 0.         0.86053973\n",
      "  1.6325796  1.795278   0.60311633 0.         0.257599   0.\n",
      "  0.01525297 0.         0.         0.4333462  0.         0.6498661\n",
      "  0.         0.         0.6921761  0.05290271 0.         0.13117035\n",
      "  0.         0.         0.         0.43188024 0.         0.\n",
      "  0.8887357  0.4359686  0.18105079 0.         0.59329706 0.\n",
      "  0.         1.2219441  0.         0.5055627  0.26841193 0.\n",
      "  0.         0.9651193  0.5049981  1.0124884  0.         0.\n",
      "  0.         0.94845635 0.27626657 0.56272787 0.94022626 0.06841616\n",
      "  0.         0.35034877 0.08485575 0.         0.         0.\n",
      "  0.         0.9254974  1.4531391  0.        ]]\n",
      "Hi!\n",
      "[[0.53959686 0.0122429  0.         0.511684   0.         0.5557991\n",
      "  1.3602775  1.9596347  0.41148698 0.         0.1985364  0.\n",
      "  1.1157715  0.8661223  0.         0.4961753  0.         0.5004663\n",
      "  0.3221558  0.         0.4157438  0.3309691  0.         0.0681566\n",
      "  0.16043742 0.         0.         1.0226395  0.         0.\n",
      "  1.7187196  0.8006274  0.15335962 0.         1.0105126  0.\n",
      "  0.21349637 1.2569854  0.22207934 0.11152177 0.35458493 0.\n",
      "  0.         0.51121575 1.4436233  1.3588436  0.         0.29700863\n",
      "  0.         0.88207316 0.5879678  0.7114838  1.0393163  0.8764224\n",
      "  0.         0.         0.59618616 0.         0.         0.\n",
      "  0.         0.4521681  1.3969125  0.        ]]\n",
      "Hi!\n",
      "[[0.06312326 0.1546746  0.06347267 0.         0.         0.00837591\n",
      "  0.         0.09961441 0.01939551 0.01051587 0.07396626 0.\n",
      "  0.21809301 0.167946   0.         0.00707691 0.         0.02921082\n",
      "  0.         0.0720824  0.06341434 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07263976 0.14906523 0.14363809 0.         0.         0.\n",
      "  0.         0.         0.22145274 0.         0.         0.\n",
      "  0.         0.         0.19088382 0.1886006  0.         0.01724417\n",
      "  0.0673049  0.03054739 0.         0.1439368  0.01544667 0.3520411\n",
      "  0.         0.         0.11479881 0.         0.         0.\n",
      "  0.01587711 0.09549733 0.         0.        ]]\n",
      "Hi!\n",
      "[[8.83392394e-02 7.79514685e-02 3.24256569e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.08872128e-01 1.03055692e+00 1.15677285e+00\n",
      "  6.08847380e-01 0.00000000e+00 3.07924479e-01 0.00000000e+00\n",
      "  3.76292378e-01 1.77427866e-02 0.00000000e+00 5.54887950e-01\n",
      "  0.00000000e+00 6.60164535e-01 0.00000000e+00 0.00000000e+00\n",
      "  4.98888403e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.17362340e-02 0.00000000e+00 0.00000000e+00 1.64250374e-01\n",
      "  0.00000000e+00 0.00000000e+00 7.66957462e-01 2.05077305e-01\n",
      "  0.00000000e+00 0.00000000e+00 4.97988135e-01 0.00000000e+00\n",
      "  0.00000000e+00 9.64016318e-01 0.00000000e+00 4.62336302e-01\n",
      "  1.12416688e-03 0.00000000e+00 0.00000000e+00 6.30966842e-01\n",
      "  3.94987285e-01 7.20566869e-01 0.00000000e+00 6.39999434e-02\n",
      "  0.00000000e+00 8.81683230e-01 4.83823150e-01 3.35421145e-01\n",
      "  5.74818671e-01 1.18842244e-01 0.00000000e+00 0.00000000e+00\n",
      "  5.51304780e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.62552464e-01 6.34658754e-01 1.26888156e-01]]\n",
      "Hi!\n",
      "[[7.51777947e-01 8.18958104e-01 0.00000000e+00 3.40953946e-01\n",
      "  0.00000000e+00 4.16443527e-01 5.64741910e-01 1.21489179e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.55437961e-01 0.00000000e+00\n",
      "  1.33442044e+00 1.17661095e+00 0.00000000e+00 1.00801334e-01\n",
      "  0.00000000e+00 3.08747411e-01 2.56904284e-04 6.51570976e-01\n",
      "  1.41810060e-01 1.51071444e-01 0.00000000e+00 3.36365938e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.91810536e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.56230807e+00 9.75510240e-01\n",
      "  4.29723740e-01 0.00000000e+00 6.07291818e-01 0.00000000e+00\n",
      "  1.86976120e-01 6.15099311e-01 8.08709919e-01 1.19446784e-01\n",
      "  7.30205998e-02 0.00000000e+00 0.00000000e+00 4.47112113e-01\n",
      "  1.56968594e+00 1.29078829e+00 0.00000000e+00 5.15612245e-01\n",
      "  3.86870891e-01 8.52232993e-01 2.76162982e-01 5.56016922e-01\n",
      "  8.81246924e-01 1.36063898e+00 0.00000000e+00 9.59130377e-02\n",
      "  5.85055172e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.13815941e-01 3.91380668e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.3768255  0.987476   1.0942339  0.         0.         0.49837115\n",
      "  0.16560139 0.30378994 1.1693708  0.         0.63083315 0.\n",
      "  1.6503434  0.         0.         0.82388365 0.         0.8318461\n",
      "  0.9361549  0.3516041  0.9974199  0.03722087 0.         0.\n",
      "  0.3212609  0.         0.         0.14914103 0.         0.\n",
      "  0.7326341  0.5618263  0.         0.         0.39590812 0.\n",
      "  0.44336182 0.99851847 0.         0.6992042  0.03282559 0.\n",
      "  0.         0.2815016  0.4260166  0.         0.         1.1489791\n",
      "  0.         0.8916833  1.0011328  0.2730073  0.33456028 0.6470556\n",
      "  0.         0.         0.21084629 0.         0.05460269 0.\n",
      "  0.         0.6994113  1.0576336  0.97776777]]\n",
      "Hi!\n",
      "[[0.53400004 0.3330957  1.781827   0.         0.         0.69796354\n",
      "  0.38455698 0.17713146 1.7927231  0.         0.8370577  0.\n",
      "  0.9985368  0.         0.         1.1904937  0.5563835  1.088826\n",
      "  0.8618006  0.         1.5067879  0.47840878 0.         0.43538597\n",
      "  0.33686185 0.         0.         0.         0.         0.\n",
      "  0.11159673 0.19550297 0.         0.         0.16435584 0.\n",
      "  0.7109735  1.2849249  0.         1.0542661  0.2100551  0.\n",
      "  0.         1.1900238  0.         0.         0.         1.103906\n",
      "  0.         1.0416758  1.1669312  0.04870554 0.12674485 0.08168182\n",
      "  0.         0.         0.02084015 0.9311475  0.04253983 0.\n",
      "  0.         1.1287462  1.4188415  1.4365114 ]]\n",
      "Hi!\n",
      "[[0.         0.11774778 0.20756541 0.         0.         0.16559592\n",
      "  0.         0.05647068 0.0423096  0.12110214 0.16435204 0.\n",
      "  0.         0.01025528 0.         0.01658799 0.         0.05911106\n",
      "  0.         0.21597622 0.11639573 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0386008  0.05372573 0.         0.         0.\n",
      "  0.         0.         0.00884227 0.11683576 0.         0.\n",
      "  0.         0.         0.06843358 0.23813705 0.         0.08270356\n",
      "  0.15363058 0.08539241 0.         0.14917648 0.04509516 0.2124298\n",
      "  0.         0.1095992  0.         0.         0.04405534 0.\n",
      "  0.09835259 0.07211796 0.         0.00024281]]\n",
      "Hi!\n",
      "[[0.13410994 1.2424624  1.1880077  0.         0.         0.55671763\n",
      "  0.         0.00426317 0.7076726  0.         0.6667604  0.\n",
      "  1.3340886  0.         0.         0.43826023 0.         0.64449626\n",
      "  0.19272742 0.76853865 0.8448891  0.         0.         0.06894245\n",
      "  0.         0.         0.         0.12762626 0.         0.\n",
      "  0.3647949  0.5508279  0.         0.         0.         0.\n",
      "  0.         0.21766387 0.27578646 0.58825254 0.         0.\n",
      "  0.         0.         0.2837309  0.00210024 0.         0.5796842\n",
      "  0.18042116 0.78368855 0.51107514 0.3325658  0.65484643 0.7417104\n",
      "  0.         0.         0.05046357 0.         0.09867149 0.\n",
      "  0.         0.5519049  0.5857046  0.67975044]]\n",
      "Hi!\n",
      "[[0.6417109  0.65793353 1.1975424  0.         0.         0.9067424\n",
      "  0.         0.         0.3369585  0.19054988 0.49517918 0.\n",
      "  0.11615074 0.         0.         0.         0.25713205 0.46779105\n",
      "  0.         0.8547491  0.7434457  0.         0.         0.3084475\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20542213 0.03168433 0.         0.         0.\n",
      "  0.         0.         0.         0.6209495  0.         0.\n",
      "  0.         0.10751491 0.03911927 0.36607784 0.         0.48894858\n",
      "  0.5592134  0.7572994  0.12366872 0.34145927 0.548805   0.4085993\n",
      "  0.         0.77781695 0.         0.         0.21669684 0.\n",
      "  0.47828373 0.5744784  0.21708333 0.47200495]]\n",
      "Hi!\n",
      "[[0.5462922  0.17536218 0.81433254 0.         0.         0.803954\n",
      "  0.48586187 0.42663708 0.38612416 0.18391088 0.34297928 0.\n",
      "  0.         0.         0.         0.2595597  0.19729549 0.4510778\n",
      "  0.         0.40796432 0.6094336  0.         0.         0.31455833\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0702237  0.20424135 0.         0.         0.\n",
      "  0.         0.15306967 0.         0.66638285 0.         0.\n",
      "  0.         0.54802895 0.         0.5155459  0.         0.\n",
      "  0.25370672 1.0237925  0.05263808 0.24238284 0.70310694 0.\n",
      "  0.         0.68904465 0.         0.         0.05068913 0.\n",
      "  0.41207075 0.7998435  0.1662644  0.        ]]\n",
      "Hi!\n",
      "[[0.10924532 0.34313574 0.4281875  0.         0.         0.38919154\n",
      "  0.04371153 0.07913258 0.1820762  0.02553598 0.2563037  0.\n",
      "  0.18405153 0.         0.         0.12440977 0.         0.35912836\n",
      "  0.         0.4347056  0.2939061  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25538555 0.02355884 0.         0.         0.\n",
      "  0.         0.18633953 0.         0.36258072 0.         0.\n",
      "  0.         0.03104943 0.05780243 0.28308904 0.         0.2504252\n",
      "  0.18052623 0.4618382  0.15612967 0.17314021 0.00972998 0.39453754\n",
      "  0.         0.20398578 0.         0.         0.00117917 0.\n",
      "  0.16755635 0.3653681  0.03769468 0.12565921]]\n",
      "Hi!\n",
      "[[0.58360416 0.         0.85118777 0.         0.         0.7452466\n",
      "  0.55629605 0.58224    0.46436974 0.07047583 0.3585396  0.\n",
      "  0.         0.         0.         0.26537552 0.3756133  0.6478182\n",
      "  0.         0.2244682  0.62719095 0.14219648 0.         0.11345481\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11833723 0.         0.         0.\n",
      "  0.         0.4771661  0.         0.6195571  0.         0.\n",
      "  0.         0.81810164 0.         0.44326767 0.         0.02762425\n",
      "  0.00883598 0.8141746  0.25986803 0.14041522 0.09954283 0.06933908\n",
      "  0.         0.54133123 0.         0.0791008  0.         0.\n",
      "  0.18472649 0.7981374  0.20518772 0.18657297]]\n",
      "Hi!\n",
      "[[0.38087064 0.14957403 0.6505164  0.12446059 0.         0.69699633\n",
      "  0.7156295  1.1262966  0.5554219  0.         0.37138137 0.\n",
      "  0.6197359  0.         0.         0.38383207 0.         0.5268702\n",
      "  0.         0.11283326 0.66621786 0.         0.         0.00823484\n",
      "  0.         0.         0.         0.41911265 0.         0.\n",
      "  0.87903833 0.5699054  0.0139243  0.         0.4024957  0.\n",
      "  0.         0.90054315 0.         0.3148947  0.05903886 0.\n",
      "  0.         0.42005137 0.5798812  0.7539337  0.         0.21776846\n",
      "  0.         0.825104   0.36338866 0.49333546 0.78428555 0.33863133\n",
      "  0.         0.09247646 0.11270428 0.         0.         0.\n",
      "  0.         0.57995933 1.1224293  0.        ]]\n",
      "Hi!\n",
      "[[0.07866563 0.31801224 0.27302822 0.         0.         0.10042077\n",
      "  0.         0.0045655  0.04711059 0.         0.18098985 0.\n",
      "  0.36704302 0.19704574 0.         0.04095721 0.         0.00301814\n",
      "  0.         0.19149227 0.15034166 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10103106 0.2226771  0.09225336 0.         0.         0.\n",
      "  0.         0.         0.31769687 0.08265066 0.         0.\n",
      "  0.         0.         0.21165451 0.12829036 0.         0.1270883\n",
      "  0.21466501 0.08337376 0.007936   0.26504445 0.11995054 0.5306977\n",
      "  0.         0.         0.10031256 0.         0.01562165 0.\n",
      "  0.0928739  0.04521269 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06455563 0.2584625  0.43840894 0.         0.         0.41129792\n",
      "  0.         0.02175128 0.07228836 0.12314826 0.27469233 0.\n",
      "  0.         0.00959048 0.         0.         0.         0.07770211\n",
      "  0.         0.46601292 0.21542946 0.         0.         0.00506656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10141987 0.03542563 0.         0.         0.\n",
      "  0.         0.         0.03638025 0.22423021 0.         0.\n",
      "  0.         0.         0.10618084 0.3633884  0.         0.26133755\n",
      "  0.34963945 0.24690944 0.         0.30575573 0.22163025 0.38998345\n",
      "  0.         0.333717   0.         0.         0.10293554 0.\n",
      "  0.12776771 0.08486235 0.         0.06364176]]\n",
      "Hi!\n",
      "[[0.3166395  0.29656258 0.24199393 0.         0.         0.39916402\n",
      "  0.1575483  0.3268148  0.         0.00827973 0.23359562 0.\n",
      "  0.1286152  0.2510878  0.         0.         0.         0.02805751\n",
      "  0.         0.4906347  0.21409716 0.         0.         0.05708579\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19801913 0.3098106  0.08948453 0.         0.         0.\n",
      "  0.         0.00165816 0.32928157 0.13746662 0.         0.\n",
      "  0.         0.         0.4116978  0.6642574  0.         0.17387716\n",
      "  0.31085014 0.45018563 0.         0.47570768 0.47411317 0.70987815\n",
      "  0.         0.4023192  0.0679515  0.         0.         0.\n",
      "  0.04745254 0.12584707 0.08718932 0.        ]]\n",
      "Hi!\n",
      "[[0.00567336 0.13326491 0.07527961 0.00394583 0.         0.0812818\n",
      "  0.02331782 0.19434652 0.         0.08914479 0.06436145 0.\n",
      "  0.06165802 0.21378827 0.         0.04693852 0.         0.0690804\n",
      "  0.         0.11528939 0.00659412 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07900754 0.17952766 0.10999147 0.         0.         0.\n",
      "  0.         0.         0.16526541 0.06852309 0.         0.\n",
      "  0.         0.         0.26767886 0.2422521  0.         0.01956145\n",
      "  0.14462478 0.1057349  0.         0.10829026 0.11343367 0.2821992\n",
      "  0.         0.06091012 0.04487249 0.         0.         0.\n",
      "  0.05725753 0.08490341 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06416772 0.2758604  0.17086928 0.         0.         0.13577011\n",
      "  0.         0.         0.04364014 0.         0.1648226  0.\n",
      "  0.32313114 0.14571002 0.         0.02777594 0.         0.00752773\n",
      "  0.         0.20551136 0.11504063 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08805094 0.1855588  0.10749358 0.         0.         0.\n",
      "  0.         0.         0.18588139 0.05047606 0.         0.\n",
      "  0.         0.         0.1586301  0.13523544 0.         0.14945564\n",
      "  0.16388893 0.07813454 0.00186585 0.19647451 0.02066331 0.45592704\n",
      "  0.         0.         0.13014704 0.         0.0382279  0.\n",
      "  0.1595189  0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.25172457 0.54090875 1.5390016  0.         0.         0.5899515\n",
      "  0.4479539  0.41245463 1.900678   0.         0.77696663 0.\n",
      "  1.4809582  0.         0.         1.3082576  0.26599738 1.0566489\n",
      "  1.4101933  0.         1.431191   0.47975194 0.         0.1598591\n",
      "  0.4669816  0.         0.         0.2813649  0.         0.\n",
      "  0.5478596  0.30807698 0.         0.         0.4229408  0.\n",
      "  0.9634648  1.4151464  0.         0.9521255  0.3117105  0.\n",
      "  0.         1.0642992  0.01434052 0.         0.         1.2350135\n",
      "  0.         1.035124   1.4087789  0.13384281 0.11623343 0.26846176\n",
      "  0.         0.         0.20825648 0.75061095 0.         0.\n",
      "  0.         0.96502334 1.6219893  1.3807377 ]]\n",
      "Hi!\n",
      "[[0.18879227 0.46915263 0.63301617 0.         0.         0.5645135\n",
      "  0.         0.         0.03740316 0.06643417 0.33111233 0.\n",
      "  0.14477007 0.0430475  0.         0.         0.         0.1460485\n",
      "  0.         0.69984573 0.29741988 0.         0.         0.01254989\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01200934 0.32291982 0.         0.         0.         0.\n",
      "  0.         0.         0.09331889 0.3087143  0.         0.\n",
      "  0.         0.         0.2735923  0.47238514 0.         0.3762834\n",
      "  0.50404286 0.42118597 0.         0.4360104  0.32440782 0.6274456\n",
      "  0.         0.5791478  0.         0.         0.10254879 0.\n",
      "  0.2038675  0.09190721 0.08669994 0.04011119]]\n",
      "Hi!\n",
      "[[0.60656726 0.9516752  0.4265387  0.         0.         0.38552386\n",
      "  0.40628937 0.99155784 1.1070594  0.         0.44927546 0.\n",
      "  2.3894439  0.78350556 0.         0.9844339  0.         0.72448415\n",
      "  1.5470885  0.16179536 0.7070994  0.26187205 0.         0.08594348\n",
      "  0.57170993 0.         0.         0.8225064  0.         0.\n",
      "  1.3619517  0.9521597  0.         0.         0.8033861  0.\n",
      "  0.969335   1.3319427  0.2688376  0.3419729  0.13561364 0.\n",
      "  0.         0.5611395  1.1869321  0.46793476 0.         1.3821645\n",
      "  0.         0.9038469  1.2939454  0.40711215 0.410101   1.2279762\n",
      "  0.         0.         0.66313696 0.         0.         0.\n",
      "  0.         0.3891811  1.2541707  0.62025106]]\n",
      "Hi!\n",
      "[[0.34968072 0.7550734  0.82757634 0.         0.         0.42467004\n",
      "  0.42861307 0.73114485 1.6015732  0.         0.62199175 0.\n",
      "  2.0008614  0.07176086 0.         1.2397864  0.         0.8721206\n",
      "  1.5917115  0.         1.0762548  0.14152193 0.         0.\n",
      "  0.593914   0.         0.         0.56113094 0.         0.\n",
      "  0.98089784 0.5541336  0.         0.         0.63295346 0.\n",
      "  0.97352594 1.4100766  0.         0.6346657  0.18231834 0.\n",
      "  0.         0.58692914 0.5517859  0.         0.         1.3488039\n",
      "  0.         1.0343387  1.3754218  0.21280561 0.18554224 0.62840235\n",
      "  0.         0.         0.4565082  0.13752012 0.         0.\n",
      "  0.         0.7143164  1.4065278  0.97549677]]\n",
      "Hi!\n",
      "[[0.25933105 0.         0.65386105 0.         0.         0.52449304\n",
      "  1.313104   1.3586744  1.1408762  0.         0.44609207 0.\n",
      "  0.35512936 0.         0.         0.8486179  0.         0.819809\n",
      "  0.11327515 0.         0.85543543 0.15048091 0.         0.1365341\n",
      "  0.13207157 0.         0.         0.26794064 0.         0.\n",
      "  0.69501305 0.11085045 0.         0.         0.5844255  0.\n",
      "  0.19754618 1.3720425  0.         0.5163632  0.18169668 0.\n",
      "  0.         1.2289305  0.15850405 0.5237452  0.         0.25820482\n",
      "  0.         0.7624599  0.75044245 0.28230414 0.4370577  0.\n",
      "  0.         0.         0.10114497 0.16401598 0.         0.\n",
      "  0.         1.0658594  1.253599   0.3377421 ]]\n",
      "Hi!\n",
      "[[0.6232499  0.30650443 1.5518436  0.         0.         0.77162707\n",
      "  0.28630733 0.2993984  1.3516089  0.         0.72610766 0.\n",
      "  0.6181575  0.         0.         0.7629638  0.48412815 0.9129541\n",
      "  0.23856041 0.         1.3012322  0.28788903 0.         0.52740085\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04680517 0.20491247 0.         0.         0.         0.\n",
      "  0.126065   0.9004306  0.         0.8839223  0.10172775 0.\n",
      "  0.         0.93749064 0.         0.         0.         0.6940367\n",
      "  0.         0.8847547  0.7828873  0.14907713 0.35224536 0.11158397\n",
      "  0.         0.13758586 0.         0.61503553 0.00248808 0.\n",
      "  0.         0.93957496 1.074735   0.9962054 ]]\n",
      "Hi!\n",
      "[[0.16991904 0.33144325 0.6720874  0.         0.         0.43095052\n",
      "  0.         0.         0.2649465  0.12156769 0.29394153 0.\n",
      "  0.         0.         0.         0.06482805 0.11065111 0.15736136\n",
      "  0.         0.51912993 0.3176072  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09957055 0.09130859 0.         0.         0.\n",
      "  0.         0.         0.         0.34078842 0.         0.\n",
      "  0.         0.         0.         0.2610674  0.         0.308623\n",
      "  0.32967284 0.3802532  0.         0.28430206 0.13960457 0.2568803\n",
      "  0.         0.4484166  0.         0.         0.1503458  0.\n",
      "  0.25724667 0.19622952 0.09413084 0.21131214]]\n",
      "Hi!\n",
      "[[0.5245774  0.03768105 0.89846694 0.06283335 0.         0.84587973\n",
      "  0.7677133  1.0310739  0.7331365  0.         0.41521952 0.\n",
      "  0.13362297 0.         0.         0.29823363 0.02792785 0.6735943\n",
      "  0.         0.         0.808025   0.         0.         0.40743202\n",
      "  0.         0.         0.         0.03290443 0.         0.\n",
      "  0.47955698 0.3270235  0.11878007 0.         0.16028178 0.\n",
      "  0.         0.7130515  0.         0.6855593  0.         0.\n",
      "  0.         0.8009184  0.02465529 0.73110276 0.         0.\n",
      "  0.         1.115387   0.36089417 0.40790397 0.9222287  0.09207793\n",
      "  0.         0.49620914 0.         0.         0.         0.\n",
      "  0.         0.8574545  0.8618126  0.1332383 ]]\n",
      "Hi!\n",
      "[[0.18313771 0.14415956 0.44341746 0.         0.         0.38076857\n",
      "  0.46103072 0.41044718 0.28609693 0.1593524  0.26427132 0.\n",
      "  0.         0.         0.         0.13737983 0.03823635 0.4257308\n",
      "  0.         0.22848617 0.3850988  0.02517914 0.         0.07321335\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05480083 0.         0.         0.\n",
      "  0.         0.1144423  0.         0.5054331  0.         0.\n",
      "  0.         0.4458762  0.         0.42976043 0.         0.\n",
      "  0.16839784 0.69134015 0.10884648 0.056387   0.15039739 0.\n",
      "  0.         0.16313249 0.         0.         0.         0.\n",
      "  0.19045028 0.7076797  0.         0.11425804]]\n",
      "Hi!\n",
      "[[0.67669207 1.1951355  0.31418976 0.         0.         0.33690915\n",
      "  0.15208988 1.029196   0.5958384  0.         0.3950118  0.\n",
      "  2.4767923  1.0549556  0.         0.6590492  0.         0.55368054\n",
      "  1.1297954  0.42865813 0.46122488 0.30294114 0.         0.2216685\n",
      "  0.23690954 0.         0.         0.92532784 0.         0.\n",
      "  1.5884737  1.134776   0.         0.         0.7350411  0.\n",
      "  0.6490591  1.030657   0.7377166  0.18567684 0.09713098 0.\n",
      "  0.         0.61489403 1.4583749  0.79472077 0.         1.094676\n",
      "  0.         0.8084143  1.0343927  0.45695546 0.7674665  1.5455252\n",
      "  0.         0.         0.63882744 0.         0.         0.\n",
      "  0.         0.22377062 1.1174543  0.27875993]]\n",
      "Hi!\n",
      "[[0.46560326 0.3894408  0.35661104 0.00440312 0.         0.50711656\n",
      "  0.78672457 1.275154   0.7958167  0.         0.37109166 0.\n",
      "  1.54868    0.5120401  0.         0.68999296 0.         0.6302754\n",
      "  0.7661368  0.         0.60539365 0.12761691 0.         0.\n",
      "  0.29399353 0.         0.         0.6959562  0.         0.\n",
      "  1.3048464  0.71430314 0.         0.         0.73953986 0.\n",
      "  0.4147138  1.2593331  0.         0.21180615 0.11045709 0.\n",
      "  0.         0.35255298 1.007445   0.7572831  0.         0.6895403\n",
      "  0.         0.7177887  0.8992866  0.5154323  0.6720075  0.7623752\n",
      "  0.         0.         0.4511064  0.         0.         0.\n",
      "  0.         0.48686895 1.2942697  0.23896492]]\n",
      "Hi!\n",
      "[[0.4680081  0.59971553 1.9194108  0.         0.         0.7970461\n",
      "  0.1771154  0.         1.6520451  0.         0.8429851  0.\n",
      "  1.2044016  0.         0.         1.1407456  0.523478   1.0624651\n",
      "  0.95358    0.09876427 1.570901   0.5135822  0.         0.2908596\n",
      "  0.3986198  0.         0.         0.         0.         0.\n",
      "  0.12544522 0.27366614 0.         0.         0.19022511 0.\n",
      "  0.62908113 1.2418087  0.         1.1310928  0.10168097 0.\n",
      "  0.         0.93174744 0.         0.         0.         1.3140152\n",
      "  0.         1.1188295  1.1581522  0.13023219 0.17434217 0.41042113\n",
      "  0.         0.         0.02764957 0.8564458  0.13760279 0.\n",
      "  0.         1.0194876  1.3709707  1.4579732 ]]\n",
      "Hi!\n",
      "[[5.8521628e-01 4.2165267e-01 1.3697456e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.2631296e-01 1.8090400e-01 1.9422136e-01 8.4984028e-01 2.9128377e-04\n",
      "  6.3443375e-01 0.0000000e+00 4.0850711e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.3738458e-01 2.8624287e-01 7.7381641e-01 0.0000000e+00 3.4789875e-01\n",
      "  1.0424215e+00 6.0710516e-02 0.0000000e+00 3.7301254e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7921271e-02 2.8752536e-01 7.1673928e-04 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.9869385e-01 0.0000000e+00 7.9065335e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.4816872e-01 0.0000000e+00\n",
      "  1.7526844e-01 0.0000000e+00 5.2128351e-01 1.1003576e-01 8.8046581e-01\n",
      "  4.9770367e-01 2.5292632e-01 4.7208756e-01 2.9894206e-01 0.0000000e+00\n",
      "  3.5147592e-01 0.0000000e+00 1.8653792e-01 8.5944258e-02 0.0000000e+00\n",
      "  0.0000000e+00 7.5307018e-01 6.8285078e-01 6.6264755e-01]]\n",
      "Hi!\n",
      "[[0.5132342  0.37598664 0.9478941  0.         0.         0.8531517\n",
      "  0.28393352 0.4261938  0.3494557  0.15142454 0.41333872 0.\n",
      "  0.         0.         0.         0.04078237 0.04125849 0.5350358\n",
      "  0.         0.52939266 0.7115884  0.         0.         0.29455543\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08854683 0.26097187 0.11486882 0.         0.         0.\n",
      "  0.         0.21828648 0.         0.5745239  0.         0.\n",
      "  0.         0.24719958 0.1173562  0.61085874 0.         0.13573179\n",
      "  0.31376964 0.9499413  0.06593075 0.38317245 0.7269232  0.21975173\n",
      "  0.         0.71105117 0.         0.         0.05537388 0.\n",
      "  0.22307421 0.6765032  0.29574132 0.17148937]]\n",
      "Hi!\n",
      "[[0.04478925 0.19042613 0.22443093 0.         0.         0.21047732\n",
      "  0.         0.10212463 0.         0.03696661 0.12501167 0.\n",
      "  0.01900707 0.15551107 0.         0.02768924 0.         0.03140389\n",
      "  0.         0.31293124 0.08535005 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03207579 0.22688916 0.12738939 0.         0.         0.\n",
      "  0.         0.         0.12259919 0.1284545  0.         0.\n",
      "  0.         0.         0.20925148 0.37063134 0.         0.08980595\n",
      "  0.2557899  0.17299274 0.         0.23171051 0.04739325 0.45052168\n",
      "  0.         0.26347145 0.01553653 0.         0.         0.\n",
      "  0.09013087 0.03298306 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.05476416 0.12824361 0.23182514 0.         0.         0.30826998\n",
      "  0.05954546 0.24606527 0.         0.13727881 0.21166018 0.\n",
      "  0.02070836 0.07543363 0.         0.         0.         0.\n",
      "  0.         0.2652689  0.08248026 0.         0.         0.02378563\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02116391 0.14087185 0.         0.         0.\n",
      "  0.         0.         0.11540072 0.25772002 0.         0.\n",
      "  0.         0.         0.22772546 0.48353076 0.         0.05827071\n",
      "  0.2233267  0.15175088 0.         0.2118257  0.24987595 0.2960479\n",
      "  0.         0.38932398 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.02453829 0.11350555 0.16373724 0.         0.         0.02473287\n",
      "  0.03506865 0.10867535 0.09994712 0.01217446 0.06170919 0.\n",
      "  0.13570893 0.04206262 0.         0.10122453 0.         0.04280334\n",
      "  0.         0.07455692 0.13960628 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01465376 0.1328687  0.09139804 0.         0.         0.\n",
      "  0.         0.         0.14688852 0.00487445 0.         0.\n",
      "  0.         0.         0.17099419 0.1775862  0.         0.08919076\n",
      "  0.03124671 0.07426583 0.         0.12310418 0.         0.28508663\n",
      "  0.         0.01831683 0.10166204 0.         0.         0.\n",
      "  0.0801     0.16357301 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.12577438 0.319231   0.33351362 0.         0.         0.39517474\n",
      "  0.         0.10333133 0.         0.09470588 0.22279695 0.\n",
      "  0.07593012 0.168682   0.         0.         0.         0.11410559\n",
      "  0.         0.4484574  0.15312673 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05285417 0.22753523 0.05411884 0.         0.         0.\n",
      "  0.         0.         0.1523877  0.17337854 0.         0.\n",
      "  0.         0.         0.28496274 0.4294512  0.         0.18804227\n",
      "  0.37633896 0.28446776 0.         0.31426492 0.24242833 0.49914318\n",
      "  0.         0.32291922 0.         0.         0.04017477 0.\n",
      "  0.10558239 0.07448994 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0457201  0.17085014 0.08479974 0.05655077 0.         0.10262999\n",
      "  0.00897732 0.31758013 0.         0.03402162 0.08102696 0.\n",
      "  0.         0.27434134 0.         0.         0.         0.08940794\n",
      "  0.         0.22918308 0.00671472 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12929998 0.27563104 0.24971642 0.         0.         0.\n",
      "  0.         0.         0.255588   0.12043483 0.         0.\n",
      "  0.         0.         0.3738441  0.4142376  0.         0.\n",
      "  0.24256577 0.29372174 0.         0.2606891  0.17367096 0.41064754\n",
      "  0.         0.26047105 0.03747703 0.         0.         0.\n",
      "  0.06260867 0.12263294 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06791572 0.12085494 0.         0.         0.         0.\n",
      "  0.06082783 0.28927326 0.05256018 0.05596963 0.08861417 0.\n",
      "  0.         0.1596806  0.         0.11378085 0.         0.09830666\n",
      "  0.         0.14220539 0.05298587 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00780454 0.01132635 0.19175711 0.         0.         0.\n",
      "  0.         0.         0.10392878 0.04896491 0.         0.\n",
      "  0.         0.         0.24607067 0.3073451  0.         0.02344954\n",
      "  0.09287167 0.10249711 0.         0.167255   0.         0.3103589\n",
      "  0.         0.11389063 0.04832399 0.         0.         0.\n",
      "  0.05604341 0.17235628 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07620593 0.29098707 0.54218644 0.         0.         0.38173366\n",
      "  0.         0.         0.17737466 0.06623691 0.30930242 0.\n",
      "  0.11982793 0.         0.         0.12753701 0.         0.\n",
      "  0.         0.4794089  0.284678   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15804814 0.0617719  0.         0.         0.\n",
      "  0.         0.         0.07047325 0.29285517 0.         0.\n",
      "  0.         0.         0.02449354 0.20973839 0.         0.30954614\n",
      "  0.29794264 0.11998845 0.06427377 0.33873928 0.1380068  0.41757268\n",
      "  0.         0.22934772 0.         0.         0.14226535 0.\n",
      "  0.09019651 0.00555424 0.03610732 0.13029493]]\n",
      "Hi!\n",
      "[[0.03881301 0.08023824 0.32032743 0.         0.         0.26620597\n",
      "  0.00413965 0.21798688 0.06087817 0.04209907 0.13359298 0.\n",
      "  0.         0.02584947 0.         0.04695142 0.         0.\n",
      "  0.         0.27216974 0.1389387  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22600158 0.13204452 0.         0.         0.\n",
      "  0.         0.         0.18174556 0.20007947 0.         0.\n",
      "  0.         0.00524068 0.19189635 0.40104535 0.         0.19658409\n",
      "  0.22524618 0.07832773 0.         0.28472072 0.04472742 0.5252228\n",
      "  0.         0.3486534  0.03109909 0.         0.         0.\n",
      "  0.03042482 0.05253918 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.47984388 0.46505502 1.3555219  0.         0.         0.81436324\n",
      "  0.14097868 0.14473152 0.94264466 0.         0.5855864  0.\n",
      "  0.77970684 0.         0.         0.5082877  0.28184098 0.75876963\n",
      "  0.25970244 0.26980937 1.0897216  0.09514138 0.         0.2581263\n",
      "  0.05960356 0.         0.         0.         0.         0.\n",
      "  0.1403692  0.39472425 0.         0.         0.03889917 0.\n",
      "  0.20493463 0.7902507  0.         0.80376405 0.         0.\n",
      "  0.         0.5052307  0.04831536 0.0402193  0.         0.89080036\n",
      "  0.04918052 0.7317884  0.60307586 0.2564435  0.27193877 0.4411701\n",
      "  0.         0.24141386 0.         0.29783213 0.06775515 0.\n",
      "  0.         0.68996924 0.988143   0.79061836]]\n",
      "Hi!\n",
      "[[0.79545325 0.20007004 1.2127947  0.         0.         0.94017017\n",
      "  0.15380254 0.2734383  0.42053336 0.14673118 0.43190652 0.\n",
      "  0.         0.         0.         0.13658738 0.47788346 0.5700609\n",
      "  0.         0.48195165 0.80956036 0.         0.         0.36168125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16190207 0.10287408 0.         0.         0.\n",
      "  0.         0.2287412  0.         0.7350999  0.         0.\n",
      "  0.         0.62140834 0.         0.41789734 0.         0.27376467\n",
      "  0.3584024  0.892419   0.17294908 0.2221268  0.45873097 0.20890649\n",
      "  0.         1.0414922  0.         0.01788471 0.044045   0.\n",
      "  0.4758376  0.67420524 0.22769462 0.2870213 ]]\n",
      "Hi!\n",
      "[[8.70260775e-01 3.00841779e-02 1.67727280e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.56845379e-01 4.14064169e-01 4.61962461e-01\n",
      "  1.58398712e+00 0.00000000e+00 7.45671570e-01 0.00000000e+00\n",
      "  1.21328086e-01 0.00000000e+00 0.00000000e+00 9.40466046e-01\n",
      "  8.25610518e-01 9.90827620e-01 1.35149136e-01 0.00000000e+00\n",
      "  1.42277431e+00 5.70657134e-01 0.00000000e+00 6.01719916e-01\n",
      "  7.01783448e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.43268654e-02\n",
      "  2.14864267e-05 0.00000000e+00 8.86845496e-03 0.00000000e+00\n",
      "  3.23909163e-01 1.07262504e+00 0.00000000e+00 1.05072999e+00\n",
      "  1.99214682e-01 0.00000000e+00 0.00000000e+00 1.54456556e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.37991333e-01\n",
      "  0.00000000e+00 9.30293381e-01 8.93463135e-01 0.00000000e+00\n",
      "  1.63401440e-01 6.95855217e-03 0.00000000e+00 1.36187553e-01\n",
      "  0.00000000e+00 9.36167896e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.14565420e+00 1.06838965e+00 1.05780268e+00]]\n",
      "Hi!\n",
      "[[0.64421743 0.5681829  0.8096759  0.03125897 0.         0.7847981\n",
      "  0.29713207 0.691426   0.40385953 0.         0.4571486  0.\n",
      "  1.1493078  0.21212739 0.         0.37655383 0.         0.55821455\n",
      "  0.39952615 0.5168864  0.67194235 0.         0.         0.10215914\n",
      "  0.04021972 0.         0.         0.49683946 0.         0.\n",
      "  0.94678926 0.8539797  0.         0.         0.4280154  0.\n",
      "  0.4428947  0.88066906 0.2662334  0.38679093 0.         0.\n",
      "  0.         0.2646452  1.0692079  0.64557    0.         0.85424274\n",
      "  0.02938255 0.63562495 0.45978245 0.50389814 0.46238375 1.0023922\n",
      "  0.         0.11322366 0.40578645 0.         0.         0.\n",
      "  0.         0.34949434 1.1756881  0.17368692]]\n",
      "Hi!\n",
      "[[0.4822398  0.         0.9288396  0.         0.         0.71729183\n",
      "  1.1038004  1.1852084  1.1799673  0.         0.49115443 0.\n",
      "  0.20242749 0.         0.         0.73204255 0.14673282 0.7931179\n",
      "  0.         0.         0.9658727  0.19027138 0.         0.372106\n",
      "  0.02693684 0.         0.         0.01171071 0.         0.\n",
      "  0.37170997 0.11907972 0.04881431 0.         0.38503554 0.\n",
      "  0.06305439 1.1656022  0.         0.65712565 0.11787899 0.\n",
      "  0.         1.2658356  0.         0.45619646 0.         0.32481062\n",
      "  0.         0.8078322  0.6797537  0.3024776  0.513253   0.\n",
      "  0.         0.00244274 0.         0.25386024 0.         0.\n",
      "  0.         1.0912462  1.1869859  0.423134  ]]\n",
      "Hi!\n",
      "[[0.         0.10029425 0.04802028 0.         0.         0.10203975\n",
      "  0.09684408 0.31301722 0.         0.125858   0.09584886 0.\n",
      "  0.         0.0806739  0.         0.0164499  0.         0.05746258\n",
      "  0.         0.13265166 0.0498236  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05397437 0.21215634 0.         0.         0.\n",
      "  0.         0.04875169 0.14363147 0.13417318 0.         0.\n",
      "  0.         0.         0.1718111  0.42065477 0.         0.01428169\n",
      "  0.14658527 0.20746386 0.         0.2067677  0.1225588  0.24461673\n",
      "  0.         0.18649311 0.         0.         0.         0.\n",
      "  0.06181366 0.25398535 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06043076 0.30883893 0.20362    0.         0.         0.23070668\n",
      "  0.         0.06149992 0.         0.05473498 0.15970924 0.\n",
      "  0.19774163 0.19122694 0.         0.         0.         0.08722522\n",
      "  0.         0.3132844  0.11967907 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07219092 0.21041235 0.08302091 0.         0.         0.\n",
      "  0.         0.         0.17317405 0.09620347 0.         0.\n",
      "  0.         0.         0.2508647  0.29851392 0.         0.17273688\n",
      "  0.25482404 0.16216989 0.         0.21879266 0.1260926  0.4353471\n",
      "  0.         0.13214056 0.08928272 0.         0.03710864 0.\n",
      "  0.08947234 0.05296096 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.15267886 0.43550816 0.69642335 0.         0.         0.4365263\n",
      "  0.379037   0.5755493  0.7620606  0.         0.4748752  0.\n",
      "  0.75938797 0.         0.         0.53666776 0.         0.6580671\n",
      "  0.09474929 0.17930049 0.7264816  0.         0.         0.\n",
      "  0.05862067 0.         0.         0.03188144 0.         0.\n",
      "  0.5112369  0.35261908 0.         0.         0.30318734 0.\n",
      "  0.05481083 0.8049653  0.         0.4714641  0.         0.\n",
      "  0.         0.40004373 0.28923708 0.3541047  0.         0.44764578\n",
      "  0.         0.70724744 0.6026303  0.27723    0.4114596  0.31972554\n",
      "  0.         0.         0.01574075 0.         0.         0.\n",
      "  0.         0.70360595 0.6548161  0.46234724]]\n",
      "Hi!\n",
      "[[0.7622507  1.2500998  0.11761392 0.05834653 0.         0.26988733\n",
      "  0.2834787  1.2862206  0.46065733 0.         0.28803164 0.\n",
      "  2.5374582  1.166724   0.         0.5314219  0.         0.43072113\n",
      "  1.0396537  0.4707662  0.3122259  0.51211494 0.         0.2566205\n",
      "  0.15892574 0.         0.         1.1754576  0.         0.\n",
      "  1.8648952  1.2411414  0.02880689 0.         0.95757246 0.\n",
      "  0.5847271  0.8905541  1.0558268  0.07668651 0.14120066 0.\n",
      "  0.         0.81187266 1.6474276  1.0053998  0.         1.0228273\n",
      "  0.         0.8639225  0.95140386 0.4251157  0.9534644  1.7879015\n",
      "  0.         0.         0.8171233  0.         0.         0.\n",
      "  0.         0.24917118 1.056239   0.        ]]\n",
      "Hi!\n",
      "[[0.8941044  0.94300056 0.28097785 0.25276756 0.         0.5289037\n",
      "  0.2997546  0.84607387 0.         0.         0.27573648 0.\n",
      "  1.6510694  1.0767441  0.         0.30535483 0.         0.47553915\n",
      "  0.35824412 0.765943   0.30128703 0.09624843 0.         0.3381201\n",
      "  0.         0.         0.         0.8812201  0.         0.\n",
      "  1.4366674  1.1517465  0.1774883  0.         0.60908383 0.\n",
      "  0.47658268 0.6952274  0.8422801  0.22144833 0.02042891 0.\n",
      "  0.         0.44537857 1.6134374  0.96509725 0.         0.8240417\n",
      "  0.27377284 0.74335915 0.40922362 0.5831613  0.6714647  1.4362433\n",
      "  0.         0.05297344 0.54593116 0.         0.         0.\n",
      "  0.         0.14161445 0.7640798  0.        ]]\n",
      "Hi!\n",
      "[[0.6124967  0.3790132  0.01395819 0.31805176 0.         0.47597912\n",
      "  0.98923403 1.5231813  0.36512172 0.         0.2578468  0.\n",
      "  1.4579667  0.9481157  0.         0.50328237 0.         0.56830686\n",
      "  0.55149627 0.13470462 0.36588675 0.28401583 0.         0.04134338\n",
      "  0.26041862 0.         0.         0.88036835 0.         0.\n",
      "  1.5135587  0.9130589  0.06205706 0.         0.8823099  0.\n",
      "  0.45775765 1.2228402  0.29343066 0.12807687 0.18561788 0.\n",
      "  0.         0.46400064 1.4327589  1.148302   0.         0.6227331\n",
      "  0.         0.79051065 0.6912024  0.582442   0.7711033  1.1129956\n",
      "  0.         0.         0.58204174 0.         0.         0.\n",
      "  0.         0.3526579  1.0710552  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.1265059  0.14227031 0.         0.         0.13344027\n",
      "  0.01534506 0.12717544 0.07924108 0.06691593 0.14000069 0.\n",
      "  0.12138885 0.08086357 0.         0.05805714 0.         0.02386858\n",
      "  0.         0.18360296 0.16525067 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01669431 0.08987574 0.11638344 0.         0.         0.\n",
      "  0.         0.         0.12790635 0.10229563 0.         0.\n",
      "  0.         0.00787496 0.09475929 0.29021782 0.         0.12855537\n",
      "  0.13395214 0.14506637 0.         0.2169391  0.         0.40898705\n",
      "  0.         0.03379336 0.02210585 0.         0.         0.\n",
      "  0.04752051 0.11001562 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5551654  1.0818065  1.099736   0.         0.         0.7492257\n",
      "  0.         0.03674401 0.3006867  0.         0.5611559  0.\n",
      "  1.2164922  0.02693    0.         0.16590425 0.         0.58242565\n",
      "  0.00382833 0.9202715  0.66377366 0.         0.         0.03801773\n",
      "  0.         0.         0.         0.00343846 0.         0.\n",
      "  0.54283994 0.7026921  0.         0.         0.04188438 0.\n",
      "  0.         0.26636454 0.330792   0.53272045 0.         0.\n",
      "  0.         0.         0.6583077  0.3775109  0.         0.763452\n",
      "  0.43911338 0.6346365  0.28645095 0.48059615 0.5883196  0.98187417\n",
      "  0.         0.2984156  0.08479609 0.         0.10778165 0.\n",
      "  0.         0.33682016 0.61159515 0.3513637 ]]\n",
      "Hi!\n",
      "[[0.0926842  0.18791838 0.24143179 0.         0.         0.154446\n",
      "  0.         0.0030534  0.13576347 0.07956009 0.14158463 0.\n",
      "  0.19363144 0.         0.         0.06631858 0.         0.0025687\n",
      "  0.         0.19103448 0.1523621  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08078051 0.0572844  0.         0.         0.\n",
      "  0.         0.         0.04362174 0.10903157 0.         0.\n",
      "  0.         0.         0.04798411 0.09624886 0.         0.09443092\n",
      "  0.04797239 0.06768801 0.         0.15104686 0.07753846 0.28488004\n",
      "  0.         0.         0.02928843 0.         0.04539545 0.\n",
      "  0.11230062 0.11398208 0.         0.03340133]]\n",
      "Hi!\n",
      "[[0.71825427 0.         0.9346325  0.3177391  0.         1.2790245\n",
      "  1.0455309  1.319317   0.14914319 0.         0.29971284 0.\n",
      "  0.         0.         0.         0.0520158  0.         0.41619003\n",
      "  0.         0.3787069  0.6867     0.         0.         0.07760576\n",
      "  0.         0.         0.         0.08068561 0.         0.\n",
      "  0.5067508  0.71429634 0.08469085 0.         0.201612   0.\n",
      "  0.         0.7315039  0.         0.49497795 0.07835601 0.\n",
      "  0.         0.3776219  0.67138135 1.0162661  0.         0.29779112\n",
      "  0.2909787  0.9593687  0.         0.7604119  0.9251448  0.68487734\n",
      "  0.         1.1758935  0.03278603 0.         0.         0.\n",
      "  0.         0.51569945 1.1281714  0.        ]]\n",
      "Hi!\n",
      "[[0.1711215  0.38210234 0.36722416 0.         0.         0.23462325\n",
      "  0.         0.         0.00752947 0.         0.23114748 0.\n",
      "  0.31855637 0.17947772 0.         0.         0.         0.03533923\n",
      "  0.         0.3970682  0.16347541 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11051193 0.34161922 0.04454789 0.         0.         0.\n",
      "  0.         0.         0.3395217  0.13016975 0.         0.\n",
      "  0.         0.         0.26442695 0.24650909 0.         0.21968417\n",
      "  0.38969994 0.17066403 0.         0.30202383 0.20856379 0.6403658\n",
      "  0.         0.16363338 0.0701099  0.         0.05694902 0.\n",
      "  0.15425715 0.03513143 0.01115483 0.        ]]\n",
      "Hi!\n",
      "[[0.06153001 0.2684392  0.33739457 0.         0.         0.23891993\n",
      "  0.         0.         0.08037832 0.01138741 0.21801671 0.\n",
      "  0.16366994 0.0232246  0.         0.03950951 0.         0.02042635\n",
      "  0.         0.32940832 0.21703896 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0223418  0.15588157 0.02608906 0.         0.         0.\n",
      "  0.         0.         0.17745174 0.17049079 0.         0.\n",
      "  0.         0.         0.1131393  0.17843983 0.         0.19149871\n",
      "  0.2524788  0.07304813 0.         0.24582468 0.11833722 0.37780118\n",
      "  0.         0.14524926 0.00450512 0.         0.07275505 0.\n",
      "  0.08005403 0.00100788 0.         0.0380637 ]]\n",
      "Hi!\n",
      "[[0.5243402  1.1607103  0.64767784 0.         0.         0.42355686\n",
      "  0.00481188 0.4164811  0.59977204 0.         0.4925784  0.\n",
      "  1.7700845  0.55496716 0.         0.6043189  0.         0.67081004\n",
      "  0.6528743  0.6375436  0.6121972  0.         0.         0.21848272\n",
      "  0.10888816 0.         0.         0.39291796 0.         0.\n",
      "  0.9543179  0.7151605  0.         0.         0.35375205 0.\n",
      "  0.39087164 0.7309443  0.32194453 0.45830917 0.         0.\n",
      "  0.         0.1905393  0.8810449  0.43635932 0.         0.8873588\n",
      "  0.         0.75463444 0.7611083  0.3447486  0.5079141  0.94700587\n",
      "  0.         0.         0.3544335  0.         0.05157047 0.\n",
      "  0.         0.43220258 0.71221465 0.48018157]]\n",
      "Hi!\n",
      "[[0.14315413 0.2539899  0.24534678 0.         0.         0.26316783\n",
      "  0.         0.11826825 0.         0.03287436 0.17975244 0.\n",
      "  0.17154256 0.22974674 0.         0.         0.         0.03032671\n",
      "  0.         0.32864368 0.09023383 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14822009 0.27944866 0.11232144 0.         0.         0.\n",
      "  0.         0.         0.21980473 0.0666033  0.         0.\n",
      "  0.         0.         0.29774597 0.37382904 0.         0.1861715\n",
      "  0.34086952 0.21870758 0.         0.2874246  0.11666141 0.5793155\n",
      "  0.         0.22497903 0.07450442 0.         0.         0.\n",
      "  0.12687774 0.05222547 0.         0.        ]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00097249 0.0445013  0.0747465  0.         0.         0.03674937\n",
      "  0.0879203  0.23510885 0.         0.06089726 0.06024806 0.\n",
      "  0.         0.12419481 0.         0.         0.         0.04303163\n",
      "  0.         0.06264411 0.01939153 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05672906 0.20315482 0.         0.         0.\n",
      "  0.         0.         0.1568433  0.07563528 0.         0.\n",
      "  0.         0.         0.19605632 0.345189   0.         0.02468938\n",
      "  0.11643693 0.01549977 0.         0.20221412 0.         0.2565295\n",
      "  0.         0.19647723 0.02665029 0.         0.         0.\n",
      "  0.00866758 0.08123717 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5371532  0.36343157 0.         0.22824995 0.         0.36991754\n",
      "  1.2127452  1.7379974  0.69100296 0.         0.25285935 0.\n",
      "  1.8379228  1.1057055  0.         0.8042117  0.         0.6072421\n",
      "  0.9431644  0.         0.46295255 0.42349628 0.         0.06666815\n",
      "  0.44445133 0.         0.         1.0549159  0.         0.\n",
      "  1.7053307  0.8553584  0.         0.         1.0414194  0.\n",
      "  0.62489545 1.4477606  0.19677334 0.02866939 0.18404093 0.\n",
      "  0.         0.57509905 1.4821267  1.040568   0.         0.76892716\n",
      "  0.         0.75477153 1.0380359  0.47755983 0.76475996 1.0668833\n",
      "  0.         0.         0.6278544  0.         0.         0.\n",
      "  0.         0.4596235  1.2823905  0.        ]]\n",
      "Hi!\n",
      "[[0.9026439  0.8125778  2.076681   0.         0.         1.2040195\n",
      "  0.         0.         0.7991934  0.         0.80656105 0.\n",
      "  0.6906704  0.         0.         0.41605487 0.75875145 0.7179112\n",
      "  0.         0.9166087  1.3279728  0.04865829 0.         0.34643993\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.43129328 0.         0.         0.         0.\n",
      "  0.         0.2994514  0.         1.196258   0.         0.\n",
      "  0.         0.31883255 0.         0.01758511 0.         1.0388206\n",
      "  0.66016    0.9688771  0.48757604 0.32639545 0.4418414  0.6657058\n",
      "  0.         0.9010397  0.         0.43475857 0.27861333 0.\n",
      "  0.29571566 0.51625353 0.8701721  0.9834086 ]]\n",
      "Hi!\n",
      "[[0.77544045 0.42290747 2.2094417  0.         0.         0.7970077\n",
      "  0.         0.         1.408216   0.         0.8534888  0.\n",
      "  0.4859925  0.         0.         0.8926666  0.92544365 1.0083822\n",
      "  0.23732477 0.23803072 1.5840498  0.49057856 0.         0.46499205\n",
      "  0.09736448 0.         0.         0.         0.         0.\n",
      "  0.         0.03398271 0.         0.         0.         0.\n",
      "  0.30703112 0.85837805 0.         1.0641143  0.         0.\n",
      "  0.         0.9704944  0.         0.         0.         1.0402895\n",
      "  0.02748322 1.0803473  0.832151   0.         0.1561169  0.07806779\n",
      "  0.         0.12844752 0.         1.0511401  0.25183043 0.\n",
      "  0.10705474 0.993042   1.1160164  1.2984115 ]]\n",
      "Hi!\n",
      "[[5.12965143e-01 2.54022658e-01 3.12337130e-01 1.25555307e-01\n",
      "  0.00000000e+00 6.34246886e-01 8.46103132e-01 1.20715284e+00\n",
      "  3.13502371e-01 0.00000000e+00 2.74774820e-01 0.00000000e+00\n",
      "  9.40516949e-01 4.18555379e-01 0.00000000e+00 3.58409375e-01\n",
      "  0.00000000e+00 5.20473242e-01 1.29634604e-01 2.10567862e-01\n",
      "  4.45824414e-01 1.55140689e-04 0.00000000e+00 0.00000000e+00\n",
      "  1.12183966e-01 0.00000000e+00 0.00000000e+00 4.91756469e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.09874272e+00 6.91520631e-01\n",
      "  0.00000000e+00 0.00000000e+00 5.44795871e-01 0.00000000e+00\n",
      "  2.06710130e-01 1.04200184e+00 0.00000000e+00 2.36890808e-01\n",
      "  5.91144972e-02 0.00000000e+00 0.00000000e+00 2.49995098e-01\n",
      "  1.02144015e+00 9.41458821e-01 0.00000000e+00 5.02344489e-01\n",
      "  0.00000000e+00 7.29882717e-01 4.37220484e-01 5.68245173e-01\n",
      "  6.07625544e-01 7.95298398e-01 0.00000000e+00 0.00000000e+00\n",
      "  3.47737223e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.86813879e-01 9.88673806e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.31225926 0.02601615 0.74576    0.         0.         0.5795837\n",
      "  0.8362535  0.966519   0.86151636 0.         0.44529825 0.\n",
      "  0.29246107 0.         0.         0.56722325 0.         0.7875471\n",
      "  0.         0.         0.76564837 0.00162033 0.         0.21157402\n",
      "  0.         0.         0.         0.10507401 0.         0.\n",
      "  0.55446076 0.24021304 0.         0.         0.35356873 0.\n",
      "  0.         0.99031633 0.         0.562808   0.04723156 0.\n",
      "  0.         0.8335593  0.09922446 0.52888316 0.         0.07939766\n",
      "  0.         0.9355478  0.56399935 0.2569879  0.5495767  0.0271675\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.9399789  0.87955713 0.2744721 ]]\n",
      "Hi!\n",
      "[[0.54266685 0.46851525 0.92323875 0.09380683 0.         0.93641365\n",
      "  0.         0.33717355 0.         0.         0.30164263 0.\n",
      "  0.35787046 0.15023273 0.         0.         0.         0.16946863\n",
      "  0.         0.92125654 0.38362464 0.         0.         0.04024029\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.39207363 0.8427805  0.12064512 0.         0.         0.\n",
      "  0.         0.07344775 0.28583306 0.3835346  0.         0.\n",
      "  0.         0.02136664 0.76458544 0.7802964  0.         0.5042088\n",
      "  0.73336023 0.589032   0.         0.60607225 0.72701293 1.0371622\n",
      "  0.         1.1007162  0.07531948 0.         0.07803907 0.\n",
      "  0.13799722 0.02695749 0.5770752  0.        ]]\n",
      "Hi!\n",
      "[[0.8699969  0.         1.1295258  0.34831488 0.         0.7836915\n",
      "  1.7572922  1.7254027  1.1696848  0.         0.4437926  0.\n",
      "  0.         0.         0.         0.74283403 0.60061026 0.8858929\n",
      "  0.         0.         1.0868607  0.43544382 0.         0.60406953\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22398995 0.05861285 0.22700804 0.         0.3182855  0.\n",
      "  0.         1.2404325  0.         0.8881314  0.29406074 0.\n",
      "  0.         1.893864   0.         0.52198297 0.         0.\n",
      "  0.         1.0088267  0.46471348 0.1973982  0.8079675  0.\n",
      "  0.         0.6240759  0.         0.28081286 0.         0.\n",
      "  0.         1.3873541  1.3490971  0.        ]]\n",
      "Hi!\n",
      "[[0.11553993 0.1785453  0.18647093 0.00964593 0.         0.11678262\n",
      "  0.         0.13415875 0.         0.02144083 0.12077513 0.\n",
      "  0.07489763 0.21920043 0.         0.         0.         0.04361908\n",
      "  0.         0.21115404 0.06696112 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05995081 0.24189347 0.18923385 0.         0.         0.\n",
      "  0.         0.         0.26781213 0.10305026 0.         0.\n",
      "  0.         0.         0.29496396 0.29826126 0.         0.04716335\n",
      "  0.2609706  0.09669469 0.         0.2223367  0.19161078 0.42474514\n",
      "  0.         0.21833853 0.0531142  0.         0.         0.\n",
      "  0.10310585 0.01868522 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.2929845  0.         1.8637952  0.07845782 0.         1.3201113\n",
      "  0.62618315 0.7788755  1.1226665  0.00983444 0.654563   0.\n",
      "  0.         0.         0.         0.43926153 1.0664529  0.8395246\n",
      "  0.         0.         1.4349793  0.57702345 0.         0.88503146\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26186538 0.         0.         0.\n",
      "  0.         0.56194615 0.         1.2011279  0.07187494 0.\n",
      "  0.         1.7661626  0.         0.3533998  0.         0.0781276\n",
      "  0.06260195 1.4074031  0.5135943  0.03436461 0.76383406 0.\n",
      "  0.         1.3325802  0.         0.602452   0.         0.\n",
      "  0.33782092 1.122085   0.81911385 0.5199648 ]]\n",
      "Hi!\n",
      "[[0.74252284 0.13241942 1.1146821  0.12148438 0.         1.1447614\n",
      "  0.542648   0.89576024 0.17049512 0.02896026 0.4028581  0.\n",
      "  0.         0.         0.         0.         0.         0.4461613\n",
      "  0.         0.5171782  0.7496538  0.         0.         0.2602856\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.39169136 0.6200212  0.1515398  0.         0.0404652  0.\n",
      "  0.         0.4338374  0.         0.5418303  0.         0.\n",
      "  0.         0.3298668  0.46508706 0.90251935 0.         0.10716635\n",
      "  0.35997033 0.98386997 0.         0.61015797 1.0211836  0.48985413\n",
      "  0.         1.1859747  0.         0.         0.         0.\n",
      "  0.02995978 0.47416568 0.9169712  0.        ]]\n",
      "Hi!\n",
      "[[0.42641732 0.05776979 0.38674614 0.12206823 0.         0.7684663\n",
      "  1.1613393  1.2793125  0.62955624 0.         0.3244641  0.\n",
      "  0.8832009  0.13131547 0.         0.58101904 0.         0.7400748\n",
      "  0.49591982 0.         0.5466393  0.12335831 0.         0.\n",
      "  0.3590251  0.         0.         0.56893986 0.         0.\n",
      "  1.0249957  0.5216314  0.         0.         0.80761236 0.\n",
      "  0.5188436  1.3916222  0.         0.28128028 0.1678434  0.\n",
      "  0.         0.56457496 0.9893655  0.8279211  0.         0.89731246\n",
      "  0.         0.670783   0.632813   0.47529545 0.34598416 0.8618964\n",
      "  0.         0.         0.48794293 0.         0.         0.\n",
      "  0.         0.63509774 1.228523   0.16366045]]\n",
      "Hi!\n",
      "[[0.7656377  0.         1.0094056  0.22956185 0.         0.95101494\n",
      "  0.8502669  1.0471483  0.5684791  0.         0.39855358 0.\n",
      "  0.         0.         0.         0.22580582 0.25237697 0.6301231\n",
      "  0.         0.         0.85152173 0.07049556 0.         0.451343\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21969579 0.36752364 0.17151503 0.         0.057285   0.\n",
      "  0.         0.6556789  0.         0.74232596 0.04102314 0.\n",
      "  0.         0.9479566  0.03276068 0.67207336 0.         0.\n",
      "  0.         1.1409501  0.16175152 0.3118871  0.84899145 0.03375689\n",
      "  0.         0.8696048  0.         0.         0.         0.\n",
      "  0.         0.83568525 0.8623094  0.        ]]\n",
      "Hi!\n",
      "[[0.02271729 0.4311996  0.5036399  0.         0.         0.3921152\n",
      "  0.         0.         0.3276127  0.01428299 0.30257064 0.\n",
      "  0.32830757 0.         0.         0.1442111  0.         0.03858539\n",
      "  0.         0.47912228 0.31652412 0.         0.         0.03070625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03758869 0.04944756 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.19676735 0.         0.\n",
      "  0.         0.         0.         0.14930646 0.         0.38590166\n",
      "  0.16188723 0.22793195 0.12389564 0.24450716 0.11004298 0.41881925\n",
      "  0.         0.01018557 0.         0.         0.13132307 0.\n",
      "  0.11460871 0.06705916 0.07306659 0.2111229 ]]\n",
      "Hi!\n",
      "[[0.30451074 0.15220314 0.5108944  0.         0.         0.524267\n",
      "  0.87853515 1.1745292  0.9124138  0.         0.4070743  0.\n",
      "  0.9853852  0.04270076 0.         0.7186066  0.         0.6655021\n",
      "  0.44263896 0.         0.7011544  0.01615411 0.         0.\n",
      "  0.20751421 0.         0.         0.49294195 0.         0.\n",
      "  0.99796927 0.45133892 0.         0.         0.62789667 0.\n",
      "  0.3051522  1.2319616  0.         0.30876288 0.10248087 0.\n",
      "  0.         0.60030663 0.58195776 0.5930478  0.         0.45845482\n",
      "  0.         0.7214118  0.77160573 0.3717103  0.6145539  0.33104792\n",
      "  0.         0.         0.24879657 0.         0.         0.\n",
      "  0.         0.7179155  1.1888174  0.29468083]]\n",
      "Hi!\n",
      "[[1.4566830e-01 3.0275598e-01 7.4513763e-04 1.2561919e-04 0.0000000e+00\n",
      "  5.2649528e-02 0.0000000e+00 2.0113185e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0594136e-01 0.0000000e+00 3.7953931e-01 3.9207250e-01 0.0000000e+00\n",
      "  4.5280713e-03 0.0000000e+00 1.2537433e-01 0.0000000e+00 1.6553776e-01\n",
      "  1.2192502e-02 0.0000000e+00 0.0000000e+00 1.4933881e-02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.2621589e-01 0.0000000e+00 0.0000000e+00\n",
      "  2.7568451e-01 2.7752122e-01 2.0980582e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4799650e-01 5.5948421e-02\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2672524e-01\n",
      "  3.4299728e-01 0.0000000e+00 6.8339109e-02 1.6012023e-01 2.0928802e-01\n",
      "  0.0000000e+00 1.8837158e-01 1.4197345e-01 6.0153276e-01 0.0000000e+00\n",
      "  3.9049145e-02 2.3306145e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2697860e-01 1.6213143e-01 0.0000000e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.92563254 0.09617983 1.7667799  0.         0.         0.9105624\n",
      "  0.38570178 0.5498946  1.3830597  0.         0.73310137 0.\n",
      "  0.25989962 0.         0.         0.76060647 0.6999678  0.9030305\n",
      "  0.         0.         1.4286896  0.31647235 0.         0.7269408\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21261357 0.00233528 0.         0.         0.\n",
      "  0.06134363 0.9558793  0.         0.9344541  0.15920748 0.\n",
      "  0.         1.2604563  0.         0.09984359 0.         0.5556799\n",
      "  0.         0.9352003  0.74513805 0.18223184 0.48399898 0.08477315\n",
      "  0.         0.52022725 0.         0.6481254  0.         0.\n",
      "  0.         1.0154531  1.2098831  0.87783396]]\n",
      "Hi!\n",
      "[[0.56559753 0.53019506 0.6681998  0.04386922 0.         0.76070106\n",
      "  0.29294607 0.63068265 0.         0.         0.3345025  0.\n",
      "  0.53938806 0.2294483  0.         0.         0.         0.3471408\n",
      "  0.         0.78565884 0.4113824  0.         0.         0.12244156\n",
      "  0.         0.         0.         0.12152804 0.         0.\n",
      "  0.79390454 0.7853319  0.01742068 0.         0.10140771 0.\n",
      "  0.         0.4392576  0.2804308  0.33292547 0.         0.\n",
      "  0.         0.06963698 0.90198314 0.92083013 0.         0.46386483\n",
      "  0.5002119  0.73929006 0.07673164 0.5429204  0.63024896 1.030021\n",
      "  0.         0.73891115 0.21534556 0.         0.         0.\n",
      "  0.         0.12911366 0.57302755 0.        ]]\n",
      "Hi!\n",
      "[[4.60341722e-01 0.00000000e+00 3.74791026e-01 4.26467180e-01\n",
      "  0.00000000e+00 5.98881066e-01 1.90393114e+00 1.63916588e+00\n",
      "  4.75739688e-01 0.00000000e+00 2.55663157e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.83584321e-01\n",
      "  4.94919978e-02 7.88163424e-01 0.00000000e+00 0.00000000e+00\n",
      "  4.82702434e-01 2.94865310e-01 0.00000000e+00 9.29406360e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.65061651e-04\n",
      "  0.00000000e+00 0.00000000e+00 3.87730002e-01 0.00000000e+00\n",
      "  2.96800733e-01 0.00000000e+00 4.60860580e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.00116146e+00 0.00000000e+00 8.01766396e-01\n",
      "  2.58412063e-01 0.00000000e+00 0.00000000e+00 1.37344456e+00\n",
      "  1.00269735e-01 8.47759545e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.04360449e+00 2.42709756e-01 2.39222333e-01\n",
      "  5.32120168e-01 0.00000000e+00 0.00000000e+00 2.31377512e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.31026375e+00 4.99332160e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.64105725 0.16048099 0.9873987  0.08518013 0.         1.0266652\n",
      "  0.6083799  0.80978847 0.21622221 0.         0.4034605  0.\n",
      "  0.0512885  0.         0.         0.0764733  0.01851711 0.52466685\n",
      "  0.         0.46054703 0.6963482  0.         0.         0.1632214\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35978276 0.5541466  0.0709549  0.         0.06790195 0.\n",
      "  0.         0.50407237 0.         0.5626279  0.         0.\n",
      "  0.         0.3708705  0.42231962 0.78552055 0.         0.17823344\n",
      "  0.2853255  0.9834343  0.10235312 0.553652   0.77484274 0.56029516\n",
      "  0.         0.95380175 0.         0.         0.         0.\n",
      "  0.06119457 0.4823054  0.71925366 0.        ]]\n",
      "Hi!\n",
      "[[0.22757253 0.5930041  1.1881192  0.         0.         0.5282047\n",
      "  0.24358955 0.23990436 1.2494205  0.         0.61345005 0.\n",
      "  1.039109   0.         0.         0.87141734 0.17273766 0.9175073\n",
      "  0.62866163 0.12476391 1.0810972  0.2750704  0.         0.10533401\n",
      "  0.2653835  0.         0.         0.         0.         0.\n",
      "  0.34144026 0.24151534 0.         0.         0.31837577 0.\n",
      "  0.4205632  1.0948465  0.         0.7923707  0.10532022 0.\n",
      "  0.         0.6443825  0.09101047 0.         0.         0.96943825\n",
      "  0.         0.8351997  0.860544   0.12859523 0.07735842 0.31762195\n",
      "  0.         0.         0.07302192 0.32927778 0.04351161 0.\n",
      "  0.         0.91527957 1.0033056  0.98305285]]\n",
      "Hi!\n",
      "[[0.38677052 0.49563652 0.18653259 0.16590224 0.         0.45764583\n",
      "  0.24622105 0.5593552  0.         0.         0.09805042 0.\n",
      "  0.2820582  0.64210165 0.         0.         0.         0.1635796\n",
      "  0.         0.6841027  0.04482408 0.         0.         0.15666008\n",
      "  0.         0.         0.         0.15257956 0.         0.\n",
      "  0.6535429  0.66705406 0.32041705 0.         0.02663097 0.\n",
      "  0.         0.07097016 0.5423356  0.1421606  0.         0.\n",
      "  0.         0.         0.9091133  0.9167215  0.         0.06908575\n",
      "  0.48278785 0.60319215 0.         0.4809568  0.64001757 0.925221\n",
      "  0.         0.5018153  0.2613778  0.         0.         0.\n",
      "  0.03084664 0.20461836 0.03595428 0.        ]]\n",
      "Hi!\n",
      "[[0.14285327 0.20916519 0.32650167 0.         0.         0.20579846\n",
      "  0.         0.23818246 0.07360032 0.         0.         0.\n",
      "  0.18668498 0.06854842 0.         0.08651954 0.         0.06311321\n",
      "  0.         0.19545697 0.06394261 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11632883 0.38361517 0.13772303 0.         0.         0.\n",
      "  0.         0.08474936 0.23787694 0.09538328 0.         0.\n",
      "  0.         0.         0.28237066 0.31049088 0.         0.11346637\n",
      "  0.26229325 0.23802067 0.         0.24116035 0.13439001 0.48943174\n",
      "  0.         0.28843215 0.04820226 0.         0.         0.\n",
      "  0.08413226 0.11758856 0.10471611 0.        ]]\n",
      "Hi!\n",
      "[[0.3718018  0.12937881 0.24834876 0.24055769 0.         0.8537338\n",
      "  0.9924374  1.180895   0.         0.08451926 0.148336   0.\n",
      "  0.         0.2708261  0.         0.0404603  0.         0.30015394\n",
      "  0.         0.47162205 0.26623553 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6871183  0.4478612  0.27662897 0.         0.1888104  0.\n",
      "  0.         0.48300022 0.         0.42815825 0.         0.\n",
      "  0.         0.17224443 0.8380132  1.241594   0.         0.04059478\n",
      "  0.33400595 0.984071   0.         0.64486486 0.8566112  0.6136554\n",
      "  0.         0.68424726 0.         0.         0.         0.\n",
      "  0.03455356 0.55330443 0.31986046 0.        ]]\n",
      "Hi!\n",
      "[[0.63939244 0.9013824  0.27448094 0.         0.         0.3438115\n",
      "  0.42303485 1.1860065  0.78748804 0.         0.3873877  0.\n",
      "  2.3078432  0.98081505 0.         0.8070607  0.         0.607982\n",
      "  1.2475737  0.19561991 0.5522017  0.271205   0.         0.09823286\n",
      "  0.39125702 0.         0.         0.92304873 0.         0.\n",
      "  1.5190533  1.0044489  0.         0.         0.79578185 0.\n",
      "  0.7477737  1.2534288  0.46153435 0.19629519 0.1308657  0.\n",
      "  0.         0.52755964 1.3928787  0.7495679  0.         1.0805168\n",
      "  0.         0.8032285  1.1395093  0.46283722 0.684457   1.3102728\n",
      "  0.         0.         0.60858846 0.         0.         0.\n",
      "  0.         0.32128808 1.2558404  0.32409263]]\n",
      "Hi!\n",
      "[[0.6675686  0.20837644 0.29477414 0.4166725  0.         0.76220137\n",
      "  0.9387456  1.3498155  0.         0.         0.21361579 0.\n",
      "  0.59562355 0.56025743 0.         0.07548685 0.         0.3913088\n",
      "  0.         0.42644238 0.37041143 0.         0.         0.10935035\n",
      "  0.         0.         0.         0.62137663 0.         0.\n",
      "  1.1971389  0.8853189  0.216697   0.         0.53480387 0.\n",
      "  0.         0.7967165  0.29007345 0.18314844 0.15930013 0.\n",
      "  0.         0.26468924 1.2821773  1.2949212  0.         0.30214724\n",
      "  0.2165534  0.8345443  0.06003818 0.6876897  0.8512115  0.9060602\n",
      "  0.         0.47833025 0.38354906 0.         0.         0.\n",
      "  0.         0.26487252 0.9771714  0.        ]]\n",
      "Hi!\n",
      "[[0.3333886  0.2501893  1.1353317  0.         0.         0.7082204\n",
      "  0.4681467  0.630965   1.0049568  0.         0.60920656 0.\n",
      "  0.77151465 0.         0.         0.68634856 0.         0.76304364\n",
      "  0.40862352 0.03558063 1.0131031  0.02482836 0.         0.09279963\n",
      "  0.08085041 0.         0.         0.18722333 0.         0.\n",
      "  0.5183775  0.4535608  0.         0.         0.36898735 0.\n",
      "  0.36528924 1.0488175  0.         0.5819543  0.07889095 0.\n",
      "  0.         0.6478984  0.34787014 0.27880126 0.         0.72382843\n",
      "  0.         0.67622775 0.6716458  0.27201825 0.3686475  0.3508316\n",
      "  0.         0.         0.18726487 0.12812798 0.         0.\n",
      "  0.         0.8057555  1.275088   0.58758336]]\n",
      "Hi!\n",
      "[[0.73422575 0.44201776 1.3391094  0.         0.         0.83596474\n",
      "  0.07613374 0.         0.63729894 0.16544487 0.5515193  0.\n",
      "  0.         0.         0.         0.18316926 0.5467517  0.7005054\n",
      "  0.         0.5535256  0.9516727  0.03060794 0.         0.3315125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05897883 0.05861776 0.         0.         0.\n",
      "  0.         0.22144325 0.         0.8016711  0.         0.\n",
      "  0.         0.5747817  0.         0.25139776 0.         0.4903434\n",
      "  0.37803847 0.7779213  0.32667187 0.15549283 0.3510032  0.17737103\n",
      "  0.         0.634417   0.         0.18920016 0.15041472 0.\n",
      "  0.3885025  0.7778341  0.253366   0.60659873]]\n",
      "Hi!\n",
      "[[0.36412024 0.5075022  1.047834   0.         0.         0.5125969\n",
      "  0.518641   0.9205541  1.7614702  0.         0.6428593  0.\n",
      "  1.9012003  0.         0.         1.1846949  0.         0.92042345\n",
      "  1.6969178  0.         1.1782517  0.14861415 0.         0.\n",
      "  0.50376743 0.         0.         0.6861418  0.         0.\n",
      "  1.0547396  0.44716424 0.         0.         0.63997895 0.\n",
      "  1.1202949  1.5429631  0.         0.48905894 0.3603202  0.\n",
      "  0.         0.74661326 0.52206856 0.11591919 0.         1.2431571\n",
      "  0.         0.9798831  1.4534466  0.33694744 0.26726857 0.5596389\n",
      "  0.         0.         0.53641045 0.3381588  0.         0.\n",
      "  0.         0.64811474 1.8856851  1.1459168 ]]\n",
      "Hi!\n",
      "[[0.26780164 0.         0.39640212 0.3600309  0.         0.6958403\n",
      "  1.7442943  1.8132975  0.66126627 0.         0.27223963 0.\n",
      "  0.0778653  0.         0.         0.5654046  0.         0.69598085\n",
      "  0.         0.         0.6237667  0.13860473 0.         0.\n",
      "  0.00619719 0.         0.         0.46753442 0.         0.\n",
      "  0.9823029  0.33324537 0.13218886 0.         0.72101444 0.\n",
      "  0.         1.3360806  0.         0.46326467 0.30580473 0.\n",
      "  0.         1.036233   0.5467344  0.9974927  0.         0.\n",
      "  0.         0.9236888  0.38721147 0.5073117  0.81490374 0.02263917\n",
      "  0.         0.0410598  0.1534829  0.         0.         0.\n",
      "  0.         0.9808614  1.3862216  0.        ]]\n",
      "Hi!\n",
      "[[0.32816115 0.         0.03132643 0.12963232 0.         0.3930017\n",
      "  1.4243625  1.5831386  0.62413764 0.         0.2833047  0.\n",
      "  0.75420713 0.44591883 0.         0.6792587  0.         0.6771407\n",
      "  0.16193323 0.         0.36830124 0.23334551 0.         0.\n",
      "  0.2769364  0.         0.         0.6130879  0.         0.\n",
      "  1.253649   0.41111258 0.         0.         0.9279538  0.\n",
      "  0.39327484 1.3824388  0.         0.2531851  0.20289046 0.\n",
      "  0.         0.6611353  0.9549988  0.98745954 0.         0.2955422\n",
      "  0.         0.80511105 0.69887406 0.4696956  0.566337   0.48693025\n",
      "  0.         0.         0.42259195 0.         0.         0.\n",
      "  0.         0.7010148  1.0161592  0.        ]]\n",
      "Hi!\n",
      "[[0.35074526 0.         0.94884646 0.03125424 0.         0.84076846\n",
      "  1.0830852  1.2486162  1.1500878  0.         0.4856982  0.\n",
      "  0.6753947  0.         0.         0.75272554 0.         0.7383755\n",
      "  0.57553554 0.         0.9741548  0.05835229 0.         0.1658222\n",
      "  0.18415351 0.         0.         0.4458339  0.         0.\n",
      "  0.748076   0.48045486 0.         0.         0.5081465  0.\n",
      "  0.41335654 1.4065639  0.         0.46198878 0.25438643 0.\n",
      "  0.         1.0034246  0.37837848 0.57377344 0.         0.6541766\n",
      "  0.         0.64509773 0.77262056 0.39031368 0.48465794 0.3279651\n",
      "  0.         0.         0.29982087 0.19861673 0.         0.\n",
      "  0.         0.842765   1.6631153  0.49156725]]\n",
      "Hi!\n",
      "[[0.         0.11277407 0.15389045 0.         0.         0.18120657\n",
      "  0.00500153 0.1751605  0.         0.1420297  0.12690169 0.\n",
      "  0.         0.07339268 0.         0.03934814 0.         0.05514989\n",
      "  0.         0.20521316 0.06766927 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06299471 0.11980616 0.         0.         0.\n",
      "  0.         0.         0.05662296 0.1723119  0.         0.\n",
      "  0.         0.         0.09445918 0.38037825 0.         0.10407814\n",
      "  0.13647291 0.20043866 0.         0.18770196 0.10159139 0.270705\n",
      "  0.         0.15292318 0.         0.         0.         0.\n",
      "  0.09759305 0.16804066 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.18433008 0.3825554  0.35958347 0.         0.         0.5669025\n",
      "  0.10080873 0.25457892 0.         0.05143099 0.23125818 0.\n",
      "  0.15069105 0.11501488 0.         0.         0.         0.2591101\n",
      "  0.         0.5771351  0.183495   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19406685 0.32694277 0.03912937 0.         0.         0.\n",
      "  0.         0.11876401 0.04633515 0.28383198 0.         0.\n",
      "  0.         0.         0.36730286 0.69780105 0.         0.4076484\n",
      "  0.40940383 0.5116107  0.         0.3813593  0.28041092 0.7319168\n",
      "  0.         0.56863296 0.         0.         0.         0.\n",
      "  0.12245212 0.1294102  0.03280067 0.        ]]\n",
      "Hi!\n",
      "[[0.42533174 0.         0.36032808 0.206693   0.         0.688586\n",
      "  1.1140727  1.4279828  0.46717918 0.         0.29498672 0.\n",
      "  0.7051667  0.22207215 0.         0.43139258 0.         0.53862077\n",
      "  0.03514398 0.02512739 0.49662542 0.01796981 0.         0.\n",
      "  0.07982167 0.         0.         0.5270324  0.         0.\n",
      "  1.0689733  0.5712445  0.         0.         0.63100886 0.\n",
      "  0.12352008 1.1566496  0.         0.27680147 0.16244298 0.\n",
      "  0.         0.45555964 0.8738435  0.9745213  0.         0.36264512\n",
      "  0.         0.7759685  0.45556113 0.58534336 0.7290099  0.54354334\n",
      "  0.         0.         0.30151865 0.         0.         0.\n",
      "  0.         0.5287546  1.1890614  0.        ]]\n",
      "Hi!\n",
      "[[0.22457273 0.         0.         0.45402458 0.         0.53351176\n",
      "  2.297236   2.1499975  0.49068335 0.         0.15249096 0.\n",
      "  0.         0.15946746 0.         0.59921557 0.         0.7139148\n",
      "  0.         0.         0.36470184 0.35098252 0.         0.\n",
      "  0.24055396 0.         0.         0.66300976 0.         0.\n",
      "  1.2173952  0.2386558  0.13762385 0.         0.96826774 0.\n",
      "  0.14120033 1.5319084  0.         0.3693414  0.44784588 0.\n",
      "  0.         1.1575909  0.86843723 1.2325995  0.         0.\n",
      "  0.         0.9780879  0.44816452 0.5185277  0.6987179  0.19553438\n",
      "  0.         0.         0.3395588  0.         0.         0.\n",
      "  0.         1.0131143  1.152332   0.        ]]\n",
      "Hi!\n",
      "[[0.4014649  0.3136041  0.5172984  0.13884479 0.         0.68286973\n",
      "  0.0613949  0.32676548 0.         0.         0.18451211 0.\n",
      "  0.17180516 0.1634785  0.         0.         0.         0.\n",
      "  0.         0.6261748  0.15430091 0.         0.         0.\n",
      "  0.         0.         0.         0.04299645 0.         0.\n",
      "  0.1574309  0.6333372  0.17423317 0.         0.         0.\n",
      "  0.         0.08981721 0.36412746 0.16960202 0.         0.\n",
      "  0.         0.         0.5960885  0.6158922  0.         0.24739705\n",
      "  0.6092975  0.454572   0.         0.5412907  0.4775354  0.98243934\n",
      "  0.         0.76939714 0.02370358 0.         0.         0.\n",
      "  0.08210958 0.01242947 0.30022013 0.        ]]\n",
      "Hi!\n",
      "[[0.6600586  0.53511316 1.130668   0.         0.         1.0445851\n",
      "  0.21086054 0.4249218  0.31374317 0.1443287  0.46699658 0.\n",
      "  0.         0.         0.         0.03078676 0.08453784 0.4235772\n",
      "  0.         0.66901004 0.7627745  0.         0.         0.40825364\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.32700709 0.07899435 0.         0.         0.\n",
      "  0.         0.14554343 0.         0.6912172  0.         0.\n",
      "  0.         0.2402654  0.05558136 0.70069766 0.         0.0735191\n",
      "  0.41400778 1.1819386  0.02766761 0.44387558 1.0318313  0.40618527\n",
      "  0.         1.0854659  0.         0.         0.06042026 0.\n",
      "  0.38028342 0.6261929  0.18051769 0.08410981]]\n",
      "Hi!\n",
      "[[0.07347515 0.3232424  0.42194885 0.         0.         0.32766756\n",
      "  0.         0.         0.06455304 0.07793859 0.22539365 0.\n",
      "  0.16012934 0.04767982 0.         0.         0.         0.10212377\n",
      "  0.         0.40533578 0.19450189 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17652775 0.         0.         0.         0.\n",
      "  0.         0.         0.05987052 0.20298898 0.         0.\n",
      "  0.         0.         0.14378382 0.25481257 0.         0.2630024\n",
      "  0.3374714  0.18084359 0.         0.28563693 0.16909404 0.4093944\n",
      "  0.         0.25541115 0.         0.         0.09213162 0.\n",
      "  0.14059606 0.08930463 0.         0.06729791]]\n",
      "Hi!\n",
      "[[0.5652872  0.         0.44953135 0.59577703 0.         0.8807513\n",
      "  2.0249228  1.8816062  0.26953065 0.         0.23129259 0.\n",
      "  0.         0.         0.         0.3201453  0.         0.68990797\n",
      "  0.         0.         0.49392372 0.14472093 0.         0.14760984\n",
      "  0.         0.         0.         0.07602394 0.         0.\n",
      "  0.52712774 0.1907743  0.33561474 0.         0.43165177 0.\n",
      "  0.         0.87486494 0.         0.8431984  0.32522023 0.\n",
      "  0.         1.3252994  0.29613578 1.1554296  0.         0.\n",
      "  0.         1.2014742  0.01414089 0.47448507 0.95404655 0.\n",
      "  0.         0.7116928  0.         0.         0.         0.\n",
      "  0.         1.119038   0.7402998  0.        ]]\n",
      "Hi!\n",
      "[[0.6712237  0.         1.2670981  0.17955585 0.         0.86143523\n",
      "  1.4315574  1.4830297  1.2119764  0.         0.51552194 0.\n",
      "  0.         0.         0.         0.7238166  0.41789922 0.84806585\n",
      "  0.         0.         1.1560848  0.3401504  0.         0.44948047\n",
      "  0.         0.         0.         0.11476059 0.         0.\n",
      "  0.29063743 0.21083367 0.11126822 0.         0.42492077 0.\n",
      "  0.04327866 1.3473241  0.         0.64153147 0.23826508 0.\n",
      "  0.         1.5872843  0.         0.45353168 0.         0.27740178\n",
      "  0.         0.6876098  0.5493408  0.24937929 0.60719705 0.\n",
      "  0.         0.38046083 0.01272478 0.34913763 0.         0.\n",
      "  0.         1.2203561  1.5869662  0.26562232]]\n",
      "Hi!\n",
      "[[0.80472463 0.         1.4987009  0.         0.         0.80381906\n",
      "  0.52376735 0.5817558  1.329963   0.         0.66725135 0.\n",
      "  0.07361583 0.         0.         0.71622217 0.60554844 0.90786237\n",
      "  0.         0.         1.2618693  0.33157954 0.         0.67459327\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10682003 0.06211813 0.         0.         0.\n",
      "  0.         0.87498105 0.         0.90799147 0.09125572 0.\n",
      "  0.         1.3033775  0.         0.12500975 0.         0.40320593\n",
      "  0.         0.8618641  0.6820624  0.13527504 0.48129094 0.\n",
      "  0.         0.40132686 0.         0.5801982  0.         0.\n",
      "  0.         1.1096411  0.99810576 0.78612834]]\n",
      "Hi!\n",
      "[[0.04430075 0.22290652 0.18696962 0.         0.         0.09343774\n",
      "  0.         0.00224944 0.04477515 0.02844827 0.10002294 0.\n",
      "  0.23150174 0.11792539 0.         0.         0.         0.03060892\n",
      "  0.         0.12270176 0.08072207 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02889956 0.22113337 0.09392358 0.         0.         0.\n",
      "  0.         0.         0.17941931 0.0558327  0.         0.\n",
      "  0.         0.         0.1549087  0.1479796  0.         0.09217863\n",
      "  0.16513811 0.05877826 0.         0.18303673 0.01556897 0.34426084\n",
      "  0.         0.03441226 0.09158154 0.         0.         0.\n",
      "  0.0882706  0.06401195 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6124954  0.53206056 1.9422623  0.         0.         0.8250825\n",
      "  0.14619644 0.         1.5521092  0.         0.8407517  0.\n",
      "  1.018683   0.         0.         1.0212203  0.6171487  1.0526499\n",
      "  0.74500483 0.12232923 1.5467198  0.4674094  0.         0.4099892\n",
      "  0.29233226 0.         0.         0.         0.         0.\n",
      "  0.03505651 0.22455084 0.         0.         0.04660189 0.\n",
      "  0.5148958  1.1510555  0.         1.0961877  0.09137169 0.\n",
      "  0.         0.92762566 0.         0.         0.         1.1861014\n",
      "  0.         1.0548929  0.9791512  0.1042107  0.23328625 0.32679063\n",
      "  0.         0.         0.         0.86511624 0.1330796  0.\n",
      "  0.         1.0059661  1.332567   1.3755988 ]]\n",
      "Hi!\n",
      "[[0.71022433 0.         1.320104   0.         0.         0.9664729\n",
      "  0.6388348  0.88437665 0.944007   0.         0.53516054 0.\n",
      "  0.13513075 0.         0.         0.501911   0.3353581  0.72417194\n",
      "  0.         0.         1.1151006  0.04886686 0.         0.5257689\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17752792 0.3367956  0.09101136 0.         0.09377854 0.\n",
      "  0.         0.8632418  0.         0.68471617 0.0458917  0.\n",
      "  0.         0.9491098  0.         0.461757   0.         0.29228836\n",
      "  0.         0.9305194  0.46577784 0.3875719  0.6412282  0.17505156\n",
      "  0.         0.59314597 0.         0.1491659  0.         0.\n",
      "  0.         0.8892466  1.1430094  0.36242902]]\n",
      "Hi!\n",
      "[[0.893716   0.         1.39521    0.         0.         1.0787319\n",
      "  0.5494196  0.60260975 0.6558276  0.         0.51841384 0.\n",
      "  0.         0.         0.         0.28207383 0.47453386 0.71137017\n",
      "  0.         0.26984036 1.0613418  0.06757625 0.         0.35925877\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31143218 0.06638736 0.         0.         0.\n",
      "  0.         0.6716504  0.         0.75368905 0.         0.\n",
      "  0.         0.82935846 0.01973806 0.4180243  0.         0.43542802\n",
      "  0.1869214  0.7960072  0.26974738 0.30940992 0.44024944 0.34992313\n",
      "  0.         0.86298126 0.         0.223355   0.         0.\n",
      "  0.14855608 0.74304867 0.8515032  0.31528476]]\n",
      "Hi!\n",
      "[[0.623024   0.         0.         0.7032602  0.         0.6790596\n",
      "  1.8171918  1.9770364  0.         0.         0.         0.\n",
      "  0.14616205 0.6769556  0.         0.18112485 0.         0.4202076\n",
      "  0.         0.20952246 0.09389612 0.32371888 0.         0.00674022\n",
      "  0.01804512 0.         0.         0.7690807  0.         0.\n",
      "  1.3551065  0.81234854 0.61678594 0.         0.7696567  0.\n",
      "  0.08844204 1.0659175  0.30525166 0.24552535 0.29812753 0.\n",
      "  0.         0.57562965 1.5936526  1.6669265  0.         0.14127453\n",
      "  0.08365203 0.97520524 0.03258719 0.7869388  0.8762778  1.0836062\n",
      "  0.         0.47046396 0.59074765 0.         0.         0.\n",
      "  0.         0.50083    0.7942102  0.        ]]\n",
      "Hi!\n",
      "[[0.7562383  0.5190441  0.18981346 0.3093299  0.         0.56349933\n",
      "  0.63521564 0.84023696 0.         0.         0.01167602 0.\n",
      "  0.56056386 0.6508649  0.         0.07514341 0.         0.24973735\n",
      "  0.         0.66431713 0.07384435 0.         0.         0.20057042\n",
      "  0.         0.         0.         0.5002891  0.         0.\n",
      "  1.0688679  0.79585224 0.37613818 0.         0.3265173  0.\n",
      "  0.12784658 0.599638   0.46977842 0.16814516 0.         0.\n",
      "  0.         0.3492196  1.2896099  1.0689573  0.         0.473655\n",
      "  0.4466888  0.72668797 0.00962861 0.5640501  0.5041795  1.1763228\n",
      "  0.         0.47826824 0.43184775 0.         0.         0.\n",
      "  0.         0.1428002  0.4599462  0.        ]]\n",
      "Hi!\n",
      "[[0.7580581  0.18047248 0.         0.5989801  0.         0.6050412\n",
      "  1.4187462  1.6374905  0.         0.         0.         0.\n",
      "  0.7377666  0.94956136 0.         0.23941407 0.         0.39225635\n",
      "  0.         0.31921926 0.07895748 0.30000824 0.         0.12320415\n",
      "  0.12947124 0.         0.         0.8581613  0.         0.\n",
      "  1.4369599  0.87976146 0.5542508  0.         0.7264718  0.\n",
      "  0.34058714 1.0345676  0.4162593  0.19676839 0.17814586 0.\n",
      "  0.         0.6374037  1.6886429  1.5229149  0.         0.5087005\n",
      "  0.12480692 0.9123226  0.23840296 0.6784822  0.700191   1.3299797\n",
      "  0.         0.24690323 0.670695   0.         0.         0.\n",
      "  0.         0.2618961  0.65473276 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07362336 0.01783261 0.06269117 0.         0.06779117\n",
      "  0.15834211 0.26865667 0.         0.02756631 0.         0.\n",
      "  0.02120488 0.2210976  0.         0.         0.         0.05098734\n",
      "  0.         0.05436191 0.00303885 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08269536 0.17757651 0.2854164  0.         0.         0.\n",
      "  0.         0.         0.29625967 0.02755921 0.         0.\n",
      "  0.         0.         0.3371772  0.35251164 0.         0.\n",
      "  0.13906413 0.09242859 0.         0.2214275  0.0173729  0.36800826\n",
      "  0.         0.15139043 0.06108575 0.         0.         0.\n",
      "  0.01085529 0.12521105 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.81086415 0.39039865 0.22384103 0.45657122 0.         0.7759354\n",
      "  0.7558015  1.2887518  0.         0.         0.16721788 0.\n",
      "  0.8642459  0.8286688  0.         0.         0.         0.30058014\n",
      "  0.         0.63063806 0.26664814 0.05405556 0.         0.14063695\n",
      "  0.         0.         0.         0.7011975  0.         0.\n",
      "  1.3505453  1.079421   0.3637877  0.         0.52731377 0.\n",
      "  0.09963959 0.72412354 0.58608055 0.1075222  0.11596271 0.\n",
      "  0.         0.33164898 1.5666368  1.3411958  0.         0.5412983\n",
      "  0.39778006 0.80110216 0.03857511 0.7769974  0.8442886  1.2836672\n",
      "  0.         0.554356   0.52342707 0.         0.         0.\n",
      "  0.         0.08919757 0.9049984  0.        ]]\n",
      "Hi!\n",
      "[[0.01915057 0.15263654 0.2687589  0.         0.         0.24986455\n",
      "  0.         0.0644811  0.14520016 0.06860228 0.14013354 0.\n",
      "  0.00104128 0.01934237 0.         0.02843033 0.         0.01793042\n",
      "  0.         0.29445267 0.18253729 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11725982 0.09296471 0.         0.         0.\n",
      "  0.         0.         0.08667096 0.10857641 0.         0.\n",
      "  0.         0.         0.04725095 0.2436636  0.         0.1681257\n",
      "  0.21167023 0.074926   0.         0.2640452  0.03331754 0.34966087\n",
      "  0.         0.2146119  0.         0.         0.00903988 0.\n",
      "  0.0944581  0.05343019 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06656644 0.18297222 0.08389835 0.         0.         0.13501602\n",
      "  0.04366328 0.22023834 0.         0.10014594 0.12422108 0.\n",
      "  0.07777689 0.23220608 0.         0.         0.         0.07944254\n",
      "  0.         0.20981887 0.04626971 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10893346 0.15986821 0.17651176 0.         0.         0.\n",
      "  0.         0.         0.19037892 0.12478402 0.         0.\n",
      "  0.         0.         0.2613716  0.39251217 0.         0.00836729\n",
      "  0.21259154 0.24242027 0.         0.2035861  0.12018288 0.44459447\n",
      "  0.         0.16699392 0.05136681 0.         0.         0.\n",
      "  0.11800443 0.16105339 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.42040497 0.38227662 1.2807603  0.         0.         0.77318174\n",
      "  0.3099366  0.5748589  1.2121423  0.         0.63212025 0.\n",
      "  0.90589285 0.         0.         0.67026377 0.14783531 0.8090463\n",
      "  0.3827499  0.         1.1187305  0.05315971 0.         0.32248113\n",
      "  0.         0.         0.         0.07460608 0.         0.\n",
      "  0.46792632 0.3966685  0.         0.         0.18541555 0.\n",
      "  0.11729635 0.9487024  0.         0.6826584  0.13244545 0.\n",
      "  0.         0.70817184 0.06403292 0.22967352 0.         0.66608816\n",
      "  0.         0.8583596  0.7916297  0.34431392 0.571198   0.30177352\n",
      "  0.         0.         0.         0.26397148 0.         0.\n",
      "  0.         0.7681488  1.201064   0.79988027]]\n",
      "Hi!\n",
      "[[0.6798518  0.25309637 1.8029623  0.         0.         0.7490573\n",
      "  0.34185445 0.17596    1.6882037  0.         0.8372774  0.\n",
      "  0.7272825  0.         0.         1.0788678  0.69694525 1.0678586\n",
      "  0.5427188  0.         1.5360582  0.4984061  0.         0.58321446\n",
      "  0.21581055 0.         0.         0.         0.         0.\n",
      "  0.         0.11876416 0.         0.         0.04752066 0.\n",
      "  0.48282462 1.1439263  0.         1.0590467  0.19441447 0.\n",
      "  0.         1.255859   0.         0.         0.         0.93470293\n",
      "  0.         1.0096732  1.0121725  0.         0.1664931  0.01363333\n",
      "  0.         0.         0.         0.9523084  0.03535228 0.\n",
      "  0.         1.1316572  1.3006086  1.3204014 ]]\n",
      "Hi!\n",
      "[[1.0632305  0.23189093 1.9320742  0.         0.         1.117012\n",
      "  0.15072176 0.19728692 0.98612    0.         0.71148133 0.\n",
      "  0.         0.         0.         0.43029758 0.85817426 0.79729104\n",
      "  0.         0.28377235 1.4011014  0.28012133 0.         0.6948207\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19115762 0.09892758 0.         0.         0.\n",
      "  0.         0.4963422  0.         1.01764    0.         0.\n",
      "  0.         1.0381166  0.         0.14940076 0.         0.5569725\n",
      "  0.21738993 0.90595204 0.43594876 0.09227877 0.50950474 0.10630774\n",
      "  0.         0.9849906  0.         0.5535762  0.09864674 0.\n",
      "  0.23442934 0.84884816 0.80482537 0.77501166]]\n",
      "Hi!\n",
      "[[0.8873986  0.         1.3387684  0.08441    0.         0.8843547\n",
      "  0.769979   0.8389377  0.8360838  0.         0.5205353  0.\n",
      "  0.         0.         0.         0.38980183 0.6119737  0.80925053\n",
      "  0.         0.         1.0629318  0.2821518  0.         0.647187\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07946804 0.19695199 0.         0.         0.\n",
      "  0.         0.6709355  0.         0.94485855 0.         0.\n",
      "  0.         1.3459605  0.         0.40919966 0.         0.\n",
      "  0.         1.1013205  0.31659827 0.10886993 0.63302785 0.\n",
      "  0.         0.8294929  0.         0.20849542 0.         0.\n",
      "  0.09015549 1.0645534  0.7138728  0.17504784]]\n",
      "Hi!\n",
      "[[0.5193154  0.         0.8840324  0.10728721 0.         0.6289592\n",
      "  1.5132562  1.5191182  1.1629272  0.         0.4535168  0.\n",
      "  0.         0.         0.         0.84042454 0.19297042 0.8473348\n",
      "  0.         0.         0.98013514 0.25371015 0.         0.37771878\n",
      "  0.02915232 0.         0.         0.15613775 0.         0.\n",
      "  0.46002626 0.07784411 0.10082155 0.         0.5095456  0.\n",
      "  0.03669233 1.3595511  0.         0.6351494  0.205993   0.\n",
      "  0.         1.5297301  0.         0.5277848  0.         0.12121765\n",
      "  0.         0.81891775 0.6117861  0.26121208 0.4810669  0.\n",
      "  0.         0.         0.         0.24850063 0.         0.\n",
      "  0.         1.2495644  1.3563886  0.23638062]]\n",
      "Hi!\n",
      "[[0.5559691  0.26038557 0.40363657 0.15302143 0.         0.6101073\n",
      "  0.5380066  0.52734375 0.         0.         0.04864987 0.\n",
      "  0.34863946 0.3227168  0.         0.05356572 0.         0.23497121\n",
      "  0.         0.567432   0.11095211 0.         0.         0.026901\n",
      "  0.         0.         0.         0.26046488 0.         0.\n",
      "  0.6622268  0.6893874  0.17075631 0.         0.12252042 0.\n",
      "  0.10683718 0.44968867 0.34392214 0.22217554 0.         0.\n",
      "  0.         0.22646187 0.8392849  0.90996146 0.         0.54049927\n",
      "  0.44676003 0.49927795 0.         0.5025252  0.34136993 0.9906266\n",
      "  0.         0.6135228  0.29591337 0.         0.         0.\n",
      "  0.         0.08692472 0.45209426 0.        ]]\n",
      "Hi!\n",
      "[[0.7013753  0.4949298  1.8277314  0.         0.         0.90395796\n",
      "  0.11663776 0.         1.3034811  0.         0.8073904  0.\n",
      "  0.8161818  0.         0.         0.8362683  0.55608857 0.95750856\n",
      "  0.34512538 0.24777544 1.4637146  0.29400265 0.         0.42282376\n",
      "  0.11666715 0.         0.         0.         0.         0.\n",
      "  0.         0.29636735 0.         0.         0.         0.\n",
      "  0.30649957 0.8887375  0.         1.0253496  0.04264622 0.\n",
      "  0.         0.76192164 0.         0.         0.         0.99619013\n",
      "  0.         0.95899177 0.77481073 0.13980469 0.2741244  0.3032581\n",
      "  0.         0.17760962 0.         0.6525699  0.14944375 0.\n",
      "  0.         0.89381266 1.1807561  1.1161186 ]]\n",
      "Hi!\n",
      "[[0.47151998 0.6690297  1.2107197  0.         0.         0.7641603\n",
      "  0.         0.         0.34478983 0.09435049 0.5261789  0.\n",
      "  0.37994626 0.         0.         0.08611617 0.27495167 0.46166924\n",
      "  0.         0.86687845 0.6952741  0.         0.         0.13862088\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23979162 0.00175583 0.         0.         0.\n",
      "  0.         0.         0.         0.65617055 0.         0.\n",
      "  0.         0.         0.00284969 0.16045158 0.         0.6031273\n",
      "  0.5798146  0.64391786 0.14811009 0.32482514 0.36354908 0.49220628\n",
      "  0.         0.66218024 0.         0.         0.21671025 0.\n",
      "  0.37652442 0.38903007 0.28606138 0.52351433]]\n",
      "Hi!\n",
      "[[0.2673174  0.32957798 0.4538753  0.         0.         0.6331704\n",
      "  0.24678077 0.4035433  0.         0.08011021 0.24151234 0.\n",
      "  0.14378606 0.06252849 0.         0.02181874 0.         0.36280757\n",
      "  0.         0.6215069  0.27614513 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.31909618 0.38082713 0.         0.         0.         0.\n",
      "  0.         0.20179062 0.         0.29688668 0.         0.\n",
      "  0.         0.         0.43084016 0.73431605 0.         0.27661535\n",
      "  0.36369005 0.6675907  0.         0.4138854  0.454256   0.5165011\n",
      "  0.         0.53226984 0.         0.         0.         0.\n",
      "  0.18656267 0.36564058 0.14088254 0.        ]]\n",
      "Hi!\n",
      "[[0.2048594  0.806959   0.5599056  0.         0.         0.3585604\n",
      "  0.         0.         0.2239538  0.         0.34091792 0.\n",
      "  0.8863672  0.1525584  0.         0.13082284 0.         0.17571448\n",
      "  0.         0.6275542  0.36972672 0.         0.         0.03017754\n",
      "  0.         0.         0.         0.01065987 0.         0.\n",
      "  0.4019178  0.28548625 0.         0.         0.         0.\n",
      "  0.         0.         0.23238172 0.19370544 0.         0.\n",
      "  0.         0.         0.19220746 0.05244428 0.         0.4858067\n",
      "  0.32526374 0.44031844 0.2243496  0.27588904 0.29160687 0.66444826\n",
      "  0.05800858 0.         0.15617573 0.         0.21166003 0.\n",
      "  0.07296874 0.01869528 0.16424687 0.23071784]]\n",
      "Hi!\n",
      "[[0.11051483 0.2791638  0.33399594 0.         0.         0.43059647\n",
      "  0.         0.16578627 0.01495377 0.16239794 0.2091928  0.\n",
      "  0.         0.         0.         0.02276726 0.         0.18106216\n",
      "  0.         0.4791882  0.17968893 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1045219  0.03240941 0.         0.         0.\n",
      "  0.         0.         0.         0.26516998 0.         0.\n",
      "  0.         0.         0.08312365 0.53700596 0.         0.15645698\n",
      "  0.34315324 0.40211147 0.         0.27586034 0.15760122 0.34942177\n",
      "  0.         0.47392064 0.         0.         0.0403872  0.\n",
      "  0.2359488  0.23399031 0.         0.01841176]]\n",
      "Hi!\n",
      "[[0.15732819 0.23621823 0.         0.09221075 0.         0.39496565\n",
      "  0.7087907  0.75196916 0.         0.08863006 0.03516563 0.\n",
      "  0.         0.35310552 0.         0.08117102 0.         0.34048048\n",
      "  0.         0.444025   0.         0.         0.         0.\n",
      "  0.         0.         0.         0.09820376 0.         0.\n",
      "  0.44352725 0.31140655 0.36618534 0.         0.04807189 0.\n",
      "  0.         0.2920092  0.15342717 0.23835379 0.         0.\n",
      "  0.         0.08878207 0.6940215  1.0032756  0.         0.03961846\n",
      "  0.26543105 0.7469188  0.         0.43993434 0.3310507  0.6342183\n",
      "  0.         0.43836534 0.13688041 0.         0.         0.\n",
      "  0.08762974 0.41922954 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.12858005 0.42298442 0.27295935 0.         0.         0.26576602\n",
      "  0.         0.09969419 0.         0.         0.19760673 0.\n",
      "  0.26937968 0.25582886 0.         0.         0.         0.15757994\n",
      "  0.         0.38906986 0.10739895 0.         0.         0.00211229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15046275 0.32258955 0.08157618 0.         0.         0.\n",
      "  0.         0.         0.25697437 0.13498393 0.         0.\n",
      "  0.         0.         0.3585698  0.36840937 0.         0.20183517\n",
      "  0.34176493 0.22012013 0.         0.25101864 0.16326478 0.5643408\n",
      "  0.         0.21200097 0.08600727 0.         0.01634926 0.\n",
      "  0.12143346 0.10079048 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.30314234 0.4313156  0.8152197  0.         0.         0.6327514\n",
      "  0.46161658 0.70857656 0.9839767  0.         0.5072454  0.\n",
      "  1.280545   0.         0.         0.73044336 0.         0.70632017\n",
      "  0.71662694 0.06916898 0.85722697 0.         0.         0.\n",
      "  0.2399124  0.         0.         0.30016896 0.         0.\n",
      "  0.8071276  0.42797345 0.         0.         0.45244765 0.\n",
      "  0.45434082 1.0249656  0.         0.45372772 0.10660198 0.\n",
      "  0.         0.39730614 0.53562146 0.37435377 0.         0.8710412\n",
      "  0.         0.7435466  0.83708835 0.37388882 0.44846258 0.5570004\n",
      "  0.         0.         0.22913234 0.         0.         0.\n",
      "  0.         0.53506744 1.1592504  0.631412  ]]\n",
      "Hi!\n",
      "[[0.35281155 0.575282   0.6318247  0.         0.         0.41363543\n",
      "  0.57262206 0.8971008  1.3315613  0.         0.50401986 0.\n",
      "  1.7487624  0.1805071  0.         0.9998569  0.         0.75426143\n",
      "  1.2534574  0.         0.900481   0.03178562 0.         0.\n",
      "  0.44573918 0.         0.         0.50628424 0.         0.\n",
      "  1.0701275  0.53990096 0.         0.         0.6624067  0.\n",
      "  0.6931446  1.3112575  0.         0.42772418 0.17736118 0.\n",
      "  0.         0.48914883 0.6117918  0.25254187 0.         1.0625266\n",
      "  0.         0.8912738  1.1686833  0.27126437 0.4118727  0.5170766\n",
      "  0.         0.         0.393738   0.         0.         0.\n",
      "  0.         0.6488249  1.3405911  0.7397407 ]]\n",
      "Hi!\n",
      "[[0.06788272 0.22424464 0.184119   0.         0.         0.11699584\n",
      "  0.         0.04874665 0.06350449 0.02673191 0.18641661 0.\n",
      "  0.19365662 0.10696965 0.         0.         0.         0.01383839\n",
      "  0.         0.22639267 0.11559923 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02188691 0.12893277 0.09147067 0.         0.         0.\n",
      "  0.         0.         0.23971668 0.09096441 0.         0.\n",
      "  0.         0.         0.17882627 0.23199938 0.         0.10582481\n",
      "  0.17748027 0.0491985  0.         0.20242646 0.05047448 0.43989944\n",
      "  0.         0.12173691 0.06355061 0.         0.00396475 0.\n",
      "  0.0590547  0.02416371 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.561453   0.02578037 0.         0.52194107 0.         0.5593693\n",
      "  1.3370004  1.7593861  0.05318581 0.         0.16738172 0.\n",
      "  0.5985097  0.92668825 0.         0.23564592 0.         0.4284475\n",
      "  0.         0.1838339  0.2227397  0.24464034 0.         0.17764804\n",
      "  0.         0.         0.         0.90678483 0.         0.\n",
      "  1.5361238  0.79497594 0.37375185 0.         0.8615876  0.\n",
      "  0.         0.8843445  0.29961205 0.14761291 0.29046333 0.\n",
      "  0.         0.4061362  1.3915601  1.4518366  0.         0.00207974\n",
      "  0.         0.9794363  0.16958448 0.69903296 1.0883927  0.75415486\n",
      "  0.         0.16404587 0.402033   0.         0.         0.\n",
      "  0.         0.47486508 0.91113377 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.10798667 0.09628469 0.         0.         0.1033325\n",
      "  0.         0.16333896 0.04124444 0.04719082 0.08763019 0.\n",
      "  0.06143434 0.09838971 0.         0.03229766 0.         0.01258144\n",
      "  0.         0.11367965 0.04900605 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06685224 0.12683693 0.         0.         0.\n",
      "  0.         0.         0.15491647 0.04966435 0.         0.\n",
      "  0.         0.         0.14807718 0.3156445  0.         0.02576979\n",
      "  0.09641518 0.0761847  0.         0.1581913  0.04771319 0.34437063\n",
      "  0.         0.07671491 0.04204655 0.         0.         0.\n",
      "  0.         0.16327433 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.76527315 0.         1.346608   0.06177257 0.         0.8245326\n",
      "  0.95999134 1.1225224  1.3246578  0.         0.5682387  0.\n",
      "  0.         0.         0.         0.7192952  0.5998614  0.89373064\n",
      "  0.         0.         1.251277   0.41938713 0.         0.7964228\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07703821 0.11046207 0.19745257 0.         0.11290715 0.\n",
      "  0.         1.0196182  0.         0.8434628  0.13948992 0.\n",
      "  0.         1.5790751  0.         0.3065181  0.         0.\n",
      "  0.         1.0387853  0.6046734  0.14422648 0.64216506 0.\n",
      "  0.         0.49048033 0.         0.4219986  0.         0.\n",
      "  0.         1.235867   1.186403   0.42950225]]\n",
      "Hi!\n",
      "[[0.2493213  0.         0.89714175 0.         0.         0.61908466\n",
      "  1.0138377  1.1758368  1.3685676  0.         0.51953524 0.\n",
      "  0.6741753  0.         0.         0.9282159  0.00913753 0.80424416\n",
      "  0.51512325 0.         1.012124   0.18332122 0.         0.2466323\n",
      "  0.14401592 0.         0.         0.32584867 0.         0.\n",
      "  0.65456575 0.22617188 0.         0.         0.49771747 0.\n",
      "  0.31325036 1.3645505  0.         0.5013081  0.2451414  0.\n",
      "  0.         1.1947507  0.07198277 0.3703555  0.         0.5032789\n",
      "  0.         0.75783235 0.8950997  0.29154125 0.438598   0.\n",
      "  0.         0.         0.12225145 0.32033336 0.         0.\n",
      "  0.         0.9713495  1.421848   0.58239186]]\n",
      "Hi!\n",
      "[[0.9870112  0.         1.2182666  0.42383155 0.         1.2761339\n",
      "  0.8831022  1.1122477  0.30237994 0.14648853 0.39472663 0.\n",
      "  0.         0.         0.         0.21765202 0.39206156 0.59289306\n",
      "  0.         0.32347116 0.80453    0.         0.         0.54106504\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3356999  0.30421776 0.         0.         0.\n",
      "  0.         0.40796185 0.         1.0274217  0.         0.\n",
      "  0.         0.95987046 0.05937795 0.8879616  0.         0.\n",
      "  0.25039777 1.3361781  0.         0.49863774 1.2309269  0.12870657\n",
      "  0.         1.5807652  0.         0.         0.         0.\n",
      "  0.386902   0.8570488  0.7097119  0.        ]]\n",
      "Hi!\n",
      "[[0.8397275  0.         1.325109   0.17951046 0.         0.95932883\n",
      "  0.87298954 1.1696233  1.0675844  0.         0.51879895 0.\n",
      "  0.         0.         0.         0.4786066  0.4507371  0.70892036\n",
      "  0.         0.         1.1323296  0.15236266 0.         0.73188525\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16334067 0.2731493  0.18979846 0.         0.02072527 0.\n",
      "  0.         0.91254824 0.         0.81598896 0.02956223 0.\n",
      "  0.         1.2271637  0.         0.52175736 0.         0.03416161\n",
      "  0.         1.0570973  0.44203502 0.32396296 0.79590744 0.\n",
      "  0.         0.77363676 0.         0.18840583 0.         0.\n",
      "  0.         1.0329089  1.2844551  0.26403818]]\n",
      "Hi!\n",
      "[[0.         0.15301275 0.3396819  0.         0.         0.2371659\n",
      "  0.         0.         0.17165379 0.13771534 0.20712861 0.\n",
      "  0.0107422  0.         0.         0.11292175 0.         0.04987345\n",
      "  0.         0.24367723 0.17422745 0.         0.         0.03485116\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06680948 0.         0.         0.\n",
      "  0.         0.         0.02271438 0.15445876 0.         0.\n",
      "  0.         0.         0.         0.17323153 0.         0.13676004\n",
      "  0.09389312 0.12608221 0.00260708 0.14461128 0.06505204 0.21078013\n",
      "  0.         0.09483323 0.         0.         0.03627869 0.\n",
      "  0.09390105 0.12715453 0.         0.10951061]]\n",
      "Hi!\n",
      "[[0.23440333 0.03694631 0.13682099 0.04735449 0.         0.35042334\n",
      "  1.3932818  1.4777906  0.68478143 0.         0.27199298 0.\n",
      "  0.7223336  0.27655077 0.         0.67724097 0.         0.711955\n",
      "  0.04766181 0.         0.47159654 0.09405317 0.         0.\n",
      "  0.25165907 0.         0.         0.49385273 0.         0.\n",
      "  1.1440438  0.30501723 0.         0.         0.7795116  0.\n",
      "  0.20509097 1.3160325  0.         0.30271626 0.13464439 0.\n",
      "  0.         0.7292974  0.71625054 0.82918847 0.         0.20381933\n",
      "  0.         0.87745225 0.71144116 0.41840836 0.5309396  0.31259716\n",
      "  0.         0.         0.2674946  0.         0.         0.\n",
      "  0.         0.7780671  0.93792737 0.03127375]]\n",
      "Hi!\n",
      "[[0.532784   0.12125145 0.         0.40793684 0.         0.51084137\n",
      "  1.3329788  1.7758816  0.35705107 0.         0.21859682 0.\n",
      "  1.1840988  0.8686325  0.         0.51737154 0.         0.5646119\n",
      "  0.3902972  0.         0.34395203 0.3288579  0.         0.\n",
      "  0.29197344 0.         0.         0.88147163 0.         0.\n",
      "  1.560577   0.80667824 0.12359476 0.         0.96614325 0.\n",
      "  0.39953646 1.3276861  0.1572762  0.142382   0.25503084 0.\n",
      "  0.         0.5004886  1.4057246  1.2871671  0.         0.46883973\n",
      "  0.         0.8228147  0.6416936  0.62573063 0.8386233  0.97452956\n",
      "  0.         0.         0.56775784 0.         0.         0.\n",
      "  0.         0.43041456 1.1447672  0.        ]]\n",
      "Hi!\n",
      "[[0.751504   0.35339868 1.7209628  0.         0.         0.82323724\n",
      "  0.16171612 0.0668893  1.2110894  0.         0.7576513  0.\n",
      "  0.42144957 0.         0.         0.70556474 0.65446377 0.8970277\n",
      "  0.         0.16226485 1.3457335  0.281776   0.         0.5005789\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18114048 0.02736434 0.         0.         0.\n",
      "  0.06754784 0.7270354  0.         1.0016873  0.09027918 0.\n",
      "  0.         0.90665925 0.         0.03535341 0.         0.66183436\n",
      "  0.06609514 0.931128   0.69530183 0.11646218 0.35845044 0.15199174\n",
      "  0.         0.34861612 0.         0.633251   0.08851478 0.\n",
      "  0.         0.91761994 0.8289377  0.9535818 ]]\n",
      "Hi!\n",
      "[[0.78182095 0.6979129  1.5997473  0.         0.         1.185745\n",
      "  0.         0.         0.36286417 0.02300469 0.6177475  0.\n",
      "  0.51840776 0.         0.         0.09401391 0.31756458 0.4973769\n",
      "  0.         0.9990474  0.9519002  0.         0.         0.21135595\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.55920917 0.05572524 0.         0.         0.\n",
      "  0.         0.20389283 0.         0.8022693  0.         0.\n",
      "  0.         0.         0.3238645  0.30766532 0.         0.8017729\n",
      "  0.6961609  0.71107507 0.1306161  0.46277606 0.6626099  0.86012465\n",
      "  0.         1.0858055  0.         0.         0.18921778 0.\n",
      "  0.23481196 0.27982783 0.78020257 0.4141799 ]]\n",
      "Hi!\n",
      "[[3.70083570e-01 3.67085248e-01 4.76361692e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.73424935e-01 3.52878988e-01 5.42298377e-01\n",
      "  5.86480908e-02 0.00000000e+00 2.98768878e-01 0.00000000e+00\n",
      "  4.64240760e-01 1.81338862e-01 0.00000000e+00 1.05819754e-01\n",
      "  0.00000000e+00 4.31431055e-01 0.00000000e+00 5.12200832e-01\n",
      "  3.39518219e-01 0.00000000e+00 0.00000000e+00 3.15982476e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.40132134e-02\n",
      "  0.00000000e+00 0.00000000e+00 6.18476272e-01 5.29028714e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.60817355e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.12904525e-01 2.94063939e-04 3.01374793e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.85576789e-02\n",
      "  6.38942301e-01 7.45617807e-01 0.00000000e+00 3.83887112e-01\n",
      "  2.49209732e-01 6.67004883e-01 1.42858967e-01 4.04127985e-01\n",
      "  4.22518730e-01 6.69553936e-01 0.00000000e+00 3.42123687e-01\n",
      "  1.18060201e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.13105792e-01 4.10198957e-01 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.67400026 0.38306642 0.28761408 0.31744748 0.         0.5487804\n",
      "  0.5783945  0.67976385 0.         0.         0.01205725 0.\n",
      "  0.37529603 0.50406265 0.         0.09401354 0.         0.0723691\n",
      "  0.         0.7231765  0.00995154 0.         0.         0.10672767\n",
      "  0.         0.         0.         0.4485945  0.         0.\n",
      "  0.819882   0.8924756  0.34314346 0.         0.11312765 0.\n",
      "  0.         0.32161075 0.5532284  0.1287096  0.         0.\n",
      "  0.         0.2608658  1.0351436  0.96357566 0.         0.31291476\n",
      "  0.58146507 0.59503007 0.         0.5782013  0.5961359  1.1962119\n",
      "  0.         0.74890983 0.3516657  0.         0.         0.\n",
      "  0.         0.12448922 0.38276988 0.        ]]\n",
      "Hi!\n",
      "[[0.03891361 0.3230501  0.26428366 0.         0.         0.1757645\n",
      "  0.         0.01915175 0.02625182 0.0184551  0.17923553 0.\n",
      "  0.24110241 0.16082618 0.         0.         0.         0.08358804\n",
      "  0.         0.27619445 0.12667018 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05343808 0.2221684  0.085003   0.         0.         0.\n",
      "  0.         0.         0.178073   0.13446486 0.         0.\n",
      "  0.         0.         0.21619119 0.21239053 0.         0.1632416\n",
      "  0.2746859  0.13172856 0.         0.20392531 0.07780948 0.47187972\n",
      "  0.         0.10862859 0.07011847 0.         0.02743493 0.\n",
      "  0.07949744 0.08206201 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.04118625 0.14735328 0.00474963 0.00682756 0.         0.10366652\n",
      "  0.11650459 0.26631013 0.         0.08105241 0.05620138 0.\n",
      "  0.02733415 0.24306263 0.         0.01230217 0.         0.05826252\n",
      "  0.         0.18139009 0.00091356 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15059955 0.20607314 0.244178   0.         0.         0.\n",
      "  0.         0.01048261 0.12847307 0.11489476 0.         0.\n",
      "  0.         0.         0.31489313 0.4375459  0.         0.\n",
      "  0.17584099 0.22711648 0.         0.1784463  0.09342358 0.35282815\n",
      "  0.         0.1656132  0.07348405 0.         0.         0.\n",
      "  0.08799728 0.11464265 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.26128238 0.11565231 0.84157515 0.         0.         0.63453275\n",
      "  0.79474527 0.856982   0.9519525  0.         0.53401995 0.\n",
      "  0.72830975 0.         0.         0.7065178  0.         0.82524115\n",
      "  0.3702079  0.         0.86430085 0.         0.         0.\n",
      "  0.23900427 0.         0.         0.24584574 0.         0.\n",
      "  0.6667214  0.37028354 0.         0.         0.5290716  0.\n",
      "  0.32841995 1.214273   0.         0.52029496 0.13971546 0.\n",
      "  0.         0.6559358  0.42078042 0.46579197 0.         0.6412546\n",
      "  0.         0.6717465  0.74191856 0.2841277  0.4143439  0.3461215\n",
      "  0.         0.         0.20452897 0.04277579 0.         0.\n",
      "  0.         0.8703523  1.2104578  0.49339458]]\n",
      "Hi!\n",
      "[[1.0054806  0.         1.614053   0.05840568 0.         0.8587446\n",
      "  0.8026177  0.81475055 1.2666059  0.         0.62242705 0.\n",
      "  0.         0.         0.         0.6154912  0.9926736  0.913906\n",
      "  0.         0.         1.3324841  0.62711006 0.         0.7989176\n",
      "  0.04476381 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.21699671 0.         0.         0.\n",
      "  0.         0.7865974  0.         1.0470381  0.15616243 0.\n",
      "  0.         1.9173604  0.         0.23182611 0.         0.\n",
      "  0.         1.1623943  0.5814019  0.         0.50672555 0.\n",
      "  0.         0.75495315 0.         0.6547907  0.         0.\n",
      "  0.07790242 1.3199079  0.7236493  0.45592734]]\n",
      "Hi!\n",
      "[[0.         0.07917627 0.21588068 0.         0.         0.17515859\n",
      "  0.         0.0779334  0.1298636  0.16283575 0.19012056 0.\n",
      "  0.         0.         0.         0.08295168 0.         0.03906254\n",
      "  0.         0.20807348 0.16202797 0.         0.         0.00330572\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09017476 0.         0.         0.\n",
      "  0.         0.         0.0262627  0.15039948 0.         0.\n",
      "  0.         0.         0.01372327 0.25975165 0.         0.12870574\n",
      "  0.10315494 0.08274043 0.         0.17093961 0.01513219 0.16430575\n",
      "  0.         0.11484299 0.         0.         0.03850124 0.\n",
      "  0.0793643  0.15003242 0.         0.04511515]]\n",
      "Hi!\n",
      "[[0.23820151 0.00231167 0.21863738 0.01500362 0.         0.40181708\n",
      "  1.4423853  1.2510946  0.64211684 0.         0.30259782 0.\n",
      "  0.44270748 0.08468217 0.         0.6455736  0.         0.8333751\n",
      "  0.         0.         0.4976324  0.12546852 0.         0.\n",
      "  0.35660627 0.         0.         0.3172694  0.         0.\n",
      "  0.88192374 0.17295526 0.         0.         0.823143   0.\n",
      "  0.32769305 1.3433338  0.         0.33754584 0.11880153 0.\n",
      "  0.         0.7693492  0.6818319  0.76211    0.         0.40400997\n",
      "  0.         0.79401106 0.66202694 0.3155245  0.3102887  0.36041546\n",
      "  0.         0.         0.31842166 0.         0.         0.\n",
      "  0.         0.89178354 0.81128746 0.07232217]]\n",
      "Hi!\n",
      "[[0.38828036 0.1738704  1.030085   0.         0.         0.9745949\n",
      "  0.6251733  0.7487224  0.804279   0.         0.5019812  0.\n",
      "  0.57835084 0.         0.         0.45752493 0.         0.74356264\n",
      "  0.13292682 0.12479845 0.91790646 0.         0.         0.06314714\n",
      "  0.12143309 0.         0.         0.         0.         0.\n",
      "  0.40441823 0.3885014  0.         0.         0.31050253 0.\n",
      "  0.16232511 0.9874411  0.         0.55184543 0.         0.\n",
      "  0.         0.6000221  0.36457348 0.4749171  0.         0.7733605\n",
      "  0.         0.67404217 0.51649934 0.4274941  0.4322392  0.5148691\n",
      "  0.         0.1795352  0.03452773 0.0568738  0.         0.\n",
      "  0.         0.74810714 1.0652876  0.48855135]]\n",
      "Hi!\n",
      "[[0.69333756 0.         0.81223565 0.37516823 0.         0.7907095\n",
      "  1.5880393  1.3694155  0.5310018  0.         0.3609057  0.\n",
      "  0.         0.         0.         0.29598215 0.3677899  0.7694719\n",
      "  0.         0.         0.72598076 0.29293954 0.         0.26365525\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10920504 0.1273892  0.28976694 0.         0.23350003 0.\n",
      "  0.         0.8321534  0.         0.80285525 0.16873844 0.\n",
      "  0.         1.4002396  0.         0.713373   0.         0.\n",
      "  0.         1.0136918  0.16285431 0.20579751 0.58904785 0.\n",
      "  0.         0.6518639  0.         0.         0.         0.\n",
      "  0.02440374 1.1875403  0.6416854  0.        ]]\n",
      "Hi!\n",
      "[[0.02295592 0.2228479  0.19748151 0.         0.         0.16331846\n",
      "  0.         0.05793118 0.02460997 0.01017153 0.12180332 0.\n",
      "  0.20993976 0.14872074 0.         0.00671967 0.         0.02566356\n",
      "  0.         0.20608526 0.10433444 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06867705 0.20720316 0.10489781 0.         0.         0.\n",
      "  0.         0.         0.26009873 0.04554894 0.         0.\n",
      "  0.         0.         0.20987757 0.2514668  0.         0.12200267\n",
      "  0.22038227 0.06813893 0.         0.2473115  0.12048214 0.47897235\n",
      "  0.         0.11603308 0.08825962 0.         0.         0.\n",
      "  0.01388548 0.06523813 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.32955846 0.26551566 0.38110307 0.         0.         0.5518787\n",
      "  0.69118947 0.81799954 0.16840373 0.         0.31455344 0.\n",
      "  0.4435244  0.2261817  0.         0.18035428 0.         0.5264156\n",
      "  0.         0.3558033  0.38737094 0.         0.         0.\n",
      "  0.         0.         0.         0.18912429 0.         0.\n",
      "  0.7756639  0.4936015  0.         0.         0.35341823 0.\n",
      "  0.         0.66670334 0.         0.28032577 0.         0.\n",
      "  0.         0.09965911 0.650015   0.86434853 0.         0.2271427\n",
      "  0.07506482 0.7920824  0.27934802 0.44147047 0.54698294 0.56419337\n",
      "  0.         0.19416028 0.09976226 0.         0.         0.\n",
      "  0.         0.40893102 0.48041427 0.        ]]\n",
      "Hi!\n",
      "[[0.17493759 0.48464903 0.2808188  0.         0.         0.34394026\n",
      "  0.         0.09075423 0.         0.         0.22040907 0.\n",
      "  0.39076695 0.30656707 0.         0.         0.         0.0998067\n",
      "  0.         0.46207714 0.15459847 0.         0.         0.06551463\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23214607 0.35450494 0.07183546 0.         0.         0.\n",
      "  0.         0.         0.30902943 0.10262773 0.         0.\n",
      "  0.         0.         0.38071984 0.35371444 0.         0.21995144\n",
      "  0.36131415 0.28597507 0.         0.3088634  0.25100505 0.6444959\n",
      "  0.         0.17977168 0.13923989 0.         0.05520295 0.\n",
      "  0.14945132 0.08443914 0.04363442 0.        ]]\n",
      "Hi!\n",
      "[[0.35737994 0.6650995  0.7272872  0.00253041 0.         0.7831578\n",
      "  0.02303377 0.46050692 0.         0.00925378 0.33532923 0.\n",
      "  0.43949494 0.3528366  0.         0.         0.         0.34693128\n",
      "  0.         0.91371393 0.4180571  0.         0.         0.18732633\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.59146684 0.65160674 0.07988409 0.         0.         0.\n",
      "  0.         0.04965543 0.28923473 0.29897046 0.         0.\n",
      "  0.         0.         0.7468172  0.890125   0.         0.22718148\n",
      "  0.56218934 0.80373186 0.         0.5616765  0.8961598  0.7812778\n",
      "  0.         0.6179495  0.         0.         0.04206199 0.\n",
      "  0.10375057 0.31612998 0.22127084 0.        ]]\n",
      "Hi!\n",
      "[[0.03658804 0.15274714 0.         0.01616985 0.         0.18585145\n",
      "  0.21021701 0.31875554 0.         0.05271373 0.0577679  0.\n",
      "  0.         0.23098783 0.         0.         0.         0.07609567\n",
      "  0.         0.19354713 0.00237123 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14340836 0.22238636 0.2605551  0.         0.         0.\n",
      "  0.         0.02615514 0.23763433 0.0758705  0.         0.\n",
      "  0.         0.         0.30926165 0.52782774 0.         0.03622698\n",
      "  0.20269762 0.2632007  0.         0.23660652 0.09093903 0.46627006\n",
      "  0.         0.24158987 0.10170943 0.         0.         0.\n",
      "  0.09782357 0.1598778  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.2444631  0.5328706  0.5865934  0.         0.         0.621844\n",
      "  0.         0.11985403 0.         0.05830854 0.29746038 0.\n",
      "  0.3085894  0.13086879 0.         0.         0.         0.32260188\n",
      "  0.         0.77114934 0.31974807 0.         0.         0.06420717\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26464957 0.4749599  0.         0.         0.         0.\n",
      "  0.         0.04045054 0.10320909 0.34501824 0.         0.\n",
      "  0.         0.         0.5228121  0.6213687  0.         0.48437035\n",
      "  0.53036034 0.5470876  0.         0.388495   0.36548114 0.7211311\n",
      "  0.         0.5935683  0.01449218 0.         0.06634076 0.\n",
      "  0.21071172 0.21820265 0.1444527  0.        ]]\n",
      "Hi!\n",
      "[[0.67277354 0.32019663 1.2097365  0.         0.         0.9375093\n",
      "  0.05465027 0.30160788 0.14743787 0.01918624 0.44271874 0.\n",
      "  0.11103803 0.         0.         0.01081471 0.08094684 0.46329826\n",
      "  0.         0.69636464 0.74059474 0.         0.         0.21488002\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10900746 0.56628406 0.10580514 0.         0.         0.\n",
      "  0.         0.25922248 0.         0.66482514 0.         0.\n",
      "  0.         0.10356165 0.31302136 0.5704546  0.         0.30963057\n",
      "  0.46296805 0.7263801  0.         0.43873426 0.68272305 0.5007763\n",
      "  0.         0.9502964  0.         0.         0.07126657 0.\n",
      "  0.23381765 0.4103453  0.6199571  0.02905079]]\n",
      "Hi!\n",
      "[[0.97486013 1.0069216  0.6108789  0.23822024 0.         0.7148735\n",
      "  0.         0.67157286 0.         0.         0.31471962 0.\n",
      "  1.4440746  0.8314383  0.         0.03655341 0.         0.341624\n",
      "  0.1301862  1.0014926  0.3372907  0.         0.         0.33637482\n",
      "  0.         0.         0.         0.60532683 0.         0.\n",
      "  1.3012393  1.1767548  0.12796845 0.         0.43608478 0.\n",
      "  0.30052605 0.4040884  1.0098413  0.2503868  0.         0.\n",
      "  0.         0.3711125  1.5254972  0.98743284 0.         0.72335076\n",
      "  0.54493    0.6884301  0.11155977 0.7600667  0.7396034  1.5245525\n",
      "  0.         0.52294666 0.5224525  0.         0.01436519 0.\n",
      "  0.         0.11676818 0.8176357  0.        ]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40007392 1.4278886  0.89050716 0.         0.         0.46932393\n",
      "  0.         0.06423836 0.634969   0.         0.5728295  0.\n",
      "  2.0389316  0.40762156 0.         0.4704337  0.         0.59604454\n",
      "  0.7151509  0.90059555 0.6591968  0.         0.         0.18074957\n",
      "  0.02403078 0.         0.         0.32184184 0.         0.\n",
      "  0.8165289  0.728899   0.         0.         0.24955544 0.\n",
      "  0.22512735 0.4001013  0.4509732  0.48023552 0.         0.\n",
      "  0.         0.06753355 0.71508086 0.29962903 0.         1.0507652\n",
      "  0.10856222 0.8134789  0.84284574 0.33424476 0.6425174  1.1334612\n",
      "  0.         0.         0.33385423 0.         0.1423012  0.\n",
      "  0.         0.37475398 0.6321004  0.60807425]]\n",
      "Hi!\n",
      "[[0.04034036 0.10282084 0.1965883  0.         0.         0.12085349\n",
      "  0.         0.06571887 0.1109089  0.         0.08196053 0.\n",
      "  0.17974356 0.         0.         0.07985254 0.         0.\n",
      "  0.         0.13771562 0.12903413 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09156202 0.07171125 0.         0.         0.\n",
      "  0.         0.         0.0366341  0.08040535 0.         0.\n",
      "  0.         0.016597   0.03206179 0.         0.         0.14347325\n",
      "  0.         0.05266007 0.01569829 0.11702496 0.01689145 0.18639272\n",
      "  0.         0.         0.06803755 0.         0.05002457 0.\n",
      "  0.04481754 0.         0.         0.04327722]]\n",
      "Hi!\n",
      "[[0.39963454 0.44370666 0.32305253 0.         0.         0.34551343\n",
      "  0.8637245  1.2143418  1.0614249  0.         0.42807442 0.\n",
      "  1.7003399  0.486382   0.         0.9538869  0.         0.75093144\n",
      "  1.1000193  0.         0.63037044 0.22204082 0.         0.\n",
      "  0.53124547 0.         0.         0.7239953  0.         0.\n",
      "  1.2719853  0.61414486 0.         0.         0.89356935 0.\n",
      "  0.7824098  1.4560429  0.         0.26231408 0.1963077  0.\n",
      "  0.         0.48815966 0.9767373  0.6087399  0.         0.94288254\n",
      "  0.         0.72378016 1.1616445  0.4101902  0.44158277 0.8169257\n",
      "  0.         0.         0.5569074  0.         0.         0.\n",
      "  0.         0.5704819  1.3153923  0.40090293]]\n",
      "Hi!\n",
      "[[0.5534046  0.9127757  0.3123685  0.         0.         0.40947145\n",
      "  0.40109095 0.8977147  0.6442063  0.         0.3524195  0.\n",
      "  1.937852   0.8048506  0.         0.6959306  0.         0.6388031\n",
      "  0.9334389  0.38354322 0.49455538 0.13248888 0.         0.0591274\n",
      "  0.40555295 0.         0.         0.62700677 0.         0.\n",
      "  1.2400109  0.8932165  0.         0.         0.64537275 0.\n",
      "  0.7095108  1.1514603  0.30154893 0.38977447 0.         0.\n",
      "  0.         0.46062332 1.1917323  0.5963836  0.         1.1631376\n",
      "  0.         0.73865074 0.969455   0.41500512 0.443998   1.2414743\n",
      "  0.         0.         0.5624919  0.         0.         0.\n",
      "  0.         0.3359195  0.86374784 0.31078392]]\n",
      "Hi!\n",
      "[[0.51412535 0.02491817 0.01814842 0.3222189  0.         0.65818554\n",
      "  1.1506106  1.0538274  0.         0.         0.02675223 0.\n",
      "  0.04932756 0.3666539  0.         0.14098623 0.         0.3139999\n",
      "  0.         0.47471184 0.03606845 0.09536389 0.         0.\n",
      "  0.         0.         0.         0.35073203 0.         0.\n",
      "  0.7825305  0.6290822  0.38868132 0.         0.37583032 0.\n",
      "  0.11396589 0.737719   0.17270276 0.25568983 0.05774472 0.\n",
      "  0.         0.33957887 1.1143894  1.1699713  0.         0.29179573\n",
      "  0.29643142 0.79378384 0.         0.57331175 0.45259193 1.0675505\n",
      "  0.         0.54089624 0.38306174 0.         0.         0.\n",
      "  0.         0.2680654  0.42848507 0.        ]]\n",
      "Hi!\n",
      "[[0.03110252 0.19586629 0.3862122  0.         0.         0.19676304\n",
      "  0.         0.         0.16019979 0.10875807 0.24977943 0.\n",
      "  0.06624119 0.         0.         0.11499274 0.         0.05133568\n",
      "  0.         0.32424456 0.21440682 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03808572 0.02675916 0.         0.         0.\n",
      "  0.         0.         0.         0.18185961 0.         0.\n",
      "  0.         0.         0.         0.1488061  0.         0.18020648\n",
      "  0.18420182 0.10194895 0.03055219 0.18974125 0.06185615 0.24859804\n",
      "  0.         0.07389309 0.         0.         0.1202125  0.\n",
      "  0.08066799 0.08748853 0.         0.11840398]]\n",
      "Hi!\n",
      "[[0.52905405 0.         0.58423185 0.5280117  0.         0.7521342\n",
      "  2.4304135  2.4482226  1.1232638  0.         0.30100748 0.\n",
      "  0.         0.         0.         0.7609676  0.05153175 0.8941369\n",
      "  0.         0.         0.79925686 0.33183888 0.         0.28570414\n",
      "  0.02026825 0.         0.         0.44908687 0.         0.\n",
      "  0.83204645 0.0882784  0.26222017 0.         0.7438228  0.\n",
      "  0.         1.5591396  0.         0.7019322  0.51447344 0.\n",
      "  0.         1.9237052  0.1528909  0.894034   0.         0.\n",
      "  0.         0.9531137  0.51140577 0.41031    0.91593874 0.\n",
      "  0.         0.28161398 0.03888132 0.01899183 0.         0.\n",
      "  0.         1.3530282  1.6401913  0.        ]]\n",
      "Hi!\n",
      "[[0.6114188  0.0831072  1.4300433  0.         0.         0.97803944\n",
      "  0.44888973 0.5692818  1.0627781  0.         0.6328683  0.\n",
      "  0.4945611  0.         0.         0.6298488  0.30046514 0.8153845\n",
      "  0.1710869  0.         1.1933769  0.11060636 0.         0.3503887\n",
      "  0.10039767 0.         0.         0.         0.         0.\n",
      "  0.13508427 0.35623348 0.         0.         0.13344465 0.\n",
      "  0.17876486 0.9857062  0.         0.7125818  0.06650937 0.\n",
      "  0.         0.8744828  0.0438708  0.25968122 0.         0.76990384\n",
      "  0.         0.69849455 0.6117134  0.29853985 0.37346926 0.31735936\n",
      "  0.         0.30907735 0.         0.4037526  0.         0.\n",
      "  0.         0.8663701  1.2297013  0.7128479 ]]\n",
      "Hi!\n",
      "[[0.62488395 0.         0.99330854 0.1237991  0.         0.70268273\n",
      "  1.2218639  1.2850342  0.96211654 0.         0.45008832 0.\n",
      "  0.         0.         0.         0.6548138  0.26632765 0.80427784\n",
      "  0.         0.         0.96223825 0.14229155 0.         0.4597302\n",
      "  0.         0.         0.         0.04071469 0.         0.\n",
      "  0.37110424 0.17466821 0.14716911 0.         0.3250766  0.\n",
      "  0.         1.0603126  0.         0.6886537  0.0978742  0.\n",
      "  0.         1.3092351  0.         0.5259984  0.         0.\n",
      "  0.         0.9710579  0.45914298 0.26215512 0.69664806 0.\n",
      "  0.         0.35539806 0.         0.09840823 0.         0.\n",
      "  0.         1.1287205  1.1157587  0.08790409]]\n",
      "Hi!\n",
      "[[0.5773583  0.523028   1.3065388  0.         0.         1.0280555\n",
      "  0.         0.09481807 0.         0.         0.44292736 0.\n",
      "  0.4696392  0.         0.         0.         0.06617391 0.37644237\n",
      "  0.         0.9894148  0.62451166 0.         0.         0.00542918\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20524944 0.7957067  0.06491765 0.         0.         0.\n",
      "  0.         0.20669152 0.16907643 0.57299536 0.         0.\n",
      "  0.         0.         0.60163826 0.5717389  0.         0.7340117\n",
      "  0.7245212  0.50484425 0.         0.52717316 0.66126156 0.9565306\n",
      "  0.         1.0238804  0.03478683 0.         0.1398314  0.\n",
      "  0.21984856 0.1465352  0.8012582  0.06334254]]\n",
      "Hi!\n",
      "[[0.1068722  0.22280751 0.16146463 0.         0.         0.32737982\n",
      "  0.03307639 0.23119049 0.         0.11644113 0.15931606 0.\n",
      "  0.01555385 0.21084163 0.         0.         0.         0.07734173\n",
      "  0.         0.34051645 0.05475703 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08467189 0.22009256 0.16248266 0.         0.         0.\n",
      "  0.         0.         0.13286729 0.15962079 0.         0.\n",
      "  0.         0.         0.3008352  0.4818174  0.         0.098441\n",
      "  0.29481217 0.34085354 0.         0.30422145 0.25255007 0.4839127\n",
      "  0.         0.29643315 0.00364243 0.         0.         0.\n",
      "  0.10693788 0.13901184 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.66365874 0.67833203 0.7591082  0.0025599  0.         0.75653785\n",
      "  0.03900335 0.34465885 0.02167898 0.         0.32844782 0.\n",
      "  0.89920604 0.3045425  0.         0.06992538 0.         0.34989685\n",
      "  0.         0.84411913 0.39157712 0.         0.         0.13812985\n",
      "  0.         0.         0.         0.26674774 0.         0.\n",
      "  0.7240471  0.8116806  0.         0.         0.12567881 0.\n",
      "  0.17840843 0.4283232  0.37381345 0.3265164  0.         0.\n",
      "  0.         0.08442087 0.9282316  0.697023   0.         0.78189397\n",
      "  0.48349476 0.51905394 0.12554628 0.5069006  0.56059885 1.1297151\n",
      "  0.         0.5076278  0.24778585 0.         0.0216138  0.\n",
      "  0.         0.06911895 0.7086666  0.        ]]\n",
      "Hi!\n",
      "[[3.6873966e-01 6.3950825e-01 8.1918383e-01 0.0000000e+00 0.0000000e+00\n",
      "  7.3124141e-01 3.2787088e-01 2.4938802e-01 7.2323805e-01 3.8074210e-02\n",
      "  4.5738369e-01 0.0000000e+00 4.3074551e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.9638474e-01 4.4033684e-02 5.1072335e-01 0.0000000e+00 5.1037812e-01\n",
      "  6.9065255e-01 5.7157404e-03 0.0000000e+00 1.3146126e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.3553001e-01 1.2949817e-01 6.4334151e-04 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 3.2380781e-01 0.0000000e+00 4.6784317e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1434274e-01 3.5071783e-02\n",
      "  2.5157481e-01 0.0000000e+00 5.2124810e-01 3.7970703e-02 6.9345945e-01\n",
      "  4.1978458e-01 2.0253602e-01 3.5916892e-01 2.2307502e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0676129e-01 0.0000000e+00\n",
      "  1.5249965e-01 7.7797490e-01 2.6858339e-01 5.3827322e-01]]\n",
      "Hi!\n",
      "[[1.016683   0.20722063 1.6112915  0.         0.         1.1072094\n",
      "  0.25460225 0.37937135 0.7491828  0.08970768 0.5922411  0.\n",
      "  0.         0.         0.         0.1852564  0.587184   0.7132673\n",
      "  0.         0.31462651 1.1446762  0.08087511 0.         0.6428298\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2617112  0.13396096 0.         0.         0.\n",
      "  0.         0.39646378 0.         0.8875418  0.         0.\n",
      "  0.         0.87132317 0.         0.34835437 0.         0.31710887\n",
      "  0.27741387 1.0300988  0.3016944  0.26124075 0.68218666 0.17698097\n",
      "  0.         1.0965014  0.         0.22968729 0.07098909 0.\n",
      "  0.2606712  0.77571344 0.6474386  0.49212372]]\n",
      "Hi!\n",
      "[[0.5782509  0.115169   0.9258008  0.18770008 0.         1.0633764\n",
      "  0.6000141  0.72994864 0.         0.         0.32522845 0.\n",
      "  0.056846   0.         0.         0.06667461 0.         0.42066622\n",
      "  0.         0.68546313 0.5718662  0.         0.         0.\n",
      "  0.         0.         0.         0.00848066 0.         0.\n",
      "  0.3892733  0.7553138  0.0591926  0.         0.09031443 0.\n",
      "  0.         0.52970177 0.         0.43592042 0.         0.\n",
      "  0.         0.03993932 0.7065657  0.87633055 0.         0.44338793\n",
      "  0.46892303 0.6987094  0.         0.622834   0.7294312  0.7874196\n",
      "  0.         1.0310942  0.11745296 0.         0.         0.\n",
      "  0.04302894 0.30680484 0.874722   0.        ]]\n",
      "Hi!\n",
      "[[0.60481566 0.52163255 0.32469177 0.12530291 0.         0.588557\n",
      "  0.6426654  1.1112373  0.49818373 0.         0.3477558  0.\n",
      "  1.5025756  0.67026407 0.         0.5401908  0.         0.5938392\n",
      "  0.6866881  0.27437904 0.49857473 0.10277139 0.         0.05069992\n",
      "  0.26687497 0.         0.         0.70766425 0.         0.\n",
      "  1.2426633  0.8732539  0.         0.         0.6891002  0.\n",
      "  0.6151649  1.14285    0.2433773  0.18423326 0.0491344  0.\n",
      "  0.         0.33524013 1.2897897  0.8005821  0.         0.9042888\n",
      "  0.         0.61311907 0.7059149  0.5123896  0.5474854  1.0971411\n",
      "  0.         0.         0.5390053  0.         0.         0.\n",
      "  0.         0.2818916  1.1073916  0.05990076]]\n",
      "Hi!\n",
      "[[0.5272786  0.14840122 0.92495424 0.         0.         0.76240927\n",
      "  0.6161843  0.7024154  0.61250556 0.05675777 0.44448102 0.\n",
      "  0.07407493 0.         0.         0.2819263  0.06578764 0.70027274\n",
      "  0.         0.1568855  0.79993176 0.         0.         0.26504195\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23092857 0.24470572 0.08307327 0.         0.12050062 0.\n",
      "  0.         0.6209156  0.         0.67368597 0.         0.\n",
      "  0.         0.63749313 0.09648841 0.5458317  0.         0.15479779\n",
      "  0.01551439 0.94744205 0.3199857  0.34196287 0.5848084  0.20725511\n",
      "  0.         0.4237759  0.         0.         0.         0.\n",
      "  0.         0.82746583 0.601327   0.20973428]]\n",
      "Hi!\n",
      "[[0.392018   0.13391595 0.68722826 0.01606299 0.         0.71868414\n",
      "  0.7322483  0.7712746  0.36611262 0.         0.35466087 0.\n",
      "  0.33923876 0.         0.         0.32902265 0.         0.5925043\n",
      "  0.         0.29612303 0.5970065  0.         0.         0.\n",
      "  0.05999878 0.         0.         0.09941086 0.         0.\n",
      "  0.593927   0.47028553 0.         0.         0.32458997 0.\n",
      "  0.13815849 0.91738033 0.         0.47871345 0.         0.\n",
      "  0.         0.3311681  0.5873911  0.6633449  0.         0.51963\n",
      "  0.         0.6533013  0.31644464 0.34487167 0.34067485 0.6425681\n",
      "  0.         0.24531728 0.21543731 0.         0.         0.\n",
      "  0.         0.5566913  0.81786215 0.01137946]]\n",
      "Hi!\n",
      "[[0.61494875 0.2609431  0.         0.43716303 0.         0.5375105\n",
      "  1.1314634  1.5208787  0.         0.         0.15043649 0.\n",
      "  0.8856208  0.9615213  0.         0.15919551 0.         0.40344968\n",
      "  0.         0.31711492 0.22759098 0.19052875 0.         0.09272966\n",
      "  0.02170047 0.         0.         0.76776105 0.         0.\n",
      "  1.4205803  0.8866253  0.33007625 0.         0.72472626 0.\n",
      "  0.09363247 0.91779625 0.32643268 0.17448449 0.19531053 0.\n",
      "  0.         0.400298   1.4749029  1.3851097  0.         0.3508828\n",
      "  0.14918026 0.890782   0.23866601 0.6693943  0.87798387 1.1050091\n",
      "  0.         0.15331852 0.49581686 0.         0.         0.\n",
      "  0.         0.29832578 0.71714246 0.        ]]\n",
      "Hi!\n",
      "[[0.05507635 0.15533195 0.         0.         0.         0.18266183\n",
      "  1.1476169  1.1220886  0.32447195 0.         0.17728235 0.\n",
      "  0.34931126 0.34874886 0.         0.47248918 0.         0.59382313\n",
      "  0.         0.07773601 0.12072317 0.04496685 0.         0.\n",
      "  0.18817693 0.         0.         0.19766697 0.         0.\n",
      "  0.7732519  0.15404882 0.07763498 0.         0.54828256 0.\n",
      "  0.13242295 0.93908376 0.         0.3366277  0.03907942 0.\n",
      "  0.         0.48838168 0.49204165 0.7810862  0.         0.10251848\n",
      "  0.         0.7521548  0.5345026  0.23038405 0.23948616 0.32881352\n",
      "  0.         0.         0.1805623  0.         0.         0.\n",
      "  0.         0.70771235 0.23944525 0.        ]]\n",
      "Hi!\n",
      "[[0.5955619  0.37169632 0.9435705  0.         0.         1.0012888\n",
      "  0.3550586  0.47245598 0.28720114 0.         0.40991268 0.\n",
      "  0.8096451  0.         0.         0.25327876 0.         0.5836043\n",
      "  0.1373054  0.5308983  0.699449   0.         0.         0.\n",
      "  0.01614481 0.         0.         0.20397268 0.         0.\n",
      "  0.5605561  0.68789804 0.         0.         0.20708074 0.\n",
      "  0.3228245  0.7980353  0.03693717 0.56730145 0.         0.\n",
      "  0.         0.17298475 0.74828404 0.6080568  0.         1.063806\n",
      "  0.24158205 0.56425035 0.34557864 0.50468045 0.3219452  1.0580091\n",
      "  0.         0.4962475  0.2590654  0.         0.         0.\n",
      "  0.         0.30922854 1.0206985  0.21451548]]\n",
      "Hi!\n",
      "[[0.39665145 0.16323985 0.4284213  0.09694716 0.         0.57345045\n",
      "  0.87837005 1.3534139  0.73529476 0.         0.38287845 0.\n",
      "  1.1145906  0.33409354 0.         0.6097206  0.         0.6032814\n",
      "  0.43353853 0.         0.65822977 0.06204376 0.         0.\n",
      "  0.10286222 0.         0.         0.7004813  0.         0.\n",
      "  1.2055227  0.61912423 0.         0.         0.7115929  0.\n",
      "  0.28113756 1.1585432  0.         0.16703233 0.13181643 0.\n",
      "  0.         0.4712099  0.87228906 0.8367526  0.         0.43499592\n",
      "  0.         0.7337801  0.64218813 0.51378876 0.71223724 0.5298927\n",
      "  0.         0.         0.39038014 0.         0.         0.\n",
      "  0.         0.55750763 1.3271034  0.08205621]]\n",
      "Hi!\n",
      "[[0.1679429  0.         0.37909773 0.15239951 0.         0.6476715\n",
      "  1.5235881  1.6384505  0.8305435  0.         0.31192568 0.\n",
      "  0.4597672  0.         0.         0.7019822  0.         0.73132914\n",
      "  0.05611837 0.         0.6857281  0.07075855 0.         0.\n",
      "  0.19119136 0.         0.         0.5031632  0.         0.\n",
      "  1.021962   0.31655395 0.         0.         0.76022464 0.\n",
      "  0.0881473  1.3878918  0.         0.34944654 0.20833285 0.\n",
      "  0.         0.98849213 0.5533362  0.84942883 0.         0.21826357\n",
      "  0.         0.8233697  0.60407126 0.49754563 0.6175876  0.12141432\n",
      "  0.         0.         0.2299232  0.         0.         0.\n",
      "  0.         0.9527119  1.3532196  0.04967787]]\n",
      "Hi!\n",
      "[[0.         0.14103909 0.11259633 0.         0.         0.2542534\n",
      "  0.09558923 0.3149756  0.         0.12836435 0.11454118 0.\n",
      "  0.         0.10333298 0.         0.02029252 0.         0.07429907\n",
      "  0.         0.2833871  0.02216165 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00172228 0.11562435 0.16223139 0.         0.         0.\n",
      "  0.         0.0072279  0.09789909 0.17197986 0.         0.\n",
      "  0.         0.         0.19432433 0.5376822  0.         0.08263177\n",
      "  0.24475782 0.31224722 0.         0.24002406 0.20038015 0.3894893\n",
      "  0.         0.29979    0.         0.         0.         0.\n",
      "  0.10460281 0.2020697  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.44476974 0.         0.08736379 0.5145261  0.         0.7826114\n",
      "  1.7651439  2.0998807  0.555909   0.         0.22085693 0.\n",
      "  0.8901233  0.49099198 0.         0.5831375  0.         0.6282652\n",
      "  0.4057944  0.         0.5328574  0.3900904  0.         0.\n",
      "  0.26937988 0.         0.         1.0465217  0.         0.\n",
      "  1.5388947  0.70061547 0.05740306 0.         1.0248606  0.\n",
      "  0.36684832 1.5146852  0.03615369 0.14554814 0.4653623  0.\n",
      "  0.         0.7461893  1.3322887  1.4245276  0.         0.39039138\n",
      "  0.         0.86812747 0.5841494  0.73930573 0.7683411  0.7760949\n",
      "  0.         0.         0.629843   0.         0.         0.\n",
      "  0.         0.60412216 1.6613934  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.24409516 0.09701574 0.         0.         0.24071178\n",
      "  0.0439009  0.22633594 0.         0.04088897 0.1366662  0.\n",
      "  0.10733799 0.24559076 0.         0.00308885 0.         0.11415627\n",
      "  0.         0.27397576 0.04760467 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14344473 0.22338441 0.19110765 0.         0.         0.\n",
      "  0.         0.         0.15891336 0.07874237 0.         0.\n",
      "  0.         0.         0.27342585 0.4296165  0.         0.11616552\n",
      "  0.20088117 0.33530867 0.         0.21401054 0.11165226 0.51666296\n",
      "  0.         0.1853892  0.06037273 0.         0.         0.\n",
      "  0.12706167 0.19772722 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07140762 0.26021376 0.24946398 0.         0.         0.14194717\n",
      "  0.         0.         0.09142184 0.05545413 0.17881425 0.\n",
      "  0.2562881  0.02297755 0.         0.06220848 0.         0.06407376\n",
      "  0.         0.2113522  0.13143715 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00945247 0.15330249 0.02287191 0.         0.         0.\n",
      "  0.         0.         0.08292131 0.05855453 0.         0.\n",
      "  0.         0.         0.05090361 0.12411274 0.         0.14106016\n",
      "  0.14363024 0.12499472 0.03632278 0.15814391 0.01527236 0.34534293\n",
      "  0.         0.         0.03504661 0.         0.07035679 0.\n",
      "  0.12322788 0.11592953 0.         0.02804763]]\n",
      "Hi!\n",
      "[[0.06687897 0.3504901  0.5700853  0.         0.         0.24054928\n",
      "  0.         0.         0.21736881 0.06125299 0.25988787 0.\n",
      "  0.22688352 0.         0.         0.12948714 0.00378258 0.11423239\n",
      "  0.         0.40473947 0.35221618 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0052178  0.09890919 0.07193418 0.         0.         0.\n",
      "  0.         0.         0.13755494 0.2283559  0.         0.\n",
      "  0.         0.         0.10950652 0.14649817 0.         0.25962484\n",
      "  0.26166803 0.23409417 0.05580541 0.2605332  0.1489034  0.4074476\n",
      "  0.         0.18336934 0.         0.         0.09202357 0.\n",
      "  0.09134381 0.09168849 0.         0.1202691 ]]\n",
      "Hi!\n",
      "[[1.0802903  0.8913338  2.2723675  0.         0.         1.6146233\n",
      "  0.         0.         0.7148927  0.02316362 0.8156952  0.\n",
      "  0.48711967 0.         0.         0.2585312  0.741003   0.6281494\n",
      "  0.         1.1488006  1.3260571  0.         0.         0.56110984\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5648388  0.03370731 0.         0.         0.\n",
      "  0.         0.18181893 0.         1.1254942  0.         0.\n",
      "  0.         0.34595034 0.04105778 0.30748636 0.         1.0728782\n",
      "  0.74910617 0.8912845  0.29347593 0.5831973  0.877649   0.839284\n",
      "  0.         1.4342413  0.         0.24238236 0.3193996  0.\n",
      "  0.3660633  0.34247681 1.0160352  0.807667  ]]\n",
      "Hi!\n",
      "[[0.45594382 0.84914184 1.0556023  0.         0.         0.82793975\n",
      "  0.         0.         0.18211186 0.         0.52089524 0.\n",
      "  0.84450334 0.         0.         0.06967919 0.         0.4491305\n",
      "  0.         0.97835    0.5986178  0.         0.         0.14314161\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38432112 0.64941627 0.         0.         0.         0.\n",
      "  0.         0.18451521 0.14439029 0.53217876 0.         0.\n",
      "  0.         0.         0.56087846 0.49232072 0.         0.7944257\n",
      "  0.59928054 0.6103162  0.2301939  0.4750729  0.59353423 0.99497026\n",
      "  0.         0.6471582  0.         0.         0.14492625 0.\n",
      "  0.04559594 0.14460722 0.50835955 0.29510066]]\n",
      "Hi!\n",
      "[[0.41021627 0.         1.0434995  0.         0.         0.79823536\n",
      "  0.7014521  0.6317705  0.66825366 0.         0.45172462 0.\n",
      "  0.17377402 0.         0.         0.41531417 0.17127462 0.6991947\n",
      "  0.         0.12614204 0.78520155 0.         0.         0.04025319\n",
      "  0.05358297 0.         0.         0.         0.         0.\n",
      "  0.21356401 0.32306218 0.         0.         0.27327308 0.\n",
      "  0.22283244 0.96372575 0.         0.4707253  0.         0.\n",
      "  0.         0.66928303 0.21159238 0.40320015 0.         0.6927789\n",
      "  0.         0.4918267  0.41832963 0.22946618 0.22034049 0.35771105\n",
      "  0.         0.16024058 0.09818491 0.1684278  0.         0.\n",
      "  0.         0.74587727 0.99564385 0.3405092 ]]\n",
      "Hi!\n",
      "[[0.31928432 1.0903156  0.46989095 0.         0.         0.35583845\n",
      "  0.         0.17362234 0.5648617  0.         0.4046959  0.\n",
      "  1.5489106  0.39120895 0.         0.5155879  0.         0.5237011\n",
      "  0.43380776 0.60472256 0.353299   0.         0.         0.01791937\n",
      "  0.05247557 0.         0.         0.23352179 0.         0.\n",
      "  0.73606616 0.4951054  0.         0.         0.2955972  0.\n",
      "  0.17212586 0.59167075 0.09207729 0.3755992  0.         0.\n",
      "  0.         0.02868218 0.51297575 0.29970205 0.         0.7870991\n",
      "  0.         0.6156018  0.8393706  0.13824263 0.19269261 0.82481843\n",
      "  0.         0.         0.34190404 0.         0.03496447 0.\n",
      "  0.         0.3869696  0.42683658 0.4922763 ]]\n",
      "Hi!\n",
      "[[0.36513874 0.50635505 0.65344423 0.00168357 0.         0.82137835\n",
      "  0.12606671 0.38946614 0.         0.06839073 0.2627127  0.\n",
      "  0.10350444 0.11107276 0.         0.         0.         0.15967944\n",
      "  0.         0.7773238  0.33576494 0.         0.         0.01121841\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19035915 0.5531267  0.08021356 0.         0.         0.\n",
      "  0.         0.         0.10050369 0.35827848 0.         0.\n",
      "  0.         0.         0.493942   0.79191333 0.         0.28905612\n",
      "  0.58782154 0.7505136  0.         0.53510386 0.7299277  0.7466655\n",
      "  0.         0.94456536 0.         0.         0.09574885 0.\n",
      "  0.23699753 0.16410424 0.28878883 0.        ]]\n",
      "Hi!\n",
      "[[0.8458307  0.400987   0.         0.5250198  0.         0.71472543\n",
      "  1.0906045  1.2250121  0.         0.         0.02604147 0.\n",
      "  0.9067644  0.9346186  0.         0.06874614 0.         0.27566218\n",
      "  0.         0.5619314  0.04534026 0.20897612 0.         0.16797514\n",
      "  0.         0.         0.         0.87318236 0.         0.\n",
      "  1.3698788  1.0173517  0.50981396 0.         0.57787    0.\n",
      "  0.3525969  0.78941286 0.5768097  0.11400507 0.09282567 0.\n",
      "  0.         0.6654048  1.5950321  1.3845268  0.         0.68281734\n",
      "  0.406589   0.76617277 0.17239495 0.6699513  0.7203886  1.5371826\n",
      "  0.         0.48072657 0.685415   0.         0.         0.\n",
      "  0.         0.1673551  0.68206817 0.        ]]\n",
      "Hi!\n",
      "[[0.07658573 0.38846263 0.22221266 0.         0.         0.17562155\n",
      "  0.22290605 0.26584405 0.2606716  0.07038918 0.22377719 0.\n",
      "  0.12709886 0.         0.         0.10195716 0.         0.27501023\n",
      "  0.         0.20132536 0.28022566 0.         0.         0.\n",
      "  0.         0.         0.         0.0049652  0.         0.\n",
      "  0.14352645 0.02304682 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.30236533 0.         0.\n",
      "  0.         0.08674508 0.10227836 0.28927118 0.         0.0481723\n",
      "  0.         0.26667193 0.25432408 0.         0.11127529 0.24013592\n",
      "  0.         0.         0.09400474 0.         0.04923833 0.\n",
      "  0.05821325 0.4332566  0.         0.140754  ]]\n",
      "Hi!\n",
      "[[1.0006714  0.5013891  2.2942507  0.         0.         1.0823976\n",
      "  0.         0.         1.3484149  0.         0.8882483  0.\n",
      "  0.5785108  0.         0.         0.76559204 1.0102361  0.9740316\n",
      "  0.18209657 0.37569734 1.6645275  0.3871573  0.         0.5261453\n",
      "  0.04009698 0.         0.         0.         0.         0.\n",
      "  0.         0.24920224 0.         0.         0.         0.\n",
      "  0.22463505 0.7142942  0.         1.255828   0.00256636 0.\n",
      "  0.         0.99444604 0.         0.         0.         1.0474614\n",
      "  0.29608288 1.1834246  0.8060018  0.11608487 0.2769987  0.30733413\n",
      "  0.         0.514976   0.         0.91478723 0.2596227  0.\n",
      "  0.01743245 0.90530354 1.0647904  1.3314573 ]]\n",
      "Hi!\n",
      "[[0.8302174  0.1445523  1.5222431  0.         0.         0.8162345\n",
      "  0.32054204 0.3795118  0.9753089  0.         0.6406951  0.\n",
      "  0.         0.         0.         0.47409838 0.60888535 0.81576544\n",
      "  0.         0.09544164 1.1785886  0.27559873 0.         0.5517123\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.1332625  0.09146317 0.         0.         0.\n",
      "  0.         0.64560544 0.         0.9149027  0.         0.\n",
      "  0.         1.0429899  0.         0.1507008  0.         0.19727723\n",
      "  0.         0.9817946  0.4893245  0.1172685  0.4904249  0.01374301\n",
      "  0.         0.5770315  0.         0.3343293  0.03778869 0.\n",
      "  0.0544443  0.9133321  0.71759164 0.54935664]]\n",
      "Hi!\n",
      "[[7.20836371e-02 2.52038270e-01 2.90930659e-01 0.00000000e+00\n",
      "  0.00000000e+00 3.80915433e-01 0.00000000e+00 2.26589903e-01\n",
      "  0.00000000e+00 1.40863732e-01 1.47343755e-01 0.00000000e+00\n",
      "  0.00000000e+00 6.45727590e-02 0.00000000e+00 1.63333360e-02\n",
      "  0.00000000e+00 1.38907582e-01 0.00000000e+00 3.75614047e-01\n",
      "  9.83821824e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.53509527e-01\n",
      "  1.15306795e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.78100542e-05 1.08858757e-03 2.38651961e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.26946419e-01 4.84440178e-01 0.00000000e+00 6.86980039e-02\n",
      "  3.04147124e-01 4.37280416e-01 0.00000000e+00 2.53482252e-01\n",
      "  2.25264475e-01 3.99924397e-01 0.00000000e+00 4.16291237e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.17810765e-01 2.61617661e-01 0.00000000e+00 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.         0.         0.         0.28792083 0.         0.1067836\n",
      "  1.5384272  1.378585   0.30754155 0.         0.         0.\n",
      "  0.         0.5348454  0.         0.46847308 0.         0.37747532\n",
      "  0.         0.         0.12586863 0.05374016 0.         0.\n",
      "  0.20786874 0.         0.         0.47456366 0.         0.\n",
      "  0.6478727  0.19381501 0.7994885  0.         0.29615352 0.\n",
      "  0.5059513  0.8362059  0.59249496 0.14094315 0.         0.\n",
      "  0.         0.52771384 0.872736   1.138704   0.         0.063014\n",
      "  0.         0.6850043  0.10595147 0.39016458 0.25724196 0.7625095\n",
      "  0.         0.07271838 0.2976044  0.         0.         0.\n",
      "  0.         0.50724053 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.36886033 0.         0.51917034 0.2562385  0.         0.7991567\n",
      "  1.283845   1.3023057  0.29253292 0.         0.2786707  0.\n",
      "  0.05151909 0.         0.         0.24539766 0.         0.61235714\n",
      "  0.         0.08051337 0.5613174  0.00713041 0.         0.\n",
      "  0.         0.         0.         0.15967625 0.         0.\n",
      "  0.7127613  0.43619284 0.06785813 0.         0.48540798 0.\n",
      "  0.         0.9768213  0.         0.4155772  0.10382711 0.\n",
      "  0.         0.53547996 0.6373519  0.96328545 0.         0.14226133\n",
      "  0.         0.8742601  0.1913642  0.5052502  0.72257245 0.33592004\n",
      "  0.         0.34804285 0.06640657 0.         0.         0.\n",
      "  0.         0.791346   0.9332494  0.        ]]\n",
      "Hi!\n",
      "[[0.         0.09420766 0.001297   0.         0.         0.09567299\n",
      "  0.0786073  0.22498845 0.         0.1018282  0.10482594 0.\n",
      "  0.         0.0898297  0.         0.0477017  0.         0.05532979\n",
      "  0.         0.18860292 0.07974115 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03866093 0.19801076 0.         0.         0.\n",
      "  0.         0.         0.09076136 0.09293739 0.         0.\n",
      "  0.         0.         0.1401886  0.41672328 0.         0.07927538\n",
      "  0.15240018 0.12979902 0.         0.1905609  0.         0.2918511\n",
      "  0.         0.18693008 0.         0.         0.         0.\n",
      "  0.05775492 0.13450971 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0938697  0.         0.         0.3336011  0.         0.44596538\n",
      "  1.8248918  1.7870455  0.37743607 0.         0.19112985 0.\n",
      "  0.         0.1135665  0.         0.44428474 0.         0.6467268\n",
      "  0.         0.         0.2894515  0.14281218 0.         0.\n",
      "  0.04677887 0.         0.         0.36969817 0.         0.\n",
      "  0.96464944 0.16793583 0.18346135 0.         0.68762976 0.\n",
      "  0.         1.1473913  0.         0.48298833 0.24286145 0.\n",
      "  0.         0.96538377 0.571446   1.1460799  0.         0.\n",
      "  0.         1.0745716  0.36363918 0.43422338 0.7322294  0.00954125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.9963364  0.71385527 0.        ]]\n",
      "Hi!\n",
      "[[0.16446595 0.7903178  0.5873423  0.         0.         0.40479848\n",
      "  0.         0.         0.1941862  0.         0.28535903 0.\n",
      "  0.660835   0.12120594 0.         0.03967393 0.         0.33424416\n",
      "  0.         0.58317447 0.21504022 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24368855 0.32660753 0.         0.         0.         0.\n",
      "  0.         0.10722698 0.14127363 0.23980929 0.         0.\n",
      "  0.         0.         0.34278238 0.31018156 0.         0.5820175\n",
      "  0.25739694 0.30820432 0.11946119 0.22942191 0.13913241 0.71218723\n",
      "  0.         0.07372106 0.05505506 0.         0.05704515 0.\n",
      "  0.12056419 0.24121897 0.16992986 0.18354292]]\n",
      "Hi!\n",
      "[[0.5279861  0.20270115 0.23033535 0.10651495 0.         0.5494638\n",
      "  0.992801   1.2598201  0.49259552 0.         0.30809912 0.\n",
      "  1.1234964  0.54867643 0.         0.58483595 0.         0.62250525\n",
      "  0.4479587  0.08086821 0.44530392 0.13438492 0.         0.\n",
      "  0.27278224 0.         0.         0.59848946 0.         0.\n",
      "  1.1679661  0.6487809  0.         0.         0.73450196 0.\n",
      "  0.538366   1.2452652  0.         0.21215044 0.10670994 0.\n",
      "  0.         0.36005476 1.0910311  0.8773446  0.         0.6783185\n",
      "  0.         0.67559016 0.6482398  0.48698506 0.44857484 0.8652322\n",
      "  0.         0.         0.488626   0.         0.         0.\n",
      "  0.         0.39968556 1.0554017  0.0017344 ]]\n",
      "Hi!\n",
      "[[0.23227923 0.         0.91807973 0.         0.         0.59784865\n",
      "  0.9363867  0.8606587  1.2537031  0.         0.55601734 0.\n",
      "  0.64314884 0.         0.         0.92050076 0.01093743 0.90266705\n",
      "  0.5582455  0.         0.9556594  0.22111136 0.         0.04814423\n",
      "  0.32596695 0.         0.         0.14276864 0.         0.\n",
      "  0.50230765 0.1604924  0.         0.         0.5634502  0.\n",
      "  0.55443317 1.3936065  0.         0.5836763  0.21599926 0.\n",
      "  0.         1.0585982  0.19603974 0.26202914 0.         0.77633387\n",
      "  0.         0.6587945  0.8839618  0.17952901 0.1380333  0.18483074\n",
      "  0.         0.         0.24875675 0.38116932 0.         0.\n",
      "  0.         1.0188301  1.2617725  0.6971781 ]]\n",
      "Hi!\n",
      "[[0.36915118 0.         0.2312638  0.3834939  0.         0.7462053\n",
      "  1.7953113  1.9391829  0.6637719  0.         0.25294363 0.\n",
      "  0.6823555  0.19623166 0.         0.6334837  0.         0.7010586\n",
      "  0.28496832 0.         0.5456715  0.29289886 0.         0.\n",
      "  0.29192948 0.         0.         0.74920285 0.         0.\n",
      "  1.2933689  0.5468774  0.         0.         0.9121276  0.\n",
      "  0.36168954 1.553357   0.         0.2408158  0.37281543 0.\n",
      "  0.         0.89921385 1.0040542  1.1613035  0.         0.38165554\n",
      "  0.         0.7632588  0.61930615 0.6093725  0.62315273 0.5320763\n",
      "  0.         0.         0.5051409  0.         0.         0.\n",
      "  0.         0.7632356  1.5530418  0.        ]]\n",
      "Hi!\n",
      "[[2.7936986e-01 0.0000000e+00 1.9671729e-01 4.9630556e-01 0.0000000e+00\n",
      "  7.2342128e-01 1.8301835e+00 1.8735751e+00 3.1837156e-01 0.0000000e+00\n",
      "  1.8780743e-01 0.0000000e+00 0.0000000e+00 3.6555188e-04 0.0000000e+00\n",
      "  3.4274900e-01 0.0000000e+00 6.3325769e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.3870458e-01 1.3558082e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 4.9059424e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0970585e+00 4.0992665e-01 1.6194457e-01 0.0000000e+00 7.3736334e-01\n",
      "  0.0000000e+00 0.0000000e+00 1.2000214e+00 0.0000000e+00 4.4739774e-01\n",
      "  3.2389188e-01 0.0000000e+00 0.0000000e+00 8.6189765e-01 7.7033067e-01\n",
      "  1.2227255e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.8337710e-01\n",
      "  2.1041302e-01 5.5835760e-01 9.2973298e-01 1.8296525e-01 0.0000000e+00\n",
      "  1.8619376e-01 1.6369638e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 8.5722911e-01 1.1493849e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[1.0542295  0.37873027 2.168069   0.         0.         1.01118\n",
      "  0.04235693 0.         1.2415869  0.         0.8460461  0.\n",
      "  0.20938155 0.         0.         0.688486   0.9921356  0.93817896\n",
      "  0.         0.3185967  1.5282536  0.36723623 0.         0.59951806\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14610428 0.05863683 0.         0.         0.\n",
      "  0.10184056 0.63065344 0.         1.1942153  0.04138333 0.\n",
      "  0.         1.1364591  0.         0.09407391 0.         0.7793559\n",
      "  0.27223793 1.0338188  0.6991889  0.07959474 0.39041618 0.17757863\n",
      "  0.         0.7045045  0.         0.84246    0.16644469 0.\n",
      "  0.05420405 0.9269848  0.8947077  1.0975245 ]]\n",
      "Hi!\n",
      "[[0.59868336 0.         0.55285823 0.41824758 0.         0.8518468\n",
      "  1.4063215  1.3864156  0.23052691 0.         0.2783665  0.\n",
      "  0.         0.         0.         0.16607998 0.04233377 0.64529186\n",
      "  0.         0.         0.5010874  0.03026065 0.         0.21468928\n",
      "  0.         0.         0.         0.01374512 0.         0.\n",
      "  0.31521413 0.2968938  0.29491624 0.         0.2607469  0.\n",
      "  0.         0.6081598  0.         0.730712   0.13338143 0.\n",
      "  0.         1.023964   0.21563923 0.952327   0.         0.\n",
      "  0.03124181 1.1924306  0.         0.39444387 0.8040939  0.\n",
      "  0.         0.79623073 0.         0.         0.         0.\n",
      "  0.         0.93528306 0.54658896 0.        ]]\n",
      "Hi!\n",
      "[[0.47807685 0.357484   0.1734308  0.20541301 0.         0.6024922\n",
      "  0.72444046 1.0267694  0.         0.         0.19752674 0.\n",
      "  0.3793794  0.5681689  0.         0.         0.         0.32011315\n",
      "  0.         0.5619314  0.18527226 0.         0.         0.11059722\n",
      "  0.         0.         0.         0.26178867 0.         0.\n",
      "  0.98352045 0.66976655 0.26919228 0.         0.31513575 0.\n",
      "  0.         0.4960253  0.24776159 0.268886   0.         0.\n",
      "  0.         0.11283635 1.0176696  1.2001206  0.         0.11881344\n",
      "  0.3848611  0.9265169  0.         0.60842973 0.7850589  0.8659375\n",
      "  0.         0.49687257 0.19093841 0.         0.         0.\n",
      "  0.         0.29804602 0.30163467 0.        ]]\n",
      "Hi!\n",
      "[[0.76419216 0.6794442  2.003224   0.         0.         0.96665174\n",
      "  0.         0.         1.3278002  0.         0.852632   0.\n",
      "  0.9274128  0.         0.         0.79475635 0.6637125  0.9642361\n",
      "  0.3711801  0.38502088 1.5110352  0.27259073 0.         0.48448217\n",
      "  0.09176672 0.         0.         0.         0.         0.\n",
      "  0.         0.30837113 0.         0.         0.         0.\n",
      "  0.2736161  0.78077966 0.         1.1216043  0.         0.\n",
      "  0.         0.67761153 0.         0.         0.         1.0445858\n",
      "  0.14916667 1.0083163  0.7913514  0.23713838 0.32057074 0.41069776\n",
      "  0.         0.2625056  0.         0.7024864  0.19927399 0.\n",
      "  0.         0.8673347  1.0845513  1.2811971 ]]\n",
      "Hi!\n",
      "[[0.5140911  0.         0.06160391 0.47613415 0.         0.63536865\n",
      "  1.776821   2.2675827  0.8595351  0.         0.251844   0.\n",
      "  1.3846468  0.6811083  0.         0.85914814 0.         0.64287454\n",
      "  0.966245   0.         0.5907989  0.5226109  0.         0.\n",
      "  0.38568583 0.         0.         1.2109396  0.         0.\n",
      "  1.7542481  0.71445876 0.         0.         1.1431944  0.\n",
      "  0.6573506  1.7216212  0.14783002 0.01994698 0.47775578 0.\n",
      "  0.         0.8364495  1.4143015  1.2364703  0.         0.5663437\n",
      "  0.         0.67848593 0.9700238  0.65771943 0.760116   0.8128141\n",
      "  0.         0.         0.740848   0.         0.         0.\n",
      "  0.         0.46666747 1.8810496  0.        ]]\n",
      "Hi!\n",
      "[[0.0635071  0.22334978 0.2923472  0.         0.         0.12029099\n",
      "  0.         0.1042872  0.         0.02785252 0.15342437 0.\n",
      "  0.04506148 0.14600597 0.         0.         0.         0.10895622\n",
      "  0.         0.28124294 0.05408351 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05409723 0.26225922 0.13998409 0.         0.         0.\n",
      "  0.         0.         0.3187884  0.08224479 0.         0.\n",
      "  0.         0.         0.25428265 0.33809587 0.         0.11330531\n",
      "  0.24108097 0.16305192 0.         0.18109013 0.22083539 0.32096905\n",
      "  0.         0.22956833 0.         0.         0.00781514 0.\n",
      "  0.07915458 0.05410826 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.134782   0.15065081 0.         0.         0.22635035\n",
      "  0.03530985 0.27129978 0.00280006 0.10429631 0.06901842 0.\n",
      "  0.         0.12262524 0.         0.02681099 0.         0.05577924\n",
      "  0.         0.2734735  0.05885945 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17348284 0.19448036 0.         0.         0.\n",
      "  0.         0.         0.09112322 0.190404   0.         0.\n",
      "  0.         0.         0.18832846 0.48187703 0.         0.10186094\n",
      "  0.24690534 0.3130506  0.         0.23740114 0.15338308 0.3803037\n",
      "  0.         0.3226721  0.         0.         0.         0.\n",
      "  0.18883032 0.18515179 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.04637919 0.22886927 0.33943328 0.         0.         0.35048622\n",
      "  0.04410578 0.13128492 0.09591137 0.17007037 0.23200886 0.\n",
      "  0.         0.         0.         0.03111089 0.         0.15231237\n",
      "  0.         0.38630006 0.1796381  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01846405 0.08696204 0.         0.         0.\n",
      "  0.         0.         0.         0.26629692 0.         0.\n",
      "  0.         0.         0.         0.37758976 0.         0.1282039\n",
      "  0.23798378 0.32829958 0.         0.2116753  0.17282763 0.25756007\n",
      "  0.         0.3352489  0.         0.         0.04878477 0.\n",
      "  0.2082253  0.25807276 0.         0.03919971]]\n",
      "Hi!\n",
      "[[0.35765666 0.15311997 0.20360042 0.25789943 0.         0.75548095\n",
      "  1.0952331  1.2295557  0.         0.         0.15033418 0.\n",
      "  0.06118738 0.36414802 0.         0.03707854 0.         0.3752802\n",
      "  0.         0.38223854 0.24449554 0.         0.         0.\n",
      "  0.         0.         0.         0.2188363  0.         0.\n",
      "  0.86953634 0.558904   0.2790386  0.         0.2771377  0.\n",
      "  0.         0.57243496 0.         0.397414   0.01510549 0.\n",
      "  0.         0.18821871 0.85029083 1.2773304  0.         0.\n",
      "  0.224844   1.0555395  0.00209684 0.5979028  0.8408639  0.6773234\n",
      "  0.         0.5370089  0.         0.         0.         0.\n",
      "  0.         0.56697756 0.3753853  0.        ]]\n",
      "Hi!\n",
      "[[0.5514345  0.         0.6825387  0.25637674 0.         0.60913587\n",
      "  1.665958   1.5599338  0.84455645 0.         0.3809081  0.\n",
      "  0.         0.         0.         0.61851496 0.08661411 0.8000765\n",
      "  0.         0.         0.7750313  0.14293732 0.         0.2561881\n",
      "  0.         0.         0.         0.13767675 0.         0.\n",
      "  0.49406618 0.14448816 0.17809075 0.         0.50786495 0.\n",
      "  0.         1.2302814  0.         0.69025385 0.22151046 0.\n",
      "  0.         1.349679   0.14681907 0.722328   0.         0.\n",
      "  0.         0.9726413  0.43320248 0.29768103 0.5626659  0.\n",
      "  0.         0.13329807 0.         0.         0.         0.\n",
      "  0.         1.2370154  1.1013006  0.        ]]\n",
      "Hi!\n",
      "[[0.1836511  0.25257853 0.7172616  0.         0.         0.5453678\n",
      "  0.         0.         0.26404122 0.16318704 0.38252324 0.\n",
      "  0.01921551 0.         0.         0.05925527 0.0492337  0.04575465\n",
      "  0.         0.5115577  0.38679367 0.         0.         0.12373743\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03635808 0.10410042 0.         0.         0.\n",
      "  0.         0.         0.11126434 0.36581925 0.         0.\n",
      "  0.         0.         0.07052418 0.32113084 0.         0.41512737\n",
      "  0.32903647 0.222545   0.00179337 0.39383483 0.20575954 0.3962704\n",
      "  0.         0.46610355 0.         0.         0.12138253 0.\n",
      "  0.08731087 0.02592718 0.10709663 0.23845378]]\n",
      "Hi!\n",
      "[[0.23984459 0.59585816 1.3510833  0.         0.         0.64755476\n",
      "  0.29178578 0.2889848  1.4496866  0.         0.69892144 0.\n",
      "  1.3032026  0.         0.         0.91308755 0.1349185  0.87286663\n",
      "  0.8560561  0.         1.2319095  0.21179973 0.         0.21772571\n",
      "  0.21430705 0.         0.         0.0741567  0.         0.\n",
      "  0.4334217  0.3900273  0.         0.         0.25237474 0.\n",
      "  0.4284125  1.0185825  0.         0.84682965 0.09755782 0.\n",
      "  0.         0.6282426  0.08703527 0.         0.         1.0105412\n",
      "  0.         0.9466488  1.0083795  0.21926516 0.35547557 0.29134935\n",
      "  0.         0.         0.01664736 0.38256508 0.03554172 0.\n",
      "  0.         0.84050035 1.1852789  1.1300328 ]]\n",
      "Hi!\n",
      "[[0.03872673 0.6049601  0.31988204 0.         0.         0.2473202\n",
      "  0.         0.00871891 0.2252013  0.         0.29328308 0.\n",
      "  0.59640765 0.05567792 0.         0.17670277 0.         0.3150562\n",
      "  0.         0.4454735  0.23696902 0.         0.         0.\n",
      "  0.         0.         0.         0.03229579 0.         0.\n",
      "  0.15723734 0.21729384 0.         0.         0.         0.\n",
      "  0.         0.17355442 0.         0.21614051 0.         0.\n",
      "  0.         0.         0.20029004 0.1949305  0.         0.29100418\n",
      "  0.1256322  0.38522252 0.26947296 0.11777933 0.00697771 0.46459734\n",
      "  0.         0.         0.06311439 0.         0.03105036 0.\n",
      "  0.02117818 0.29657638 0.02770579 0.18255077]]\n",
      "Hi!\n",
      "[[0.         0.07257126 0.06446049 0.         0.         0.11381494\n",
      "  0.18756622 0.31412467 0.04382435 0.16314897 0.09952638 0.\n",
      "  0.         0.02851555 0.         0.13311194 0.         0.131973\n",
      "  0.         0.17699954 0.16519816 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18737529 0.         0.         0.\n",
      "  0.         0.         0.         0.1761278  0.         0.\n",
      "  0.         0.04623377 0.05365927 0.4443799  0.         0.\n",
      "  0.23452187 0.2661528  0.         0.19879797 0.00720822 0.21922576\n",
      "  0.         0.2694162  0.         0.         0.         0.\n",
      "  0.12588401 0.35369325 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.07487784 0.26510268 0.31604    0.         0.         0.38005745\n",
      "  0.         0.0958067  0.         0.06763405 0.2227976  0.\n",
      "  0.         0.11118117 0.         0.         0.         0.10018925\n",
      "  0.         0.4338395  0.14018562 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18692353 0.08063128 0.         0.         0.\n",
      "  0.         0.         0.08963747 0.2097267  0.         0.\n",
      "  0.         0.         0.19833869 0.4308848  0.         0.15814695\n",
      "  0.36900923 0.2789389  0.         0.30756095 0.22745012 0.41710618\n",
      "  0.         0.3889579  0.         0.         0.05123447 0.\n",
      "  0.1728372  0.09142336 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.19963118 0.         0.3420843  0.25405452 0.         0.6281557\n",
      "  1.7782778  1.855119   0.85811055 0.         0.31231922 0.\n",
      "  0.39241385 0.         0.         0.7466745  0.         0.75078905\n",
      "  0.08028908 0.         0.6412777  0.24390072 0.         0.\n",
      "  0.23329593 0.         0.         0.597953   0.         0.\n",
      "  1.1280195  0.30265024 0.         0.         0.88144803 0.\n",
      "  0.22525221 1.5277897  0.         0.379649   0.3668221  0.\n",
      "  0.         1.1265296  0.6576663  0.983394   0.         0.17041636\n",
      "  0.         0.79144    0.6216916  0.4834934  0.65857875 0.14564691\n",
      "  0.         0.         0.3606403  0.         0.         0.\n",
      "  0.         0.9605049  1.5027293  0.        ]]\n",
      "Hi!\n",
      "[[0.3363655  0.         0.68831974 0.09318976 0.         0.68289524\n",
      "  1.2471129  1.3492763  0.88551855 0.         0.40969056 0.\n",
      "  0.27054778 0.         0.         0.63968396 0.         0.76835847\n",
      "  0.         0.         0.80648226 0.02214427 0.         0.14651993\n",
      "  0.03810533 0.         0.         0.27561557 0.         0.\n",
      "  0.7156564  0.27227852 0.01452847 0.         0.5504911  0.\n",
      "  0.         1.2550223  0.         0.50672513 0.15098329 0.\n",
      "  0.         0.97060245 0.29037333 0.67915195 0.         0.19244938\n",
      "  0.         0.82261354 0.55060536 0.36754245 0.6214145  0.06267855\n",
      "  0.         0.         0.08886818 0.         0.         0.\n",
      "  0.         0.9817314  1.2973577  0.14015079]]\n",
      "Hi!\n",
      "[[0.92977625 0.12661128 2.0350456  0.         0.         0.91457653\n",
      "  0.24289167 0.28511456 1.4584758  0.         0.8136444  0.\n",
      "  0.31035113 0.         0.         0.8603662  0.85898185 1.0110444\n",
      "  0.19622028 0.         1.5616963  0.40564784 0.         0.6633797\n",
      "  0.02894421 0.         0.         0.         0.         0.\n",
      "  0.         0.1608786  0.         0.         0.         0.\n",
      "  0.3063844  1.0084463  0.         1.0768296  0.11064344 0.\n",
      "  0.         1.3041655  0.         0.01268096 0.         0.8371477\n",
      "  0.         0.9034066  0.7764027  0.06333411 0.30871823 0.08928391\n",
      "  0.         0.47758773 0.         0.95566595 0.04331051 0.\n",
      "  0.         1.0592848  1.3027272  1.1103436 ]]\n",
      "Hi!\n",
      "[[0.2672235  0.771135   0.6587137  0.         0.         0.4226577\n",
      "  0.3470781  0.51423985 0.8151815  0.         0.45758167 0.\n",
      "  1.3415596  0.22371055 0.         0.60710925 0.         0.7073712\n",
      "  0.5551249  0.32232922 0.7091255  0.         0.         0.\n",
      "  0.13110438 0.         0.         0.21085232 0.         0.\n",
      "  0.85075665 0.5208673  0.         0.         0.4206255  0.\n",
      "  0.15611164 0.86189234 0.         0.44352487 0.         0.\n",
      "  0.         0.10808386 0.5136663  0.37071776 0.         0.7649126\n",
      "  0.         0.72097886 0.7852321  0.23166943 0.50861573 0.5039016\n",
      "  0.         0.         0.18811722 0.         0.01236082 0.\n",
      "  0.         0.6703942  0.7651543  0.53562623]]\n",
      "Hi!\n",
      "[[0.16150856 0.0918292  0.5053299  0.         0.         0.2448084\n",
      "  0.85743475 0.574727   0.72954476 0.         0.29900417 0.\n",
      "  0.03072369 0.         0.         0.5360616  0.11726769 0.75190175\n",
      "  0.         0.04309271 0.5084562  0.1563191  0.         0.\n",
      "  0.1852648  0.         0.         0.         0.         0.\n",
      "  0.192469   0.         0.         0.         0.40234575 0.\n",
      "  0.15560912 0.96241504 0.         0.38831258 0.07496438 0.\n",
      "  0.         0.740587   0.         0.21997398 0.         0.41060472\n",
      "  0.         0.54612345 0.53244793 0.03450964 0.         0.10336778\n",
      "  0.         0.         0.         0.10860828 0.         0.\n",
      "  0.         0.8686561  0.5297353  0.31100887]]\n",
      "Hi!\n",
      "[[0.40263394 0.514303   0.67471325 0.         0.         0.5043119\n",
      "  0.5284571  0.8759256  1.12255    0.         0.49525207 0.\n",
      "  1.5905242  0.11139055 0.         0.8642839  0.         0.71584815\n",
      "  1.029565   0.         0.83380467 0.00744721 0.         0.\n",
      "  0.39012548 0.         0.         0.48339114 0.         0.\n",
      "  1.0432581  0.5735171  0.         0.         0.6353973  0.\n",
      "  0.5889424  1.2633089  0.         0.39414954 0.14057516 0.\n",
      "  0.         0.4054772  0.70610356 0.36686435 0.         0.96118915\n",
      "  0.         0.8014384  1.0600276  0.36679307 0.49212983 0.63651127\n",
      "  0.         0.         0.39998797 0.         0.         0.\n",
      "  0.         0.57574826 1.3320619  0.63188714]]\n",
      "Hi!\n",
      "[[0.46800894 0.82518613 0.7906354  0.         0.         0.60606736\n",
      "  0.         0.27243584 0.37204725 0.         0.469185   0.\n",
      "  1.2128932  0.21158172 0.         0.30875117 0.         0.51792425\n",
      "  0.21515206 0.6549752  0.58530265 0.         0.         0.09485991\n",
      "  0.         0.         0.         0.09027289 0.         0.\n",
      "  0.65676427 0.6329429  0.         0.         0.13178332 0.\n",
      "  0.15261652 0.4898165  0.15046571 0.4327211  0.         0.\n",
      "  0.         0.03036023 0.6892643  0.4333648  0.         0.7393508\n",
      "  0.2425948  0.5920012  0.33756337 0.38513428 0.46554813 0.8389942\n",
      "  0.         0.00596454 0.16444062 0.         0.04932511 0.\n",
      "  0.         0.28874105 0.66510594 0.3693389 ]]\n",
      "Hi!\n",
      "[[0.32399863 0.         0.08046761 0.32511818 0.         0.5625567\n",
      "  1.6279519  1.5151604  0.09553777 0.         0.16729265 0.\n",
      "  0.02488298 0.21637814 0.         0.22833571 0.         0.5758519\n",
      "  0.         0.068772   0.30183074 0.10698817 0.         0.\n",
      "  0.10633116 0.         0.         0.4593889  0.         0.\n",
      "  0.95683146 0.39768317 0.19862272 0.         0.6215961  0.\n",
      "  0.         1.0831778  0.         0.3270662  0.20211837 0.\n",
      "  0.         0.545837   0.9063386  1.1464455  0.         0.02520874\n",
      "  0.         0.88942987 0.19059932 0.49034098 0.5207775  0.47837886\n",
      "  0.         0.02258681 0.27874574 0.         0.         0.\n",
      "  0.         0.73359567 0.6955246  0.        ]]\n",
      "Hi!\n",
      "[[0.35762268 0.16728608 0.5041023  0.1263425  0.         0.76116693\n",
      "  0.7920543  0.9506995  0.02896719 0.         0.26985547 0.\n",
      "  0.12674387 0.05539429 0.         0.05112221 0.         0.4465906\n",
      "  0.         0.43478003 0.4213505  0.         0.         0.\n",
      "  0.         0.         0.         0.04917617 0.         0.\n",
      "  0.6838139  0.52145475 0.05268412 0.         0.27369446 0.\n",
      "  0.         0.599293   0.         0.38903752 0.         0.\n",
      "  0.         0.12730892 0.7028244  0.97973144 0.         0.17603743\n",
      "  0.23780099 0.8721134  0.06457659 0.5113736  0.7160384  0.5681625\n",
      "  0.         0.5449155  0.02883236 0.         0.         0.\n",
      "  0.         0.47482055 0.50034446 0.        ]]\n",
      "Hi!\n",
      "[[0.7319356  0.4516783  1.3158892  0.02218249 0.         1.1977333\n",
      "  0.         0.49385557 0.16735674 0.02488952 0.48832214 0.\n",
      "  0.26703534 0.         0.         0.         0.08711945 0.33357018\n",
      "  0.         0.82687604 0.77766806 0.         0.         0.22971253\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25042796 0.66413563 0.09360965 0.         0.         0.\n",
      "  0.         0.2096333  0.         0.5089078  0.         0.\n",
      "  0.         0.         0.51166993 0.68158567 0.         0.3736\n",
      "  0.6576582  0.87619627 0.         0.60200834 0.9784571  0.7380541\n",
      "  0.         1.2616109  0.         0.         0.12814115 0.\n",
      "  0.17415556 0.30820826 0.7916916  0.        ]]\n",
      "Hi!\n",
      "[[0.05401719 0.2783428  0.16432133 0.         0.         0.1558498\n",
      "  0.         0.02641778 0.02600149 0.03863683 0.15757091 0.\n",
      "  0.2237304  0.13806035 0.         0.         0.         0.04619955\n",
      "  0.         0.23990372 0.10849604 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04593659 0.20168921 0.10770843 0.         0.         0.\n",
      "  0.         0.         0.15529543 0.06783649 0.         0.\n",
      "  0.         0.         0.15638806 0.2131698  0.         0.10700913\n",
      "  0.19292678 0.13453932 0.         0.19471292 0.06314681 0.36015388\n",
      "  0.         0.0119799  0.08846165 0.         0.04097326 0.\n",
      "  0.10116377 0.07947776 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.9658673  0.         1.4379052  0.11847214 0.         1.0952091\n",
      "  0.8015352  1.0243323  0.7893414  0.         0.5207845  0.\n",
      "  0.         0.         0.         0.37289077 0.50465584 0.6854444\n",
      "  0.         0.01924906 1.1202564  0.1203066  0.         0.6179846\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04702153 0.3474676  0.13792847 0.         0.         0.\n",
      "  0.         0.7913586  0.         0.8106188  0.         0.\n",
      "  0.         1.11402    0.         0.5510623  0.         0.12081759\n",
      "  0.         1.0291759  0.2844229  0.3878287  0.79258746 0.14317973\n",
      "  0.         1.025623   0.         0.12616009 0.         0.\n",
      "  0.         0.88835466 1.1486876  0.15188792]]\n",
      "Hi!\n",
      "[[0.3642912  0.         0.54703313 0.09727603 0.         0.53767574\n",
      "  1.4688944  1.3818783  0.81104887 0.         0.35419258 0.\n",
      "  0.00723341 0.         0.         0.6271014  0.         0.7379063\n",
      "  0.         0.         0.72777253 0.07320789 0.         0.06674836\n",
      "  0.08678706 0.         0.         0.1305786  0.         0.\n",
      "  0.5841515  0.10184874 0.06799098 0.         0.55596375 0.\n",
      "  0.         1.2148342  0.         0.5590358  0.15968882 0.\n",
      "  0.         1.111826   0.24540482 0.62917036 0.         0.13036187\n",
      "  0.         0.81179214 0.5219014  0.31496775 0.45789242 0.0319513\n",
      "  0.         0.         0.01883902 0.         0.         0.\n",
      "  0.         1.0342228  0.9598685  0.10394663]]\n",
      "Hi!\n",
      "[[0.3210159  0.4569288  0.2672971  0.12188385 0.         0.26299232\n",
      "  0.         0.27917898 0.         0.         0.12132006 0.\n",
      "  0.3956618  0.49473423 0.         0.         0.         0.12158786\n",
      "  0.         0.44581088 0.05759683 0.         0.         0.11818809\n",
      "  0.         0.         0.         0.16681613 0.         0.\n",
      "  0.422866   0.5860769  0.20903775 0.         0.         0.\n",
      "  0.         0.         0.49026555 0.06688505 0.         0.\n",
      "  0.         0.         0.65751916 0.5423002  0.         0.11356989\n",
      "  0.44673094 0.3493799  0.         0.38288632 0.33311304 0.79337186\n",
      "  0.         0.3343359  0.2011247  0.         0.         0.\n",
      "  0.15415764 0.09990076 0.07519314 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.0919764  0.07078838 0.0753128  0.         0.07979151\n",
      "  0.05783884 0.2877163  0.         0.05199171 0.03095726 0.\n",
      "  0.         0.15867665 0.         0.02887602 0.         0.02010021\n",
      "  0.         0.06237955 0.05017548 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01944803 0.20115283 0.27659974 0.         0.         0.\n",
      "  0.         0.         0.23942156 0.06891908 0.         0.\n",
      "  0.         0.         0.23563918 0.38386628 0.         0.02167306\n",
      "  0.13166049 0.17913392 0.         0.21352907 0.08905597 0.35625252\n",
      "  0.         0.17150284 0.03064036 0.         0.         0.\n",
      "  0.04572724 0.15404907 0.         0.        ]]\n",
      "Hi!\n",
      "[[4.7697854e-01 7.4588060e-01 7.9240298e-01 0.0000000e+00 0.0000000e+00\n",
      "  4.8288438e-01 3.9204049e-01 7.8227901e-01 1.4195071e+00 0.0000000e+00\n",
      "  5.5478990e-01 0.0000000e+00 2.0578198e+00 1.4582944e-01 0.0000000e+00\n",
      "  1.0708535e+00 0.0000000e+00 8.0153656e-01 1.5801109e+00 1.3662150e-04\n",
      "  9.7708917e-01 7.4363127e-02 0.0000000e+00 0.0000000e+00 5.4677534e-01\n",
      "  0.0000000e+00 0.0000000e+00 5.8666235e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0666735e+00 6.3774693e-01 0.0000000e+00 0.0000000e+00 6.5553176e-01\n",
      "  0.0000000e+00 9.2166841e-01 1.3800790e+00 0.0000000e+00 5.5193120e-01\n",
      "  1.5264793e-01 0.0000000e+00 0.0000000e+00 4.4924095e-01 6.9238788e-01\n",
      "  1.4593121e-01 0.0000000e+00 1.3170935e+00 0.0000000e+00 9.8004967e-01\n",
      "  1.3111829e+00 3.3553040e-01 2.6207504e-01 8.0305028e-01 0.0000000e+00\n",
      "  0.0000000e+00 4.9225885e-01 1.0979123e-02 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 5.5884761e-01 1.4726692e+00 9.4401300e-01]]\n",
      "Hi!\n",
      "[[0.21629567 0.41924602 0.41930103 0.         0.         0.5733602\n",
      "  0.17826155 0.4445351  0.         0.08586576 0.2392513  0.\n",
      "  0.149179   0.22162129 0.         0.         0.         0.33118913\n",
      "  0.         0.60765743 0.2774954  0.         0.         0.03902055\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37264797 0.37381873 0.04541767 0.         0.         0.\n",
      "  0.         0.12509874 0.         0.31963316 0.         0.\n",
      "  0.         0.         0.45933694 0.7810408  0.         0.14712216\n",
      "  0.37019256 0.67564714 0.         0.3632471  0.48717877 0.503524\n",
      "  0.         0.42285725 0.         0.         0.         0.\n",
      "  0.2090005  0.39549664 0.01961135 0.        ]]\n",
      "Hi!\n",
      "[[0.48245555 0.8241742  1.1073653  0.         0.         0.61805195\n",
      "  0.13954052 0.32499328 1.0561584  0.         0.6220527  0.\n",
      "  1.5217013  0.         0.         0.7627874  0.         0.7946208\n",
      "  0.88760346 0.295179   0.98232985 0.         0.         0.\n",
      "  0.29319784 0.         0.         0.22884011 0.         0.\n",
      "  0.6952218  0.5960062  0.         0.         0.37427717 0.\n",
      "  0.50874287 1.0231078  0.         0.68513805 0.         0.\n",
      "  0.         0.24705209 0.5515444  0.06736506 0.         1.132564\n",
      "  0.         0.82622397 0.90558356 0.3207839  0.2999877  0.731464\n",
      "  0.         0.         0.22523208 0.         0.05229086 0.\n",
      "  0.         0.6164576  1.141948   0.87328583]]\n",
      "Hi!\n",
      "[[0.2635135  0.4545365  0.7748171  0.         0.         0.66062427\n",
      "  0.38811466 0.62563306 0.5406392  0.         0.44076166 0.\n",
      "  0.7903367  0.         0.         0.3448815  0.         0.6222494\n",
      "  0.         0.3687987  0.68873256 0.         0.         0.\n",
      "  0.         0.         0.         0.10519461 0.         0.\n",
      "  0.68236566 0.50815296 0.         0.         0.3104721  0.\n",
      "  0.         0.713266   0.         0.4124831  0.         0.\n",
      "  0.         0.19559275 0.5309872  0.6109762  0.         0.48718944\n",
      "  0.         0.8052108  0.4519223  0.42302892 0.6675563  0.52060103\n",
      "  0.         0.04537727 0.05644102 0.         0.         0.\n",
      "  0.         0.56652766 0.7744563  0.24847503]]\n",
      "Hi!\n",
      "[[0.06312817 0.43774155 0.5844477  0.         0.         0.25212443\n",
      "  0.47081065 0.4274229  0.8059369  0.         0.43866435 0.\n",
      "  0.52051723 0.         0.         0.5863799  0.         0.6922129\n",
      "  0.02268607 0.16803813 0.57576233 0.11397336 0.         0.\n",
      "  0.04722157 0.         0.         0.00485708 0.         0.\n",
      "  0.3408041  0.13625316 0.         0.         0.330392   0.\n",
      "  0.06687654 0.7829892  0.         0.40916333 0.03330861 0.\n",
      "  0.         0.4942914  0.06528214 0.14382689 0.         0.3973963\n",
      "  0.         0.6128826  0.6171926  0.         0.13254073 0.08964472\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.8382706  0.3869094  0.44600955]]\n",
      "Hi!\n",
      "[[0.49368143 0.45062163 0.8814345  0.         0.         0.74171156\n",
      "  0.3152429  0.826446   0.68606335 0.         0.4705439  0.\n",
      "  1.0854714  0.         0.         0.40458626 0.         0.5175986\n",
      "  0.33527556 0.31224158 0.7824006  0.         0.         0.\n",
      "  0.         0.         0.         0.36864555 0.         0.\n",
      "  0.85292464 0.6930987  0.         0.         0.31609446 0.\n",
      "  0.18912257 0.89879984 0.         0.3501952  0.         0.\n",
      "  0.         0.21925367 0.6703951  0.60530776 0.         0.65726227\n",
      "  0.         0.760805   0.57516944 0.54446346 0.7096426  0.6884622\n",
      "  0.         0.05417317 0.21164276 0.         0.00218891 0.\n",
      "  0.         0.4179051  1.2415763  0.27167696]]\n",
      "Hi!\n",
      "[[0.3110698  0.24325596 0.3035062  0.05988684 0.         0.47329313\n",
      "  0.84279084 1.0125822  0.33594444 0.         0.30818093 0.\n",
      "  0.5850497  0.24035567 0.         0.37987372 0.         0.6248872\n",
      "  0.         0.19758414 0.44163254 0.         0.         0.\n",
      "  0.04789779 0.         0.         0.3258138  0.         0.\n",
      "  0.91804355 0.46596542 0.         0.         0.51373714 0.\n",
      "  0.         0.89601433 0.         0.25988865 0.         0.\n",
      "  0.         0.25597638 0.7622639  0.84868044 0.         0.2236302\n",
      "  0.         0.79618275 0.36213744 0.40819225 0.55953825 0.42821482\n",
      "  0.         0.         0.19915633 0.         0.         0.\n",
      "  0.         0.6213077  0.71811044 0.        ]]\n",
      "Hi!\n",
      "[[0.03684999 0.20674285 0.5680749  0.         0.         0.45672718\n",
      "  0.         0.         0.3061414  0.16489705 0.3842588  0.\n",
      "  0.         0.         0.         0.16690403 0.04731758 0.01368969\n",
      "  0.         0.48833263 0.4005328  0.         0.         0.04061665\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05033965 0.         0.         0.\n",
      "  0.         0.         0.03265683 0.30923697 0.         0.\n",
      "  0.         0.         0.         0.26613343 0.         0.3372461\n",
      "  0.24258056 0.09962743 0.09648632 0.28090748 0.09097533 0.29399896\n",
      "  0.         0.26889694 0.         0.         0.17411764 0.\n",
      "  0.06613921 0.04132169 0.00679782 0.18783617]]\n",
      "Hi!\n",
      "[[0.4502127  1.0783747  0.81070936 0.         0.         0.7101763\n",
      "  0.         0.21143778 0.47772816 0.         0.4790734  0.\n",
      "  1.3496495  0.3709443  0.         0.1349898  0.         0.4051631\n",
      "  0.2327903  0.82110107 0.59260243 0.         0.         0.14718662\n",
      "  0.         0.         0.         0.08233598 0.         0.\n",
      "  0.5637797  0.51408625 0.         0.         0.00560821 0.\n",
      "  0.07079983 0.29005942 0.26808852 0.34213752 0.         0.\n",
      "  0.         0.         0.6537905  0.5100899  0.         0.89496905\n",
      "  0.27375242 0.5284765  0.47844875 0.40803227 0.50370294 0.9573999\n",
      "  0.         0.         0.16933799 0.         0.09816708 0.\n",
      "  0.         0.14851059 0.3965299  0.43662617]]\n",
      "Hi!\n",
      "[[0.40461186 0.         0.27260542 0.15202403 0.         0.78042704\n",
      "  1.0033053  0.9777683  0.         0.12115736 0.16509746 0.\n",
      "  0.         0.         0.         0.09160133 0.         0.39573392\n",
      "  0.         0.39019457 0.20935829 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3768924  0.32316    0.2062009  0.         0.12761553 0.\n",
      "  0.         0.45214552 0.         0.4427192  0.         0.\n",
      "  0.         0.24920264 0.5084506  0.99527633 0.         0.0150682\n",
      "  0.21246888 0.83709747 0.         0.5144394  0.55189896 0.5008057\n",
      "  0.         0.7011952  0.         0.         0.         0.\n",
      "  0.17111729 0.5756613  0.22848055 0.        ]]\n",
      "Hi!\n",
      "[[0.57820517 0.         0.5929123  0.41049105 0.         0.6560081\n",
      "  2.0364501  1.8145486  0.69594616 0.         0.3224393  0.\n",
      "  0.         0.         0.         0.48892453 0.16975611 0.8132724\n",
      "  0.         0.         0.7100502  0.28978392 0.         0.14859131\n",
      "  0.         0.         0.         0.08820046 0.         0.\n",
      "  0.42929006 0.07155375 0.24929804 0.         0.5513501  0.\n",
      "  0.         1.2320454  0.         0.7075055  0.3232028  0.\n",
      "  0.         1.564088   0.14981812 0.80861527 0.         0.\n",
      "  0.         0.9503144  0.28058562 0.24985896 0.62665766 0.\n",
      "  0.         0.25170714 0.         0.         0.         0.\n",
      "  0.         1.3117683  0.94914436 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.11421677 0.15224373 0.         0.         0.25568175\n",
      "  0.13054487 0.27545112 0.         0.14885622 0.18774877 0.\n",
      "  0.         0.06573485 0.         0.         0.         0.08716787\n",
      "  0.         0.28110376 0.10546288 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1462864  0.         0.         0.\n",
      "  0.         0.         0.14472333 0.22611573 0.         0.\n",
      "  0.         0.         0.17884088 0.44525793 0.         0.\n",
      "  0.20815781 0.17546202 0.         0.21570665 0.1874371  0.30733442\n",
      "  0.         0.246474   0.         0.         0.         0.\n",
      "  0.03734123 0.08419448 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4135743  0.16044436 0.5048706  0.0293961  0.         0.72178936\n",
      "  0.5842673  0.7391709  0.10629161 0.23518074 0.24409498 0.\n",
      "  0.         0.         0.         0.14950784 0.01495145 0.3971104\n",
      "  0.         0.43672296 0.39520103 0.         0.         0.26799533\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13653378 0.         0.         0.\n",
      "  0.         0.17941603 0.         0.7774083  0.         0.\n",
      "  0.         0.56257105 0.         0.8624416  0.         0.\n",
      "  0.44428247 1.0456524  0.00537182 0.28016624 0.56581    0.05314124\n",
      "  0.         0.6420711  0.         0.         0.         0.\n",
      "  0.4016834  0.8143684  0.         0.        ]]\n",
      "Hi!\n",
      "[[7.4361855e-01 0.0000000e+00 1.4993992e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.7206848e-01 5.5851012e-01 5.5827945e-01 1.3113254e+00 0.0000000e+00\n",
      "  6.7436975e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.6876312e-01 6.6580874e-01 9.6100491e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.2971586e+00 4.2356619e-01 0.0000000e+00 5.8558232e-01 3.3164310e-04\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 6.2975749e-02 0.0000000e+00 4.2993929e-02\n",
      "  0.0000000e+00 5.3353731e-02 9.9967819e-01 0.0000000e+00 9.0338349e-01\n",
      "  1.0154522e-01 0.0000000e+00 0.0000000e+00 1.3621148e+00 0.0000000e+00\n",
      "  6.6500731e-02 0.0000000e+00 3.9501819e-01 0.0000000e+00 7.7251047e-01\n",
      "  6.4631736e-01 0.0000000e+00 2.3039104e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.7568125e-01 0.0000000e+00 6.3394302e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.1770983e+00 9.7243571e-01 7.3646897e-01]]\n",
      "Hi!\n",
      "[[0.30290928 0.         0.60197586 0.04070089 0.         0.69854695\n",
      "  1.120547   1.3116034  0.89247507 0.         0.41434246 0.\n",
      "  0.8865565  0.         0.         0.702119   0.         0.72867006\n",
      "  0.45555434 0.         0.7618758  0.05893322 0.         0.\n",
      "  0.24025671 0.         0.         0.5371752  0.         0.\n",
      "  0.9915577  0.4678306  0.         0.         0.6955867  0.\n",
      "  0.2769725  1.3529608  0.         0.316584   0.17191976 0.\n",
      "  0.         0.7179566  0.6485288  0.7260715  0.         0.5214572\n",
      "  0.         0.68224794 0.69049156 0.42491361 0.5881378  0.36316124\n",
      "  0.         0.         0.34546015 0.         0.         0.\n",
      "  0.         0.7400304  1.4294028  0.25153443]]\n",
      "Hi!\n",
      "[[0.06894869 0.0153053  0.         0.02905693 0.         0.17990172\n",
      "  0.30661884 0.4069785  0.         0.09335529 0.03014979 0.\n",
      "  0.         0.23883313 0.         0.01711532 0.         0.02860315\n",
      "  0.         0.15761268 0.01890965 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12394511 0.18939626 0.2645498  0.         0.         0.\n",
      "  0.         0.02050697 0.2837866  0.10909318 0.         0.\n",
      "  0.         0.         0.3384193  0.58204657 0.         0.01834953\n",
      "  0.22379588 0.26155117 0.         0.2990969  0.10886792 0.44464406\n",
      "  0.         0.27357003 0.03681844 0.         0.         0.\n",
      "  0.05760459 0.14982411 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5940536  0.         1.0706707  0.         0.         0.7276852\n",
      "  0.8897508  0.6615005  0.79632    0.         0.41714537 0.\n",
      "  0.         0.         0.         0.39522257 0.40473124 0.83718985\n",
      "  0.         0.029856   0.88858503 0.2340156  0.         0.16485777\n",
      "  0.07153558 0.         0.         0.         0.         0.\n",
      "  0.         0.10799895 0.01503832 0.         0.2507054  0.\n",
      "  0.01013998 0.9012215  0.         0.5837055  0.01544425 0.\n",
      "  0.         0.9386344  0.         0.32339802 0.         0.42881805\n",
      "  0.         0.61705434 0.39758733 0.11849725 0.15406902 0.15492575\n",
      "  0.         0.26472077 0.         0.294754   0.         0.\n",
      "  0.         0.9370176  0.7054705  0.35076383]]\n",
      "Hi!\n",
      "[[0.4962684  0.         0.33346003 0.3171     0.         0.7719776\n",
      "  1.3151906  1.7479696  0.6822726  0.         0.33813408 0.\n",
      "  1.081242   0.33860108 0.         0.61824566 0.         0.600512\n",
      "  0.6142922  0.         0.62072396 0.25751594 0.         0.\n",
      "  0.219079   0.         0.         0.97242785 0.         0.\n",
      "  1.4050691  0.7394945  0.         0.         0.8706465  0.\n",
      "  0.51297945 1.417167   0.         0.15194654 0.31063262 0.\n",
      "  0.         0.64174896 1.1874659  1.1016442  0.         0.5449267\n",
      "  0.         0.69327885 0.6741338  0.6002591  0.6416616  0.7627383\n",
      "  0.         0.         0.61107314 0.         0.         0.\n",
      "  0.         0.51648927 1.683849   0.        ]]\n",
      "Hi!\n",
      "[[0.12433177 0.27310598 0.07614902 0.         0.         0.07383376\n",
      "  0.         0.05179305 0.12491922 0.         0.15545359 0.\n",
      "  0.35106564 0.229638   0.         0.08572503 0.         0.03760574\n",
      "  0.         0.14076217 0.14275587 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16641906 0.22102502 0.09121413 0.         0.         0.\n",
      "  0.         0.         0.19213815 0.02218424 0.         0.\n",
      "  0.         0.         0.15195768 0.12707768 0.         0.12314956\n",
      "  0.0891722  0.08819158 0.07521113 0.15633313 0.         0.5204481\n",
      "  0.         0.         0.18573205 0.         0.         0.\n",
      "  0.13100211 0.07643194 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.98127294 0.         1.8730674  0.         0.         0.80905503\n",
      "  0.3461152  0.38916284 1.3897676  0.         0.72467655 0.\n",
      "  0.         0.         0.         0.72714746 1.0063463  0.97669816\n",
      "  0.         0.         1.4435829  0.5602467  0.         0.61533254\n",
      "  0.0395508  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07318466 0.         0.         0.\n",
      "  0.14691547 0.9457723  0.         0.9893056  0.07997442 0.\n",
      "  0.         1.4399582  0.         0.11086692 0.         0.6179451\n",
      "  0.         0.83586127 0.7041354  0.         0.24256845 0.\n",
      "  0.         0.43289846 0.         0.90872794 0.00202638 0.\n",
      "  0.         1.1282713  1.0021435  0.8869819 ]]\n",
      "Hi!\n",
      "[[0.4884458  0.24873136 0.01328271 0.20096965 0.         0.46924278\n",
      "  1.4175829  1.8046778  1.0095251  0.         0.29858658 0.\n",
      "  1.9912875  0.93498564 0.         1.0509945  0.         0.73865956\n",
      "  1.29229    0.         0.53026104 0.48984846 0.         0.\n",
      "  0.6343573  0.         0.         1.149735   0.         0.\n",
      "  1.7168041  0.8084302  0.         0.         1.1865808  0.\n",
      "  0.94381356 1.7167542  0.15247832 0.0112624  0.26761565 0.\n",
      "  0.         0.6243378  1.3816599  0.89381135 0.         1.065297\n",
      "  0.         0.7359795  1.2394834  0.46314898 0.5837379  1.0496354\n",
      "  0.         0.         0.7313071  0.         0.         0.\n",
      "  0.         0.45448986 1.5372528  0.18177727]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3160222  0.52840775 0.5435689  0.         0.         0.50371474\n",
      "  0.51255536 0.8738519  0.60676247 0.         0.41760325 0.\n",
      "  1.1357423  0.3090672  0.         0.52580553 0.         0.6615555\n",
      "  0.17601122 0.19982941 0.61542547 0.         0.         0.02817977\n",
      "  0.05590284 0.         0.         0.3977083  0.         0.\n",
      "  1.030334   0.58650726 0.         0.         0.49196285 0.\n",
      "  0.04306309 0.8907667  0.         0.3276555  0.         0.\n",
      "  0.         0.19015363 0.7353001  0.65238947 0.         0.4171972\n",
      "  0.         0.83485687 0.6340711  0.41398004 0.6920305  0.56577903\n",
      "  0.         0.         0.18520898 0.         0.         0.\n",
      "  0.         0.63809705 0.88716096 0.25196403]]\n",
      "Hi!\n",
      "[[0.42933446 0.         1.0533973  0.01281388 0.         0.64455277\n",
      "  1.6560159  1.7068892  1.9318627  0.         0.58033675 0.\n",
      "  0.2709642  0.         0.         1.3120211  0.32705364 0.9722199\n",
      "  0.5525189  0.         1.206501   0.5469893  0.         0.29111618\n",
      "  0.33439687 0.         0.         0.42849523 0.         0.\n",
      "  0.66651136 0.         0.         0.         0.60208714 0.\n",
      "  0.6661148  1.7559211  0.         0.5930843  0.48687032 0.\n",
      "  0.         2.1209095  0.         0.21660805 0.         0.36986047\n",
      "  0.         0.80192566 1.2286898  0.18670222 0.33010212 0.\n",
      "  0.         0.         0.16739252 0.77739215 0.         0.\n",
      "  0.         1.3207695  1.7679733  0.71266884]]\n",
      "Hi!\n",
      "[[0.71702605 0.11903464 1.0368502  0.0656818  0.         1.032885\n",
      "  0.5284485  0.55101687 0.18923339 0.0744784  0.299948   0.\n",
      "  0.         0.         0.         0.09131886 0.203857   0.531607\n",
      "  0.         0.5140252  0.63611823 0.         0.         0.09778361\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02656584 0.44981858 0.0673581  0.         0.         0.\n",
      "  0.         0.4225596  0.         0.62783533 0.         0.\n",
      "  0.         0.41631    0.30668017 0.66737247 0.         0.49615932\n",
      "  0.3887801  0.75782824 0.02892307 0.4185667  0.46468884 0.6157996\n",
      "  0.         1.1292818  0.         0.         0.         0.\n",
      "  0.3358615  0.5331592  0.50340277 0.03246265]]\n",
      "Hi!\n",
      "[[0.4094055  0.5311903  0.9175641  0.         0.         0.81016713\n",
      "  0.         0.06435078 0.22317623 0.06787822 0.41873944 0.\n",
      "  0.38292181 0.         0.         0.06465918 0.02536206 0.49109635\n",
      "  0.         0.73047584 0.55620927 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1644479  0.38338816 0.         0.         0.         0.\n",
      "  0.         0.28513652 0.         0.5196049  0.         0.\n",
      "  0.         0.         0.3700302  0.47413552 0.         0.6852218\n",
      "  0.42128456 0.5941425  0.16944525 0.38038558 0.37703487 0.6297939\n",
      "  0.         0.53639114 0.         0.         0.10454466 0.\n",
      "  0.17074129 0.36465073 0.41316742 0.24410246]]\n",
      "Hi!\n",
      "[[0.6605428  0.         0.7664224  0.19564322 0.         0.5343865\n",
      "  1.6801044  1.5264301  1.005619   0.         0.41584134 0.\n",
      "  0.         0.         0.         0.6721288  0.4119786  0.8611313\n",
      "  0.         0.         0.86587673 0.44771194 0.         0.29618245\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18355292 0.         0.20479012 0.         0.4077252  0.\n",
      "  0.         1.1850342  0.         0.7618193  0.2168829  0.\n",
      "  0.         1.711843   0.         0.46875966 0.         0.\n",
      "  0.         0.8976903  0.5012147  0.10619334 0.4153033  0.\n",
      "  0.         0.12463029 0.         0.26567227 0.         0.\n",
      "  0.         1.37915    0.8098331  0.07240387]]\n",
      "Hi!\n",
      "[[0.56759423 0.20312795 1.109849   0.         0.         0.6993154\n",
      "  0.28662443 0.23642033 0.6667008  0.03472091 0.48209354 0.\n",
      "  0.01788845 0.         0.         0.3359963  0.321472   0.7588805\n",
      "  0.         0.29911885 0.83953387 0.09106027 0.         0.17238419\n",
      "  0.00292516 0.         0.         0.         0.         0.\n",
      "  0.         0.10330587 0.         0.         0.0265086  0.\n",
      "  0.         0.6137327  0.         0.62053525 0.         0.\n",
      "  0.         0.5487871  0.         0.2531094  0.         0.51685524\n",
      "  0.02719071 0.6194493  0.38193592 0.16064161 0.16276936 0.19406466\n",
      "  0.         0.23815112 0.         0.19985107 0.04382202 0.\n",
      "  0.04150939 0.7959816  0.5005762  0.5051895 ]]\n",
      "Hi!\n",
      "[[0.7442979  0.0622359  1.3495232  0.         0.         0.83914244\n",
      "  0.27856404 0.33434436 0.6887694  0.0158249  0.5349528  0.\n",
      "  0.         0.         0.         0.29389524 0.4814995  0.74998325\n",
      "  0.         0.26225778 0.97029096 0.13815969 0.         0.3354777\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18750143 0.04766976 0.         0.         0.\n",
      "  0.         0.56003755 0.         0.7796628  0.         0.\n",
      "  0.         0.71981514 0.         0.2973771  0.         0.35422805\n",
      "  0.13316354 0.7078672  0.34613758 0.16684659 0.33154154 0.15286647\n",
      "  0.         0.57218564 0.         0.19709076 0.0349769  0.\n",
      "  0.13517874 0.80197465 0.62442315 0.41875702]]\n",
      "Hi!\n",
      "[[0.35164028 0.32206148 1.0658958  0.         0.         0.64743894\n",
      "  0.3897205  0.61830425 1.0030705  0.         0.5643385  0.\n",
      "  0.73040056 0.         0.         0.6496543  0.02157033 0.74268734\n",
      "  0.09811616 0.03859686 0.93830043 0.         0.         0.16739362\n",
      "  0.         0.         0.         0.02405303 0.         0.\n",
      "  0.46565935 0.35596743 0.         0.         0.23441596 0.\n",
      "  0.04945181 0.87900734 0.         0.62286717 0.0506246  0.\n",
      "  0.         0.66900074 0.13534485 0.31241012 0.         0.4904008\n",
      "  0.         0.85337055 0.7139772  0.35068187 0.55255306 0.2917347\n",
      "  0.         0.         0.         0.11953867 0.         0.\n",
      "  0.         0.76048994 0.9064767  0.58802295]]\n",
      "Hi!\n",
      "[[1.2410454  0.17160684 1.8421867  0.         0.         1.2922488\n",
      "  0.3178263  0.54957587 0.8779809  0.03229349 0.6505485  0.\n",
      "  0.         0.         0.         0.27562022 0.8196685  0.71304107\n",
      "  0.         0.22704536 1.3548293  0.17734325 0.         0.8164529\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27748653 0.20837013 0.         0.         0.\n",
      "  0.         0.40180928 0.         0.971259   0.         0.\n",
      "  0.         1.1302482  0.         0.35742474 0.         0.157203\n",
      "  0.26600185 1.2643586  0.30713734 0.28169358 0.9238727  0.1273857\n",
      "  0.         1.4272757  0.         0.31537077 0.02382822 0.\n",
      "  0.2333929  0.84948176 0.86724395 0.45872045]]\n",
      "Hi!\n",
      "[[0.08723989 0.24301307 0.15997967 0.         0.         0.09918307\n",
      "  0.         0.05345446 0.09240202 0.05905485 0.1303811  0.\n",
      "  0.2881317  0.096544   0.         0.03343036 0.         0.0345375\n",
      "  0.         0.11854687 0.10684314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09420935 0.22670655 0.0666559  0.         0.         0.\n",
      "  0.         0.         0.15891482 0.04945359 0.         0.\n",
      "  0.         0.         0.09413963 0.05042908 0.         0.08439814\n",
      "  0.06770934 0.09083565 0.01278201 0.12438812 0.04279435 0.3460058\n",
      "  0.         0.         0.12293781 0.         0.02572686 0.\n",
      "  0.10900804 0.03737918 0.         0.00082626]]\n",
      "Hi!\n",
      "[[0.0454185  0.37529078 0.45825583 0.         0.         0.3681626\n",
      "  0.         0.         0.1396793  0.08251623 0.25780633 0.\n",
      "  0.15929422 0.         0.         0.05662761 0.         0.13507314\n",
      "  0.         0.5232582  0.24270566 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12439105 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23139022 0.         0.\n",
      "  0.         0.         0.03132833 0.27005228 0.         0.27853057\n",
      "  0.32868803 0.23972115 0.00101174 0.2550197  0.1231585  0.3920442\n",
      "  0.         0.2437475  0.         0.         0.14760964 0.\n",
      "  0.19824122 0.13706513 0.         0.15869083]]\n",
      "Hi!\n",
      "[[0.72766656 0.44094017 1.8844069  0.         0.         0.76949215\n",
      "  0.06526718 0.         1.2614919  0.         0.7993748  0.\n",
      "  0.5334603  0.         0.         0.77622974 0.66826314 0.8984754\n",
      "  0.2605187  0.23028791 1.3921208  0.34304774 0.         0.37712792\n",
      "  0.04324729 0.         0.         0.         0.         0.\n",
      "  0.         0.20147778 0.04764742 0.         0.         0.\n",
      "  0.33440247 0.82775897 0.         0.92309695 0.         0.\n",
      "  0.         0.82183176 0.         0.         0.         0.9116415\n",
      "  0.         0.88843346 0.67531633 0.05680153 0.2035132  0.18318708\n",
      "  0.         0.1795193  0.         0.7090023  0.15741323 0.\n",
      "  0.03143666 0.8949235  1.1390915  1.0479407 ]]\n",
      "Hi!\n",
      "[[0.04302927 0.2793473  0.23518296 0.         0.         0.19883114\n",
      "  0.         0.06682951 0.01176095 0.01952883 0.19366032 0.\n",
      "  0.12112909 0.12553246 0.         0.         0.         0.04481286\n",
      "  0.         0.3377573  0.14724067 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04163734 0.26038238 0.1371821  0.         0.         0.\n",
      "  0.         0.         0.21675098 0.16298567 0.         0.\n",
      "  0.         0.         0.20560203 0.28273308 0.         0.09987129\n",
      "  0.28198552 0.15532176 0.         0.24545698 0.07494087 0.42356503\n",
      "  0.         0.20120852 0.03853258 0.         0.         0.\n",
      "  0.11942229 0.06390959 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.07847508 0.11607258 0.         0.         0.15095821\n",
      "  0.11750828 0.24267088 0.         0.13013412 0.10891819 0.\n",
      "  0.         0.07126608 0.         0.08330581 0.         0.04366339\n",
      "  0.         0.11941272 0.09702156 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04189244 0.1340319  0.         0.         0.\n",
      "  0.         0.01749128 0.08785624 0.1251954  0.         0.\n",
      "  0.         0.         0.14941454 0.34865013 0.         0.\n",
      "  0.14590591 0.20430839 0.         0.19893646 0.13382085 0.2625383\n",
      "  0.         0.13076416 0.         0.         0.         0.\n",
      "  0.09426412 0.21122597 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.40072775 0.16762187 0.61523205 0.03145923 0.         0.71904284\n",
      "  0.39921835 0.4382997  0.         0.08987285 0.2297915  0.\n",
      "  0.         0.         0.         0.10632718 0.         0.41121197\n",
      "  0.         0.51893985 0.36208272 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18565778 0.40344894 0.08931684 0.         0.         0.\n",
      "  0.         0.29416326 0.         0.38647562 0.         0.\n",
      "  0.         0.08490813 0.4135166  0.685537   0.         0.34158903\n",
      "  0.3681324  0.60301363 0.         0.41502187 0.3635163  0.5229485\n",
      "  0.         0.7715994  0.         0.         0.         0.\n",
      "  0.22237256 0.39155325 0.2718562  0.        ]]\n",
      "Hi!\n",
      "[[0.92525727 0.08406772 1.5453862  0.         0.         1.2052014\n",
      "  0.34887418 0.5025012  0.5065973  0.03491509 0.5424869  0.\n",
      "  0.         0.         0.         0.15576887 0.4947351  0.65611553\n",
      "  0.         0.44930968 1.0111895  0.00254503 0.         0.42756495\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.42988706 0.14615606 0.         0.         0.\n",
      "  0.         0.420033   0.         0.8420245  0.         0.\n",
      "  0.         0.7298655  0.         0.48624647 0.         0.2956632\n",
      "  0.28899652 0.9308388  0.1711991  0.33347267 0.68091655 0.32274884\n",
      "  0.         1.2160848  0.         0.03537272 0.0365034  0.\n",
      "  0.260786   0.69220966 0.8139461  0.1547045 ]]\n",
      "Hi!\n",
      "[[0.05523968 0.21665171 0.22428854 0.         0.         0.121853\n",
      "  0.         0.02266331 0.10384898 0.05882667 0.14098358 0.\n",
      "  0.21299638 0.04467573 0.         0.07875542 0.         0.\n",
      "  0.         0.17768447 0.14850943 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02071591 0.10212928 0.07530558 0.         0.         0.\n",
      "  0.         0.         0.15182649 0.11323231 0.         0.\n",
      "  0.         0.         0.0833912  0.122665   0.         0.10790029\n",
      "  0.13137265 0.07809403 0.01349504 0.22624512 0.09666678 0.33398703\n",
      "  0.         0.         0.05505132 0.         0.02967513 0.\n",
      "  0.02768181 0.04927021 0.         0.01101915]]\n",
      "Hi!\n",
      "[[0.5169729  0.02039175 0.06594108 0.27776688 0.         0.56100833\n",
      "  1.3548295  1.5775186  0.41698202 0.         0.23645703 0.\n",
      "  0.9891235  0.62038344 0.         0.57457626 0.         0.63381475\n",
      "  0.35546458 0.         0.3571333  0.23556788 0.         0.\n",
      "  0.3377414  0.         0.         0.69926655 0.         0.\n",
      "  1.3124036  0.64550245 0.         0.         0.8908208  0.\n",
      "  0.4920091  1.3864856  0.03949119 0.14628477 0.22814071 0.\n",
      "  0.         0.49360633 1.2203122  1.0973347  0.         0.58621013\n",
      "  0.         0.7425694  0.6439371  0.5628428  0.55080897 0.86619884\n",
      "  0.         0.         0.5326626  0.         0.         0.\n",
      "  0.         0.49411067 1.1250852  0.        ]]\n",
      "Hi!\n",
      "[[0.6954062  0.11016612 1.8424507  0.         0.         0.80675507\n",
      "  0.36637965 0.27155006 1.6889774  0.         0.8031271  0.\n",
      "  0.5161415  0.         0.         1.0528322  0.76751614 1.0539328\n",
      "  0.48805207 0.         1.5604984  0.56734645 0.         0.543675\n",
      "  0.28254244 0.         0.         0.         0.         0.\n",
      "  0.         0.05276304 0.         0.         0.07493755 0.\n",
      "  0.48406664 1.2191719  0.         1.0394038  0.14132574 0.\n",
      "  0.         1.4156802  0.         0.         0.         0.9499191\n",
      "  0.         0.99738747 0.9802444  0.         0.13261579 0.\n",
      "  0.         0.         0.         1.0097439  0.04900142 0.\n",
      "  0.         1.2494081  1.2780161  1.2760377 ]]\n",
      "Hi!\n",
      "[[0.         0.13346493 0.         0.06198072 0.         0.15040384\n",
      "  0.12892897 0.39639997 0.         0.06342399 0.07739384 0.\n",
      "  0.         0.22789973 0.         0.         0.         0.12199263\n",
      "  0.         0.24693827 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06995258 0.16044961 0.2813994  0.         0.         0.\n",
      "  0.         0.         0.19050245 0.13852742 0.         0.\n",
      "  0.         0.         0.2529915  0.572842   0.         0.\n",
      "  0.21166755 0.25939754 0.         0.2581275  0.085632   0.40425903\n",
      "  0.         0.2668758  0.00950388 0.         0.         0.\n",
      "  0.08864763 0.22628984 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.25194007 0.5499069  0.6422849  0.         0.         0.58356583\n",
      "  0.         0.16871846 0.         0.01181774 0.27339008 0.\n",
      "  0.33177173 0.20300926 0.         0.         0.         0.21983248\n",
      "  0.         0.7577168  0.2686357  0.         0.         0.05764899\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27981645 0.5027808  0.01927187 0.         0.         0.\n",
      "  0.         0.         0.16334714 0.25523788 0.         0.\n",
      "  0.         0.         0.5039842  0.5299035  0.         0.3110709\n",
      "  0.5351267  0.53633827 0.         0.41081956 0.47975686 0.7243007\n",
      "  0.         0.54279363 0.02658934 0.         0.02729811 0.\n",
      "  0.19859931 0.18865225 0.20329328 0.        ]]\n",
      "Hi!\n",
      "[[0.76438665 0.5094207  0.40810055 0.27853835 0.         0.8452458\n",
      "  0.35079843 0.7764742  0.         0.         0.20815714 0.\n",
      "  0.62686837 0.6416741  0.         0.         0.         0.09931833\n",
      "  0.         0.91132534 0.16343527 0.         0.         0.13966148\n",
      "  0.         0.         0.         0.31901264 0.         0.\n",
      "  0.91654193 0.9016094  0.30943635 0.         0.1269914  0.\n",
      "  0.         0.31132674 0.6211398  0.10423114 0.         0.\n",
      "  0.         0.16907439 1.1777103  1.2046105  0.         0.56489855\n",
      "  0.70854706 0.79487073 0.         0.77945113 0.8602535  1.2864629\n",
      "  0.         0.84090173 0.33412424 0.         0.         0.\n",
      "  0.         0.         0.608658   0.        ]]\n",
      "Hi!\n",
      "[[1.072591   0.37617826 1.779648   0.         0.         1.2612666\n",
      "  0.13397732 0.28206095 0.73219    0.04250399 0.6520465  0.\n",
      "  0.058944   0.         0.         0.18367618 0.60551566 0.6580352\n",
      "  0.         0.5178074  1.2372878  0.00183712 0.         0.59172666\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3871351  0.09958876 0.         0.         0.\n",
      "  0.         0.3918118  0.         0.87134314 0.         0.\n",
      "  0.         0.6567907  0.         0.33844504 0.         0.5453127\n",
      "  0.41780064 0.9759499  0.33625856 0.35261288 0.77005273 0.38578677\n",
      "  0.         1.2330942  0.         0.25887635 0.12668231 0.\n",
      "  0.24323058 0.6301265  0.83993816 0.584544  ]]\n",
      "Hi!\n",
      "[[0.5132002  0.07967899 1.2279614  0.         0.         0.9407461\n",
      "  0.57959163 0.762455   0.8882868  0.         0.5464522  0.\n",
      "  0.4344407  0.         0.         0.50237715 0.15786117 0.7125977\n",
      "  0.         0.0362326  1.0600349  0.         0.         0.33312723\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29902968 0.36920783 0.00887073 0.         0.1883419  0.\n",
      "  0.         0.8961267  0.         0.58509207 0.04736925 0.\n",
      "  0.         0.74848884 0.12350509 0.46136376 0.         0.5250724\n",
      "  0.         0.79210615 0.4983231  0.40407488 0.5930839  0.29752716\n",
      "  0.         0.40159273 0.         0.12051486 0.         0.\n",
      "  0.         0.79814476 1.1905477  0.4420444 ]]\n",
      "Hi!\n",
      "[[0.         0.         0.         0.06311142 0.         0.11823799\n",
      "  0.29773617 0.44027504 0.         0.08940959 0.         0.\n",
      "  0.         0.19494648 0.         0.03094807 0.         0.08032721\n",
      "  0.         0.10874154 0.0239748  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09797892 0.16643052 0.27093112 0.         0.         0.\n",
      "  0.         0.         0.22102663 0.12882864 0.         0.\n",
      "  0.         0.0192249  0.31201345 0.58693814 0.         0.\n",
      "  0.24412869 0.2525347  0.         0.27382466 0.06265699 0.34552735\n",
      "  0.         0.2939799  0.         0.         0.         0.\n",
      "  0.07237642 0.23829795 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6503939  0.3562936  0.32530364 0.13959494 0.         0.7019802\n",
      "  0.7544799  0.921212   0.11933389 0.         0.17009783 0.\n",
      "  0.8593057  0.37350067 0.         0.25670764 0.         0.44562644\n",
      "  0.12317741 0.37159693 0.33029553 0.00625325 0.         0.00369209\n",
      "  0.17465493 0.         0.         0.5457562  0.         0.\n",
      "  0.98889947 0.6907225  0.12020304 0.         0.5278753  0.\n",
      "  0.41206807 0.9994728  0.23304391 0.22901808 0.02553998 0.\n",
      "  0.         0.37861407 1.117692   0.85766804 0.         0.9066304\n",
      "  0.09718302 0.58197653 0.38246417 0.53199875 0.34958574 1.1706948\n",
      "  0.         0.18407306 0.48850572 0.         0.         0.\n",
      "  0.         0.22129947 0.8302948  0.        ]]\n",
      "Hi!\n",
      "[[0.7849106  0.         0.96698636 0.21506001 0.         0.97701395\n",
      "  0.68986654 0.8811655  0.38556346 0.15338157 0.35022753 0.\n",
      "  0.         0.         0.         0.17718776 0.25131312 0.5637999\n",
      "  0.         0.27246878 0.7305191  0.10681338 0.         0.4096868\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13751394 0.32051256 0.         0.         0.\n",
      "  0.         0.36110532 0.         1.0201594  0.         0.\n",
      "  0.         0.98819816 0.         0.7707723  0.         0.\n",
      "  0.28102624 1.3694023  0.03024979 0.35345787 0.96902525 0.\n",
      "  0.         1.0992686  0.         0.         0.         0.\n",
      "  0.30526116 0.9149274  0.20019937 0.        ]]\n",
      "Hi!\n",
      "[[0.04867797 0.19003035 0.07379524 0.         0.         0.15688558\n",
      "  0.01498353 0.16012038 0.         0.0999593  0.12238159 0.\n",
      "  0.08658069 0.19995378 0.         0.00605421 0.         0.07627955\n",
      "  0.         0.19885762 0.05750201 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08755473 0.16158998 0.14052661 0.         0.         0.\n",
      "  0.         0.         0.13553698 0.09911027 0.         0.\n",
      "  0.         0.         0.26259452 0.32215568 0.         0.05892549\n",
      "  0.16724426 0.13636379 0.         0.16227126 0.08178423 0.34083626\n",
      "  0.         0.11154924 0.06562699 0.         0.0082728  0.\n",
      "  0.0872606  0.07488382 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.85867816 0.08454503 1.3983909  0.         0.         0.87796175\n",
      "  0.3796795  0.423907   0.89057916 0.08166642 0.5691345  0.\n",
      "  0.         0.         0.         0.29086158 0.64472955 0.7048193\n",
      "  0.         0.13429834 1.1076833  0.3291076  0.         0.5808611\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02932223 0.1698894  0.         0.         0.\n",
      "  0.         0.46928194 0.         0.8915802  0.         0.\n",
      "  0.         1.1021464  0.         0.25623408 0.         0.25610867\n",
      "  0.10937446 1.037477   0.41263744 0.06362233 0.48149678 0.\n",
      "  0.         0.69467205 0.         0.33630458 0.         0.\n",
      "  0.22077975 0.9616946  0.44963107 0.5778838 ]]\n",
      "Hi!\n",
      "[[0.9402895  0.         1.2516308  0.1452407  0.         1.1259232\n",
      "  0.5422936  0.77853346 0.43572754 0.14818321 0.44640976 0.\n",
      "  0.         0.         0.         0.20910844 0.4726764  0.5589733\n",
      "  0.         0.34796733 0.8441071  0.         0.         0.50075126\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18931699 0.25471497 0.         0.         0.\n",
      "  0.         0.3303655  0.         0.9473793  0.         0.\n",
      "  0.         0.95812416 0.         0.6627926  0.         0.\n",
      "  0.27339882 1.2226236  0.0414397  0.3435843  0.8906271  0.01265453\n",
      "  0.         1.3135397  0.         0.         0.         0.\n",
      "  0.40595788 0.85047746 0.46199587 0.        ]]\n",
      "Hi!\n",
      "[[0.22674055 0.12504628 0.2597686  0.         0.         0.46873707\n",
      "  1.0376167  0.90471643 0.4020914  0.         0.28625312 0.\n",
      "  0.38922638 0.06238262 0.         0.4462905  0.         0.6985236\n",
      "  0.         0.13033044 0.39773604 0.02155213 0.         0.\n",
      "  0.24931571 0.         0.         0.15638906 0.         0.\n",
      "  0.7084961  0.24452893 0.         0.         0.5640983  0.\n",
      "  0.21214807 1.0046372  0.         0.3541087  0.02910701 0.\n",
      "  0.         0.41626868 0.6062625  0.7009516  0.         0.39550987\n",
      "  0.         0.7032841  0.47658756 0.29718894 0.2174376  0.50539064\n",
      "  0.         0.         0.22082816 0.         0.         0.\n",
      "  0.         0.61430347 0.5271312  0.06271692]]\n",
      "Hi!\n",
      "[[0.6716032  0.1338371  1.6261752  0.         0.         0.81142783\n",
      "  0.3582393  0.31973252 1.4638423  0.         0.74062824 0.\n",
      "  0.50119406 0.         0.         0.8921659  0.6106382  0.95571643\n",
      "  0.33040395 0.         1.4036103  0.39010772 0.         0.5332465\n",
      "  0.14377284 0.         0.         0.         0.         0.\n",
      "  0.         0.16988175 0.         0.         0.03134222 0.\n",
      "  0.33807    1.0257869  0.         0.9427833  0.13130623 0.\n",
      "  0.         1.2199032  0.         0.         0.         0.8407484\n",
      "  0.         0.8972056  0.8475772  0.07127668 0.20965233 0.05846721\n",
      "  0.         0.11122329 0.         0.79567826 0.01463936 0.\n",
      "  0.         1.0563868  1.1452235  1.0663384 ]]\n",
      "Hi!\n",
      "[[0.         0.14313693 0.01123699 0.         0.         0.03721547\n",
      "  0.05524405 0.20483853 0.         0.0284644  0.05430404 0.\n",
      "  0.15487358 0.22163157 0.         0.02959553 0.         0.0672544\n",
      "  0.         0.06638525 0.05548175 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1271129  0.1859702  0.20813839 0.         0.         0.\n",
      "  0.         0.         0.26430592 0.         0.         0.\n",
      "  0.         0.         0.27866158 0.3204832  0.         0.\n",
      "  0.11238468 0.16733846 0.         0.17006753 0.08817873 0.39415103\n",
      "  0.         0.00897942 0.09230629 0.         0.         0.\n",
      "  0.05697201 0.11455353 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.00345596 0.14693873 0.37623438 0.         0.         0.2491478\n",
      "  0.         0.         0.11659831 0.11284723 0.20374991 0.\n",
      "  0.0420913  0.         0.         0.04478515 0.         0.02710834\n",
      "  0.         0.2670986  0.16513605 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03965345 0.0721448  0.         0.         0.\n",
      "  0.         0.         0.         0.15923245 0.         0.\n",
      "  0.         0.         0.00117844 0.21296576 0.         0.2350141\n",
      "  0.16329193 0.09375057 0.         0.24427302 0.03182972 0.27257964\n",
      "  0.         0.12716056 0.         0.         0.06369149 0.\n",
      "  0.0780755  0.07265868 0.         0.06651603]]\n",
      "Hi!\n",
      "[[6.6662276e-01 3.9440110e-01 9.4236523e-01 2.5465345e-02 0.0000000e+00\n",
      "  1.1095142e+00 4.9038225e-01 7.1572798e-01 3.2333452e-01 1.3121547e-01\n",
      "  4.0452430e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.3284046e-04 0.0000000e+00 4.4723457e-01 0.0000000e+00 5.4618853e-01\n",
      "  7.6626843e-01 0.0000000e+00 0.0000000e+00 4.2898351e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.5595524e-02 3.2355997e-01 1.5358908e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.7387801e-01 0.0000000e+00 7.8317600e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3602735e-01 8.4031366e-02\n",
      "  8.6053276e-01 0.0000000e+00 8.2766649e-04 3.0156896e-01 1.2024237e+00\n",
      "  1.3142852e-01 4.8543161e-01 1.0668241e+00 2.8913188e-01 0.0000000e+00\n",
      "  1.0601348e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.0330307e-01 6.9387388e-01 3.1139293e-01 1.6133228e-02]]\n",
      "Hi!\n",
      "[[0.24840347 0.8080776  0.5565853  0.         0.         0.5314515\n",
      "  0.         0.07527205 0.10031036 0.         0.34030125 0.\n",
      "  0.777208   0.26602355 0.         0.04121484 0.         0.33745128\n",
      "  0.         0.76844007 0.29999885 0.         0.         0.05883944\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.36141548 0.45262936 0.         0.         0.         0.\n",
      "  0.         0.08049085 0.19818936 0.31209615 0.         0.\n",
      "  0.         0.         0.49941418 0.44760194 0.         0.5301009\n",
      "  0.40938872 0.42428395 0.0634824  0.37477356 0.30907577 0.7596058\n",
      "  0.         0.19702448 0.11755797 0.         0.07270364 0.\n",
      "  0.10081706 0.19778506 0.1710497  0.1343342 ]]\n",
      "Hi!\n",
      "[[0.29380685 0.         0.11657333 0.4237427  0.         0.66610515\n",
      "  1.9884977  1.9810414  0.47506124 0.         0.19770566 0.\n",
      "  0.14646234 0.13636559 0.         0.54466504 0.         0.6362428\n",
      "  0.         0.         0.43275908 0.26115444 0.         0.\n",
      "  0.12140307 0.         0.         0.6472836  0.         0.\n",
      "  1.1913557  0.3989363  0.09184102 0.         0.8846512  0.\n",
      "  0.07596371 1.4190675  0.         0.32110384 0.38005096 0.\n",
      "  0.         0.9532113  0.90823656 1.198779   0.         0.00930508\n",
      "  0.         0.90410644 0.36451396 0.570012   0.76330745 0.26670069\n",
      "  0.         0.         0.3587827  0.         0.         0.\n",
      "  0.         0.88009375 1.3028983  0.        ]]\n",
      "Hi!\n",
      "[[0.815218   0.32938537 1.3461243  0.         0.         1.0332967\n",
      "  0.06647201 0.30878812 0.3609204  0.07777087 0.47862902 0.\n",
      "  0.0410354  0.         0.         0.0793802  0.32088602 0.56984127\n",
      "  0.         0.593969   0.9041774  0.         0.         0.33008894\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.45945573 0.04194515 0.         0.         0.\n",
      "  0.         0.3648126  0.         0.76458144 0.         0.\n",
      "  0.         0.32785395 0.18437558 0.50226694 0.         0.47898173\n",
      "  0.4271269  0.798556   0.13329972 0.40176424 0.56601167 0.5384776\n",
      "  0.         1.0758171  0.         0.         0.0618086  0.\n",
      "  0.28923577 0.49518478 0.60266775 0.2689331 ]]\n",
      "Hi!\n",
      "[[1.82986483e-01 4.39462870e-01 2.24149793e-01 6.10506744e-04\n",
      "  0.00000000e+00 1.02042936e-01 0.00000000e+00 1.62524998e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.53694019e-01 0.00000000e+00\n",
      "  4.69541937e-01 4.13227975e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.34675339e-01 0.00000000e+00 2.79214293e-01\n",
      "  7.85501376e-02 0.00000000e+00 0.00000000e+00 2.32511424e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.47654563e-01\n",
      "  0.00000000e+00 0.00000000e+00 2.60286152e-01 4.08204198e-01\n",
      "  1.68126628e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.24481356e-01 4.87027317e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.29659009e-01 2.77861267e-01 0.00000000e+00 6.82975277e-02\n",
      "  3.40114444e-01 1.88837528e-01 0.00000000e+00 3.23793679e-01\n",
      "  2.94272959e-01 6.87127411e-01 0.00000000e+00 1.39923081e-01\n",
      "  1.93674296e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.73811838e-01 9.81654152e-02 8.23729485e-02 0.00000000e+00]]\n",
      "Hi!\n",
      "[[5.5297166e-01 2.0043209e-01 9.5559734e-01 8.5001767e-02 0.0000000e+00\n",
      "  9.5493436e-01 3.5431796e-01 6.5938962e-01 1.6961241e-01 0.0000000e+00\n",
      "  3.9265880e-01 0.0000000e+00 2.9921025e-01 0.0000000e+00 0.0000000e+00\n",
      "  2.1902535e-02 0.0000000e+00 4.0186608e-01 0.0000000e+00 5.1851869e-01\n",
      "  6.6689736e-01 0.0000000e+00 0.0000000e+00 7.4566871e-02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.4898522e-02 0.0000000e+00 0.0000000e+00\n",
      "  4.2868450e-01 6.8753046e-01 5.6547392e-02 0.0000000e+00 2.3947852e-02\n",
      "  0.0000000e+00 0.0000000e+00 5.5644441e-01 0.0000000e+00 4.5521253e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0982680e-01 5.9530103e-01\n",
      "  7.3533964e-01 0.0000000e+00 4.2756268e-01 3.9136979e-01 7.1013516e-01\n",
      "  2.7692890e-02 4.9435219e-01 6.7504871e-01 6.6828877e-01 0.0000000e+00\n",
      "  8.1711113e-01 4.8886996e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 3.9814028e-01 8.5147607e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.66587806 1.2490405  0.55218065 0.         0.         0.394621\n",
      "  0.         0.7008711  0.56365347 0.         0.48840258 0.\n",
      "  2.175997   0.80018264 0.         0.5705492  0.         0.58175457\n",
      "  0.80825734 0.591239   0.5819298  0.02974383 0.         0.3135532\n",
      "  0.03677368 0.         0.         0.6923367  0.         0.\n",
      "  1.3662381  0.99570036 0.         0.         0.5001026  0.\n",
      "  0.4105825  0.78160846 0.67485374 0.32572055 0.         0.\n",
      "  0.         0.37042573 1.2233726  0.64514595 0.         0.9002014\n",
      "  0.         0.76185066 0.82202625 0.4357343  0.8202357  1.257624\n",
      "  0.         0.         0.45091638 0.         0.         0.\n",
      "  0.         0.27079996 1.007602   0.2780634 ]]\n",
      "Hi!\n",
      "[[0.4501826  0.730924   1.0263582  0.         0.         0.781273\n",
      "  0.07769283 0.53450644 0.60568786 0.         0.5390827  0.\n",
      "  1.2199837  0.         0.         0.32782644 0.         0.5477226\n",
      "  0.26987556 0.51143795 0.81034094 0.         0.         0.06322929\n",
      "  0.         0.         0.         0.17541793 0.         0.\n",
      "  0.74898845 0.717291   0.         0.         0.18156041 0.\n",
      "  0.09025537 0.65103686 0.01486975 0.44762227 0.         0.\n",
      "  0.         0.0814495  0.6745535  0.48530763 0.         0.70580596\n",
      "  0.11192065 0.7312247  0.49140307 0.4957107  0.7524653  0.7916973\n",
      "  0.         0.12880068 0.1286903  0.         0.05461396 0.\n",
      "  0.         0.38462368 1.0209146  0.41395816]]\n",
      "Hi!\n",
      "[[0.29063222 1.1095021  1.1434895  0.         0.         0.57499665\n",
      "  0.         0.         0.60020566 0.         0.59800154 0.\n",
      "  1.3544298  0.         0.         0.40965986 0.08914676 0.53576523\n",
      "  0.30038875 0.86689115 0.7532089  0.         0.         0.00338247\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35044724 0.47464573 0.         0.         0.0512002  0.\n",
      "  0.         0.2479375  0.08793612 0.5460726  0.         0.\n",
      "  0.         0.         0.24241622 0.         0.         0.84631515\n",
      "  0.29807925 0.740375   0.53983146 0.26220256 0.2852497  0.789028\n",
      "  0.         0.         0.06928953 0.         0.20575368 0.\n",
      "  0.04284014 0.35061565 0.58063525 0.695686  ]]\n",
      "Hi!\n",
      "[[0.8109741  0.4483557  1.7650018  0.         0.         1.0790737\n",
      "  0.05561706 0.05957626 0.9297605  0.         0.7207619  0.\n",
      "  0.7047517  0.         0.         0.53455    0.45120072 0.8034323\n",
      "  0.08684552 0.41408968 1.288614   0.10010666 0.         0.41463938\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03408495 0.445533   0.         0.         0.         0.\n",
      "  0.13978694 0.69135123 0.         0.8954254  0.         0.\n",
      "  0.         0.5320373  0.04407188 0.13366325 0.         0.9069237\n",
      "  0.29618385 0.8036607  0.56331486 0.34303904 0.44743112 0.51704913\n",
      "  0.         0.6599938  0.         0.45548475 0.12339994 0.\n",
      "  0.         0.60711676 1.1198436  0.8508059 ]]\n",
      "Hi!\n",
      "[[0.57061356 0.7571441  0.4807872  0.         0.         0.40360862\n",
      "  0.3952558  1.038325   0.78185534 0.         0.43816537 0.\n",
      "  1.8765746  0.6526212  0.         0.6852933  0.         0.58749205\n",
      "  0.8805302  0.2132427  0.6397302  0.0883453  0.         0.1389772\n",
      "  0.1893702  0.         0.         0.709556   0.         0.\n",
      "  1.3112289  0.8346442  0.         0.         0.6267927  0.\n",
      "  0.50117147 1.1014345  0.23359844 0.21125856 0.03822361 0.\n",
      "  0.         0.34567836 1.0722775  0.6379825  0.         0.7906818\n",
      "  0.         0.74195737 0.9366081  0.44912365 0.6988312  0.9490208\n",
      "  0.         0.         0.44783825 0.         0.         0.\n",
      "  0.         0.39301336 1.2341201  0.31069678]]\n",
      "Hi!\n",
      "[[0.33140156 0.46290275 0.8488209  0.         0.         0.53926355\n",
      "  0.5233402  0.59801084 1.1332397  0.         0.57253075 0.\n",
      "  1.2337239  0.         0.         0.9165921  0.         0.8611227\n",
      "  0.81524813 0.03042568 0.8875154  0.         0.         0.\n",
      "  0.4075033  0.         0.         0.24780358 0.         0.\n",
      "  0.6881264  0.37642652 0.         0.         0.5617319  0.\n",
      "  0.6195067  1.2810407  0.         0.58584225 0.12144391 0.\n",
      "  0.         0.5421359  0.49423128 0.17658094 0.         1.0211346\n",
      "  0.         0.737289   0.9563717  0.26029631 0.19559978 0.54660654\n",
      "  0.         0.         0.30580392 0.10800412 0.         0.\n",
      "  0.         0.74864274 1.1729977  0.75056523]]\n",
      "Hi!\n",
      "[[0.02396747 0.35272297 0.28456968 0.         0.         0.14418207\n",
      "  0.04818149 0.17252971 0.01950314 0.09583102 0.18623875 0.\n",
      "  0.1443341  0.09410022 0.         0.         0.         0.27517107\n",
      "  0.         0.35659114 0.1966973  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19584218 0.01228    0.         0.         0.\n",
      "  0.         0.02383115 0.09429213 0.18712331 0.         0.\n",
      "  0.         0.         0.20032404 0.36866468 0.         0.07572412\n",
      "  0.20856757 0.2554152  0.         0.19946232 0.14016654 0.37716874\n",
      "  0.         0.14927235 0.         0.         0.         0.\n",
      "  0.109249   0.25992978 0.         0.03024695]]\n",
      "Hi!\n",
      "[[0.3859108  0.         0.         0.74961597 0.         0.6284577\n",
      "  2.4911435  2.3453598  0.         0.         0.00737623 0.\n",
      "  0.         0.44635043 0.         0.3513151  0.         0.57675517\n",
      "  0.         0.         0.10096566 0.47617626 0.         0.\n",
      "  0.23325789 0.         0.         0.82169867 0.         0.\n",
      "  1.376305   0.50237656 0.5305028  0.         0.95324683 0.\n",
      "  0.10333528 1.391491   0.05035594 0.40550274 0.46823665 0.\n",
      "  0.         0.8480072  1.3590502  1.6392338  0.         0.\n",
      "  0.         1.0459859  0.21316972 0.7393045  0.7785861  0.62855\n",
      "  0.         0.13396786 0.45477825 0.         0.         0.\n",
      "  0.         0.8708835  0.96358144 0.        ]]\n",
      "Hi!\n",
      "[[0.28434494 0.6003146  1.2105196  0.         0.         0.5600609\n",
      "  0.2994486  0.32233083 1.2595718  0.         0.6615469  0.\n",
      "  1.1953957  0.         0.         0.84293157 0.08628694 0.8421524\n",
      "  0.76784754 0.08787458 1.1143527  0.18042728 0.         0.12371316\n",
      "  0.23284861 0.         0.         0.04945771 0.         0.\n",
      "  0.46138957 0.3818235  0.         0.         0.31471977 0.\n",
      "  0.44793013 1.0653862  0.         0.7453527  0.07643163 0.\n",
      "  0.         0.56370676 0.17846724 0.         0.         0.96364486\n",
      "  0.         0.84936345 0.9292863  0.1767621  0.28266928 0.30450708\n",
      "  0.         0.         0.11074243 0.26674134 0.0569916  0.\n",
      "  0.         0.8103258  1.1646193  0.97513795]]\n",
      "Hi!\n",
      "[[0.05736876 0.15793954 0.20424429 0.         0.         0.05511026\n",
      "  0.         0.06863173 0.158545   0.11590998 0.1685046  0.\n",
      "  0.10536225 0.03237697 0.         0.14194211 0.         0.09100495\n",
      "  0.         0.14329457 0.18465497 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01545386 0.13765323 0.02967926 0.         0.         0.\n",
      "  0.         0.         0.04779802 0.09325564 0.         0.\n",
      "  0.         0.         0.0399845  0.1176177  0.         0.03413272\n",
      "  0.0761738  0.06862012 0.03429272 0.11794007 0.11695399 0.26143345\n",
      "  0.         0.         0.02056288 0.         0.01673586 0.\n",
      "  0.075058   0.08932029 0.         0.0253214 ]]\n",
      "Hi!\n",
      "[[0.5845893  0.80582047 1.3137637  0.         0.         1.0387396\n",
      "  0.         0.00164679 0.23459937 0.07318089 0.5367485  0.\n",
      "  0.49277297 0.         0.         0.         0.06138215 0.3548647\n",
      "  0.         1.038513   0.7420298  0.         0.         0.19888073\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09289908 0.54904    0.01678029 0.         0.         0.\n",
      "  0.         0.         0.         0.5716067  0.         0.\n",
      "  0.         0.         0.3814284  0.4100569  0.         0.5539111\n",
      "  0.71856177 0.7717795  0.03657385 0.5292785  0.8168652  0.7779221\n",
      "  0.         0.8996622  0.         0.         0.16214176 0.\n",
      "  0.31328094 0.32061937 0.35105702 0.37122265]]\n",
      "Hi!\n",
      "[[0.8116932  0.11278965 0.         0.70796573 0.         0.74471736\n",
      "  1.3781341  1.7757921  0.         0.         0.         0.\n",
      "  0.5016841  0.92120296 0.         0.14861095 0.         0.2807026\n",
      "  0.         0.43048647 0.05199275 0.22178979 0.         0.14887103\n",
      "  0.         0.         0.         0.8341372  0.         0.\n",
      "  1.4914337  0.99538046 0.6848723  0.         0.6049356  0.\n",
      "  0.14922093 0.86133426 0.50865984 0.22187893 0.17467903 0.\n",
      "  0.         0.5643412  1.7326165  1.7183046  0.         0.3507306\n",
      "  0.32080802 0.93098384 0.         0.8117123  0.8793756  1.3266187\n",
      "  0.         0.60958844 0.62634647 0.         0.         0.\n",
      "  0.         0.19979206 0.7263156  0.        ]]\n",
      "Hi!\n",
      "[[0.14501305 0.67215055 0.49536508 0.         0.         0.37419966\n",
      "  0.         0.         0.11980335 0.         0.3179269  0.\n",
      "  0.5378978  0.15834463 0.         0.01515498 0.         0.23033163\n",
      "  0.         0.6141094  0.27644145 0.         0.         0.03144458\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15917315 0.31655446 0.         0.         0.         0.\n",
      "  0.         0.         0.21486536 0.25051454 0.         0.\n",
      "  0.         0.         0.2580034  0.27146617 0.         0.3976842\n",
      "  0.37696204 0.30257687 0.06206592 0.2885567  0.20259224 0.613869\n",
      "  0.         0.11673096 0.06451672 0.         0.10586283 0.\n",
      "  0.14507085 0.14394127 0.06542222 0.11698321]]\n",
      "Hi!\n",
      "[[0.06778494 0.40139386 0.10556839 0.         0.         0.20265695\n",
      "  0.         0.10882751 0.02456669 0.         0.15147631 0.\n",
      "  0.3747928  0.26542592 0.         0.         0.         0.11786206\n",
      "  0.         0.32018864 0.07203008 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2249796  0.26486692 0.11267988 0.         0.         0.\n",
      "  0.         0.         0.16189529 0.07872132 0.         0.\n",
      "  0.         0.         0.33714825 0.3191726  0.         0.22360505\n",
      "  0.18004216 0.21321352 0.         0.19744357 0.05875455 0.43976048\n",
      "  0.         0.05696573 0.15313485 0.         0.00948779 0.\n",
      "  0.09152713 0.09289099 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.33335575 0.32683    0.00944056 0.13556421 0.         0.39509997\n",
      "  0.63446015 0.67252177 0.         0.         0.         0.\n",
      "  0.36801863 0.49289247 0.         0.136298   0.         0.30085588\n",
      "  0.         0.37606078 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.35064244 0.         0.\n",
      "  0.6592905  0.46525773 0.40199366 0.         0.18460548 0.\n",
      "  0.1735919  0.52804464 0.3883822  0.10566054 0.         0.\n",
      "  0.         0.30445984 0.79855645 0.941548   0.         0.40828136\n",
      "  0.22103134 0.5268293  0.00177177 0.4270116  0.21711749 0.94920033\n",
      "  0.         0.40352377 0.34139922 0.         0.         0.\n",
      "  0.         0.22404593 0.12731129 0.        ]]\n",
      "Hi!\n",
      "[[0.1233696  0.3755431  0.17928551 0.         0.         0.31808275\n",
      "  0.         0.20112382 0.         0.00359945 0.1692284  0.\n",
      "  0.23471466 0.2745293  0.         0.         0.         0.13451989\n",
      "  0.         0.41586664 0.10948231 0.         0.         0.0190129\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22314872 0.3057043  0.11348232 0.         0.         0.\n",
      "  0.         0.         0.22980759 0.11092311 0.         0.\n",
      "  0.         0.         0.36083448 0.5058537  0.         0.1539412\n",
      "  0.30817452 0.292958   0.         0.28896528 0.23328783 0.5803063\n",
      "  0.         0.23070334 0.11005258 0.         0.00846045 0.\n",
      "  0.086321   0.12165825 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.534272   0.66950494 0.66369575 0.         0.         0.5963694\n",
      "  0.25130746 0.7412868  0.68308437 0.         0.4689998  0.\n",
      "  1.5240825  0.31443635 0.         0.55783916 0.         0.5708591\n",
      "  0.69559354 0.34029144 0.7175723  0.         0.         0.10550103\n",
      "  0.14126162 0.         0.         0.44251755 0.         0.\n",
      "  0.9892423  0.7305248  0.         0.         0.4192971  0.\n",
      "  0.47013378 0.9198164  0.05680735 0.32938036 0.         0.\n",
      "  0.         0.22817771 0.9088039  0.5113619  0.         0.88430256\n",
      "  0.         0.6910634  0.70671135 0.43036696 0.5353196  0.9100549\n",
      "  0.         0.         0.34074298 0.         0.         0.\n",
      "  0.         0.32771727 1.09838    0.3869451 ]]\n",
      "Hi!\n",
      "[[0.0413489  0.29968753 0.1083369  0.         0.         0.18930294\n",
      "  0.02703402 0.2015362  0.01952726 0.01451855 0.16737045 0.\n",
      "  0.2559634  0.22499476 0.         0.02332932 0.         0.09854623\n",
      "  0.         0.28095996 0.08727486 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12892316 0.16547446 0.14015079 0.         0.         0.\n",
      "  0.         0.         0.18865627 0.07986668 0.         0.\n",
      "  0.         0.         0.20799087 0.31369504 0.         0.04650064\n",
      "  0.16780494 0.24019927 0.00403983 0.16427206 0.12089609 0.44078016\n",
      "  0.         0.06050875 0.12136982 0.         0.         0.\n",
      "  0.12474377 0.2258121  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.9466891  0.         1.3225638  0.27084267 0.         1.0151294\n",
      "  1.0834229  1.0737238  0.77988625 0.00840259 0.48329136 0.\n",
      "  0.         0.         0.         0.3457343  0.6686522  0.73463976\n",
      "  0.         0.         1.0449107  0.3207471  0.         0.649049\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05574185 0.24654236 0.         0.         0.\n",
      "  0.         0.67925406 0.         1.0109379  0.09073607 0.\n",
      "  0.         1.5298043  0.         0.4721413  0.         0.\n",
      "  0.         1.1725801  0.28279096 0.19282095 0.75610316 0.\n",
      "  0.         1.0528057  0.         0.22495812 0.         0.\n",
      "  0.15600191 1.1162761  0.81401116 0.03595778]]\n",
      "Hi!\n",
      "[[0.18303841 0.4483469  0.17895615 0.         0.         0.19464144\n",
      "  0.7266627  0.6586285  0.42926502 0.         0.29188246 0.\n",
      "  0.66866535 0.16811474 0.         0.44936958 0.         0.6288799\n",
      "  0.         0.23769875 0.2374543  0.         0.         0.\n",
      "  0.17931633 0.         0.         0.14244689 0.         0.\n",
      "  0.6478913  0.2821084  0.         0.         0.44237378 0.\n",
      "  0.11636844 0.81781447 0.         0.26534697 0.         0.\n",
      "  0.         0.25901964 0.42143404 0.5508034  0.         0.4255924\n",
      "  0.         0.61858445 0.55651504 0.13720521 0.20374006 0.37596244\n",
      "  0.         0.         0.13696577 0.         0.         0.\n",
      "  0.         0.64893484 0.36785465 0.10051755]]\n",
      "Hi!\n",
      "[[5.42047739e-01 6.65712774e-01 4.72065836e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.17425954e-01 4.02341872e-01 1.00198364e+00\n",
      "  6.21655524e-01 0.00000000e+00 4.16677356e-01 0.00000000e+00\n",
      "  1.56453037e+00 5.98542511e-01 0.00000000e+00 5.64430535e-01\n",
      "  0.00000000e+00 5.70054412e-01 6.41255319e-01 3.06324273e-01\n",
      "  5.89128137e-01 1.26634107e-03 0.00000000e+00 9.39784870e-02\n",
      "  1.00508325e-01 0.00000000e+00 0.00000000e+00 6.36196256e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.17178810e+00 7.97482729e-01\n",
      "  0.00000000e+00 0.00000000e+00 5.67881763e-01 0.00000000e+00\n",
      "  4.19321835e-01 1.00332761e+00 1.82425857e-01 2.38484696e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.19805658e-01\n",
      "  1.06478000e+00 6.94097519e-01 0.00000000e+00 6.87885642e-01\n",
      "  0.00000000e+00 7.08292186e-01 7.05896199e-01 4.84611392e-01\n",
      "  6.36378825e-01 8.89708161e-01 0.00000000e+00 0.00000000e+00\n",
      "  3.82812619e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.18264210e-01 1.10313308e+00 1.58403099e-01]]\n",
      "Hi!\n",
      "[[0.10757294 0.42976737 0.25358364 0.         0.         0.22749293\n",
      "  0.         0.09622843 0.         0.         0.2081724  0.\n",
      "  0.34629768 0.2619916  0.         0.         0.         0.12678474\n",
      "  0.         0.34685642 0.12799615 0.         0.         0.01965971\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1534854  0.2914593  0.11148237 0.         0.         0.\n",
      "  0.         0.         0.29401794 0.09207264 0.         0.\n",
      "  0.         0.         0.32568225 0.28762197 0.         0.1765806\n",
      "  0.31184387 0.17517771 0.         0.21863124 0.1385986  0.5811788\n",
      "  0.         0.12523285 0.14667614 0.         0.01261913 0.\n",
      "  0.12979852 0.11961921 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.01930393 0.14636546 0.12933448 0.05327653 0.         0.\n",
      "  0.         0.11436512 0.01626244 0.         0.         0.\n",
      "  0.14637294 0.15056053 0.         0.04372713 0.         0.02930218\n",
      "  0.         0.         0.0155192  0.         0.         0.\n",
      "  0.         0.         0.         0.02127563 0.         0.\n",
      "  0.04153803 0.23062195 0.13039963 0.         0.         0.\n",
      "  0.         0.         0.2411029  0.02622203 0.         0.\n",
      "  0.         0.         0.26007617 0.07196575 0.         0.01804879\n",
      "  0.18113677 0.11962643 0.         0.15012796 0.09962976 0.30134565\n",
      "  0.         0.06227345 0.03599011 0.         0.         0.\n",
      "  0.10580283 0.07133354 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.418611   0.         0.8414276  0.         0.         0.65269315\n",
      "  1.0364764  0.99506825 0.8776982  0.         0.46190688 0.\n",
      "  0.25860533 0.         0.         0.60051054 0.         0.82438177\n",
      "  0.         0.         0.85337347 0.         0.         0.16315843\n",
      "  0.07111464 0.         0.         0.10057089 0.         0.\n",
      "  0.50153387 0.24121512 0.         0.         0.4193667  0.\n",
      "  0.03615406 1.1511726  0.         0.54968625 0.11366907 0.\n",
      "  0.         0.86748403 0.21931611 0.53998184 0.         0.33724546\n",
      "  0.         0.7350572  0.53800327 0.24179071 0.42613062 0.1176625\n",
      "  0.         0.         0.05641178 0.05158509 0.         0.\n",
      "  0.         0.97909474 1.111208   0.29670495]]\n",
      "Hi!\n",
      "[[0.         0.05966968 0.27612993 0.         0.         0.23002706\n",
      "  0.         0.13141517 0.06760731 0.11784288 0.15386535 0.\n",
      "  0.         0.         0.         0.06193244 0.         0.\n",
      "  0.         0.22153328 0.14857686 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03853174 0.13104485 0.         0.         0.\n",
      "  0.         0.         0.08407024 0.19211364 0.         0.\n",
      "  0.         0.         0.0932944  0.29293466 0.         0.18707454\n",
      "  0.12079887 0.00672309 0.         0.25944358 0.02752404 0.29568207\n",
      "  0.         0.19485532 0.         0.         0.02838589 0.\n",
      "  0.         0.         0.         0.01911152]]\n",
      "Hi!\n",
      "[[0.9427871  0.         1.4558351  0.08441928 0.         1.0061519\n",
      "  0.760528   0.7916907  0.79520667 0.         0.5288275  0.\n",
      "  0.         0.         0.         0.36615577 0.6546343  0.77384883\n",
      "  0.         0.         1.11549    0.27708593 0.         0.54232264\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15956186 0.13371286 0.         0.         0.\n",
      "  0.         0.6779645  0.         0.87496936 0.         0.\n",
      "  0.         1.2517022  0.         0.36244547 0.         0.12542623\n",
      "  0.         0.9760193  0.32407647 0.17153482 0.53927815 0.00483347\n",
      "  0.         0.90847355 0.         0.27836138 0.         0.\n",
      "  0.17826451 0.9978166  0.8109566  0.25662562]]\n",
      "Hi!\n",
      "[[0.6026669  0.00468168 0.97525555 0.04129519 0.         0.9689514\n",
      "  0.7173489  0.98700404 0.7576119  0.02233677 0.43581486 0.\n",
      "  0.17485951 0.         0.         0.33739504 0.07294668 0.68442744\n",
      "  0.         0.         0.8929345  0.         0.         0.44588274\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3471055  0.35822207 0.12563871 0.         0.11160629 0.\n",
      "  0.         0.7976726  0.         0.6658727  0.         0.\n",
      "  0.         0.7540909  0.08181681 0.6499172  0.         0.18092787\n",
      "  0.         1.0101566  0.33661938 0.4160351  0.7459924  0.13255307\n",
      "  0.         0.50844646 0.         0.         0.         0.\n",
      "  0.         0.87036437 1.0018667  0.27119854]]\n",
      "Hi!\n",
      "[[0.4579729  0.46748897 1.0543422  0.         0.         0.65480053\n",
      "  0.33835042 0.26259866 0.8412676  0.01504773 0.5544644  0.\n",
      "  0.41106114 0.         0.         0.4169353  0.12446309 0.761933\n",
      "  0.         0.27650443 0.9070092  0.09129298 0.         0.29704666\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13302134 0.2580258  0.00925638 0.         0.01034177 0.\n",
      "  0.         0.58791554 0.         0.71705496 0.         0.\n",
      "  0.         0.53122276 0.         0.23712268 0.         0.46784815\n",
      "  0.         0.8443464  0.4756967  0.18539533 0.45943937 0.20850046\n",
      "  0.         0.06382824 0.         0.03545718 0.01486597 0.\n",
      "  0.         0.880998   0.45367843 0.6076575 ]]\n",
      "Hi!\n",
      "[[0.30783072 0.77951866 0.40114084 0.         0.         0.41987926\n",
      "  0.37160954 0.51639634 0.71148056 0.         0.37883142 0.\n",
      "  1.3819381  0.33571514 0.         0.6066049  0.         0.6580175\n",
      "  0.5127831  0.3854382  0.47827354 0.         0.         0.\n",
      "  0.19498686 0.         0.         0.2139393  0.         0.\n",
      "  0.7843565  0.46950692 0.         0.         0.49757576 0.\n",
      "  0.35771132 0.9380577  0.         0.3888497  0.         0.\n",
      "  0.         0.14925987 0.55216175 0.31033772 0.         0.90898114\n",
      "  0.         0.6742747  0.7957252  0.17146105 0.13987829 0.6931332\n",
      "  0.         0.         0.3381208  0.         0.         0.\n",
      "  0.         0.45814952 0.6391212  0.47950786]]\n",
      "Hi!\n",
      "[[0.39660048 0.76188916 1.1665099  0.         0.         0.65437055\n",
      "  0.01261609 0.035822   0.83159053 0.         0.5908049  0.\n",
      "  1.1128986  0.         0.         0.60805655 0.07197315 0.7886918\n",
      "  0.41207218 0.46307695 0.9431037  0.0384239  0.         0.\n",
      "  0.17959526 0.         0.         0.02374772 0.         0.\n",
      "  0.38896212 0.49797893 0.         0.         0.18306918 0.\n",
      "  0.34385625 0.8355801  0.         0.7056101  0.         0.\n",
      "  0.         0.19312571 0.3481292  0.02252649 0.         1.0319636\n",
      "  0.         0.7458541  0.681941   0.21571438 0.17035209 0.61048\n",
      "  0.         0.         0.10409519 0.0561955  0.09006026 0.\n",
      "  0.         0.58181703 0.93499255 0.7413429 ]]\n",
      "Hi!\n",
      "[[0.3798035  0.64840406 0.47337565 0.         0.         0.6255971\n",
      "  0.23850194 0.5320646  0.27972916 0.         0.3294936  0.\n",
      "  0.81021553 0.30074164 0.         0.09544958 0.         0.4504791\n",
      "  0.         0.6059809  0.3863044  0.         0.         0.\n",
      "  0.         0.         0.         0.06895288 0.         0.\n",
      "  0.6772891  0.49788418 0.         0.         0.17072897 0.\n",
      "  0.         0.5228588  0.         0.25009373 0.         0.\n",
      "  0.         0.         0.64231753 0.69545794 0.         0.61149335\n",
      "  0.13444391 0.7114851  0.3078513  0.41205037 0.5085509  0.7224424\n",
      "  0.         0.05586658 0.12689106 0.         0.         0.\n",
      "  0.         0.37845922 0.46228307 0.10765667]]\n",
      "Hi!\n",
      "[[0.89199287 0.         1.1212319  0.26687595 0.         1.0002645\n",
      "  0.94228697 0.97988737 0.550552   0.12346537 0.413906   0.\n",
      "  0.         0.         0.         0.2151329  0.5362526  0.678533\n",
      "  0.         0.02177882 0.813174   0.2986767  0.         0.5320199\n",
      "  0.0172884  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33364075 0.         0.         0.\n",
      "  0.         0.44374642 0.         1.1545382  0.         0.\n",
      "  0.         1.4637587  0.         0.6079489  0.         0.\n",
      "  0.18784988 1.3703012  0.14453954 0.19196664 0.784003   0.\n",
      "  0.         1.0859993  0.         0.         0.         0.\n",
      "  0.36418396 1.1642154  0.26743346 0.        ]]\n",
      "Hi!\n",
      "[[0.5882366  0.64677525 0.2852907  0.         0.         0.36929098\n",
      "  0.59626174 1.1606033  0.77162886 0.         0.39068592 0.\n",
      "  1.8144162  0.759373   0.         0.7298475  0.         0.6188489\n",
      "  0.9314384  0.14774804 0.566794   0.1624739  0.         0.15083636\n",
      "  0.26580438 0.         0.         0.76374644 0.         0.\n",
      "  1.3598138  0.8013347  0.         0.         0.7164659  0.\n",
      "  0.66149527 1.200512   0.16064201 0.20166355 0.0531684  0.\n",
      "  0.         0.42229936 1.1588852  0.72049296 0.         0.83335525\n",
      "  0.         0.6924001  0.94427085 0.4372578  0.5675638  0.9760658\n",
      "  0.         0.         0.52306443 0.         0.         0.\n",
      "  0.         0.37111798 1.1625614  0.24317281]]\n",
      "Hi!\n",
      "[[0.47841525 0.         0.53397095 0.37082583 0.         0.6677086\n",
      "  2.1424403  2.0277078  0.91441965 0.         0.33034348 0.\n",
      "  0.         0.         0.         0.6914679  0.0367413  0.82152575\n",
      "  0.         0.         0.7480527  0.29757443 0.         0.12339002\n",
      "  0.07146442 0.         0.         0.27084336 0.         0.\n",
      "  0.6971461  0.06471425 0.17827213 0.         0.71680653 0.\n",
      "  0.         1.472638   0.         0.6909161  0.44177094 0.\n",
      "  0.         1.6632184  0.23693311 0.8341865  0.         0.\n",
      "  0.         0.9394571  0.48009324 0.36147383 0.62387615 0.\n",
      "  0.         0.02791806 0.04776416 0.         0.         0.\n",
      "  0.         1.3007789  1.3101786  0.        ]]\n",
      "Hi!\n",
      "[[0.6804671  0.         1.1013082  0.00815799 0.         0.6361822\n",
      "  0.754029   0.6166039  0.84334797 0.03776323 0.45366183 0.\n",
      "  0.         0.         0.         0.37837127 0.5377848  0.7920736\n",
      "  0.         0.         0.9313274  0.36090195 0.         0.42736349\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16569538 0.         0.         0.\n",
      "  0.         0.63454884 0.         0.79187155 0.03337781 0.\n",
      "  0.         1.1777809  0.         0.26225314 0.         0.\n",
      "  0.         0.9178373  0.35609943 0.         0.33495072 0.\n",
      "  0.         0.3928023  0.         0.24297999 0.         0.\n",
      "  0.12322507 1.1360711  0.45499077 0.27874166]]\n",
      "Hi!\n",
      "[[0.2921129  0.6112904  0.47425255 0.         0.         0.3642735\n",
      "  0.6218146  0.73798543 0.88383365 0.         0.44228765 0.\n",
      "  1.3022286  0.20037378 0.         0.7576245  0.         0.7867197\n",
      "  0.61238664 0.18705359 0.6595887  0.         0.         0.\n",
      "  0.34355372 0.         0.         0.2567947  0.         0.\n",
      "  0.920988   0.42601293 0.         0.         0.65897816 0.\n",
      "  0.4354262  1.1563236  0.         0.41906026 0.07015548 0.\n",
      "  0.         0.36085433 0.6209252  0.37797853 0.         0.85620445\n",
      "  0.         0.71545106 0.8760681  0.23046221 0.35057464 0.516676\n",
      "  0.         0.         0.32820225 0.         0.         0.\n",
      "  0.         0.6659597  0.8958492  0.5142141 ]]\n",
      "Hi!\n",
      "[[0.96997947 0.         1.4828128  0.07686856 0.         0.92487234\n",
      "  0.7895458  0.96937615 1.1051466  0.         0.58002317 0.\n",
      "  0.         0.         0.         0.5412884  0.6388607  0.7837157\n",
      "  0.         0.         1.2238644  0.28829196 0.         0.74557245\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18059865 0.14732076 0.         0.         0.\n",
      "  0.         0.8965361  0.         0.8804376  0.00855848 0.\n",
      "  0.         1.3432221  0.         0.35910827 0.         0.08213251\n",
      "  0.         1.0783349  0.48791397 0.21783814 0.6689492  0.\n",
      "  0.         0.779024   0.         0.36392513 0.         0.\n",
      "  0.         1.087091   1.1301955  0.39169654]]\n",
      "Hi!\n",
      "[[0.755402   0.         1.0858192  0.13339259 0.         0.91147614\n",
      "  0.89707583 0.9799758  0.6894881  0.06430694 0.42364165 0.\n",
      "  0.         0.         0.         0.28720883 0.25417086 0.7186943\n",
      "  0.         0.         0.90817595 0.03610481 0.         0.4370313\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11565672 0.21204859 0.15755007 0.         0.05188974 0.\n",
      "  0.         0.7606196  0.         0.72072685 0.         0.\n",
      "  0.         0.91505206 0.01421107 0.63001025 0.         0.13042408\n",
      "  0.         0.9547002  0.2564913  0.33251673 0.65564215 0.06329869\n",
      "  0.         0.72854686 0.         0.02744494 0.         0.\n",
      "  0.         0.9809469  0.8838272  0.18538782]]\n",
      "Hi!\n",
      "[[0.3782989  0.         0.         0.4235502  0.         0.5133066\n",
      "  1.7872463  1.9104877  0.30812204 0.         0.17358057 0.\n",
      "  0.6670248  0.6380615  0.         0.5150498  0.         0.65477926\n",
      "  0.         0.         0.30348542 0.36335197 0.         0.\n",
      "  0.33865455 0.         0.         0.7866412  0.         0.\n",
      "  1.4023255  0.5388824  0.18557687 0.         0.9779154  0.\n",
      "  0.30855414 1.4281913  0.         0.24475259 0.31850797 0.\n",
      "  0.         0.6217194  1.2420024  1.3468838  0.         0.2566453\n",
      "  0.         0.95975554 0.570598   0.6153563  0.73567396 0.742483\n",
      "  0.         0.         0.45043266 0.         0.         0.\n",
      "  0.         0.71204734 1.0068256  0.        ]]\n",
      "Hi!\n",
      "[[0.74780905 0.6432604  0.2241443  0.50876445 0.         0.5662152\n",
      "  0.53439856 1.1143805  0.         0.         0.1233822  0.\n",
      "  0.67419344 0.98549956 0.         0.         0.         0.21053654\n",
      "  0.         0.7598675  0.06893209 0.         0.         0.32918662\n",
      "  0.         0.         0.         0.61796504 0.         0.\n",
      "  1.3337992  0.9606352  0.57306325 0.         0.40067175 0.\n",
      "  0.         0.30371645 0.9454211  0.06499655 0.         0.\n",
      "  0.         0.20033559 1.4720436  1.30109    0.         0.\n",
      "  0.5406602  0.9144432  0.         0.7090702  1.0084312  1.1724169\n",
      "  0.         0.5992195  0.48289886 0.         0.         0.\n",
      "  0.         0.20247963 0.43750417 0.        ]]\n",
      "Hi!\n",
      "[[0.6896073  1.0293543  0.44621193 0.         0.         0.38487023\n",
      "  0.18869741 0.89678615 0.650916   0.         0.45184618 0.\n",
      "  2.1078005  0.8377859  0.         0.64708066 0.         0.6026107\n",
      "  0.9499578  0.43485785 0.5628483  0.13590513 0.         0.21620704\n",
      "  0.18837115 0.         0.         0.7808349  0.         0.\n",
      "  1.3565147  0.99048644 0.         0.         0.624508   0.\n",
      "  0.6050102  0.9805845  0.53679353 0.2677886  0.         0.\n",
      "  0.         0.42660335 1.2853749  0.66175985 0.         0.954283\n",
      "  0.         0.71033245 0.9062707  0.45072395 0.69846934 1.242928\n",
      "  0.         0.         0.5007795  0.         0.         0.\n",
      "  0.         0.33519945 1.0679693  0.25993884]]\n",
      "Hi!\n",
      "[[0.50736946 0.3456002  0.         0.28823483 0.         0.4925499\n",
      "  0.97186124 1.1823591  0.         0.         0.08749078 0.\n",
      "  0.44992024 0.83052635 0.         0.02927754 0.         0.3034753\n",
      "  0.         0.53408897 0.05841412 0.02151142 0.         0.16314237\n",
      "  0.         0.         0.         0.45699883 0.         0.\n",
      "  1.1496885  0.6798225  0.38917595 0.         0.4157803  0.\n",
      "  0.         0.6117813  0.25283635 0.27741238 0.01422477 0.\n",
      "  0.         0.221784   1.2377188  1.2818269  0.         0.15973452\n",
      "  0.32091242 0.9252677  0.07500892 0.58848727 0.71501476 0.95947886\n",
      "  0.         0.31029704 0.3633961  0.         0.         0.\n",
      "  0.         0.2983652  0.19219254 0.        ]]\n",
      "Hi!\n",
      "[[0.03709701 0.19906208 0.13532831 0.         0.         0.09541798\n",
      "  0.         0.07901254 0.         0.         0.07087182 0.\n",
      "  0.22338185 0.21472743 0.         0.         0.         0.06052155\n",
      "  0.         0.13316073 0.01918022 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12028891 0.23924942 0.16615358 0.         0.         0.\n",
      "  0.         0.         0.26573452 0.01316456 0.         0.\n",
      "  0.         0.         0.24322626 0.21672174 0.         0.06247615\n",
      "  0.16408616 0.09671638 0.         0.21608311 0.06935695 0.4420537\n",
      "  0.         0.08012561 0.1318488  0.         0.         0.\n",
      "  0.09918527 0.05898124 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.32858542 0.29308352 0.47645733 0.01208188 0.         0.6832337\n",
      "  0.43540862 0.5854075  0.11877941 0.14316414 0.27673143 0.\n",
      "  0.         0.         0.         0.0714407  0.         0.40775356\n",
      "  0.         0.44882676 0.34528702 0.         0.         0.19413824\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0098147  0.16012992 0.06332938 0.         0.         0.\n",
      "  0.         0.11095306 0.         0.64753854 0.         0.\n",
      "  0.         0.3651127  0.05579158 0.70739716 0.         0.\n",
      "  0.2929835  0.95430076 0.0159858  0.29796785 0.6154666  0.16501729\n",
      "  0.         0.49828517 0.         0.         0.         0.\n",
      "  0.26435262 0.6585971  0.         0.        ]]\n",
      "Hi!\n",
      "[[5.9319776e-01 0.0000000e+00 6.8202543e-01 3.0638948e-01 0.0000000e+00\n",
      "  7.5063270e-01 1.7269647e+00 1.3976108e+00 5.4957014e-01 0.0000000e+00\n",
      "  3.1461766e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.6123389e-01 1.2632215e-01 7.6608211e-01 0.0000000e+00 0.0000000e+00\n",
      "  6.5555722e-01 1.6942813e-01 0.0000000e+00 1.1968258e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.8889762e-02 0.0000000e+00 0.0000000e+00\n",
      "  3.2596436e-01 2.0213331e-01 1.5101919e-01 0.0000000e+00 4.8050556e-01\n",
      "  0.0000000e+00 0.0000000e+00 1.1248252e+00 0.0000000e+00 6.2298286e-01\n",
      "  2.1868524e-01 0.0000000e+00 0.0000000e+00 1.1619687e+00 2.1167184e-01\n",
      "  7.8716391e-01 0.0000000e+00 1.2219514e-03 0.0000000e+00 8.4058803e-01\n",
      "  2.2822635e-01 2.4068555e-01 4.1535434e-01 6.2153477e-02 0.0000000e+00\n",
      "  2.9395378e-01 1.7478170e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0975479e+00 8.8020444e-01 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.         0.05246182 0.         0.01727788 0.         0.\n",
      "  0.23631085 0.33677545 0.07184982 0.06478562 0.06120374 0.\n",
      "  0.         0.06875336 0.         0.15566441 0.         0.08719137\n",
      "  0.         0.16789207 0.1334333  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02426007 0.29905668 0.         0.         0.\n",
      "  0.         0.06101432 0.         0.11303372 0.         0.\n",
      "  0.         0.00592757 0.22818774 0.44058558 0.         0.06909558\n",
      "  0.08820029 0.18702288 0.01570874 0.17718619 0.         0.2067651\n",
      "  0.         0.17683373 0.         0.         0.         0.\n",
      "  0.01552845 0.18477216 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6475006  0.         0.9996675  0.         0.         0.63248384\n",
      "  0.6628778  0.47353905 0.6756972  0.11684617 0.41531906 0.\n",
      "  0.         0.         0.         0.33421597 0.49197415 0.631101\n",
      "  0.         0.04237144 0.7939024  0.25824335 0.         0.38469005\n",
      "  0.02333472 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19735464 0.         0.         0.\n",
      "  0.         0.30982658 0.         0.7874455  0.         0.\n",
      "  0.         1.144414   0.         0.24538001 0.         0.\n",
      "  0.17834394 1.0521657  0.26066023 0.         0.47068548 0.\n",
      "  0.         0.47257486 0.         0.18030457 0.02935943 0.\n",
      "  0.3068145  1.1580719  0.06878189 0.23405002]]\n",
      "Hi!\n",
      "[[0.7632974  0.         1.077413   0.2703593  0.         0.7760329\n",
      "  1.3329856  1.2400125  0.85667366 0.         0.44952178 0.\n",
      "  0.         0.         0.         0.48549196 0.533507   0.83512235\n",
      "  0.         0.         0.9643266  0.35777557 0.         0.49850726\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01458105 0.         0.22890757 0.         0.13968256 0.\n",
      "  0.         0.89953506 0.         0.882345   0.13937183 0.\n",
      "  0.         1.5434034  0.         0.49647525 0.         0.\n",
      "  0.         1.045237   0.3236577  0.12796411 0.6245543  0.\n",
      "  0.         0.62826926 0.         0.1822059  0.         0.\n",
      "  0.         1.2418131  0.81804746 0.        ]]\n",
      "Hi!\n",
      "[[1.1633075  0.03464281 1.63205    0.06341808 0.         1.3107542\n",
      "  0.34114715 0.5938784  0.57459974 0.12886682 0.53653973 0.\n",
      "  0.         0.         0.         0.15897898 0.6706545  0.6007696\n",
      "  0.         0.39571577 1.0803523  0.06202786 0.         0.58829206\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21694873 0.22707944 0.         0.         0.\n",
      "  0.         0.32934904 0.         0.96701705 0.         0.\n",
      "  0.         1.013887   0.         0.46230915 0.         0.27842152\n",
      "  0.37459737 1.1550103  0.13320136 0.25682983 0.84594434 0.1677498\n",
      "  0.         1.4994926  0.         0.16709286 0.         0.\n",
      "  0.5109096  0.82947564 0.6216932  0.29605976]]\n",
      "Hi!\n",
      "[[0.3349695  0.49838683 0.86217916 0.         0.         0.55197316\n",
      "  0.35005713 0.66506356 0.813141   0.         0.518848   0.\n",
      "  1.0523113  0.         0.         0.53095084 0.         0.7236781\n",
      "  0.31300187 0.1539084  0.81492287 0.         0.         0.\n",
      "  0.09923594 0.         0.         0.27801257 0.         0.\n",
      "  0.8081809  0.5367395  0.         0.         0.42903033 0.\n",
      "  0.11421649 0.92742324 0.         0.40441018 0.04470143 0.\n",
      "  0.         0.27472943 0.5018608  0.45294383 0.         0.62573344\n",
      "  0.         0.7108039  0.6847617  0.33583272 0.5656262  0.48498031\n",
      "  0.         0.         0.1770027  0.         0.         0.\n",
      "  0.         0.6700288  1.0533125  0.4374673 ]]\n",
      "Hi!\n",
      "[[0.08457194 0.2997788  0.1044103  0.         0.         0.1245314\n",
      "  0.         0.07595845 0.06365513 0.02304168 0.1450344  0.\n",
      "  0.3116821  0.195858   0.         0.03047918 0.         0.03232161\n",
      "  0.         0.19103812 0.10138266 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14663552 0.17725347 0.12102484 0.         0.         0.\n",
      "  0.         0.         0.20699763 0.02600029 0.         0.\n",
      "  0.         0.         0.18657489 0.1638567  0.         0.08145609\n",
      "  0.10493199 0.07244527 0.         0.1542002  0.03334564 0.41803285\n",
      "  0.         0.         0.13919671 0.         0.         0.\n",
      "  0.05487522 0.09629828 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.1682239  0.49508846 0.3778408  0.         0.         0.26605254\n",
      "  0.         0.05988246 0.         0.         0.2186964  0.\n",
      "  0.41514248 0.29957074 0.         0.         0.         0.1082587\n",
      "  0.         0.42473948 0.17383532 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1524431  0.33742937 0.08007176 0.         0.         0.\n",
      "  0.         0.         0.3617628  0.12109563 0.         0.\n",
      "  0.         0.         0.37566686 0.30843395 0.         0.22254567\n",
      "  0.3647451  0.17405617 0.         0.29865587 0.19621153 0.67687505\n",
      "  0.         0.1717943  0.13536267 0.         0.0057968  0.\n",
      "  0.11654013 0.06542496 0.00419396 0.        ]]\n",
      "Hi!\n",
      "[[0.         0.2627571  0.23230997 0.         0.         0.24513033\n",
      "  0.04062492 0.15518177 0.06631234 0.11703493 0.17336234 0.\n",
      "  0.08928096 0.02989774 0.         0.07870457 0.         0.13956225\n",
      "  0.         0.26628378 0.15682873 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07891033 0.04690513 0.         0.         0.\n",
      "  0.         0.         0.         0.12462443 0.         0.\n",
      "  0.         0.         0.06534628 0.32552493 0.         0.11940129\n",
      "  0.10446276 0.28788295 0.01912923 0.15290849 0.12086591 0.33698344\n",
      "  0.         0.03839738 0.         0.         0.01433262 0.\n",
      "  0.15166636 0.29749957 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0563192  0.22287445 0.24995565 0.         0.         0.11215289\n",
      "  0.         0.02239135 0.03920432 0.04156537 0.14528662 0.\n",
      "  0.17940415 0.07562641 0.         0.         0.         0.00295484\n",
      "  0.         0.17329705 0.10037813 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01471559 0.21008523 0.10096823 0.         0.         0.\n",
      "  0.         0.         0.22388276 0.08159272 0.         0.\n",
      "  0.         0.         0.14936407 0.15994862 0.         0.07028078\n",
      "  0.2042096  0.06891872 0.         0.22278278 0.08796655 0.3778124\n",
      "  0.         0.08247588 0.03170712 0.         0.00857729 0.\n",
      "  0.05712575 0.06505594 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.58743525 0.         1.236257   0.         0.         0.59243774\n",
      "  0.91712785 0.9941064  1.5771834  0.         0.63366675 0.\n",
      "  0.26175016 0.         0.         1.0094513  0.42218825 0.9331308\n",
      "  0.1665286  0.         1.2084324  0.32935098 0.         0.526017\n",
      "  0.0061641  0.         0.         0.09098942 0.         0.\n",
      "  0.32073724 0.10573686 0.         0.         0.29129323 0.\n",
      "  0.25373402 1.258165   0.         0.76765865 0.31439102 0.\n",
      "  0.         1.4894042  0.         0.185786   0.         0.36377546\n",
      "  0.         0.83636904 0.8960018  0.14330687 0.46377048 0.\n",
      "  0.         0.         0.         0.54519576 0.         0.\n",
      "  0.         1.1909317  1.366506   0.7350627 ]]\n",
      "Hi!\n",
      "[[0.49423537 0.         0.24184455 0.5428436  0.         0.6642341\n",
      "  2.2496943  1.8722746  0.29026455 0.         0.18998292 0.\n",
      "  0.         0.         0.         0.36346763 0.         0.7534427\n",
      "  0.         0.         0.39691922 0.18150577 0.         0.00839887\n",
      "  0.         0.         0.         0.19576408 0.         0.\n",
      "  0.5603475  0.08867807 0.32188278 0.         0.5713216  0.\n",
      "  0.         1.068126   0.         0.7760067  0.29509428 0.\n",
      "  0.         1.287293   0.39124015 1.071864   0.         0.\n",
      "  0.         1.0865097  0.08223386 0.3885182  0.6109406  0.\n",
      "  0.         0.3660501  0.         0.         0.         0.\n",
      "  0.         1.2416189  0.6337935  0.        ]]\n",
      "Hi!\n",
      "[[0.34263253 0.5819336  0.45328385 0.03715761 0.         0.59346443\n",
      "  0.         0.47360143 0.         0.02755277 0.24135739 0.\n",
      "  0.27777132 0.41128445 0.         0.         0.         0.20255765\n",
      "  0.         0.66602635 0.23206155 0.         0.         0.18645567\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4495329  0.56353295 0.16466126 0.         0.         0.\n",
      "  0.         0.         0.4180363  0.26767752 0.         0.\n",
      "  0.         0.         0.64220417 0.74129915 0.         0.04832736\n",
      "  0.475801   0.67139477 0.         0.4758623  0.7752881  0.7269902\n",
      "  0.         0.61542594 0.04901188 0.         0.         0.\n",
      "  0.15096018 0.28417856 0.11251602 0.        ]]\n",
      "Hi!\n",
      "[[0.01926931 0.53785914 0.         0.         0.         0.12227253\n",
      "  0.40922838 0.50680053 0.30755854 0.         0.17321295 0.\n",
      "  0.6952791  0.32838598 0.         0.34052643 0.         0.3718646\n",
      "  0.         0.1838589  0.06698982 0.         0.         0.\n",
      "  0.1376349  0.         0.         0.20091508 0.         0.\n",
      "  0.3975748  0.23299108 0.02810506 0.         0.1743834  0.\n",
      "  0.09891649 0.57941854 0.         0.14740963 0.         0.\n",
      "  0.         0.06990052 0.36082804 0.47058812 0.         0.32394862\n",
      "  0.         0.45150065 0.4900065  0.11736736 0.         0.57266057\n",
      "  0.         0.         0.22922342 0.         0.         0.\n",
      "  0.         0.3564088  0.         0.16262144]]\n",
      "Hi!\n",
      "[[0.35138008 0.4223728  0.6906681  0.         0.         0.64753366\n",
      "  0.         0.06136705 0.         0.10769952 0.26725566 0.\n",
      "  0.04465578 0.         0.         0.         0.         0.20923552\n",
      "  0.         0.723326   0.32382706 0.         0.         0.03219486\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05498821 0.34883878 0.08272273 0.         0.         0.\n",
      "  0.         0.00780856 0.01169928 0.40899518 0.         0.\n",
      "  0.         0.         0.3434454  0.5486638  0.         0.37267873\n",
      "  0.5674292  0.5316609  0.         0.3846655  0.46234533 0.64610094\n",
      "  0.         0.776857   0.         0.         0.07568543 0.\n",
      "  0.3119652  0.19107868 0.08522555 0.04969309]]\n",
      "Hi!\n",
      "[[0.01835171 0.         0.08392269 0.         0.         0.12600408\n",
      "  0.0877634  0.19615766 0.01895517 0.12827744 0.1148449  0.\n",
      "  0.         0.         0.         0.01945277 0.         0.\n",
      "  0.         0.1280339  0.07746653 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1409497  0.         0.         0.\n",
      "  0.         0.         0.         0.15269803 0.         0.\n",
      "  0.         0.         0.04001685 0.36511827 0.         0.03784603\n",
      "  0.06178762 0.05374255 0.         0.20753969 0.         0.1541045\n",
      "  0.         0.18664996 0.         0.         0.         0.\n",
      "  0.         0.0569249  0.         0.        ]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02413177 0.12967478 0.10653522 0.         0.         0.09725645\n",
      "  0.01944632 0.14853148 0.         0.10713261 0.13264558 0.\n",
      "  0.02921497 0.13856629 0.         0.03200953 0.         0.06314215\n",
      "  0.         0.15828039 0.08883815 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10393618 0.12067504 0.         0.         0.\n",
      "  0.         0.         0.07867978 0.0979637  0.         0.\n",
      "  0.         0.         0.15800524 0.30686617 0.         0.03105215\n",
      "  0.13269891 0.13716535 0.         0.14136596 0.01797882 0.33012006\n",
      "  0.         0.07318725 0.02809335 0.         0.         0.\n",
      "  0.0554524  0.14111125 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.         0.00987129 0.05784054 0.         0.\n",
      "  0.15957086 0.31278235 0.         0.1532552  0.08772311 0.\n",
      "  0.         0.01374978 0.         0.10929903 0.         0.05424035\n",
      "  0.         0.05294405 0.11478326 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.2049628  0.         0.         0.\n",
      "  0.         0.06462758 0.07485081 0.1358382  0.         0.\n",
      "  0.         0.         0.11480816 0.34543696 0.         0.01723823\n",
      "  0.11709175 0.06746266 0.         0.16328304 0.         0.11201485\n",
      "  0.         0.22430605 0.         0.         0.         0.\n",
      "  0.         0.17786093 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.46985596 0.2830453  0.425646   0.01282908 0.         0.60487795\n",
      "  0.8430916  1.1757531  0.74921185 0.         0.3896187  0.\n",
      "  1.2817171  0.30600163 0.         0.67531633 0.         0.6532366\n",
      "  0.70322734 0.02074045 0.62723565 0.10504299 0.         0.\n",
      "  0.3083523  0.         0.         0.54472846 0.         0.\n",
      "  1.110224   0.6402927  0.         0.         0.7020068  0.\n",
      "  0.55299544 1.26761    0.         0.24925926 0.10378849 0.\n",
      "  0.         0.37923872 0.9603331  0.6959643  0.         0.7791999\n",
      "  0.         0.6093399  0.8075316  0.4892151  0.500247   0.7892613\n",
      "  0.         0.         0.4540151  0.         0.         0.\n",
      "  0.         0.4583844  1.2786927  0.24218692]]\n",
      "Hi!\n",
      "[[0.50608885 0.00987329 1.2578623  0.         0.         0.688807\n",
      "  0.5833107  0.5519701  1.1446773  0.         0.6219014  0.\n",
      "  0.39428937 0.         0.         0.7502833  0.2988627  0.8573256\n",
      "  0.16152114 0.         1.1002879  0.20383185 0.         0.3691208\n",
      "  0.05788574 0.         0.         0.         0.         0.\n",
      "  0.18303755 0.2412267  0.         0.         0.19596136 0.\n",
      "  0.28725496 1.0714215  0.         0.76431704 0.09916075 0.\n",
      "  0.         0.965402   0.         0.18764202 0.         0.64079994\n",
      "  0.         0.6462253  0.66832316 0.12991124 0.268116   0.10674044\n",
      "  0.         0.01257429 0.         0.42239383 0.         0.\n",
      "  0.         0.961194   1.1603708  0.6911916 ]]\n",
      "Hi!\n",
      "[[0.09092616 0.3611072  0.900256   0.         0.         0.39355913\n",
      "  0.702565   0.5501653  1.2238921  0.         0.5627263  0.\n",
      "  0.8113026  0.         0.         0.9837773  0.         0.89995503\n",
      "  0.5167834  0.01733609 0.9226286  0.19854513 0.         0.\n",
      "  0.35802382 0.         0.         0.19298495 0.         0.\n",
      "  0.54977477 0.10232989 0.         0.         0.54399395 0.\n",
      "  0.39819747 1.2135776  0.         0.44343767 0.15421388 0.\n",
      "  0.         0.78357214 0.2681421  0.03890474 0.         0.7621357\n",
      "  0.         0.7799586  0.97912025 0.10290468 0.16138944 0.12422504\n",
      "  0.         0.         0.1628763  0.33926934 0.         0.\n",
      "  0.         0.98272806 1.0177587  0.7077778 ]]\n",
      "Hi!\n",
      "[[0.6283954  0.         0.85945517 0.38530207 0.         0.80387294\n",
      "  2.0333838  2.0180523  1.0363601  0.         0.38394177 0.\n",
      "  0.         0.         0.         0.70336956 0.2524843  0.8116361\n",
      "  0.         0.         0.9270396  0.2883402  0.         0.35705096\n",
      "  0.         0.         0.         0.2447194  0.         0.\n",
      "  0.5759988  0.15495959 0.21014723 0.         0.601655   0.\n",
      "  0.         1.4385561  0.         0.7240046  0.4003865  0.\n",
      "  0.         1.7714797  0.08198294 0.7349066  0.         0.\n",
      "  0.         0.9163194  0.4575012  0.37204564 0.7166756  0.\n",
      "  0.         0.356587   0.         0.09610258 0.         0.\n",
      "  0.         1.3106599  1.5195372  0.        ]]\n",
      "Hi!\n",
      "[[0.5724842  0.97008413 0.5093263  0.         0.         0.3153791\n",
      "  0.24976341 0.72603476 0.7792512  0.         0.47442383 0.\n",
      "  1.8883734  0.6469634  0.         0.751516   0.         0.6953633\n",
      "  0.85090804 0.3797864  0.6328281  0.01789516 0.         0.1776919\n",
      "  0.23862697 0.         0.         0.5444627  0.         0.\n",
      "  1.2114705  0.786419   0.         0.         0.55801356 0.\n",
      "  0.54524636 1.0026169  0.24420235 0.40061736 0.         0.\n",
      "  0.         0.36103117 1.0041156  0.49865553 0.         0.9362745\n",
      "  0.         0.7495158  0.90667665 0.35349387 0.54943806 0.94011724\n",
      "  0.         0.         0.41653773 0.         0.         0.\n",
      "  0.         0.44277048 0.96394014 0.4031162 ]]\n",
      "Hi!\n",
      "[[0.84733856 0.13400678 1.4505893  0.07850919 0.         1.3134546\n",
      "  0.43670163 0.61278415 0.28839988 0.         0.4266702  0.\n",
      "  0.1160881  0.         0.         0.09100379 0.28154075 0.5326508\n",
      "  0.         0.5584018  0.8823508  0.         0.         0.19492814\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11265171 0.69525415 0.06030035 0.         0.         0.\n",
      "  0.         0.56311125 0.         0.6623152  0.         0.\n",
      "  0.         0.42738286 0.37777573 0.65242606 0.         0.66050977\n",
      "  0.48848036 0.73138136 0.06339202 0.57880354 0.6849518  0.7500967\n",
      "  0.         1.2942107  0.         0.         0.         0.\n",
      "  0.14635856 0.46740827 1.0592697  0.04672193]]\n",
      "Hi!\n",
      "[[0.6517831  0.8034161  0.6597292  0.         0.         0.8444645\n",
      "  0.04523258 0.66976523 0.12641965 0.         0.37568462 0.\n",
      "  1.1929545  0.4913098  0.         0.         0.         0.2781956\n",
      "  0.03992058 0.8171007  0.4858278  0.         0.         0.14057562\n",
      "  0.         0.         0.         0.28946266 0.         0.\n",
      "  0.9553057  0.8873978  0.         0.         0.18715474 0.\n",
      "  0.00982032 0.47092253 0.4041227  0.21382621 0.         0.\n",
      "  0.         0.1539614  1.0667797  0.88999635 0.         0.75065285\n",
      "  0.48740894 0.7227882  0.22382466 0.6010893  0.8587682  1.2810483\n",
      "  0.         0.504999   0.29223606 0.         0.         0.\n",
      "  0.         0.         0.70225006 0.00855671]]\n",
      "Hi!\n",
      "[[0.12932561 0.5125822  0.36545795 0.         0.         0.20623723\n",
      "  0.         0.         0.16354427 0.         0.2355206  0.\n",
      "  0.48685804 0.14347088 0.         0.08394293 0.         0.09517287\n",
      "  0.         0.37807414 0.22256586 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21434322 0.21979922 0.         0.         0.         0.\n",
      "  0.         0.         0.17935473 0.12121208 0.         0.\n",
      "  0.         0.         0.14122356 0.08719722 0.         0.267102\n",
      "  0.21288775 0.22767054 0.09294485 0.2233729  0.08504267 0.47554263\n",
      "  0.         0.         0.11514849 0.         0.09927855 0.\n",
      "  0.10065081 0.09955622 0.         0.07793691]]\n",
      "Hi!\n",
      "[[0.88204086 0.9853421  0.9186161  0.12424176 0.         0.6880534\n",
      "  0.         0.2788152  0.         0.         0.34324163 0.\n",
      "  1.1299175  0.48493788 0.         0.         0.         0.36538017\n",
      "  0.01231321 0.97014016 0.4357548  0.         0.         0.2837373\n",
      "  0.         0.         0.         0.38973555 0.         0.\n",
      "  0.80730814 1.011761   0.         0.         0.13970481 0.\n",
      "  0.23805074 0.23423004 0.8511277  0.30638513 0.         0.\n",
      "  0.         0.14271836 1.1437982  0.65152043 0.         0.6980301\n",
      "  0.65714055 0.4711773  0.         0.66641635 0.58474946 1.4117546\n",
      "  0.         0.5937044  0.3357652  0.         0.03242138 0.\n",
      "  0.         0.17583758 0.7516682  0.        ]]\n",
      "Hi!\n",
      "[[0.3250388  0.01612503 0.8887979  0.         0.         0.74340045\n",
      "  0.89240074 0.85906255 0.76726794 0.         0.47179046 0.\n",
      "  0.49748418 0.         0.         0.6114239  0.         0.8020085\n",
      "  0.15435188 0.         0.82828057 0.         0.         0.\n",
      "  0.19560935 0.         0.         0.17048116 0.         0.\n",
      "  0.55164325 0.35955215 0.         0.         0.45185181 0.\n",
      "  0.29385602 1.1875268  0.         0.52881974 0.0397031  0.\n",
      "  0.         0.695158   0.45712572 0.5250425  0.         0.69030666\n",
      "  0.         0.6326429  0.5326631  0.2821204  0.28171608 0.42965192\n",
      "  0.         0.         0.26407743 0.06741118 0.         0.\n",
      "  0.         0.8306438  1.165331   0.34874645]]\n",
      "Hi!\n",
      "[[0.73068327 0.         1.0949391  0.07103888 0.         0.81254834\n",
      "  0.9547858  0.96928954 0.8099606  0.         0.4581348  0.\n",
      "  0.         0.         0.         0.41346887 0.38893127 0.7470777\n",
      "  0.         0.         0.9793073  0.21009089 0.         0.49002337\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05277761 0.17570697 0.10748369 0.         0.09669543 0.\n",
      "  0.         0.8159213  0.         0.7385423  0.         0.\n",
      "  0.         1.1280565  0.         0.44728348 0.         0.05528172\n",
      "  0.         0.9226636  0.33424577 0.22577558 0.5571085  0.\n",
      "  0.         0.610893   0.         0.1560359  0.         0.\n",
      "  0.         1.0279732  0.8834519  0.16802107]]\n",
      "Hi!\n",
      "[[0.15981063 0.25298578 0.         0.11878481 0.         0.13787548\n",
      "  0.28143817 0.3996307  0.         0.02990892 0.01222614 0.\n",
      "  0.13616163 0.3309621  0.         0.01020725 0.         0.15180892\n",
      "  0.         0.32715484 0.         0.         0.         0.06557766\n",
      "  0.         0.         0.         0.1586135  0.         0.\n",
      "  0.3146024  0.30803248 0.3529718  0.         0.02161083 0.\n",
      "  0.         0.05849057 0.24242379 0.1467359  0.         0.\n",
      "  0.         0.00979855 0.49911007 0.625756   0.         0.01159952\n",
      "  0.15559785 0.3462125  0.         0.26362747 0.18210873 0.56161785\n",
      "  0.         0.14927122 0.2309226  0.         0.         0.\n",
      "  0.         0.19618666 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.0034704  0.12888867 0.         0.         0.         0.01579276\n",
      "  0.04848873 0.2299989  0.         0.05359917 0.06246158 0.\n",
      "  0.06608995 0.2166085  0.         0.01691037 0.         0.09500384\n",
      "  0.         0.05615102 0.01223034 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05572699 0.11023889 0.18044212 0.         0.         0.\n",
      "  0.         0.         0.19770423 0.01768116 0.         0.\n",
      "  0.         0.         0.24544169 0.3211194  0.         0.\n",
      "  0.11312132 0.06709513 0.         0.15281405 0.04615507 0.34561056\n",
      "  0.         0.04981208 0.07802723 0.         0.         0.\n",
      "  0.03221999 0.17869473 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.37597042 0.2197997  0.7392587  0.         0.         0.7838278\n",
      "  0.5461828  0.76017463 0.37455517 0.03273753 0.3732115  0.\n",
      "  0.25633317 0.         0.         0.18107566 0.         0.54245955\n",
      "  0.         0.2969106  0.67951244 0.         0.         0.15285876\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.44107637 0.39780796 0.03754456 0.         0.16105075 0.\n",
      "  0.         0.59191906 0.         0.45444655 0.         0.\n",
      "  0.         0.30554536 0.3533607  0.6500894  0.         0.1990051\n",
      "  0.08819572 0.869776   0.15757117 0.4066487  0.6415982  0.28549558\n",
      "  0.         0.3822192  0.         0.         0.         0.\n",
      "  0.         0.6506641  0.691949   0.05991062]]\n",
      "Hi!\n",
      "[[0.5940763  0.0611027  1.295621   0.         0.         0.85689735\n",
      "  0.44927555 0.43985716 0.9225869  0.         0.60513747 0.\n",
      "  0.37881187 0.         0.         0.5862002  0.2794956  0.80479676\n",
      "  0.00544228 0.05535754 1.1011324  0.09340958 0.         0.28635898\n",
      "  0.02808526 0.         0.         0.         0.         0.\n",
      "  0.08539355 0.30637246 0.         0.         0.13612497 0.\n",
      "  0.17707825 0.8824073  0.         0.7403387  0.05733102 0.\n",
      "  0.         0.78579754 0.         0.25865486 0.         0.74839574\n",
      "  0.         0.6863717  0.5532502  0.22032908 0.26110846 0.34680226\n",
      "  0.         0.21997412 0.         0.37391636 0.         0.\n",
      "  0.         0.8042176  1.024741   0.6034499 ]]\n",
      "Hi!\n",
      "[[0.97616476 0.         1.422471   0.08449191 0.         1.141407\n",
      "  0.51917166 0.6699126  0.58681124 0.1022026  0.5019385  0.\n",
      "  0.         0.         0.         0.17547695 0.5659352  0.69478256\n",
      "  0.         0.26288864 0.99213725 0.08405203 0.         0.559688\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19041394 0.18114106 0.         0.         0.\n",
      "  0.         0.3998125  0.         0.9237543  0.         0.\n",
      "  0.         1.0154034  0.         0.51138747 0.         0.11371569\n",
      "  0.21622255 1.089969   0.17156607 0.27226645 0.7406133  0.0578546\n",
      "  0.         1.1867394  0.         0.0836909  0.         0.\n",
      "  0.37263498 0.8982298  0.5983892  0.18528518]]\n",
      "Hi!\n",
      "[[0.07983197 0.19955985 0.19987233 0.         0.         0.25216982\n",
      "  0.         0.00508639 0.10932995 0.04774817 0.22953387 0.\n",
      "  0.16955072 0.06883229 0.         0.03431517 0.         0.\n",
      "  0.         0.28936264 0.16781728 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05784192 0.06145519 0.         0.         0.\n",
      "  0.         0.         0.13284042 0.11568729 0.         0.\n",
      "  0.         0.         0.06055757 0.24405083 0.         0.17234477\n",
      "  0.16209644 0.08169807 0.         0.22195567 0.05924818 0.42329353\n",
      "  0.         0.0070885  0.01538306 0.         0.04415564 0.\n",
      "  0.01722528 0.02874639 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.38974342 0.04486952 0.6783533  0.         0.         0.47215346\n",
      "  0.6549153  0.5866825  0.5970994  0.05802361 0.37752414 0.\n",
      "  0.         0.         0.         0.33915034 0.17813475 0.7390053\n",
      "  0.         0.07435431 0.65686274 0.21543078 0.         0.15477562\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10606777 0.         0.10014258 0.\n",
      "  0.         0.6154158  0.         0.5407417  0.         0.\n",
      "  0.         0.7956596  0.         0.35841605 0.         0.\n",
      "  0.         0.8051494  0.31105155 0.05786248 0.24151278 0.\n",
      "  0.         0.01072168 0.         0.         0.         0.\n",
      "  0.03403948 1.0298078  0.20865889 0.22108288]]\n",
      "Hi!\n",
      "[[0.5141996  0.00284424 0.         0.4778666  0.         0.4474394\n",
      "  1.6631231  1.7513903  0.         0.         0.09825995 0.\n",
      "  0.5663359  0.82976735 0.         0.2744811  0.         0.4963399\n",
      "  0.         0.1060336  0.13499987 0.31576592 0.         0.00665449\n",
      "  0.2043181  0.         0.         0.7722226  0.         0.\n",
      "  1.3896184  0.6380076  0.38408756 0.         0.8428507  0.\n",
      "  0.24151613 1.133045   0.09788425 0.24736239 0.26428163 0.\n",
      "  0.         0.49436864 1.3937678  1.4157075  0.         0.19630897\n",
      "  0.         0.9348048  0.36690378 0.6310869  0.7356844  0.8938416\n",
      "  0.         0.00457634 0.51922154 0.         0.         0.\n",
      "  0.         0.519606   0.6394534  0.        ]]\n",
      "Hi!\n",
      "[[0.41134283 0.24933223 0.46580592 0.01365049 0.         0.7566249\n",
      "  0.39864412 0.59138864 0.         0.2522475  0.17611621 0.\n",
      "  0.         0.02575543 0.         0.10889873 0.         0.28746432\n",
      "  0.         0.6505288  0.25256693 0.         0.         0.05124746\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06095296 0.25744268 0.18559839 0.         0.         0.\n",
      "  0.         0.12503645 0.         0.54486525 0.         0.\n",
      "  0.         0.14699219 0.32401636 0.8752501  0.         0.03672798\n",
      "  0.46868935 0.8814714  0.         0.4388666  0.6275039  0.44159487\n",
      "  0.         0.9149387  0.         0.         0.         0.\n",
      "  0.39725646 0.54801047 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.356885   0.2933237  0.5816278  0.         0.         0.50953615\n",
      "  0.5938954  0.57616484 0.6275664  0.         0.40618593 0.\n",
      "  0.6989524  0.         0.         0.5422553  0.         0.65970343\n",
      "  0.21012114 0.19669452 0.5721595  0.         0.         0.\n",
      "  0.2154707  0.         0.         0.15173738 0.         0.\n",
      "  0.55813074 0.32557967 0.         0.         0.44224125 0.\n",
      "  0.34103578 0.986102   0.         0.37669945 0.0313521  0.\n",
      "  0.         0.31098852 0.4934679  0.42594686 0.         0.71970564\n",
      "  0.         0.5440581  0.5846915  0.2628094  0.15508105 0.5369146\n",
      "  0.         0.         0.24032395 0.         0.         0.\n",
      "  0.         0.5583186  0.8429913  0.3377944 ]]\n",
      "Hi!\n",
      "[[0.10112892 0.39229602 0.3440962  0.         0.         0.21748243\n",
      "  0.         0.         0.19799711 0.03032544 0.24278209 0.\n",
      "  0.38380995 0.         0.         0.07686735 0.         0.05188631\n",
      "  0.         0.31806684 0.23811689 0.         0.         0.0102193\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14448947 0.20268184 0.         0.         0.         0.\n",
      "  0.         0.         0.02678362 0.12879987 0.         0.\n",
      "  0.         0.         0.00088744 0.02007766 0.         0.2672332\n",
      "  0.11058906 0.19367515 0.08905917 0.14740136 0.0957029  0.352666\n",
      "  0.         0.         0.04153067 0.         0.12000448 0.\n",
      "  0.11345832 0.04080594 0.         0.12645695]]\n",
      "Hi!\n",
      "[[0.8253188  0.35530186 1.4577748  0.         0.         1.0178707\n",
      "  0.1908647  0.27948675 0.6923089  0.07082081 0.5866081  0.\n",
      "  0.07751562 0.         0.         0.23035844 0.46074563 0.6660709\n",
      "  0.         0.41344765 1.0889859  0.06052973 0.         0.5556472\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26812187 0.09932592 0.         0.         0.\n",
      "  0.         0.38108355 0.         0.803099   0.         0.\n",
      "  0.         0.6798362  0.         0.2893733  0.         0.38334042\n",
      "  0.28770307 0.9650876  0.31558844 0.25981706 0.6351096  0.26814768\n",
      "  0.         0.8821652  0.         0.16725904 0.08765047 0.\n",
      "  0.21561712 0.7041903  0.5872252  0.50082743]]\n",
      "Hi!\n",
      "[[0.6345108  0.63987726 0.18488465 0.21806215 0.         0.46970028\n",
      "  0.3673102  0.7100174  0.         0.         0.1540017  0.\n",
      "  0.80429393 0.8206946  0.         0.         0.         0.25366184\n",
      "  0.         0.7296453  0.04366444 0.         0.         0.2970364\n",
      "  0.         0.         0.         0.48033652 0.         0.\n",
      "  1.0760689  0.8871158  0.33055943 0.         0.26645377 0.\n",
      "  0.02511578 0.31126514 0.6345357  0.14134367 0.         0.\n",
      "  0.         0.17151305 1.1777374  1.0727379  0.         0.39630756\n",
      "  0.4730112  0.69995797 0.         0.53891146 0.63643605 1.0923078\n",
      "  0.         0.49107024 0.37775126 0.         0.         0.\n",
      "  0.         0.06177731 0.2963278  0.        ]]\n",
      "Hi!\n",
      "[[8.27966556e-02 4.45669085e-01 3.04933220e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.64058536e-01 0.00000000e+00 3.28069218e-02\n",
      "  2.54998296e-01 1.55645441e-02 2.22559959e-01 0.00000000e+00\n",
      "  4.77263898e-01 0.00000000e+00 0.00000000e+00 1.40047923e-01\n",
      "  0.00000000e+00 1.40969483e-02 0.00000000e+00 3.55840534e-01\n",
      "  2.32891932e-01 0.00000000e+00 0.00000000e+00 4.79510101e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00261223e-05 0.00000000e+00 1.14059955e-01 2.26546139e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.08068879e-02 1.01652117e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.86315347e-02\n",
      "  8.14105198e-02 0.00000000e+00 0.00000000e+00 2.63502508e-01\n",
      "  0.00000000e+00 7.95214623e-02 1.09637566e-01 1.20664006e-02\n",
      "  4.34377752e-02 4.31174427e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.63206458e-01 0.00000000e+00 3.10603045e-02 0.00000000e+00\n",
      "  6.41802549e-02 5.41073568e-02 1.47531240e-03 1.26820683e-01]]\n",
      "Hi!\n",
      "[[0.14147112 0.48040566 0.3803779  0.         0.         0.24341993\n",
      "  0.         0.03268227 0.         0.         0.21402471 0.\n",
      "  0.4223275  0.24321468 0.         0.         0.         0.12635244\n",
      "  0.         0.4116744  0.15270723 0.         0.         0.00670671\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19603495 0.34641063 0.08365256 0.         0.         0.\n",
      "  0.         0.         0.321976   0.11316372 0.         0.\n",
      "  0.         0.         0.33196    0.26489577 0.         0.24231188\n",
      "  0.35807922 0.23286189 0.         0.27482426 0.15578651 0.6846445\n",
      "  0.         0.15439963 0.16149592 0.         0.         0.\n",
      "  0.13589527 0.09049395 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.42524773 0.         0.70027035 0.13252077 0.         0.5726095\n",
      "  1.4369886  1.292223   0.8249962  0.         0.41413116 0.\n",
      "  0.         0.         0.         0.61094433 0.04548751 0.8509991\n",
      "  0.         0.         0.8022167  0.12558655 0.         0.1679691\n",
      "  0.06683507 0.         0.         0.07687166 0.         0.\n",
      "  0.45407227 0.08269317 0.10232489 0.         0.5175208  0.\n",
      "  0.         1.1983124  0.         0.5971637  0.15677546 0.\n",
      "  0.         1.1665794  0.16682835 0.6265255  0.         0.05079383\n",
      "  0.         0.8369834  0.44178957 0.2193936  0.43771592 0.\n",
      "  0.         0.         0.         0.01631824 0.         0.\n",
      "  0.         1.1751875  1.0083283  0.11177356]]\n",
      "Hi!\n",
      "[[0.90106124 0.         1.2478757  0.11382281 0.         1.0224003\n",
      "  0.6400002  0.8155507  0.6883761  0.10141219 0.47185114 0.\n",
      "  0.         0.         0.         0.22411479 0.44696248 0.69931966\n",
      "  0.         0.04875125 0.9785018  0.10644756 0.         0.6637637\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17881377 0.2181099  0.         0.         0.\n",
      "  0.         0.51542056 0.         0.9182422  0.         0.\n",
      "  0.         1.0593368  0.         0.55420494 0.         0.\n",
      "  0.06062686 1.2008578  0.215108   0.29142982 0.8032206  0.\n",
      "  0.         1.0089213  0.         0.09297453 0.         0.\n",
      "  0.15556009 0.9746874  0.67343587 0.17402484]]\n",
      "Hi!\n",
      "[[0.31733808 0.         0.47397834 0.14436491 0.         0.71172214\n",
      "  1.3601333  1.6174688  1.0207492  0.         0.37730393 0.\n",
      "  0.98234355 0.01801391 0.         0.7870191  0.         0.71181995\n",
      "  0.6308722  0.         0.7336543  0.19553666 0.         0.\n",
      "  0.31447557 0.         0.         0.730174   0.         0.\n",
      "  1.2086468  0.48316088 0.         0.         0.8121201  0.\n",
      "  0.44307384 1.5128436  0.         0.25311816 0.25451666 0.\n",
      "  0.         0.87596965 0.7553014  0.84922504 0.         0.51272386\n",
      "  0.         0.7023148  0.8430598  0.5205487  0.60843915 0.40256083\n",
      "  0.         0.         0.47717494 0.         0.         0.\n",
      "  0.         0.7079909  1.6473099  0.24059169]]\n",
      "Hi!\n",
      "[[0.37266093 0.         0.7315616  0.11675444 0.         0.6877468\n",
      "  1.1471654  1.3100661  0.82178223 0.         0.40462023 0.\n",
      "  0.25812086 0.         0.         0.5642435  0.         0.7096866\n",
      "  0.         0.         0.795615   0.00649194 0.         0.16694465\n",
      "  0.         0.         0.         0.29276147 0.         0.\n",
      "  0.7420182  0.38667548 0.06417073 0.         0.5061752  0.\n",
      "  0.         1.1575738  0.         0.47656116 0.13425274 0.\n",
      "  0.         0.89679503 0.31989074 0.73055834 0.         0.15189728\n",
      "  0.         0.8406421  0.47054416 0.36761987 0.6782012  0.10569019\n",
      "  0.         0.03601798 0.12563275 0.         0.         0.\n",
      "  0.         0.9172428  1.2632627  0.08305476]]\n",
      "Hi!\n",
      "[[0.30950716 0.34286767 0.2159482  0.13064684 0.         0.317801\n",
      "  0.         0.30070454 0.         0.         0.05332175 0.\n",
      "  0.3267299  0.5176941  0.         0.         0.         0.07760483\n",
      "  0.         0.34423128 0.         0.         0.         0.06342722\n",
      "  0.         0.         0.         0.13505223 0.         0.\n",
      "  0.41140777 0.6311396  0.282849   0.         0.         0.\n",
      "  0.         0.         0.59078044 0.08095307 0.         0.\n",
      "  0.         0.         0.67779    0.51109034 0.         0.07647952\n",
      "  0.5002092  0.37576106 0.         0.412937   0.37492377 0.9148739\n",
      "  0.         0.36597538 0.1955328  0.         0.         0.\n",
      "  0.17577624 0.11671738 0.05749271 0.        ]]\n",
      "Hi!\n",
      "[[0.45202962 0.15623713 0.8307347  0.         0.         0.67872036\n",
      "  0.4871935  0.34227222 0.42108148 0.         0.3482658  0.\n",
      "  0.06953392 0.         0.         0.21520028 0.20228027 0.6308061\n",
      "  0.         0.31781775 0.6339733  0.         0.         0.\n",
      "  0.03090028 0.         0.         0.         0.         0.\n",
      "  0.11826675 0.16311245 0.         0.         0.11905961 0.\n",
      "  0.00620721 0.63533163 0.         0.48501223 0.         0.\n",
      "  0.         0.39325857 0.15250802 0.3726126  0.         0.5397425\n",
      "  0.09871172 0.5527747  0.29176885 0.21067154 0.11188626 0.39464688\n",
      "  0.         0.2656072  0.         0.02300701 0.         0.\n",
      "  0.03009913 0.62626135 0.501417   0.27168158]]\n",
      "Hi!\n",
      "[[0.5960235  0.         0.95778555 0.18762851 0.         0.6762855\n",
      "  1.3782992  1.4786053  1.1508597  0.         0.4462803  0.\n",
      "  0.         0.         0.         0.72950673 0.2357765  0.8048581\n",
      "  0.         0.         0.98699814 0.2402188  0.         0.50764155\n",
      "  0.         0.         0.         0.11971352 0.         0.\n",
      "  0.41919783 0.14422576 0.13949318 0.         0.3855497  0.\n",
      "  0.         1.2389064  0.         0.7347592  0.16635117 0.\n",
      "  0.         1.4397986  0.         0.54840827 0.         0.00971535\n",
      "  0.         0.88713324 0.56322896 0.25931588 0.6501177  0.\n",
      "  0.         0.23399092 0.         0.19708827 0.         0.\n",
      "  0.         1.2050313  1.3554236  0.19642898]]\n",
      "Hi!\n",
      "[[0.02028156 0.24673049 0.26371476 0.         0.         0.31819293\n",
      "  0.         0.1033309  0.1060265  0.09826499 0.2397209  0.\n",
      "  0.04377259 0.07617111 0.         0.         0.         0.05116457\n",
      "  0.         0.351838   0.19313723 0.         0.         0.0105025\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07253873 0.04225257 0.         0.         0.\n",
      "  0.         0.         0.06062162 0.1802351  0.         0.\n",
      "  0.         0.         0.09247586 0.35980573 0.         0.1526843\n",
      "  0.22586688 0.20799163 0.         0.2598265  0.19566293 0.32231286\n",
      "  0.         0.17809257 0.00235759 0.         0.07689762 0.\n",
      "  0.08324965 0.13868089 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.00046182 0.01151315 0.         0.         0.\n",
      "  0.18239866 0.24498309 0.05359493 0.13439077 0.05523704 0.\n",
      "  0.         0.07756209 0.         0.03947047 0.         0.06494809\n",
      "  0.         0.         0.08070116 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17877744 0.         0.         0.\n",
      "  0.         0.00883592 0.1169265  0.10207807 0.         0.\n",
      "  0.         0.         0.16526964 0.33567083 0.         0.\n",
      "  0.1533951  0.         0.         0.23517998 0.         0.10371228\n",
      "  0.         0.22559321 0.00161094 0.         0.         0.\n",
      "  0.00608446 0.09525491 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.06352866 0.15244141 0.37917918 0.         0.         0.2475925\n",
      "  0.         0.01975748 0.20089981 0.1790672  0.24376516 0.\n",
      "  0.         0.         0.         0.12667112 0.         0.11112241\n",
      "  0.         0.3213773  0.25077903 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1058114  0.         0.         0.\n",
      "  0.         0.         0.02834043 0.22530903 0.         0.\n",
      "  0.         0.         0.         0.22189045 0.         0.11744165\n",
      "  0.15826279 0.18590361 0.00808619 0.15814252 0.05562358 0.16072924\n",
      "  0.         0.18107606 0.         0.         0.08234196 0.\n",
      "  0.1328042  0.20075384 0.         0.14159083]]\n",
      "Hi!\n",
      "[[0.7846817  0.39129573 1.3395418  0.         0.         1.2067953\n",
      "  0.0922817  0.40884322 0.32968947 0.09236654 0.50138324 0.\n",
      "  0.2044878  0.         0.         0.         0.17272279 0.46609622\n",
      "  0.         0.70662296 0.8653538  0.         0.         0.28600627\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08650637 0.530773   0.05797214 0.         0.         0.\n",
      "  0.         0.36628255 0.         0.60423535 0.         0.\n",
      "  0.         0.15746586 0.30895248 0.59489197 0.         0.5882139\n",
      "  0.5203809  0.8370339  0.11067332 0.5525548  0.7723162  0.69116247\n",
      "  0.         1.2018857  0.         0.         0.07020751 0.\n",
      "  0.15534344 0.36171028 0.77285475 0.23840544]]\n",
      "Hi!\n",
      "[[0.8446555  0.10420287 1.1549346  0.15034279 0.         1.174533\n",
      "  0.53405374 0.85726976 0.19012298 0.07321309 0.4129305  0.\n",
      "  0.         0.         0.         0.09463932 0.19304483 0.51557827\n",
      "  0.         0.4821485  0.756439   0.         0.         0.37933853\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1597479  0.49239147 0.13328896 0.         0.         0.\n",
      "  0.         0.34189132 0.         0.72247916 0.         0.\n",
      "  0.         0.51094794 0.2771822  0.8692213  0.         0.\n",
      "  0.32489854 1.1595716  0.         0.53194803 1.0338936  0.336963\n",
      "  0.         1.3062338  0.         0.         0.00605192 0.\n",
      "  0.2922134  0.60937715 0.6586099  0.        ]]\n",
      "Hi!\n",
      "[[0.0756147  0.20108968 0.04425629 0.01007864 0.         0.\n",
      "  0.         0.15313101 0.         0.00655846 0.08439013 0.\n",
      "  0.19328685 0.25668934 0.         0.         0.         0.08167467\n",
      "  0.         0.12128827 0.05143067 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0992312  0.18736976 0.23636685 0.         0.         0.\n",
      "  0.         0.         0.26486105 0.01929283 0.         0.\n",
      "  0.         0.         0.26341265 0.28545895 0.         0.\n",
      "  0.12677117 0.08043193 0.         0.22040923 0.06369241 0.41692182\n",
      "  0.         0.06094154 0.1375702  0.         0.         0.\n",
      "  0.09715015 0.08814244 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.00859366 0.5451701  0.15515032 0.         0.         0.19068946\n",
      "  0.27087033 0.51422596 0.12147855 0.         0.27105418 0.\n",
      "  0.37553623 0.2603446  0.         0.06591435 0.         0.11918855\n",
      "  0.         0.3463015  0.32083997 0.         0.         0.08322788\n",
      "  0.         0.         0.         0.27798527 0.         0.\n",
      "  0.2669855  0.21568173 0.04137421 0.         0.         0.\n",
      "  0.         0.07871048 0.42284092 0.3161303  0.         0.\n",
      "  0.         0.         0.27990815 0.57257265 0.         0.\n",
      "  0.33947536 0.34619465 0.31248844 0.21236508 0.68020046 0.52975523\n",
      "  0.         0.         0.21030715 0.         0.         0.\n",
      "  0.0279365  0.4161071  0.         0.        ]]\n",
      "Hi!\n",
      "[[0.3083524  0.         0.47632784 0.02459806 0.         0.72683847\n",
      "  1.0577083  0.9829144  0.35909134 0.         0.29808182 0.\n",
      "  0.3439018  0.         0.         0.31807214 0.         0.65093803\n",
      "  0.         0.13332051 0.5123192  0.04750716 0.         0.\n",
      "  0.14424203 0.         0.         0.14487721 0.         0.\n",
      "  0.68477875 0.4226124  0.         0.         0.49653494 0.\n",
      "  0.2052252  1.0209907  0.         0.34899622 0.00161906 0.\n",
      "  0.         0.47888228 0.6295523  0.77633816 0.         0.5430633\n",
      "  0.         0.6707591  0.37077793 0.3905985  0.3082646  0.6673634\n",
      "  0.         0.10819321 0.2059599  0.         0.         0.\n",
      "  0.         0.58766    0.7875225  0.04018725]]\n",
      "Hi!\n",
      "[[0.74433315 0.         1.0227938  0.09024097 0.         0.8829103\n",
      "  0.7714954  0.7001035  0.45234808 0.02157365 0.38208297 0.\n",
      "  0.         0.         0.         0.19048057 0.37966007 0.62600595\n",
      "  0.         0.22715203 0.76928765 0.04932792 0.         0.24781364\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18844959 0.11982577 0.         0.04756333 0.\n",
      "  0.         0.5818206  0.         0.63586855 0.         0.\n",
      "  0.         0.8324201  0.01049776 0.4955224  0.         0.16787162\n",
      "  0.09644724 0.82160044 0.1607177  0.25544113 0.41061303 0.21966979\n",
      "  0.         0.77917254 0.         0.         0.         0.\n",
      "  0.25081304 0.7821333  0.50297284 0.07601537]]\n",
      "Hi!\n",
      "[[0.8421005  0.6154203  0.13026625 0.49064958 0.         0.68548125\n",
      "  0.5972893  1.2080997  0.         0.         0.08996692 0.\n",
      "  0.79573846 1.0092506  0.         0.         0.         0.10526299\n",
      "  0.         0.8293236  0.10185178 0.         0.         0.34091455\n",
      "  0.         0.         0.         0.5685316  0.         0.\n",
      "  1.3870846  0.95850927 0.5556989  0.         0.36172912 0.\n",
      "  0.         0.40780413 0.79611707 0.15538949 0.         0.\n",
      "  0.         0.30270982 1.582669   1.4437064  0.         0.34848723\n",
      "  0.7091574  0.9092907  0.         0.76015615 1.0036236  1.3631258\n",
      "  0.         0.7276066  0.4881185  0.         0.         0.\n",
      "  0.         0.00339134 0.41301167 0.        ]]\n",
      "Hi!\n",
      "[[0.27999592 0.4640728  0.84894186 0.         0.         0.5315868\n",
      "  0.30095935 0.2710113  0.6154234  0.         0.4436388  0.\n",
      "  0.41313663 0.         0.         0.37878036 0.09828494 0.6787238\n",
      "  0.         0.3403891  0.7346508  0.060783   0.         0.10184141\n",
      "  0.01280488 0.         0.         0.         0.         0.\n",
      "  0.1734926  0.29717314 0.         0.         0.10218094 0.\n",
      "  0.         0.612674   0.         0.5688188  0.         0.\n",
      "  0.         0.38304397 0.09919084 0.20405415 0.         0.445906\n",
      "  0.         0.6975015  0.39424542 0.13429356 0.19134562 0.26404\n",
      "  0.         0.         0.         0.         0.00749619 0.\n",
      "  0.         0.79480445 0.4094776  0.46518013]]\n",
      "Hi!\n",
      "[[0.35096523 0.8340364  1.0512297  0.         0.         0.582056\n",
      "  0.11792636 0.2262807  1.0132464  0.         0.62532234 0.\n",
      "  1.4548541  0.         0.         0.74751806 0.         0.7553538\n",
      "  0.7357367  0.347262   0.96722466 0.01530592 0.         0.\n",
      "  0.21551183 0.         0.         0.08848907 0.         0.\n",
      "  0.5884868  0.479365   0.         0.         0.2612726  0.\n",
      "  0.41686168 0.86555856 0.         0.6815773  0.         0.\n",
      "  0.         0.23827964 0.35570094 0.00577569 0.         0.9898265\n",
      "  0.         0.8434157  0.8243149  0.25762135 0.24698795 0.5983516\n",
      "  0.         0.         0.14256266 0.00172895 0.04819667 0.\n",
      "  0.         0.60924315 0.97086716 0.8620305 ]]\n",
      "Hi!\n",
      "[[0.         0.3469806  0.30904803 0.         0.         0.3350556\n",
      "  0.         0.03968293 0.13457859 0.06323668 0.21683007 0.\n",
      "  0.19017524 0.0218145  0.         0.01173077 0.         0.15016596\n",
      "  0.         0.41233307 0.21426752 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05351752 0.09589843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.17638493 0.         0.\n",
      "  0.         0.         0.08060313 0.2823684  0.         0.22772764\n",
      "  0.24765274 0.19120686 0.00460885 0.19269104 0.07371552 0.37012762\n",
      "  0.         0.13996725 0.01894815 0.         0.09344401 0.\n",
      "  0.13868502 0.14683357 0.         0.11278328]]\n",
      "Hi!\n",
      "[[0.04247015 0.27805662 0.3318332  0.         0.         0.23578355\n",
      "  0.         0.         0.07039241 0.0163936  0.23140177 0.\n",
      "  0.13885589 0.10805351 0.         0.04626929 0.         0.05540308\n",
      "  0.         0.35534123 0.17844121 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18161544 0.09362566 0.         0.         0.\n",
      "  0.         0.         0.17362635 0.15306255 0.         0.\n",
      "  0.         0.         0.13892086 0.2561945  0.         0.1884412\n",
      "  0.2772084  0.13018022 0.         0.25489312 0.10467248 0.46391952\n",
      "  0.         0.14861074 0.00950484 0.         0.04512951 0.\n",
      "  0.07090521 0.06747779 0.         0.01160299]]\n",
      "Hi!\n",
      "[[0.65194154 1.2866682  0.7096744  0.         0.         0.39894068\n",
      "  0.00392351 0.60194707 0.9397889  0.         0.5574106  0.\n",
      "  2.4246173  0.66927993 0.         0.83642936 0.         0.6936947\n",
      "  1.3241411  0.52776396 0.7576847  0.06193658 0.         0.23152925\n",
      "  0.3388139  0.         0.         0.659133   0.         0.\n",
      "  1.3003448  0.9948487  0.         0.         0.54233724 0.\n",
      "  0.75338626 1.0207646  0.5446715  0.4428075  0.         0.\n",
      "  0.         0.4552729  1.1546506  0.36421955 0.         1.2792385\n",
      "  0.         0.87359124 1.1272142  0.38303536 0.615801   1.2890048\n",
      "  0.         0.         0.49893934 0.         0.02534849 0.\n",
      "  0.         0.38183224 1.1875658  0.6165811 ]]\n",
      "Hi!\n",
      "[[0.46055168 0.47492257 1.138515   0.         0.         1.1114591\n",
      "  0.11842804 0.5698417  0.47591618 0.         0.48199022 0.\n",
      "  0.82059306 0.         0.         0.13288623 0.         0.3889813\n",
      "  0.         0.6149347  0.8485695  0.         0.         0.11901347\n",
      "  0.         0.         0.         0.03258179 0.         0.\n",
      "  0.55253386 0.6876199  0.         0.         0.03634923 0.\n",
      "  0.         0.5713114  0.         0.47671264 0.         0.\n",
      "  0.         0.03992774 0.52851444 0.58833593 0.         0.71244687\n",
      "  0.34047762 0.8387335  0.3039807  0.62924767 0.81002086 0.7938993\n",
      "  0.         0.7148782  0.         0.         0.03523029 0.\n",
      "  0.         0.2384195  1.0192914  0.2986637 ]]\n",
      "Hi!\n",
      "[[0.50262034 0.61517966 0.5723416  0.         0.         0.50399417\n",
      "  0.39359742 0.5895897  0.54406667 0.         0.4109492  0.\n",
      "  1.1178126  0.2558233  0.         0.498177   0.         0.6373333\n",
      "  0.3208725  0.43120632 0.56025124 0.         0.         0.\n",
      "  0.15583144 0.         0.         0.33101898 0.         0.\n",
      "  0.83692086 0.57623076 0.         0.         0.45105025 0.\n",
      "  0.37651104 0.9302238  0.         0.36429417 0.         0.\n",
      "  0.         0.14572278 0.77370375 0.47047523 0.         0.7750998\n",
      "  0.         0.6341139  0.59697896 0.32245207 0.37251306 0.7003222\n",
      "  0.         0.         0.29999164 0.         0.         0.\n",
      "  0.         0.46640307 0.85501385 0.2387358 ]]\n",
      "Hi!\n",
      "[[0.04463037 0.09220766 0.2602886  0.         0.         0.19178684\n",
      "  0.         0.02529006 0.08314718 0.08214173 0.18799265 0.\n",
      "  0.05843696 0.04047924 0.         0.         0.         0.\n",
      "  0.         0.19463389 0.10812823 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03647362 0.0495558  0.         0.         0.\n",
      "  0.         0.         0.06947965 0.12345112 0.         0.\n",
      "  0.         0.         0.05266091 0.3044098  0.         0.1312685\n",
      "  0.13904817 0.06188716 0.         0.19790551 0.0237805  0.29819772\n",
      "  0.         0.15867499 0.00044594 0.         0.02222221 0.\n",
      "  0.03173979 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.22085117 0.5940591  0.30722785 0.01085694 0.         0.26797563\n",
      "  0.         0.22025107 0.         0.         0.22340313 0.\n",
      "  0.43533412 0.39986032 0.         0.         0.         0.13991174\n",
      "  0.         0.5253513  0.15563239 0.         0.         0.10343832\n",
      "  0.         0.         0.         0.1155097  0.         0.\n",
      "  0.27452856 0.4692597  0.1419563  0.         0.         0.\n",
      "  0.         0.         0.5807001  0.08946816 0.         0.\n",
      "  0.         0.         0.4859334  0.42655516 0.         0.09771843\n",
      "  0.4097426  0.2912018  0.         0.36950615 0.41133332 0.70913815\n",
      "  0.         0.25620404 0.16225299 0.         0.         0.\n",
      "  0.16077214 0.09445774 0.10363018 0.        ]]\n",
      "Hi!\n",
      "[[0.2721197  0.11994141 1.1449285  0.         0.         0.6425902\n",
      "  0.67396075 0.691025   1.4936848  0.         0.62013537 0.\n",
      "  0.93846244 0.         0.         1.0385578  0.10555327 0.9308913\n",
      "  0.87185085 0.         1.124089   0.30702808 0.         0.12500829\n",
      "  0.36442837 0.         0.         0.16643585 0.         0.\n",
      "  0.4754193  0.21416043 0.         0.         0.4945166  0.\n",
      "  0.690466   1.3896827  0.         0.6997362  0.24509399 0.\n",
      "  0.         1.0691353  0.10578869 0.05219116 0.         0.95234245\n",
      "  0.         0.820278   1.0493535  0.17385416 0.11789059 0.18190332\n",
      "  0.         0.         0.23119591 0.5457725  0.         0.\n",
      "  0.         0.949239   1.4016285  0.9624249 ]]\n",
      "Hi!\n",
      "[[0.02224106 0.26996696 0.06519684 0.         0.         0.32530046\n",
      "  0.12209972 0.2811678  0.         0.09156533 0.14601888 0.\n",
      "  0.05645917 0.20185806 0.         0.         0.         0.14946066\n",
      "  0.         0.35404986 0.07906207 0.         0.         0.00793586\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16331166 0.13356264 0.11731959 0.         0.         0.\n",
      "  0.         0.04567579 0.04998807 0.17570275 0.         0.\n",
      "  0.         0.         0.30927315 0.5613987  0.         0.15555319\n",
      "  0.22009306 0.30684152 0.         0.24356388 0.16738263 0.41655326\n",
      "  0.         0.21489374 0.03467355 0.         0.00569327 0.\n",
      "  0.10563382 0.17205982 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.5069033  0.9364538  0.9178027  0.         0.         0.67047155\n",
      "  0.         0.35348025 0.4767582  0.         0.53515506 0.\n",
      "  1.3639268  0.18564944 0.         0.29736865 0.         0.53306484\n",
      "  0.26827896 0.6847301  0.7018471  0.         0.         0.12585004\n",
      "  0.         0.         0.         0.13039541 0.         0.\n",
      "  0.7806599  0.73223805 0.         0.         0.19427502 0.\n",
      "  0.06013916 0.5134635  0.17245045 0.43762955 0.         0.\n",
      "  0.         0.07889611 0.73366874 0.4360612  0.         0.7544853\n",
      "  0.22137931 0.7184736  0.44408646 0.43962705 0.6924192  0.8608613\n",
      "  0.         0.05879685 0.14514355 0.         0.08613713 0.\n",
      "  0.         0.3055374  0.824814   0.39982727]]\n",
      "Hi!\n",
      "[[3.4230825e-01 0.0000000e+00 4.7312742e-01 2.6561028e-01 0.0000000e+00\n",
      "  8.0179882e-01 1.5393453e+00 1.6609627e+00 6.4183891e-01 0.0000000e+00\n",
      "  3.2046977e-01 0.0000000e+00 4.2099348e-01 0.0000000e+00 0.0000000e+00\n",
      "  5.7141739e-01 0.0000000e+00 6.8760502e-01 1.3923853e-02 0.0000000e+00\n",
      "  6.1948776e-01 1.7146729e-01 0.0000000e+00 0.0000000e+00 1.5310384e-01\n",
      "  0.0000000e+00 0.0000000e+00 5.8977407e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.0720654e+00 5.1815420e-01 2.6729755e-04 0.0000000e+00 7.1581036e-01\n",
      "  0.0000000e+00 2.1806875e-01 1.3914894e+00 0.0000000e+00 3.5060194e-01\n",
      "  2.9532543e-01 0.0000000e+00 0.0000000e+00 8.4019005e-01 8.2075292e-01\n",
      "  1.0156945e+00 0.0000000e+00 3.1187612e-01 0.0000000e+00 8.0132228e-01\n",
      "  4.5036522e-01 5.5085069e-01 5.8272624e-01 4.0076223e-01 0.0000000e+00\n",
      "  0.0000000e+00 3.8389733e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 8.1088740e-01 1.4393570e+00 0.0000000e+00]]\n",
      "Hi!\n",
      "[[0.         0.32136595 0.17148033 0.         0.         0.34370384\n",
      "  0.30603123 0.34182218 0.01493789 0.13984402 0.17724621 0.\n",
      "  0.         0.12038506 0.         0.07871581 0.         0.24373288\n",
      "  0.         0.3642378  0.18513043 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00872388 0.07546759 0.12329793 0.         0.         0.\n",
      "  0.         0.         0.06071936 0.29749826 0.         0.\n",
      "  0.         0.         0.20333932 0.5047389  0.         0.\n",
      "  0.20395021 0.43971017 0.         0.16339292 0.34999576 0.30723208\n",
      "  0.         0.12592606 0.00627968 0.         0.00730195 0.\n",
      "  0.16372903 0.38456348 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.70271593 0.         1.3193944  0.         0.         0.801965\n",
      "  0.5328181  0.49393967 0.7626207  0.         0.5629362  0.\n",
      "  0.         0.         0.         0.38678437 0.4490555  0.90097123\n",
      "  0.         0.13956726 1.0225267  0.21487427 0.         0.34960115\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12793818 0.09389605 0.         0.04244632 0.\n",
      "  0.         0.6662415  0.         0.7974627  0.         0.\n",
      "  0.         0.96079457 0.         0.30660257 0.         0.21275753\n",
      "  0.         0.83259755 0.34050372 0.11837333 0.39427856 0.\n",
      "  0.         0.4654236  0.         0.21128315 0.         0.\n",
      "  0.06015969 0.93958944 0.65576214 0.35454014]]\n",
      "Hi!\n",
      "[[0.27953115 0.         0.02043703 0.41550103 0.         0.76342654\n",
      "  1.6026539  1.6604707  0.         0.         0.08910526 0.\n",
      "  0.         0.34850365 0.         0.12036461 0.         0.40713796\n",
      "  0.         0.22628321 0.18250722 0.06710446 0.         0.\n",
      "  0.         0.         0.         0.2254965  0.         0.\n",
      "  0.8501266  0.392349   0.39731517 0.         0.42580765 0.\n",
      "  0.         0.6907207  0.         0.49028212 0.12110385 0.\n",
      "  0.         0.50049496 0.8610658  1.3578916  0.         0.\n",
      "  0.08830471 1.1376215  0.         0.66915464 0.8585595  0.423782\n",
      "  0.         0.47803333 0.03195739 0.         0.         0.\n",
      "  0.         0.7223472  0.45463023 0.        ]]\n",
      "Hi!\n",
      "[[0.06610519 0.6733245  0.647128   0.         0.         0.38347352\n",
      "  0.         0.         0.26845288 0.         0.35110742 0.\n",
      "  0.574022   0.03843088 0.         0.10788827 0.         0.2643995\n",
      "  0.         0.61169624 0.40157488 0.         0.         0.02390268\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18051563 0.22968195 0.         0.         0.         0.\n",
      "  0.         0.         0.12040851 0.24831468 0.         0.\n",
      "  0.         0.         0.16009295 0.11433631 0.         0.38876432\n",
      "  0.37757266 0.35170707 0.12416675 0.2601908  0.15997899 0.5393266\n",
      "  0.         0.07544795 0.02389226 0.         0.13452083 0.\n",
      "  0.19927943 0.25534344 0.11667643 0.27746525]]\n",
      "Hi!\n",
      "[[0.03401126 0.         0.43592423 0.07357127 0.         0.5786656\n",
      "  1.9073064  1.9285839  1.2980044  0.         0.38038725 0.\n",
      "  0.59828156 0.         0.         1.0483736  0.         0.85066426\n",
      "  0.5511401  0.         0.824444   0.30220446 0.         0.\n",
      "  0.41984025 0.         0.         0.636318   0.         0.\n",
      "  1.1209401  0.14518486 0.         0.         0.9728534  0.\n",
      "  0.50452346 1.7472538  0.         0.35154533 0.37578756 0.\n",
      "  0.         1.5650641  0.4849233  0.70887995 0.         0.3566987\n",
      "  0.         0.7210129  0.96977526 0.39848343 0.42747793 0.\n",
      "  0.         0.         0.4020509  0.14674607 0.         0.\n",
      "  0.         1.0862795  1.556168   0.2524765 ]]\n",
      "Hi!\n",
      "[[1.1098073  0.2644302  1.833757   0.         0.         1.1983138\n",
      "  0.14791167 0.2964872  0.7911607  0.04096231 0.6557068  0.\n",
      "  0.         0.         0.         0.20373781 0.8135039  0.7053671\n",
      "  0.         0.41344395 1.2493962  0.22147365 0.         0.66133446\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17081761 0.1263934  0.         0.         0.\n",
      "  0.         0.30680856 0.         0.9873136  0.         0.\n",
      "  0.         1.0620452  0.         0.2739674  0.         0.36526367\n",
      "  0.3491912  1.055256   0.34063312 0.1722522  0.6584977  0.12627645\n",
      "  0.         1.2988852  0.         0.3640668  0.09092161 0.\n",
      "  0.48654318 0.813976   0.60290927 0.5859748 ]]\n",
      "Hi!\n",
      "[[0.20342752 0.03269755 0.5246585  0.         0.         0.33244586\n",
      "  0.99194956 0.9084414  0.8082267  0.         0.4128337  0.\n",
      "  0.12187581 0.         0.         0.62508494 0.         0.78936505\n",
      "  0.         0.         0.640588   0.15107094 0.         0.\n",
      "  0.14790465 0.         0.         0.         0.         0.\n",
      "  0.44619998 0.04448674 0.         0.         0.4888865  0.\n",
      "  0.05719639 1.0621877  0.         0.48171318 0.04385127 0.\n",
      "  0.         0.9144232  0.11574735 0.3560299  0.         0.19974732\n",
      "  0.         0.7547145  0.61727375 0.13044699 0.2488497  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.0272593  0.58443004 0.3124064 ]]\n",
      "Hi!\n",
      "[[0.18373062 0.26466992 0.36619365 0.         0.         0.2838544\n",
      "  0.         0.13736343 0.         0.         0.1336865  0.\n",
      "  0.12393501 0.08690313 0.         0.         0.         0.\n",
      "  0.         0.39367384 0.07764807 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10716874 0.43657663 0.1379942  0.         0.         0.\n",
      "  0.         0.         0.2795053  0.15048529 0.         0.\n",
      "  0.         0.         0.3098656  0.4103833  0.         0.14327323\n",
      "  0.33313215 0.26857868 0.         0.36501557 0.2854642  0.6484251\n",
      "  0.         0.3951854  0.03871684 0.         0.         0.\n",
      "  0.09273354 0.         0.         0.        ]]\n",
      "Hi!\n",
      "[[0.8426537  0.         1.1810646  0.03423465 0.         0.96936893\n",
      "  0.6566235  0.71718013 0.5580738  0.0915226  0.45193362 0.\n",
      "  0.         0.         0.         0.2047619  0.4301375  0.6889814\n",
      "  0.         0.18746664 0.84997237 0.06885292 0.         0.39360264\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17949145 0.13049538 0.         0.         0.\n",
      "  0.         0.514354   0.         0.8421476  0.         0.\n",
      "  0.         0.9071031  0.         0.52180463 0.         0.11586446\n",
      "  0.12473153 0.95887446 0.20948775 0.22602993 0.5868695  0.09405855\n",
      "  0.         0.8752082  0.         0.03325629 0.         0.\n",
      "  0.25033453 0.8844792  0.52082604 0.16262516]]\n",
      "Hi!\n",
      "[[0.49440238 0.7839462  1.4182538  0.         0.         0.9701038\n",
      "  0.         0.         0.32074344 0.01983678 0.51220167 0.\n",
      "  0.6081415  0.         0.         0.         0.3476791  0.29916233\n",
      "  0.         1.0158507  0.7096872  0.         0.         0.13969776\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.49735445 0.08452453 0.         0.         0.\n",
      "  0.         0.         0.09936145 0.61904764 0.         0.\n",
      "  0.         0.         0.30609703 0.17721057 0.         0.8216984\n",
      "  0.77831155 0.61519307 0.14050567 0.58577657 0.61067474 0.9912323\n",
      "  0.         0.9624443  0.         0.         0.20262617 0.\n",
      "  0.29616088 0.15897363 0.52281237 0.38882467]]\n",
      "Hi!\n",
      "[[0.46811783 0.         0.12638637 0.3634021  0.         0.6410339\n",
      "  1.583773   1.69636    0.32745433 0.         0.23818223 0.\n",
      "  0.531475   0.3306338  0.         0.4360011  0.         0.6752697\n",
      "  0.         0.         0.35805503 0.27937266 0.         0.\n",
      "  0.25891286 0.         0.         0.6335748  0.         0.\n",
      "  1.2453921  0.588401   0.08468577 0.         0.839357   0.\n",
      "  0.31336665 1.3468208  0.         0.25208828 0.29158464 0.\n",
      "  0.         0.57451963 1.130083   1.2946471  0.         0.33210316\n",
      "  0.         0.847708   0.44982547 0.5533197  0.58596694 0.7742332\n",
      "  0.         0.         0.5184678  0.         0.         0.\n",
      "  0.         0.6890467  1.1270375  0.        ]]\n",
      "Hi!\n",
      "[[0.44375235 0.         0.7378611  0.         0.         0.7193086\n",
      "  0.84833854 0.90718716 0.6397727  0.         0.39592996 0.\n",
      "  0.12709647 0.         0.         0.43160266 0.00643726 0.69726706\n",
      "  0.         0.         0.7260952  0.         0.         0.19083595\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3959366  0.27400792 0.03283897 0.         0.29443875 0.\n",
      "  0.         0.8788721  0.         0.56304437 0.         0.\n",
      "  0.         0.7207366  0.16039693 0.5587617  0.         0.11927439\n",
      "  0.         0.88888365 0.37359455 0.28536043 0.4423225  0.21304953\n",
      "  0.         0.11136883 0.         0.         0.         0.\n",
      "  0.         0.82683265 0.80119514 0.14166676]]\n",
      "Hi!\n",
      "[[5.99781930e-01 3.22578549e-02 1.38679504e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.77290356e-01 4.46633667e-01 4.50718313e-01\n",
      "  1.27312613e+00 0.00000000e+00 6.45392418e-01 0.00000000e+00\n",
      "  1.49945775e-02 0.00000000e+00 0.00000000e+00 7.42514610e-01\n",
      "  5.84234536e-01 9.39942479e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.22453153e+00 3.93513143e-01 0.00000000e+00 5.03539383e-01\n",
      "  4.04057056e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.43997679e-02 0.00000000e+00 5.81188425e-02 0.00000000e+00\n",
      "  5.73289841e-02 9.38292325e-01 0.00000000e+00 8.21713507e-01\n",
      "  9.60574225e-02 0.00000000e+00 0.00000000e+00 1.20092988e+00\n",
      "  0.00000000e+00 3.31192054e-02 0.00000000e+00 3.89024645e-01\n",
      "  0.00000000e+00 7.16963768e-01 6.72303021e-01 0.00000000e+00\n",
      "  2.14030251e-01 0.00000000e+00 0.00000000e+00 2.71759145e-02\n",
      "  0.00000000e+00 5.63534081e-01 1.62866287e-04 0.00000000e+00\n",
      "  0.00000000e+00 1.14753354e+00 8.88272822e-01 7.71812916e-01]]\n",
      "Hi!\n",
      "[[0.69362694 0.09703085 1.3397142  0.         0.         0.8348308\n",
      "  0.3476662  0.30202702 0.88117933 0.         0.58397865 0.\n",
      "  0.08984166 0.         0.         0.5102598  0.41404372 0.85605884\n",
      "  0.         0.159597   1.0558909  0.17387843 0.         0.29487723\n",
      "  0.00285837 0.         0.         0.         0.         0.\n",
      "  0.         0.20326002 0.03187424 0.         0.05131061 0.\n",
      "  0.04765771 0.7390256  0.         0.8239069  0.         0.\n",
      "  0.         0.7910981  0.         0.15629962 0.         0.62337273\n",
      "  0.         0.68715024 0.4989652  0.1386038  0.22238272 0.24718806\n",
      "  0.         0.2965674  0.         0.38327554 0.00504311 0.\n",
      "  0.         0.8687918  0.75282454 0.6460506 ]]\n",
      "Hi!\n",
      "[[0.54379666 0.20064378 0.22301987 0.28074571 0.         0.6247913\n",
      "  0.95554537 1.4509834  0.36191043 0.         0.28476673 0.\n",
      "  1.1255906  0.65645987 0.         0.43725234 0.         0.49748576\n",
      "  0.31963122 0.13771355 0.4470977  0.09811611 0.         0.043982\n",
      "  0.07540965 0.         0.         0.79231995 0.         0.\n",
      "  1.311302   0.77599174 0.01541995 0.         0.7005572  0.\n",
      "  0.31862685 1.1269875  0.11854964 0.11663227 0.17062706 0.\n",
      "  0.         0.30537972 1.2055418  1.1201525  0.         0.4609938\n",
      "  0.         0.74343485 0.46083862 0.5910457  0.7204732  0.8531178\n",
      "  0.         0.         0.46282786 0.         0.         0.\n",
      "  0.         0.36921358 1.1842266  0.        ]]\n",
      "Hi!\n",
      "[[1.0915977  0.14167587 1.7724148  0.         0.         1.1531597\n",
      "  0.16179298 0.3236645  0.9674034  0.         0.6171292  0.\n",
      "  0.         0.         0.         0.4398425  0.9499532  0.7499125\n",
      "  0.         0.40290686 1.2102228  0.29854298 0.         0.42476943\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19368538 0.05310614 0.         0.         0.\n",
      "  0.         0.5437993  0.         0.9606615  0.         0.\n",
      "  0.         1.1243485  0.         0.3382053  0.         0.6780452\n",
      "  0.266545   0.8640646  0.44607916 0.12811808 0.3980993  0.3780733\n",
      "  0.         1.0336972  0.         0.5453336  0.         0.\n",
      "  0.3230654  0.8443886  0.7322873  0.630294  ]]\n",
      "Hi!\n",
      "[[0.29622185 0.         0.250821   0.23857309 0.         0.54034346\n",
      "  1.397179   1.6441661  0.6453128  0.         0.28634438 0.\n",
      "  0.7076909  0.23327652 0.         0.5981702  0.         0.6553297\n",
      "  0.04425389 0.         0.51297766 0.16788848 0.         0.\n",
      "  0.1735113  0.         0.         0.64819896 0.         0.\n",
      "  1.2866809  0.44664726 0.         0.         0.82923204 0.\n",
      "  0.09160866 1.2740151  0.         0.2791341  0.23524626 0.\n",
      "  0.         0.66973436 0.82655585 1.057528   0.         0.11330803\n",
      "  0.         0.88926864 0.56071264 0.5310174  0.82888097 0.37452006\n",
      "  0.         0.         0.3485631  0.         0.         0.\n",
      "  0.         0.7374683  1.2962629  0.        ]]\n",
      "Hi!\n",
      "[[0.44568977 1.0438029  1.3099029  0.         0.         0.66118866\n",
      "  0.         0.19239393 0.9854395  0.         0.69062525 0.\n",
      "  1.6409628  0.         0.         0.6752027  0.         0.77192104\n",
      "  0.7343681  0.46725282 1.0305876  0.         0.         0.07560882\n",
      "  0.05626848 0.         0.         0.17568019 0.         0.\n",
      "  0.68182766 0.64554137 0.         0.         0.18801223 0.\n",
      "  0.34891492 0.7616715  0.07818603 0.6605602  0.         0.\n",
      "  0.         0.13447054 0.51536506 0.04713344 0.         0.99853957\n",
      "  0.         0.84308094 0.78881025 0.37600976 0.5106914  0.7660597\n",
      "  0.         0.         0.12304518 0.         0.0914102  0.\n",
      "  0.         0.51579326 1.143661   0.8683087 ]]\n",
      "Hi!\n",
      "[[0.         0.03747897 0.07168061 0.         0.         0.\n",
      "  0.19088902 0.29558966 0.03507891 0.14297716 0.09429588 0.\n",
      "  0.         0.01929193 0.         0.14189772 0.         0.05152272\n",
      "  0.         0.         0.16280133 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.12388812 0.         0.         0.\n",
      "  0.         0.         0.06748998 0.07879336 0.         0.\n",
      "  0.         0.         0.14377795 0.331722   0.         0.\n",
      "  0.14493953 0.03272456 0.         0.17362718 0.         0.14412148\n",
      "  0.         0.2485715  0.         0.         0.         0.\n",
      "  0.01996626 0.24060443 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.17802013 0.26628375 0.12762085 0.         0.         0.49651054\n",
      "  0.55275166 0.61560833 0.         0.05527898 0.13110566 0.\n",
      "  0.05372717 0.28336594 0.         0.01093965 0.         0.27666616\n",
      "  0.         0.49754947 0.10056476 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.45637533 0.31867543 0.20326397 0.         0.02392665 0.\n",
      "  0.         0.26061815 0.05151699 0.23843895 0.         0.\n",
      "  0.         0.02293178 0.5819292  0.92369556 0.         0.2040014\n",
      "  0.35344586 0.68753284 0.         0.42222026 0.3597162  0.7145054\n",
      "  0.         0.51066077 0.11838248 0.         0.         0.\n",
      "  0.11519836 0.27714455 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.4296064  0.         0.47643688 0.35209054 0.         0.68764204\n",
      "  1.4747438  1.5232556  0.5034571  0.         0.30981895 0.\n",
      "  0.         0.         0.         0.35656273 0.         0.66228026\n",
      "  0.         0.         0.5573225  0.00654215 0.         0.17260185\n",
      "  0.         0.         0.         0.18119477 0.         0.\n",
      "  0.6579682  0.23348957 0.24160631 0.         0.45436633 0.\n",
      "  0.         0.9393246  0.         0.6361739  0.17329562 0.\n",
      "  0.         1.0179043  0.281252   0.91269135 0.         0.\n",
      "  0.         1.1261277  0.21293665 0.36488837 0.8438931  0.\n",
      "  0.         0.37049568 0.         0.         0.         0.\n",
      "  0.         1.0116968  0.83445317 0.        ]]\n",
      "Hi!\n",
      "[[0.12729488 0.35246155 0.56491446 0.         0.         0.32686985\n",
      "  0.60589516 0.6645001  0.7500159  0.         0.43058774 0.\n",
      "  0.63276345 0.         0.         0.6021972  0.         0.755566\n",
      "  0.12271053 0.0954463  0.6466697  0.01529211 0.         0.\n",
      "  0.19835657 0.         0.         0.08698799 0.         0.\n",
      "  0.56284994 0.28598604 0.         0.         0.4053002  0.\n",
      "  0.17791799 0.9513105  0.         0.46073678 0.         0.\n",
      "  0.         0.53388494 0.29453194 0.36516306 0.         0.4286542\n",
      "  0.         0.69459265 0.6529892  0.14371799 0.30740348 0.22784582\n",
      "  0.         0.         0.09023618 0.         0.         0.\n",
      "  0.         0.8306538  0.57158536 0.38818488]]\n",
      "Hi!\n",
      "[[0.         0.15272479 0.17529267 0.         0.         0.15514429\n",
      "  0.         0.08937442 0.0285102  0.10248832 0.16480525 0.\n",
      "  0.01070071 0.03930984 0.         0.02906653 0.         0.08288135\n",
      "  0.         0.21384592 0.10439961 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06095722 0.0711857  0.         0.         0.\n",
      "  0.         0.         0.06134332 0.09556039 0.         0.\n",
      "  0.         0.         0.06145376 0.29134429 0.         0.04735791\n",
      "  0.16167517 0.13857624 0.         0.18122895 0.08374655 0.24858525\n",
      "  0.         0.09545603 0.         0.         0.03180094 0.\n",
      "  0.08946173 0.16506118 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.         0.08447295 0.15087764 0.         0.         0.16954494\n",
      "  0.0008505  0.11105476 0.06298453 0.1381025  0.15788482 0.\n",
      "  0.         0.01201659 0.         0.         0.         0.01352103\n",
      "  0.         0.21406758 0.09557828 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07610038 0.         0.         0.\n",
      "  0.         0.         0.0146258  0.16586927 0.         0.\n",
      "  0.         0.         0.04006589 0.3521027  0.         0.11194948\n",
      "  0.1363644  0.13605316 0.         0.18317598 0.09259744 0.27710152\n",
      "  0.         0.08820918 0.         0.         0.         0.\n",
      "  0.         0.11984095 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.37304989 0.31951606 0.6824815  0.         0.         0.61290926\n",
      "  0.59877455 0.9671603  0.66702497 0.         0.44859296 0.\n",
      "  0.8669876  0.         0.         0.4833655  0.         0.60250205\n",
      "  0.21527387 0.15882349 0.6833661  0.         0.         0.\n",
      "  0.         0.         0.         0.39735347 0.         0.\n",
      "  0.9039418  0.571953   0.         0.         0.49617246 0.\n",
      "  0.1781699  0.9729085  0.         0.32707554 0.04797861 0.\n",
      "  0.         0.39733076 0.6258815  0.653733   0.         0.42952597\n",
      "  0.         0.760266   0.50748557 0.42096382 0.658495   0.4421604\n",
      "  0.         0.         0.22600032 0.         0.         0.\n",
      "  0.         0.63436    1.1459041  0.17662036]]\n",
      "Hi!\n",
      "[[0.7506314  1.2373583  0.65450144 0.         0.         0.50402445\n",
      "  0.         0.60081846 0.49609488 0.         0.48501006 0.\n",
      "  2.0845504  0.68472457 0.         0.49111527 0.         0.5583258\n",
      "  0.7784822  0.69747925 0.5894781  0.02411941 0.         0.2748956\n",
      "  0.02310498 0.         0.         0.6233181  0.         0.\n",
      "  1.2250881  1.0512623  0.         0.         0.45862147 0.\n",
      "  0.46778503 0.69927466 0.6984238  0.35926193 0.         0.\n",
      "  0.         0.3815931  1.287986   0.58663005 0.         0.984782\n",
      "  0.10701601 0.74501246 0.7339595  0.49275    0.7251327  1.393986\n",
      "  0.         0.         0.43843254 0.         0.02509135 0.\n",
      "  0.         0.19272695 0.9945458  0.2932425 ]]\n",
      "Hi!\n",
      "[[0.04890566 0.3035631  0.18547015 0.         0.         0.08126868\n",
      "  0.         0.06875649 0.00962296 0.         0.10477009 0.\n",
      "  0.27829266 0.16267823 0.         0.03205311 0.         0.04349463\n",
      "  0.         0.1920111  0.11621182 0.         0.         0.\n",
      "  0.         0.         0.         0.00411173 0.         0.\n",
      "  0.0792271  0.21146522 0.0806603  0.         0.         0.\n",
      "  0.         0.         0.21233746 0.05724754 0.         0.\n",
      "  0.         0.         0.2182932  0.19347197 0.         0.09211566\n",
      "  0.15062569 0.13561122 0.00502006 0.22324127 0.07629552 0.423641\n",
      "  0.         0.00114928 0.08050374 0.         0.         0.\n",
      "  0.06912148 0.14143245 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.69750756 0.42834806 1.1854861  0.         0.         0.9090896\n",
      "  0.         0.127761   0.17877838 0.15206799 0.44307482 0.\n",
      "  0.         0.         0.         0.05715075 0.26466587 0.42492884\n",
      "  0.         0.7811433  0.6840683  0.         0.         0.24663629\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.36018807 0.08499546 0.         0.         0.\n",
      "  0.         0.11107081 0.         0.6247149  0.         0.\n",
      "  0.         0.10945026 0.18086916 0.5531992  0.         0.37227294\n",
      "  0.5775288  0.75483876 0.00532546 0.36961064 0.60985386 0.50219184\n",
      "  0.         1.1240404  0.         0.         0.14456536 0.\n",
      "  0.44553694 0.41007322 0.26922673 0.22136244]]\n",
      "Hi!\n",
      "[[0.39530274 0.         0.         0.36255214 0.         0.57785016\n",
      "  1.678533   1.7283422  0.28497103 0.         0.16870338 0.\n",
      "  0.44078663 0.35029107 0.         0.4269223  0.         0.6692065\n",
      "  0.         0.         0.28054333 0.2538931  0.         0.\n",
      "  0.31981608 0.         0.         0.60407835 0.         0.\n",
      "  1.1809523  0.5082908  0.17289403 0.         0.8521382  0.\n",
      "  0.32696563 1.3741177  0.         0.2693706  0.2575975  0.\n",
      "  0.         0.59869367 1.0783708  1.2798994  0.         0.31180367\n",
      "  0.         0.8082347  0.4104556  0.5642369  0.51035136 0.7342198\n",
      "  0.         0.         0.43445665 0.         0.         0.\n",
      "  0.         0.7116146  0.9913998  0.        ]]\n",
      "Hi!\n",
      "[[0.329805   0.17998187 0.10950873 0.1978188  0.         0.53707665\n",
      "  1.0446478  1.2532171  0.02107635 0.         0.2104707  0.\n",
      "  0.29437396 0.4930119  0.         0.1281179  0.         0.44433182\n",
      "  0.         0.27505237 0.21518464 0.         0.         0.\n",
      "  0.         0.         0.         0.3517676  0.         0.\n",
      "  0.9682779  0.5449789  0.16283347 0.         0.42041028 0.\n",
      "  0.         0.777565   0.         0.31259975 0.03385959 0.\n",
      "  0.         0.21449362 0.85183    1.1193175  0.         0.\n",
      "  0.0262549  0.9890453  0.19024448 0.508828   0.7832864  0.5307703\n",
      "  0.         0.11017846 0.07977448 0.         0.         0.\n",
      "  0.         0.5692116  0.38738722 0.        ]]\n",
      "Hi!\n",
      "[[0.84323025 0.4661874  0.11863811 0.5667881  0.         0.6003831\n",
      "  0.8230442  1.5835049  0.00525516 0.         0.21558127 0.\n",
      "  1.2722235  0.9881717  0.         0.16718632 0.         0.3326436\n",
      "  0.06292792 0.49123955 0.31856614 0.20531975 0.         0.24388248\n",
      "  0.         0.         0.         0.9785682  0.         0.\n",
      "  1.7049459  1.0441046  0.25296193 0.         0.7403732  0.\n",
      "  0.11699235 0.86622614 0.77527654 0.09751064 0.28145793 0.\n",
      "  0.         0.4407043  1.6616775  1.3847505  0.         0.35168177\n",
      "  0.16212448 0.92034906 0.2566329  0.7425664  1.148529   1.2564871\n",
      "  0.         0.26151913 0.61723727 0.         0.         0.\n",
      "  0.         0.2680733  1.155572   0.        ]]\n",
      "Hi!\n",
      "[[0.19885245 0.6150989  0.33886257 0.         0.         0.45514813\n",
      "  0.08376133 0.42418748 0.00775032 0.00529863 0.25669143 0.\n",
      "  0.43246907 0.36592278 0.         0.         0.         0.284757\n",
      "  0.         0.6646993  0.26011932 0.         0.         0.11504247\n",
      "  0.         0.         0.         0.00483272 0.         0.\n",
      "  0.46886188 0.3910364  0.05993795 0.         0.         0.\n",
      "  0.         0.03312352 0.19721648 0.22768736 0.         0.\n",
      "  0.         0.         0.5351764  0.7317574  0.         0.2667484\n",
      "  0.3782271  0.605431   0.05355389 0.37335128 0.5176563  0.65791094\n",
      "  0.         0.21075456 0.10488643 0.         0.0575605  0.\n",
      "  0.04250183 0.2870994  0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0489521  0.5036149  1.8098185  0.         0.         1.3937523\n",
      "  0.09052457 0.30869445 0.5347063  0.13207147 0.6405256  0.\n",
      "  0.06432657 0.         0.         0.03400123 0.52107704 0.50784516\n",
      "  0.         0.73486245 1.2162462  0.         0.         0.59155446\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40563515 0.15176357 0.         0.         0.\n",
      "  0.         0.25239506 0.         0.8104005  0.         0.\n",
      "  0.         0.47109076 0.         0.48150006 0.         0.51760167\n",
      "  0.5939589  1.0956489  0.17991303 0.44654688 0.9614953  0.5382578\n",
      "  0.         1.5300006  0.         0.0394376  0.10606902 0.\n",
      "  0.35805395 0.5122686  0.76627874 0.44729596]]\n",
      "Hi!\n",
      "[[1.0109122  0.19697718 1.5820452  0.         0.         1.1554172\n",
      "  0.16339028 0.32811567 0.5912612  0.10256824 0.5606231  0.\n",
      "  0.         0.         0.         0.14227262 0.6799522  0.6705119\n",
      "  0.         0.48840046 1.064279   0.10593373 0.         0.5079417\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16687329 0.13958117 0.         0.         0.\n",
      "  0.         0.28974617 0.         0.876748   0.         0.\n",
      "  0.         0.8705082  0.         0.35499576 0.         0.32051188\n",
      "  0.36699402 1.0255394  0.2211875  0.23299056 0.59085536 0.17426664\n",
      "  0.         1.2224144  0.         0.21038751 0.08637473 0.\n",
      "  0.5068407  0.7427519  0.47151175 0.4138453 ]]\n",
      "Hi!\n",
      "[[0.29480198 0.1096575  0.8370716  0.         0.         0.7105972\n",
      "  0.82189137 1.121489   1.1637686  0.         0.4994348  0.\n",
      "  1.0002216  0.         0.         0.7825297  0.         0.7483322\n",
      "  0.60194045 0.         0.90948576 0.         0.         0.05433448\n",
      "  0.16191791 0.         0.         0.48942962 0.         0.\n",
      "  0.89027435 0.45264676 0.         0.         0.5260633  0.\n",
      "  0.3688139  1.2957939  0.         0.41836914 0.2035782  0.\n",
      "  0.         0.775341   0.376931   0.5405466  0.         0.61100495\n",
      "  0.         0.7214201  0.8613693  0.40574956 0.5525775  0.3047024\n",
      "  0.         0.         0.27027723 0.0400122  0.         0.\n",
      "  0.         0.7306783  1.4922962  0.5329975 ]]\n",
      "Hi!\n",
      "[[0.46979743 0.25300175 1.2747383  0.         0.         0.71951544\n",
      "  0.3544247  0.43309277 1.2395904  0.         0.6539011  0.\n",
      "  0.6257633  0.         0.         0.7873272  0.25417194 0.86153316\n",
      "  0.28713763 0.         1.1275828  0.2158237  0.         0.306612\n",
      "  0.08733286 0.         0.         0.         0.         0.\n",
      "  0.19553503 0.24350986 0.         0.         0.17011668 0.\n",
      "  0.24341679 0.9926508  0.         0.7855408  0.11127466 0.\n",
      "  0.         0.88762414 0.         0.09345338 0.         0.72227925\n",
      "  0.         0.7636544  0.79032606 0.20180237 0.29093874 0.18783537\n",
      "  0.         0.         0.         0.44425383 0.         0.\n",
      "  0.         0.9177908  1.065403   0.82325816]]\n",
      "Hi!\n",
      "[[0.42906865 0.         0.6181764  0.10292426 0.         0.6604013\n",
      "  1.3392081  1.0630932  0.5134084  0.         0.34519398 0.\n",
      "  0.         0.         0.         0.37672654 0.         0.80274826\n",
      "  0.         0.         0.6477604  0.03577534 0.         0.\n",
      "  0.08146554 0.         0.         0.02080655 0.         0.\n",
      "  0.4341988  0.19546862 0.04034127 0.         0.4908568  0.\n",
      "  0.         1.0477787  0.         0.49627775 0.08663583 0.\n",
      "  0.         0.8521705  0.31449685 0.6824832  0.         0.21514884\n",
      "  0.         0.7503918  0.32665157 0.2531318  0.3073624  0.14724216\n",
      "  0.         0.05899397 0.04377413 0.         0.         0.\n",
      "  0.         0.93007463 0.7185711  0.02674394]]\n",
      "Hi!\n",
      "[[0.6320005  0.         1.0235058  0.1743263  0.         0.9629614\n",
      "  1.0978379  1.2976115  0.74469143 0.         0.41606447 0.\n",
      "  0.         0.         0.         0.43472722 0.14207302 0.63981503\n",
      "  0.         0.         0.9373494  0.         0.         0.38393292\n",
      "  0.         0.         0.         0.04489442 0.         0.\n",
      "  0.424528   0.38115653 0.1448845  0.         0.26672179 0.\n",
      "  0.         0.9767412  0.         0.63969547 0.06910362 0.\n",
      "  0.         0.97244555 0.20233493 0.7038704  0.         0.11369654\n",
      "  0.         0.96040314 0.32248917 0.4931199  0.7666215  0.15735689\n",
      "  0.         0.6335435  0.         0.         0.         0.\n",
      "  0.         0.9018181  1.2645634  0.03773817]]\n",
      "Hi!\n",
      "[[1.0746815  0.         1.8454117  0.         0.         0.9550441\n",
      "  0.45544866 0.66462445 1.3447092  0.         0.7032956  0.\n",
      "  0.         0.         0.         0.6966485  0.90892273 0.89051974\n",
      "  0.         0.         1.4878042  0.45608953 0.         0.8525504\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09933238 0.11146723 0.         0.         0.\n",
      "  0.         0.8723387  0.         0.9897764  0.09339762 0.\n",
      "  0.         1.4857587  0.         0.11642426 0.         0.30058995\n",
      "  0.         1.0097713  0.6246238  0.09239867 0.5629741  0.\n",
      "  0.         0.8049882  0.         0.70245516 0.         0.\n",
      "  0.         1.0914773  1.1404366  0.7501983 ]]\n",
      "Hi!\n",
      "[[0.00633548 0.12927204 0.0758834  0.02559326 0.         0.01240663\n",
      "  0.06909701 0.19640645 0.         0.         0.         0.\n",
      "  0.20281687 0.25493804 0.         0.         0.         0.03195371\n",
      "  0.         0.03306014 0.07018702 0.         0.         0.\n",
      "  0.         0.         0.         0.01623875 0.         0.\n",
      "  0.11367404 0.21106337 0.2530096  0.         0.         0.\n",
      "  0.         0.         0.29706776 0.         0.         0.\n",
      "  0.         0.         0.2986142  0.27843866 0.         0.\n",
      "  0.12213568 0.094743   0.         0.17416136 0.0639027  0.40458086\n",
      "  0.         0.0500099  0.13677879 0.         0.         0.\n",
      "  0.01701803 0.08333226 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.93986183 0.         1.0979518  0.48044583 0.         1.2235717\n",
      "  1.4318441  1.4401606  0.41933239 0.08712208 0.37594548 0.\n",
      "  0.         0.         0.         0.20720437 0.42313558 0.73832667\n",
      "  0.         0.         0.82177323 0.06945942 0.         0.5601926\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06414439 0.2724072  0.36644405 0.         0.         0.\n",
      "  0.         0.5611329  0.         1.0303653  0.15143679 0.\n",
      "  0.         1.4025934  0.         0.8969257  0.         0.\n",
      "  0.07451487 1.3219428  0.         0.471452   1.1085129  0.\n",
      "  0.         1.4355417  0.         0.         0.         0.\n",
      "  0.274959   1.0245107  0.8137618  0.        ]]\n",
      "Hi!\n",
      "[[0.20031956 0.15379435 0.06857624 0.16222821 0.         0.2772508\n",
      "  0.3029606  0.4761553  0.         0.         0.         0.\n",
      "  0.27725473 0.40402934 0.         0.         0.         0.07385422\n",
      "  0.         0.22343098 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23940513 0.         0.\n",
      "  0.42193547 0.5102651  0.3341219  0.         0.         0.\n",
      "  0.         0.07365642 0.5028041  0.         0.         0.\n",
      "  0.         0.1623977  0.6037749  0.60559624 0.         0.12047738\n",
      "  0.36493766 0.38356197 0.         0.37848616 0.20840086 0.8563475\n",
      "  0.         0.44621173 0.23184368 0.         0.         0.\n",
      "  0.08053917 0.27970526 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.71915567 0.16914138 1.6977726  0.         0.         0.87980896\n",
      "  0.27494952 0.30588746 1.3029016  0.         0.75298935 0.\n",
      "  0.5087621  0.         0.         0.7930857  0.5787573  0.92502403\n",
      "  0.15750451 0.         1.3765842  0.23524472 0.         0.5152997\n",
      "  0.03931037 0.         0.         0.         0.         0.\n",
      "  0.         0.27392617 0.         0.         0.         0.\n",
      "  0.24616341 0.93143    0.         0.9082869  0.09960397 0.\n",
      "  0.         1.0337415  0.         0.01069972 0.         0.77206576\n",
      "  0.         0.8879644  0.74216115 0.18586598 0.38913202 0.16825701\n",
      "  0.         0.33742428 0.         0.6503303  0.04251186 0.\n",
      "  0.         0.95194644 1.1729609  0.93496466]]\n",
      "Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2108232  0.35561597 0.7657598  0.         0.         0.42215064\n",
      "  0.5057747  0.7285031  1.0964463  0.         0.52043504 0.\n",
      "  0.91872704 0.         0.         0.8184031  0.         0.73172045\n",
      "  0.48199928 0.         0.7632802  0.01951101 0.         0.00318541\n",
      "  0.17989437 0.         0.         0.15831453 0.         0.\n",
      "  0.6322853  0.31025288 0.         0.         0.47018027 0.\n",
      "  0.45991644 1.067328   0.         0.46126512 0.1350796  0.\n",
      "  0.         0.688946   0.26548892 0.2487555  0.         0.6453607\n",
      "  0.         0.7173585  0.7980038  0.22553328 0.2559092  0.33278102\n",
      "  0.         0.         0.27384272 0.04413646 0.         0.\n",
      "  0.         0.8332793  1.0546395  0.5368722 ]]\n",
      "Hi!\n",
      "[[0.51554114 0.63638467 0.69234926 0.         0.         0.5987221\n",
      "  0.3287888  0.9284541  0.8664464  0.         0.49139714 0.\n",
      "  1.652457   0.25701457 0.         0.64594066 0.         0.5988909\n",
      "  0.8654476  0.19792624 0.7637645  0.         0.         0.07314169\n",
      "  0.1628667  0.         0.         0.57582253 0.         0.\n",
      "  1.1139319  0.74550045 0.         0.         0.5422891  0.\n",
      "  0.48363677 1.0605717  0.04513468 0.27461055 0.07135988 0.\n",
      "  0.         0.3049404  0.8862514  0.53705907 0.         0.85425085\n",
      "  0.         0.73670727 0.8743564  0.5043009  0.6299823  0.8569205\n",
      "  0.         0.         0.39972106 0.         0.         0.\n",
      "  0.         0.37801737 1.3374285  0.4576026 ]]\n",
      "Hi!\n",
      "[[0.06801628 0.4371774  0.50361407 0.         0.         0.41330844\n",
      "  0.         0.01713064 0.06861104 0.02940513 0.2880731  0.\n",
      "  0.17609678 0.06647932 0.         0.         0.         0.10649766\n",
      "  0.         0.54979485 0.23116286 0.         0.         0.0061656\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20882098 0.00730532 0.         0.         0.\n",
      "  0.         0.         0.16125195 0.2412863  0.         0.\n",
      "  0.         0.         0.14272118 0.3469969  0.         0.25968254\n",
      "  0.408595   0.2366197  0.         0.3308317  0.26126567 0.511467\n",
      "  0.         0.3226815  0.         0.         0.09671874 0.\n",
      "  0.15466718 0.07054918 0.035563   0.10171106]]\n",
      "Hi!\n",
      "[[0.8667253  0.         1.7771173  0.         0.         0.9672659\n",
      "  0.6582265  0.6939384  1.3451139  0.         0.69181925 0.\n",
      "  0.14771049 0.         0.         0.7755936  0.7281933  0.95293087\n",
      "  0.22044364 0.         1.4205488  0.41154316 0.         0.48822832\n",
      "  0.12335686 0.         0.         0.         0.         0.\n",
      "  0.         0.23957138 0.02266125 0.         0.07809935 0.\n",
      "  0.3869514  1.2072188  0.         0.87725776 0.09793787 0.\n",
      "  0.         1.3695296  0.         0.11210629 0.         0.87566984\n",
      "  0.         0.73859596 0.6525509  0.05233877 0.2727281  0.13363802\n",
      "  0.         0.34424973 0.03258591 0.76964813 0.         0.\n",
      "  0.         1.1184852  1.4511364  0.8253377 ]]\n",
      "Hi!\n",
      "[[0.6854897  0.         1.1098069  0.         0.         0.6519197\n",
      "  1.1943839  1.187147   1.2284032  0.         0.53112006 0.\n",
      "  0.         0.         0.         0.8011685  0.42444068 0.8774808\n",
      "  0.         0.         1.0944983  0.37518114 0.         0.5087931\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18335444 0.06933241 0.05716963 0.         0.27106026 0.\n",
      "  0.01296752 1.1996652  0.         0.73635507 0.15229891 0.\n",
      "  0.         1.5003083  0.         0.36389267 0.         0.18239562\n",
      "  0.         0.8465045  0.63448477 0.140002   0.4247657  0.\n",
      "  0.         0.1254433  0.         0.40565807 0.         0.\n",
      "  0.         1.2675604  1.1666683  0.4168481 ]]\n",
      "Hi!\n",
      "[[0.08447041 0.1657159  0.20621805 0.01178608 0.         0.21074665\n",
      "  0.         0.14690481 0.         0.01468122 0.08342755 0.\n",
      "  0.14656502 0.22650412 0.         0.         0.         0.01874554\n",
      "  0.         0.21592169 0.04158767 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10954513 0.27282083 0.19370654 0.         0.         0.\n",
      "  0.         0.         0.23294441 0.06290916 0.         0.\n",
      "  0.         0.         0.28303766 0.37039465 0.         0.14610079\n",
      "  0.25521898 0.14841726 0.         0.28507552 0.07104095 0.5758821\n",
      "  0.         0.23081337 0.106659   0.         0.         0.\n",
      "  0.0705451  0.08481015 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.61895597 0.         0.48447236 0.28351563 0.         0.9510448\n",
      "  1.3061091  1.2275467  0.08231597 0.10583664 0.23989648 0.\n",
      "  0.         0.         0.         0.20013502 0.         0.5623615\n",
      "  0.         0.20440443 0.3960086  0.         0.         0.16275978\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2553287  0.20417055 0.2880348  0.         0.16414878 0.\n",
      "  0.         0.50349236 0.         0.7709625  0.07281213 0.\n",
      "  0.         0.82419777 0.29776248 0.956645   0.         0.\n",
      "  0.14455445 1.1148869  0.         0.4443129  0.73126364 0.18429804\n",
      "  0.         0.8441658  0.         0.         0.         0.\n",
      "  0.23568006 0.9074881  0.2884917  0.        ]]\n",
      "Hi!\n",
      "[[0.1647805  0.7098728  0.6712754  0.         0.         0.62975365\n",
      "  0.27437428 0.32674178 0.46795946 0.         0.4211286  0.\n",
      "  0.6716064  0.         0.         0.2151749  0.         0.4587252\n",
      "  0.         0.5474616  0.56395185 0.         0.         0.21243936\n",
      "  0.         0.         0.         0.03266053 0.         0.\n",
      "  0.34245825 0.29864353 0.         0.         0.         0.\n",
      "  0.         0.20276847 0.         0.38105276 0.         0.\n",
      "  0.         0.04496571 0.13111502 0.48834538 0.         0.3053992\n",
      "  0.0796807  0.8360271  0.37937832 0.24368311 0.584872   0.3521803\n",
      "  0.         0.         0.         0.         0.01819526 0.\n",
      "  0.         0.6254863  0.23296301 0.2629389 ]]\n",
      "Hi!\n",
      "[[0.09685676 0.         0.48105118 0.1877718  0.         0.5576911\n",
      "  1.4924173  1.6924946  0.972433   0.         0.33616745 0.\n",
      "  0.58463687 0.         0.         0.6778427  0.         0.70652354\n",
      "  0.         0.         0.7824727  0.         0.         0.1205717\n",
      "  0.         0.         0.         0.6220418  0.         0.\n",
      "  1.0900155  0.2638279  0.06686302 0.         0.64968264 0.\n",
      "  0.         1.2845956  0.         0.43615407 0.1695023  0.\n",
      "  0.         1.112036   0.3190979  0.7851016  0.         0.\n",
      "  0.         0.9629357  0.69224185 0.4554862  0.8600909  0.\n",
      "  0.         0.         0.02012095 0.         0.         0.\n",
      "  0.         0.93612486 1.357407   0.09687966]]\n",
      "Hi!\n",
      "[[0.34848297 0.32498893 0.09604084 0.06701301 0.         0.44983414\n",
      "  0.96041703 1.2775569  0.37404424 0.         0.26231351 0.\n",
      "  0.9728347  0.5480142  0.         0.45015815 0.         0.5162554\n",
      "  0.         0.1661872  0.3865934  0.         0.         0.\n",
      "  0.11065193 0.         0.         0.5618856  0.         0.\n",
      "  1.1898075  0.542824   0.         0.         0.61523837 0.\n",
      "  0.10695232 1.050934   0.         0.23525694 0.06441042 0.\n",
      "  0.         0.2992162  0.94257265 0.9201684  0.         0.24225971\n",
      "  0.         0.87620264 0.56256944 0.46025336 0.63651145 0.64684916\n",
      "  0.         0.         0.2943738  0.         0.         0.\n",
      "  0.         0.5316971  0.7199834  0.        ]]\n",
      "Hi!\n",
      "[[0.7546432  0.0581279  1.5715712  0.         0.         0.8588005\n",
      "  0.47431725 0.66681206 1.4156582  0.         0.69124305 0.\n",
      "  0.43892223 0.         0.         0.8171807  0.51168555 0.9003682\n",
      "  0.31178373 0.         1.3885037  0.3272799  0.         0.65583324\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18322235 0.23983344 0.         0.         0.10052747 0.\n",
      "  0.14780825 1.112572   0.         0.8527925  0.2506744  0.\n",
      "  0.         1.2131302  0.         0.171134   0.         0.6252547\n",
      "  0.         0.84442514 0.76232547 0.12033243 0.34859547 0.07912221\n",
      "  0.         0.26028565 0.         0.600151   0.         0.\n",
      "  0.         1.0132952  1.3704748  0.85567224]]\n",
      "Hi!\n",
      "[[0.31380063 0.12069774 1.101638   0.         0.         0.56607455\n",
      "  0.64855385 0.7008325  1.4573413  0.         0.6344195  0.\n",
      "  0.6997918  0.         0.         0.9841338  0.16030034 0.9064376\n",
      "  0.5396228  0.         1.0848799  0.2925621  0.         0.2569545\n",
      "  0.1933284  0.         0.         0.06842967 0.         0.\n",
      "  0.40155128 0.16513203 0.         0.         0.38240325 0.\n",
      "  0.46305004 1.253313   0.         0.7136365  0.22728747 0.\n",
      "  0.         1.0898391  0.         0.08355852 0.         0.6701948\n",
      "  0.         0.78866684 0.9657173  0.1590372  0.26993167 0.\n",
      "  0.         0.         0.05777575 0.47072226 0.         0.\n",
      "  0.         1.0495617  1.2552651  0.8693542 ]]\n",
      "Hi!\n",
      "[[0.97751397 0.3032893  1.7206154  0.         0.         1.0272083\n",
      "  0.17582731 0.10067488 0.7749389  0.08996631 0.6566678  0.\n",
      "  0.         0.         0.         0.21912393 0.7562199  0.7769569\n",
      "  0.         0.44604364 1.1830416  0.15818521 0.         0.50480235\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03687475 0.13841756 0.         0.         0.\n",
      "  0.         0.3001315  0.         0.92011744 0.         0.\n",
      "  0.         0.8415345  0.         0.27079687 0.         0.37608394\n",
      "  0.31382814 0.9469111  0.31604505 0.13950685 0.51526654 0.03682816\n",
      "  0.         0.954473   0.         0.40615952 0.17945874 0.\n",
      "  0.41316053 0.83962095 0.49826097 0.6100799 ]]\n",
      "Hi!\n",
      "[[0.25498918 0.74009275 1.2429088  0.         0.         0.55290306\n",
      "  0.12288161 0.03763613 1.0803564  0.         0.6346242  0.\n",
      "  1.0519094  0.         0.         0.7420442  0.20829523 0.85837305\n",
      "  0.442664   0.35300323 1.08978    0.18975282 0.         0.07771485\n",
      "  0.15704726 0.         0.         0.         0.         0.\n",
      "  0.24564733 0.30771494 0.         0.         0.20251748 0.\n",
      "  0.23601115 0.90183794 0.         0.7150459  0.00775919 0.\n",
      "  0.         0.34510717 0.09751988 0.         0.         0.9389385\n",
      "  0.         0.8314095  0.77285725 0.12918991 0.1586117  0.35807604\n",
      "  0.         0.         0.00421254 0.26317075 0.10488702 0.\n",
      "  0.         0.8002906  0.92689335 0.93716407]]\n",
      "Hi!\n",
      "[[1.1246675  0.         1.5679252  0.22738443 0.         1.2216015\n",
      "  0.6845331  0.97506404 0.8534306  0.06838033 0.5269579  0.\n",
      "  0.         0.         0.         0.24933013 0.6643627  0.6704955\n",
      "  0.         0.0449978  1.1619726  0.1511895  0.         0.7911836\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23202766 0.27369982 0.         0.         0.\n",
      "  0.         0.544527   0.         1.028053   0.         0.\n",
      "  0.         1.2488635  0.         0.5587822  0.         0.03381409\n",
      "  0.09272926 1.3054911  0.28975335 0.37314785 0.9879959  0.\n",
      "  0.         1.3602309  0.         0.1923934  0.         0.\n",
      "  0.11437494 0.9501243  0.9684745  0.25517774]]\n",
      "Hi!\n",
      "[[0.34866026 0.         0.         0.6205139  0.         0.6346471\n",
      "  2.210132   2.1661224  0.01709407 0.         0.07526248 0.\n",
      "  0.         0.31911394 0.         0.28045878 0.         0.5619282\n",
      "  0.         0.         0.18397866 0.29623    0.         0.\n",
      "  0.0218671  0.         0.         0.65709984 0.         0.\n",
      "  1.2713969  0.41537052 0.4816091  0.         0.8074493  0.\n",
      "  0.         1.1794497  0.         0.43661252 0.35736552 0.\n",
      "  0.         0.8466099  1.1068531  1.4522539  0.         0.\n",
      "  0.         1.1062391  0.08258924 0.6670483  0.8781795  0.34676692\n",
      "  0.         0.22365688 0.21400051 0.         0.         0.\n",
      "  0.         0.8078218  0.87503165 0.        ]]\n",
      "Hi!\n",
      "[[0.7696928  0.         1.15312    0.3058122  0.         0.9225889\n",
      "  1.2607808  1.3844634  0.93458086 0.         0.43502554 0.\n",
      "  0.         0.         0.         0.4134887  0.45818865 0.7241193\n",
      "  0.         0.         1.0325222  0.28019378 0.         0.6890369\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15345387 0.16519967 0.299437   0.         0.08167789 0.\n",
      "  0.         0.85722494 0.         0.8841821  0.09524143 0.\n",
      "  0.         1.4819113  0.         0.5819626  0.         0.\n",
      "  0.         1.0922345  0.34788662 0.29826915 0.81900024 0.\n",
      "  0.         0.8456596  0.         0.08885726 0.         0.\n",
      "  0.         1.120529   1.0749077  0.        ]]\n",
      "Hi!\n",
      "[[0.40992424 0.         0.35729504 0.17280395 0.         0.6752138\n",
      "  1.216586   1.4510332  0.6765956  0.         0.3419454  0.\n",
      "  1.0195005  0.33177406 0.         0.64074636 0.         0.6679365\n",
      "  0.51131856 0.         0.5698665  0.15900579 0.         0.\n",
      "  0.30727553 0.         0.         0.7056101  0.         0.\n",
      "  1.2131113  0.5984233  0.         0.         0.8356026  0.\n",
      "  0.42788535 1.3843548  0.         0.1836322  0.22415742 0.\n",
      "  0.         0.5607402  1.0171157  0.9284036  0.         0.6227988\n",
      "  0.         0.6984584  0.68244964 0.55076456 0.5724289  0.6652755\n",
      "  0.         0.         0.49500734 0.         0.         0.\n",
      "  0.         0.5900791  1.3864037  0.05537538]]\n",
      "Hi!\n",
      "[[0.05214553 0.24538313 0.13263878 0.         0.         0.15174328\n",
      "  0.         0.05891733 0.03090689 0.05053785 0.18281895 0.\n",
      "  0.22342594 0.17413427 0.         0.         0.         0.04271867\n",
      "  0.         0.19411382 0.11005661 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07538464 0.15032564 0.0720749  0.         0.         0.\n",
      "  0.         0.         0.15092841 0.06024537 0.         0.\n",
      "  0.         0.         0.1807662  0.23864809 0.         0.07300692\n",
      "  0.14894202 0.13195994 0.0087447  0.18003055 0.07377765 0.42474452\n",
      "  0.         0.         0.06656528 0.         0.00529208 0.\n",
      "  0.06780439 0.10407682 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.00732278 0.0685844  0.26126277 0.         0.         0.16973078\n",
      "  0.         0.         0.13859652 0.15409479 0.23153749 0.\n",
      "  0.         0.         0.         0.07006302 0.         0.0122284\n",
      "  0.         0.20910269 0.20109135 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05217635 0.         0.         0.\n",
      "  0.         0.00444717 0.05274376 0.15360484 0.         0.\n",
      "  0.         0.         0.04511847 0.19997801 0.         0.1028361\n",
      "  0.08890021 0.         0.00304567 0.17681704 0.00069688 0.18480761\n",
      "  0.         0.06334506 0.         0.         0.06726572 0.\n",
      "  0.         0.06246363 0.         0.00406132]]\n",
      "Hi!\n",
      "[[0.23478079 0.25548342 0.5216466  0.         0.         0.40207264\n",
      "  0.8915689  0.97625935 1.0413828  0.         0.43306842 0.\n",
      "  0.98780066 0.         0.         0.8807425  0.         0.7855297\n",
      "  0.5352959  0.         0.70449287 0.         0.         0.\n",
      "  0.32641646 0.         0.         0.3128072  0.         0.\n",
      "  0.87230617 0.25172454 0.         0.         0.65949345 0.\n",
      "  0.4526067  1.2944729  0.         0.42198172 0.13646795 0.\n",
      "  0.         0.70747566 0.506273   0.43090397 0.         0.6452807\n",
      "  0.         0.670216   0.8655178  0.29503033 0.3232189  0.31614175\n",
      "  0.         0.         0.3064673  0.         0.         0.\n",
      "  0.         0.80503774 1.0472126  0.46265894]]\n",
      "Hi!\n",
      "[[0.41065696 0.49613953 1.2103014  0.         0.         0.81653064\n",
      "  0.13083428 0.1921028  0.6831389  0.         0.6082548  0.\n",
      "  0.8832834  0.         0.         0.5296702  0.         0.7228009\n",
      "  0.2900356  0.47547612 0.9336867  0.         0.         0.\n",
      "  0.09094448 0.         0.         0.07539868 0.         0.\n",
      "  0.38073722 0.5277342  0.         0.         0.20922026 0.\n",
      "  0.3849184  0.82117146 0.         0.62398195 0.         0.\n",
      "  0.         0.23364751 0.4324127  0.2230572  0.         1.0015503\n",
      "  0.03158331 0.646332   0.59936774 0.31205973 0.3358059  0.6406761\n",
      "  0.         0.05777049 0.13815716 0.026427   0.07362187 0.\n",
      "  0.         0.55739695 1.0318834  0.58762234]]\n",
      "Hi!\n",
      "[[0.7790788  0.642165   1.5225149  0.         0.         1.1906085\n",
      "  0.11689218 0.3274876  0.45987505 0.07037227 0.59967583 0.\n",
      "  0.44977325 0.         0.         0.         0.14783028 0.50430256\n",
      "  0.         0.71120733 1.0400378  0.         0.         0.4145512\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22894694 0.5808944  0.11688928 0.         0.         0.\n",
      "  0.         0.18901561 0.         0.63974935 0.         0.\n",
      "  0.         0.12230562 0.2582702  0.572339   0.         0.41700563\n",
      "  0.53746265 1.0681326  0.1967569  0.5559079  1.0711856  0.6135837\n",
      "  0.         1.1833678  0.         0.         0.1081368  0.\n",
      "  0.04347092 0.44560912 0.73899585 0.33462378]]\n",
      "Hi!\n",
      "[[0.6796519  1.2234092  1.1738876  0.         0.         0.7216742\n",
      "  0.         0.15270913 0.5665242  0.         0.59795976 0.\n",
      "  1.7297667  0.08856973 0.         0.41082278 0.         0.60457706\n",
      "  0.5314476  0.795556   0.79828113 0.         0.         0.21850528\n",
      "  0.         0.         0.         0.23062855 0.         0.\n",
      "  0.7977585  0.9027168  0.         0.         0.13359298 0.\n",
      "  0.34621742 0.51216555 0.47836357 0.55345213 0.         0.\n",
      "  0.         0.1625775  0.8310335  0.27661878 0.         1.0353338\n",
      "  0.26395205 0.74306285 0.5655787  0.48210242 0.60513455 1.1283182\n",
      "  0.         0.09633272 0.22508541 0.         0.12235366 0.\n",
      "  0.         0.2624373  1.0266547  0.5821366 ]]\n",
      "Hi!\n",
      "[[0.         0.09584648 0.         0.         0.         0.16096944\n",
      "  0.22638063 0.34871933 0.05440552 0.10347565 0.08142142 0.\n",
      "  0.         0.1673543  0.         0.03808322 0.         0.04884727\n",
      "  0.         0.19016355 0.07949409 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.02428602 0.09285292 0.21897185 0.         0.         0.\n",
      "  0.         0.03521813 0.14216878 0.15446763 0.         0.\n",
      "  0.         0.         0.20883535 0.55408293 0.         0.06720331\n",
      "  0.14558466 0.2698204  0.         0.2317175  0.03190545 0.36910436\n",
      "  0.         0.21340913 0.00752135 0.         0.         0.\n",
      "  0.08229224 0.19610953 0.         0.        ]]\n",
      "Hi!\n",
      "[[1.1756713  0.49779105 2.414657   0.         0.         1.1763852\n",
      "  0.         0.         1.2060366  0.         0.90490013 0.\n",
      "  0.220331   0.         0.         0.6586568  1.1519091  0.90237176\n",
      "  0.         0.48809126 1.6459205  0.36420226 0.         0.7033931\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15068492 0.01400905 0.         0.         0.\n",
      "  0.01099632 0.49382752 0.         1.2678494  0.         0.\n",
      "  0.         1.0835392  0.         0.15259998 0.         0.7990322\n",
      "  0.4139763  1.1151137  0.674886   0.0995509  0.500164   0.22205503\n",
      "  0.         0.9959772  0.         0.91837436 0.21030523 0.\n",
      "  0.2676729  0.8539211  0.91640407 1.1521082 ]]\n",
      "Hi!\n",
      "[[0.8172602  0.         0.90735424 0.36076874 0.         1.1971896\n",
      "  1.025638   1.2216434  0.13374932 0.15257265 0.31807098 0.\n",
      "  0.         0.         0.         0.17345092 0.14371383 0.5189749\n",
      "  0.         0.29676706 0.633863   0.         0.         0.40881175\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17590052 0.3770571  0.30543017 0.         0.         0.\n",
      "  0.         0.38032997 0.         0.91298425 0.         0.\n",
      "  0.         0.88027257 0.21649082 1.0366186  0.         0.\n",
      "  0.27689946 1.2690179  0.         0.5699984  1.1054753  0.1564112\n",
      "  0.         1.3785686  0.         0.         0.         0.\n",
      "  0.29805988 0.7968077  0.5544306  0.        ]]\n",
      "Hi!\n",
      "[[0.3188651  0.39656314 0.         0.15050405 0.         0.44057706\n",
      "  0.4973569  0.6201661  0.         0.02865497 0.00994893 0.\n",
      "  0.15625235 0.5301507  0.         0.0020823  0.         0.15536748\n",
      "  0.         0.6386943  0.         0.         0.         0.07938085\n",
      "  0.         0.         0.         0.21711746 0.         0.\n",
      "  0.596185   0.49494967 0.4363708  0.         0.03029101 0.\n",
      "  0.         0.23434058 0.3213647  0.10885492 0.         0.\n",
      "  0.         0.09206071 0.8659018  0.9154671  0.         0.13334109\n",
      "  0.39871627 0.6563853  0.         0.5127275  0.44135657 0.9166281\n",
      "  0.         0.53112    0.2138289  0.         0.         0.\n",
      "  0.03802935 0.14712071 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.1591712  0.90242684 0.7955781  0.         0.         0.59733677\n",
      "  0.02585662 0.3432857  0.6110242  0.         0.49219227 0.\n",
      "  1.2088313  0.101755   0.         0.34379438 0.         0.49246213\n",
      "  0.09288485 0.576757   0.65217245 0.         0.         0.03771779\n",
      "  0.         0.         0.         0.09252138 0.         0.\n",
      "  0.645626   0.47012654 0.         0.         0.09801569 0.\n",
      "  0.         0.4015458  0.         0.3560838  0.         0.\n",
      "  0.         0.         0.3432547  0.41825327 0.         0.5567604\n",
      "  0.11601767 0.7436078  0.4938161  0.33856735 0.5974527  0.56938463\n",
      "  0.         0.         0.05644665 0.         0.01781364 0.\n",
      "  0.         0.48912024 0.56101614 0.47101045]]\n",
      "Hi!\n",
      "[[0.65927315 0.         0.7499874  0.40899545 0.         0.93788576\n",
      "  1.0489724  1.1501043  0.11414494 0.0710556  0.30151838 0.\n",
      "  0.         0.         0.         0.20161055 0.12286964 0.677523\n",
      "  0.         0.26195383 0.45233992 0.0318047  0.         0.32274365\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05483744 0.24822383 0.3475848  0.         0.         0.\n",
      "  0.         0.38460335 0.         1.001651   0.04639592 0.\n",
      "  0.         1.0035313  0.09517642 0.9756467  0.         0.\n",
      "  0.303719   1.297034   0.         0.38776994 0.9986434  0.03130307\n",
      "  0.         1.0621773  0.         0.         0.         0.\n",
      "  0.35364097 1.0000321  0.27804744 0.        ]]\n",
      "Hi!\n",
      "[[0.99901426 0.08570637 1.5637211  0.03060823 0.         1.1977618\n",
      "  0.3578527  0.69424736 0.7024769  0.06871467 0.54844564 0.\n",
      "  0.         0.         0.         0.21055533 0.54445565 0.6391471\n",
      "  0.         0.24269006 1.1395574  0.03205271 0.         0.6500689\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34379944 0.18762246 0.         0.         0.\n",
      "  0.         0.4909662  0.         0.8550864  0.         0.\n",
      "  0.         0.90543276 0.         0.47321838 0.         0.1963634\n",
      "  0.25175112 1.0704767  0.21945101 0.38441467 0.8402881  0.17974985\n",
      "  0.         1.2648706  0.         0.12160899 0.         0.\n",
      "  0.14589068 0.7612589  0.9166897  0.26038784]]\n",
      "Hi!\n",
      "[[0.03980345 0.15845822 0.08444162 0.         0.         0.10920015\n",
      "  0.         0.13466063 0.04061383 0.07751772 0.1447774  0.\n",
      "  0.         0.04876077 0.         0.07572377 0.         0.01645981\n",
      "  0.         0.23448658 0.0851288  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02621855 0.12307771 0.         0.         0.\n",
      "  0.         0.         0.10488457 0.08098026 0.         0.\n",
      "  0.         0.         0.06567336 0.3372013  0.         0.09865759\n",
      "  0.09092495 0.10819013 0.         0.16365491 0.09644876 0.30538088\n",
      "  0.         0.12303482 0.         0.         0.01818943 0.\n",
      "  0.01026067 0.15277086 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.6640594  0.3119312  0.         0.45924863 0.         0.47080955\n",
      "  1.1464009  1.8322082  0.50858533 0.         0.23612633 0.\n",
      "  1.6479999  1.114332   0.         0.6357487  0.         0.54624933\n",
      "  0.8113757  0.04129053 0.4206457  0.40718353 0.         0.05182655\n",
      "  0.30735177 0.         0.         1.14339    0.         0.\n",
      "  1.767082   0.96011305 0.12131935 0.         1.0453868  0.\n",
      "  0.58819133 1.3591926  0.42025807 0.03738112 0.28773132 0.\n",
      "  0.         0.5835503  1.6196982  1.2530966  0.         0.75175554\n",
      "  0.         0.73247385 0.83680844 0.63855076 0.8735594  1.1728492\n",
      "  0.         0.         0.6977055  0.         0.         0.\n",
      "  0.         0.3087153  1.3622558  0.        ]]\n",
      "Hi!\n",
      "[[0.6066187  0.42682526 1.4299684  0.         0.         1.1314485\n",
      "  0.04186862 0.28043076 0.33434352 0.         0.5941937  0.\n",
      "  0.709315   0.         0.         0.23664053 0.10330807 0.55554307\n",
      "  0.         0.7413388  0.9710489  0.         0.         0.07631122\n",
      "  0.         0.         0.         0.03659263 0.         0.\n",
      "  0.33821017 0.83728874 0.00754887 0.         0.         0.\n",
      "  0.17237672 0.5999952  0.         0.68962884 0.         0.\n",
      "  0.         0.07773894 0.5572498  0.52786624 0.         0.9013653\n",
      "  0.44557905 0.55399084 0.23533815 0.46415296 0.5534003  0.9209406\n",
      "  0.         0.8062162  0.16454417 0.         0.05677538 0.\n",
      "  0.         0.31060797 1.1701802  0.23560722]]\n",
      "Hi!\n",
      "[[0.33568338 0.17965236 0.81536    0.         0.         0.67715305\n",
      "  0.5426201  0.48959336 0.47609738 0.         0.40258345 0.\n",
      "  0.42531067 0.         0.         0.3954349  0.         0.61396927\n",
      "  0.         0.28950047 0.62379146 0.         0.         0.\n",
      "  0.0777072  0.         0.         0.081014   0.         0.\n",
      "  0.40732807 0.35178787 0.         0.         0.3065938  0.\n",
      "  0.18794407 0.84172994 0.         0.41041455 0.         0.\n",
      "  0.         0.32892174 0.40967837 0.4214171  0.         0.65194494\n",
      "  0.         0.5149662  0.3982715  0.27716115 0.22850075 0.45856884\n",
      "  0.         0.05959497 0.13227578 0.         0.         0.\n",
      "  0.         0.55910397 0.8242708  0.26410252]]\n",
      "Hi!\n",
      "[[0.4980438  0.         0.88550085 0.05088717 0.         0.5769786\n",
      "  0.6631347  0.6518395  0.5736654  0.04141301 0.36726013 0.\n",
      "  0.         0.         0.         0.26192027 0.2181196  0.67907286\n",
      "  0.         0.05534675 0.7278407  0.06143341 0.         0.2602295\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01817419 0.12834693 0.10732502 0.         0.05423416 0.\n",
      "  0.         0.65087306 0.         0.52611893 0.         0.\n",
      "  0.         0.71034455 0.         0.41332546 0.         0.10013773\n",
      "  0.00284008 0.7538974  0.23726936 0.19007765 0.39317602 0.\n",
      "  0.         0.37361094 0.         0.         0.         0.\n",
      "  0.0105071  0.91423935 0.60063183 0.19290565]]\n",
      "Hi!\n",
      "[[0.45395786 0.13238367 1.0437744  0.         0.         0.82099116\n",
      "  0.6434707  0.76070184 0.80423754 0.         0.51759166 0.\n",
      "  0.43162265 0.         0.         0.47759393 0.02785992 0.75068456\n",
      "  0.         0.0965827  0.95995814 0.         0.         0.16117923\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40823525 0.35297608 0.         0.         0.27829453 0.\n",
      "  0.         0.9041877  0.         0.55073285 0.03385152 0.\n",
      "  0.         0.63657933 0.23641175 0.48819518 0.         0.446888\n",
      "  0.         0.8049656  0.502177   0.3750024  0.60987276 0.26841468\n",
      "  0.         0.25198576 0.         0.02202001 0.         0.\n",
      "  0.         0.78362405 1.0771922  0.33689427]]\n",
      "Hi!\n",
      "[[0.49090776 0.9207069  0.8034088  0.         0.         0.65450567\n",
      "  0.         0.3637864  0.1522547  0.         0.4343985  0.\n",
      "  1.0718136  0.3479604  0.         0.06688215 0.         0.42545477\n",
      "  0.         0.8196604  0.5277359  0.         0.         0.2562491\n",
      "  0.         0.         0.         0.19220553 0.         0.\n",
      "  0.766638   0.76013297 0.         0.         0.19112808 0.\n",
      "  0.         0.2025723  0.4101614  0.34871185 0.         0.\n",
      "  0.         0.01347556 0.7602498  0.6232449  0.         0.470538\n",
      "  0.4328323  0.7619034  0.18071128 0.49349573 0.8033161  0.94044596\n",
      "  0.         0.3664792  0.13606147 0.         0.08816132 0.\n",
      "  0.         0.23610951 0.5386483  0.0868478 ]]\n",
      "Hi!\n",
      "[[0.7082585  0.2127363  0.17326717 0.5860817  0.         0.713605\n",
      "  0.82728386 1.0872822  0.         0.         0.         0.\n",
      "  0.14145267 0.6419046  0.         0.02961152 0.         0.12893064\n",
      "  0.         0.68585205 0.         0.         0.         0.13728599\n",
      "  0.         0.         0.         0.4209693  0.         0.\n",
      "  0.9451268  0.9776576  0.5630719  0.         0.13310918 0.\n",
      "  0.         0.36835358 0.6384764  0.18642972 0.         0.\n",
      "  0.         0.30695105 1.3621227  1.225051   0.         0.07797866\n",
      "  0.67702615 0.85372627 0.         0.7851363  0.9046534  1.2204912\n",
      "  0.         1.0282296  0.35609293 0.         0.         0.\n",
      "  0.         0.15136503 0.46793857 0.        ]]\n",
      "Hi!\n",
      "[[0.2320004  0.26774904 0.28172126 0.00678941 0.         0.4609217\n",
      "  0.20817538 0.35128582 0.         0.         0.03832512 0.\n",
      "  0.3220424  0.18941127 0.         0.00716653 0.         0.19881727\n",
      "  0.         0.34072602 0.0893302  0.         0.         0.\n",
      "  0.         0.         0.         0.15632732 0.         0.\n",
      "  0.26050422 0.47495016 0.154038   0.         0.         0.\n",
      "  0.07082274 0.23608872 0.3301667  0.26336318 0.         0.\n",
      "  0.         0.094918   0.45841786 0.6127392  0.         0.45686886\n",
      "  0.39404085 0.30133885 0.         0.40558448 0.09924476 0.82820886\n",
      "  0.         0.5194212  0.16620596 0.         0.         0.\n",
      "  0.0072707  0.09579698 0.13685122 0.        ]]\n",
      "Hi!\n",
      "[[0.45674244 0.3567182  1.3508698  0.         0.         0.7983237\n",
      "  0.29997998 0.42921492 1.1576401  0.         0.6641998  0.\n",
      "  0.8449644  0.         0.         0.6670539  0.18206845 0.8205602\n",
      "  0.37517008 0.03733651 1.1707082  0.02350275 0.         0.29124236\n",
      "  0.07240291 0.         0.         0.         0.         0.\n",
      "  0.33357903 0.3899261  0.         0.         0.18170819 0.\n",
      "  0.20367539 0.93409294 0.         0.7237026  0.10462655 0.\n",
      "  0.         0.6597886  0.09589599 0.18033656 0.         0.7835416\n",
      "  0.         0.8031828  0.7476369  0.277243   0.47615737 0.30995032\n",
      "  0.         0.08291681 0.         0.30251685 0.02532313 0.\n",
      "  0.         0.7900371  1.2099303  0.7983626 ]]\n",
      "Hi!\n",
      "[[7.55605707e-03 2.22412139e-01 3.28752995e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.78971106e-01 0.00000000e+00 4.13052877e-03\n",
      "  4.71775234e-02 5.79967871e-02 1.96296036e-01 0.00000000e+00\n",
      "  1.13688953e-01 3.95342298e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.42743455e-02 0.00000000e+00 3.16122949e-01\n",
      "  1.42617539e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.47221580e-01\n",
      "  4.49161865e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.45946249e-01 1.58110529e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.39536008e-01 2.52824575e-01 0.00000000e+00 1.74719751e-01\n",
      "  2.64307320e-01 1.14867225e-01 0.00000000e+00 2.69286186e-01\n",
      "  1.57864064e-01 3.86580586e-01 0.00000000e+00 1.80288076e-01\n",
      "  3.57132667e-04 0.00000000e+00 5.19183911e-02 0.00000000e+00\n",
      "  5.68125248e-02 4.07036580e-02 0.00000000e+00 1.79521032e-02]]\n",
      "Hi!\n",
      "[[0.65672565 0.11416009 0.83694166 0.14165886 0.         1.0376959\n",
      "  0.5481801  0.81185293 0.15299706 0.17299235 0.3230136  0.\n",
      "  0.         0.         0.         0.1293827  0.07420203 0.43858483\n",
      "  0.         0.48086703 0.56153756 0.         0.         0.374487\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27459556 0.18612595 0.         0.         0.\n",
      "  0.         0.28586537 0.         0.88638526 0.         0.\n",
      "  0.         0.68621194 0.03445796 0.87768096 0.         0.\n",
      "  0.41652033 1.312429   0.         0.4556722  0.9711553  0.14161602\n",
      "  0.         1.139009   0.         0.         0.         0.\n",
      "  0.40778613 0.7767096  0.10389759 0.        ]]\n",
      "Hi!\n",
      "[[0.43447012 0.8536467  1.2112427  0.         0.         0.6936511\n",
      "  0.01153311 0.17189689 0.72837317 0.         0.62550586 0.\n",
      "  1.1553363  0.         0.         0.41810903 0.         0.6713942\n",
      "  0.2503075  0.5369133  0.9263047  0.         0.         0.07204752\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.51771194 0.59304833 0.         0.         0.11607035 0.\n",
      "  0.04126569 0.59558266 0.         0.6319571  0.         0.\n",
      "  0.         0.07792383 0.41377714 0.15578426 0.         0.74795973\n",
      "  0.13248692 0.7023427  0.51719946 0.3484739  0.51730233 0.63421905\n",
      "  0.         0.06308704 0.03438863 0.         0.11939563 0.\n",
      "  0.         0.51646435 0.89583975 0.62058544]]\n",
      "Hi!\n",
      "[[3.48610938e-01 4.91991282e-01 2.65280932e-01 5.20938411e-02\n",
      "  0.00000000e+00 2.25359023e-01 0.00000000e+00 2.82637209e-01\n",
      "  0.00000000e+00 0.00000000e+00 1.84841022e-01 0.00000000e+00\n",
      "  4.70678955e-01 4.89163220e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.21504873e-01 0.00000000e+00 4.34906244e-01\n",
      "  9.54459831e-02 0.00000000e+00 0.00000000e+00 1.15940765e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.30493551e-01\n",
      "  0.00000000e+00 0.00000000e+00 4.08238292e-01 5.33912838e-01\n",
      "  2.18648031e-01 0.00000000e+00 2.77917337e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.31335318e-01 9.18479040e-02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.02082908e-01 4.75522220e-01 0.00000000e+00 5.31872772e-02\n",
      "  4.72990543e-01 2.97783971e-01 0.00000000e+00 3.66819888e-01\n",
      "  4.01089996e-01 8.99822116e-01 0.00000000e+00 2.60885060e-01\n",
      "  2.24227220e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.19046593e-01 1.07223593e-01 8.59581307e-02 0.00000000e+00]]\n",
      "Hi!\n",
      "[[0.0868668  0.4002471  0.42692342 0.         0.         0.3807402\n",
      "  0.         0.03196039 0.13772741 0.06123717 0.29111144 0.\n",
      "  0.3171037  0.09814165 0.         0.0042658  0.         0.11865473\n",
      "  0.         0.43680754 0.24153563 0.         0.         0.01324395\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.03055883 0.16615798 0.         0.         0.         0.\n",
      "  0.         0.         0.12124056 0.18137853 0.         0.\n",
      "  0.         0.         0.1347163  0.24564974 0.         0.25524312\n",
      "  0.27053592 0.27552968 0.02053817 0.27097553 0.24520205 0.5648926\n",
      "  0.         0.1607788  0.03131116 0.         0.05656895 0.\n",
      "  0.09913225 0.20552985 0.00646315 0.        ]]\n",
      "Hi!\n",
      "[[0.38316822 0.09059114 0.39075845 0.22406779 0.         0.82682717\n",
      "  0.92457426 1.0606011  0.09178821 0.05335759 0.2425385  0.\n",
      "  0.         0.         0.         0.02874108 0.         0.43188345\n",
      "  0.         0.25473017 0.42231974 0.         0.         0.10627455\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.46633953 0.3529242  0.13538387 0.         0.18343002 0.\n",
      "  0.         0.4733502  0.         0.5620349  0.         0.\n",
      "  0.         0.40361902 0.4378003  0.8948401  0.         0.\n",
      "  0.0997365  1.0369203  0.04643083 0.4558244  0.7334736  0.29893407\n",
      "  0.         0.53388625 0.         0.         0.         0.\n",
      "  0.         0.6527986  0.41046193 0.        ]]\n",
      "Hi!\n",
      "[[0.3553289  0.6717871  1.2605424  0.         0.         0.5241525\n",
      "  0.31822607 0.40616184 1.542165   0.         0.71372396 0.\n",
      "  1.5840894  0.         0.         1.06729    0.01186618 0.8948393\n",
      "  1.2411225  0.         1.182688   0.17759739 0.         0.00572294\n",
      "  0.37969014 0.         0.         0.30108652 0.         0.\n",
      "  0.6524939  0.4237639  0.         0.         0.46729475 0.\n",
      "  0.786436   1.206787   0.         0.71706635 0.17646576 0.\n",
      "  0.         0.63300955 0.23862831 0.         0.         1.1974714\n",
      "  0.         0.9541782  1.1936712  0.20607217 0.2107372  0.44916525\n",
      "  0.         0.         0.27389973 0.32808286 0.         0.\n",
      "  0.         0.7888344  1.3977255  1.1271893 ]]\n",
      "Hi!\n",
      "[[0.7309365  0.00295586 1.1461055  0.         0.         0.9035862\n",
      "  0.58844864 0.55380964 0.5713526  0.         0.42530298 0.\n",
      "  0.         0.         0.         0.2094764  0.3564898  0.6963479\n",
      "  0.         0.24440347 0.8747363  0.02430513 0.         0.19547768\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31082746 0.03029668 0.         0.04629885 0.\n",
      "  0.         0.68956697 0.         0.6524301  0.         0.\n",
      "  0.         0.65572023 0.07462927 0.42615908 0.         0.47581306\n",
      "  0.11865295 0.70976883 0.2773051  0.28940699 0.32399315 0.41527262\n",
      "  0.         0.6896408  0.         0.12648302 0.         0.\n",
      "  0.10815039 0.7045619  0.72583747 0.2559315 ]]\n",
      "Hi!\n",
      "[[0.16375402 0.3193132  0.3368825  0.         0.         0.47913036\n",
      "  0.02463662 0.27306268 0.         0.12769604 0.2416122  0.\n",
      "  0.         0.13547607 0.         0.         0.         0.11558109\n",
      "  0.         0.52031076 0.17260063 0.         0.         0.02628459\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14204405 0.05848451 0.         0.         0.\n",
      "  0.         0.01202924 0.09807767 0.26786527 0.         0.\n",
      "  0.         0.         0.22811204 0.5789748  0.         0.10484371\n",
      "  0.34452227 0.42421392 0.         0.325626   0.4303675  0.5364678\n",
      "  0.         0.43466413 0.         0.         0.05029875 0.\n",
      "  0.15880708 0.14968158 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.14744642 0.         0.17375188 0.         0.         0.38789833\n",
      "  0.7566696  0.5027549  0.0079818  0.3983474  0.19809768 0.\n",
      "  0.         0.         0.00259765 0.07694475 0.         0.06367043\n",
      "  0.         0.22725642 0.23308712 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14965029 0.         0.         0.\n",
      "  0.         0.17925322 0.02952147 0.5638585  0.         0.\n",
      "  0.         0.16130197 0.12362662 0.86371267 0.         0.\n",
      "  0.24405567 0.3028691  0.04913322 0.35525212 0.43473393 0.09568758\n",
      "  0.         0.4718052  0.         0.         0.         0.\n",
      "  0.03988894 0.3257792  0.         0.        ]]\n",
      "Hi!\n",
      "[[1.0539441  0.18376768 1.9832388  0.         0.         1.0465126\n",
      "  0.2536893  0.3331332  1.267082   0.         0.7562475  0.\n",
      "  0.136519   0.         0.         0.67851967 0.86388123 0.8537252\n",
      "  0.         0.01660957 1.5195978  0.3023706  0.         0.74989355\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2574373  0.0447959  0.         0.         0.\n",
      "  0.         0.7404811  0.         1.0376158  0.03769444 0.\n",
      "  0.         1.2139658  0.         0.10260633 0.         0.5958294\n",
      "  0.046799   0.93293834 0.67405087 0.17531662 0.5728928  0.14283939\n",
      "  0.         0.8497503  0.         0.7020588  0.04823947 0.\n",
      "  0.         0.9043409  1.0564482  0.8818631 ]]\n",
      "Hi!\n",
      "[[0.18892588 0.27384856 0.19579424 0.         0.         0.04937923\n",
      "  0.         0.22100565 0.07967719 0.         0.15558822 0.\n",
      "  0.325687   0.2597886  0.         0.02178408 0.         0.09113196\n",
      "  0.         0.12487003 0.07074494 0.         0.         0.\n",
      "  0.         0.         0.         0.12082195 0.         0.\n",
      "  0.19286051 0.14034809 0.10730971 0.         0.00290468 0.\n",
      "  0.         0.         0.3343932  0.05471358 0.         0.\n",
      "  0.         0.08871225 0.24273328 0.19830799 0.         0.01499039\n",
      "  0.11943556 0.14994712 0.09810957 0.1079829  0.02082209 0.4450894\n",
      "  0.         0.04400004 0.28552425 0.         0.         0.\n",
      "  0.14756049 0.16031347 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.60634637 0.         1.3573579  0.         0.         0.8131385\n",
      "  0.61642027 0.71849656 1.1289705  0.         0.5925796  0.\n",
      "  0.30138612 0.         0.         0.6885744  0.36254576 0.80681485\n",
      "  0.09477133 0.         1.1978     0.19673832 0.         0.49005118\n",
      "  0.0096476  0.         0.         0.         0.         0.\n",
      "  0.17791478 0.23735411 0.         0.         0.12926993 0.\n",
      "  0.08286568 1.0703931  0.         0.7387256  0.07355725 0.\n",
      "  0.         1.0524143  0.         0.27743003 0.         0.5735155\n",
      "  0.         0.70500666 0.58464366 0.19983734 0.29123577 0.12652609\n",
      "  0.         0.26847285 0.         0.40471742 0.         0.\n",
      "  0.         0.99459076 1.2971013  0.60521126]]\n",
      "Hi!\n",
      "[[0.79056674 0.72961587 0.37172395 0.18634821 0.         0.5574901\n",
      "  0.4682564  1.20543    0.47259033 0.         0.40262815 0.\n",
      "  1.826428   0.80051315 0.         0.4857975  0.         0.5697453\n",
      "  0.86411095 0.3555292  0.57562524 0.23353638 0.         0.2174523\n",
      "  0.13973309 0.         0.         0.9140104  0.         0.\n",
      "  1.5063677  1.0824782  0.         0.         0.8356447  0.\n",
      "  0.5489959  1.0034413  0.612534   0.22226804 0.08502133 0.\n",
      "  0.         0.5418608  1.5035943  0.912039   0.         0.8532527\n",
      "  0.         0.75981987 0.75743103 0.5687409  0.81387573 1.3525654\n",
      "  0.         0.         0.6596098  0.         0.         0.\n",
      "  0.         0.24563648 1.3210642  0.00655563]]\n",
      "Hi!\n",
      "[[0.00031584 0.18504456 0.22295338 0.         0.         0.2025873\n",
      "  0.         0.05718489 0.07359631 0.08440373 0.133625   0.\n",
      "  0.05527348 0.02296914 0.         0.05827519 0.         0.04965818\n",
      "  0.         0.26653486 0.12179496 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06606814 0.09593181 0.         0.         0.\n",
      "  0.         0.         0.07035332 0.09939855 0.         0.\n",
      "  0.         0.         0.05860066 0.2037561  0.         0.17708577\n",
      "  0.18665142 0.0854655  0.         0.2162931  0.0015774  0.29145828\n",
      "  0.         0.11838977 0.01164918 0.         0.03799237 0.\n",
      "  0.09651969 0.04141468 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.2370677  0.         0.25597778 0.1800832  0.         0.5661779\n",
      "  1.2115954  1.3831238  0.35012642 0.         0.2608789  0.\n",
      "  0.30428603 0.1808407  0.         0.3567004  0.         0.61502534\n",
      "  0.         0.         0.4102582  0.         0.         0.\n",
      "  0.         0.         0.         0.40682533 0.         0.\n",
      "  1.010783   0.4143666  0.00381597 0.         0.58213335 0.\n",
      "  0.         0.99465364 0.         0.37251195 0.0986782  0.\n",
      "  0.         0.5140415  0.6803215  0.9919858  0.         0.\n",
      "  0.         0.95987844 0.3189781  0.4649295  0.7702657  0.27536345\n",
      "  0.         0.         0.06826985 0.         0.         0.\n",
      "  0.         0.73371    0.8064292  0.        ]]\n",
      "Hi!\n",
      "[[1.0363822  0.         1.5845996  0.12470152 0.         1.0695393\n",
      "  0.7254246  1.0027765  1.0769033  0.         0.5730697  0.\n",
      "  0.         0.         0.         0.4484214  0.68467885 0.76575345\n",
      "  0.         0.         1.2367823  0.30278063 0.         0.83806926\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24076165 0.1984262  0.         0.         0.\n",
      "  0.         0.80635417 0.         0.95136607 0.00618423 0.\n",
      "  0.         1.3732519  0.         0.3897725  0.         0.05848682\n",
      "  0.         1.123503   0.4701898  0.26301247 0.79928696 0.\n",
      "  0.         1.010371   0.         0.3564433  0.         0.\n",
      "  0.         1.034969   1.15535    0.36470753]]\n",
      "Hi!\n",
      "[[0.         0.16774614 0.20157993 0.         0.         0.23289493\n",
      "  0.         0.04687272 0.02221126 0.08050773 0.1688013  0.\n",
      "  0.02017638 0.04740466 0.         0.0031868  0.         0.01827944\n",
      "  0.         0.2695812  0.09314356 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10721529 0.06658536 0.         0.         0.\n",
      "  0.         0.         0.07532734 0.1256431  0.         0.\n",
      "  0.         0.         0.07154569 0.3579729  0.         0.137927\n",
      "  0.24242978 0.15673877 0.         0.23837064 0.09066225 0.35080215\n",
      "  0.         0.18588983 0.         0.         0.01838956 0.\n",
      "  0.04695526 0.06698414 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.80258584 0.         1.0172791  0.31896514 0.         0.8556427\n",
      "  1.3161905  1.3516717  0.8337586  0.         0.4181205  0.\n",
      "  0.         0.         0.         0.44746086 0.3880247  0.7445173\n",
      "  0.         0.         0.9250306  0.22498043 0.         0.56850785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18103789 0.15197295 0.23671663 0.         0.17311946 0.\n",
      "  0.         0.9438982  0.         0.86336374 0.12583959 0.\n",
      "  0.         1.3788743  0.         0.63814765 0.         0.\n",
      "  0.         1.115864   0.2860707  0.23941399 0.77329534 0.\n",
      "  0.         0.7087473  0.         0.04275282 0.         0.\n",
      "  0.         1.1597111  1.061598   0.        ]]\n",
      "Hi!\n",
      "[[0.6347201  1.3607059  0.58120275 0.         0.         0.40765452\n",
      "  0.         0.5840556  0.48042098 0.         0.50392956 0.\n",
      "  2.122258   0.8218886  0.         0.54313874 0.         0.5951374\n",
      "  0.7341184  0.7570458  0.56120783 0.01927917 0.         0.37774274\n",
      "  0.0435965  0.         0.         0.6203244  0.         0.\n",
      "  1.3078213  0.9965395  0.         0.         0.41999596 0.\n",
      "  0.32029393 0.6131407  0.75089616 0.36924735 0.         0.\n",
      "  0.         0.3250326  1.1752294  0.640334   0.         0.9001295\n",
      "  0.10089361 0.7703793  0.76847124 0.4233014  0.79907453 1.2528387\n",
      "  0.         0.         0.42483214 0.         0.01532001 0.\n",
      "  0.         0.2749228  0.8385056  0.29120532]]\n",
      "Hi!\n",
      "[[1.0533565  0.2840623  1.6525564  0.         0.         1.2995704\n",
      "  0.19340262 0.47922897 0.60143536 0.12289116 0.5894907  0.\n",
      "  0.         0.         0.         0.10691732 0.5606227  0.58586633\n",
      "  0.         0.50855875 1.1164123  0.         0.         0.6154867\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.37903178 0.17115103 0.         0.         0.\n",
      "  0.         0.3043543  0.         0.8093615  0.         0.\n",
      "  0.         0.68746656 0.         0.45534593 0.         0.3088784\n",
      "  0.4324334  1.1449327  0.18165405 0.43461505 0.87847453 0.4015362\n",
      "  0.         1.4304693  0.         0.0702647  0.09203535 0.\n",
      "  0.2769766  0.6293501  0.78969085 0.31143877]]\n",
      "Hi!\n",
      "[[2.5050968e-01 4.4223872e-01 1.0199308e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.6603628e-01 0.0000000e+00 0.0000000e+00 2.7047041e-01 2.2056455e-02\n",
      "  3.9533737e-01 0.0000000e+00 2.0433521e-01 0.0000000e+00 0.0000000e+00\n",
      "  1.3713488e-01 2.3903388e-01 1.4304250e-01 0.0000000e+00 6.7070872e-01\n",
      "  5.1666647e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 3.9680645e-01 8.5159376e-02 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.3224743e-04 0.0000000e+00 5.4207230e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8782491e-02\n",
      "  1.2478876e-01 0.0000000e+00 4.9829620e-01 3.7503588e-01 3.8302314e-01\n",
      "  1.8027934e-01 3.3383143e-01 3.3295542e-01 6.4750552e-01 0.0000000e+00\n",
      "  5.7325178e-01 0.0000000e+00 0.0000000e+00 1.9361192e-01 0.0000000e+00\n",
      "  2.6065361e-01 1.3972954e-01 2.8894338e-01 2.4304509e-01]]\n",
      "Hi!\n",
      "[[1.0600531  0.3318757  1.7323467  0.         0.         1.2348306\n",
      "  0.15705533 0.30326664 0.5833679  0.13883683 0.57846916 0.\n",
      "  0.         0.         0.         0.10098994 0.68169713 0.564889\n",
      "  0.         0.6404485  1.0868945  0.         0.         0.47081137\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11132513 0.18679376 0.         0.         0.\n",
      "  0.         0.313048   0.         0.9286171  0.         0.\n",
      "  0.         0.780522   0.         0.39374796 0.         0.31389183\n",
      "  0.5570448  1.1322666  0.19690204 0.2572085  0.7680527  0.20666046\n",
      "  0.         1.390908   0.         0.13240469 0.12313066 0.\n",
      "  0.65216535 0.81556886 0.36307245 0.45747608]]\n",
      "Hi!\n",
      "[[0.11574022 0.         0.19869836 0.04750653 0.         0.36968285\n",
      "  1.6288503  1.6211617  0.8578649  0.         0.29430354 0.\n",
      "  0.4212226  0.         0.         0.79506665 0.         0.75640965\n",
      "  0.02527497 0.         0.5783843  0.11607502 0.         0.\n",
      "  0.2638109  0.         0.         0.43880057 0.         0.\n",
      "  1.018731   0.13037607 0.         0.         0.800367   0.\n",
      "  0.2506774  1.44495    0.         0.39553216 0.23321801 0.\n",
      "  0.         1.0831866  0.52342594 0.7708988  0.         0.14157405\n",
      "  0.         0.8428408  0.7080792  0.36120975 0.45344332 0.09826328\n",
      "  0.         0.         0.23650962 0.         0.         0.\n",
      "  0.         0.9571247  1.0811114  0.08602871]]\n",
      "Hi!\n",
      "[[0.47328717 0.01207792 0.9528773  0.06830494 0.         0.9619711\n",
      "  0.8290798  1.0233431  0.6438874  0.         0.49367085 0.\n",
      "  0.73822534 0.         0.         0.5213226  0.         0.675002\n",
      "  0.35157028 0.1280158  0.8549907  0.02195148 0.         0.\n",
      "  0.09934454 0.         0.         0.48786634 0.         0.\n",
      "  0.7855708  0.7293078  0.         0.         0.48040283 0.\n",
      "  0.42367253 1.1507758  0.         0.43246725 0.07018548 0.\n",
      "  0.         0.55552626 0.772812   0.7212204  0.         0.79507774\n",
      "  0.         0.63289165 0.4725929  0.4550962  0.4755511  0.70224434\n",
      "  0.         0.18128575 0.40902945 0.         0.         0.\n",
      "  0.         0.5425004  1.4671434  0.19291282]]\n",
      "Hi!\n",
      "[[0.14021896 0.22527833 0.41322008 0.         0.         0.32382002\n",
      "  0.         0.         0.         0.00511322 0.2226891  0.\n",
      "  0.0827354  0.09101734 0.         0.         0.         0.00950209\n",
      "  0.         0.38467318 0.1582205  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25573727 0.06725404 0.         0.         0.\n",
      "  0.         0.         0.22834563 0.1772705  0.         0.\n",
      "  0.         0.         0.20369434 0.33358184 0.         0.21442017\n",
      "  0.35357425 0.15582515 0.         0.3180912  0.22347628 0.4287969\n",
      "  0.         0.3885424  0.         0.         0.01854063 0.\n",
      "  0.05945699 0.         0.01008774 0.        ]]\n",
      "Hi!\n",
      "[[0.14801534 0.14483923 0.2548193  0.         0.         0.4847407\n",
      "  0.17383876 0.3256971  0.         0.12673229 0.18349797 0.\n",
      "  0.         0.12150244 0.         0.         0.         0.13685893\n",
      "  0.         0.434517   0.15504208 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05214433 0.22125305 0.07487134 0.         0.         0.\n",
      "  0.         0.02856845 0.         0.22797088 0.         0.\n",
      "  0.         0.         0.29995877 0.63107556 0.         0.13080814\n",
      "  0.34431085 0.42426255 0.         0.38452744 0.30440366 0.44380328\n",
      "  0.         0.48850304 0.         0.         0.         0.\n",
      "  0.18579124 0.21836945 0.         0.        ]]\n",
      "Hi!\n",
      "[[0.7338845  0.14044614 0.         0.6124819  0.         0.6092471\n",
      "  1.3586951  1.7939119  0.         0.         0.05179111 0.\n",
      "  0.9091536  0.9972974  0.         0.26238516 0.         0.341379\n",
      "  0.         0.25999096 0.13084848 0.280847   0.         0.06841061\n",
      "  0.11159333 0.         0.         0.9051815  0.         0.\n",
      "  1.5643119  0.9566604  0.4789736  0.         0.7462231  0.\n",
      "  0.3083138  1.1054609  0.44896117 0.17199779 0.22215304 0.\n",
      "  0.         0.5305343  1.6747202  1.5988897  0.         0.5145252\n",
      "  0.05356758 0.89589506 0.2665111  0.7307288  0.82854545 1.3402259\n",
      "  0.         0.19307047 0.65817684 0.         0.         0.\n",
      "  0.         0.21242955 0.8149157  0.        ]]\n",
      "Hi!\n",
      "[[0.03177453 0.17005093 0.3637105  0.         0.         0.23747791\n",
      "  0.         0.         0.14055157 0.0597772  0.1910229  0.\n",
      "  0.15100308 0.         0.         0.02776159 0.         0.\n",
      "  0.         0.27224717 0.21264894 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05330143 0.01056886 0.         0.         0.\n",
      "  0.         0.         0.         0.15303367 0.         0.\n",
      "  0.         0.03532996 0.         0.04452594 0.         0.22422177\n",
      "  0.0962728  0.09265975 0.00707569 0.17517404 0.06992551 0.20925377\n",
      "  0.         0.04964433 0.         0.         0.09726212 0.\n",
      "  0.07238488 0.         0.00358979 0.10153224]]\n",
      "Hi!\n",
      "[[0.01435838 0.3510301  0.36264104 0.         0.         0.3049498\n",
      "  0.         0.         0.15284567 0.06080439 0.23558365 0.\n",
      "  0.24636135 0.         0.         0.0466934  0.         0.1341369\n",
      "  0.         0.43047515 0.23954843 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06051515 0.09880789 0.         0.         0.         0.\n",
      "  0.         0.         0.00919908 0.19269502 0.         0.\n",
      "  0.         0.         0.07764807 0.19826761 0.         0.2311435\n",
      "  0.22815712 0.23155026 0.06692895 0.17368565 0.11862933 0.36759263\n",
      "  0.         0.06539781 0.00963458 0.         0.11896145 0.\n",
      "  0.14470741 0.11902887 0.         0.13923007]]\n",
      "Hi!\n",
      "[[0.06936659 0.3192257  0.         0.12823421 0.         0.24277143\n",
      "  0.34998444 0.7176794  0.         0.         0.07053044 0.\n",
      "  0.14692122 0.5018711  0.         0.07413679 0.         0.09316804\n",
      "  0.         0.36813703 0.         0.         0.         0.0980688\n",
      "  0.         0.         0.         0.06700575 0.         0.\n",
      "  0.46760887 0.37355945 0.20181297 0.         0.06530289 0.\n",
      "  0.         0.06278585 0.40595466 0.22827639 0.         0.\n",
      "  0.         0.         0.664462   0.7762191  0.         0.\n",
      "  0.2017128  0.53574574 0.         0.3021491  0.5528233  0.64932626\n",
      "  0.         0.21239233 0.28567743 0.         0.         0.\n",
      "  0.         0.23853156 0.01891227 0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/training_classHead.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c2dfd115d703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# for i_batch, (X_batch, y_batch, idx_batch, sample_weight) in enumerate(dataloader_train):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m#     print(X_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#     print(y_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Josh/Documents/github_repos/GCaMP_ROI_classifier/old_stuff/util.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0monehot_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheadmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_prediction\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from training_classHead import HeadModel\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import torchvision.transforms    \n",
    "\n",
    "# transforms = torch.nn.Sequential()\n",
    "# scripted_transforms = transforms\n",
    "\n",
    "\n",
    "# dataset_train = util.dataset_simCLR(torch.tensor(X_train), \n",
    "#                                     y_train, \n",
    "#                                     n_transforms=2, \n",
    "#                                     transform=scripted_transforms,\n",
    "#                                     DEVICE='cpu',\n",
    "#                                     dtype_X=torch.float32,\n",
    "#                                     dtype_y=torch.int64 )\n",
    "\n",
    "# dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "#                                                 batch_size=1024,\n",
    "#                                                 shuffle=True,\n",
    "#                                                 drop_last=True,\n",
    "#                                                 pin_memory=False,\n",
    "#                                                 num_workers=0,\n",
    "# #                                                 num_workers=16,\n",
    "# #                                                 prefetch_factor=3,\n",
    "# #                                                 persistent_workers=True,\n",
    "#                                                 )\n",
    "\n",
    "\n",
    "# classHead = HeadModel(model, LogisticRegression)\n",
    "# dataset_train.set_headmodel(classHead)\n",
    "\n",
    "# n_epochs=300000\n",
    "\n",
    "# i_batch = 0\n",
    "# dl = dataset_train.__getitem__(0)\n",
    "# # if True:\n",
    "\n",
    "# # for i_batch, (X_batch, y_batch, idx_batch, sample_weight) in enumerate(dataloader_train):\n",
    "# for i_batch, (dl) in enumerate(dataloader_train):\n",
    "# #     print(X_batch)\n",
    "# #     print(y_batch)\n",
    "# #     print(idx_batch)\n",
    "# #     print(sample_weight)\n",
    "#     print(dl)\n",
    "    \n",
    "#     classHead.fit(X_train[:, None, :, :], y_train)\n",
    "#     dataset_train.set_headmodel(classHead)\n",
    "#     preds = classHead.predict(X_train[:, None, :, :])\n",
    "    \n",
    "#     class_weights = np.zeros((preds.shape[0], classHead.n_classes)).astype(int)\n",
    "#     class_weights[np.arange(preds.shape[0]), preds] = 1\n",
    "#     class_weights = class_weights.sum(axis=0)\n",
    "\n",
    "#     total_num = class_weights.sum()\n",
    "\n",
    "#     class_weights[class_weights == 0] = total_num\n",
    "#     class_weights[class_weights == 1] = total_num\n",
    "#     weightings = class_weights.sum()/class_weights\n",
    "#     final_weights = weightings / weightings.sum()\n",
    "\n",
    "#     dataset_train.set_classweights(final_weights)\n",
    "    \n",
    "#     print('dataset_train.final_weights', dataset_train.class_weights)\n",
    "    \n",
    "    \n",
    "#     sample_weight = torch.tensor([1.0], device=dataset_train.X.device)\n",
    "\n",
    "#     if dataset_train.headmodel is not None and dataset_train.headmodel.n_classes is not None:\n",
    "#         prediction = dataset_train.headmodel.predict(dataset_train.X[0:16])\n",
    "#         print(prediction)\n",
    "#         onehot_prediction = np.eye(dataset_train.headmodel.n_classes)[prediction]\n",
    "#         print(onehot_prediction)\n",
    "#         sample_weight = onehot_prediction * dataset_train.class_weights\n",
    "#         print(sample_weight)\n",
    "#         sample_weight = torch.tensor(sample_weight, device=dataset_train.X.device)\n",
    "#         print(sample_weight)\n",
    "#         sample_weight = sample_weight.sum(axis=-1)\n",
    "#         print(sample_weight)\n",
    "\n",
    "#     print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_train.class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dl in dataloader_train:\n",
    "#     print(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classHead.fit(X_train[:, None, :, :], y_train)\n",
    "# preds = classHead.predict(X_train[:, None, :, :])\n",
    "\n",
    "# class_weights = np.zeros((preds.shape[0], classHead.n_classes)).astype(int)\n",
    "# class_weights[np.arange(preds.shape[0]), preds] = 1\n",
    "# class_weights = class_weights.sum(axis=0)\n",
    "\n",
    "# total_num = class_weights.sum()\n",
    "\n",
    "# class_weights[class_weights == 0] = total_num\n",
    "# class_weights[class_weights == 1] = total_num\n",
    "# weightings = class_weights.sum()/class_weights\n",
    "# final_weights = weightings / weightings.sum()\n",
    "\n",
    "# dataset_train.set_classweights(final_weights)\n",
    "\n",
    "# # print(weightings)\n",
    "# # dataset_train.set_classweights(classHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg = RandomForestClassifier()\n",
    "# logreg.fit(classHead.get_simCLR_head(X_train[:,None,:,:]), y_train)\n",
    "# logreg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_epochs=300000\n",
    "# for epoch in range(n_epochs):\n",
    "#     print(f'epoch: {epoch}')\n",
    "#     training_simCLR.epoch_step( dataloader_train, \n",
    "#                                 model, \n",
    "#                                 optimizer, \n",
    "#                                 criterion, \n",
    "#                                 scheduler=scheduler, \n",
    "#                                 temperature=0.5,\n",
    "#                                 loss_rolling_train=losses_train, \n",
    "#                                 device=DEVICE, \n",
    "#                                 do_validation=False,\n",
    "#                                 validation_Object=val_obj,\n",
    "#                                 loss_rolling_val=losses_val,\n",
    "#                                 verbose=2,\n",
    "#                                 verbose_update_period=10,\n",
    "#                                )\n",
    "#     # model predict\n",
    "#     # Update model in DS\n",
    "#     # get item calls model for each sample\n",
    "#     # output\n",
    "#     # X sample weights predictions\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_mdl = torch.load('/Users/josh/Documents/Harvard/pretrained/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth',\n",
    "#                  map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(load_mdl)\n",
    "# # model.load_state_dict('/Users/josh/Documents/Harvard/pretrained/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(losses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in (dataloader_train):\n",
    "#     print(v)\n",
    "#     print(len(v))\n",
    "#     model(v)\n",
    "#     break\n",
    "\n",
    "# model(torch.tensor(X_train[:,None,:,:]).float())\n",
    "# tm = training_classHead.get_simCLR_interim(model, X_train[:, None, :, :])\n",
    "# tm = training_classHead.get_simCLR_output(model, X_train[:, None, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training_classHead\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# # # import training_classHead\n",
    "# # from training_classHead import HeadModel\n",
    "\n",
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# # from sklearn.tree import DecisionTreeClassifier\n",
    "# # from sklearn.ensemble import RandomForestClassifier\n",
    "# # from sklearn.svm import SVC\n",
    "# # from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # exp_X_train = X_train[:, None, :, :]\n",
    "# # exp_X_val = X_val[:, None, :, :]\n",
    "\n",
    "# # classHead = HeadModel(model, RandomForestClassifier).train(exp_X_train, y_train)\n",
    "# # prediction = classHead.predict(exp_X_val)\n",
    "\n",
    "# # print(classHead.score(exp_X_val, y_val))\n",
    "\n",
    "# # cm = confusion_matrix(y_val, prediction)\n",
    "# # print(cm)\n",
    "# # print(cm/cm.sum(axis=0))\n",
    "\n",
    "# # # prediction_proba = classHead.predict_proba(exp_X_val)\n",
    "\n",
    "\n",
    "\n",
    "# PredictionClass = RandomForestClassifier\n",
    "# logreg = training_classHead.train_head(model, PredictionClass, X_train[:, None, :, :], y_train)\n",
    "# prediction_proba = training_classHead.predict(model, logreg, X_val[:,None,...])\n",
    "# prediction = training_classHead.predict(model, logreg, X_val[:,None,...])\n",
    "\n",
    "# print(confusion_matrix(y_val, prediction))\n",
    "# print(logreg.score(training_classHead.get_simCLR_head(model, X_val[:,None,:,:]), y_val))\n",
    "\n",
    "# prediction = training_classHead.predict(model, logreg, X_val[:,None,...])\n",
    "\n",
    "# cm = confusion_matrix(y_val, prediction)\n",
    "# print(cm/cm.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC on Dendrite Classification\n",
    "# Goal: Accuracy / Precision of Dendrite Classification is most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with pd.option_context('max_rows', 3000):\n",
    "    display(pd.DataFrame(np.concatenate([y_val.reshape(-1,1), prediction.reshape(-1,1)], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_classHead.get_simCLR_interim(model, X_val[:,None,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model(torch.tensor(images_labeled, device=DEVICE, dtype=torch.float32)[:,None,...]).detach()\n",
    "# features = model(torch.tensor(X_val, device=DEVICE, dtype=torch.float32)[:,None,...]).detach()\n",
    "# features = model(torch.tensor(X_train, device=DEVICE, dtype=torch.float32)[:,None,...]).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, features_embedded, _, _ = decomposition.torch_pca(features, device=DEVICE, return_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, \n",
    "                     perplexity=90.0, \n",
    "                     early_exaggeration=12.0, \n",
    "                     learning_rate=200, \n",
    "                     n_iter=1000, \n",
    "                     n_iter_without_progress=300, \n",
    "                     min_grad_norm=1e-07, \n",
    "                     metric='euclidean', \n",
    "                     init='pca', \n",
    "                     verbose=0, \n",
    "                     random_state=None, \n",
    "                     method='barnes_hut', \n",
    "                     angle=0.5, \n",
    "                     n_jobs=-1, \n",
    "#                      square_distances='legacy'\n",
    "                    )\n",
    "features_embedded = tsne.fit_transform(features.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'Set1'\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.scatter(features_embedded[:,0], features_embedded[:,1], c=labels)\n",
    "# plt.scatter(features_embedded[:,0], features_embedded[:,1], c=y_val)\n",
    "# plt.scatter(features_embedded[:,4], features_embedded[:,5], c=y_train)\n",
    "# plt.scatter(features_embedded[:,11], features[:,43].cpu(), c=y_train)\n",
    "mpl.rcParams['image.cmap'] = 'viridis'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer_1 = model.state_dict()['cnn_layers.0.weight'].cpu()\n",
    "layer_2 = model.state_dict()['cnn_layers.2.weight'].cpu()\n",
    "layer_3 = model.state_dict()['cnn_layers.5.weight'].cpu()\n",
    "layer_4 = model.state_dict()['cnn_layers.8.weight'].cpu()\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_1.shape[1]):\n",
    "    for jj in range(layer_1.shape[0]):\n",
    "        plt.subplot2grid((layer_1.shape[1],layer_1.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_1[jj,ii,:,:] , clim=(-0.2,0.2))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(layer_2.shape[1]):\n",
    "    for jj in range(layer_2.shape[0]):\n",
    "        plt.subplot2grid((layer_2.shape[1],layer_2.shape[0]),(ii,jj))\n",
    "        fig = plt.imshow(layer_2[jj,ii,:,:], clim=(-.05,.05))\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_3[jj, ii,:,:])\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.figure()\n",
    "for ii in range(16):\n",
    "    for jj in range(16):\n",
    "        plt.subplot2grid((16,16),(ii,jj))\n",
    "        fig = plt.imshow(layer_4[jj, ii,:,:])\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/media/rich/bigSSD/Net_trainedOnAug_20211025_trainingSet_mouse628_20200903and20200815_simCLR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model.load_state_dict(torch.load('test_save.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "943px",
    "left": "1381px",
    "right": "20px",
    "top": "106px",
    "width": "501px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
